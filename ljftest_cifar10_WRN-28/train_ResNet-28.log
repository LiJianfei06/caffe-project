WARNING: Logging before InitGoogleLogging() is written to STDERR
I1003 12:39:09.417467  5017 caffe.cpp:530] argc:5 lijianfei debug!!!!!!!!!!
I1003 12:39:09.417579  5017 caffe.cpp:533] argv[0]:../../build/tools/caffe lijianfei debug!!!!!!!!!!
I1003 12:39:09.417584  5017 caffe.cpp:533] argv[1]:train lijianfei debug!!!!!!!!!!
I1003 12:39:09.417590  5017 caffe.cpp:533] argv[2]:--solver=./solver.prototxt lijianfei debug!!!!!!!!!!
I1003 12:39:09.417594  5017 caffe.cpp:533] argv[3]:--weights= lijianfei debug!!!!!!!!!!
I1003 12:39:09.417598  5017 caffe.cpp:533] argv[4]:--gpu=0 lijianfei debug!!!!!!!!!!
I1003 12:39:09.417659  5017 caffe.cpp:548] use WITH_PYTHON_LAYER lijianfei debug!!!!!!!!!!
I1003 12:39:09.417825  5017 caffe.cpp:553] caffe::string(argv[1]):train lijianfei debug!!!!!!!!!!
I1003 12:39:09.419668  5017 caffe.cpp:238] stages: lijianfei debug!!!!!!!!!!!!
I1003 12:39:09.419708  5017 caffe.cpp:269] Using GPUs 0
I1003 12:39:09.449214  5017 caffe.cpp:274] GPU 0: GeForce GTX 1060 6GB
I1003 12:39:09.851150  5017 solver_factory.hpp:111] function Solver<Dtype>* CreateSolver()  lijianfei debug!!!!!!!!!!
I1003 12:39:09.851192  5017 solver_factory.hpp:113] type:Nesterov lijianfei debug!!!!!!!!!!
I1003 12:39:09.870919  5017 solver.cpp:97] Initializing solver from parameters: 
train_net: "./train_WRN_28.prototxt"
test_net: "./test_WRN_28.prototxt"
test_iter: 1000
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "./model_save/cifar10_WRN_28"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
stepvalue: 32000
stepvalue: 48000
iter_size: 4
type: "Nesterov"
I1003 12:39:09.871178  5017 solver.cpp:167] Creating training net from train_net file: ./train_WRN_28.prototxt
I1003 12:39:09.872436  5017 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./train_WRN_28.prototxt
I1003 12:39:09.872460  5017 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I1003 12:39:09.873700  5017 net.cpp:82] Initializing net from parameters: 
name: "WRN-28"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: true
    crop_size: 32
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_Drop1"
  type: "Dropout"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_down"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn_down"
  type: "BatchNorm"
  bottom: "conv2_1_down"
  top: "conv2_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale_down"
  type: "Scale"
  bottom: "conv2_1_down"
  top: "conv2_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv2_1_1"
  bottom: "conv2_1_down"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_Drop2"
  type: "Dropout"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_Drop3"
  type: "Dropout"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv2_4_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv2_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4_bn0"
  type: "BatchNorm"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_4_scale0"
  type: "Scale"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_4_ReLU0"
  type: "ReLU"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
}
layer {
  name: "conv2_Drop4"
  type: "Dropout"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv2_4_1"
  type: "Convolution"
  bottom: "conv2_4_0"
  top: "conv2_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4bn1"
  type: "BatchNorm"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_4_scale1"
  type: "Scale"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_4"
  type: "Eltwise"
  bottom: "conv2_Eltwise_3"
  bottom: "conv2_4_1"
  top: "conv2_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_4ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_4"
  top: "conv2_Eltwise_4"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_4"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_Drop1"
  type: "Dropout"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_4"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_Drop2"
  type: "Dropout"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_Drop3"
  type: "Dropout"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv3_4_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv3_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4_bn0"
  type: "BatchNorm"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_4_scale0"
  type: "Scale"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_ReLU0"
  type: "ReLU"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
}
layer {
  name: "conv3_Drop4"
  type: "Dropout"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv3_4_1"
  type: "Convolution"
  bottom: "conv3_4_0"
  top: "conv3_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4bn1"
  type: "BatchNorm"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_4_scale1"
  type: "Scale"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_4"
  type: "Eltwise"
  bottom: "conv3_Eltwise_3"
  bottom: "conv3_4_1"
  top: "conv3_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_4ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_4"
  top: "conv3_Eltwise_4"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_4"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_Drop1"
  type: "Dropout"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_4"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_Drop2"
  type: "Dropout"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_Drop3"
  type: "Dropout"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "conv4_4_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_3"
  top: "conv4_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_4_bn0"
  type: "BatchNorm"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_4_scale0"
  type: "Scale"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4_ReLU0"
  type: "ReLU"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
}
layer {
  name: "conv4_Drop4"
  type: "Dropout"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "conv4_4_1"
  type: "Convolution"
  bottom: "conv4_4_0"
  top: "conv4_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_4bn1"
  type: "BatchNorm"
  bottom: "conv4_4_1"
  top: "conv4_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_4_scale1"
  type: "Scale"
  bottom: "conv4_4_1"
  top: "conv4_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_4"
  type: "Eltwise"
  bottom: "conv4_Eltwise_3"
  bottom: "conv4_4_1"
  top: "conv4_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_4ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_4"
  top: "conv4_Eltwise_4"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "conv4_Eltwise_4"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
   
I1003 12:39:09.874361  5017 layer_factory.hpp:77] Creating layer Data1
I1003 12:39:09.874562  5017 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/train_lmdb
I1003 12:39:09.874604  5017 net.cpp:128] Creating Layer Data1
I1003 12:39:09.874614  5017 net.cpp:522] Data1 -> data
I1003 12:39:09.874642  5017 net.cpp:522] Data1 -> label
I1003 12:39:09.876268  5017 data_layer.cpp:45] output data size: 32,3,32,32
I1003 12:39:09.878829  5017 net.cpp:172] Setting up Data1
I1003 12:39:09.878856  5017 net.cpp:186] Top shape: 32 3 32 32 (98304)
I1003 12:39:09.878862  5017 net.cpp:186] Top shape: 32 (32)
I1003 12:39:09.878866  5017 net.cpp:194] Memory required for data: 393344
I1003 12:39:09.878876  5017 layer_factory.hpp:77] Creating layer conv1
I1003 12:39:09.878926  5017 net.cpp:128] Creating Layer conv1
I1003 12:39:09.878933  5017 net.cpp:558] conv1 <- data
I1003 12:39:09.878950  5017 net.cpp:522] conv1 -> conv1
I1003 12:39:10.630921  5017 net.cpp:172] Setting up conv1
I1003 12:39:10.630980  5017 net.cpp:186] Top shape: 32 16 32 32 (524288)
I1003 12:39:10.630985  5017 net.cpp:194] Memory required for data: 2490496
I1003 12:39:10.631021  5017 layer_factory.hpp:77] Creating layer conv1/bn
I1003 12:39:10.631038  5017 net.cpp:128] Creating Layer conv1/bn
I1003 12:39:10.631047  5017 net.cpp:558] conv1/bn <- conv1
I1003 12:39:10.631055  5017 net.cpp:509] conv1/bn -> conv1 (in-place)
I1003 12:39:10.631322  5017 net.cpp:172] Setting up conv1/bn
I1003 12:39:10.631335  5017 net.cpp:186] Top shape: 32 16 32 32 (524288)
I1003 12:39:10.631340  5017 net.cpp:194] Memory required for data: 4587648
I1003 12:39:10.631356  5017 layer_factory.hpp:77] Creating layer conv1/scale
I1003 12:39:10.631364  5017 net.cpp:128] Creating Layer conv1/scale
I1003 12:39:10.631368  5017 net.cpp:558] conv1/scale <- conv1
I1003 12:39:10.631374  5017 net.cpp:509] conv1/scale -> conv1 (in-place)
I1003 12:39:10.631422  5017 layer_factory.hpp:77] Creating layer conv1/scale
I1003 12:39:10.631543  5017 net.cpp:172] Setting up conv1/scale
I1003 12:39:10.631557  5017 net.cpp:186] Top shape: 32 16 32 32 (524288)
I1003 12:39:10.631561  5017 net.cpp:194] Memory required for data: 6684800
I1003 12:39:10.631572  5017 layer_factory.hpp:77] Creating layer conv1/ReLU
I1003 12:39:10.631580  5017 net.cpp:128] Creating Layer conv1/ReLU
I1003 12:39:10.631584  5017 net.cpp:558] conv1/ReLU <- conv1
I1003 12:39:10.631589  5017 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I1003 12:39:10.631808  5017 net.cpp:172] Setting up conv1/ReLU
I1003 12:39:10.631820  5017 net.cpp:186] Top shape: 32 16 32 32 (524288)
I1003 12:39:10.631824  5017 net.cpp:194] Memory required for data: 8781952
I1003 12:39:10.631829  5017 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I1003 12:39:10.631837  5017 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I1003 12:39:10.631841  5017 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I1003 12:39:10.631848  5017 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I1003 12:39:10.631856  5017 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I1003 12:39:10.631899  5017 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I1003 12:39:10.631906  5017 net.cpp:186] Top shape: 32 16 32 32 (524288)
I1003 12:39:10.631913  5017 net.cpp:186] Top shape: 32 16 32 32 (524288)
I1003 12:39:10.631917  5017 net.cpp:194] Memory required for data: 12976256
I1003 12:39:10.631922  5017 layer_factory.hpp:77] Creating layer conv2_1_0
I1003 12:39:10.631934  5017 net.cpp:128] Creating Layer conv2_1_0
I1003 12:39:10.631938  5017 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I1003 12:39:10.631945  5017 net.cpp:522] conv2_1_0 -> conv2_1_0
I1003 12:39:10.634896  5017 net.cpp:172] Setting up conv2_1_0
I1003 12:39:10.634925  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.634929  5017 net.cpp:194] Memory required for data: 33947776
I1003 12:39:10.634943  5017 layer_factory.hpp:77] Creating layer conv2_1_bn0
I1003 12:39:10.634953  5017 net.cpp:128] Creating Layer conv2_1_bn0
I1003 12:39:10.634958  5017 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I1003 12:39:10.634969  5017 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I1003 12:39:10.635185  5017 net.cpp:172] Setting up conv2_1_bn0
I1003 12:39:10.635195  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.635200  5017 net.cpp:194] Memory required for data: 54919296
I1003 12:39:10.635210  5017 layer_factory.hpp:77] Creating layer conv2_1_scale0
I1003 12:39:10.635217  5017 net.cpp:128] Creating Layer conv2_1_scale0
I1003 12:39:10.635222  5017 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I1003 12:39:10.635228  5017 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I1003 12:39:10.635267  5017 layer_factory.hpp:77] Creating layer conv2_1_scale0
I1003 12:39:10.635382  5017 net.cpp:172] Setting up conv2_1_scale0
I1003 12:39:10.635394  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.635398  5017 net.cpp:194] Memory required for data: 75890816
I1003 12:39:10.635407  5017 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I1003 12:39:10.635413  5017 net.cpp:128] Creating Layer conv2_1_ReLU0
I1003 12:39:10.635417  5017 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I1003 12:39:10.635423  5017 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I1003 12:39:10.635633  5017 net.cpp:172] Setting up conv2_1_ReLU0
I1003 12:39:10.635648  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.635653  5017 net.cpp:194] Memory required for data: 96862336
I1003 12:39:10.635673  5017 layer_factory.hpp:77] Creating layer conv2_Drop1
I1003 12:39:10.635682  5017 net.cpp:128] Creating Layer conv2_Drop1
I1003 12:39:10.635687  5017 net.cpp:558] conv2_Drop1 <- conv2_1_0
I1003 12:39:10.635694  5017 net.cpp:509] conv2_Drop1 -> conv2_1_0 (in-place)
I1003 12:39:10.635725  5017 net.cpp:172] Setting up conv2_Drop1
I1003 12:39:10.635732  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.635736  5017 net.cpp:194] Memory required for data: 117833856
I1003 12:39:10.635740  5017 layer_factory.hpp:77] Creating layer conv2_1_1
I1003 12:39:10.635751  5017 net.cpp:128] Creating Layer conv2_1_1
I1003 12:39:10.635756  5017 net.cpp:558] conv2_1_1 <- conv2_1_0
I1003 12:39:10.635761  5017 net.cpp:522] conv2_1_1 -> conv2_1_1
I1003 12:39:10.641816  5017 net.cpp:172] Setting up conv2_1_1
I1003 12:39:10.641846  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.641851  5017 net.cpp:194] Memory required for data: 138805376
I1003 12:39:10.641862  5017 layer_factory.hpp:77] Creating layer conv2_1bn1
I1003 12:39:10.641872  5017 net.cpp:128] Creating Layer conv2_1bn1
I1003 12:39:10.641877  5017 net.cpp:558] conv2_1bn1 <- conv2_1_1
I1003 12:39:10.641885  5017 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I1003 12:39:10.642133  5017 net.cpp:172] Setting up conv2_1bn1
I1003 12:39:10.642145  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.642150  5017 net.cpp:194] Memory required for data: 159776896
I1003 12:39:10.642163  5017 layer_factory.hpp:77] Creating layer conv2_1_scale1
I1003 12:39:10.642171  5017 net.cpp:128] Creating Layer conv2_1_scale1
I1003 12:39:10.642176  5017 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I1003 12:39:10.642182  5017 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I1003 12:39:10.642223  5017 layer_factory.hpp:77] Creating layer conv2_1_scale1
I1003 12:39:10.642347  5017 net.cpp:172] Setting up conv2_1_scale1
I1003 12:39:10.642359  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.642362  5017 net.cpp:194] Memory required for data: 180748416
I1003 12:39:10.642370  5017 layer_factory.hpp:77] Creating layer conv2_1_down
I1003 12:39:10.642380  5017 net.cpp:128] Creating Layer conv2_1_down
I1003 12:39:10.642385  5017 net.cpp:558] conv2_1_down <- conv1_conv1/ReLU_0_split_1
I1003 12:39:10.642392  5017 net.cpp:522] conv2_1_down -> conv2_1_down
I1003 12:39:10.644773  5017 net.cpp:172] Setting up conv2_1_down
I1003 12:39:10.644795  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.644799  5017 net.cpp:194] Memory required for data: 201719936
I1003 12:39:10.644809  5017 layer_factory.hpp:77] Creating layer conv2_1_bn_down
I1003 12:39:10.644819  5017 net.cpp:128] Creating Layer conv2_1_bn_down
I1003 12:39:10.644824  5017 net.cpp:558] conv2_1_bn_down <- conv2_1_down
I1003 12:39:10.644835  5017 net.cpp:509] conv2_1_bn_down -> conv2_1_down (in-place)
I1003 12:39:10.645053  5017 net.cpp:172] Setting up conv2_1_bn_down
I1003 12:39:10.645064  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.645069  5017 net.cpp:194] Memory required for data: 222691456
I1003 12:39:10.645079  5017 layer_factory.hpp:77] Creating layer conv2_1_scale_down
I1003 12:39:10.645089  5017 net.cpp:128] Creating Layer conv2_1_scale_down
I1003 12:39:10.645093  5017 net.cpp:558] conv2_1_scale_down <- conv2_1_down
I1003 12:39:10.645099  5017 net.cpp:509] conv2_1_scale_down -> conv2_1_down (in-place)
I1003 12:39:10.645141  5017 layer_factory.hpp:77] Creating layer conv2_1_scale_down
I1003 12:39:10.645258  5017 net.cpp:172] Setting up conv2_1_scale_down
I1003 12:39:10.645272  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.645275  5017 net.cpp:194] Memory required for data: 243662976
I1003 12:39:10.645283  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I1003 12:39:10.645292  5017 net.cpp:128] Creating Layer conv2_Eltwise_1
I1003 12:39:10.645295  5017 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I1003 12:39:10.645300  5017 net.cpp:558] conv2_Eltwise_1 <- conv2_1_down
I1003 12:39:10.645306  5017 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I1003 12:39:10.645359  5017 net.cpp:172] Setting up conv2_Eltwise_1
I1003 12:39:10.645366  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.645370  5017 net.cpp:194] Memory required for data: 264634496
I1003 12:39:10.645375  5017 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I1003 12:39:10.645381  5017 net.cpp:128] Creating Layer conv2_1ReLU_1
I1003 12:39:10.645385  5017 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I1003 12:39:10.645391  5017 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I1003 12:39:10.645799  5017 net.cpp:172] Setting up conv2_1ReLU_1
I1003 12:39:10.645820  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.645825  5017 net.cpp:194] Memory required for data: 285606016
I1003 12:39:10.645830  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1003 12:39:10.645839  5017 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1003 12:39:10.645844  5017 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I1003 12:39:10.645851  5017 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I1003 12:39:10.645860  5017 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I1003 12:39:10.645916  5017 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1003 12:39:10.645925  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.645931  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.645936  5017 net.cpp:194] Memory required for data: 327549056
I1003 12:39:10.645941  5017 layer_factory.hpp:77] Creating layer conv2_2_0
I1003 12:39:10.645951  5017 net.cpp:128] Creating Layer conv2_2_0
I1003 12:39:10.645956  5017 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I1003 12:39:10.645963  5017 net.cpp:522] conv2_2_0 -> conv2_2_0
I1003 12:39:10.650913  5017 net.cpp:172] Setting up conv2_2_0
I1003 12:39:10.650939  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.650944  5017 net.cpp:194] Memory required for data: 348520576
I1003 12:39:10.650954  5017 layer_factory.hpp:77] Creating layer conv2_2_bn0
I1003 12:39:10.650964  5017 net.cpp:128] Creating Layer conv2_2_bn0
I1003 12:39:10.650969  5017 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I1003 12:39:10.650975  5017 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I1003 12:39:10.651211  5017 net.cpp:172] Setting up conv2_2_bn0
I1003 12:39:10.651221  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.651226  5017 net.cpp:194] Memory required for data: 369492096
I1003 12:39:10.651239  5017 layer_factory.hpp:77] Creating layer conv2_2_scale0
I1003 12:39:10.651247  5017 net.cpp:128] Creating Layer conv2_2_scale0
I1003 12:39:10.651252  5017 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I1003 12:39:10.651257  5017 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I1003 12:39:10.651299  5017 layer_factory.hpp:77] Creating layer conv2_2_scale0
I1003 12:39:10.651437  5017 net.cpp:172] Setting up conv2_2_scale0
I1003 12:39:10.651448  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.651453  5017 net.cpp:194] Memory required for data: 390463616
I1003 12:39:10.651459  5017 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I1003 12:39:10.651466  5017 net.cpp:128] Creating Layer conv2_2_ReLU0
I1003 12:39:10.651470  5017 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I1003 12:39:10.651475  5017 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I1003 12:39:10.651687  5017 net.cpp:172] Setting up conv2_2_ReLU0
I1003 12:39:10.651700  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.651705  5017 net.cpp:194] Memory required for data: 411435136
I1003 12:39:10.651708  5017 layer_factory.hpp:77] Creating layer conv2_Drop2
I1003 12:39:10.651716  5017 net.cpp:128] Creating Layer conv2_Drop2
I1003 12:39:10.651721  5017 net.cpp:558] conv2_Drop2 <- conv2_2_0
I1003 12:39:10.651726  5017 net.cpp:509] conv2_Drop2 -> conv2_2_0 (in-place)
I1003 12:39:10.651754  5017 net.cpp:172] Setting up conv2_Drop2
I1003 12:39:10.651782  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.651785  5017 net.cpp:194] Memory required for data: 432406656
I1003 12:39:10.651790  5017 layer_factory.hpp:77] Creating layer conv2_2_1
I1003 12:39:10.651799  5017 net.cpp:128] Creating Layer conv2_2_1
I1003 12:39:10.651804  5017 net.cpp:558] conv2_2_1 <- conv2_2_0
I1003 12:39:10.651811  5017 net.cpp:522] conv2_2_1 -> conv2_2_1
I1003 12:39:10.657985  5017 net.cpp:172] Setting up conv2_2_1
I1003 12:39:10.658015  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.658020  5017 net.cpp:194] Memory required for data: 453378176
I1003 12:39:10.658030  5017 layer_factory.hpp:77] Creating layer conv2_2bn1
I1003 12:39:10.658041  5017 net.cpp:128] Creating Layer conv2_2bn1
I1003 12:39:10.658046  5017 net.cpp:558] conv2_2bn1 <- conv2_2_1
I1003 12:39:10.658053  5017 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I1003 12:39:10.658285  5017 net.cpp:172] Setting up conv2_2bn1
I1003 12:39:10.658298  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.658303  5017 net.cpp:194] Memory required for data: 474349696
I1003 12:39:10.658313  5017 layer_factory.hpp:77] Creating layer conv2_2_scale1
I1003 12:39:10.658319  5017 net.cpp:128] Creating Layer conv2_2_scale1
I1003 12:39:10.658324  5017 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I1003 12:39:10.658329  5017 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I1003 12:39:10.658370  5017 layer_factory.hpp:77] Creating layer conv2_2_scale1
I1003 12:39:10.658493  5017 net.cpp:172] Setting up conv2_2_scale1
I1003 12:39:10.658504  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.658507  5017 net.cpp:194] Memory required for data: 495321216
I1003 12:39:10.658515  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I1003 12:39:10.658522  5017 net.cpp:128] Creating Layer conv2_Eltwise_2
I1003 12:39:10.658566  5017 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I1003 12:39:10.658571  5017 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I1003 12:39:10.658578  5017 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I1003 12:39:10.658603  5017 net.cpp:172] Setting up conv2_Eltwise_2
I1003 12:39:10.658610  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.658614  5017 net.cpp:194] Memory required for data: 516292736
I1003 12:39:10.658618  5017 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I1003 12:39:10.658624  5017 net.cpp:128] Creating Layer conv2_2ReLU_1
I1003 12:39:10.658628  5017 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I1003 12:39:10.658634  5017 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I1003 12:39:10.658851  5017 net.cpp:172] Setting up conv2_2ReLU_1
I1003 12:39:10.658864  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.658869  5017 net.cpp:194] Memory required for data: 537264256
I1003 12:39:10.658874  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1003 12:39:10.658881  5017 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1003 12:39:10.658885  5017 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I1003 12:39:10.658892  5017 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I1003 12:39:10.658900  5017 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I1003 12:39:10.659054  5017 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1003 12:39:10.659062  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.659068  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.659072  5017 net.cpp:194] Memory required for data: 579207296
I1003 12:39:10.659076  5017 layer_factory.hpp:77] Creating layer conv2_3_0
I1003 12:39:10.659087  5017 net.cpp:128] Creating Layer conv2_3_0
I1003 12:39:10.659091  5017 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I1003 12:39:10.659098  5017 net.cpp:522] conv2_3_0 -> conv2_3_0
I1003 12:39:10.664000  5017 net.cpp:172] Setting up conv2_3_0
I1003 12:39:10.664042  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.664047  5017 net.cpp:194] Memory required for data: 600178816
I1003 12:39:10.664062  5017 layer_factory.hpp:77] Creating layer conv2_3_bn0
I1003 12:39:10.664072  5017 net.cpp:128] Creating Layer conv2_3_bn0
I1003 12:39:10.664080  5017 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I1003 12:39:10.664086  5017 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I1003 12:39:10.664324  5017 net.cpp:172] Setting up conv2_3_bn0
I1003 12:39:10.664335  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.664338  5017 net.cpp:194] Memory required for data: 621150336
I1003 12:39:10.664348  5017 layer_factory.hpp:77] Creating layer conv2_3_scale0
I1003 12:39:10.664358  5017 net.cpp:128] Creating Layer conv2_3_scale0
I1003 12:39:10.664362  5017 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I1003 12:39:10.664368  5017 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I1003 12:39:10.664410  5017 layer_factory.hpp:77] Creating layer conv2_3_scale0
I1003 12:39:10.664536  5017 net.cpp:172] Setting up conv2_3_scale0
I1003 12:39:10.664547  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.664552  5017 net.cpp:194] Memory required for data: 642121856
I1003 12:39:10.664559  5017 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I1003 12:39:10.664566  5017 net.cpp:128] Creating Layer conv2_3_ReLU0
I1003 12:39:10.664571  5017 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I1003 12:39:10.664575  5017 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I1003 12:39:10.664980  5017 net.cpp:172] Setting up conv2_3_ReLU0
I1003 12:39:10.665000  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.665005  5017 net.cpp:194] Memory required for data: 663093376
I1003 12:39:10.665010  5017 layer_factory.hpp:77] Creating layer conv2_Drop3
I1003 12:39:10.665019  5017 net.cpp:128] Creating Layer conv2_Drop3
I1003 12:39:10.665024  5017 net.cpp:558] conv2_Drop3 <- conv2_3_0
I1003 12:39:10.665031  5017 net.cpp:509] conv2_Drop3 -> conv2_3_0 (in-place)
I1003 12:39:10.665062  5017 net.cpp:172] Setting up conv2_Drop3
I1003 12:39:10.665071  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.665076  5017 net.cpp:194] Memory required for data: 684064896
I1003 12:39:10.665079  5017 layer_factory.hpp:77] Creating layer conv2_3_1
I1003 12:39:10.665091  5017 net.cpp:128] Creating Layer conv2_3_1
I1003 12:39:10.665094  5017 net.cpp:558] conv2_3_1 <- conv2_3_0
I1003 12:39:10.665102  5017 net.cpp:522] conv2_3_1 -> conv2_3_1
I1003 12:39:10.671304  5017 net.cpp:172] Setting up conv2_3_1
I1003 12:39:10.671334  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.671339  5017 net.cpp:194] Memory required for data: 705036416
I1003 12:39:10.671355  5017 layer_factory.hpp:77] Creating layer conv2_3bn1
I1003 12:39:10.671365  5017 net.cpp:128] Creating Layer conv2_3bn1
I1003 12:39:10.671372  5017 net.cpp:558] conv2_3bn1 <- conv2_3_1
I1003 12:39:10.671380  5017 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I1003 12:39:10.671620  5017 net.cpp:172] Setting up conv2_3bn1
I1003 12:39:10.671631  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.671635  5017 net.cpp:194] Memory required for data: 726007936
I1003 12:39:10.671645  5017 layer_factory.hpp:77] Creating layer conv2_3_scale1
I1003 12:39:10.671654  5017 net.cpp:128] Creating Layer conv2_3_scale1
I1003 12:39:10.671664  5017 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I1003 12:39:10.671670  5017 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I1003 12:39:10.671713  5017 layer_factory.hpp:77] Creating layer conv2_3_scale1
I1003 12:39:10.671845  5017 net.cpp:172] Setting up conv2_3_scale1
I1003 12:39:10.671854  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.671859  5017 net.cpp:194] Memory required for data: 746979456
I1003 12:39:10.671867  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I1003 12:39:10.671875  5017 net.cpp:128] Creating Layer conv2_Eltwise_3
I1003 12:39:10.671880  5017 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I1003 12:39:10.671903  5017 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I1003 12:39:10.671911  5017 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I1003 12:39:10.671937  5017 net.cpp:172] Setting up conv2_Eltwise_3
I1003 12:39:10.671947  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.671952  5017 net.cpp:194] Memory required for data: 767950976
I1003 12:39:10.671955  5017 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I1003 12:39:10.671962  5017 net.cpp:128] Creating Layer conv2_3ReLU_1
I1003 12:39:10.671967  5017 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I1003 12:39:10.671972  5017 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I1003 12:39:10.672194  5017 net.cpp:172] Setting up conv2_3ReLU_1
I1003 12:39:10.672207  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.672211  5017 net.cpp:194] Memory required for data: 788922496
I1003 12:39:10.672215  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1003 12:39:10.672224  5017 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1003 12:39:10.672227  5017 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I1003 12:39:10.672235  5017 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I1003 12:39:10.672242  5017 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I1003 12:39:10.672286  5017 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1003 12:39:10.672296  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.672302  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.672304  5017 net.cpp:194] Memory required for data: 830865536
I1003 12:39:10.672309  5017 layer_factory.hpp:77] Creating layer conv2_4_0
I1003 12:39:10.672319  5017 net.cpp:128] Creating Layer conv2_4_0
I1003 12:39:10.672327  5017 net.cpp:558] conv2_4_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I1003 12:39:10.672333  5017 net.cpp:522] conv2_4_0 -> conv2_4_0
I1003 12:39:10.677258  5017 net.cpp:172] Setting up conv2_4_0
I1003 12:39:10.677286  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.677290  5017 net.cpp:194] Memory required for data: 851837056
I1003 12:39:10.677305  5017 layer_factory.hpp:77] Creating layer conv2_4_bn0
I1003 12:39:10.677314  5017 net.cpp:128] Creating Layer conv2_4_bn0
I1003 12:39:10.677321  5017 net.cpp:558] conv2_4_bn0 <- conv2_4_0
I1003 12:39:10.677335  5017 net.cpp:509] conv2_4_bn0 -> conv2_4_0 (in-place)
I1003 12:39:10.677574  5017 net.cpp:172] Setting up conv2_4_bn0
I1003 12:39:10.677584  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.677588  5017 net.cpp:194] Memory required for data: 872808576
I1003 12:39:10.677598  5017 layer_factory.hpp:77] Creating layer conv2_4_scale0
I1003 12:39:10.677606  5017 net.cpp:128] Creating Layer conv2_4_scale0
I1003 12:39:10.677611  5017 net.cpp:558] conv2_4_scale0 <- conv2_4_0
I1003 12:39:10.677616  5017 net.cpp:509] conv2_4_scale0 -> conv2_4_0 (in-place)
I1003 12:39:10.677659  5017 layer_factory.hpp:77] Creating layer conv2_4_scale0
I1003 12:39:10.677788  5017 net.cpp:172] Setting up conv2_4_scale0
I1003 12:39:10.677798  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.677803  5017 net.cpp:194] Memory required for data: 893780096
I1003 12:39:10.677809  5017 layer_factory.hpp:77] Creating layer conv2_4_ReLU0
I1003 12:39:10.677816  5017 net.cpp:128] Creating Layer conv2_4_ReLU0
I1003 12:39:10.677820  5017 net.cpp:558] conv2_4_ReLU0 <- conv2_4_0
I1003 12:39:10.677825  5017 net.cpp:509] conv2_4_ReLU0 -> conv2_4_0 (in-place)
I1003 12:39:10.678057  5017 net.cpp:172] Setting up conv2_4_ReLU0
I1003 12:39:10.678072  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.678076  5017 net.cpp:194] Memory required for data: 914751616
I1003 12:39:10.678081  5017 layer_factory.hpp:77] Creating layer conv2_Drop4
I1003 12:39:10.678089  5017 net.cpp:128] Creating Layer conv2_Drop4
I1003 12:39:10.678093  5017 net.cpp:558] conv2_Drop4 <- conv2_4_0
I1003 12:39:10.678118  5017 net.cpp:509] conv2_Drop4 -> conv2_4_0 (in-place)
I1003 12:39:10.678150  5017 net.cpp:172] Setting up conv2_Drop4
I1003 12:39:10.678160  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.678164  5017 net.cpp:194] Memory required for data: 935723136
I1003 12:39:10.678169  5017 layer_factory.hpp:77] Creating layer conv2_4_1
I1003 12:39:10.678179  5017 net.cpp:128] Creating Layer conv2_4_1
I1003 12:39:10.678182  5017 net.cpp:558] conv2_4_1 <- conv2_4_0
I1003 12:39:10.678189  5017 net.cpp:522] conv2_4_1 -> conv2_4_1
I1003 12:39:10.684411  5017 net.cpp:172] Setting up conv2_4_1
I1003 12:39:10.684440  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.684445  5017 net.cpp:194] Memory required for data: 956694656
I1003 12:39:10.684468  5017 layer_factory.hpp:77] Creating layer conv2_4bn1
I1003 12:39:10.684487  5017 net.cpp:128] Creating Layer conv2_4bn1
I1003 12:39:10.684495  5017 net.cpp:558] conv2_4bn1 <- conv2_4_1
I1003 12:39:10.684504  5017 net.cpp:509] conv2_4bn1 -> conv2_4_1 (in-place)
I1003 12:39:10.684751  5017 net.cpp:172] Setting up conv2_4bn1
I1003 12:39:10.684762  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.684767  5017 net.cpp:194] Memory required for data: 977666176
I1003 12:39:10.684777  5017 layer_factory.hpp:77] Creating layer conv2_4_scale1
I1003 12:39:10.684784  5017 net.cpp:128] Creating Layer conv2_4_scale1
I1003 12:39:10.684789  5017 net.cpp:558] conv2_4_scale1 <- conv2_4_1
I1003 12:39:10.684794  5017 net.cpp:509] conv2_4_scale1 -> conv2_4_1 (in-place)
I1003 12:39:10.684839  5017 layer_factory.hpp:77] Creating layer conv2_4_scale1
I1003 12:39:10.684969  5017 net.cpp:172] Setting up conv2_4_scale1
I1003 12:39:10.684980  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.684984  5017 net.cpp:194] Memory required for data: 998637696
I1003 12:39:10.684991  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_4
I1003 12:39:10.684999  5017 net.cpp:128] Creating Layer conv2_Eltwise_4
I1003 12:39:10.685004  5017 net.cpp:558] conv2_Eltwise_4 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I1003 12:39:10.685009  5017 net.cpp:558] conv2_Eltwise_4 <- conv2_4_1
I1003 12:39:10.685015  5017 net.cpp:522] conv2_Eltwise_4 -> conv2_Eltwise_4
I1003 12:39:10.685041  5017 net.cpp:172] Setting up conv2_Eltwise_4
I1003 12:39:10.685050  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.685055  5017 net.cpp:194] Memory required for data: 1019609216
I1003 12:39:10.685060  5017 layer_factory.hpp:77] Creating layer conv2_4ReLU_1
I1003 12:39:10.685065  5017 net.cpp:128] Creating Layer conv2_4ReLU_1
I1003 12:39:10.685070  5017 net.cpp:558] conv2_4ReLU_1 <- conv2_Eltwise_4
I1003 12:39:10.685075  5017 net.cpp:509] conv2_4ReLU_1 -> conv2_Eltwise_4 (in-place)
I1003 12:39:10.685297  5017 net.cpp:172] Setting up conv2_4ReLU_1
I1003 12:39:10.685312  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.685315  5017 net.cpp:194] Memory required for data: 1040580736
I1003 12:39:10.685320  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I1003 12:39:10.685328  5017 net.cpp:128] Creating Layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I1003 12:39:10.685333  5017 net.cpp:558] conv2_Eltwise_4_conv2_4ReLU_1_0_split <- conv2_Eltwise_4
I1003 12:39:10.685338  5017 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I1003 12:39:10.685346  5017 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I1003 12:39:10.685391  5017 net.cpp:172] Setting up conv2_Eltwise_4_conv2_4ReLU_1_0_split
I1003 12:39:10.685398  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.685405  5017 net.cpp:186] Top shape: 32 160 32 32 (5242880)
I1003 12:39:10.685408  5017 net.cpp:194] Memory required for data: 1082523776
I1003 12:39:10.685412  5017 layer_factory.hpp:77] Creating layer conv3_1_0
I1003 12:39:10.685422  5017 net.cpp:128] Creating Layer conv3_1_0
I1003 12:39:10.685427  5017 net.cpp:558] conv3_1_0 <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I1003 12:39:10.685451  5017 net.cpp:522] conv3_1_0 -> conv3_1_0
I1003 12:39:10.695235  5017 net.cpp:172] Setting up conv3_1_0
I1003 12:39:10.695264  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.695268  5017 net.cpp:194] Memory required for data: 1093009536
I1003 12:39:10.695279  5017 layer_factory.hpp:77] Creating layer conv3_1_bn0
I1003 12:39:10.695291  5017 net.cpp:128] Creating Layer conv3_1_bn0
I1003 12:39:10.695296  5017 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I1003 12:39:10.695302  5017 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I1003 12:39:10.695551  5017 net.cpp:172] Setting up conv3_1_bn0
I1003 12:39:10.695562  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.695566  5017 net.cpp:194] Memory required for data: 1103495296
I1003 12:39:10.695576  5017 layer_factory.hpp:77] Creating layer conv3_1_scale0
I1003 12:39:10.695585  5017 net.cpp:128] Creating Layer conv3_1_scale0
I1003 12:39:10.695588  5017 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I1003 12:39:10.695595  5017 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I1003 12:39:10.695641  5017 layer_factory.hpp:77] Creating layer conv3_1_scale0
I1003 12:39:10.695783  5017 net.cpp:172] Setting up conv3_1_scale0
I1003 12:39:10.695794  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.695798  5017 net.cpp:194] Memory required for data: 1113981056
I1003 12:39:10.695806  5017 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I1003 12:39:10.695813  5017 net.cpp:128] Creating Layer conv3_1_ReLU0
I1003 12:39:10.695817  5017 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I1003 12:39:10.695823  5017 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I1003 12:39:10.696239  5017 net.cpp:172] Setting up conv3_1_ReLU0
I1003 12:39:10.696264  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.696269  5017 net.cpp:194] Memory required for data: 1124466816
I1003 12:39:10.696274  5017 layer_factory.hpp:77] Creating layer conv3_Drop1
I1003 12:39:10.696283  5017 net.cpp:128] Creating Layer conv3_Drop1
I1003 12:39:10.696288  5017 net.cpp:558] conv3_Drop1 <- conv3_1_0
I1003 12:39:10.696295  5017 net.cpp:509] conv3_Drop1 -> conv3_1_0 (in-place)
I1003 12:39:10.696322  5017 net.cpp:172] Setting up conv3_Drop1
I1003 12:39:10.696329  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.696333  5017 net.cpp:194] Memory required for data: 1134952576
I1003 12:39:10.696338  5017 layer_factory.hpp:77] Creating layer conv3_1_1
I1003 12:39:10.696348  5017 net.cpp:128] Creating Layer conv3_1_1
I1003 12:39:10.696352  5017 net.cpp:558] conv3_1_1 <- conv3_1_0
I1003 12:39:10.696359  5017 net.cpp:522] conv3_1_1 -> conv3_1_1
I1003 12:39:10.714267  5017 net.cpp:172] Setting up conv3_1_1
I1003 12:39:10.714303  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.714308  5017 net.cpp:194] Memory required for data: 1145438336
I1003 12:39:10.714321  5017 layer_factory.hpp:77] Creating layer conv3_1bn1
I1003 12:39:10.714334  5017 net.cpp:128] Creating Layer conv3_1bn1
I1003 12:39:10.714339  5017 net.cpp:558] conv3_1bn1 <- conv3_1_1
I1003 12:39:10.714351  5017 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I1003 12:39:10.714603  5017 net.cpp:172] Setting up conv3_1bn1
I1003 12:39:10.714617  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.714620  5017 net.cpp:194] Memory required for data: 1155924096
I1003 12:39:10.714630  5017 layer_factory.hpp:77] Creating layer conv3_1_scale1
I1003 12:39:10.714640  5017 net.cpp:128] Creating Layer conv3_1_scale1
I1003 12:39:10.714644  5017 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I1003 12:39:10.714649  5017 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I1003 12:39:10.714699  5017 layer_factory.hpp:77] Creating layer conv3_1_scale1
I1003 12:39:10.714836  5017 net.cpp:172] Setting up conv3_1_scale1
I1003 12:39:10.714843  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.714848  5017 net.cpp:194] Memory required for data: 1166409856
I1003 12:39:10.714855  5017 layer_factory.hpp:77] Creating layer conv3_1_down
I1003 12:39:10.714893  5017 net.cpp:128] Creating Layer conv3_1_down
I1003 12:39:10.714898  5017 net.cpp:558] conv3_1_down <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I1003 12:39:10.714906  5017 net.cpp:522] conv3_1_down -> conv3_1_down
I1003 12:39:10.716917  5017 net.cpp:172] Setting up conv3_1_down
I1003 12:39:10.716944  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.716948  5017 net.cpp:194] Memory required for data: 1176895616
I1003 12:39:10.716958  5017 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I1003 12:39:10.716967  5017 net.cpp:128] Creating Layer conv3_1_bn_down
I1003 12:39:10.716972  5017 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I1003 12:39:10.716979  5017 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I1003 12:39:10.717227  5017 net.cpp:172] Setting up conv3_1_bn_down
I1003 12:39:10.717238  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.717242  5017 net.cpp:194] Memory required for data: 1187381376
I1003 12:39:10.717253  5017 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I1003 12:39:10.717260  5017 net.cpp:128] Creating Layer conv3_1_scale_down
I1003 12:39:10.717265  5017 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I1003 12:39:10.717270  5017 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I1003 12:39:10.717317  5017 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I1003 12:39:10.717453  5017 net.cpp:172] Setting up conv3_1_scale_down
I1003 12:39:10.717464  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.717469  5017 net.cpp:194] Memory required for data: 1197867136
I1003 12:39:10.717478  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I1003 12:39:10.717489  5017 net.cpp:128] Creating Layer conv3_Eltwise_1
I1003 12:39:10.717494  5017 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I1003 12:39:10.717499  5017 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I1003 12:39:10.717504  5017 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I1003 12:39:10.717527  5017 net.cpp:172] Setting up conv3_Eltwise_1
I1003 12:39:10.717533  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.717537  5017 net.cpp:194] Memory required for data: 1208352896
I1003 12:39:10.717542  5017 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I1003 12:39:10.717548  5017 net.cpp:128] Creating Layer conv3_1ReLU_1
I1003 12:39:10.717552  5017 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I1003 12:39:10.717558  5017 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I1003 12:39:10.717784  5017 net.cpp:172] Setting up conv3_1ReLU_1
I1003 12:39:10.717798  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.717803  5017 net.cpp:194] Memory required for data: 1218838656
I1003 12:39:10.717808  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1003 12:39:10.717815  5017 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1003 12:39:10.717819  5017 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I1003 12:39:10.717826  5017 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I1003 12:39:10.717834  5017 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I1003 12:39:10.717881  5017 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1003 12:39:10.717891  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.717897  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.717911  5017 net.cpp:194] Memory required for data: 1239810176
I1003 12:39:10.717916  5017 layer_factory.hpp:77] Creating layer conv3_2_0
I1003 12:39:10.717926  5017 net.cpp:128] Creating Layer conv3_2_0
I1003 12:39:10.717931  5017 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I1003 12:39:10.717938  5017 net.cpp:522] conv3_2_0 -> conv3_2_0
I1003 12:39:10.735940  5017 net.cpp:172] Setting up conv3_2_0
I1003 12:39:10.735980  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.735983  5017 net.cpp:194] Memory required for data: 1250295936
I1003 12:39:10.736022  5017 layer_factory.hpp:77] Creating layer conv3_2_bn0
I1003 12:39:10.736034  5017 net.cpp:128] Creating Layer conv3_2_bn0
I1003 12:39:10.736040  5017 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I1003 12:39:10.736049  5017 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I1003 12:39:10.736332  5017 net.cpp:172] Setting up conv3_2_bn0
I1003 12:39:10.736344  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.736348  5017 net.cpp:194] Memory required for data: 1260781696
I1003 12:39:10.736358  5017 layer_factory.hpp:77] Creating layer conv3_2_scale0
I1003 12:39:10.736366  5017 net.cpp:128] Creating Layer conv3_2_scale0
I1003 12:39:10.736371  5017 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I1003 12:39:10.736378  5017 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I1003 12:39:10.736428  5017 layer_factory.hpp:77] Creating layer conv3_2_scale0
I1003 12:39:10.736579  5017 net.cpp:172] Setting up conv3_2_scale0
I1003 12:39:10.736587  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.736590  5017 net.cpp:194] Memory required for data: 1271267456
I1003 12:39:10.736598  5017 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I1003 12:39:10.736605  5017 net.cpp:128] Creating Layer conv3_2_ReLU0
I1003 12:39:10.736609  5017 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I1003 12:39:10.736614  5017 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I1003 12:39:10.736853  5017 net.cpp:172] Setting up conv3_2_ReLU0
I1003 12:39:10.736867  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.736871  5017 net.cpp:194] Memory required for data: 1281753216
I1003 12:39:10.736876  5017 layer_factory.hpp:77] Creating layer conv3_Drop2
I1003 12:39:10.736883  5017 net.cpp:128] Creating Layer conv3_Drop2
I1003 12:39:10.736888  5017 net.cpp:558] conv3_Drop2 <- conv3_2_0
I1003 12:39:10.736896  5017 net.cpp:509] conv3_Drop2 -> conv3_2_0 (in-place)
I1003 12:39:10.736922  5017 net.cpp:172] Setting up conv3_Drop2
I1003 12:39:10.736928  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.736932  5017 net.cpp:194] Memory required for data: 1292238976
I1003 12:39:10.736937  5017 layer_factory.hpp:77] Creating layer conv3_2_1
I1003 12:39:10.736950  5017 net.cpp:128] Creating Layer conv3_2_1
I1003 12:39:10.736954  5017 net.cpp:558] conv3_2_1 <- conv3_2_0
I1003 12:39:10.736966  5017 net.cpp:522] conv3_2_1 -> conv3_2_1
I1003 12:39:10.755000  5017 net.cpp:172] Setting up conv3_2_1
I1003 12:39:10.755038  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.755043  5017 net.cpp:194] Memory required for data: 1302724736
I1003 12:39:10.755056  5017 layer_factory.hpp:77] Creating layer conv3_2bn1
I1003 12:39:10.755070  5017 net.cpp:128] Creating Layer conv3_2bn1
I1003 12:39:10.755076  5017 net.cpp:558] conv3_2bn1 <- conv3_2_1
I1003 12:39:10.755089  5017 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I1003 12:39:10.755362  5017 net.cpp:172] Setting up conv3_2bn1
I1003 12:39:10.755373  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.755378  5017 net.cpp:194] Memory required for data: 1313210496
I1003 12:39:10.755388  5017 layer_factory.hpp:77] Creating layer conv3_2_scale1
I1003 12:39:10.755395  5017 net.cpp:128] Creating Layer conv3_2_scale1
I1003 12:39:10.755399  5017 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I1003 12:39:10.755405  5017 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I1003 12:39:10.755461  5017 layer_factory.hpp:77] Creating layer conv3_2_scale1
I1003 12:39:10.755611  5017 net.cpp:172] Setting up conv3_2_scale1
I1003 12:39:10.755625  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.755628  5017 net.cpp:194] Memory required for data: 1323696256
I1003 12:39:10.755636  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I1003 12:39:10.755646  5017 net.cpp:128] Creating Layer conv3_Eltwise_2
I1003 12:39:10.755652  5017 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I1003 12:39:10.755657  5017 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I1003 12:39:10.755663  5017 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I1003 12:39:10.755710  5017 net.cpp:172] Setting up conv3_Eltwise_2
I1003 12:39:10.755718  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.755722  5017 net.cpp:194] Memory required for data: 1334182016
I1003 12:39:10.755726  5017 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I1003 12:39:10.755733  5017 net.cpp:128] Creating Layer conv3_2ReLU_1
I1003 12:39:10.755738  5017 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I1003 12:39:10.755744  5017 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I1003 12:39:10.756184  5017 net.cpp:172] Setting up conv3_2ReLU_1
I1003 12:39:10.756207  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.756211  5017 net.cpp:194] Memory required for data: 1344667776
I1003 12:39:10.756217  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1003 12:39:10.756225  5017 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1003 12:39:10.756230  5017 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I1003 12:39:10.756239  5017 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I1003 12:39:10.756248  5017 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I1003 12:39:10.756301  5017 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1003 12:39:10.756309  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.756314  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.756317  5017 net.cpp:194] Memory required for data: 1365639296
I1003 12:39:10.756321  5017 layer_factory.hpp:77] Creating layer conv3_3_0
I1003 12:39:10.756335  5017 net.cpp:128] Creating Layer conv3_3_0
I1003 12:39:10.756340  5017 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I1003 12:39:10.756350  5017 net.cpp:522] conv3_3_0 -> conv3_3_0
I1003 12:39:10.774534  5017 net.cpp:172] Setting up conv3_3_0
I1003 12:39:10.774572  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.774577  5017 net.cpp:194] Memory required for data: 1376125056
I1003 12:39:10.774590  5017 layer_factory.hpp:77] Creating layer conv3_3_bn0
I1003 12:39:10.774605  5017 net.cpp:128] Creating Layer conv3_3_bn0
I1003 12:39:10.774610  5017 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I1003 12:39:10.774623  5017 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I1003 12:39:10.774904  5017 net.cpp:172] Setting up conv3_3_bn0
I1003 12:39:10.774915  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.774920  5017 net.cpp:194] Memory required for data: 1386610816
I1003 12:39:10.774930  5017 layer_factory.hpp:77] Creating layer conv3_3_scale0
I1003 12:39:10.774940  5017 net.cpp:128] Creating Layer conv3_3_scale0
I1003 12:39:10.774945  5017 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I1003 12:39:10.774950  5017 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I1003 12:39:10.775007  5017 layer_factory.hpp:77] Creating layer conv3_3_scale0
I1003 12:39:10.775161  5017 net.cpp:172] Setting up conv3_3_scale0
I1003 12:39:10.775167  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.775171  5017 net.cpp:194] Memory required for data: 1397096576
I1003 12:39:10.775178  5017 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I1003 12:39:10.775185  5017 net.cpp:128] Creating Layer conv3_3_ReLU0
I1003 12:39:10.775189  5017 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I1003 12:39:10.775197  5017 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I1003 12:39:10.775432  5017 net.cpp:172] Setting up conv3_3_ReLU0
I1003 12:39:10.775449  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.775455  5017 net.cpp:194] Memory required for data: 1407582336
I1003 12:39:10.775460  5017 layer_factory.hpp:77] Creating layer conv3_Drop3
I1003 12:39:10.775470  5017 net.cpp:128] Creating Layer conv3_Drop3
I1003 12:39:10.775473  5017 net.cpp:558] conv3_Drop3 <- conv3_3_0
I1003 12:39:10.775481  5017 net.cpp:509] conv3_Drop3 -> conv3_3_0 (in-place)
I1003 12:39:10.775508  5017 net.cpp:172] Setting up conv3_Drop3
I1003 12:39:10.775539  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.775543  5017 net.cpp:194] Memory required for data: 1418068096
I1003 12:39:10.775548  5017 layer_factory.hpp:77] Creating layer conv3_3_1
I1003 12:39:10.775563  5017 net.cpp:128] Creating Layer conv3_3_1
I1003 12:39:10.775566  5017 net.cpp:558] conv3_3_1 <- conv3_3_0
I1003 12:39:10.775573  5017 net.cpp:522] conv3_3_1 -> conv3_3_1
I1003 12:39:10.793627  5017 net.cpp:172] Setting up conv3_3_1
I1003 12:39:10.793663  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.793666  5017 net.cpp:194] Memory required for data: 1428553856
I1003 12:39:10.793679  5017 layer_factory.hpp:77] Creating layer conv3_3bn1
I1003 12:39:10.793694  5017 net.cpp:128] Creating Layer conv3_3bn1
I1003 12:39:10.793699  5017 net.cpp:558] conv3_3bn1 <- conv3_3_1
I1003 12:39:10.793709  5017 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I1003 12:39:10.793998  5017 net.cpp:172] Setting up conv3_3bn1
I1003 12:39:10.794010  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.794015  5017 net.cpp:194] Memory required for data: 1439039616
I1003 12:39:10.794025  5017 layer_factory.hpp:77] Creating layer conv3_3_scale1
I1003 12:39:10.794032  5017 net.cpp:128] Creating Layer conv3_3_scale1
I1003 12:39:10.794037  5017 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I1003 12:39:10.794047  5017 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I1003 12:39:10.794100  5017 layer_factory.hpp:77] Creating layer conv3_3_scale1
I1003 12:39:10.794258  5017 net.cpp:172] Setting up conv3_3_scale1
I1003 12:39:10.794265  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.794270  5017 net.cpp:194] Memory required for data: 1449525376
I1003 12:39:10.794277  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I1003 12:39:10.794286  5017 net.cpp:128] Creating Layer conv3_Eltwise_3
I1003 12:39:10.794291  5017 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I1003 12:39:10.794296  5017 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I1003 12:39:10.794304  5017 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I1003 12:39:10.794328  5017 net.cpp:172] Setting up conv3_Eltwise_3
I1003 12:39:10.794334  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.794338  5017 net.cpp:194] Memory required for data: 1460011136
I1003 12:39:10.794342  5017 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I1003 12:39:10.794351  5017 net.cpp:128] Creating Layer conv3_3ReLU_1
I1003 12:39:10.794356  5017 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I1003 12:39:10.794361  5017 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I1003 12:39:10.794595  5017 net.cpp:172] Setting up conv3_3ReLU_1
I1003 12:39:10.794608  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.794613  5017 net.cpp:194] Memory required for data: 1470496896
I1003 12:39:10.794617  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1003 12:39:10.794626  5017 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1003 12:39:10.794631  5017 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I1003 12:39:10.794638  5017 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I1003 12:39:10.794646  5017 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I1003 12:39:10.794700  5017 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1003 12:39:10.794708  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.794713  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.794718  5017 net.cpp:194] Memory required for data: 1491468416
I1003 12:39:10.794721  5017 layer_factory.hpp:77] Creating layer conv3_4_0
I1003 12:39:10.794734  5017 net.cpp:128] Creating Layer conv3_4_0
I1003 12:39:10.794740  5017 net.cpp:558] conv3_4_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I1003 12:39:10.794747  5017 net.cpp:522] conv3_4_0 -> conv3_4_0
I1003 12:39:10.812765  5017 net.cpp:172] Setting up conv3_4_0
I1003 12:39:10.812804  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.812809  5017 net.cpp:194] Memory required for data: 1501954176
I1003 12:39:10.812824  5017 layer_factory.hpp:77] Creating layer conv3_4_bn0
I1003 12:39:10.812835  5017 net.cpp:128] Creating Layer conv3_4_bn0
I1003 12:39:10.812845  5017 net.cpp:558] conv3_4_bn0 <- conv3_4_0
I1003 12:39:10.812855  5017 net.cpp:509] conv3_4_bn0 -> conv3_4_0 (in-place)
I1003 12:39:10.813134  5017 net.cpp:172] Setting up conv3_4_bn0
I1003 12:39:10.813145  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.813150  5017 net.cpp:194] Memory required for data: 1512439936
I1003 12:39:10.813160  5017 layer_factory.hpp:77] Creating layer conv3_4_scale0
I1003 12:39:10.813174  5017 net.cpp:128] Creating Layer conv3_4_scale0
I1003 12:39:10.813179  5017 net.cpp:558] conv3_4_scale0 <- conv3_4_0
I1003 12:39:10.813184  5017 net.cpp:509] conv3_4_scale0 -> conv3_4_0 (in-place)
I1003 12:39:10.813238  5017 layer_factory.hpp:77] Creating layer conv3_4_scale0
I1003 12:39:10.813400  5017 net.cpp:172] Setting up conv3_4_scale0
I1003 12:39:10.813410  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.813414  5017 net.cpp:194] Memory required for data: 1522925696
I1003 12:39:10.813422  5017 layer_factory.hpp:77] Creating layer conv3_4_ReLU0
I1003 12:39:10.813431  5017 net.cpp:128] Creating Layer conv3_4_ReLU0
I1003 12:39:10.813436  5017 net.cpp:558] conv3_4_ReLU0 <- conv3_4_0
I1003 12:39:10.813441  5017 net.cpp:509] conv3_4_ReLU0 -> conv3_4_0 (in-place)
I1003 12:39:10.813887  5017 net.cpp:172] Setting up conv3_4_ReLU0
I1003 12:39:10.813925  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.813930  5017 net.cpp:194] Memory required for data: 1533411456
I1003 12:39:10.813935  5017 layer_factory.hpp:77] Creating layer conv3_Drop4
I1003 12:39:10.813946  5017 net.cpp:128] Creating Layer conv3_Drop4
I1003 12:39:10.813951  5017 net.cpp:558] conv3_Drop4 <- conv3_4_0
I1003 12:39:10.813957  5017 net.cpp:509] conv3_Drop4 -> conv3_4_0 (in-place)
I1003 12:39:10.813992  5017 net.cpp:172] Setting up conv3_Drop4
I1003 12:39:10.813998  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.814002  5017 net.cpp:194] Memory required for data: 1543897216
I1003 12:39:10.814007  5017 layer_factory.hpp:77] Creating layer conv3_4_1
I1003 12:39:10.814019  5017 net.cpp:128] Creating Layer conv3_4_1
I1003 12:39:10.814024  5017 net.cpp:558] conv3_4_1 <- conv3_4_0
I1003 12:39:10.814033  5017 net.cpp:522] conv3_4_1 -> conv3_4_1
I1003 12:39:10.832037  5017 net.cpp:172] Setting up conv3_4_1
I1003 12:39:10.832075  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.832080  5017 net.cpp:194] Memory required for data: 1554382976
I1003 12:39:10.832093  5017 layer_factory.hpp:77] Creating layer conv3_4bn1
I1003 12:39:10.832105  5017 net.cpp:128] Creating Layer conv3_4bn1
I1003 12:39:10.832116  5017 net.cpp:558] conv3_4bn1 <- conv3_4_1
I1003 12:39:10.832125  5017 net.cpp:509] conv3_4bn1 -> conv3_4_1 (in-place)
I1003 12:39:10.832412  5017 net.cpp:172] Setting up conv3_4bn1
I1003 12:39:10.832422  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.832427  5017 net.cpp:194] Memory required for data: 1564868736
I1003 12:39:10.832453  5017 layer_factory.hpp:77] Creating layer conv3_4_scale1
I1003 12:39:10.832465  5017 net.cpp:128] Creating Layer conv3_4_scale1
I1003 12:39:10.832470  5017 net.cpp:558] conv3_4_scale1 <- conv3_4_1
I1003 12:39:10.832478  5017 net.cpp:509] conv3_4_scale1 -> conv3_4_1 (in-place)
I1003 12:39:10.832535  5017 layer_factory.hpp:77] Creating layer conv3_4_scale1
I1003 12:39:10.832690  5017 net.cpp:172] Setting up conv3_4_scale1
I1003 12:39:10.832702  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.832706  5017 net.cpp:194] Memory required for data: 1575354496
I1003 12:39:10.832715  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_4
I1003 12:39:10.832722  5017 net.cpp:128] Creating Layer conv3_Eltwise_4
I1003 12:39:10.832727  5017 net.cpp:558] conv3_Eltwise_4 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I1003 12:39:10.832762  5017 net.cpp:558] conv3_Eltwise_4 <- conv3_4_1
I1003 12:39:10.832768  5017 net.cpp:522] conv3_Eltwise_4 -> conv3_Eltwise_4
I1003 12:39:10.832794  5017 net.cpp:172] Setting up conv3_Eltwise_4
I1003 12:39:10.832808  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.832813  5017 net.cpp:194] Memory required for data: 1585840256
I1003 12:39:10.832818  5017 layer_factory.hpp:77] Creating layer conv3_4ReLU_1
I1003 12:39:10.832823  5017 net.cpp:128] Creating Layer conv3_4ReLU_1
I1003 12:39:10.832828  5017 net.cpp:558] conv3_4ReLU_1 <- conv3_Eltwise_4
I1003 12:39:10.832834  5017 net.cpp:509] conv3_4ReLU_1 -> conv3_Eltwise_4 (in-place)
I1003 12:39:10.833070  5017 net.cpp:172] Setting up conv3_4ReLU_1
I1003 12:39:10.833087  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.833092  5017 net.cpp:194] Memory required for data: 1596326016
I1003 12:39:10.833096  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I1003 12:39:10.833104  5017 net.cpp:128] Creating Layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I1003 12:39:10.833109  5017 net.cpp:558] conv3_Eltwise_4_conv3_4ReLU_1_0_split <- conv3_Eltwise_4
I1003 12:39:10.833118  5017 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I1003 12:39:10.833127  5017 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I1003 12:39:10.833179  5017 net.cpp:172] Setting up conv3_Eltwise_4_conv3_4ReLU_1_0_split
I1003 12:39:10.833199  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.833204  5017 net.cpp:186] Top shape: 32 320 16 16 (2621440)
I1003 12:39:10.833209  5017 net.cpp:194] Memory required for data: 1617297536
I1003 12:39:10.833212  5017 layer_factory.hpp:77] Creating layer conv4_1_0
I1003 12:39:10.833227  5017 net.cpp:128] Creating Layer conv4_1_0
I1003 12:39:10.833231  5017 net.cpp:558] conv4_1_0 <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I1003 12:39:10.833238  5017 net.cpp:522] conv4_1_0 -> conv4_1_0
I1003 12:39:10.868814  5017 net.cpp:172] Setting up conv4_1_0
I1003 12:39:10.868872  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.868877  5017 net.cpp:194] Memory required for data: 1622540416
I1003 12:39:10.868894  5017 layer_factory.hpp:77] Creating layer conv4_1_bn0
I1003 12:39:10.868911  5017 net.cpp:128] Creating Layer conv4_1_bn0
I1003 12:39:10.868923  5017 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I1003 12:39:10.868932  5017 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I1003 12:39:10.869223  5017 net.cpp:172] Setting up conv4_1_bn0
I1003 12:39:10.869235  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.869240  5017 net.cpp:194] Memory required for data: 1627783296
I1003 12:39:10.869249  5017 layer_factory.hpp:77] Creating layer conv4_1_scale0
I1003 12:39:10.869257  5017 net.cpp:128] Creating Layer conv4_1_scale0
I1003 12:39:10.869262  5017 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I1003 12:39:10.869274  5017 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I1003 12:39:10.869328  5017 layer_factory.hpp:77] Creating layer conv4_1_scale0
I1003 12:39:10.869489  5017 net.cpp:172] Setting up conv4_1_scale0
I1003 12:39:10.869498  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.869503  5017 net.cpp:194] Memory required for data: 1633026176
I1003 12:39:10.869510  5017 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I1003 12:39:10.869518  5017 net.cpp:128] Creating Layer conv4_1_ReLU0
I1003 12:39:10.869523  5017 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I1003 12:39:10.869527  5017 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I1003 12:39:10.869773  5017 net.cpp:172] Setting up conv4_1_ReLU0
I1003 12:39:10.869796  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.869801  5017 net.cpp:194] Memory required for data: 1638269056
I1003 12:39:10.869804  5017 layer_factory.hpp:77] Creating layer conv4_Drop1
I1003 12:39:10.869814  5017 net.cpp:128] Creating Layer conv4_Drop1
I1003 12:39:10.869856  5017 net.cpp:558] conv4_Drop1 <- conv4_1_0
I1003 12:39:10.869863  5017 net.cpp:509] conv4_Drop1 -> conv4_1_0 (in-place)
I1003 12:39:10.869917  5017 net.cpp:172] Setting up conv4_Drop1
I1003 12:39:10.869926  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.869930  5017 net.cpp:194] Memory required for data: 1643511936
I1003 12:39:10.869935  5017 layer_factory.hpp:77] Creating layer conv4_1_1
I1003 12:39:10.869948  5017 net.cpp:128] Creating Layer conv4_1_1
I1003 12:39:10.869953  5017 net.cpp:558] conv4_1_1 <- conv4_1_0
I1003 12:39:10.869962  5017 net.cpp:522] conv4_1_1 -> conv4_1_1
I1003 12:39:10.939828  5017 net.cpp:172] Setting up conv4_1_1
I1003 12:39:10.939887  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.939891  5017 net.cpp:194] Memory required for data: 1648754816
I1003 12:39:10.939911  5017 layer_factory.hpp:77] Creating layer conv4_1bn1
I1003 12:39:10.939929  5017 net.cpp:128] Creating Layer conv4_1bn1
I1003 12:39:10.939935  5017 net.cpp:558] conv4_1bn1 <- conv4_1_1
I1003 12:39:10.939951  5017 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I1003 12:39:10.940239  5017 net.cpp:172] Setting up conv4_1bn1
I1003 12:39:10.940250  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.940254  5017 net.cpp:194] Memory required for data: 1653997696
I1003 12:39:10.940265  5017 layer_factory.hpp:77] Creating layer conv4_1_scale1
I1003 12:39:10.940275  5017 net.cpp:128] Creating Layer conv4_1_scale1
I1003 12:39:10.940280  5017 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I1003 12:39:10.940285  5017 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I1003 12:39:10.940340  5017 layer_factory.hpp:77] Creating layer conv4_1_scale1
I1003 12:39:10.940508  5017 net.cpp:172] Setting up conv4_1_scale1
I1003 12:39:10.940518  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.940523  5017 net.cpp:194] Memory required for data: 1659240576
I1003 12:39:10.940531  5017 layer_factory.hpp:77] Creating layer conv4_1_down
I1003 12:39:10.940546  5017 net.cpp:128] Creating Layer conv4_1_down
I1003 12:39:10.940551  5017 net.cpp:558] conv4_1_down <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I1003 12:39:10.940560  5017 net.cpp:522] conv4_1_down -> conv4_1_down
I1003 12:39:10.945240  5017 net.cpp:172] Setting up conv4_1_down
I1003 12:39:10.945266  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.945271  5017 net.cpp:194] Memory required for data: 1664483456
I1003 12:39:10.945281  5017 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I1003 12:39:10.945292  5017 net.cpp:128] Creating Layer conv4_1_bn_down
I1003 12:39:10.945297  5017 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I1003 12:39:10.945303  5017 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I1003 12:39:10.945587  5017 net.cpp:172] Setting up conv4_1_bn_down
I1003 12:39:10.945598  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.945602  5017 net.cpp:194] Memory required for data: 1669726336
I1003 12:39:10.945612  5017 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I1003 12:39:10.945619  5017 net.cpp:128] Creating Layer conv4_1_scale_down
I1003 12:39:10.945624  5017 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I1003 12:39:10.945632  5017 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I1003 12:39:10.945677  5017 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I1003 12:39:10.945840  5017 net.cpp:172] Setting up conv4_1_scale_down
I1003 12:39:10.945852  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.945858  5017 net.cpp:194] Memory required for data: 1674969216
I1003 12:39:10.945865  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I1003 12:39:10.945873  5017 net.cpp:128] Creating Layer conv4_Eltwise_1
I1003 12:39:10.945878  5017 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I1003 12:39:10.945883  5017 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I1003 12:39:10.945888  5017 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I1003 12:39:10.945930  5017 net.cpp:172] Setting up conv4_Eltwise_1
I1003 12:39:10.945936  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.945981  5017 net.cpp:194] Memory required for data: 1680212096
I1003 12:39:10.945986  5017 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I1003 12:39:10.945996  5017 net.cpp:128] Creating Layer conv4_1ReLU_1
I1003 12:39:10.946000  5017 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I1003 12:39:10.946007  5017 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I1003 12:39:10.946247  5017 net.cpp:172] Setting up conv4_1ReLU_1
I1003 12:39:10.946260  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.946265  5017 net.cpp:194] Memory required for data: 1685454976
I1003 12:39:10.946269  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1003 12:39:10.946279  5017 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1003 12:39:10.946283  5017 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I1003 12:39:10.946290  5017 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I1003 12:39:10.946298  5017 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I1003 12:39:10.946354  5017 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1003 12:39:10.946367  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.946373  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:10.946377  5017 net.cpp:194] Memory required for data: 1695940736
I1003 12:39:10.946382  5017 layer_factory.hpp:77] Creating layer conv4_2_0
I1003 12:39:10.946398  5017 net.cpp:128] Creating Layer conv4_2_0
I1003 12:39:10.946403  5017 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I1003 12:39:10.946410  5017 net.cpp:522] conv4_2_0 -> conv4_2_0
I1003 12:39:11.016469  5017 net.cpp:172] Setting up conv4_2_0
I1003 12:39:11.016530  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.016535  5017 net.cpp:194] Memory required for data: 1701183616
I1003 12:39:11.016551  5017 layer_factory.hpp:77] Creating layer conv4_2_bn0
I1003 12:39:11.016567  5017 net.cpp:128] Creating Layer conv4_2_bn0
I1003 12:39:11.016575  5017 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I1003 12:39:11.016587  5017 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I1003 12:39:11.016880  5017 net.cpp:172] Setting up conv4_2_bn0
I1003 12:39:11.016891  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.016894  5017 net.cpp:194] Memory required for data: 1706426496
I1003 12:39:11.016904  5017 layer_factory.hpp:77] Creating layer conv4_2_scale0
I1003 12:39:11.016913  5017 net.cpp:128] Creating Layer conv4_2_scale0
I1003 12:39:11.016917  5017 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I1003 12:39:11.016923  5017 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I1003 12:39:11.016978  5017 layer_factory.hpp:77] Creating layer conv4_2_scale0
I1003 12:39:11.017143  5017 net.cpp:172] Setting up conv4_2_scale0
I1003 12:39:11.017150  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.017154  5017 net.cpp:194] Memory required for data: 1711669376
I1003 12:39:11.017161  5017 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I1003 12:39:11.017169  5017 net.cpp:128] Creating Layer conv4_2_ReLU0
I1003 12:39:11.017174  5017 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I1003 12:39:11.017180  5017 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I1003 12:39:11.017633  5017 net.cpp:172] Setting up conv4_2_ReLU0
I1003 12:39:11.017658  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.017663  5017 net.cpp:194] Memory required for data: 1716912256
I1003 12:39:11.017668  5017 layer_factory.hpp:77] Creating layer conv4_Drop2
I1003 12:39:11.017678  5017 net.cpp:128] Creating Layer conv4_Drop2
I1003 12:39:11.017683  5017 net.cpp:558] conv4_Drop2 <- conv4_2_0
I1003 12:39:11.017690  5017 net.cpp:509] conv4_Drop2 -> conv4_2_0 (in-place)
I1003 12:39:11.017729  5017 net.cpp:172] Setting up conv4_Drop2
I1003 12:39:11.017738  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.017742  5017 net.cpp:194] Memory required for data: 1722155136
I1003 12:39:11.017784  5017 layer_factory.hpp:77] Creating layer conv4_2_1
I1003 12:39:11.017799  5017 net.cpp:128] Creating Layer conv4_2_1
I1003 12:39:11.017804  5017 net.cpp:558] conv4_2_1 <- conv4_2_0
I1003 12:39:11.017812  5017 net.cpp:522] conv4_2_1 -> conv4_2_1
I1003 12:39:11.087848  5017 net.cpp:172] Setting up conv4_2_1
I1003 12:39:11.087906  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.087910  5017 net.cpp:194] Memory required for data: 1727398016
I1003 12:39:11.087929  5017 layer_factory.hpp:77] Creating layer conv4_2bn1
I1003 12:39:11.087946  5017 net.cpp:128] Creating Layer conv4_2bn1
I1003 12:39:11.087956  5017 net.cpp:558] conv4_2bn1 <- conv4_2_1
I1003 12:39:11.087970  5017 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I1003 12:39:11.088263  5017 net.cpp:172] Setting up conv4_2bn1
I1003 12:39:11.088274  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.088277  5017 net.cpp:194] Memory required for data: 1732640896
I1003 12:39:11.088287  5017 layer_factory.hpp:77] Creating layer conv4_2_scale1
I1003 12:39:11.088299  5017 net.cpp:128] Creating Layer conv4_2_scale1
I1003 12:39:11.088304  5017 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I1003 12:39:11.088310  5017 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I1003 12:39:11.088364  5017 layer_factory.hpp:77] Creating layer conv4_2_scale1
I1003 12:39:11.088537  5017 net.cpp:172] Setting up conv4_2_scale1
I1003 12:39:11.088548  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.088552  5017 net.cpp:194] Memory required for data: 1737883776
I1003 12:39:11.088560  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I1003 12:39:11.088572  5017 net.cpp:128] Creating Layer conv4_Eltwise_2
I1003 12:39:11.088577  5017 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I1003 12:39:11.088582  5017 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I1003 12:39:11.088588  5017 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I1003 12:39:11.088619  5017 net.cpp:172] Setting up conv4_Eltwise_2
I1003 12:39:11.088632  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.088636  5017 net.cpp:194] Memory required for data: 1743126656
I1003 12:39:11.088640  5017 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I1003 12:39:11.088649  5017 net.cpp:128] Creating Layer conv4_2ReLU_1
I1003 12:39:11.088652  5017 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I1003 12:39:11.088660  5017 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I1003 12:39:11.088907  5017 net.cpp:172] Setting up conv4_2ReLU_1
I1003 12:39:11.088922  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.088927  5017 net.cpp:194] Memory required for data: 1748369536
I1003 12:39:11.088932  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1003 12:39:11.088938  5017 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1003 12:39:11.088943  5017 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I1003 12:39:11.088953  5017 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I1003 12:39:11.088960  5017 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I1003 12:39:11.089016  5017 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1003 12:39:11.089030  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.089035  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.089040  5017 net.cpp:194] Memory required for data: 1758855296
I1003 12:39:11.089043  5017 layer_factory.hpp:77] Creating layer conv4_3_0
I1003 12:39:11.089058  5017 net.cpp:128] Creating Layer conv4_3_0
I1003 12:39:11.089063  5017 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I1003 12:39:11.089072  5017 net.cpp:522] conv4_3_0 -> conv4_3_0
I1003 12:39:11.158800  5017 net.cpp:172] Setting up conv4_3_0
I1003 12:39:11.158859  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.158864  5017 net.cpp:194] Memory required for data: 1764098176
I1003 12:39:11.158924  5017 layer_factory.hpp:77] Creating layer conv4_3_bn0
I1003 12:39:11.158942  5017 net.cpp:128] Creating Layer conv4_3_bn0
I1003 12:39:11.158951  5017 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I1003 12:39:11.158967  5017 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I1003 12:39:11.159265  5017 net.cpp:172] Setting up conv4_3_bn0
I1003 12:39:11.159278  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.159283  5017 net.cpp:194] Memory required for data: 1769341056
I1003 12:39:11.159293  5017 layer_factory.hpp:77] Creating layer conv4_3_scale0
I1003 12:39:11.159302  5017 net.cpp:128] Creating Layer conv4_3_scale0
I1003 12:39:11.159307  5017 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I1003 12:39:11.159313  5017 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I1003 12:39:11.159369  5017 layer_factory.hpp:77] Creating layer conv4_3_scale0
I1003 12:39:11.159535  5017 net.cpp:172] Setting up conv4_3_scale0
I1003 12:39:11.159543  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.159546  5017 net.cpp:194] Memory required for data: 1774583936
I1003 12:39:11.159554  5017 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I1003 12:39:11.159570  5017 net.cpp:128] Creating Layer conv4_3_ReLU0
I1003 12:39:11.159575  5017 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I1003 12:39:11.159581  5017 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I1003 12:39:11.159829  5017 net.cpp:172] Setting up conv4_3_ReLU0
I1003 12:39:11.159847  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.159852  5017 net.cpp:194] Memory required for data: 1779826816
I1003 12:39:11.159857  5017 layer_factory.hpp:77] Creating layer conv4_Drop3
I1003 12:39:11.159867  5017 net.cpp:128] Creating Layer conv4_Drop3
I1003 12:39:11.159870  5017 net.cpp:558] conv4_Drop3 <- conv4_3_0
I1003 12:39:11.159878  5017 net.cpp:509] conv4_Drop3 -> conv4_3_0 (in-place)
I1003 12:39:11.159914  5017 net.cpp:172] Setting up conv4_Drop3
I1003 12:39:11.159920  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.159924  5017 net.cpp:194] Memory required for data: 1785069696
I1003 12:39:11.159929  5017 layer_factory.hpp:77] Creating layer conv4_3_1
I1003 12:39:11.159945  5017 net.cpp:128] Creating Layer conv4_3_1
I1003 12:39:11.159948  5017 net.cpp:558] conv4_3_1 <- conv4_3_0
I1003 12:39:11.159955  5017 net.cpp:522] conv4_3_1 -> conv4_3_1
I1003 12:39:11.229876  5017 net.cpp:172] Setting up conv4_3_1
I1003 12:39:11.229955  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.229960  5017 net.cpp:194] Memory required for data: 1790312576
I1003 12:39:11.229979  5017 layer_factory.hpp:77] Creating layer conv4_3bn1
I1003 12:39:11.229992  5017 net.cpp:128] Creating Layer conv4_3bn1
I1003 12:39:11.230000  5017 net.cpp:558] conv4_3bn1 <- conv4_3_1
I1003 12:39:11.230016  5017 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I1003 12:39:11.230324  5017 net.cpp:172] Setting up conv4_3bn1
I1003 12:39:11.230334  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.230338  5017 net.cpp:194] Memory required for data: 1795555456
I1003 12:39:11.230350  5017 layer_factory.hpp:77] Creating layer conv4_3_scale1
I1003 12:39:11.230357  5017 net.cpp:128] Creating Layer conv4_3_scale1
I1003 12:39:11.230362  5017 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I1003 12:39:11.230367  5017 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I1003 12:39:11.230425  5017 layer_factory.hpp:77] Creating layer conv4_3_scale1
I1003 12:39:11.230590  5017 net.cpp:172] Setting up conv4_3_scale1
I1003 12:39:11.230602  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.230607  5017 net.cpp:194] Memory required for data: 1800798336
I1003 12:39:11.230614  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I1003 12:39:11.230625  5017 net.cpp:128] Creating Layer conv4_Eltwise_3
I1003 12:39:11.230631  5017 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I1003 12:39:11.230638  5017 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I1003 12:39:11.230643  5017 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I1003 12:39:11.230718  5017 net.cpp:172] Setting up conv4_Eltwise_3
I1003 12:39:11.230736  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.230741  5017 net.cpp:194] Memory required for data: 1806041216
I1003 12:39:11.230744  5017 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I1003 12:39:11.230751  5017 net.cpp:128] Creating Layer conv4_3ReLU_1
I1003 12:39:11.230756  5017 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I1003 12:39:11.230763  5017 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I1003 12:39:11.231225  5017 net.cpp:172] Setting up conv4_3ReLU_1
I1003 12:39:11.231247  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.231251  5017 net.cpp:194] Memory required for data: 1811284096
I1003 12:39:11.231256  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I1003 12:39:11.231266  5017 net.cpp:128] Creating Layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I1003 12:39:11.231271  5017 net.cpp:558] conv4_Eltwise_3_conv4_3ReLU_1_0_split <- conv4_Eltwise_3
I1003 12:39:11.231279  5017 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I1003 12:39:11.231288  5017 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I1003 12:39:11.231349  5017 net.cpp:172] Setting up conv4_Eltwise_3_conv4_3ReLU_1_0_split
I1003 12:39:11.231359  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.231365  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.231369  5017 net.cpp:194] Memory required for data: 1821769856
I1003 12:39:11.231374  5017 layer_factory.hpp:77] Creating layer conv4_4_0
I1003 12:39:11.231386  5017 net.cpp:128] Creating Layer conv4_4_0
I1003 12:39:11.231391  5017 net.cpp:558] conv4_4_0 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I1003 12:39:11.231401  5017 net.cpp:522] conv4_4_0 -> conv4_4_0
I1003 12:39:11.301421  5017 net.cpp:172] Setting up conv4_4_0
I1003 12:39:11.301479  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.301483  5017 net.cpp:194] Memory required for data: 1827012736
I1003 12:39:11.301502  5017 layer_factory.hpp:77] Creating layer conv4_4_bn0
I1003 12:39:11.301517  5017 net.cpp:128] Creating Layer conv4_4_bn0
I1003 12:39:11.301524  5017 net.cpp:558] conv4_4_bn0 <- conv4_4_0
I1003 12:39:11.301533  5017 net.cpp:509] conv4_4_bn0 -> conv4_4_0 (in-place)
I1003 12:39:11.301839  5017 net.cpp:172] Setting up conv4_4_bn0
I1003 12:39:11.301851  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.301856  5017 net.cpp:194] Memory required for data: 1832255616
I1003 12:39:11.301867  5017 layer_factory.hpp:77] Creating layer conv4_4_scale0
I1003 12:39:11.301875  5017 net.cpp:128] Creating Layer conv4_4_scale0
I1003 12:39:11.301880  5017 net.cpp:558] conv4_4_scale0 <- conv4_4_0
I1003 12:39:11.301888  5017 net.cpp:509] conv4_4_scale0 -> conv4_4_0 (in-place)
I1003 12:39:11.301967  5017 layer_factory.hpp:77] Creating layer conv4_4_scale0
I1003 12:39:11.302141  5017 net.cpp:172] Setting up conv4_4_scale0
I1003 12:39:11.302155  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.302160  5017 net.cpp:194] Memory required for data: 1837498496
I1003 12:39:11.302167  5017 layer_factory.hpp:77] Creating layer conv4_4_ReLU0
I1003 12:39:11.302175  5017 net.cpp:128] Creating Layer conv4_4_ReLU0
I1003 12:39:11.302179  5017 net.cpp:558] conv4_4_ReLU0 <- conv4_4_0
I1003 12:39:11.302186  5017 net.cpp:509] conv4_4_ReLU0 -> conv4_4_0 (in-place)
I1003 12:39:11.302438  5017 net.cpp:172] Setting up conv4_4_ReLU0
I1003 12:39:11.302458  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.302462  5017 net.cpp:194] Memory required for data: 1842741376
I1003 12:39:11.302466  5017 layer_factory.hpp:77] Creating layer conv4_Drop4
I1003 12:39:11.302475  5017 net.cpp:128] Creating Layer conv4_Drop4
I1003 12:39:11.302479  5017 net.cpp:558] conv4_Drop4 <- conv4_4_0
I1003 12:39:11.302485  5017 net.cpp:509] conv4_Drop4 -> conv4_4_0 (in-place)
I1003 12:39:11.302523  5017 net.cpp:172] Setting up conv4_Drop4
I1003 12:39:11.302570  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.302575  5017 net.cpp:194] Memory required for data: 1847984256
I1003 12:39:11.302579  5017 layer_factory.hpp:77] Creating layer conv4_4_1
I1003 12:39:11.302593  5017 net.cpp:128] Creating Layer conv4_4_1
I1003 12:39:11.302597  5017 net.cpp:558] conv4_4_1 <- conv4_4_0
I1003 12:39:11.302606  5017 net.cpp:522] conv4_4_1 -> conv4_4_1
I1003 12:39:11.372716  5017 net.cpp:172] Setting up conv4_4_1
I1003 12:39:11.372776  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.372781  5017 net.cpp:194] Memory required for data: 1853227136
I1003 12:39:11.372800  5017 layer_factory.hpp:77] Creating layer conv4_4bn1
I1003 12:39:11.372817  5017 net.cpp:128] Creating Layer conv4_4bn1
I1003 12:39:11.372829  5017 net.cpp:558] conv4_4bn1 <- conv4_4_1
I1003 12:39:11.372838  5017 net.cpp:509] conv4_4bn1 -> conv4_4_1 (in-place)
I1003 12:39:11.373147  5017 net.cpp:172] Setting up conv4_4bn1
I1003 12:39:11.373158  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.373163  5017 net.cpp:194] Memory required for data: 1858470016
I1003 12:39:11.373173  5017 layer_factory.hpp:77] Creating layer conv4_4_scale1
I1003 12:39:11.373183  5017 net.cpp:128] Creating Layer conv4_4_scale1
I1003 12:39:11.373188  5017 net.cpp:558] conv4_4_scale1 <- conv4_4_1
I1003 12:39:11.373195  5017 net.cpp:509] conv4_4_scale1 -> conv4_4_1 (in-place)
I1003 12:39:11.373250  5017 layer_factory.hpp:77] Creating layer conv4_4_scale1
I1003 12:39:11.373437  5017 net.cpp:172] Setting up conv4_4_scale1
I1003 12:39:11.373445  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.373450  5017 net.cpp:194] Memory required for data: 1863712896
I1003 12:39:11.373457  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_4
I1003 12:39:11.373466  5017 net.cpp:128] Creating Layer conv4_Eltwise_4
I1003 12:39:11.373471  5017 net.cpp:558] conv4_Eltwise_4 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I1003 12:39:11.373476  5017 net.cpp:558] conv4_Eltwise_4 <- conv4_4_1
I1003 12:39:11.373484  5017 net.cpp:522] conv4_Eltwise_4 -> conv4_Eltwise_4
I1003 12:39:11.373514  5017 net.cpp:172] Setting up conv4_Eltwise_4
I1003 12:39:11.373524  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.373528  5017 net.cpp:194] Memory required for data: 1868955776
I1003 12:39:11.373533  5017 layer_factory.hpp:77] Creating layer conv4_4ReLU_1
I1003 12:39:11.373540  5017 net.cpp:128] Creating Layer conv4_4ReLU_1
I1003 12:39:11.373544  5017 net.cpp:558] conv4_4ReLU_1 <- conv4_Eltwise_4
I1003 12:39:11.373549  5017 net.cpp:509] conv4_4ReLU_1 -> conv4_Eltwise_4 (in-place)
I1003 12:39:11.373800  5017 net.cpp:172] Setting up conv4_4ReLU_1
I1003 12:39:11.373814  5017 net.cpp:186] Top shape: 32 640 8 8 (1310720)
I1003 12:39:11.373819  5017 net.cpp:194] Memory required for data: 1874198656
I1003 12:39:11.373823  5017 layer_factory.hpp:77] Creating layer Pooling1
I1003 12:39:11.373834  5017 net.cpp:128] Creating Layer Pooling1
I1003 12:39:11.373839  5017 net.cpp:558] Pooling1 <- conv4_Eltwise_4
I1003 12:39:11.373845  5017 net.cpp:522] Pooling1 -> Pooling1
I1003 12:39:11.374414  5017 net.cpp:172] Setting up Pooling1
I1003 12:39:11.374441  5017 net.cpp:186] Top shape: 32 640 1 1 (20480)
I1003 12:39:11.374445  5017 net.cpp:194] Memory required for data: 1874280576
I1003 12:39:11.374450  5017 layer_factory.hpp:77] Creating layer fc1
I1003 12:39:11.374460  5017 net.cpp:128] Creating Layer fc1
I1003 12:39:11.374465  5017 net.cpp:558] fc1 <- Pooling1
I1003 12:39:11.374475  5017 net.cpp:522] fc1 -> fc1
I1003 12:39:11.376121  5017 net.cpp:172] Setting up fc1
I1003 12:39:11.376145  5017 net.cpp:186] Top shape: 32 10 (320)
I1003 12:39:11.376149  5017 net.cpp:194] Memory required for data: 1874281856
I1003 12:39:11.376160  5017 layer_factory.hpp:77] Creating layer Softmax1
I1003 12:39:11.376168  5017 net.cpp:128] Creating Layer Softmax1
I1003 12:39:11.376173  5017 net.cpp:558] Softmax1 <- fc1
I1003 12:39:11.376178  5017 net.cpp:558] Softmax1 <- label
I1003 12:39:11.376193  5017 net.cpp:522] Softmax1 -> Softmax1
I1003 12:39:11.376230  5017 layer_factory.hpp:77] Creating layer Softmax1
I1003 12:39:11.376617  5017 net.cpp:172] Setting up Softmax1
I1003 12:39:11.376639  5017 net.cpp:186] Top shape: (1)
I1003 12:39:11.376643  5017 net.cpp:189]     with loss weight 1
I1003 12:39:11.376673  5017 net.cpp:194] Memory required for data: 1874281860
I1003 12:39:11.376678  5017 net.cpp:301] Softmax1 needs backward computation.
I1003 12:39:11.376684  5017 net.cpp:301] fc1 needs backward computation.
I1003 12:39:11.376688  5017 net.cpp:301] Pooling1 needs backward computation.
I1003 12:39:11.376693  5017 net.cpp:301] conv4_4ReLU_1 needs backward computation.
I1003 12:39:11.376696  5017 net.cpp:301] conv4_Eltwise_4 needs backward computation.
I1003 12:39:11.376701  5017 net.cpp:301] conv4_4_scale1 needs backward computation.
I1003 12:39:11.376705  5017 net.cpp:301] conv4_4bn1 needs backward computation.
I1003 12:39:11.376709  5017 net.cpp:301] conv4_4_1 needs backward computation.
I1003 12:39:11.376713  5017 net.cpp:301] conv4_Drop4 needs backward computation.
I1003 12:39:11.376718  5017 net.cpp:301] conv4_4_ReLU0 needs backward computation.
I1003 12:39:11.376722  5017 net.cpp:301] conv4_4_scale0 needs backward computation.
I1003 12:39:11.376726  5017 net.cpp:301] conv4_4_bn0 needs backward computation.
I1003 12:39:11.376730  5017 net.cpp:301] conv4_4_0 needs backward computation.
I1003 12:39:11.376735  5017 net.cpp:301] conv4_Eltwise_3_conv4_3ReLU_1_0_split needs backward computation.
I1003 12:39:11.376740  5017 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I1003 12:39:11.376745  5017 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I1003 12:39:11.376750  5017 net.cpp:301] conv4_3_scale1 needs backward computation.
I1003 12:39:11.376755  5017 net.cpp:301] conv4_3bn1 needs backward computation.
I1003 12:39:11.376760  5017 net.cpp:301] conv4_3_1 needs backward computation.
I1003 12:39:11.376763  5017 net.cpp:301] conv4_Drop3 needs backward computation.
I1003 12:39:11.376767  5017 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I1003 12:39:11.376772  5017 net.cpp:301] conv4_3_scale0 needs backward computation.
I1003 12:39:11.376776  5017 net.cpp:301] conv4_3_bn0 needs backward computation.
I1003 12:39:11.376781  5017 net.cpp:301] conv4_3_0 needs backward computation.
I1003 12:39:11.376785  5017 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I1003 12:39:11.376792  5017 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I1003 12:39:11.376796  5017 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I1003 12:39:11.376802  5017 net.cpp:301] conv4_2_scale1 needs backward computation.
I1003 12:39:11.376806  5017 net.cpp:301] conv4_2bn1 needs backward computation.
I1003 12:39:11.376811  5017 net.cpp:301] conv4_2_1 needs backward computation.
I1003 12:39:11.376814  5017 net.cpp:301] conv4_Drop2 needs backward computation.
I1003 12:39:11.376819  5017 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I1003 12:39:11.376824  5017 net.cpp:301] conv4_2_scale0 needs backward computation.
I1003 12:39:11.376828  5017 net.cpp:301] conv4_2_bn0 needs backward computation.
I1003 12:39:11.376832  5017 net.cpp:301] conv4_2_0 needs backward computation.
I1003 12:39:11.376837  5017 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I1003 12:39:11.376842  5017 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I1003 12:39:11.376845  5017 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I1003 12:39:11.376852  5017 net.cpp:301] conv4_1_scale_down needs backward computation.
I1003 12:39:11.376855  5017 net.cpp:301] conv4_1_bn_down needs backward computation.
I1003 12:39:11.376859  5017 net.cpp:301] conv4_1_down needs backward computation.
I1003 12:39:11.376864  5017 net.cpp:301] conv4_1_scale1 needs backward computation.
I1003 12:39:11.376868  5017 net.cpp:301] conv4_1bn1 needs backward computation.
I1003 12:39:11.376873  5017 net.cpp:301] conv4_1_1 needs backward computation.
I1003 12:39:11.376878  5017 net.cpp:301] conv4_Drop1 needs backward computation.
I1003 12:39:11.376895  5017 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I1003 12:39:11.376899  5017 net.cpp:301] conv4_1_scale0 needs backward computation.
I1003 12:39:11.376904  5017 net.cpp:301] conv4_1_bn0 needs backward computation.
I1003 12:39:11.376910  5017 net.cpp:301] conv4_1_0 needs backward computation.
I1003 12:39:11.376915  5017 net.cpp:301] conv3_Eltwise_4_conv3_4ReLU_1_0_split needs backward computation.
I1003 12:39:11.376919  5017 net.cpp:301] conv3_4ReLU_1 needs backward computation.
I1003 12:39:11.376924  5017 net.cpp:301] conv3_Eltwise_4 needs backward computation.
I1003 12:39:11.376929  5017 net.cpp:301] conv3_4_scale1 needs backward computation.
I1003 12:39:11.376933  5017 net.cpp:301] conv3_4bn1 needs backward computation.
I1003 12:39:11.376937  5017 net.cpp:301] conv3_4_1 needs backward computation.
I1003 12:39:11.376945  5017 net.cpp:301] conv3_Drop4 needs backward computation.
I1003 12:39:11.376948  5017 net.cpp:301] conv3_4_ReLU0 needs backward computation.
I1003 12:39:11.376952  5017 net.cpp:301] conv3_4_scale0 needs backward computation.
I1003 12:39:11.376957  5017 net.cpp:301] conv3_4_bn0 needs backward computation.
I1003 12:39:11.376961  5017 net.cpp:301] conv3_4_0 needs backward computation.
I1003 12:39:11.376966  5017 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I1003 12:39:11.376971  5017 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I1003 12:39:11.376976  5017 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I1003 12:39:11.376981  5017 net.cpp:301] conv3_3_scale1 needs backward computation.
I1003 12:39:11.376984  5017 net.cpp:301] conv3_3bn1 needs backward computation.
I1003 12:39:11.376988  5017 net.cpp:301] conv3_3_1 needs backward computation.
I1003 12:39:11.376993  5017 net.cpp:301] conv3_Drop3 needs backward computation.
I1003 12:39:11.376997  5017 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I1003 12:39:11.377002  5017 net.cpp:301] conv3_3_scale0 needs backward computation.
I1003 12:39:11.377005  5017 net.cpp:301] conv3_3_bn0 needs backward computation.
I1003 12:39:11.377010  5017 net.cpp:301] conv3_3_0 needs backward computation.
I1003 12:39:11.377015  5017 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I1003 12:39:11.377019  5017 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I1003 12:39:11.377023  5017 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I1003 12:39:11.377029  5017 net.cpp:301] conv3_2_scale1 needs backward computation.
I1003 12:39:11.377033  5017 net.cpp:301] conv3_2bn1 needs backward computation.
I1003 12:39:11.377038  5017 net.cpp:301] conv3_2_1 needs backward computation.
I1003 12:39:11.377041  5017 net.cpp:301] conv3_Drop2 needs backward computation.
I1003 12:39:11.377045  5017 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I1003 12:39:11.377050  5017 net.cpp:301] conv3_2_scale0 needs backward computation.
I1003 12:39:11.377054  5017 net.cpp:301] conv3_2_bn0 needs backward computation.
I1003 12:39:11.377058  5017 net.cpp:301] conv3_2_0 needs backward computation.
I1003 12:39:11.377063  5017 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I1003 12:39:11.377068  5017 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I1003 12:39:11.377071  5017 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I1003 12:39:11.377076  5017 net.cpp:301] conv3_1_scale_down needs backward computation.
I1003 12:39:11.377081  5017 net.cpp:301] conv3_1_bn_down needs backward computation.
I1003 12:39:11.377085  5017 net.cpp:301] conv3_1_down needs backward computation.
I1003 12:39:11.377090  5017 net.cpp:301] conv3_1_scale1 needs backward computation.
I1003 12:39:11.377095  5017 net.cpp:301] conv3_1bn1 needs backward computation.
I1003 12:39:11.377099  5017 net.cpp:301] conv3_1_1 needs backward computation.
I1003 12:39:11.377104  5017 net.cpp:301] conv3_Drop1 needs backward computation.
I1003 12:39:11.377108  5017 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I1003 12:39:11.377112  5017 net.cpp:301] conv3_1_scale0 needs backward computation.
I1003 12:39:11.377125  5017 net.cpp:301] conv3_1_bn0 needs backward computation.
I1003 12:39:11.377130  5017 net.cpp:301] conv3_1_0 needs backward computation.
I1003 12:39:11.377135  5017 net.cpp:301] conv2_Eltwise_4_conv2_4ReLU_1_0_split needs backward computation.
I1003 12:39:11.377143  5017 net.cpp:301] conv2_4ReLU_1 needs backward computation.
I1003 12:39:11.377148  5017 net.cpp:301] conv2_Eltwise_4 needs backward computation.
I1003 12:39:11.377153  5017 net.cpp:301] conv2_4_scale1 needs backward computation.
I1003 12:39:11.377157  5017 net.cpp:301] conv2_4bn1 needs backward computation.
I1003 12:39:11.377162  5017 net.cpp:301] conv2_4_1 needs backward computation.
I1003 12:39:11.377166  5017 net.cpp:301] conv2_Drop4 needs backward computation.
I1003 12:39:11.377171  5017 net.cpp:301] conv2_4_ReLU0 needs backward computation.
I1003 12:39:11.377176  5017 net.cpp:301] conv2_4_scale0 needs backward computation.
I1003 12:39:11.377179  5017 net.cpp:301] conv2_4_bn0 needs backward computation.
I1003 12:39:11.377184  5017 net.cpp:301] conv2_4_0 needs backward computation.
I1003 12:39:11.377189  5017 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I1003 12:39:11.377193  5017 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I1003 12:39:11.377198  5017 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I1003 12:39:11.377203  5017 net.cpp:301] conv2_3_scale1 needs backward computation.
I1003 12:39:11.377207  5017 net.cpp:301] conv2_3bn1 needs backward computation.
I1003 12:39:11.377213  5017 net.cpp:301] conv2_3_1 needs backward computation.
I1003 12:39:11.377216  5017 net.cpp:301] conv2_Drop3 needs backward computation.
I1003 12:39:11.377220  5017 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I1003 12:39:11.377224  5017 net.cpp:301] conv2_3_scale0 needs backward computation.
I1003 12:39:11.377229  5017 net.cpp:301] conv2_3_bn0 needs backward computation.
I1003 12:39:11.377233  5017 net.cpp:301] conv2_3_0 needs backward computation.
I1003 12:39:11.377238  5017 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I1003 12:39:11.377243  5017 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I1003 12:39:11.377248  5017 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I1003 12:39:11.377252  5017 net.cpp:301] conv2_2_scale1 needs backward computation.
I1003 12:39:11.377256  5017 net.cpp:301] conv2_2bn1 needs backward computation.
I1003 12:39:11.377260  5017 net.cpp:301] conv2_2_1 needs backward computation.
I1003 12:39:11.377264  5017 net.cpp:301] conv2_Drop2 needs backward computation.
I1003 12:39:11.377269  5017 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I1003 12:39:11.377272  5017 net.cpp:301] conv2_2_scale0 needs backward computation.
I1003 12:39:11.377277  5017 net.cpp:301] conv2_2_bn0 needs backward computation.
I1003 12:39:11.377281  5017 net.cpp:301] conv2_2_0 needs backward computation.
I1003 12:39:11.377286  5017 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I1003 12:39:11.377291  5017 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I1003 12:39:11.377295  5017 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I1003 12:39:11.377300  5017 net.cpp:301] conv2_1_scale_down needs backward computation.
I1003 12:39:11.377305  5017 net.cpp:301] conv2_1_bn_down needs backward computation.
I1003 12:39:11.377310  5017 net.cpp:301] conv2_1_down needs backward computation.
I1003 12:39:11.377315  5017 net.cpp:301] conv2_1_scale1 needs backward computation.
I1003 12:39:11.377319  5017 net.cpp:301] conv2_1bn1 needs backward computation.
I1003 12:39:11.377323  5017 net.cpp:301] conv2_1_1 needs backward computation.
I1003 12:39:11.377328  5017 net.cpp:301] conv2_Drop1 needs backward computation.
I1003 12:39:11.377332  5017 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I1003 12:39:11.377336  5017 net.cpp:301] conv2_1_scale0 needs backward computation.
I1003 12:39:11.377341  5017 net.cpp:301] conv2_1_bn0 needs backward computation.
I1003 12:39:11.377346  5017 net.cpp:301] conv2_1_0 needs backward computation.
I1003 12:39:11.377357  5017 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I1003 12:39:11.377362  5017 net.cpp:301] conv1/ReLU needs backward computation.
I1003 12:39:11.377367  5017 net.cpp:301] conv1/scale needs backward computation.
I1003 12:39:11.377370  5017 net.cpp:301] conv1/bn needs backward computation.
I1003 12:39:11.377375  5017 net.cpp:301] conv1 needs backward computation.
I1003 12:39:11.377380  5017 net.cpp:303] Data1 does not need backward computation.
I1003 12:39:11.377384  5017 net.cpp:348] This network produces output Softmax1
I1003 12:39:11.377465  5017 net.cpp:363] Network initialization done.
I1003 12:39:11.378993  5017 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./test_WRN_28.prototxt
I1003 12:39:11.379021  5017 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I1003 12:39:11.379030  5017 solver.cpp:277] Creating test net (#0) specified by test_net file: ./test_WRN_28.prototxt
I1003 12:39:11.380065  5017 net.cpp:82] Initializing net from parameters: 
name: "WRN-28"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: false
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/test_lmdb"
    batch_size: 10
    backend: LMDB
  }
  image_data_param {
    shuffle: false
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_Drop1"
  type: "Dropout"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_down"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn_down"
  type: "BatchNorm"
  bottom: "conv2_1_down"
  top: "conv2_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale_down"
  type: "Scale"
  bottom: "conv2_1_down"
  top: "conv2_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv2_1_1"
  bottom: "conv2_1_down"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_Drop2"
  type: "Dropout"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_Drop3"
  type: "Dropout"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv2_4_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv2_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4_bn0"
  type: "BatchNorm"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_4_scale0"
  type: "Scale"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_4_ReLU0"
  type: "ReLU"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
}
layer {
  name: "conv2_Drop4"
  type: "Dropout"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv2_4_1"
  type: "Convolution"
  bottom: "conv2_4_0"
  top: "conv2_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 160
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4bn1"
  type: "BatchNorm"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_4_scale1"
  type: "Scale"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_4"
  type: "Eltwise"
  bottom: "conv2_Eltwise_3"
  bottom: "conv2_4_1"
  top: "conv2_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_4ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_4"
  top: "conv2_Eltwise_4"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_4"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_Drop1"
  type: "Dropout"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_4"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_Drop2"
  type: "Dropout"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_Drop3"
  type: "Dropout"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv3_4_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv3_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4_bn0"
  type: "BatchNorm"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_scale0"
  type: "Scale"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_ReLU0"
  type: "ReLU"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
}
layer {
  name: "conv3_Drop4"
  type: "Dropout"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv3_4_1"
  type: "Convolution"
  bottom: "conv3_4_0"
  top: "conv3_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 320
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4bn1"
  type: "BatchNorm"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_scale1"
  type: "Scale"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_4"
  type: "Eltwise"
  bottom: "conv3_Eltwise_3"
  bottom: "conv3_4_1"
  top: "conv3_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_4ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_4"
  top: "conv3_Eltwise_4"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_4"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_Drop1"
  type: "Dropout"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_4"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_Drop2"
  type: "Dropout"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_Drop3"
  type: "Dropout"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "conv4_4_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_3"
  top: "conv4_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_4_bn0"
  type: "BatchNorm"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4_scale0"
  type: "Scale"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_4_ReLU0"
  type: "ReLU"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
}
layer {
  name: "conv4_Drop4"
  type: "Dropout"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  dropout_param {
    dropout_ratio: 1
  }
}
layer {
  name: "conv4_4_1"
  type: "Convolution"
  bottom: "conv4_4_0"
  top: "conv4_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 640
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_4bn1"
  type: "BatchNorm"
  bottom: "conv4_4_1"
  top: "conv4_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4_scale1"
  type: "Scale"
  bottom: "conv4_4_1"
  top: "conv4_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_4"
  type: "Eltwise"
  bottom: "conv4_Eltwise_3"
  bottom: "conv4_4_1"
  top: "conv4_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_4ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_4"
  top: "conv4_Eltwise_4"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "conv4_Eltwise_4"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_fille
I1003 12:39:11.380570  5017 layer_factory.hpp:77] Creating layer Data1
I1003 12:39:11.380650  5017 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/test_lmdb
I1003 12:39:11.380666  5017 net.cpp:128] Creating Layer Data1
I1003 12:39:11.380673  5017 net.cpp:522] Data1 -> data
I1003 12:39:11.380683  5017 net.cpp:522] Data1 -> label
I1003 12:39:11.380853  5017 data_layer.cpp:45] output data size: 10,3,32,32
I1003 12:39:11.381867  5017 net.cpp:172] Setting up Data1
I1003 12:39:11.381884  5017 net.cpp:186] Top shape: 10 3 32 32 (30720)
I1003 12:39:11.381891  5017 net.cpp:186] Top shape: 10 (10)
I1003 12:39:11.381894  5017 net.cpp:194] Memory required for data: 122920
I1003 12:39:11.381908  5017 layer_factory.hpp:77] Creating layer label_Data1_1_split
I1003 12:39:11.381920  5017 net.cpp:128] Creating Layer label_Data1_1_split
I1003 12:39:11.381925  5017 net.cpp:558] label_Data1_1_split <- label
I1003 12:39:11.381964  5017 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_0
I1003 12:39:11.381974  5017 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_1
I1003 12:39:11.382041  5017 net.cpp:172] Setting up label_Data1_1_split
I1003 12:39:11.382050  5017 net.cpp:186] Top shape: 10 (10)
I1003 12:39:11.382055  5017 net.cpp:186] Top shape: 10 (10)
I1003 12:39:11.382057  5017 net.cpp:194] Memory required for data: 123000
I1003 12:39:11.382061  5017 layer_factory.hpp:77] Creating layer conv1
I1003 12:39:11.382074  5017 net.cpp:128] Creating Layer conv1
I1003 12:39:11.382079  5017 net.cpp:558] conv1 <- data
I1003 12:39:11.382087  5017 net.cpp:522] conv1 -> conv1
I1003 12:39:11.384318  5017 net.cpp:172] Setting up conv1
I1003 12:39:11.384336  5017 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1003 12:39:11.384356  5017 net.cpp:194] Memory required for data: 778360
I1003 12:39:11.384371  5017 layer_factory.hpp:77] Creating layer conv1/bn
I1003 12:39:11.384382  5017 net.cpp:128] Creating Layer conv1/bn
I1003 12:39:11.384387  5017 net.cpp:558] conv1/bn <- conv1
I1003 12:39:11.384394  5017 net.cpp:509] conv1/bn -> conv1 (in-place)
I1003 12:39:11.384809  5017 net.cpp:172] Setting up conv1/bn
I1003 12:39:11.384819  5017 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1003 12:39:11.384851  5017 net.cpp:194] Memory required for data: 1433720
I1003 12:39:11.384866  5017 layer_factory.hpp:77] Creating layer conv1/scale
I1003 12:39:11.384876  5017 net.cpp:128] Creating Layer conv1/scale
I1003 12:39:11.384879  5017 net.cpp:558] conv1/scale <- conv1
I1003 12:39:11.384886  5017 net.cpp:509] conv1/scale -> conv1 (in-place)
I1003 12:39:11.384954  5017 layer_factory.hpp:77] Creating layer conv1/scale
I1003 12:39:11.385216  5017 net.cpp:172] Setting up conv1/scale
I1003 12:39:11.385226  5017 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1003 12:39:11.385229  5017 net.cpp:194] Memory required for data: 2089080
I1003 12:39:11.385237  5017 layer_factory.hpp:77] Creating layer conv1/ReLU
I1003 12:39:11.385350  5017 net.cpp:128] Creating Layer conv1/ReLU
I1003 12:39:11.385355  5017 net.cpp:558] conv1/ReLU <- conv1
I1003 12:39:11.385361  5017 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I1003 12:39:11.385632  5017 net.cpp:172] Setting up conv1/ReLU
I1003 12:39:11.385643  5017 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1003 12:39:11.385646  5017 net.cpp:194] Memory required for data: 2744440
I1003 12:39:11.385651  5017 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I1003 12:39:11.385659  5017 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I1003 12:39:11.385664  5017 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I1003 12:39:11.385673  5017 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I1003 12:39:11.385680  5017 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I1003 12:39:11.385740  5017 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I1003 12:39:11.385748  5017 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1003 12:39:11.385754  5017 net.cpp:186] Top shape: 10 16 32 32 (163840)
I1003 12:39:11.385757  5017 net.cpp:194] Memory required for data: 4055160
I1003 12:39:11.385776  5017 layer_factory.hpp:77] Creating layer conv2_1_0
I1003 12:39:11.385797  5017 net.cpp:128] Creating Layer conv2_1_0
I1003 12:39:11.385802  5017 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I1003 12:39:11.385808  5017 net.cpp:522] conv2_1_0 -> conv2_1_0
I1003 12:39:11.387883  5017 net.cpp:172] Setting up conv2_1_0
I1003 12:39:11.387903  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.387912  5017 net.cpp:194] Memory required for data: 10608760
I1003 12:39:11.387925  5017 layer_factory.hpp:77] Creating layer conv2_1_bn0
I1003 12:39:11.387939  5017 net.cpp:128] Creating Layer conv2_1_bn0
I1003 12:39:11.387946  5017 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I1003 12:39:11.387961  5017 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I1003 12:39:11.388276  5017 net.cpp:172] Setting up conv2_1_bn0
I1003 12:39:11.388286  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.388290  5017 net.cpp:194] Memory required for data: 17162360
I1003 12:39:11.388300  5017 layer_factory.hpp:77] Creating layer conv2_1_scale0
I1003 12:39:11.388308  5017 net.cpp:128] Creating Layer conv2_1_scale0
I1003 12:39:11.388311  5017 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I1003 12:39:11.388319  5017 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I1003 12:39:11.388370  5017 layer_factory.hpp:77] Creating layer conv2_1_scale0
I1003 12:39:11.388535  5017 net.cpp:172] Setting up conv2_1_scale0
I1003 12:39:11.388545  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.388550  5017 net.cpp:194] Memory required for data: 23715960
I1003 12:39:11.388557  5017 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I1003 12:39:11.388563  5017 net.cpp:128] Creating Layer conv2_1_ReLU0
I1003 12:39:11.388584  5017 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I1003 12:39:11.388590  5017 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I1003 12:39:11.388841  5017 net.cpp:172] Setting up conv2_1_ReLU0
I1003 12:39:11.388857  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.388864  5017 net.cpp:194] Memory required for data: 30269560
I1003 12:39:11.388869  5017 layer_factory.hpp:77] Creating layer conv2_Drop1
I1003 12:39:11.388875  5017 net.cpp:128] Creating Layer conv2_Drop1
I1003 12:39:11.388880  5017 net.cpp:558] conv2_Drop1 <- conv2_1_0
I1003 12:39:11.388885  5017 net.cpp:509] conv2_Drop1 -> conv2_1_0 (in-place)
I1003 12:39:11.388926  5017 net.cpp:172] Setting up conv2_Drop1
I1003 12:39:11.388934  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.388938  5017 net.cpp:194] Memory required for data: 36823160
I1003 12:39:11.388942  5017 layer_factory.hpp:77] Creating layer conv2_1_1
I1003 12:39:11.388954  5017 net.cpp:128] Creating Layer conv2_1_1
I1003 12:39:11.388960  5017 net.cpp:558] conv2_1_1 <- conv2_1_0
I1003 12:39:11.388970  5017 net.cpp:522] conv2_1_1 -> conv2_1_1
I1003 12:39:11.395457  5017 net.cpp:172] Setting up conv2_1_1
I1003 12:39:11.395488  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.395493  5017 net.cpp:194] Memory required for data: 43376760
I1003 12:39:11.395509  5017 layer_factory.hpp:77] Creating layer conv2_1bn1
I1003 12:39:11.395521  5017 net.cpp:128] Creating Layer conv2_1bn1
I1003 12:39:11.395527  5017 net.cpp:558] conv2_1bn1 <- conv2_1_1
I1003 12:39:11.395540  5017 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I1003 12:39:11.395864  5017 net.cpp:172] Setting up conv2_1bn1
I1003 12:39:11.395874  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.395879  5017 net.cpp:194] Memory required for data: 49930360
I1003 12:39:11.395891  5017 layer_factory.hpp:77] Creating layer conv2_1_scale1
I1003 12:39:11.395901  5017 net.cpp:128] Creating Layer conv2_1_scale1
I1003 12:39:11.395906  5017 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I1003 12:39:11.395912  5017 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I1003 12:39:11.395968  5017 layer_factory.hpp:77] Creating layer conv2_1_scale1
I1003 12:39:11.396136  5017 net.cpp:172] Setting up conv2_1_scale1
I1003 12:39:11.396149  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.396153  5017 net.cpp:194] Memory required for data: 56483960
I1003 12:39:11.396162  5017 layer_factory.hpp:77] Creating layer conv2_1_down
I1003 12:39:11.396173  5017 net.cpp:128] Creating Layer conv2_1_down
I1003 12:39:11.396178  5017 net.cpp:558] conv2_1_down <- conv1_conv1/ReLU_0_split_1
I1003 12:39:11.396188  5017 net.cpp:522] conv2_1_down -> conv2_1_down
I1003 12:39:11.397760  5017 net.cpp:172] Setting up conv2_1_down
I1003 12:39:11.397785  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.397790  5017 net.cpp:194] Memory required for data: 63037560
I1003 12:39:11.397799  5017 layer_factory.hpp:77] Creating layer conv2_1_bn_down
I1003 12:39:11.397814  5017 net.cpp:128] Creating Layer conv2_1_bn_down
I1003 12:39:11.397819  5017 net.cpp:558] conv2_1_bn_down <- conv2_1_down
I1003 12:39:11.397827  5017 net.cpp:509] conv2_1_bn_down -> conv2_1_down (in-place)
I1003 12:39:11.398146  5017 net.cpp:172] Setting up conv2_1_bn_down
I1003 12:39:11.398159  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.398164  5017 net.cpp:194] Memory required for data: 69591160
I1003 12:39:11.398174  5017 layer_factory.hpp:77] Creating layer conv2_1_scale_down
I1003 12:39:11.398180  5017 net.cpp:128] Creating Layer conv2_1_scale_down
I1003 12:39:11.398185  5017 net.cpp:558] conv2_1_scale_down <- conv2_1_down
I1003 12:39:11.398190  5017 net.cpp:509] conv2_1_scale_down -> conv2_1_down (in-place)
I1003 12:39:11.398247  5017 layer_factory.hpp:77] Creating layer conv2_1_scale_down
I1003 12:39:11.398412  5017 net.cpp:172] Setting up conv2_1_scale_down
I1003 12:39:11.398422  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.398427  5017 net.cpp:194] Memory required for data: 76144760
I1003 12:39:11.398453  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I1003 12:39:11.398466  5017 net.cpp:128] Creating Layer conv2_Eltwise_1
I1003 12:39:11.398470  5017 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I1003 12:39:11.398476  5017 net.cpp:558] conv2_Eltwise_1 <- conv2_1_down
I1003 12:39:11.398483  5017 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I1003 12:39:11.398517  5017 net.cpp:172] Setting up conv2_Eltwise_1
I1003 12:39:11.398530  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.398533  5017 net.cpp:194] Memory required for data: 82698360
I1003 12:39:11.398537  5017 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I1003 12:39:11.398545  5017 net.cpp:128] Creating Layer conv2_1ReLU_1
I1003 12:39:11.398548  5017 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I1003 12:39:11.398556  5017 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I1003 12:39:11.399008  5017 net.cpp:172] Setting up conv2_1ReLU_1
I1003 12:39:11.399029  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.399032  5017 net.cpp:194] Memory required for data: 89251960
I1003 12:39:11.399037  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1003 12:39:11.399046  5017 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1003 12:39:11.399051  5017 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I1003 12:39:11.399060  5017 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I1003 12:39:11.399070  5017 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I1003 12:39:11.399129  5017 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I1003 12:39:11.399140  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.399147  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.399149  5017 net.cpp:194] Memory required for data: 102359160
I1003 12:39:11.399154  5017 layer_factory.hpp:77] Creating layer conv2_2_0
I1003 12:39:11.399166  5017 net.cpp:128] Creating Layer conv2_2_0
I1003 12:39:11.399170  5017 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I1003 12:39:11.399179  5017 net.cpp:522] conv2_2_0 -> conv2_2_0
I1003 12:39:11.404330  5017 net.cpp:172] Setting up conv2_2_0
I1003 12:39:11.404356  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.404361  5017 net.cpp:194] Memory required for data: 108912760
I1003 12:39:11.404371  5017 layer_factory.hpp:77] Creating layer conv2_2_bn0
I1003 12:39:11.404381  5017 net.cpp:128] Creating Layer conv2_2_bn0
I1003 12:39:11.404386  5017 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I1003 12:39:11.404392  5017 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I1003 12:39:11.404711  5017 net.cpp:172] Setting up conv2_2_bn0
I1003 12:39:11.404723  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.404727  5017 net.cpp:194] Memory required for data: 115466360
I1003 12:39:11.404742  5017 layer_factory.hpp:77] Creating layer conv2_2_scale0
I1003 12:39:11.404748  5017 net.cpp:128] Creating Layer conv2_2_scale0
I1003 12:39:11.404753  5017 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I1003 12:39:11.404758  5017 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I1003 12:39:11.404815  5017 layer_factory.hpp:77] Creating layer conv2_2_scale0
I1003 12:39:11.404989  5017 net.cpp:172] Setting up conv2_2_scale0
I1003 12:39:11.404999  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.405004  5017 net.cpp:194] Memory required for data: 122019960
I1003 12:39:11.405010  5017 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I1003 12:39:11.405017  5017 net.cpp:128] Creating Layer conv2_2_ReLU0
I1003 12:39:11.405022  5017 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I1003 12:39:11.405030  5017 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I1003 12:39:11.405277  5017 net.cpp:172] Setting up conv2_2_ReLU0
I1003 12:39:11.405292  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.405295  5017 net.cpp:194] Memory required for data: 128573560
I1003 12:39:11.405316  5017 layer_factory.hpp:77] Creating layer conv2_Drop2
I1003 12:39:11.405324  5017 net.cpp:128] Creating Layer conv2_Drop2
I1003 12:39:11.405328  5017 net.cpp:558] conv2_Drop2 <- conv2_2_0
I1003 12:39:11.405338  5017 net.cpp:509] conv2_Drop2 -> conv2_2_0 (in-place)
I1003 12:39:11.405375  5017 net.cpp:172] Setting up conv2_Drop2
I1003 12:39:11.405385  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.405388  5017 net.cpp:194] Memory required for data: 135127160
I1003 12:39:11.405392  5017 layer_factory.hpp:77] Creating layer conv2_2_1
I1003 12:39:11.405407  5017 net.cpp:128] Creating Layer conv2_2_1
I1003 12:39:11.405411  5017 net.cpp:558] conv2_2_1 <- conv2_2_0
I1003 12:39:11.405418  5017 net.cpp:522] conv2_2_1 -> conv2_2_1
I1003 12:39:11.411891  5017 net.cpp:172] Setting up conv2_2_1
I1003 12:39:11.411921  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.411926  5017 net.cpp:194] Memory required for data: 141680760
I1003 12:39:11.411937  5017 layer_factory.hpp:77] Creating layer conv2_2bn1
I1003 12:39:11.411949  5017 net.cpp:128] Creating Layer conv2_2bn1
I1003 12:39:11.411954  5017 net.cpp:558] conv2_2bn1 <- conv2_2_1
I1003 12:39:11.411964  5017 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I1003 12:39:11.412292  5017 net.cpp:172] Setting up conv2_2bn1
I1003 12:39:11.412302  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.412307  5017 net.cpp:194] Memory required for data: 148234360
I1003 12:39:11.412317  5017 layer_factory.hpp:77] Creating layer conv2_2_scale1
I1003 12:39:11.412324  5017 net.cpp:128] Creating Layer conv2_2_scale1
I1003 12:39:11.412328  5017 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I1003 12:39:11.412333  5017 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I1003 12:39:11.412391  5017 layer_factory.hpp:77] Creating layer conv2_2_scale1
I1003 12:39:11.412564  5017 net.cpp:172] Setting up conv2_2_scale1
I1003 12:39:11.412575  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.412580  5017 net.cpp:194] Memory required for data: 154787960
I1003 12:39:11.412587  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I1003 12:39:11.412596  5017 net.cpp:128] Creating Layer conv2_Eltwise_2
I1003 12:39:11.412601  5017 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I1003 12:39:11.412606  5017 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I1003 12:39:11.412616  5017 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I1003 12:39:11.412645  5017 net.cpp:172] Setting up conv2_Eltwise_2
I1003 12:39:11.412653  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.412657  5017 net.cpp:194] Memory required for data: 161341560
I1003 12:39:11.412662  5017 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I1003 12:39:11.412669  5017 net.cpp:128] Creating Layer conv2_2ReLU_1
I1003 12:39:11.412674  5017 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I1003 12:39:11.412679  5017 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I1003 12:39:11.412922  5017 net.cpp:172] Setting up conv2_2ReLU_1
I1003 12:39:11.412937  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.412941  5017 net.cpp:194] Memory required for data: 167895160
I1003 12:39:11.412946  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1003 12:39:11.412956  5017 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1003 12:39:11.412961  5017 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I1003 12:39:11.412967  5017 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I1003 12:39:11.412979  5017 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I1003 12:39:11.413040  5017 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I1003 12:39:11.413048  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.413054  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.413058  5017 net.cpp:194] Memory required for data: 181002360
I1003 12:39:11.413079  5017 layer_factory.hpp:77] Creating layer conv2_3_0
I1003 12:39:11.413095  5017 net.cpp:128] Creating Layer conv2_3_0
I1003 12:39:11.413100  5017 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I1003 12:39:11.413107  5017 net.cpp:522] conv2_3_0 -> conv2_3_0
I1003 12:39:11.418287  5017 net.cpp:172] Setting up conv2_3_0
I1003 12:39:11.418314  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.418318  5017 net.cpp:194] Memory required for data: 187555960
I1003 12:39:11.418329  5017 layer_factory.hpp:77] Creating layer conv2_3_bn0
I1003 12:39:11.418339  5017 net.cpp:128] Creating Layer conv2_3_bn0
I1003 12:39:11.418344  5017 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I1003 12:39:11.418354  5017 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I1003 12:39:11.418684  5017 net.cpp:172] Setting up conv2_3_bn0
I1003 12:39:11.418696  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.418702  5017 net.cpp:194] Memory required for data: 194109560
I1003 12:39:11.418711  5017 layer_factory.hpp:77] Creating layer conv2_3_scale0
I1003 12:39:11.418720  5017 net.cpp:128] Creating Layer conv2_3_scale0
I1003 12:39:11.418723  5017 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I1003 12:39:11.418730  5017 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I1003 12:39:11.418783  5017 layer_factory.hpp:77] Creating layer conv2_3_scale0
I1003 12:39:11.418961  5017 net.cpp:172] Setting up conv2_3_scale0
I1003 12:39:11.418972  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.418975  5017 net.cpp:194] Memory required for data: 200663160
I1003 12:39:11.418983  5017 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I1003 12:39:11.418992  5017 net.cpp:128] Creating Layer conv2_3_ReLU0
I1003 12:39:11.418997  5017 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I1003 12:39:11.419001  5017 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I1003 12:39:11.419461  5017 net.cpp:172] Setting up conv2_3_ReLU0
I1003 12:39:11.419482  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.419486  5017 net.cpp:194] Memory required for data: 207216760
I1003 12:39:11.419492  5017 layer_factory.hpp:77] Creating layer conv2_Drop3
I1003 12:39:11.419502  5017 net.cpp:128] Creating Layer conv2_Drop3
I1003 12:39:11.419507  5017 net.cpp:558] conv2_Drop3 <- conv2_3_0
I1003 12:39:11.419514  5017 net.cpp:509] conv2_Drop3 -> conv2_3_0 (in-place)
I1003 12:39:11.419555  5017 net.cpp:172] Setting up conv2_Drop3
I1003 12:39:11.419562  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.419566  5017 net.cpp:194] Memory required for data: 213770360
I1003 12:39:11.419570  5017 layer_factory.hpp:77] Creating layer conv2_3_1
I1003 12:39:11.419581  5017 net.cpp:128] Creating Layer conv2_3_1
I1003 12:39:11.419585  5017 net.cpp:558] conv2_3_1 <- conv2_3_0
I1003 12:39:11.419595  5017 net.cpp:522] conv2_3_1 -> conv2_3_1
I1003 12:39:11.426087  5017 net.cpp:172] Setting up conv2_3_1
I1003 12:39:11.426115  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.426120  5017 net.cpp:194] Memory required for data: 220323960
I1003 12:39:11.426131  5017 layer_factory.hpp:77] Creating layer conv2_3bn1
I1003 12:39:11.426142  5017 net.cpp:128] Creating Layer conv2_3bn1
I1003 12:39:11.426147  5017 net.cpp:558] conv2_3bn1 <- conv2_3_1
I1003 12:39:11.426162  5017 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I1003 12:39:11.426486  5017 net.cpp:172] Setting up conv2_3bn1
I1003 12:39:11.426498  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.426503  5017 net.cpp:194] Memory required for data: 226877560
I1003 12:39:11.426513  5017 layer_factory.hpp:77] Creating layer conv2_3_scale1
I1003 12:39:11.426527  5017 net.cpp:128] Creating Layer conv2_3_scale1
I1003 12:39:11.426532  5017 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I1003 12:39:11.426537  5017 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I1003 12:39:11.426594  5017 layer_factory.hpp:77] Creating layer conv2_3_scale1
I1003 12:39:11.426775  5017 net.cpp:172] Setting up conv2_3_scale1
I1003 12:39:11.426805  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.426810  5017 net.cpp:194] Memory required for data: 233431160
I1003 12:39:11.426818  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I1003 12:39:11.426826  5017 net.cpp:128] Creating Layer conv2_Eltwise_3
I1003 12:39:11.426832  5017 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I1003 12:39:11.426838  5017 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I1003 12:39:11.426846  5017 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I1003 12:39:11.426882  5017 net.cpp:172] Setting up conv2_Eltwise_3
I1003 12:39:11.426889  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.426893  5017 net.cpp:194] Memory required for data: 239984760
I1003 12:39:11.426898  5017 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I1003 12:39:11.426903  5017 net.cpp:128] Creating Layer conv2_3ReLU_1
I1003 12:39:11.426908  5017 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I1003 12:39:11.426913  5017 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I1003 12:39:11.427167  5017 net.cpp:172] Setting up conv2_3ReLU_1
I1003 12:39:11.427182  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.427186  5017 net.cpp:194] Memory required for data: 246538360
I1003 12:39:11.427191  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1003 12:39:11.427198  5017 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1003 12:39:11.427204  5017 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I1003 12:39:11.427213  5017 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I1003 12:39:11.427222  5017 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I1003 12:39:11.427281  5017 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I1003 12:39:11.427292  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.427299  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.427304  5017 net.cpp:194] Memory required for data: 259645560
I1003 12:39:11.427307  5017 layer_factory.hpp:77] Creating layer conv2_4_0
I1003 12:39:11.427321  5017 net.cpp:128] Creating Layer conv2_4_0
I1003 12:39:11.427325  5017 net.cpp:558] conv2_4_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I1003 12:39:11.427335  5017 net.cpp:522] conv2_4_0 -> conv2_4_0
I1003 12:39:11.432507  5017 net.cpp:172] Setting up conv2_4_0
I1003 12:39:11.432533  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.432538  5017 net.cpp:194] Memory required for data: 266199160
I1003 12:39:11.432548  5017 layer_factory.hpp:77] Creating layer conv2_4_bn0
I1003 12:39:11.432557  5017 net.cpp:128] Creating Layer conv2_4_bn0
I1003 12:39:11.432562  5017 net.cpp:558] conv2_4_bn0 <- conv2_4_0
I1003 12:39:11.432575  5017 net.cpp:509] conv2_4_bn0 -> conv2_4_0 (in-place)
I1003 12:39:11.432904  5017 net.cpp:172] Setting up conv2_4_bn0
I1003 12:39:11.432915  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.432920  5017 net.cpp:194] Memory required for data: 272752760
I1003 12:39:11.432929  5017 layer_factory.hpp:77] Creating layer conv2_4_scale0
I1003 12:39:11.432936  5017 net.cpp:128] Creating Layer conv2_4_scale0
I1003 12:39:11.432941  5017 net.cpp:558] conv2_4_scale0 <- conv2_4_0
I1003 12:39:11.432951  5017 net.cpp:509] conv2_4_scale0 -> conv2_4_0 (in-place)
I1003 12:39:11.433006  5017 layer_factory.hpp:77] Creating layer conv2_4_scale0
I1003 12:39:11.433179  5017 net.cpp:172] Setting up conv2_4_scale0
I1003 12:39:11.433192  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.433197  5017 net.cpp:194] Memory required for data: 279306360
I1003 12:39:11.433204  5017 layer_factory.hpp:77] Creating layer conv2_4_ReLU0
I1003 12:39:11.433210  5017 net.cpp:128] Creating Layer conv2_4_ReLU0
I1003 12:39:11.433215  5017 net.cpp:558] conv2_4_ReLU0 <- conv2_4_0
I1003 12:39:11.433220  5017 net.cpp:509] conv2_4_ReLU0 -> conv2_4_0 (in-place)
I1003 12:39:11.433480  5017 net.cpp:172] Setting up conv2_4_ReLU0
I1003 12:39:11.433511  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.433516  5017 net.cpp:194] Memory required for data: 285859960
I1003 12:39:11.433521  5017 layer_factory.hpp:77] Creating layer conv2_Drop4
I1003 12:39:11.433528  5017 net.cpp:128] Creating Layer conv2_Drop4
I1003 12:39:11.433534  5017 net.cpp:558] conv2_Drop4 <- conv2_4_0
I1003 12:39:11.433540  5017 net.cpp:509] conv2_Drop4 -> conv2_4_0 (in-place)
I1003 12:39:11.433578  5017 net.cpp:172] Setting up conv2_Drop4
I1003 12:39:11.433586  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.433590  5017 net.cpp:194] Memory required for data: 292413560
I1003 12:39:11.433594  5017 layer_factory.hpp:77] Creating layer conv2_4_1
I1003 12:39:11.433605  5017 net.cpp:128] Creating Layer conv2_4_1
I1003 12:39:11.433609  5017 net.cpp:558] conv2_4_1 <- conv2_4_0
I1003 12:39:11.433620  5017 net.cpp:522] conv2_4_1 -> conv2_4_1
I1003 12:39:11.440086  5017 net.cpp:172] Setting up conv2_4_1
I1003 12:39:11.440115  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.440119  5017 net.cpp:194] Memory required for data: 298967160
I1003 12:39:11.440141  5017 layer_factory.hpp:77] Creating layer conv2_4bn1
I1003 12:39:11.440158  5017 net.cpp:128] Creating Layer conv2_4bn1
I1003 12:39:11.440163  5017 net.cpp:558] conv2_4bn1 <- conv2_4_1
I1003 12:39:11.440171  5017 net.cpp:509] conv2_4bn1 -> conv2_4_1 (in-place)
I1003 12:39:11.440501  5017 net.cpp:172] Setting up conv2_4bn1
I1003 12:39:11.440513  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.440517  5017 net.cpp:194] Memory required for data: 305520760
I1003 12:39:11.440527  5017 layer_factory.hpp:77] Creating layer conv2_4_scale1
I1003 12:39:11.440534  5017 net.cpp:128] Creating Layer conv2_4_scale1
I1003 12:39:11.440538  5017 net.cpp:558] conv2_4_scale1 <- conv2_4_1
I1003 12:39:11.440546  5017 net.cpp:509] conv2_4_scale1 -> conv2_4_1 (in-place)
I1003 12:39:11.440601  5017 layer_factory.hpp:77] Creating layer conv2_4_scale1
I1003 12:39:11.440781  5017 net.cpp:172] Setting up conv2_4_scale1
I1003 12:39:11.440794  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.440798  5017 net.cpp:194] Memory required for data: 312074360
I1003 12:39:11.440806  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_4
I1003 12:39:11.440814  5017 net.cpp:128] Creating Layer conv2_Eltwise_4
I1003 12:39:11.440819  5017 net.cpp:558] conv2_Eltwise_4 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I1003 12:39:11.440824  5017 net.cpp:558] conv2_Eltwise_4 <- conv2_4_1
I1003 12:39:11.440831  5017 net.cpp:522] conv2_Eltwise_4 -> conv2_Eltwise_4
I1003 12:39:11.440862  5017 net.cpp:172] Setting up conv2_Eltwise_4
I1003 12:39:11.440871  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.440876  5017 net.cpp:194] Memory required for data: 318627960
I1003 12:39:11.440881  5017 layer_factory.hpp:77] Creating layer conv2_4ReLU_1
I1003 12:39:11.440887  5017 net.cpp:128] Creating Layer conv2_4ReLU_1
I1003 12:39:11.440891  5017 net.cpp:558] conv2_4ReLU_1 <- conv2_Eltwise_4
I1003 12:39:11.440896  5017 net.cpp:509] conv2_4ReLU_1 -> conv2_Eltwise_4 (in-place)
I1003 12:39:11.441366  5017 net.cpp:172] Setting up conv2_4ReLU_1
I1003 12:39:11.441390  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.441395  5017 net.cpp:194] Memory required for data: 325181560
I1003 12:39:11.441401  5017 layer_factory.hpp:77] Creating layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I1003 12:39:11.441411  5017 net.cpp:128] Creating Layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I1003 12:39:11.441416  5017 net.cpp:558] conv2_Eltwise_4_conv2_4ReLU_1_0_split <- conv2_Eltwise_4
I1003 12:39:11.441422  5017 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I1003 12:39:11.441433  5017 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I1003 12:39:11.441498  5017 net.cpp:172] Setting up conv2_Eltwise_4_conv2_4ReLU_1_0_split
I1003 12:39:11.441510  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.441531  5017 net.cpp:186] Top shape: 10 160 32 32 (1638400)
I1003 12:39:11.441535  5017 net.cpp:194] Memory required for data: 338288760
I1003 12:39:11.441540  5017 layer_factory.hpp:77] Creating layer conv3_1_0
I1003 12:39:11.441552  5017 net.cpp:128] Creating Layer conv3_1_0
I1003 12:39:11.441557  5017 net.cpp:558] conv3_1_0 <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I1003 12:39:11.441566  5017 net.cpp:522] conv3_1_0 -> conv3_1_0
I1003 12:39:11.451443  5017 net.cpp:172] Setting up conv3_1_0
I1003 12:39:11.451472  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.451475  5017 net.cpp:194] Memory required for data: 341565560
I1003 12:39:11.451488  5017 layer_factory.hpp:77] Creating layer conv3_1_bn0
I1003 12:39:11.451499  5017 net.cpp:128] Creating Layer conv3_1_bn0
I1003 12:39:11.451505  5017 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I1003 12:39:11.451519  5017 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I1003 12:39:11.451843  5017 net.cpp:172] Setting up conv3_1_bn0
I1003 12:39:11.451855  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.451860  5017 net.cpp:194] Memory required for data: 344842360
I1003 12:39:11.451870  5017 layer_factory.hpp:77] Creating layer conv3_1_scale0
I1003 12:39:11.451880  5017 net.cpp:128] Creating Layer conv3_1_scale0
I1003 12:39:11.451885  5017 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I1003 12:39:11.451890  5017 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I1003 12:39:11.451951  5017 layer_factory.hpp:77] Creating layer conv3_1_scale0
I1003 12:39:11.452134  5017 net.cpp:172] Setting up conv3_1_scale0
I1003 12:39:11.452143  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.452147  5017 net.cpp:194] Memory required for data: 348119160
I1003 12:39:11.452155  5017 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I1003 12:39:11.452172  5017 net.cpp:128] Creating Layer conv3_1_ReLU0
I1003 12:39:11.452175  5017 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I1003 12:39:11.452181  5017 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I1003 12:39:11.452435  5017 net.cpp:172] Setting up conv3_1_ReLU0
I1003 12:39:11.452450  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.452455  5017 net.cpp:194] Memory required for data: 351395960
I1003 12:39:11.452458  5017 layer_factory.hpp:77] Creating layer conv3_Drop1
I1003 12:39:11.452468  5017 net.cpp:128] Creating Layer conv3_Drop1
I1003 12:39:11.452473  5017 net.cpp:558] conv3_Drop1 <- conv3_1_0
I1003 12:39:11.452479  5017 net.cpp:509] conv3_Drop1 -> conv3_1_0 (in-place)
I1003 12:39:11.452512  5017 net.cpp:172] Setting up conv3_Drop1
I1003 12:39:11.452519  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.452523  5017 net.cpp:194] Memory required for data: 354672760
I1003 12:39:11.452527  5017 layer_factory.hpp:77] Creating layer conv3_1_1
I1003 12:39:11.452538  5017 net.cpp:128] Creating Layer conv3_1_1
I1003 12:39:11.452543  5017 net.cpp:558] conv3_1_1 <- conv3_1_0
I1003 12:39:11.452553  5017 net.cpp:522] conv3_1_1 -> conv3_1_1
I1003 12:39:11.470793  5017 net.cpp:172] Setting up conv3_1_1
I1003 12:39:11.470830  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.470834  5017 net.cpp:194] Memory required for data: 357949560
I1003 12:39:11.470847  5017 layer_factory.hpp:77] Creating layer conv3_1bn1
I1003 12:39:11.470861  5017 net.cpp:128] Creating Layer conv3_1bn1
I1003 12:39:11.470868  5017 net.cpp:558] conv3_1bn1 <- conv3_1_1
I1003 12:39:11.470881  5017 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I1003 12:39:11.471216  5017 net.cpp:172] Setting up conv3_1bn1
I1003 12:39:11.471227  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.471233  5017 net.cpp:194] Memory required for data: 361226360
I1003 12:39:11.471244  5017 layer_factory.hpp:77] Creating layer conv3_1_scale1
I1003 12:39:11.471251  5017 net.cpp:128] Creating Layer conv3_1_scale1
I1003 12:39:11.471256  5017 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I1003 12:39:11.471264  5017 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I1003 12:39:11.471352  5017 layer_factory.hpp:77] Creating layer conv3_1_scale1
I1003 12:39:11.471539  5017 net.cpp:172] Setting up conv3_1_scale1
I1003 12:39:11.471547  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.471551  5017 net.cpp:194] Memory required for data: 364503160
I1003 12:39:11.471560  5017 layer_factory.hpp:77] Creating layer conv3_1_down
I1003 12:39:11.471576  5017 net.cpp:128] Creating Layer conv3_1_down
I1003 12:39:11.471582  5017 net.cpp:558] conv3_1_down <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I1003 12:39:11.471592  5017 net.cpp:522] conv3_1_down -> conv3_1_down
I1003 12:39:11.473832  5017 net.cpp:172] Setting up conv3_1_down
I1003 12:39:11.473858  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.473862  5017 net.cpp:194] Memory required for data: 367779960
I1003 12:39:11.473872  5017 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I1003 12:39:11.473883  5017 net.cpp:128] Creating Layer conv3_1_bn_down
I1003 12:39:11.473888  5017 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I1003 12:39:11.473896  5017 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I1003 12:39:11.474244  5017 net.cpp:172] Setting up conv3_1_bn_down
I1003 12:39:11.474257  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.474262  5017 net.cpp:194] Memory required for data: 371056760
I1003 12:39:11.474273  5017 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I1003 12:39:11.474287  5017 net.cpp:128] Creating Layer conv3_1_scale_down
I1003 12:39:11.474292  5017 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I1003 12:39:11.474298  5017 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I1003 12:39:11.474359  5017 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I1003 12:39:11.474542  5017 net.cpp:172] Setting up conv3_1_scale_down
I1003 12:39:11.474550  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.474555  5017 net.cpp:194] Memory required for data: 374333560
I1003 12:39:11.474562  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I1003 12:39:11.474573  5017 net.cpp:128] Creating Layer conv3_Eltwise_1
I1003 12:39:11.474577  5017 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I1003 12:39:11.474582  5017 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I1003 12:39:11.474588  5017 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I1003 12:39:11.474618  5017 net.cpp:172] Setting up conv3_Eltwise_1
I1003 12:39:11.474625  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.474629  5017 net.cpp:194] Memory required for data: 377610360
I1003 12:39:11.474633  5017 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I1003 12:39:11.474640  5017 net.cpp:128] Creating Layer conv3_1ReLU_1
I1003 12:39:11.474644  5017 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I1003 12:39:11.474649  5017 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I1003 12:39:11.474911  5017 net.cpp:172] Setting up conv3_1ReLU_1
I1003 12:39:11.474927  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.474932  5017 net.cpp:194] Memory required for data: 380887160
I1003 12:39:11.474936  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1003 12:39:11.474943  5017 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1003 12:39:11.474948  5017 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I1003 12:39:11.474957  5017 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I1003 12:39:11.474969  5017 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I1003 12:39:11.475033  5017 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I1003 12:39:11.475040  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.475046  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.475050  5017 net.cpp:194] Memory required for data: 387440760
I1003 12:39:11.475054  5017 layer_factory.hpp:77] Creating layer conv3_2_0
I1003 12:39:11.475071  5017 net.cpp:128] Creating Layer conv3_2_0
I1003 12:39:11.475091  5017 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I1003 12:39:11.475100  5017 net.cpp:522] conv3_2_0 -> conv3_2_0
I1003 12:39:11.493329  5017 net.cpp:172] Setting up conv3_2_0
I1003 12:39:11.493366  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.493371  5017 net.cpp:194] Memory required for data: 390717560
I1003 12:39:11.493383  5017 layer_factory.hpp:77] Creating layer conv3_2_bn0
I1003 12:39:11.493396  5017 net.cpp:128] Creating Layer conv3_2_bn0
I1003 12:39:11.493402  5017 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I1003 12:39:11.493413  5017 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I1003 12:39:11.493757  5017 net.cpp:172] Setting up conv3_2_bn0
I1003 12:39:11.493770  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.493774  5017 net.cpp:194] Memory required for data: 393994360
I1003 12:39:11.493785  5017 layer_factory.hpp:77] Creating layer conv3_2_scale0
I1003 12:39:11.493795  5017 net.cpp:128] Creating Layer conv3_2_scale0
I1003 12:39:11.493799  5017 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I1003 12:39:11.493805  5017 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I1003 12:39:11.493868  5017 layer_factory.hpp:77] Creating layer conv3_2_scale0
I1003 12:39:11.494078  5017 net.cpp:172] Setting up conv3_2_scale0
I1003 12:39:11.494088  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.494092  5017 net.cpp:194] Memory required for data: 397271160
I1003 12:39:11.494101  5017 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I1003 12:39:11.494107  5017 net.cpp:128] Creating Layer conv3_2_ReLU0
I1003 12:39:11.494112  5017 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I1003 12:39:11.494119  5017 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I1003 12:39:11.494382  5017 net.cpp:172] Setting up conv3_2_ReLU0
I1003 12:39:11.494393  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.494397  5017 net.cpp:194] Memory required for data: 400547960
I1003 12:39:11.494401  5017 layer_factory.hpp:77] Creating layer conv3_Drop2
I1003 12:39:11.494410  5017 net.cpp:128] Creating Layer conv3_Drop2
I1003 12:39:11.494413  5017 net.cpp:558] conv3_Drop2 <- conv3_2_0
I1003 12:39:11.494421  5017 net.cpp:509] conv3_Drop2 -> conv3_2_0 (in-place)
I1003 12:39:11.494453  5017 net.cpp:172] Setting up conv3_Drop2
I1003 12:39:11.494460  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.494464  5017 net.cpp:194] Memory required for data: 403824760
I1003 12:39:11.494468  5017 layer_factory.hpp:77] Creating layer conv3_2_1
I1003 12:39:11.494480  5017 net.cpp:128] Creating Layer conv3_2_1
I1003 12:39:11.494485  5017 net.cpp:558] conv3_2_1 <- conv3_2_0
I1003 12:39:11.494495  5017 net.cpp:522] conv3_2_1 -> conv3_2_1
I1003 12:39:11.512688  5017 net.cpp:172] Setting up conv3_2_1
I1003 12:39:11.512727  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.512732  5017 net.cpp:194] Memory required for data: 407101560
I1003 12:39:11.512747  5017 layer_factory.hpp:77] Creating layer conv3_2bn1
I1003 12:39:11.512758  5017 net.cpp:128] Creating Layer conv3_2bn1
I1003 12:39:11.512763  5017 net.cpp:558] conv3_2bn1 <- conv3_2_1
I1003 12:39:11.512776  5017 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I1003 12:39:11.513121  5017 net.cpp:172] Setting up conv3_2bn1
I1003 12:39:11.513137  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.513142  5017 net.cpp:194] Memory required for data: 410378360
I1003 12:39:11.513152  5017 layer_factory.hpp:77] Creating layer conv3_2_scale1
I1003 12:39:11.513162  5017 net.cpp:128] Creating Layer conv3_2_scale1
I1003 12:39:11.513167  5017 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I1003 12:39:11.513172  5017 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I1003 12:39:11.513236  5017 layer_factory.hpp:77] Creating layer conv3_2_scale1
I1003 12:39:11.513422  5017 net.cpp:172] Setting up conv3_2_scale1
I1003 12:39:11.513433  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.513438  5017 net.cpp:194] Memory required for data: 413655160
I1003 12:39:11.513445  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I1003 12:39:11.513490  5017 net.cpp:128] Creating Layer conv3_Eltwise_2
I1003 12:39:11.513497  5017 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I1003 12:39:11.513502  5017 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I1003 12:39:11.513509  5017 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I1003 12:39:11.513541  5017 net.cpp:172] Setting up conv3_Eltwise_2
I1003 12:39:11.513548  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.513552  5017 net.cpp:194] Memory required for data: 416931960
I1003 12:39:11.513556  5017 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I1003 12:39:11.513563  5017 net.cpp:128] Creating Layer conv3_2ReLU_1
I1003 12:39:11.513567  5017 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I1003 12:39:11.513576  5017 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I1003 12:39:11.514051  5017 net.cpp:172] Setting up conv3_2ReLU_1
I1003 12:39:11.514073  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.514077  5017 net.cpp:194] Memory required for data: 420208760
I1003 12:39:11.514083  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1003 12:39:11.514091  5017 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1003 12:39:11.514096  5017 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I1003 12:39:11.514106  5017 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I1003 12:39:11.514114  5017 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I1003 12:39:11.514183  5017 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I1003 12:39:11.514194  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.514199  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.514202  5017 net.cpp:194] Memory required for data: 426762360
I1003 12:39:11.514206  5017 layer_factory.hpp:77] Creating layer conv3_3_0
I1003 12:39:11.514223  5017 net.cpp:128] Creating Layer conv3_3_0
I1003 12:39:11.514228  5017 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I1003 12:39:11.514237  5017 net.cpp:522] conv3_3_0 -> conv3_3_0
I1003 12:39:11.532584  5017 net.cpp:172] Setting up conv3_3_0
I1003 12:39:11.532622  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.532626  5017 net.cpp:194] Memory required for data: 430039160
I1003 12:39:11.532641  5017 layer_factory.hpp:77] Creating layer conv3_3_bn0
I1003 12:39:11.532655  5017 net.cpp:128] Creating Layer conv3_3_bn0
I1003 12:39:11.532665  5017 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I1003 12:39:11.532675  5017 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I1003 12:39:11.533020  5017 net.cpp:172] Setting up conv3_3_bn0
I1003 12:39:11.533031  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.533036  5017 net.cpp:194] Memory required for data: 433315960
I1003 12:39:11.533046  5017 layer_factory.hpp:77] Creating layer conv3_3_scale0
I1003 12:39:11.533054  5017 net.cpp:128] Creating Layer conv3_3_scale0
I1003 12:39:11.533058  5017 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I1003 12:39:11.533066  5017 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I1003 12:39:11.533131  5017 layer_factory.hpp:77] Creating layer conv3_3_scale0
I1003 12:39:11.533324  5017 net.cpp:172] Setting up conv3_3_scale0
I1003 12:39:11.533335  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.533339  5017 net.cpp:194] Memory required for data: 436592760
I1003 12:39:11.533347  5017 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I1003 12:39:11.533354  5017 net.cpp:128] Creating Layer conv3_3_ReLU0
I1003 12:39:11.533358  5017 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I1003 12:39:11.533366  5017 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I1003 12:39:11.533632  5017 net.cpp:172] Setting up conv3_3_ReLU0
I1003 12:39:11.533646  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.533651  5017 net.cpp:194] Memory required for data: 439869560
I1003 12:39:11.533679  5017 layer_factory.hpp:77] Creating layer conv3_Drop3
I1003 12:39:11.533689  5017 net.cpp:128] Creating Layer conv3_Drop3
I1003 12:39:11.533694  5017 net.cpp:558] conv3_Drop3 <- conv3_3_0
I1003 12:39:11.533701  5017 net.cpp:509] conv3_Drop3 -> conv3_3_0 (in-place)
I1003 12:39:11.533737  5017 net.cpp:172] Setting up conv3_Drop3
I1003 12:39:11.533747  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.533751  5017 net.cpp:194] Memory required for data: 443146360
I1003 12:39:11.533756  5017 layer_factory.hpp:77] Creating layer conv3_3_1
I1003 12:39:11.533771  5017 net.cpp:128] Creating Layer conv3_3_1
I1003 12:39:11.533774  5017 net.cpp:558] conv3_3_1 <- conv3_3_0
I1003 12:39:11.533782  5017 net.cpp:522] conv3_3_1 -> conv3_3_1
I1003 12:39:11.552006  5017 net.cpp:172] Setting up conv3_3_1
I1003 12:39:11.552044  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.552048  5017 net.cpp:194] Memory required for data: 446423160
I1003 12:39:11.552062  5017 layer_factory.hpp:77] Creating layer conv3_3bn1
I1003 12:39:11.552075  5017 net.cpp:128] Creating Layer conv3_3bn1
I1003 12:39:11.552085  5017 net.cpp:558] conv3_3bn1 <- conv3_3_1
I1003 12:39:11.552093  5017 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I1003 12:39:11.552443  5017 net.cpp:172] Setting up conv3_3bn1
I1003 12:39:11.552455  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.552460  5017 net.cpp:194] Memory required for data: 449699960
I1003 12:39:11.552470  5017 layer_factory.hpp:77] Creating layer conv3_3_scale1
I1003 12:39:11.552479  5017 net.cpp:128] Creating Layer conv3_3_scale1
I1003 12:39:11.552482  5017 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I1003 12:39:11.552490  5017 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I1003 12:39:11.552552  5017 layer_factory.hpp:77] Creating layer conv3_3_scale1
I1003 12:39:11.552743  5017 net.cpp:172] Setting up conv3_3_scale1
I1003 12:39:11.552754  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.552759  5017 net.cpp:194] Memory required for data: 452976760
I1003 12:39:11.552767  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I1003 12:39:11.552776  5017 net.cpp:128] Creating Layer conv3_Eltwise_3
I1003 12:39:11.552781  5017 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I1003 12:39:11.552788  5017 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I1003 12:39:11.552795  5017 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I1003 12:39:11.552824  5017 net.cpp:172] Setting up conv3_Eltwise_3
I1003 12:39:11.552839  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.552844  5017 net.cpp:194] Memory required for data: 456253560
I1003 12:39:11.552847  5017 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I1003 12:39:11.552856  5017 net.cpp:128] Creating Layer conv3_3ReLU_1
I1003 12:39:11.552861  5017 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I1003 12:39:11.552867  5017 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I1003 12:39:11.553130  5017 net.cpp:172] Setting up conv3_3ReLU_1
I1003 12:39:11.553148  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.553153  5017 net.cpp:194] Memory required for data: 459530360
I1003 12:39:11.553156  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1003 12:39:11.553166  5017 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1003 12:39:11.553171  5017 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I1003 12:39:11.553177  5017 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I1003 12:39:11.553185  5017 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I1003 12:39:11.553252  5017 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I1003 12:39:11.553259  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.553264  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.553268  5017 net.cpp:194] Memory required for data: 466083960
I1003 12:39:11.553272  5017 layer_factory.hpp:77] Creating layer conv3_4_0
I1003 12:39:11.553303  5017 net.cpp:128] Creating Layer conv3_4_0
I1003 12:39:11.553310  5017 net.cpp:558] conv3_4_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I1003 12:39:11.553320  5017 net.cpp:522] conv3_4_0 -> conv3_4_0
I1003 12:39:11.571703  5017 net.cpp:172] Setting up conv3_4_0
I1003 12:39:11.571745  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.571750  5017 net.cpp:194] Memory required for data: 469360760
I1003 12:39:11.571765  5017 layer_factory.hpp:77] Creating layer conv3_4_bn0
I1003 12:39:11.571776  5017 net.cpp:128] Creating Layer conv3_4_bn0
I1003 12:39:11.571787  5017 net.cpp:558] conv3_4_bn0 <- conv3_4_0
I1003 12:39:11.571796  5017 net.cpp:509] conv3_4_bn0 -> conv3_4_0 (in-place)
I1003 12:39:11.572147  5017 net.cpp:172] Setting up conv3_4_bn0
I1003 12:39:11.572160  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.572165  5017 net.cpp:194] Memory required for data: 472637560
I1003 12:39:11.572175  5017 layer_factory.hpp:77] Creating layer conv3_4_scale0
I1003 12:39:11.572185  5017 net.cpp:128] Creating Layer conv3_4_scale0
I1003 12:39:11.572190  5017 net.cpp:558] conv3_4_scale0 <- conv3_4_0
I1003 12:39:11.572196  5017 net.cpp:509] conv3_4_scale0 -> conv3_4_0 (in-place)
I1003 12:39:11.572259  5017 layer_factory.hpp:77] Creating layer conv3_4_scale0
I1003 12:39:11.572455  5017 net.cpp:172] Setting up conv3_4_scale0
I1003 12:39:11.572466  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.572471  5017 net.cpp:194] Memory required for data: 475914360
I1003 12:39:11.572479  5017 layer_factory.hpp:77] Creating layer conv3_4_ReLU0
I1003 12:39:11.572487  5017 net.cpp:128] Creating Layer conv3_4_ReLU0
I1003 12:39:11.572492  5017 net.cpp:558] conv3_4_ReLU0 <- conv3_4_0
I1003 12:39:11.572497  5017 net.cpp:509] conv3_4_ReLU0 -> conv3_4_0 (in-place)
I1003 12:39:11.572975  5017 net.cpp:172] Setting up conv3_4_ReLU0
I1003 12:39:11.572999  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.573004  5017 net.cpp:194] Memory required for data: 479191160
I1003 12:39:11.573009  5017 layer_factory.hpp:77] Creating layer conv3_Drop4
I1003 12:39:11.573019  5017 net.cpp:128] Creating Layer conv3_Drop4
I1003 12:39:11.573024  5017 net.cpp:558] conv3_Drop4 <- conv3_4_0
I1003 12:39:11.573031  5017 net.cpp:509] conv3_Drop4 -> conv3_4_0 (in-place)
I1003 12:39:11.573070  5017 net.cpp:172] Setting up conv3_Drop4
I1003 12:39:11.573076  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.573081  5017 net.cpp:194] Memory required for data: 482467960
I1003 12:39:11.573084  5017 layer_factory.hpp:77] Creating layer conv3_4_1
I1003 12:39:11.573097  5017 net.cpp:128] Creating Layer conv3_4_1
I1003 12:39:11.573101  5017 net.cpp:558] conv3_4_1 <- conv3_4_0
I1003 12:39:11.573110  5017 net.cpp:522] conv3_4_1 -> conv3_4_1
I1003 12:39:11.591362  5017 net.cpp:172] Setting up conv3_4_1
I1003 12:39:11.591399  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.591404  5017 net.cpp:194] Memory required for data: 485744760
I1003 12:39:11.591418  5017 layer_factory.hpp:77] Creating layer conv3_4bn1
I1003 12:39:11.591431  5017 net.cpp:128] Creating Layer conv3_4bn1
I1003 12:39:11.591437  5017 net.cpp:558] conv3_4bn1 <- conv3_4_1
I1003 12:39:11.591450  5017 net.cpp:509] conv3_4bn1 -> conv3_4_1 (in-place)
I1003 12:39:11.591806  5017 net.cpp:172] Setting up conv3_4bn1
I1003 12:39:11.591820  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.591825  5017 net.cpp:194] Memory required for data: 489021560
I1003 12:39:11.591845  5017 layer_factory.hpp:77] Creating layer conv3_4_scale1
I1003 12:39:11.591855  5017 net.cpp:128] Creating Layer conv3_4_scale1
I1003 12:39:11.591859  5017 net.cpp:558] conv3_4_scale1 <- conv3_4_1
I1003 12:39:11.591866  5017 net.cpp:509] conv3_4_scale1 -> conv3_4_1 (in-place)
I1003 12:39:11.591933  5017 layer_factory.hpp:77] Creating layer conv3_4_scale1
I1003 12:39:11.592121  5017 net.cpp:172] Setting up conv3_4_scale1
I1003 12:39:11.592133  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.592166  5017 net.cpp:194] Memory required for data: 492298360
I1003 12:39:11.592176  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_4
I1003 12:39:11.592187  5017 net.cpp:128] Creating Layer conv3_Eltwise_4
I1003 12:39:11.592193  5017 net.cpp:558] conv3_Eltwise_4 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I1003 12:39:11.592198  5017 net.cpp:558] conv3_Eltwise_4 <- conv3_4_1
I1003 12:39:11.592206  5017 net.cpp:522] conv3_Eltwise_4 -> conv3_Eltwise_4
I1003 12:39:11.592238  5017 net.cpp:172] Setting up conv3_Eltwise_4
I1003 12:39:11.592245  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.592249  5017 net.cpp:194] Memory required for data: 495575160
I1003 12:39:11.592253  5017 layer_factory.hpp:77] Creating layer conv3_4ReLU_1
I1003 12:39:11.592260  5017 net.cpp:128] Creating Layer conv3_4ReLU_1
I1003 12:39:11.592265  5017 net.cpp:558] conv3_4ReLU_1 <- conv3_Eltwise_4
I1003 12:39:11.592270  5017 net.cpp:509] conv3_4ReLU_1 -> conv3_Eltwise_4 (in-place)
I1003 12:39:11.592535  5017 net.cpp:172] Setting up conv3_4ReLU_1
I1003 12:39:11.592553  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.592558  5017 net.cpp:194] Memory required for data: 498851960
I1003 12:39:11.592562  5017 layer_factory.hpp:77] Creating layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I1003 12:39:11.592571  5017 net.cpp:128] Creating Layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I1003 12:39:11.592574  5017 net.cpp:558] conv3_Eltwise_4_conv3_4ReLU_1_0_split <- conv3_Eltwise_4
I1003 12:39:11.592583  5017 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I1003 12:39:11.592592  5017 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I1003 12:39:11.592656  5017 net.cpp:172] Setting up conv3_Eltwise_4_conv3_4ReLU_1_0_split
I1003 12:39:11.592666  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.592672  5017 net.cpp:186] Top shape: 10 320 16 16 (819200)
I1003 12:39:11.592676  5017 net.cpp:194] Memory required for data: 505405560
I1003 12:39:11.592680  5017 layer_factory.hpp:77] Creating layer conv4_1_0
I1003 12:39:11.592694  5017 net.cpp:128] Creating Layer conv4_1_0
I1003 12:39:11.592700  5017 net.cpp:558] conv4_1_0 <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I1003 12:39:11.592707  5017 net.cpp:522] conv4_1_0 -> conv4_1_0
I1003 12:39:11.628914  5017 net.cpp:172] Setting up conv4_1_0
I1003 12:39:11.628970  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.628975  5017 net.cpp:194] Memory required for data: 507043960
I1003 12:39:11.628994  5017 layer_factory.hpp:77] Creating layer conv4_1_bn0
I1003 12:39:11.629011  5017 net.cpp:128] Creating Layer conv4_1_bn0
I1003 12:39:11.629022  5017 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I1003 12:39:11.629034  5017 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I1003 12:39:11.629398  5017 net.cpp:172] Setting up conv4_1_bn0
I1003 12:39:11.629412  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.629417  5017 net.cpp:194] Memory required for data: 508682360
I1003 12:39:11.629428  5017 layer_factory.hpp:77] Creating layer conv4_1_scale0
I1003 12:39:11.629438  5017 net.cpp:128] Creating Layer conv4_1_scale0
I1003 12:39:11.629442  5017 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I1003 12:39:11.629451  5017 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I1003 12:39:11.629513  5017 layer_factory.hpp:77] Creating layer conv4_1_scale0
I1003 12:39:11.629712  5017 net.cpp:172] Setting up conv4_1_scale0
I1003 12:39:11.629724  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.629729  5017 net.cpp:194] Memory required for data: 510320760
I1003 12:39:11.629736  5017 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I1003 12:39:11.629745  5017 net.cpp:128] Creating Layer conv4_1_ReLU0
I1003 12:39:11.629750  5017 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I1003 12:39:11.629756  5017 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I1003 12:39:11.630043  5017 net.cpp:172] Setting up conv4_1_ReLU0
I1003 12:39:11.630060  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.630105  5017 net.cpp:194] Memory required for data: 511959160
I1003 12:39:11.630111  5017 layer_factory.hpp:77] Creating layer conv4_Drop1
I1003 12:39:11.630121  5017 net.cpp:128] Creating Layer conv4_Drop1
I1003 12:39:11.630126  5017 net.cpp:558] conv4_Drop1 <- conv4_1_0
I1003 12:39:11.630136  5017 net.cpp:509] conv4_Drop1 -> conv4_1_0 (in-place)
I1003 12:39:11.630179  5017 net.cpp:172] Setting up conv4_Drop1
I1003 12:39:11.630193  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.630198  5017 net.cpp:194] Memory required for data: 513597560
I1003 12:39:11.630203  5017 layer_factory.hpp:77] Creating layer conv4_1_1
I1003 12:39:11.630216  5017 net.cpp:128] Creating Layer conv4_1_1
I1003 12:39:11.630221  5017 net.cpp:558] conv4_1_1 <- conv4_1_0
I1003 12:39:11.630228  5017 net.cpp:522] conv4_1_1 -> conv4_1_1
I1003 12:39:11.700357  5017 net.cpp:172] Setting up conv4_1_1
I1003 12:39:11.700417  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.700422  5017 net.cpp:194] Memory required for data: 515235960
I1003 12:39:11.700443  5017 layer_factory.hpp:77] Creating layer conv4_1bn1
I1003 12:39:11.700460  5017 net.cpp:128] Creating Layer conv4_1bn1
I1003 12:39:11.700469  5017 net.cpp:558] conv4_1bn1 <- conv4_1_1
I1003 12:39:11.700484  5017 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I1003 12:39:11.700840  5017 net.cpp:172] Setting up conv4_1bn1
I1003 12:39:11.700857  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.700862  5017 net.cpp:194] Memory required for data: 516874360
I1003 12:39:11.700872  5017 layer_factory.hpp:77] Creating layer conv4_1_scale1
I1003 12:39:11.700884  5017 net.cpp:128] Creating Layer conv4_1_scale1
I1003 12:39:11.700889  5017 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I1003 12:39:11.700894  5017 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I1003 12:39:11.700958  5017 layer_factory.hpp:77] Creating layer conv4_1_scale1
I1003 12:39:11.701158  5017 net.cpp:172] Setting up conv4_1_scale1
I1003 12:39:11.701169  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.701174  5017 net.cpp:194] Memory required for data: 518512760
I1003 12:39:11.701181  5017 layer_factory.hpp:77] Creating layer conv4_1_down
I1003 12:39:11.701195  5017 net.cpp:128] Creating Layer conv4_1_down
I1003 12:39:11.701200  5017 net.cpp:558] conv4_1_down <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I1003 12:39:11.701212  5017 net.cpp:522] conv4_1_down -> conv4_1_down
I1003 12:39:11.706046  5017 net.cpp:172] Setting up conv4_1_down
I1003 12:39:11.706073  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.706077  5017 net.cpp:194] Memory required for data: 520151160
I1003 12:39:11.706087  5017 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I1003 12:39:11.706099  5017 net.cpp:128] Creating Layer conv4_1_bn_down
I1003 12:39:11.706104  5017 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I1003 12:39:11.706110  5017 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I1003 12:39:11.706463  5017 net.cpp:172] Setting up conv4_1_bn_down
I1003 12:39:11.706476  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.706480  5017 net.cpp:194] Memory required for data: 521789560
I1003 12:39:11.706490  5017 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I1003 12:39:11.706497  5017 net.cpp:128] Creating Layer conv4_1_scale_down
I1003 12:39:11.706501  5017 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I1003 12:39:11.706509  5017 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I1003 12:39:11.706564  5017 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I1003 12:39:11.706760  5017 net.cpp:172] Setting up conv4_1_scale_down
I1003 12:39:11.706771  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.706775  5017 net.cpp:194] Memory required for data: 523427960
I1003 12:39:11.706784  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I1003 12:39:11.706792  5017 net.cpp:128] Creating Layer conv4_Eltwise_1
I1003 12:39:11.706796  5017 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I1003 12:39:11.706801  5017 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I1003 12:39:11.706851  5017 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I1003 12:39:11.706887  5017 net.cpp:172] Setting up conv4_Eltwise_1
I1003 12:39:11.706900  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.706905  5017 net.cpp:194] Memory required for data: 525066360
I1003 12:39:11.706909  5017 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I1003 12:39:11.706917  5017 net.cpp:128] Creating Layer conv4_1ReLU_1
I1003 12:39:11.706921  5017 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I1003 12:39:11.706926  5017 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I1003 12:39:11.707410  5017 net.cpp:172] Setting up conv4_1ReLU_1
I1003 12:39:11.707432  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.707437  5017 net.cpp:194] Memory required for data: 526704760
I1003 12:39:11.707442  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1003 12:39:11.707453  5017 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1003 12:39:11.707458  5017 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I1003 12:39:11.707468  5017 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I1003 12:39:11.707476  5017 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I1003 12:39:11.707545  5017 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I1003 12:39:11.707562  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.707568  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.707572  5017 net.cpp:194] Memory required for data: 529981560
I1003 12:39:11.707576  5017 layer_factory.hpp:77] Creating layer conv4_2_0
I1003 12:39:11.707588  5017 net.cpp:128] Creating Layer conv4_2_0
I1003 12:39:11.707593  5017 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I1003 12:39:11.707600  5017 net.cpp:522] conv4_2_0 -> conv4_2_0
I1003 12:39:11.777547  5017 net.cpp:172] Setting up conv4_2_0
I1003 12:39:11.777604  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.777609  5017 net.cpp:194] Memory required for data: 531619960
I1003 12:39:11.777626  5017 layer_factory.hpp:77] Creating layer conv4_2_bn0
I1003 12:39:11.777643  5017 net.cpp:128] Creating Layer conv4_2_bn0
I1003 12:39:11.777650  5017 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I1003 12:39:11.777667  5017 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I1003 12:39:11.778046  5017 net.cpp:172] Setting up conv4_2_bn0
I1003 12:39:11.778060  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.778064  5017 net.cpp:194] Memory required for data: 533258360
I1003 12:39:11.778075  5017 layer_factory.hpp:77] Creating layer conv4_2_scale0
I1003 12:39:11.778087  5017 net.cpp:128] Creating Layer conv4_2_scale0
I1003 12:39:11.778092  5017 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I1003 12:39:11.778098  5017 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I1003 12:39:11.778167  5017 layer_factory.hpp:77] Creating layer conv4_2_scale0
I1003 12:39:11.778368  5017 net.cpp:172] Setting up conv4_2_scale0
I1003 12:39:11.778375  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.778379  5017 net.cpp:194] Memory required for data: 534896760
I1003 12:39:11.778388  5017 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I1003 12:39:11.778395  5017 net.cpp:128] Creating Layer conv4_2_ReLU0
I1003 12:39:11.778399  5017 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I1003 12:39:11.778407  5017 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I1003 12:39:11.778669  5017 net.cpp:172] Setting up conv4_2_ReLU0
I1003 12:39:11.778686  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.778690  5017 net.cpp:194] Memory required for data: 536535160
I1003 12:39:11.778694  5017 layer_factory.hpp:77] Creating layer conv4_Drop2
I1003 12:39:11.778703  5017 net.cpp:128] Creating Layer conv4_Drop2
I1003 12:39:11.778708  5017 net.cpp:558] conv4_Drop2 <- conv4_2_0
I1003 12:39:11.778720  5017 net.cpp:509] conv4_Drop2 -> conv4_2_0 (in-place)
I1003 12:39:11.778810  5017 net.cpp:172] Setting up conv4_Drop2
I1003 12:39:11.778820  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.778825  5017 net.cpp:194] Memory required for data: 538173560
I1003 12:39:11.778829  5017 layer_factory.hpp:77] Creating layer conv4_2_1
I1003 12:39:11.778842  5017 net.cpp:128] Creating Layer conv4_2_1
I1003 12:39:11.778847  5017 net.cpp:558] conv4_2_1 <- conv4_2_0
I1003 12:39:11.778856  5017 net.cpp:522] conv4_2_1 -> conv4_2_1
I1003 12:39:11.848891  5017 net.cpp:172] Setting up conv4_2_1
I1003 12:39:11.848950  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.848955  5017 net.cpp:194] Memory required for data: 539811960
I1003 12:39:11.848976  5017 layer_factory.hpp:77] Creating layer conv4_2bn1
I1003 12:39:11.848992  5017 net.cpp:128] Creating Layer conv4_2bn1
I1003 12:39:11.849000  5017 net.cpp:558] conv4_2bn1 <- conv4_2_1
I1003 12:39:11.849014  5017 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I1003 12:39:11.849378  5017 net.cpp:172] Setting up conv4_2bn1
I1003 12:39:11.849396  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.849400  5017 net.cpp:194] Memory required for data: 541450360
I1003 12:39:11.849411  5017 layer_factory.hpp:77] Creating layer conv4_2_scale1
I1003 12:39:11.849422  5017 net.cpp:128] Creating Layer conv4_2_scale1
I1003 12:39:11.849427  5017 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I1003 12:39:11.849433  5017 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I1003 12:39:11.849498  5017 layer_factory.hpp:77] Creating layer conv4_2_scale1
I1003 12:39:11.849704  5017 net.cpp:172] Setting up conv4_2_scale1
I1003 12:39:11.849715  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.849720  5017 net.cpp:194] Memory required for data: 543088760
I1003 12:39:11.849727  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I1003 12:39:11.849738  5017 net.cpp:128] Creating Layer conv4_Eltwise_2
I1003 12:39:11.849745  5017 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I1003 12:39:11.849750  5017 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I1003 12:39:11.849758  5017 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I1003 12:39:11.849795  5017 net.cpp:172] Setting up conv4_Eltwise_2
I1003 12:39:11.849819  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.849824  5017 net.cpp:194] Memory required for data: 544727160
I1003 12:39:11.849828  5017 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I1003 12:39:11.849838  5017 net.cpp:128] Creating Layer conv4_2ReLU_1
I1003 12:39:11.849843  5017 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I1003 12:39:11.849848  5017 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I1003 12:39:11.850138  5017 net.cpp:172] Setting up conv4_2ReLU_1
I1003 12:39:11.850158  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.850162  5017 net.cpp:194] Memory required for data: 546365560
I1003 12:39:11.850167  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1003 12:39:11.850178  5017 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1003 12:39:11.850183  5017 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I1003 12:39:11.850191  5017 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I1003 12:39:11.850201  5017 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I1003 12:39:11.850272  5017 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I1003 12:39:11.850281  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.850286  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.850291  5017 net.cpp:194] Memory required for data: 549642360
I1003 12:39:11.850294  5017 layer_factory.hpp:77] Creating layer conv4_3_0
I1003 12:39:11.850307  5017 net.cpp:128] Creating Layer conv4_3_0
I1003 12:39:11.850312  5017 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I1003 12:39:11.850322  5017 net.cpp:522] conv4_3_0 -> conv4_3_0
I1003 12:39:11.920426  5017 net.cpp:172] Setting up conv4_3_0
I1003 12:39:11.920485  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.920490  5017 net.cpp:194] Memory required for data: 551280760
I1003 12:39:11.920509  5017 layer_factory.hpp:77] Creating layer conv4_3_bn0
I1003 12:39:11.920526  5017 net.cpp:128] Creating Layer conv4_3_bn0
I1003 12:39:11.920539  5017 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I1003 12:39:11.920552  5017 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I1003 12:39:11.920923  5017 net.cpp:172] Setting up conv4_3_bn0
I1003 12:39:11.920938  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.920943  5017 net.cpp:194] Memory required for data: 552919160
I1003 12:39:11.920954  5017 layer_factory.hpp:77] Creating layer conv4_3_scale0
I1003 12:39:11.920977  5017 net.cpp:128] Creating Layer conv4_3_scale0
I1003 12:39:11.920982  5017 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I1003 12:39:11.920987  5017 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I1003 12:39:11.921054  5017 layer_factory.hpp:77] Creating layer conv4_3_scale0
I1003 12:39:11.921267  5017 net.cpp:172] Setting up conv4_3_scale0
I1003 12:39:11.921277  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.921281  5017 net.cpp:194] Memory required for data: 554557560
I1003 12:39:11.921290  5017 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I1003 12:39:11.921298  5017 net.cpp:128] Creating Layer conv4_3_ReLU0
I1003 12:39:11.921303  5017 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I1003 12:39:11.921308  5017 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I1003 12:39:11.921574  5017 net.cpp:172] Setting up conv4_3_ReLU0
I1003 12:39:11.921591  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.921597  5017 net.cpp:194] Memory required for data: 556195960
I1003 12:39:11.921602  5017 layer_factory.hpp:77] Creating layer conv4_Drop3
I1003 12:39:11.921609  5017 net.cpp:128] Creating Layer conv4_Drop3
I1003 12:39:11.921614  5017 net.cpp:558] conv4_Drop3 <- conv4_3_0
I1003 12:39:11.921623  5017 net.cpp:509] conv4_Drop3 -> conv4_3_0 (in-place)
I1003 12:39:11.921665  5017 net.cpp:172] Setting up conv4_Drop3
I1003 12:39:11.921679  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.921682  5017 net.cpp:194] Memory required for data: 557834360
I1003 12:39:11.921686  5017 layer_factory.hpp:77] Creating layer conv4_3_1
I1003 12:39:11.921705  5017 net.cpp:128] Creating Layer conv4_3_1
I1003 12:39:11.921710  5017 net.cpp:558] conv4_3_1 <- conv4_3_0
I1003 12:39:11.921716  5017 net.cpp:522] conv4_3_1 -> conv4_3_1
I1003 12:39:11.991736  5017 net.cpp:172] Setting up conv4_3_1
I1003 12:39:11.991796  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.991801  5017 net.cpp:194] Memory required for data: 559472760
I1003 12:39:11.991817  5017 layer_factory.hpp:77] Creating layer conv4_3bn1
I1003 12:39:11.991833  5017 net.cpp:128] Creating Layer conv4_3bn1
I1003 12:39:11.991842  5017 net.cpp:558] conv4_3bn1 <- conv4_3_1
I1003 12:39:11.991858  5017 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I1003 12:39:11.992224  5017 net.cpp:172] Setting up conv4_3bn1
I1003 12:39:11.992236  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.992241  5017 net.cpp:194] Memory required for data: 561111160
I1003 12:39:11.992252  5017 layer_factory.hpp:77] Creating layer conv4_3_scale1
I1003 12:39:11.992261  5017 net.cpp:128] Creating Layer conv4_3_scale1
I1003 12:39:11.992266  5017 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I1003 12:39:11.992275  5017 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I1003 12:39:11.992341  5017 layer_factory.hpp:77] Creating layer conv4_3_scale1
I1003 12:39:11.992559  5017 net.cpp:172] Setting up conv4_3_scale1
I1003 12:39:11.992570  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.992575  5017 net.cpp:194] Memory required for data: 562749560
I1003 12:39:11.992583  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I1003 12:39:11.992594  5017 net.cpp:128] Creating Layer conv4_Eltwise_3
I1003 12:39:11.992599  5017 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I1003 12:39:11.992647  5017 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I1003 12:39:11.992655  5017 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I1003 12:39:11.992696  5017 net.cpp:172] Setting up conv4_Eltwise_3
I1003 12:39:11.992705  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.992709  5017 net.cpp:194] Memory required for data: 564387960
I1003 12:39:11.992713  5017 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I1003 12:39:11.992722  5017 net.cpp:128] Creating Layer conv4_3ReLU_1
I1003 12:39:11.992725  5017 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I1003 12:39:11.992733  5017 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I1003 12:39:11.993227  5017 net.cpp:172] Setting up conv4_3ReLU_1
I1003 12:39:11.993249  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.993253  5017 net.cpp:194] Memory required for data: 566026360
I1003 12:39:11.993259  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I1003 12:39:11.993270  5017 net.cpp:128] Creating Layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I1003 12:39:11.993275  5017 net.cpp:558] conv4_Eltwise_3_conv4_3ReLU_1_0_split <- conv4_Eltwise_3
I1003 12:39:11.993284  5017 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I1003 12:39:11.993294  5017 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I1003 12:39:11.993371  5017 net.cpp:172] Setting up conv4_Eltwise_3_conv4_3ReLU_1_0_split
I1003 12:39:11.993381  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.993389  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:11.993393  5017 net.cpp:194] Memory required for data: 569303160
I1003 12:39:11.993397  5017 layer_factory.hpp:77] Creating layer conv4_4_0
I1003 12:39:11.993412  5017 net.cpp:128] Creating Layer conv4_4_0
I1003 12:39:11.993417  5017 net.cpp:558] conv4_4_0 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I1003 12:39:11.993423  5017 net.cpp:522] conv4_4_0 -> conv4_4_0
I1003 12:39:12.063536  5017 net.cpp:172] Setting up conv4_4_0
I1003 12:39:12.063593  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:12.063598  5017 net.cpp:194] Memory required for data: 570941560
I1003 12:39:12.063617  5017 layer_factory.hpp:77] Creating layer conv4_4_bn0
I1003 12:39:12.063632  5017 net.cpp:128] Creating Layer conv4_4_bn0
I1003 12:39:12.063639  5017 net.cpp:558] conv4_4_bn0 <- conv4_4_0
I1003 12:39:12.063655  5017 net.cpp:509] conv4_4_bn0 -> conv4_4_0 (in-place)
I1003 12:39:12.064030  5017 net.cpp:172] Setting up conv4_4_bn0
I1003 12:39:12.064049  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:12.064052  5017 net.cpp:194] Memory required for data: 572579960
I1003 12:39:12.064064  5017 layer_factory.hpp:77] Creating layer conv4_4_scale0
I1003 12:39:12.064072  5017 net.cpp:128] Creating Layer conv4_4_scale0
I1003 12:39:12.064076  5017 net.cpp:558] conv4_4_scale0 <- conv4_4_0
I1003 12:39:12.064085  5017 net.cpp:509] conv4_4_scale0 -> conv4_4_0 (in-place)
I1003 12:39:12.064147  5017 layer_factory.hpp:77] Creating layer conv4_4_scale0
I1003 12:39:12.064352  5017 net.cpp:172] Setting up conv4_4_scale0
I1003 12:39:12.064366  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:12.064370  5017 net.cpp:194] Memory required for data: 574218360
I1003 12:39:12.064378  5017 layer_factory.hpp:77] Creating layer conv4_4_ReLU0
I1003 12:39:12.064386  5017 net.cpp:128] Creating Layer conv4_4_ReLU0
I1003 12:39:12.064390  5017 net.cpp:558] conv4_4_ReLU0 <- conv4_4_0
I1003 12:39:12.064395  5017 net.cpp:509] conv4_4_ReLU0 -> conv4_4_0 (in-place)
I1003 12:39:12.064673  5017 net.cpp:172] Setting up conv4_4_ReLU0
I1003 12:39:12.064693  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:12.064700  5017 net.cpp:194] Memory required for data: 575856760
I1003 12:39:12.064704  5017 layer_factory.hpp:77] Creating layer conv4_Drop4
I1003 12:39:12.064715  5017 net.cpp:128] Creating Layer conv4_Drop4
I1003 12:39:12.064720  5017 net.cpp:558] conv4_Drop4 <- conv4_4_0
I1003 12:39:12.064769  5017 net.cpp:509] conv4_Drop4 -> conv4_4_0 (in-place)
I1003 12:39:12.064815  5017 net.cpp:172] Setting up conv4_Drop4
I1003 12:39:12.064826  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:12.064831  5017 net.cpp:194] Memory required for data: 577495160
I1003 12:39:12.064836  5017 layer_factory.hpp:77] Creating layer conv4_4_1
I1003 12:39:12.064848  5017 net.cpp:128] Creating Layer conv4_4_1
I1003 12:39:12.064852  5017 net.cpp:558] conv4_4_1 <- conv4_4_0
I1003 12:39:12.064862  5017 net.cpp:522] conv4_4_1 -> conv4_4_1
I1003 12:39:12.135082  5017 net.cpp:172] Setting up conv4_4_1
I1003 12:39:12.135141  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:12.135146  5017 net.cpp:194] Memory required for data: 579133560
I1003 12:39:12.135164  5017 layer_factory.hpp:77] Creating layer conv4_4bn1
I1003 12:39:12.135181  5017 net.cpp:128] Creating Layer conv4_4bn1
I1003 12:39:12.135190  5017 net.cpp:558] conv4_4bn1 <- conv4_4_1
I1003 12:39:12.135205  5017 net.cpp:509] conv4_4bn1 -> conv4_4_1 (in-place)
I1003 12:39:12.135578  5017 net.cpp:172] Setting up conv4_4bn1
I1003 12:39:12.135591  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:12.135596  5017 net.cpp:194] Memory required for data: 580771960
I1003 12:39:12.135607  5017 layer_factory.hpp:77] Creating layer conv4_4_scale1
I1003 12:39:12.135615  5017 net.cpp:128] Creating Layer conv4_4_scale1
I1003 12:39:12.135620  5017 net.cpp:558] conv4_4_scale1 <- conv4_4_1
I1003 12:39:12.135628  5017 net.cpp:509] conv4_4_scale1 -> conv4_4_1 (in-place)
I1003 12:39:12.135694  5017 layer_factory.hpp:77] Creating layer conv4_4_scale1
I1003 12:39:12.135902  5017 net.cpp:172] Setting up conv4_4_scale1
I1003 12:39:12.135913  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:12.135917  5017 net.cpp:194] Memory required for data: 582410360
I1003 12:39:12.135926  5017 layer_factory.hpp:77] Creating layer conv4_Eltwise_4
I1003 12:39:12.135936  5017 net.cpp:128] Creating Layer conv4_Eltwise_4
I1003 12:39:12.135941  5017 net.cpp:558] conv4_Eltwise_4 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I1003 12:39:12.135946  5017 net.cpp:558] conv4_Eltwise_4 <- conv4_4_1
I1003 12:39:12.135956  5017 net.cpp:522] conv4_Eltwise_4 -> conv4_Eltwise_4
I1003 12:39:12.135991  5017 net.cpp:172] Setting up conv4_Eltwise_4
I1003 12:39:12.136004  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:12.136008  5017 net.cpp:194] Memory required for data: 584048760
I1003 12:39:12.136013  5017 layer_factory.hpp:77] Creating layer conv4_4ReLU_1
I1003 12:39:12.136019  5017 net.cpp:128] Creating Layer conv4_4ReLU_1
I1003 12:39:12.136024  5017 net.cpp:558] conv4_4ReLU_1 <- conv4_Eltwise_4
I1003 12:39:12.136029  5017 net.cpp:509] conv4_4ReLU_1 -> conv4_Eltwise_4 (in-place)
I1003 12:39:12.136301  5017 net.cpp:172] Setting up conv4_4ReLU_1
I1003 12:39:12.136320  5017 net.cpp:186] Top shape: 10 640 8 8 (409600)
I1003 12:39:12.136325  5017 net.cpp:194] Memory required for data: 585687160
I1003 12:39:12.136329  5017 layer_factory.hpp:77] Creating layer Pooling1
I1003 12:39:12.136338  5017 net.cpp:128] Creating Layer Pooling1
I1003 12:39:12.136343  5017 net.cpp:558] Pooling1 <- conv4_Eltwise_4
I1003 12:39:12.136350  5017 net.cpp:522] Pooling1 -> Pooling1
I1003 12:39:12.136878  5017 net.cpp:172] Setting up Pooling1
I1003 12:39:12.136903  5017 net.cpp:186] Top shape: 10 640 1 1 (6400)
I1003 12:39:12.136906  5017 net.cpp:194] Memory required for data: 585712760
I1003 12:39:12.136911  5017 layer_factory.hpp:77] Creating layer fc1
I1003 12:39:12.136922  5017 net.cpp:128] Creating Layer fc1
I1003 12:39:12.136927  5017 net.cpp:558] fc1 <- Pooling1
I1003 12:39:12.136937  5017 net.cpp:522] fc1 -> fc1
I1003 12:39:12.137246  5017 net.cpp:172] Setting up fc1
I1003 12:39:12.137257  5017 net.cpp:186] Top shape: 10 10 (100)
I1003 12:39:12.137262  5017 net.cpp:194] Memory required for data: 585713160
I1003 12:39:12.137271  5017 layer_factory.hpp:77] Creating layer fc1_fc1_0_split
I1003 12:39:12.137282  5017 net.cpp:128] Creating Layer fc1_fc1_0_split
I1003 12:39:12.137326  5017 net.cpp:558] fc1_fc1_0_split <- fc1
I1003 12:39:12.137336  5017 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_0
I1003 12:39:12.137344  5017 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_1
I1003 12:39:12.137408  5017 net.cpp:172] Setting up fc1_fc1_0_split
I1003 12:39:12.137420  5017 net.cpp:186] Top shape: 10 10 (100)
I1003 12:39:12.137425  5017 net.cpp:186] Top shape: 10 10 (100)
I1003 12:39:12.137429  5017 net.cpp:194] Memory required for data: 585713960
I1003 12:39:12.137434  5017 layer_factory.hpp:77] Creating layer Softmax1
I1003 12:39:12.137439  5017 net.cpp:128] Creating Layer Softmax1
I1003 12:39:12.137444  5017 net.cpp:558] Softmax1 <- fc1_fc1_0_split_0
I1003 12:39:12.137449  5017 net.cpp:558] Softmax1 <- label_Data1_1_split_0
I1003 12:39:12.137455  5017 net.cpp:522] Softmax1 -> Softmax1
I1003 12:39:12.137465  5017 layer_factory.hpp:77] Creating layer Softmax1
I1003 12:39:12.137892  5017 net.cpp:172] Setting up Softmax1
I1003 12:39:12.137930  5017 net.cpp:186] Top shape: (1)
I1003 12:39:12.137935  5017 net.cpp:189]     with loss weight 1
I1003 12:39:12.137951  5017 net.cpp:194] Memory required for data: 585713964
I1003 12:39:12.137956  5017 layer_factory.hpp:77] Creating layer prob
I1003 12:39:12.137964  5017 net.cpp:128] Creating Layer prob
I1003 12:39:12.137969  5017 net.cpp:558] prob <- fc1_fc1_0_split_1
I1003 12:39:12.137975  5017 net.cpp:558] prob <- label_Data1_1_split_1
I1003 12:39:12.137981  5017 net.cpp:522] prob -> prob
I1003 12:39:12.137997  5017 net.cpp:172] Setting up prob
I1003 12:39:12.138003  5017 net.cpp:186] Top shape: (1)
I1003 12:39:12.138007  5017 net.cpp:194] Memory required for data: 585713968
I1003 12:39:12.138011  5017 net.cpp:303] prob does not need backward computation.
I1003 12:39:12.138016  5017 net.cpp:301] Softmax1 needs backward computation.
I1003 12:39:12.138021  5017 net.cpp:301] fc1_fc1_0_split needs backward computation.
I1003 12:39:12.138025  5017 net.cpp:301] fc1 needs backward computation.
I1003 12:39:12.138031  5017 net.cpp:301] Pooling1 needs backward computation.
I1003 12:39:12.138034  5017 net.cpp:301] conv4_4ReLU_1 needs backward computation.
I1003 12:39:12.138038  5017 net.cpp:301] conv4_Eltwise_4 needs backward computation.
I1003 12:39:12.138043  5017 net.cpp:301] conv4_4_scale1 needs backward computation.
I1003 12:39:12.138047  5017 net.cpp:301] conv4_4bn1 needs backward computation.
I1003 12:39:12.138051  5017 net.cpp:301] conv4_4_1 needs backward computation.
I1003 12:39:12.138056  5017 net.cpp:301] conv4_Drop4 needs backward computation.
I1003 12:39:12.138059  5017 net.cpp:301] conv4_4_ReLU0 needs backward computation.
I1003 12:39:12.138065  5017 net.cpp:301] conv4_4_scale0 needs backward computation.
I1003 12:39:12.138069  5017 net.cpp:301] conv4_4_bn0 needs backward computation.
I1003 12:39:12.138073  5017 net.cpp:301] conv4_4_0 needs backward computation.
I1003 12:39:12.138078  5017 net.cpp:301] conv4_Eltwise_3_conv4_3ReLU_1_0_split needs backward computation.
I1003 12:39:12.138083  5017 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I1003 12:39:12.138087  5017 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I1003 12:39:12.138092  5017 net.cpp:301] conv4_3_scale1 needs backward computation.
I1003 12:39:12.138098  5017 net.cpp:301] conv4_3bn1 needs backward computation.
I1003 12:39:12.138103  5017 net.cpp:301] conv4_3_1 needs backward computation.
I1003 12:39:12.138106  5017 net.cpp:301] conv4_Drop3 needs backward computation.
I1003 12:39:12.138110  5017 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I1003 12:39:12.138115  5017 net.cpp:301] conv4_3_scale0 needs backward computation.
I1003 12:39:12.138119  5017 net.cpp:301] conv4_3_bn0 needs backward computation.
I1003 12:39:12.138123  5017 net.cpp:301] conv4_3_0 needs backward computation.
I1003 12:39:12.138129  5017 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I1003 12:39:12.138134  5017 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I1003 12:39:12.138139  5017 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I1003 12:39:12.138159  5017 net.cpp:301] conv4_2_scale1 needs backward computation.
I1003 12:39:12.138162  5017 net.cpp:301] conv4_2bn1 needs backward computation.
I1003 12:39:12.138167  5017 net.cpp:301] conv4_2_1 needs backward computation.
I1003 12:39:12.138171  5017 net.cpp:301] conv4_Drop2 needs backward computation.
I1003 12:39:12.138176  5017 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I1003 12:39:12.138180  5017 net.cpp:301] conv4_2_scale0 needs backward computation.
I1003 12:39:12.138185  5017 net.cpp:301] conv4_2_bn0 needs backward computation.
I1003 12:39:12.138188  5017 net.cpp:301] conv4_2_0 needs backward computation.
I1003 12:39:12.138193  5017 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I1003 12:39:12.138198  5017 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I1003 12:39:12.138202  5017 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I1003 12:39:12.138207  5017 net.cpp:301] conv4_1_scale_down needs backward computation.
I1003 12:39:12.138212  5017 net.cpp:301] conv4_1_bn_down needs backward computation.
I1003 12:39:12.138216  5017 net.cpp:301] conv4_1_down needs backward computation.
I1003 12:39:12.138224  5017 net.cpp:301] conv4_1_scale1 needs backward computation.
I1003 12:39:12.138228  5017 net.cpp:301] conv4_1bn1 needs backward computation.
I1003 12:39:12.138233  5017 net.cpp:301] conv4_1_1 needs backward computation.
I1003 12:39:12.138238  5017 net.cpp:301] conv4_Drop1 needs backward computation.
I1003 12:39:12.138242  5017 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I1003 12:39:12.138247  5017 net.cpp:301] conv4_1_scale0 needs backward computation.
I1003 12:39:12.138250  5017 net.cpp:301] conv4_1_bn0 needs backward computation.
I1003 12:39:12.138255  5017 net.cpp:301] conv4_1_0 needs backward computation.
I1003 12:39:12.138259  5017 net.cpp:301] conv3_Eltwise_4_conv3_4ReLU_1_0_split needs backward computation.
I1003 12:39:12.138264  5017 net.cpp:301] conv3_4ReLU_1 needs backward computation.
I1003 12:39:12.138268  5017 net.cpp:301] conv3_Eltwise_4 needs backward computation.
I1003 12:39:12.138274  5017 net.cpp:301] conv3_4_scale1 needs backward computation.
I1003 12:39:12.138278  5017 net.cpp:301] conv3_4bn1 needs backward computation.
I1003 12:39:12.138283  5017 net.cpp:301] conv3_4_1 needs backward computation.
I1003 12:39:12.138286  5017 net.cpp:301] conv3_Drop4 needs backward computation.
I1003 12:39:12.138290  5017 net.cpp:301] conv3_4_ReLU0 needs backward computation.
I1003 12:39:12.138295  5017 net.cpp:301] conv3_4_scale0 needs backward computation.
I1003 12:39:12.138299  5017 net.cpp:301] conv3_4_bn0 needs backward computation.
I1003 12:39:12.138303  5017 net.cpp:301] conv3_4_0 needs backward computation.
I1003 12:39:12.138309  5017 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I1003 12:39:12.138314  5017 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I1003 12:39:12.138317  5017 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I1003 12:39:12.138322  5017 net.cpp:301] conv3_3_scale1 needs backward computation.
I1003 12:39:12.138326  5017 net.cpp:301] conv3_3bn1 needs backward computation.
I1003 12:39:12.138331  5017 net.cpp:301] conv3_3_1 needs backward computation.
I1003 12:39:12.138335  5017 net.cpp:301] conv3_Drop3 needs backward computation.
I1003 12:39:12.138339  5017 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I1003 12:39:12.138344  5017 net.cpp:301] conv3_3_scale0 needs backward computation.
I1003 12:39:12.138348  5017 net.cpp:301] conv3_3_bn0 needs backward computation.
I1003 12:39:12.138352  5017 net.cpp:301] conv3_3_0 needs backward computation.
I1003 12:39:12.138357  5017 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I1003 12:39:12.138362  5017 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I1003 12:39:12.138366  5017 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I1003 12:39:12.138372  5017 net.cpp:301] conv3_2_scale1 needs backward computation.
I1003 12:39:12.138376  5017 net.cpp:301] conv3_2bn1 needs backward computation.
I1003 12:39:12.138387  5017 net.cpp:301] conv3_2_1 needs backward computation.
I1003 12:39:12.138392  5017 net.cpp:301] conv3_Drop2 needs backward computation.
I1003 12:39:12.138397  5017 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I1003 12:39:12.138401  5017 net.cpp:301] conv3_2_scale0 needs backward computation.
I1003 12:39:12.138406  5017 net.cpp:301] conv3_2_bn0 needs backward computation.
I1003 12:39:12.138409  5017 net.cpp:301] conv3_2_0 needs backward computation.
I1003 12:39:12.138414  5017 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I1003 12:39:12.138419  5017 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I1003 12:39:12.138423  5017 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I1003 12:39:12.138428  5017 net.cpp:301] conv3_1_scale_down needs backward computation.
I1003 12:39:12.138433  5017 net.cpp:301] conv3_1_bn_down needs backward computation.
I1003 12:39:12.138437  5017 net.cpp:301] conv3_1_down needs backward computation.
I1003 12:39:12.138442  5017 net.cpp:301] conv3_1_scale1 needs backward computation.
I1003 12:39:12.138447  5017 net.cpp:301] conv3_1bn1 needs backward computation.
I1003 12:39:12.138450  5017 net.cpp:301] conv3_1_1 needs backward computation.
I1003 12:39:12.138454  5017 net.cpp:301] conv3_Drop1 needs backward computation.
I1003 12:39:12.138459  5017 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I1003 12:39:12.138463  5017 net.cpp:301] conv3_1_scale0 needs backward computation.
I1003 12:39:12.138468  5017 net.cpp:301] conv3_1_bn0 needs backward computation.
I1003 12:39:12.138473  5017 net.cpp:301] conv3_1_0 needs backward computation.
I1003 12:39:12.138479  5017 net.cpp:301] conv2_Eltwise_4_conv2_4ReLU_1_0_split needs backward computation.
I1003 12:39:12.138484  5017 net.cpp:301] conv2_4ReLU_1 needs backward computation.
I1003 12:39:12.138489  5017 net.cpp:301] conv2_Eltwise_4 needs backward computation.
I1003 12:39:12.138494  5017 net.cpp:301] conv2_4_scale1 needs backward computation.
I1003 12:39:12.138497  5017 net.cpp:301] conv2_4bn1 needs backward computation.
I1003 12:39:12.138502  5017 net.cpp:301] conv2_4_1 needs backward computation.
I1003 12:39:12.138506  5017 net.cpp:301] conv2_Drop4 needs backward computation.
I1003 12:39:12.138511  5017 net.cpp:301] conv2_4_ReLU0 needs backward computation.
I1003 12:39:12.138515  5017 net.cpp:301] conv2_4_scale0 needs backward computation.
I1003 12:39:12.138520  5017 net.cpp:301] conv2_4_bn0 needs backward computation.
I1003 12:39:12.138523  5017 net.cpp:301] conv2_4_0 needs backward computation.
I1003 12:39:12.138528  5017 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I1003 12:39:12.138533  5017 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I1003 12:39:12.138537  5017 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I1003 12:39:12.138543  5017 net.cpp:301] conv2_3_scale1 needs backward computation.
I1003 12:39:12.138547  5017 net.cpp:301] conv2_3bn1 needs backward computation.
I1003 12:39:12.138551  5017 net.cpp:301] conv2_3_1 needs backward computation.
I1003 12:39:12.138556  5017 net.cpp:301] conv2_Drop3 needs backward computation.
I1003 12:39:12.138561  5017 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I1003 12:39:12.138564  5017 net.cpp:301] conv2_3_scale0 needs backward computation.
I1003 12:39:12.138568  5017 net.cpp:301] conv2_3_bn0 needs backward computation.
I1003 12:39:12.138572  5017 net.cpp:301] conv2_3_0 needs backward computation.
I1003 12:39:12.138577  5017 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I1003 12:39:12.138581  5017 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I1003 12:39:12.138586  5017 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I1003 12:39:12.138592  5017 net.cpp:301] conv2_2_scale1 needs backward computation.
I1003 12:39:12.138595  5017 net.cpp:301] conv2_2bn1 needs backward computation.
I1003 12:39:12.138600  5017 net.cpp:301] conv2_2_1 needs backward computation.
I1003 12:39:12.138604  5017 net.cpp:301] conv2_Drop2 needs backward computation.
I1003 12:39:12.138615  5017 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I1003 12:39:12.138620  5017 net.cpp:301] conv2_2_scale0 needs backward computation.
I1003 12:39:12.138624  5017 net.cpp:301] conv2_2_bn0 needs backward computation.
I1003 12:39:12.138628  5017 net.cpp:301] conv2_2_0 needs backward computation.
I1003 12:39:12.138633  5017 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I1003 12:39:12.138638  5017 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I1003 12:39:12.138643  5017 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I1003 12:39:12.138648  5017 net.cpp:301] conv2_1_scale_down needs backward computation.
I1003 12:39:12.138654  5017 net.cpp:301] conv2_1_bn_down needs backward computation.
I1003 12:39:12.138659  5017 net.cpp:301] conv2_1_down needs backward computation.
I1003 12:39:12.138664  5017 net.cpp:301] conv2_1_scale1 needs backward computation.
I1003 12:39:12.138669  5017 net.cpp:301] conv2_1bn1 needs backward computation.
I1003 12:39:12.138674  5017 net.cpp:301] conv2_1_1 needs backward computation.
I1003 12:39:12.138679  5017 net.cpp:301] conv2_Drop1 needs backward computation.
I1003 12:39:12.138682  5017 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I1003 12:39:12.138686  5017 net.cpp:301] conv2_1_scale0 needs backward computation.
I1003 12:39:12.138690  5017 net.cpp:301] conv2_1_bn0 needs backward computation.
I1003 12:39:12.138695  5017 net.cpp:301] conv2_1_0 needs backward computation.
I1003 12:39:12.138700  5017 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I1003 12:39:12.138705  5017 net.cpp:301] conv1/ReLU needs backward computation.
I1003 12:39:12.138710  5017 net.cpp:301] conv1/scale needs backward computation.
I1003 12:39:12.138713  5017 net.cpp:301] conv1/bn needs backward computation.
I1003 12:39:12.138718  5017 net.cpp:301] conv1 needs backward computation.
I1003 12:39:12.138723  5017 net.cpp:303] label_Data1_1_split does not need backward computation.
I1003 12:39:12.138728  5017 net.cpp:303] Data1 does not need backward computation.
I1003 12:39:12.138732  5017 net.cpp:348] This network produces output Softmax1
I1003 12:39:12.138736  5017 net.cpp:348] This network produces output prob
I1003 12:39:12.138818  5017 net.cpp:363] Network initialization done.
I1003 12:39:12.139329  5017 solver.cpp:110] Solver scaffolding done.
I1003 12:39:12.152765  5017 caffe.cpp:313] Starting Optimization
I1003 12:39:12.152786  5017 solver.cpp:425] Solving WRN-28
I1003 12:39:12.152791  5017 solver.cpp:427] Learning Rate Policy: multistep
I1003 12:39:12.159823  5017 solver.cpp:514] Iteration 0, Testing net (#0)
I1003 12:39:54.073109  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:39:54.239440  5017 solver.cpp:580]     Test net output #0: Softmax1 = 2.30259 (* 1 = 2.30259 loss)
I1003 12:39:54.239465  5017 solver.cpp:580]     Test net output #1: prob = 0
I1003 12:39:55.904431  5017 solver.cpp:357] Iteration 0 (0 iter/s, 43.7526s/100 iters), loss = 3.54284
I1003 12:39:55.904494  5017 solver.cpp:376]     Train net output #0: Softmax1 = 3.4889 (* 1 = 3.4889 loss)
I1003 12:39:55.904527  5017 sgd_solver.cpp:165] Iteration 0, lr = 0.1
I1003 12:42:39.463832  5017 solver.cpp:357] Iteration 100 (0.611386 iter/s, 163.563s/100 iters), loss = 2.23737
I1003 12:42:39.463968  5017 solver.cpp:376]     Train net output #0: Softmax1 = 2.50643 (* 1 = 2.50643 loss)
I1003 12:42:39.463979  5017 sgd_solver.cpp:165] Iteration 100, lr = 0.1
I1003 12:45:23.516304  5017 solver.cpp:357] Iteration 200 (0.609548 iter/s, 164.056s/100 iters), loss = 2.01177
I1003 12:45:23.516396  5017 solver.cpp:376]     Train net output #0: Softmax1 = 2.10141 (* 1 = 2.10141 loss)
I1003 12:45:23.516407  5017 sgd_solver.cpp:165] Iteration 200, lr = 0.1
I1003 12:48:08.151890  5017 solver.cpp:357] Iteration 300 (0.607384 iter/s, 164.64s/100 iters), loss = 2.00689
I1003 12:48:08.152070  5017 solver.cpp:376]     Train net output #0: Softmax1 = 2.06822 (* 1 = 2.06822 loss)
I1003 12:48:08.152081  5017 sgd_solver.cpp:165] Iteration 300, lr = 0.1
I1003 12:50:34.223179  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:50:52.682322  5017 solver.cpp:357] Iteration 400 (0.607772 iter/s, 164.535s/100 iters), loss = 2.00216
I1003 12:50:52.682386  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.86123 (* 1 = 1.86123 loss)
I1003 12:50:52.682396  5017 sgd_solver.cpp:165] Iteration 400, lr = 0.1
I1003 12:53:35.520520  5017 solver.cpp:514] Iteration 500, Testing net (#0)
I1003 12:54:17.720768  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 12:54:17.888104  5017 solver.cpp:580]     Test net output #0: Softmax1 = 2.11997 (* 1 = 2.11997 loss)
I1003 12:54:17.888130  5017 solver.cpp:580]     Test net output #1: prob = 0.1612
I1003 12:54:19.515388  5017 solver.cpp:357] Iteration 500 (0.483468 iter/s, 206.839s/100 iters), loss = 1.71935
I1003 12:54:19.515444  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.80247 (* 1 = 1.80247 loss)
I1003 12:54:19.515453  5017 sgd_solver.cpp:165] Iteration 500, lr = 0.1
I1003 12:57:03.990015  5017 solver.cpp:357] Iteration 600 (0.60798 iter/s, 164.479s/100 iters), loss = 1.65363
I1003 12:57:03.990146  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.97491 (* 1 = 1.97491 loss)
I1003 12:57:03.990156  5017 sgd_solver.cpp:165] Iteration 600, lr = 0.1
I1003 12:59:48.677666  5017 solver.cpp:357] Iteration 700 (0.607194 iter/s, 164.692s/100 iters), loss = 1.60966
I1003 12:59:48.677814  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.6079 (* 1 = 1.6079 loss)
I1003 12:59:48.677825  5017 sgd_solver.cpp:165] Iteration 700, lr = 0.1
I1003 13:01:59.337472  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:02:33.430114  5017 solver.cpp:357] Iteration 800 (0.606956 iter/s, 164.757s/100 iters), loss = 1.69292
I1003 13:02:33.430251  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.68028 (* 1 = 1.68028 loss)
I1003 13:02:33.430261  5017 sgd_solver.cpp:165] Iteration 800, lr = 0.1
I1003 13:05:18.047348  5017 solver.cpp:357] Iteration 900 (0.607455 iter/s, 164.621s/100 iters), loss = 1.59687
I1003 13:05:18.047487  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.53911 (* 1 = 1.53911 loss)
I1003 13:05:18.047498  5017 sgd_solver.cpp:165] Iteration 900, lr = 0.1
I1003 13:08:01.167465  5017 solver.cpp:514] Iteration 1000, Testing net (#0)
I1003 13:08:43.408705  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:08:43.576560  5017 solver.cpp:580]     Test net output #0: Softmax1 = 2.30087 (* 1 = 2.30087 loss)
I1003 13:08:43.576586  5017 solver.cpp:580]     Test net output #1: prob = 0.1858
I1003 13:08:45.202251  5017 solver.cpp:357] Iteration 1000 (0.482719 iter/s, 207.16s/100 iters), loss = 1.4542
I1003 13:08:45.202307  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.28909 (* 1 = 1.28909 loss)
I1003 13:08:45.202317  5017 sgd_solver.cpp:165] Iteration 1000, lr = 0.1
I1003 13:11:29.787153  5017 solver.cpp:357] Iteration 1100 (0.607574 iter/s, 164.589s/100 iters), loss = 1.34182
I1003 13:11:29.787292  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.30979 (* 1 = 1.30979 loss)
I1003 13:11:29.787302  5017 sgd_solver.cpp:165] Iteration 1100, lr = 0.1
I1003 13:13:25.173586  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:14:14.585594  5017 solver.cpp:357] Iteration 1200 (0.606787 iter/s, 164.802s/100 iters), loss = 1.43364
I1003 13:14:14.585731  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.50891 (* 1 = 1.50891 loss)
I1003 13:14:14.585741  5017 sgd_solver.cpp:165] Iteration 1200, lr = 0.1
I1003 13:16:59.413203  5017 solver.cpp:357] Iteration 1300 (0.60668 iter/s, 164.832s/100 iters), loss = 1.19373
I1003 13:16:59.413345  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.21871 (* 1 = 1.21871 loss)
I1003 13:16:59.413355  5017 sgd_solver.cpp:165] Iteration 1300, lr = 0.1
I1003 13:19:44.285259  5017 solver.cpp:357] Iteration 1400 (0.606517 iter/s, 164.876s/100 iters), loss = 1.12856
I1003 13:19:44.285454  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.24717 (* 1 = 1.24717 loss)
I1003 13:19:44.285465  5017 sgd_solver.cpp:165] Iteration 1400, lr = 0.1
I1003 13:22:27.740725  5017 solver.cpp:514] Iteration 1500, Testing net (#0)
I1003 13:23:09.953689  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:23:10.121979  5017 solver.cpp:580]     Test net output #0: Softmax1 = 2.33604 (* 1 = 2.33604 loss)
I1003 13:23:10.122004  5017 solver.cpp:580]     Test net output #1: prob = 0.2202
I1003 13:23:10.122022  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_1500.caffemodel
I1003 13:23:10.977306  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_1500.solverstate
I1003 13:23:11.284186  5017 solver.cpp:593]     Max_acc: 0.2202  with iter: 1500
I1003 13:23:12.914296  5017 solver.cpp:357] Iteration 1500 (0.479303 iter/s, 208.636s/100 iters), loss = 1.22824
I1003 13:23:12.914355  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.1103 (* 1 = 1.1103 loss)
I1003 13:23:12.914366  5017 sgd_solver.cpp:165] Iteration 1500, lr = 0.1
I1003 13:24:52.594815  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:25:57.850556  5017 solver.cpp:357] Iteration 1600 (0.606274 iter/s, 164.942s/100 iters), loss = 1.22687
I1003 13:25:57.850697  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.13385 (* 1 = 1.13385 loss)
I1003 13:25:57.850706  5017 sgd_solver.cpp:165] Iteration 1600, lr = 0.1
I1003 13:28:42.887573  5017 solver.cpp:357] Iteration 1700 (0.605905 iter/s, 165.042s/100 iters), loss = 1.29921
I1003 13:28:42.887722  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.58121 (* 1 = 1.58121 loss)
I1003 13:28:42.887732  5017 sgd_solver.cpp:165] Iteration 1700, lr = 0.1
I1003 13:31:28.060278  5017 solver.cpp:357] Iteration 1800 (0.605409 iter/s, 165.178s/100 iters), loss = 1.22654
I1003 13:31:28.060426  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.2007 (* 1 = 1.2007 loss)
I1003 13:31:28.060437  5017 sgd_solver.cpp:165] Iteration 1800, lr = 0.1
I1003 13:34:13.179651  5017 solver.cpp:357] Iteration 1900 (0.605605 iter/s, 165.124s/100 iters), loss = 1.01633
I1003 13:34:13.179797  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.20414 (* 1 = 1.20414 loss)
I1003 13:34:13.179807  5017 sgd_solver.cpp:165] Iteration 1900, lr = 0.1
I1003 13:35:37.851305  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:36:56.728713  5017 solver.cpp:514] Iteration 2000, Testing net (#0)
I1003 13:37:38.950225  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:37:39.117547  5017 solver.cpp:580]     Test net output #0: Softmax1 = 3.692 (* 1 = 3.692 loss)
I1003 13:37:39.117573  5017 solver.cpp:580]     Test net output #1: prob = 0.1786
I1003 13:37:39.117579  5017 solver.cpp:593]     Max_acc: 0.2202  with iter: 1500
I1003 13:37:40.744359  5017 solver.cpp:357] Iteration 2000 (0.481764 iter/s, 207.57s/100 iters), loss = 0.969154
I1003 13:37:40.744415  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.922299 (* 1 = 0.922299 loss)
I1003 13:37:40.744426  5017 sgd_solver.cpp:165] Iteration 2000, lr = 0.1
I1003 13:40:25.905089  5017 solver.cpp:357] Iteration 2100 (0.605454 iter/s, 165.165s/100 iters), loss = 0.937362
I1003 13:40:25.905226  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.721364 (* 1 = 0.721364 loss)
I1003 13:40:25.905236  5017 sgd_solver.cpp:165] Iteration 2100, lr = 0.1
I1003 13:43:11.208818  5017 solver.cpp:357] Iteration 2200 (0.604931 iter/s, 165.308s/100 iters), loss = 1.14423
I1003 13:43:11.208916  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.17967 (* 1 = 1.17967 loss)
I1003 13:43:11.208927  5017 sgd_solver.cpp:165] Iteration 2200, lr = 0.1
I1003 13:45:56.380875  5017 solver.cpp:357] Iteration 2300 (0.605413 iter/s, 165.176s/100 iters), loss = 0.787974
I1003 13:45:56.381067  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.896333 (* 1 = 0.896333 loss)
I1003 13:45:56.381078  5017 sgd_solver.cpp:165] Iteration 2300, lr = 0.1
I1003 13:47:05.360852  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:48:41.612948  5017 solver.cpp:357] Iteration 2400 (0.605194 iter/s, 165.236s/100 iters), loss = 0.708047
I1003 13:48:41.613090  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.643635 (* 1 = 0.643635 loss)
I1003 13:48:41.613101  5017 sgd_solver.cpp:165] Iteration 2400, lr = 0.1
I1003 13:51:25.206356  5017 solver.cpp:514] Iteration 2500, Testing net (#0)
I1003 13:52:07.448426  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 13:52:07.617681  5017 solver.cpp:580]     Test net output #0: Softmax1 = 3.28233 (* 1 = 3.28233 loss)
I1003 13:52:07.617707  5017 solver.cpp:580]     Test net output #1: prob = 0.1549
I1003 13:52:07.617714  5017 solver.cpp:593]     Max_acc: 0.2202  with iter: 1500
I1003 13:52:09.244463  5017 solver.cpp:357] Iteration 2500 (0.48161 iter/s, 207.637s/100 iters), loss = 0.763477
I1003 13:52:09.244515  5017 solver.cpp:376]     Train net output #0: Softmax1 = 1.00982 (* 1 = 1.00982 loss)
I1003 13:52:09.244526  5017 sgd_solver.cpp:165] Iteration 2500, lr = 0.1
I1003 13:54:54.341141  5017 solver.cpp:357] Iteration 2600 (0.60568 iter/s, 165.104s/100 iters), loss = 0.877091
I1003 13:54:54.341243  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.837923 (* 1 = 0.837923 loss)
I1003 13:54:54.341253  5017 sgd_solver.cpp:165] Iteration 2600, lr = 0.1
I1003 13:57:39.423779  5017 solver.cpp:357] Iteration 2700 (0.605681 iter/s, 165.104s/100 iters), loss = 0.89613
I1003 13:57:39.423920  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.8116 (* 1 = 0.8116 loss)
I1003 13:57:39.423930  5017 sgd_solver.cpp:165] Iteration 2700, lr = 0.1
I1003 13:58:33.080265  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 14:00:24.477177  5017 solver.cpp:357] Iteration 2800 (0.605802 iter/s, 165.07s/100 iters), loss = 0.606554
I1003 14:00:24.477293  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.525802 (* 1 = 0.525802 loss)
I1003 14:00:24.477308  5017 sgd_solver.cpp:165] Iteration 2800, lr = 0.1
I1003 14:03:09.591975  5017 solver.cpp:357] Iteration 2900 (0.605586 iter/s, 165.129s/100 iters), loss = 0.712346
I1003 14:03:09.592118  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.767624 (* 1 = 0.767624 loss)
I1003 14:03:09.592129  5017 sgd_solver.cpp:165] Iteration 2900, lr = 0.1
I1003 14:05:53.028419  5017 solver.cpp:514] Iteration 3000, Testing net (#0)
I1003 14:06:35.253069  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 14:06:35.421380  5017 solver.cpp:580]     Test net output #0: Softmax1 = 2.70563 (* 1 = 2.70563 loss)
I1003 14:06:35.421406  5017 solver.cpp:580]     Test net output #1: prob = 0.2084
I1003 14:06:35.421414  5017 solver.cpp:593]     Max_acc: 0.2202  with iter: 1500
I1003 14:06:37.050235  5017 solver.cpp:357] Iteration 3000 (0.481989 iter/s, 207.474s/100 iters), loss = 0.694834
I1003 14:06:37.050292  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.98221 (* 1 = 0.98221 loss)
I1003 14:06:37.050302  5017 sgd_solver.cpp:165] Iteration 3000, lr = 0.1
I1003 14:09:21.942629  5017 solver.cpp:357] Iteration 3100 (0.606416 iter/s, 164.903s/100 iters), loss = 0.673771
I1003 14:09:21.942764  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.643625 (* 1 = 0.643625 loss)
I1003 14:09:21.942775  5017 sgd_solver.cpp:165] Iteration 3100, lr = 0.1
I1003 14:09:59.960460  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 14:12:07.184830  5017 solver.cpp:357] Iteration 3200 (0.605136 iter/s, 165.252s/100 iters), loss = 0.592211
I1003 14:12:07.185111  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.308579 (* 1 = 0.308579 loss)
I1003 14:12:07.185122  5017 sgd_solver.cpp:165] Iteration 3200, lr = 0.1
I1003 14:14:52.468116  5017 solver.cpp:357] Iteration 3300 (0.604989 iter/s, 165.292s/100 iters), loss = 0.566158
I1003 14:14:52.468304  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.54829 (* 1 = 0.54829 loss)
I1003 14:14:52.468315  5017 sgd_solver.cpp:165] Iteration 3300, lr = 0.1
I1003 14:17:37.409072  5017 solver.cpp:357] Iteration 3400 (0.606246 iter/s, 164.949s/100 iters), loss = 0.571849
I1003 14:17:37.409171  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.608881 (* 1 = 0.608881 loss)
I1003 14:17:37.409181  5017 sgd_solver.cpp:165] Iteration 3400, lr = 0.1
I1003 14:20:20.740620  5017 solver.cpp:514] Iteration 3500, Testing net (#0)
I1003 14:21:02.918131  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 14:21:03.086838  5017 solver.cpp:580]     Test net output #0: Softmax1 = 1.96669 (* 1 = 1.96669 loss)
I1003 14:21:03.086863  5017 solver.cpp:580]     Test net output #1: prob = 0.368
I1003 14:21:03.086876  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_3500.caffemodel
I1003 14:21:03.874419  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_3500.solverstate
I1003 14:21:04.183531  5017 solver.cpp:593]     Max_acc: 0.368  with iter: 3500
I1003 14:21:05.810698  5017 solver.cpp:357] Iteration 3500 (0.479819 iter/s, 208.412s/100 iters), loss = 0.555047
I1003 14:21:05.810750  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.903888 (* 1 = 0.903888 loss)
I1003 14:21:05.810763  5017 sgd_solver.cpp:165] Iteration 3500, lr = 0.1
I1003 14:21:28.403475  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 14:23:50.718559  5017 solver.cpp:357] Iteration 3600 (0.60637 iter/s, 164.916s/100 iters), loss = 0.673676
I1003 14:23:50.718698  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.849423 (* 1 = 0.849423 loss)
I1003 14:23:50.718709  5017 sgd_solver.cpp:165] Iteration 3600, lr = 0.1
I1003 14:26:35.717830  5017 solver.cpp:357] Iteration 3700 (0.606035 iter/s, 165.007s/100 iters), loss = 0.391826
I1003 14:26:35.717972  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.290977 (* 1 = 0.290977 loss)
I1003 14:26:35.717983  5017 sgd_solver.cpp:165] Iteration 3700, lr = 0.1
I1003 14:29:20.553079  5017 solver.cpp:357] Iteration 3800 (0.606638 iter/s, 164.843s/100 iters), loss = 0.454043
I1003 14:29:20.553176  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.644591 (* 1 = 0.644591 loss)
I1003 14:29:20.553189  5017 sgd_solver.cpp:165] Iteration 3800, lr = 0.1
I1003 14:32:05.564740  5017 solver.cpp:357] Iteration 3900 (0.60599 iter/s, 165.019s/100 iters), loss = 0.604751
I1003 14:32:05.564878  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.760938 (* 1 = 0.760938 loss)
I1003 14:32:05.564888  5017 sgd_solver.cpp:165] Iteration 3900, lr = 0.1
I1003 14:32:12.596525  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 14:34:48.936501  5017 solver.cpp:514] Iteration 4000, Testing net (#0)
I1003 14:35:31.147959  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 14:35:31.316244  5017 solver.cpp:580]     Test net output #0: Softmax1 = 1.61367 (* 1 = 1.61367 loss)
I1003 14:35:31.316269  5017 solver.cpp:580]     Test net output #1: prob = 0.4847
I1003 14:35:31.316282  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_4000.caffemodel
I1003 14:35:32.099689  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_4000.solverstate
I1003 14:35:32.402878  5017 solver.cpp:593]     Max_acc: 0.4847  with iter: 4000
I1003 14:35:34.029387  5017 solver.cpp:357] Iteration 4000 (0.479676 iter/s, 208.474s/100 iters), loss = 0.629956
I1003 14:35:34.029445  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.771511 (* 1 = 0.771511 loss)
I1003 14:35:34.029456  5017 sgd_solver.cpp:165] Iteration 4000, lr = 0.1
I1003 14:38:18.824102  5017 solver.cpp:357] Iteration 4100 (0.606788 iter/s, 164.802s/100 iters), loss = 0.591724
I1003 14:38:18.824198  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.657966 (* 1 = 0.657966 loss)
I1003 14:38:18.824208  5017 sgd_solver.cpp:165] Iteration 4100, lr = 0.1
I1003 14:41:03.839906  5017 solver.cpp:357] Iteration 4200 (0.605975 iter/s, 165.023s/100 iters), loss = 0.602854
I1003 14:41:03.840049  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.488995 (* 1 = 0.488995 loss)
I1003 14:41:03.840060  5017 sgd_solver.cpp:165] Iteration 4200, lr = 0.1
I1003 14:43:40.791280  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 14:43:49.018206  5017 solver.cpp:357] Iteration 4300 (0.60538 iter/s, 165.186s/100 iters), loss = 0.511206
I1003 14:43:49.018268  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.353994 (* 1 = 0.353994 loss)
I1003 14:43:49.018277  5017 sgd_solver.cpp:165] Iteration 4300, lr = 0.1
I1003 14:46:34.048709  5017 solver.cpp:357] Iteration 4400 (0.605944 iter/s, 165.032s/100 iters), loss = 0.504597
I1003 14:46:34.048852  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.466899 (* 1 = 0.466899 loss)
I1003 14:46:34.048863  5017 sgd_solver.cpp:165] Iteration 4400, lr = 0.1
I1003 14:49:17.504863  5017 solver.cpp:514] Iteration 4500, Testing net (#0)
I1003 14:49:59.725667  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 14:49:59.892035  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.918201 (* 1 = 0.918201 loss)
I1003 14:49:59.892060  5017 solver.cpp:580]     Test net output #1: prob = 0.6926
I1003 14:49:59.892073  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_4500.caffemodel
I1003 14:50:00.680434  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_4500.solverstate
I1003 14:50:00.985590  5017 solver.cpp:593]     Max_acc: 0.6926  with iter: 4500
I1003 14:50:02.613056  5017 solver.cpp:357] Iteration 4500 (0.47957 iter/s, 208.52s/100 iters), loss = 0.574511
I1003 14:50:02.613116  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.480517 (* 1 = 0.480517 loss)
I1003 14:50:02.613127  5017 sgd_solver.cpp:165] Iteration 4500, lr = 0.1
I1003 14:52:47.427788  5017 solver.cpp:357] Iteration 4600 (0.606804 iter/s, 164.798s/100 iters), loss = 0.49055
I1003 14:52:47.427932  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.407913 (* 1 = 0.407913 loss)
I1003 14:52:47.427943  5017 sgd_solver.cpp:165] Iteration 4600, lr = 0.1
I1003 14:55:08.621407  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 14:55:32.534294  5017 solver.cpp:357] Iteration 4700 (0.605704 iter/s, 165.097s/100 iters), loss = 0.491988
I1003 14:55:32.534358  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.506044 (* 1 = 0.506044 loss)
I1003 14:55:32.534368  5017 sgd_solver.cpp:165] Iteration 4700, lr = 0.1
I1003 14:58:17.646430  5017 solver.cpp:357] Iteration 4800 (0.605667 iter/s, 165.107s/100 iters), loss = 0.454534
I1003 14:58:17.646534  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.499703 (* 1 = 0.499703 loss)
I1003 14:58:17.646545  5017 sgd_solver.cpp:165] Iteration 4800, lr = 0.1
I1003 15:01:03.543512  5017 solver.cpp:357] Iteration 4900 (0.602794 iter/s, 165.894s/100 iters), loss = 0.515889
I1003 15:01:03.543603  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.301681 (* 1 = 0.301681 loss)
I1003 15:01:03.543619  5017 sgd_solver.cpp:165] Iteration 4900, lr = 0.1
I1003 15:03:47.720012  5017 solver.cpp:514] Iteration 5000, Testing net (#0)
I1003 15:04:29.984761  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 15:04:30.152938  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.889117 (* 1 = 0.889117 loss)
I1003 15:04:30.152963  5017 solver.cpp:580]     Test net output #1: prob = 0.7152
I1003 15:04:30.152976  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_5000.caffemodel
I1003 15:04:30.937731  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_5000.solverstate
I1003 15:04:31.247839  5017 solver.cpp:593]     Max_acc: 0.7152  with iter: 5000
I1003 15:04:32.877296  5017 solver.cpp:357] Iteration 5000 (0.477721 iter/s, 209.327s/100 iters), loss = 0.331647
I1003 15:04:32.877357  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.569482 (* 1 = 0.569482 loss)
I1003 15:04:32.877368  5017 sgd_solver.cpp:165] Iteration 5000, lr = 0.1
I1003 15:06:39.372673  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 15:07:18.806366  5017 solver.cpp:357] Iteration 5100 (0.602704 iter/s, 165.919s/100 iters), loss = 0.577286
I1003 15:07:18.806506  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.566559 (* 1 = 0.566559 loss)
I1003 15:07:18.806516  5017 sgd_solver.cpp:165] Iteration 5100, lr = 0.1
I1003 15:10:04.842603  5017 solver.cpp:357] Iteration 5200 (0.602307 iter/s, 166.028s/100 iters), loss = 0.656731
I1003 15:10:04.842741  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.684766 (* 1 = 0.684766 loss)
I1003 15:10:04.842751  5017 sgd_solver.cpp:165] Iteration 5200, lr = 0.1
I1003 15:12:50.929432  5017 solver.cpp:357] Iteration 5300 (0.602117 iter/s, 166.081s/100 iters), loss = 0.506456
I1003 15:12:50.929576  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.671593 (* 1 = 0.671593 loss)
I1003 15:12:50.929586  5017 sgd_solver.cpp:165] Iteration 5300, lr = 0.1
I1003 15:15:36.990124  5017 solver.cpp:357] Iteration 5400 (0.602208 iter/s, 166.056s/100 iters), loss = 0.330346
I1003 15:15:36.990263  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.345207 (* 1 = 0.345207 loss)
I1003 15:15:36.990274  5017 sgd_solver.cpp:165] Iteration 5400, lr = 0.1
I1003 15:17:27.852178  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 15:18:21.380759  5017 solver.cpp:514] Iteration 5500, Testing net (#0)
I1003 15:19:03.604960  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 15:19:03.772836  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.768557 (* 1 = 0.768557 loss)
I1003 15:19:03.772862  5017 solver.cpp:580]     Test net output #1: prob = 0.7558
I1003 15:19:03.772874  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_5500.caffemodel
I1003 15:19:04.554833  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_5500.solverstate
I1003 15:19:04.861299  5017 solver.cpp:593]     Max_acc: 0.7558  with iter: 5500
I1003 15:19:06.490397  5017 solver.cpp:357] Iteration 5500 (0.477338 iter/s, 209.495s/100 iters), loss = 0.375338
I1003 15:19:06.490451  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.33597 (* 1 = 0.33597 loss)
I1003 15:19:06.490463  5017 sgd_solver.cpp:165] Iteration 5500, lr = 0.1
I1003 15:21:52.666533  5017 solver.cpp:357] Iteration 5600 (0.601783 iter/s, 166.173s/100 iters), loss = 0.362226
I1003 15:21:52.666676  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.317977 (* 1 = 0.317977 loss)
I1003 15:21:52.666690  5017 sgd_solver.cpp:165] Iteration 5600, lr = 0.1
I1003 15:24:38.778875  5017 solver.cpp:357] Iteration 5700 (0.602013 iter/s, 166.109s/100 iters), loss = 0.418263
I1003 15:24:38.779012  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.362501 (* 1 = 0.362501 loss)
I1003 15:24:38.779022  5017 sgd_solver.cpp:165] Iteration 5700, lr = 0.1
I1003 15:27:25.176982  5017 solver.cpp:357] Iteration 5800 (0.600978 iter/s, 166.395s/100 iters), loss = 0.309189
I1003 15:27:25.177083  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.321708 (* 1 = 0.321708 loss)
I1003 15:27:25.177093  5017 sgd_solver.cpp:165] Iteration 5800, lr = 0.1
I1003 15:29:00.911088  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 15:30:11.640722  5017 solver.cpp:357] Iteration 5900 (0.60074 iter/s, 166.461s/100 iters), loss = 0.624876
I1003 15:30:11.640822  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.359916 (* 1 = 0.359916 loss)
I1003 15:30:11.640832  5017 sgd_solver.cpp:165] Iteration 5900, lr = 0.1
I1003 15:32:56.128710  5017 solver.cpp:514] Iteration 6000, Testing net (#0)
I1003 15:33:38.371613  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 15:33:38.538964  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.58149 (* 1 = 0.58149 loss)
I1003 15:33:38.538990  5017 solver.cpp:580]     Test net output #1: prob = 0.804
I1003 15:33:38.539002  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_6000.caffemodel
I1003 15:33:39.332278  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_6000.solverstate
I1003 15:33:39.642383  5017 solver.cpp:593]     Max_acc: 0.804  with iter: 6000
I1003 15:33:41.273476  5017 solver.cpp:357] Iteration 6000 (0.477031 iter/s, 209.63s/100 iters), loss = 0.415904
I1003 15:33:41.273533  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.373447 (* 1 = 0.373447 loss)
I1003 15:33:41.273545  5017 sgd_solver.cpp:165] Iteration 6000, lr = 0.1
I1003 15:36:27.407343  5017 solver.cpp:357] Iteration 6100 (0.601932 iter/s, 166.132s/100 iters), loss = 0.443185
I1003 15:36:27.407495  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.380778 (* 1 = 0.380778 loss)
I1003 15:36:27.407505  5017 sgd_solver.cpp:165] Iteration 6100, lr = 0.1
I1003 15:39:13.650758  5017 solver.cpp:357] Iteration 6200 (0.601477 iter/s, 166.257s/100 iters), loss = 0.405946
I1003 15:39:13.650913  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.245137 (* 1 = 0.245137 loss)
I1003 15:39:13.650926  5017 sgd_solver.cpp:165] Iteration 6200, lr = 0.1
I1003 15:40:33.455865  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 15:41:59.704951  5017 solver.cpp:357] Iteration 6300 (0.602145 iter/s, 166.073s/100 iters), loss = 0.295679
I1003 15:41:59.705049  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.161856 (* 1 = 0.161856 loss)
I1003 15:41:59.705062  5017 sgd_solver.cpp:165] Iteration 6300, lr = 0.1
I1003 15:44:45.820596  5017 solver.cpp:357] Iteration 6400 (0.601938 iter/s, 166.13s/100 iters), loss = 0.384411
I1003 15:44:45.820744  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.417957 (* 1 = 0.417957 loss)
I1003 15:44:45.820755  5017 sgd_solver.cpp:165] Iteration 6400, lr = 0.1
I1003 15:47:30.364650  5017 solver.cpp:514] Iteration 6500, Testing net (#0)
I1003 15:48:12.614542  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 15:48:12.782678  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.634183 (* 1 = 0.634183 loss)
I1003 15:48:12.782704  5017 solver.cpp:580]     Test net output #1: prob = 0.787
I1003 15:48:12.782711  5017 solver.cpp:593]     Max_acc: 0.804  with iter: 6000
I1003 15:48:14.410199  5017 solver.cpp:357] Iteration 6500 (0.479379 iter/s, 208.603s/100 iters), loss = 0.355252
I1003 15:48:14.410253  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.418995 (* 1 = 0.418995 loss)
I1003 15:48:14.410264  5017 sgd_solver.cpp:165] Iteration 6500, lr = 0.1
I1003 15:51:00.398772  5017 solver.cpp:357] Iteration 6600 (0.602421 iter/s, 165.997s/100 iters), loss = 0.404159
I1003 15:51:00.398916  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.274304 (* 1 = 0.274304 loss)
I1003 15:51:00.398926  5017 sgd_solver.cpp:165] Iteration 6600, lr = 0.1
I1003 15:52:04.711222  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 15:53:46.362531  5017 solver.cpp:357] Iteration 6700 (0.602517 iter/s, 165.97s/100 iters), loss = 0.478683
I1003 15:53:46.362632  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.445799 (* 1 = 0.445799 loss)
I1003 15:53:46.362641  5017 sgd_solver.cpp:165] Iteration 6700, lr = 0.1
I1003 15:56:32.802080  5017 solver.cpp:357] Iteration 6800 (0.600799 iter/s, 166.445s/100 iters), loss = 0.465432
I1003 15:56:32.802173  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.459033 (* 1 = 0.459033 loss)
I1003 15:56:32.802184  5017 sgd_solver.cpp:165] Iteration 6800, lr = 0.1
I1003 15:59:18.813212  5017 solver.cpp:357] Iteration 6900 (0.602352 iter/s, 166.016s/100 iters), loss = 0.444187
I1003 15:59:18.813333  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.538194 (* 1 = 0.538194 loss)
I1003 15:59:18.813347  5017 sgd_solver.cpp:165] Iteration 6900, lr = 0.1
I1003 16:02:03.202018  5017 solver.cpp:514] Iteration 7000, Testing net (#0)
I1003 16:02:45.427947  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 16:02:45.597059  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.555797 (* 1 = 0.555797 loss)
I1003 16:02:45.597084  5017 solver.cpp:580]     Test net output #1: prob = 0.819101
I1003 16:02:45.597097  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_7000.caffemodel
I1003 16:02:46.387311  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_7000.solverstate
I1003 16:02:46.695189  5017 solver.cpp:593]     Max_acc: 0.819101  with iter: 7000
I1003 16:02:48.322701  5017 solver.cpp:357] Iteration 7000 (0.477294 iter/s, 209.515s/100 iters), loss = 0.367668
I1003 16:02:48.322758  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.273585 (* 1 = 0.273585 loss)
I1003 16:02:48.322769  5017 sgd_solver.cpp:165] Iteration 7000, lr = 0.1
I1003 16:03:36.873767  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 16:05:34.357988  5017 solver.cpp:357] Iteration 7100 (0.602269 iter/s, 166.039s/100 iters), loss = 0.420636
I1003 16:05:34.358124  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.511741 (* 1 = 0.511741 loss)
I1003 16:05:34.358134  5017 sgd_solver.cpp:165] Iteration 7100, lr = 0.1
I1003 16:08:20.314465  5017 solver.cpp:357] Iteration 7200 (0.602556 iter/s, 165.96s/100 iters), loss = 0.5933
I1003 16:08:20.314612  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.439202 (* 1 = 0.439202 loss)
I1003 16:08:20.314622  5017 sgd_solver.cpp:165] Iteration 7200, lr = 0.1
I1003 16:11:06.351702  5017 solver.cpp:357] Iteration 7300 (0.602264 iter/s, 166.04s/100 iters), loss = 0.438476
I1003 16:11:06.351806  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.347862 (* 1 = 0.347862 loss)
I1003 16:11:06.351816  5017 sgd_solver.cpp:165] Iteration 7300, lr = 0.1
I1003 16:13:52.810149  5017 solver.cpp:357] Iteration 7400 (0.600734 iter/s, 166.463s/100 iters), loss = 0.418305
I1003 16:13:52.810288  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.486712 (* 1 = 0.486712 loss)
I1003 16:13:52.810298  5017 sgd_solver.cpp:165] Iteration 7400, lr = 0.1
I1003 16:14:26.127945  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 16:16:37.487071  5017 solver.cpp:514] Iteration 7500, Testing net (#0)
I1003 16:17:19.725857  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 16:17:19.893623  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.790019 (* 1 = 0.790019 loss)
I1003 16:17:19.893649  5017 solver.cpp:580]     Test net output #1: prob = 0.7335
I1003 16:17:19.893656  5017 solver.cpp:593]     Max_acc: 0.819101  with iter: 7000
I1003 16:17:21.542667  5017 solver.cpp:357] Iteration 7500 (0.479069 iter/s, 208.738s/100 iters), loss = 0.332101
I1003 16:17:21.542726  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.236016 (* 1 = 0.236016 loss)
I1003 16:17:21.542737  5017 sgd_solver.cpp:165] Iteration 7500, lr = 0.1
I1003 16:20:07.904872  5017 solver.cpp:357] Iteration 7600 (0.601084 iter/s, 166.366s/100 iters), loss = 0.381148
I1003 16:20:07.905010  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.317624 (* 1 = 0.317624 loss)
I1003 16:20:07.905021  5017 sgd_solver.cpp:165] Iteration 7600, lr = 0.1
I1003 16:22:53.897663  5017 solver.cpp:357] Iteration 7700 (0.602423 iter/s, 165.996s/100 iters), loss = 0.375482
I1003 16:22:53.897807  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.28603 (* 1 = 0.28603 loss)
I1003 16:22:53.897819  5017 sgd_solver.cpp:165] Iteration 7700, lr = 0.1
I1003 16:25:39.817719  5017 solver.cpp:357] Iteration 7800 (0.602688 iter/s, 165.923s/100 iters), loss = 0.388601
I1003 16:25:39.817842  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.389128 (* 1 = 0.389128 loss)
I1003 16:25:39.817853  5017 sgd_solver.cpp:165] Iteration 7800, lr = 0.1
I1003 16:25:57.246457  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 16:28:25.716830  5017 solver.cpp:357] Iteration 7900 (0.602764 iter/s, 165.902s/100 iters), loss = 0.396771
I1003 16:28:25.717023  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.27729 (* 1 = 0.27729 loss)
I1003 16:28:25.717033  5017 sgd_solver.cpp:165] Iteration 7900, lr = 0.1
I1003 16:31:10.121287  5017 solver.cpp:514] Iteration 8000, Testing net (#0)
I1003 16:31:52.346774  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 16:31:52.512802  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.789408 (* 1 = 0.789408 loss)
I1003 16:31:52.512827  5017 solver.cpp:580]     Test net output #1: prob = 0.7694
I1003 16:31:52.512835  5017 solver.cpp:593]     Max_acc: 0.819101  with iter: 7000
I1003 16:31:54.157589  5017 solver.cpp:357] Iteration 8000 (0.479744 iter/s, 208.445s/100 iters), loss = 0.283479
I1003 16:31:54.157644  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.234016 (* 1 = 0.234016 loss)
I1003 16:31:54.157655  5017 sgd_solver.cpp:165] Iteration 8000, lr = 0.1
I1003 16:34:39.991644  5017 solver.cpp:357] Iteration 8100 (0.603001 iter/s, 165.837s/100 iters), loss = 0.371825
I1003 16:34:39.991791  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.516442 (* 1 = 0.516442 loss)
I1003 16:34:39.991801  5017 sgd_solver.cpp:165] Iteration 8100, lr = 0.1
I1003 16:37:26.032683  5017 solver.cpp:357] Iteration 8200 (0.60225 iter/s, 166.044s/100 iters), loss = 0.425707
I1003 16:37:26.032805  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.482748 (* 1 = 0.482748 loss)
I1003 16:37:26.032815  5017 sgd_solver.cpp:165] Iteration 8200, lr = 0.1
I1003 16:37:28.112002  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 16:40:12.194820  5017 solver.cpp:357] Iteration 8300 (0.601811 iter/s, 166.165s/100 iters), loss = 0.491974
I1003 16:40:12.195065  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.659676 (* 1 = 0.659676 loss)
I1003 16:40:12.195076  5017 sgd_solver.cpp:165] Iteration 8300, lr = 0.1
I1003 16:42:58.203310  5017 solver.cpp:357] Iteration 8400 (0.602369 iter/s, 166.011s/100 iters), loss = 0.347735
I1003 16:42:58.203435  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.130505 (* 1 = 0.130505 loss)
I1003 16:42:58.203446  5017 sgd_solver.cpp:165] Iteration 8400, lr = 0.1
I1003 16:45:42.289278  5017 solver.cpp:514] Iteration 8500, Testing net (#0)
I1003 16:46:24.517632  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 16:46:24.685417  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.822343 (* 1 = 0.822343 loss)
I1003 16:46:24.685442  5017 solver.cpp:580]     Test net output #1: prob = 0.7293
I1003 16:46:24.685448  5017 solver.cpp:593]     Max_acc: 0.819101  with iter: 7000
I1003 16:46:26.334126  5017 solver.cpp:357] Iteration 8500 (0.480457 iter/s, 208.135s/100 iters), loss = 0.307361
I1003 16:46:26.334182  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.392871 (* 1 = 0.392871 loss)
I1003 16:46:26.334193  5017 sgd_solver.cpp:165] Iteration 8500, lr = 0.1
I1003 16:48:58.449980  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 16:49:12.088785  5017 solver.cpp:357] Iteration 8600 (0.603281 iter/s, 165.76s/100 iters), loss = 0.371113
I1003 16:49:12.088847  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.193791 (* 1 = 0.193791 loss)
I1003 16:49:12.088858  5017 sgd_solver.cpp:165] Iteration 8600, lr = 0.1
I1003 16:51:57.479054  5017 solver.cpp:357] Iteration 8700 (0.604612 iter/s, 165.395s/100 iters), loss = 0.342162
I1003 16:51:57.479198  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.421634 (* 1 = 0.421634 loss)
I1003 16:51:57.479209  5017 sgd_solver.cpp:165] Iteration 8700, lr = 0.1
I1003 16:54:42.915417  5017 solver.cpp:357] Iteration 8800 (0.604446 iter/s, 165.441s/100 iters), loss = 0.432664
I1003 16:54:42.915539  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.137487 (* 1 = 0.137487 loss)
I1003 16:54:42.915550  5017 sgd_solver.cpp:165] Iteration 8800, lr = 0.1
I1003 16:57:28.407148  5017 solver.cpp:357] Iteration 8900 (0.604245 iter/s, 165.496s/100 iters), loss = 0.433427
I1003 16:57:28.407296  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.498899 (* 1 = 0.498899 loss)
I1003 16:57:28.407307  5017 sgd_solver.cpp:165] Iteration 8900, lr = 0.1
I1003 16:59:44.957587  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 17:00:12.352944  5017 solver.cpp:514] Iteration 9000, Testing net (#0)
I1003 17:00:54.616858  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 17:00:54.783290  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.887571 (* 1 = 0.887571 loss)
I1003 17:00:54.783316  5017 solver.cpp:580]     Test net output #1: prob = 0.7248
I1003 17:00:54.783323  5017 solver.cpp:593]     Max_acc: 0.819101  with iter: 7000
I1003 17:00:56.413738  5017 solver.cpp:357] Iteration 9000 (0.480743 iter/s, 208.011s/100 iters), loss = 0.247063
I1003 17:00:56.413792  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.312957 (* 1 = 0.312957 loss)
I1003 17:00:56.413803  5017 sgd_solver.cpp:165] Iteration 9000, lr = 0.1
I1003 17:03:41.574867  5017 solver.cpp:357] Iteration 9100 (0.605456 iter/s, 165.165s/100 iters), loss = 0.31206
I1003 17:03:41.574966  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.450274 (* 1 = 0.450274 loss)
I1003 17:03:41.574977  5017 sgd_solver.cpp:165] Iteration 9100, lr = 0.1
I1003 17:06:26.401285  5017 solver.cpp:357] Iteration 9200 (0.606686 iter/s, 164.83s/100 iters), loss = 0.349978
I1003 17:06:26.401429  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.395637 (* 1 = 0.395637 loss)
I1003 17:06:26.401440  5017 sgd_solver.cpp:165] Iteration 9200, lr = 0.1
I1003 17:09:11.222555  5017 solver.cpp:357] Iteration 9300 (0.606705 iter/s, 164.825s/100 iters), loss = 0.373814
I1003 17:09:11.222694  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.542927 (* 1 = 0.542927 loss)
I1003 17:09:11.222705  5017 sgd_solver.cpp:165] Iteration 9300, lr = 0.1
I1003 17:11:11.764454  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 17:11:56.300056  5017 solver.cpp:357] Iteration 9400 (0.605764 iter/s, 165.081s/100 iters), loss = 0.543364
I1003 17:11:56.300202  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.319003 (* 1 = 0.319003 loss)
I1003 17:11:56.300212  5017 sgd_solver.cpp:165] Iteration 9400, lr = 0.1
I1003 17:14:39.573096  5017 solver.cpp:514] Iteration 9500, Testing net (#0)
I1003 17:15:21.814090  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 17:15:21.979954  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.721959 (* 1 = 0.721959 loss)
I1003 17:15:21.979979  5017 solver.cpp:580]     Test net output #1: prob = 0.7758
I1003 17:15:21.979985  5017 solver.cpp:593]     Max_acc: 0.819101  with iter: 7000
I1003 17:15:23.605748  5017 solver.cpp:357] Iteration 9500 (0.48237 iter/s, 207.31s/100 iters), loss = 0.339653
I1003 17:15:23.605805  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.38892 (* 1 = 0.38892 loss)
I1003 17:15:23.605815  5017 sgd_solver.cpp:165] Iteration 9500, lr = 0.1
I1003 17:18:08.374601  5017 solver.cpp:357] Iteration 9600 (0.606899 iter/s, 164.772s/100 iters), loss = 0.405408
I1003 17:18:08.374747  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.50254 (* 1 = 0.50254 loss)
I1003 17:18:08.374758  5017 sgd_solver.cpp:165] Iteration 9600, lr = 0.1
I1003 17:20:53.051556  5017 solver.cpp:357] Iteration 9700 (0.607235 iter/s, 164.681s/100 iters), loss = 0.408506
I1003 17:20:53.051695  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.270046 (* 1 = 0.270046 loss)
I1003 17:20:53.051705  5017 sgd_solver.cpp:165] Iteration 9700, lr = 0.1
I1003 17:22:37.985662  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 17:23:37.772727  5017 solver.cpp:357] Iteration 9800 (0.607069 iter/s, 164.726s/100 iters), loss = 0.340291
I1003 17:23:37.772859  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.577982 (* 1 = 0.577982 loss)
I1003 17:23:37.772869  5017 sgd_solver.cpp:165] Iteration 9800, lr = 0.1
I1003 17:26:22.732306  5017 solver.cpp:357] Iteration 9900 (0.606193 iter/s, 164.964s/100 iters), loss = 0.47443
I1003 17:26:22.732496  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.451464 (* 1 = 0.451464 loss)
I1003 17:26:22.732507  5017 sgd_solver.cpp:165] Iteration 9900, lr = 0.1
I1003 17:29:05.753088  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_10000.caffemodel
I1003 17:29:06.540071  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_10000.solverstate
I1003 17:29:06.841563  5017 solver.cpp:514] Iteration 10000, Testing net (#0)
I1003 17:29:49.102437  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 17:29:49.270674  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.533817 (* 1 = 0.533817 loss)
I1003 17:29:49.270700  5017 solver.cpp:580]     Test net output #1: prob = 0.817501
I1003 17:29:49.270706  5017 solver.cpp:593]     Max_acc: 0.819101  with iter: 7000
I1003 17:29:50.901712  5017 solver.cpp:357] Iteration 10000 (0.480366 iter/s, 208.175s/100 iters), loss = 0.281309
I1003 17:29:50.901767  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.144509 (* 1 = 0.144509 loss)
I1003 17:29:50.901783  5017 sgd_solver.cpp:165] Iteration 10000, lr = 0.1
I1003 17:32:35.549530  5017 solver.cpp:357] Iteration 10100 (0.607342 iter/s, 164.652s/100 iters), loss = 0.370489
I1003 17:32:35.549669  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.219347 (* 1 = 0.219347 loss)
I1003 17:32:35.549679  5017 sgd_solver.cpp:165] Iteration 10100, lr = 0.1
I1003 17:34:05.084065  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 17:35:20.404383  5017 solver.cpp:357] Iteration 10200 (0.60658 iter/s, 164.859s/100 iters), loss = 0.385289
I1003 17:35:20.404526  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.346654 (* 1 = 0.346654 loss)
I1003 17:35:20.404536  5017 sgd_solver.cpp:165] Iteration 10200, lr = 0.1
I1003 17:38:05.385042  5017 solver.cpp:357] Iteration 10300 (0.606118 iter/s, 164.984s/100 iters), loss = 0.271674
I1003 17:38:05.385181  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.252727 (* 1 = 0.252727 loss)
I1003 17:38:05.385191  5017 sgd_solver.cpp:165] Iteration 10300, lr = 0.1
I1003 17:40:50.232103  5017 solver.cpp:357] Iteration 10400 (0.60661 iter/s, 164.851s/100 iters), loss = 0.403481
I1003 17:40:50.232250  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.445082 (* 1 = 0.445082 loss)
I1003 17:40:50.232261  5017 sgd_solver.cpp:165] Iteration 10400, lr = 0.1
I1003 17:43:33.496081  5017 solver.cpp:514] Iteration 10500, Testing net (#0)
I1003 17:44:15.717070  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 17:44:15.885249  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.612148 (* 1 = 0.612148 loss)
I1003 17:44:15.885280  5017 solver.cpp:580]     Test net output #1: prob = 0.801501
I1003 17:44:15.885288  5017 solver.cpp:593]     Max_acc: 0.819101  with iter: 7000
I1003 17:44:17.508545  5017 solver.cpp:357] Iteration 10500 (0.482437 iter/s, 207.281s/100 iters), loss = 0.432439
I1003 17:44:17.508602  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.228977 (* 1 = 0.228977 loss)
I1003 17:44:17.508613  5017 sgd_solver.cpp:165] Iteration 10500, lr = 0.1
I1003 17:45:31.399461  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 17:47:01.725241  5017 solver.cpp:357] Iteration 10600 (0.608938 iter/s, 164.22s/100 iters), loss = 0.361269
I1003 17:47:01.725325  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.49478 (* 1 = 0.49478 loss)
I1003 17:47:01.725337  5017 sgd_solver.cpp:165] Iteration 10600, lr = 0.1
I1003 17:49:46.448438  5017 solver.cpp:357] Iteration 10700 (0.607066 iter/s, 164.727s/100 iters), loss = 0.322865
I1003 17:49:46.448580  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.270316 (* 1 = 0.270316 loss)
I1003 17:49:46.448590  5017 sgd_solver.cpp:165] Iteration 10700, lr = 0.1
I1003 17:52:30.966168  5017 solver.cpp:357] Iteration 10800 (0.607824 iter/s, 164.521s/100 iters), loss = 0.391306
I1003 17:52:30.966359  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.456797 (* 1 = 0.456797 loss)
I1003 17:52:30.966370  5017 sgd_solver.cpp:165] Iteration 10800, lr = 0.1
I1003 17:55:15.518772  5017 solver.cpp:357] Iteration 10900 (0.607669 iter/s, 164.563s/100 iters), loss = 0.381165
I1003 17:55:15.518919  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.479255 (* 1 = 0.479255 loss)
I1003 17:55:15.518930  5017 sgd_solver.cpp:165] Iteration 10900, lr = 0.1
I1003 17:56:13.911581  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 17:57:58.394095  5017 solver.cpp:514] Iteration 11000, Testing net (#0)
I1003 17:58:40.613795  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 17:58:40.782479  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.870419 (* 1 = 0.870419 loss)
I1003 17:58:40.782505  5017 solver.cpp:580]     Test net output #1: prob = 0.7159
I1003 17:58:40.782510  5017 solver.cpp:593]     Max_acc: 0.819101  with iter: 7000
I1003 17:58:42.410743  5017 solver.cpp:357] Iteration 11000 (0.483295 iter/s, 206.913s/100 iters), loss = 0.307911
I1003 17:58:42.410796  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.234325 (* 1 = 0.234325 loss)
I1003 17:58:42.410809  5017 sgd_solver.cpp:165] Iteration 11000, lr = 0.1
I1003 18:01:26.626251  5017 solver.cpp:357] Iteration 11100 (0.608907 iter/s, 164.229s/100 iters), loss = 0.334167
I1003 18:01:26.626395  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.357787 (* 1 = 0.357787 loss)
I1003 18:01:26.626405  5017 sgd_solver.cpp:165] Iteration 11100, lr = 0.1
I1003 18:04:11.393925  5017 solver.cpp:357] Iteration 11200 (0.606875 iter/s, 164.779s/100 iters), loss = 0.353804
I1003 18:04:11.394047  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.396271 (* 1 = 0.396271 loss)
I1003 18:04:11.394057  5017 sgd_solver.cpp:165] Iteration 11200, lr = 0.1
I1003 18:06:55.792713  5017 solver.cpp:357] Iteration 11300 (0.608242 iter/s, 164.408s/100 iters), loss = 0.323613
I1003 18:06:55.792857  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.346518 (* 1 = 0.346518 loss)
I1003 18:06:55.792868  5017 sgd_solver.cpp:165] Iteration 11300, lr = 0.1
I1003 18:07:38.985801  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 18:09:40.221524  5017 solver.cpp:357] Iteration 11400 (0.608135 iter/s, 164.437s/100 iters), loss = 0.289519
I1003 18:09:40.221642  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.467703 (* 1 = 0.467703 loss)
I1003 18:09:40.221652  5017 sgd_solver.cpp:165] Iteration 11400, lr = 0.1
I1003 18:12:22.859665  5017 solver.cpp:514] Iteration 11500, Testing net (#0)
I1003 18:13:05.093014  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 18:13:05.260191  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.542554 (* 1 = 0.542554 loss)
I1003 18:13:05.260216  5017 solver.cpp:580]     Test net output #1: prob = 0.822801
I1003 18:13:05.260229  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_11500.caffemodel
I1003 18:13:06.047520  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_11500.solverstate
I1003 18:13:06.354322  5017 solver.cpp:593]     Max_acc: 0.822801  with iter: 11500
I1003 18:13:07.980753  5017 solver.cpp:357] Iteration 11500 (0.481305 iter/s, 207.769s/100 iters), loss = 0.35105
I1003 18:13:07.980834  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.391504 (* 1 = 0.391504 loss)
I1003 18:13:07.980845  5017 sgd_solver.cpp:165] Iteration 11500, lr = 0.1
I1003 18:15:52.121665  5017 solver.cpp:357] Iteration 11600 (0.609207 iter/s, 164.148s/100 iters), loss = 0.323917
I1003 18:15:52.121814  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.373783 (* 1 = 0.373783 loss)
I1003 18:15:52.121824  5017 sgd_solver.cpp:165] Iteration 11600, lr = 0.1
I1003 18:18:36.555836  5017 solver.cpp:357] Iteration 11700 (0.608122 iter/s, 164.441s/100 iters), loss = 0.324632
I1003 18:18:36.555977  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.194245 (* 1 = 0.194245 loss)
I1003 18:18:36.555987  5017 sgd_solver.cpp:165] Iteration 11700, lr = 0.1
I1003 18:19:04.066380  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 18:21:20.906100  5017 solver.cpp:357] Iteration 11800 (0.608434 iter/s, 164.356s/100 iters), loss = 0.355655
I1003 18:21:20.906267  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.471587 (* 1 = 0.471587 loss)
I1003 18:21:20.906282  5017 sgd_solver.cpp:165] Iteration 11800, lr = 0.1
I1003 18:24:05.474066  5017 solver.cpp:357] Iteration 11900 (0.60763 iter/s, 164.574s/100 iters), loss = 0.390982
I1003 18:24:05.474161  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.388357 (* 1 = 0.388357 loss)
I1003 18:24:05.474174  5017 sgd_solver.cpp:165] Iteration 11900, lr = 0.1
I1003 18:26:48.244144  5017 solver.cpp:514] Iteration 12000, Testing net (#0)
I1003 18:27:30.505753  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 18:27:30.673983  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.658233 (* 1 = 0.658233 loss)
I1003 18:27:30.674008  5017 solver.cpp:580]     Test net output #1: prob = 0.7838
I1003 18:27:30.674015  5017 solver.cpp:593]     Max_acc: 0.822801  with iter: 11500
I1003 18:27:32.298178  5017 solver.cpp:357] Iteration 12000 (0.483486 iter/s, 206.831s/100 iters), loss = 0.331396
I1003 18:27:32.298233  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.245189 (* 1 = 0.245189 loss)
I1003 18:27:32.298243  5017 sgd_solver.cpp:165] Iteration 12000, lr = 0.1
I1003 18:30:16.525688  5017 solver.cpp:357] Iteration 12100 (0.608994 iter/s, 164.205s/100 iters), loss = 0.294692
I1003 18:30:16.525830  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.251037 (* 1 = 0.251037 loss)
I1003 18:30:16.525841  5017 sgd_solver.cpp:165] Iteration 12100, lr = 0.1
I1003 18:30:28.870340  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 18:33:01.083534  5017 solver.cpp:357] Iteration 12200 (0.607777 iter/s, 164.534s/100 iters), loss = 0.361641
I1003 18:33:01.083621  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.477354 (* 1 = 0.477354 loss)
I1003 18:33:01.083636  5017 sgd_solver.cpp:165] Iteration 12200, lr = 0.1
I1003 18:35:45.579730  5017 solver.cpp:357] Iteration 12300 (0.607982 iter/s, 164.479s/100 iters), loss = 0.406355
I1003 18:35:45.579869  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.386982 (* 1 = 0.386982 loss)
I1003 18:35:45.579880  5017 sgd_solver.cpp:165] Iteration 12300, lr = 0.1
I1003 18:38:30.203753  5017 solver.cpp:357] Iteration 12400 (0.607493 iter/s, 164.611s/100 iters), loss = 0.491449
I1003 18:38:30.203894  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.814708 (* 1 = 0.814708 loss)
I1003 18:38:30.203905  5017 sgd_solver.cpp:165] Iteration 12400, lr = 0.1
I1003 18:41:11.382233  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 18:41:13.019079  5017 solver.cpp:514] Iteration 12500, Testing net (#0)
I1003 18:41:55.269520  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 18:41:55.438773  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.750646 (* 1 = 0.750646 loss)
I1003 18:41:55.438798  5017 solver.cpp:580]     Test net output #1: prob = 0.756199
I1003 18:41:55.438804  5017 solver.cpp:593]     Max_acc: 0.822801  with iter: 11500
I1003 18:41:57.067406  5017 solver.cpp:357] Iteration 12500 (0.483438 iter/s, 206.852s/100 iters), loss = 0.407852
I1003 18:41:57.067461  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.54568 (* 1 = 0.54568 loss)
I1003 18:41:57.067471  5017 sgd_solver.cpp:165] Iteration 12500, lr = 0.1
I1003 18:44:41.509842  5017 solver.cpp:357] Iteration 12600 (0.60814 iter/s, 164.436s/100 iters), loss = 0.400398
I1003 18:44:41.509995  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.4099 (* 1 = 0.4099 loss)
I1003 18:44:41.510006  5017 sgd_solver.cpp:165] Iteration 12600, lr = 0.1
I1003 18:47:26.092360  5017 solver.cpp:357] Iteration 12700 (0.607617 iter/s, 164.577s/100 iters), loss = 0.520757
I1003 18:47:26.092552  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.31762 (* 1 = 0.31762 loss)
I1003 18:47:26.092567  5017 sgd_solver.cpp:165] Iteration 12700, lr = 0.1
I1003 18:50:10.468802  5017 solver.cpp:357] Iteration 12800 (0.608375 iter/s, 164.372s/100 iters), loss = 0.24477
I1003 18:50:10.468945  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.455103 (* 1 = 0.455103 loss)
I1003 18:50:10.468955  5017 sgd_solver.cpp:165] Iteration 12800, lr = 0.1
I1003 18:52:36.483898  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 18:52:54.963564  5017 solver.cpp:357] Iteration 12900 (0.607934 iter/s, 164.492s/100 iters), loss = 0.362152
I1003 18:52:54.963624  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.375883 (* 1 = 0.375883 loss)
I1003 18:52:54.963635  5017 sgd_solver.cpp:165] Iteration 12900, lr = 0.1
I1003 18:55:37.665511  5017 solver.cpp:514] Iteration 13000, Testing net (#0)
I1003 18:56:19.897284  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 18:56:20.065373  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.552504 (* 1 = 0.552504 loss)
I1003 18:56:20.065398  5017 solver.cpp:580]     Test net output #1: prob = 0.820401
I1003 18:56:20.065404  5017 solver.cpp:593]     Max_acc: 0.822801  with iter: 11500
I1003 18:56:21.694648  5017 solver.cpp:357] Iteration 13000 (0.483727 iter/s, 206.728s/100 iters), loss = 0.283904
I1003 18:56:21.694700  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.385594 (* 1 = 0.385594 loss)
I1003 18:56:21.694712  5017 sgd_solver.cpp:165] Iteration 13000, lr = 0.1
I1003 18:59:06.004514  5017 solver.cpp:357] Iteration 13100 (0.608614 iter/s, 164.308s/100 iters), loss = 0.349211
I1003 18:59:06.004655  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.305812 (* 1 = 0.305812 loss)
I1003 18:59:06.004665  5017 sgd_solver.cpp:165] Iteration 13100, lr = 0.1
I1003 19:01:50.514973  5017 solver.cpp:357] Iteration 13200 (0.607871 iter/s, 164.509s/100 iters), loss = 0.312047
I1003 19:01:50.515095  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.444357 (* 1 = 0.444357 loss)
I1003 19:01:50.515105  5017 sgd_solver.cpp:165] Iteration 13200, lr = 0.1
I1003 19:04:00.925737  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 19:04:35.042239  5017 solver.cpp:357] Iteration 13300 (0.607808 iter/s, 164.526s/100 iters), loss = 0.362148
I1003 19:04:35.042330  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.345544 (* 1 = 0.345544 loss)
I1003 19:04:35.042340  5017 sgd_solver.cpp:165] Iteration 13300, lr = 0.1
I1003 19:07:19.486578  5017 solver.cpp:357] Iteration 13400 (0.608114 iter/s, 164.443s/100 iters), loss = 0.426375
I1003 19:07:19.486694  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.400033 (* 1 = 0.400033 loss)
I1003 19:07:19.486709  5017 sgd_solver.cpp:165] Iteration 13400, lr = 0.1
I1003 19:10:02.427171  5017 solver.cpp:514] Iteration 13500, Testing net (#0)
I1003 19:10:44.670301  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 19:10:44.836859  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.853997 (* 1 = 0.853997 loss)
I1003 19:10:44.836885  5017 solver.cpp:580]     Test net output #1: prob = 0.7396
I1003 19:10:44.836891  5017 solver.cpp:593]     Max_acc: 0.822801  with iter: 11500
I1003 19:10:46.461189  5017 solver.cpp:357] Iteration 13500 (0.483155 iter/s, 206.973s/100 iters), loss = 0.347078
I1003 19:10:46.461246  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.298167 (* 1 = 0.298167 loss)
I1003 19:10:46.461256  5017 sgd_solver.cpp:165] Iteration 13500, lr = 0.1
I1003 19:13:30.883517  5017 solver.cpp:357] Iteration 13600 (0.608194 iter/s, 164.421s/100 iters), loss = 0.225008
I1003 19:13:30.883613  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.183682 (* 1 = 0.183682 loss)
I1003 19:13:30.883623  5017 sgd_solver.cpp:165] Iteration 13600, lr = 0.1
I1003 19:15:26.120520  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 19:16:15.479414  5017 solver.cpp:357] Iteration 13700 (0.607553 iter/s, 164.595s/100 iters), loss = 0.461938
I1003 19:16:15.479590  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.411888 (* 1 = 0.411888 loss)
I1003 19:16:15.479601  5017 sgd_solver.cpp:165] Iteration 13700, lr = 0.1
I1003 19:19:00.076864  5017 solver.cpp:357] Iteration 13800 (0.607547 iter/s, 164.596s/100 iters), loss = 0.303403
I1003 19:19:00.077018  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.406183 (* 1 = 0.406183 loss)
I1003 19:19:00.077028  5017 sgd_solver.cpp:165] Iteration 13800, lr = 0.1
I1003 19:21:44.532492  5017 solver.cpp:357] Iteration 13900 (0.607552 iter/s, 164.595s/100 iters), loss = 0.272772
I1003 19:21:44.532611  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.176402 (* 1 = 0.176402 loss)
I1003 19:21:44.532622  5017 sgd_solver.cpp:165] Iteration 13900, lr = 0.1
I1003 19:24:27.207301  5017 solver.cpp:514] Iteration 14000, Testing net (#0)
I1003 19:25:09.421797  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 19:25:09.589793  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.843997 (* 1 = 0.843997 loss)
I1003 19:25:09.589818  5017 solver.cpp:580]     Test net output #1: prob = 0.7367
I1003 19:25:09.589824  5017 solver.cpp:593]     Max_acc: 0.822801  with iter: 11500
I1003 19:25:11.214105  5017 solver.cpp:357] Iteration 14000 (0.483642 iter/s, 206.764s/100 iters), loss = 0.300711
I1003 19:25:11.214159  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.258549 (* 1 = 0.258549 loss)
I1003 19:25:11.214171  5017 sgd_solver.cpp:165] Iteration 14000, lr = 0.1
I1003 19:26:50.506788  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 19:27:55.406677  5017 solver.cpp:357] Iteration 14100 (0.608903 iter/s, 164.23s/100 iters), loss = 0.338406
I1003 19:27:55.406795  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.160231 (* 1 = 0.160231 loss)
I1003 19:27:55.406810  5017 sgd_solver.cpp:165] Iteration 14100, lr = 0.1
I1003 19:30:39.834142  5017 solver.cpp:357] Iteration 14200 (0.608268 iter/s, 164.401s/100 iters), loss = 0.421814
I1003 19:30:39.834282  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.377092 (* 1 = 0.377092 loss)
I1003 19:30:39.834297  5017 sgd_solver.cpp:165] Iteration 14200, lr = 0.1
I1003 19:33:24.334890  5017 solver.cpp:357] Iteration 14300 (0.607877 iter/s, 164.507s/100 iters), loss = 0.325016
I1003 19:33:24.334985  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.409914 (* 1 = 0.409914 loss)
I1003 19:33:24.334993  5017 sgd_solver.cpp:165] Iteration 14300, lr = 0.1
I1003 19:36:08.712460  5017 solver.cpp:357] Iteration 14400 (0.608298 iter/s, 164.393s/100 iters), loss = 0.331003
I1003 19:36:08.712602  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.272792 (* 1 = 0.272792 loss)
I1003 19:36:08.712612  5017 sgd_solver.cpp:165] Iteration 14400, lr = 0.1
I1003 19:37:33.359611  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 19:38:52.130825  5017 solver.cpp:514] Iteration 14500, Testing net (#0)
I1003 19:39:34.432106  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 19:39:34.601150  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.62427 (* 1 = 0.62427 loss)
I1003 19:39:34.601176  5017 solver.cpp:580]     Test net output #1: prob = 0.7995
I1003 19:39:34.601181  5017 solver.cpp:593]     Max_acc: 0.822801  with iter: 11500
I1003 19:39:36.227262  5017 solver.cpp:357] Iteration 14500 (0.482047 iter/s, 207.449s/100 iters), loss = 0.302824
I1003 19:39:36.227318  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.135057 (* 1 = 0.135057 loss)
I1003 19:39:36.227329  5017 sgd_solver.cpp:165] Iteration 14500, lr = 0.1
I1003 19:42:20.972498  5017 solver.cpp:357] Iteration 14600 (0.607042 iter/s, 164.733s/100 iters), loss = 0.395324
I1003 19:42:20.972637  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.562915 (* 1 = 0.562915 loss)
I1003 19:42:20.972648  5017 sgd_solver.cpp:165] Iteration 14600, lr = 0.1
I1003 19:45:05.415940  5017 solver.cpp:357] Iteration 14700 (0.608112 iter/s, 164.443s/100 iters), loss = 0.370218
I1003 19:45:05.416134  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.291345 (* 1 = 0.291345 loss)
I1003 19:45:05.416146  5017 sgd_solver.cpp:165] Iteration 14700, lr = 0.1
I1003 19:47:50.113363  5017 solver.cpp:357] Iteration 14800 (0.607096 iter/s, 164.719s/100 iters), loss = 0.353359
I1003 19:47:50.113508  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.338074 (* 1 = 0.338074 loss)
I1003 19:47:50.113518  5017 sgd_solver.cpp:165] Iteration 14800, lr = 0.1
I1003 19:48:58.862452  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 19:50:34.746881  5017 solver.cpp:357] Iteration 14900 (0.607358 iter/s, 164.648s/100 iters), loss = 0.271539
I1003 19:50:34.747022  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.310574 (* 1 = 0.310574 loss)
I1003 19:50:34.747035  5017 sgd_solver.cpp:165] Iteration 14900, lr = 0.1
I1003 19:53:18.046257  5017 solver.cpp:514] Iteration 15000, Testing net (#0)
I1003 19:54:00.339483  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 19:54:00.510020  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.668462 (* 1 = 0.668462 loss)
I1003 19:54:00.510046  5017 solver.cpp:580]     Test net output #1: prob = 0.7757
I1003 19:54:00.510052  5017 solver.cpp:593]     Max_acc: 0.822801  with iter: 11500
I1003 19:54:02.137328  5017 solver.cpp:357] Iteration 15000 (0.482153 iter/s, 207.403s/100 iters), loss = 0.437934
I1003 19:54:02.137385  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.526415 (* 1 = 0.526415 loss)
I1003 19:54:02.137398  5017 sgd_solver.cpp:165] Iteration 15000, lr = 0.1
I1003 19:56:46.456579  5017 solver.cpp:357] Iteration 15100 (0.608541 iter/s, 164.327s/100 iters), loss = 0.387005
I1003 19:56:46.456723  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.330037 (* 1 = 0.330037 loss)
I1003 19:56:46.456734  5017 sgd_solver.cpp:165] Iteration 15100, lr = 0.1
I1003 19:59:31.083724  5017 solver.cpp:357] Iteration 15200 (0.607407 iter/s, 164.634s/100 iters), loss = 0.48648
I1003 19:59:31.083843  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.575323 (* 1 = 0.575323 loss)
I1003 19:59:31.083853  5017 sgd_solver.cpp:165] Iteration 15200, lr = 0.1
I1003 20:00:24.545186  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 20:02:15.748217  5017 solver.cpp:357] Iteration 15300 (0.607271 iter/s, 164.671s/100 iters), loss = 0.33293
I1003 20:02:15.748360  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.473279 (* 1 = 0.473279 loss)
I1003 20:02:15.748370  5017 sgd_solver.cpp:165] Iteration 15300, lr = 0.1
I1003 20:05:00.589408  5017 solver.cpp:357] Iteration 15400 (0.606633 iter/s, 164.844s/100 iters), loss = 0.347565
I1003 20:05:00.589550  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.241593 (* 1 = 0.241593 loss)
I1003 20:05:00.589561  5017 sgd_solver.cpp:165] Iteration 15400, lr = 0.1
I1003 20:07:43.606314  5017 solver.cpp:514] Iteration 15500, Testing net (#0)
I1003 20:08:25.885571  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 20:08:26.054066  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.693042 (* 1 = 0.693042 loss)
I1003 20:08:26.054091  5017 solver.cpp:580]     Test net output #1: prob = 0.7712
I1003 20:08:26.054097  5017 solver.cpp:593]     Max_acc: 0.822801  with iter: 11500
I1003 20:08:27.680238  5017 solver.cpp:357] Iteration 15500 (0.482868 iter/s, 207.096s/100 iters), loss = 0.285294
I1003 20:08:27.680291  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.347997 (* 1 = 0.347997 loss)
I1003 20:08:27.680307  5017 sgd_solver.cpp:165] Iteration 15500, lr = 0.1
I1003 20:11:12.055867  5017 solver.cpp:357] Iteration 15600 (0.608346 iter/s, 164.38s/100 iters), loss = 0.291843
I1003 20:11:12.055989  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.431432 (* 1 = 0.431432 loss)
I1003 20:11:12.055999  5017 sgd_solver.cpp:165] Iteration 15600, lr = 0.1
I1003 20:11:49.866935  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 20:13:56.593998  5017 solver.cpp:357] Iteration 15700 (0.607744 iter/s, 164.543s/100 iters), loss = 0.332666
I1003 20:13:56.594190  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.244489 (* 1 = 0.244489 loss)
I1003 20:13:56.594202  5017 sgd_solver.cpp:165] Iteration 15700, lr = 0.1
I1003 20:16:41.129525  5017 solver.cpp:357] Iteration 15800 (0.607753 iter/s, 164.541s/100 iters), loss = 0.287332
I1003 20:16:41.129673  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.285364 (* 1 = 0.285364 loss)
I1003 20:16:41.129684  5017 sgd_solver.cpp:165] Iteration 15800, lr = 0.1
I1003 20:19:25.512042  5017 solver.cpp:357] Iteration 15900 (0.608317 iter/s, 164.388s/100 iters), loss = 0.250741
I1003 20:19:25.512173  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.203329 (* 1 = 0.203329 loss)
I1003 20:19:25.512184  5017 sgd_solver.cpp:165] Iteration 15900, lr = 0.1
I1003 20:22:08.433509  5017 solver.cpp:514] Iteration 16000, Testing net (#0)
I1003 20:22:50.743877  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 20:22:50.911821  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.533486 (* 1 = 0.533486 loss)
I1003 20:22:50.911847  5017 solver.cpp:580]     Test net output #1: prob = 0.824801
I1003 20:22:50.911859  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_16000.caffemodel
I1003 20:22:51.697635  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_16000.solverstate
I1003 20:22:52.009590  5017 solver.cpp:593]     Max_acc: 0.824801  with iter: 16000
I1003 20:22:53.638111  5017 solver.cpp:357] Iteration 16000 (0.480462 iter/s, 208.133s/100 iters), loss = 0.244845
I1003 20:22:53.638167  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.30237 (* 1 = 0.30237 loss)
I1003 20:22:53.638178  5017 sgd_solver.cpp:165] Iteration 16000, lr = 0.1
I1003 20:23:16.197041  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 20:25:37.720124  5017 solver.cpp:357] Iteration 16100 (0.60943 iter/s, 164.088s/100 iters), loss = 0.406809
I1003 20:25:37.720218  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.357465 (* 1 = 0.357465 loss)
I1003 20:25:37.720228  5017 sgd_solver.cpp:165] Iteration 16100, lr = 0.1
I1003 20:28:21.796203  5017 solver.cpp:357] Iteration 16200 (0.609452 iter/s, 164.082s/100 iters), loss = 0.275928
I1003 20:28:21.796344  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.276023 (* 1 = 0.276023 loss)
I1003 20:28:21.796355  5017 sgd_solver.cpp:165] Iteration 16200, lr = 0.1
I1003 20:31:05.894358  5017 solver.cpp:357] Iteration 16300 (0.60937 iter/s, 164.104s/100 iters), loss = 0.253507
I1003 20:31:05.894454  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.407179 (* 1 = 0.407179 loss)
I1003 20:31:05.894464  5017 sgd_solver.cpp:165] Iteration 16300, lr = 0.1
I1003 20:33:49.934279  5017 solver.cpp:357] Iteration 16400 (0.609586 iter/s, 164.046s/100 iters), loss = 0.342377
I1003 20:33:49.934379  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.526445 (* 1 = 0.526445 loss)
I1003 20:33:49.934394  5017 sgd_solver.cpp:165] Iteration 16400, lr = 0.1
I1003 20:33:56.914366  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 20:36:32.405629  5017 solver.cpp:514] Iteration 16500, Testing net (#0)
I1003 20:37:14.655949  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 20:37:14.824643  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.930325 (* 1 = 0.930325 loss)
I1003 20:37:14.824668  5017 solver.cpp:580]     Test net output #1: prob = 0.7236
I1003 20:37:14.824676  5017 solver.cpp:593]     Max_acc: 0.824801  with iter: 16000
I1003 20:37:16.449569  5017 solver.cpp:357] Iteration 16500 (0.484216 iter/s, 206.519s/100 iters), loss = 0.316504
I1003 20:37:16.449622  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.297989 (* 1 = 0.297989 loss)
I1003 20:37:16.449632  5017 sgd_solver.cpp:165] Iteration 16500, lr = 0.1
I1003 20:40:00.501798  5017 solver.cpp:357] Iteration 16600 (0.609568 iter/s, 164.051s/100 iters), loss = 0.326472
I1003 20:40:00.501941  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.521144 (* 1 = 0.521144 loss)
I1003 20:40:00.501956  5017 sgd_solver.cpp:165] Iteration 16600, lr = 0.1
I1003 20:42:44.812378  5017 solver.cpp:357] Iteration 16700 (0.608603 iter/s, 164.311s/100 iters), loss = 0.355553
I1003 20:42:44.812520  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.291425 (* 1 = 0.291425 loss)
I1003 20:42:44.812531  5017 sgd_solver.cpp:165] Iteration 16700, lr = 0.1
I1003 20:45:21.030812  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 20:45:29.246608  5017 solver.cpp:357] Iteration 16800 (0.608141 iter/s, 164.436s/100 iters), loss = 0.282369
I1003 20:45:29.246671  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.208537 (* 1 = 0.208537 loss)
I1003 20:45:29.246685  5017 sgd_solver.cpp:165] Iteration 16800, lr = 0.1
I1003 20:48:13.424218  5017 solver.cpp:357] Iteration 16900 (0.609087 iter/s, 164.18s/100 iters), loss = 0.325966
I1003 20:48:13.424356  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.302362 (* 1 = 0.302362 loss)
I1003 20:48:13.424367  5017 sgd_solver.cpp:165] Iteration 16900, lr = 0.1
I1003 20:50:55.871182  5017 solver.cpp:514] Iteration 17000, Testing net (#0)
I1003 20:51:38.113557  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 20:51:38.281199  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.599409 (* 1 = 0.599409 loss)
I1003 20:51:38.281225  5017 solver.cpp:580]     Test net output #1: prob = 0.8055
I1003 20:51:38.281231  5017 solver.cpp:593]     Max_acc: 0.824801  with iter: 16000
I1003 20:51:39.907456  5017 solver.cpp:357] Iteration 17000 (0.484292 iter/s, 206.487s/100 iters), loss = 0.382178
I1003 20:51:39.907510  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.230415 (* 1 = 0.230415 loss)
I1003 20:51:39.907526  5017 sgd_solver.cpp:165] Iteration 17000, lr = 0.1
I1003 20:54:24.050366  5017 solver.cpp:357] Iteration 17100 (0.609211 iter/s, 164.147s/100 iters), loss = 0.276027
I1003 20:54:24.050504  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.167502 (* 1 = 0.167502 loss)
I1003 20:54:24.050514  5017 sgd_solver.cpp:165] Iteration 17100, lr = 0.1
I1003 20:56:44.532857  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 20:57:08.354338  5017 solver.cpp:357] Iteration 17200 (0.608613 iter/s, 164.308s/100 iters), loss = 0.264132
I1003 20:57:08.354398  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.239249 (* 1 = 0.239249 loss)
I1003 20:57:08.354410  5017 sgd_solver.cpp:165] Iteration 17200, lr = 0.1
I1003 20:59:52.438757  5017 solver.cpp:357] Iteration 17300 (0.609427 iter/s, 164.089s/100 iters), loss = 0.247427
I1003 20:59:52.438854  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.295621 (* 1 = 0.295621 loss)
I1003 20:59:52.438865  5017 sgd_solver.cpp:165] Iteration 17300, lr = 0.1
I1003 21:02:36.433264  5017 solver.cpp:357] Iteration 17400 (0.60976 iter/s, 163.999s/100 iters), loss = 0.277922
I1003 21:02:36.433395  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.243543 (* 1 = 0.243543 loss)
I1003 21:02:36.433406  5017 sgd_solver.cpp:165] Iteration 17400, lr = 0.1
I1003 21:05:19.099014  5017 solver.cpp:514] Iteration 17500, Testing net (#0)
I1003 21:06:01.402699  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 21:06:01.571614  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.707645 (* 1 = 0.707645 loss)
I1003 21:06:01.571640  5017 solver.cpp:580]     Test net output #1: prob = 0.7733
I1003 21:06:01.571645  5017 solver.cpp:593]     Max_acc: 0.824801  with iter: 16000
I1003 21:06:03.195591  5017 solver.cpp:357] Iteration 17500 (0.483634 iter/s, 206.768s/100 iters), loss = 0.198115
I1003 21:06:03.195646  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.1742 (* 1 = 0.1742 loss)
I1003 21:06:03.195655  5017 sgd_solver.cpp:165] Iteration 17500, lr = 0.1
I1003 21:08:08.467290  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 21:08:47.472968  5017 solver.cpp:357] Iteration 17600 (0.608709 iter/s, 164.282s/100 iters), loss = 0.440797
I1003 21:08:47.473165  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.497211 (* 1 = 0.497211 loss)
I1003 21:08:47.473177  5017 sgd_solver.cpp:165] Iteration 17600, lr = 0.1
I1003 21:11:31.801059  5017 solver.cpp:357] Iteration 17700 (0.60856 iter/s, 164.322s/100 iters), loss = 0.343223
I1003 21:11:31.801198  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.321635 (* 1 = 0.321635 loss)
I1003 21:11:31.801209  5017 sgd_solver.cpp:165] Iteration 17700, lr = 0.1
I1003 21:14:16.117218  5017 solver.cpp:357] Iteration 17800 (0.608642 iter/s, 164.3s/100 iters), loss = 0.343193
I1003 21:14:16.117352  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.442848 (* 1 = 0.442848 loss)
I1003 21:14:16.117362  5017 sgd_solver.cpp:165] Iteration 17800, lr = 0.1
I1003 21:17:00.343766  5017 solver.cpp:357] Iteration 17900 (0.608957 iter/s, 164.215s/100 iters), loss = 0.291137
I1003 21:17:00.343914  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.431556 (* 1 = 0.431556 loss)
I1003 21:17:00.343924  5017 sgd_solver.cpp:165] Iteration 17900, lr = 0.1
I1003 21:18:49.987597  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 21:19:42.993134  5017 solver.cpp:514] Iteration 18000, Testing net (#0)
I1003 21:20:25.266182  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 21:20:25.434521  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.710149 (* 1 = 0.710149 loss)
I1003 21:20:25.434546  5017 solver.cpp:580]     Test net output #1: prob = 0.7623
I1003 21:20:25.434552  5017 solver.cpp:593]     Max_acc: 0.824801  with iter: 16000
I1003 21:20:27.063423  5017 solver.cpp:357] Iteration 18000 (0.48377 iter/s, 206.71s/100 iters), loss = 0.201949
I1003 21:20:27.063478  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.15964 (* 1 = 0.15964 loss)
I1003 21:20:27.063488  5017 sgd_solver.cpp:165] Iteration 18000, lr = 0.1
I1003 21:23:11.327484  5017 solver.cpp:357] Iteration 18100 (0.608795 iter/s, 164.259s/100 iters), loss = 0.293775
I1003 21:23:11.327621  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.319164 (* 1 = 0.319164 loss)
I1003 21:23:11.327631  5017 sgd_solver.cpp:165] Iteration 18100, lr = 0.1
I1003 21:25:55.698310  5017 solver.cpp:357] Iteration 18200 (0.608394 iter/s, 164.367s/100 iters), loss = 0.39235
I1003 21:25:55.698405  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.484423 (* 1 = 0.484423 loss)
I1003 21:25:55.698417  5017 sgd_solver.cpp:165] Iteration 18200, lr = 0.1
I1003 21:28:40.099100  5017 solver.cpp:357] Iteration 18300 (0.608278 iter/s, 164.398s/100 iters), loss = 0.286229
I1003 21:28:40.099241  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.233801 (* 1 = 0.233801 loss)
I1003 21:28:40.099251  5017 sgd_solver.cpp:165] Iteration 18300, lr = 0.1
I1003 21:30:14.615638  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 21:31:24.449666  5017 solver.cpp:357] Iteration 18400 (0.608461 iter/s, 164.349s/100 iters), loss = 0.45772
I1003 21:31:24.449762  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.166501 (* 1 = 0.166501 loss)
I1003 21:31:24.449777  5017 sgd_solver.cpp:165] Iteration 18400, lr = 0.1
I1003 21:34:07.166353  5017 solver.cpp:514] Iteration 18500, Testing net (#0)
I1003 21:34:49.466691  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 21:34:49.635581  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.596738 (* 1 = 0.596738 loss)
I1003 21:34:49.635607  5017 solver.cpp:580]     Test net output #1: prob = 0.806901
I1003 21:34:49.635613  5017 solver.cpp:593]     Max_acc: 0.824801  with iter: 16000
I1003 21:34:51.264684  5017 solver.cpp:357] Iteration 18500 (0.483526 iter/s, 206.814s/100 iters), loss = 0.388167
I1003 21:34:51.264740  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.364914 (* 1 = 0.364914 loss)
I1003 21:34:51.264751  5017 sgd_solver.cpp:165] Iteration 18500, lr = 0.1
I1003 21:37:35.555047  5017 solver.cpp:357] Iteration 18600 (0.60868 iter/s, 164.29s/100 iters), loss = 0.37098
I1003 21:37:35.555143  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.211481 (* 1 = 0.211481 loss)
I1003 21:37:35.555153  5017 sgd_solver.cpp:165] Iteration 18600, lr = 0.1
I1003 21:40:19.878932  5017 solver.cpp:357] Iteration 18700 (0.608555 iter/s, 164.324s/100 iters), loss = 0.322646
I1003 21:40:19.879122  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.252029 (* 1 = 0.252029 loss)
I1003 21:40:19.879132  5017 sgd_solver.cpp:165] Iteration 18700, lr = 0.1
I1003 21:41:38.926651  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 21:43:04.380676  5017 solver.cpp:357] Iteration 18800 (0.607896 iter/s, 164.502s/100 iters), loss = 0.201969
I1003 21:43:04.380770  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.105493 (* 1 = 0.105493 loss)
I1003 21:43:04.380780  5017 sgd_solver.cpp:165] Iteration 18800, lr = 0.1
I1003 21:45:48.746794  5017 solver.cpp:357] Iteration 18900 (0.608346 iter/s, 164.38s/100 iters), loss = 0.330181
I1003 21:45:48.746940  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.375953 (* 1 = 0.375953 loss)
I1003 21:45:48.746950  5017 sgd_solver.cpp:165] Iteration 18900, lr = 0.1
I1003 21:48:31.441819  5017 solver.cpp:514] Iteration 19000, Testing net (#0)
I1003 21:49:13.715807  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 21:49:13.884475  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.815131 (* 1 = 0.815131 loss)
I1003 21:49:13.884500  5017 solver.cpp:580]     Test net output #1: prob = 0.7583
I1003 21:49:13.884506  5017 solver.cpp:593]     Max_acc: 0.824801  with iter: 16000
I1003 21:49:15.516152  5017 solver.cpp:357] Iteration 19000 (0.483561 iter/s, 206.799s/100 iters), loss = 0.248722
I1003 21:49:15.516206  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.366862 (* 1 = 0.366862 loss)
I1003 21:49:15.516217  5017 sgd_solver.cpp:165] Iteration 19000, lr = 0.1
I1003 21:51:59.790740  5017 solver.cpp:357] Iteration 19100 (0.608671 iter/s, 164.292s/100 iters), loss = 0.256563
I1003 21:51:59.790838  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.258762 (* 1 = 0.258762 loss)
I1003 21:51:59.790848  5017 sgd_solver.cpp:165] Iteration 19100, lr = 0.1
I1003 21:53:03.454839  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 21:54:44.096839  5017 solver.cpp:357] Iteration 19200 (0.608568 iter/s, 164.32s/100 iters), loss = 0.421831
I1003 21:54:44.096958  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.657131 (* 1 = 0.657131 loss)
I1003 21:54:44.096968  5017 sgd_solver.cpp:165] Iteration 19200, lr = 0.1
I1003 21:57:28.406389  5017 solver.cpp:357] Iteration 19300 (0.608565 iter/s, 164.321s/100 iters), loss = 0.319
I1003 21:57:28.406528  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.252014 (* 1 = 0.252014 loss)
I1003 21:57:28.406555  5017 sgd_solver.cpp:165] Iteration 19300, lr = 0.1
I1003 22:00:12.707391  5017 solver.cpp:357] Iteration 19400 (0.608604 iter/s, 164.31s/100 iters), loss = 0.329641
I1003 22:00:12.707489  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.318849 (* 1 = 0.318849 loss)
I1003 22:00:12.707501  5017 sgd_solver.cpp:165] Iteration 19400, lr = 0.1
I1003 22:02:55.237112  5017 solver.cpp:514] Iteration 19500, Testing net (#0)
I1003 22:03:37.528156  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 22:03:37.697036  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.634116 (* 1 = 0.634116 loss)
I1003 22:03:37.697062  5017 solver.cpp:580]     Test net output #1: prob = 0.8095
I1003 22:03:37.697069  5017 solver.cpp:593]     Max_acc: 0.824801  with iter: 16000
I1003 22:03:39.323487  5017 solver.cpp:357] Iteration 19500 (0.483966 iter/s, 206.626s/100 iters), loss = 0.279501
I1003 22:03:39.323539  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.240139 (* 1 = 0.240139 loss)
I1003 22:03:39.323549  5017 sgd_solver.cpp:165] Iteration 19500, lr = 0.1
I1003 22:04:27.390321  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 22:06:23.599566  5017 solver.cpp:357] Iteration 19600 (0.608707 iter/s, 164.283s/100 iters), loss = 0.377982
I1003 22:06:23.604760  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.268366 (* 1 = 0.268366 loss)
I1003 22:06:23.604775  5017 sgd_solver.cpp:165] Iteration 19600, lr = 0.1
I1003 22:09:07.926529  5017 solver.cpp:357] Iteration 19700 (0.60854 iter/s, 164.328s/100 iters), loss = 0.243773
I1003 22:09:07.926626  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.204644 (* 1 = 0.204644 loss)
I1003 22:09:07.926637  5017 sgd_solver.cpp:165] Iteration 19700, lr = 0.1
I1003 22:11:52.172719  5017 solver.cpp:357] Iteration 19800 (0.608822 iter/s, 164.252s/100 iters), loss = 0.340506
I1003 22:11:52.172855  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.270231 (* 1 = 0.270231 loss)
I1003 22:11:52.172865  5017 sgd_solver.cpp:165] Iteration 19800, lr = 0.1
I1003 22:14:36.496906  5017 solver.cpp:357] Iteration 19900 (0.608534 iter/s, 164.329s/100 iters), loss = 0.290247
I1003 22:14:36.497045  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.352237 (* 1 = 0.352237 loss)
I1003 22:14:36.497056  5017 sgd_solver.cpp:165] Iteration 19900, lr = 0.1
I1003 22:15:09.384593  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 22:17:19.156546  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_20000.caffemodel
I1003 22:17:19.947099  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_20000.solverstate
I1003 22:17:20.251308  5017 solver.cpp:514] Iteration 20000, Testing net (#0)
I1003 22:18:02.534687  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 22:18:02.702672  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.763847 (* 1 = 0.763847 loss)
I1003 22:18:02.702697  5017 solver.cpp:580]     Test net output #1: prob = 0.7622
I1003 22:18:02.702702  5017 solver.cpp:593]     Max_acc: 0.824801  with iter: 16000
I1003 22:18:04.330322  5017 solver.cpp:357] Iteration 20000 (0.48114 iter/s, 207.84s/100 iters), loss = 0.322358
I1003 22:18:04.330375  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.210792 (* 1 = 0.210792 loss)
I1003 22:18:04.330389  5017 sgd_solver.cpp:165] Iteration 20000, lr = 0.1
I1003 22:20:48.631884  5017 solver.cpp:357] Iteration 20100 (0.608667 iter/s, 164.293s/100 iters), loss = 0.264207
I1003 22:20:48.632025  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.184537 (* 1 = 0.184537 loss)
I1003 22:20:48.632036  5017 sgd_solver.cpp:165] Iteration 20100, lr = 0.1
I1003 22:23:32.966017  5017 solver.cpp:357] Iteration 20200 (0.608549 iter/s, 164.325s/100 iters), loss = 0.292385
I1003 22:23:32.966131  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.215898 (* 1 = 0.215898 loss)
I1003 22:23:32.966142  5017 sgd_solver.cpp:165] Iteration 20200, lr = 0.1
I1003 22:26:17.302696  5017 solver.cpp:357] Iteration 20300 (0.608529 iter/s, 164.331s/100 iters), loss = 0.312368
I1003 22:26:17.303908  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.321852 (* 1 = 0.321852 loss)
I1003 22:26:17.303922  5017 sgd_solver.cpp:165] Iteration 20300, lr = 0.1
I1003 22:26:34.678670  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 22:29:02.053452  5017 solver.cpp:357] Iteration 20400 (0.606996 iter/s, 164.746s/100 iters), loss = 0.384015
I1003 22:29:02.053539  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.382252 (* 1 = 0.382252 loss)
I1003 22:29:02.053550  5017 sgd_solver.cpp:165] Iteration 20400, lr = 0.1
I1003 22:31:44.797493  5017 solver.cpp:514] Iteration 20500, Testing net (#0)
I1003 22:32:27.081594  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 22:32:27.249650  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.500005 (* 1 = 0.500005 loss)
I1003 22:32:27.249677  5017 solver.cpp:580]     Test net output #1: prob = 0.838201
I1003 22:32:27.249689  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_20500.caffemodel
I1003 22:32:28.039793  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_20500.solverstate
I1003 22:32:28.348353  5017 solver.cpp:593]     Max_acc: 0.838201  with iter: 20500
I1003 22:32:29.977973  5017 solver.cpp:357] Iteration 20500 (0.48095 iter/s, 207.922s/100 iters), loss = 0.315557
I1003 22:32:29.978031  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.44958 (* 1 = 0.44958 loss)
I1003 22:32:29.978042  5017 sgd_solver.cpp:165] Iteration 20500, lr = 0.1
I1003 22:35:14.071333  5017 solver.cpp:357] Iteration 20600 (0.609414 iter/s, 164.092s/100 iters), loss = 0.330397
I1003 22:35:14.071519  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.594245 (* 1 = 0.594245 loss)
I1003 22:35:14.071529  5017 sgd_solver.cpp:165] Iteration 20600, lr = 0.1
I1003 22:37:58.121803  5017 solver.cpp:357] Iteration 20700 (0.609571 iter/s, 164.05s/100 iters), loss = 0.347853
I1003 22:37:58.121978  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.184178 (* 1 = 0.184178 loss)
I1003 22:37:58.121987  5017 sgd_solver.cpp:165] Iteration 20700, lr = 0.1
I1003 22:38:00.184530  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 22:40:42.223764  5017 solver.cpp:357] Iteration 20800 (0.609377 iter/s, 164.102s/100 iters), loss = 0.34048
I1003 22:40:42.223861  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.417544 (* 1 = 0.417544 loss)
I1003 22:40:42.223871  5017 sgd_solver.cpp:165] Iteration 20800, lr = 0.1
I1003 22:43:26.544116  5017 solver.cpp:357] Iteration 20900 (0.608566 iter/s, 164.321s/100 iters), loss = 0.389239
I1003 22:43:26.544247  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.214352 (* 1 = 0.214352 loss)
I1003 22:43:26.544257  5017 sgd_solver.cpp:165] Iteration 20900, lr = 0.1
I1003 22:46:09.420583  5017 solver.cpp:514] Iteration 21000, Testing net (#0)
I1003 22:46:51.748059  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 22:46:51.915781  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.623025 (* 1 = 0.623025 loss)
I1003 22:46:51.915805  5017 solver.cpp:580]     Test net output #1: prob = 0.797201
I1003 22:46:51.915812  5017 solver.cpp:593]     Max_acc: 0.838201  with iter: 20500
I1003 22:46:53.543198  5017 solver.cpp:357] Iteration 21000 (0.483092 iter/s, 207s/100 iters), loss = 0.354761
I1003 22:46:53.543253  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.414063 (* 1 = 0.414063 loss)
I1003 22:46:53.543269  5017 sgd_solver.cpp:165] Iteration 21000, lr = 0.1
I1003 22:49:24.378943  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 22:49:37.926625  5017 solver.cpp:357] Iteration 21100 (0.60833 iter/s, 164.384s/100 iters), loss = 0.334361
I1003 22:49:37.926687  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.189498 (* 1 = 0.189498 loss)
I1003 22:49:37.926697  5017 sgd_solver.cpp:165] Iteration 21100, lr = 0.1
I1003 22:52:22.370132  5017 solver.cpp:357] Iteration 21200 (0.608108 iter/s, 164.445s/100 iters), loss = 0.293096
I1003 22:52:22.370230  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.440356 (* 1 = 0.440356 loss)
I1003 22:52:22.370241  5017 sgd_solver.cpp:165] Iteration 21200, lr = 0.1
I1003 22:55:06.758955  5017 solver.cpp:357] Iteration 21300 (0.608299 iter/s, 164.393s/100 iters), loss = 0.368001
I1003 22:55:06.759059  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0837505 (* 1 = 0.0837505 loss)
I1003 22:55:06.759069  5017 sgd_solver.cpp:165] Iteration 21300, lr = 0.1
I1003 22:57:51.217728  5017 solver.cpp:357] Iteration 21400 (0.608041 iter/s, 164.463s/100 iters), loss = 0.384059
I1003 22:57:51.217825  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.448168 (* 1 = 0.448168 loss)
I1003 22:57:51.217835  5017 sgd_solver.cpp:165] Iteration 21400, lr = 0.1
I1003 23:00:07.106868  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 23:00:34.304100  5017 solver.cpp:514] Iteration 21500, Testing net (#0)
I1003 23:01:16.621755  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 23:01:16.790194  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.875295 (* 1 = 0.875295 loss)
I1003 23:01:16.790220  5017 solver.cpp:580]     Test net output #1: prob = 0.7359
I1003 23:01:16.790225  5017 solver.cpp:593]     Max_acc: 0.838201  with iter: 20500
I1003 23:01:18.418282  5017 solver.cpp:357] Iteration 21500 (0.482615 iter/s, 207.205s/100 iters), loss = 0.222304
I1003 23:01:18.418335  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.244353 (* 1 = 0.244353 loss)
I1003 23:01:18.418349  5017 sgd_solver.cpp:165] Iteration 21500, lr = 0.1
I1003 23:04:02.935519  5017 solver.cpp:357] Iteration 21600 (0.607829 iter/s, 164.52s/100 iters), loss = 0.300902
I1003 23:04:02.935703  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.229578 (* 1 = 0.229578 loss)
I1003 23:04:02.935716  5017 sgd_solver.cpp:165] Iteration 21600, lr = 0.1
I1003 23:06:47.469128  5017 solver.cpp:357] Iteration 21700 (0.60777 iter/s, 164.536s/100 iters), loss = 0.270596
I1003 23:06:47.469271  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.27787 (* 1 = 0.27787 loss)
I1003 23:06:47.469282  5017 sgd_solver.cpp:165] Iteration 21700, lr = 0.1
I1003 23:09:32.129878  5017 solver.cpp:357] Iteration 21800 (0.607301 iter/s, 164.663s/100 iters), loss = 0.217972
I1003 23:09:32.130023  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.223297 (* 1 = 0.223297 loss)
I1003 23:09:32.130033  5017 sgd_solver.cpp:165] Iteration 21800, lr = 0.1
I1003 23:11:32.280097  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 23:12:16.664979  5017 solver.cpp:357] Iteration 21900 (0.607765 iter/s, 164.537s/100 iters), loss = 0.44788
I1003 23:12:16.665118  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.227734 (* 1 = 0.227734 loss)
I1003 23:12:16.665133  5017 sgd_solver.cpp:165] Iteration 21900, lr = 0.1
I1003 23:14:59.762845  5017 solver.cpp:514] Iteration 22000, Testing net (#0)
I1003 23:15:42.045029  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 23:15:42.212957  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.817651 (* 1 = 0.817651 loss)
I1003 23:15:42.212985  5017 solver.cpp:580]     Test net output #1: prob = 0.7611
I1003 23:15:42.212991  5017 solver.cpp:593]     Max_acc: 0.838201  with iter: 20500
I1003 23:15:43.841574  5017 solver.cpp:357] Iteration 22000 (0.482674 iter/s, 207.179s/100 iters), loss = 0.246763
I1003 23:15:43.841629  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.283496 (* 1 = 0.283496 loss)
I1003 23:15:43.841640  5017 sgd_solver.cpp:165] Iteration 22000, lr = 0.1
I1003 23:18:28.278432  5017 solver.cpp:357] Iteration 22100 (0.608129 iter/s, 164.439s/100 iters), loss = 0.339453
I1003 23:18:28.278578  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.41705 (* 1 = 0.41705 loss)
I1003 23:18:28.278589  5017 sgd_solver.cpp:165] Iteration 22100, lr = 0.1
I1003 23:21:13.050729  5017 solver.cpp:357] Iteration 22200 (0.606891 iter/s, 164.774s/100 iters), loss = 0.270019
I1003 23:21:13.050837  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.145384 (* 1 = 0.145384 loss)
I1003 23:21:13.050848  5017 sgd_solver.cpp:165] Iteration 22200, lr = 0.1
I1003 23:22:57.920959  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 23:23:57.546066  5017 solver.cpp:357] Iteration 22300 (0.607913 iter/s, 164.497s/100 iters), loss = 0.227994
I1003 23:23:57.546205  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.418957 (* 1 = 0.418957 loss)
I1003 23:23:57.546214  5017 sgd_solver.cpp:165] Iteration 22300, lr = 0.1
I1003 23:26:42.192255  5017 solver.cpp:357] Iteration 22400 (0.607357 iter/s, 164.648s/100 iters), loss = 0.280234
I1003 23:26:42.192356  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.243063 (* 1 = 0.243063 loss)
I1003 23:26:42.192368  5017 sgd_solver.cpp:165] Iteration 22400, lr = 0.1
I1003 23:29:25.061985  5017 solver.cpp:514] Iteration 22500, Testing net (#0)
I1003 23:30:07.375277  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 23:30:07.544355  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.547054 (* 1 = 0.547054 loss)
I1003 23:30:07.544380  5017 solver.cpp:580]     Test net output #1: prob = 0.818201
I1003 23:30:07.544386  5017 solver.cpp:593]     Max_acc: 0.838201  with iter: 20500
I1003 23:30:09.173967  5017 solver.cpp:357] Iteration 22500 (0.483078 iter/s, 207.006s/100 iters), loss = 0.289872
I1003 23:30:09.174022  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.21355 (* 1 = 0.21355 loss)
I1003 23:30:09.174033  5017 sgd_solver.cpp:165] Iteration 22500, lr = 0.1
I1003 23:32:53.669452  5017 solver.cpp:357] Iteration 22600 (0.60786 iter/s, 164.512s/100 iters), loss = 0.3389
I1003 23:32:53.669600  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.124631 (* 1 = 0.124631 loss)
I1003 23:32:53.669612  5017 sgd_solver.cpp:165] Iteration 22600, lr = 0.1
I1003 23:34:23.172281  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 23:35:38.558778  5017 solver.cpp:357] Iteration 22700 (0.606419 iter/s, 164.902s/100 iters), loss = 0.230325
I1003 23:35:38.558915  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.150441 (* 1 = 0.150441 loss)
I1003 23:35:38.558926  5017 sgd_solver.cpp:165] Iteration 22700, lr = 0.1
I1003 23:38:23.233654  5017 solver.cpp:357] Iteration 22800 (0.607217 iter/s, 164.686s/100 iters), loss = 0.262967
I1003 23:38:23.233794  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.383123 (* 1 = 0.383123 loss)
I1003 23:38:23.233805  5017 sgd_solver.cpp:165] Iteration 22800, lr = 0.1
I1003 23:41:07.959480  5017 solver.cpp:357] Iteration 22900 (0.607035 iter/s, 164.735s/100 iters), loss = 0.385973
I1003 23:41:07.959609  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.514609 (* 1 = 0.514609 loss)
I1003 23:41:07.959620  5017 sgd_solver.cpp:165] Iteration 22900, lr = 0.1
I1003 23:43:50.872130  5017 solver.cpp:514] Iteration 23000, Testing net (#0)
I1003 23:44:33.166805  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 23:44:33.334812  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.779867 (* 1 = 0.779867 loss)
I1003 23:44:33.334838  5017 solver.cpp:580]     Test net output #1: prob = 0.7689
I1003 23:44:33.334844  5017 solver.cpp:593]     Max_acc: 0.838201  with iter: 20500
I1003 23:44:34.962644  5017 solver.cpp:357] Iteration 23000 (0.483061 iter/s, 207.013s/100 iters), loss = 0.452222
I1003 23:44:34.962697  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.439619 (* 1 = 0.439619 loss)
I1003 23:44:34.962707  5017 sgd_solver.cpp:165] Iteration 23000, lr = 0.1
I1003 23:45:48.942880  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 23:47:19.642324  5017 solver.cpp:357] Iteration 23100 (0.607213 iter/s, 164.687s/100 iters), loss = 0.395551
I1003 23:47:19.642419  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.489789 (* 1 = 0.489789 loss)
I1003 23:47:19.642431  5017 sgd_solver.cpp:165] Iteration 23100, lr = 0.1
I1003 23:50:04.174648  5017 solver.cpp:357] Iteration 23200 (0.607759 iter/s, 164.539s/100 iters), loss = 0.345334
I1003 23:50:04.174741  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.268153 (* 1 = 0.268153 loss)
I1003 23:50:04.174751  5017 sgd_solver.cpp:165] Iteration 23200, lr = 0.1
I1003 23:52:48.823678  5017 solver.cpp:357] Iteration 23300 (0.607329 iter/s, 164.655s/100 iters), loss = 0.240514
I1003 23:52:48.823812  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.444474 (* 1 = 0.444474 loss)
I1003 23:52:48.823823  5017 sgd_solver.cpp:165] Iteration 23300, lr = 0.1
I1003 23:55:33.353842  5017 solver.cpp:357] Iteration 23400 (0.607769 iter/s, 164.536s/100 iters), loss = 0.341736
I1003 23:55:33.353941  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.293227 (* 1 = 0.293227 loss)
I1003 23:55:33.353952  5017 sgd_solver.cpp:165] Iteration 23400, lr = 0.1
I1003 23:56:31.949918  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1003 23:58:16.574828  5017 solver.cpp:514] Iteration 23500, Testing net (#0)
I1003 23:58:58.843595  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1003 23:58:59.011901  5017 solver.cpp:580]     Test net output #0: Softmax1 = 1.44306 (* 1 = 1.44306 loss)
I1003 23:58:59.011926  5017 solver.cpp:580]     Test net output #1: prob = 0.6386
I1003 23:58:59.011934  5017 solver.cpp:593]     Max_acc: 0.838201  with iter: 20500
I1003 23:59:00.642819  5017 solver.cpp:357] Iteration 23500 (0.482401 iter/s, 207.296s/100 iters), loss = 0.292102
I1003 23:59:00.642873  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.21797 (* 1 = 0.21797 loss)
I1003 23:59:00.642885  5017 sgd_solver.cpp:165] Iteration 23500, lr = 0.1
I1004 00:01:44.970607  5017 solver.cpp:357] Iteration 23600 (0.608533 iter/s, 164.329s/100 iters), loss = 0.387661
I1004 00:01:44.970787  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.549537 (* 1 = 0.549537 loss)
I1004 00:01:44.970798  5017 sgd_solver.cpp:165] Iteration 23600, lr = 0.1
I1004 00:04:29.657647  5017 solver.cpp:357] Iteration 23700 (0.607243 iter/s, 164.679s/100 iters), loss = 0.279769
I1004 00:04:29.657752  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.178183 (* 1 = 0.178183 loss)
I1004 00:04:29.657766  5017 sgd_solver.cpp:165] Iteration 23700, lr = 0.1
I1004 00:07:14.190706  5017 solver.cpp:357] Iteration 23800 (0.6078 iter/s, 164.528s/100 iters), loss = 0.347452
I1004 00:07:14.190821  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.374279 (* 1 = 0.374279 loss)
I1004 00:07:14.190834  5017 sgd_solver.cpp:165] Iteration 23800, lr = 0.1
I1004 00:07:57.388517  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 00:09:58.671032  5017 solver.cpp:357] Iteration 23900 (0.607986 iter/s, 164.478s/100 iters), loss = 0.268063
I1004 00:09:58.671175  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.369284 (* 1 = 0.369284 loss)
I1004 00:09:58.671185  5017 sgd_solver.cpp:165] Iteration 23900, lr = 0.1
I1004 00:12:41.532517  5017 solver.cpp:514] Iteration 24000, Testing net (#0)
I1004 00:13:23.834378  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 00:13:24.002729  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.51088 (* 1 = 0.51088 loss)
I1004 00:13:24.002755  5017 solver.cpp:580]     Test net output #1: prob = 0.829901
I1004 00:13:24.002761  5017 solver.cpp:593]     Max_acc: 0.838201  with iter: 20500
I1004 00:13:25.629894  5017 solver.cpp:357] Iteration 24000 (0.483191 iter/s, 206.958s/100 iters), loss = 0.439444
I1004 00:13:25.629958  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.440164 (* 1 = 0.440164 loss)
I1004 00:13:25.629969  5017 sgd_solver.cpp:165] Iteration 24000, lr = 0.1
I1004 00:16:09.864221  5017 solver.cpp:357] Iteration 24100 (0.608885 iter/s, 164.235s/100 iters), loss = 0.323346
I1004 00:16:09.864361  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.462751 (* 1 = 0.462751 loss)
I1004 00:16:09.864372  5017 sgd_solver.cpp:165] Iteration 24100, lr = 0.1
I1004 00:18:54.373821  5017 solver.cpp:357] Iteration 24200 (0.607863 iter/s, 164.511s/100 iters), loss = 0.250559
I1004 00:18:54.373925  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.333506 (* 1 = 0.333506 loss)
I1004 00:18:54.373935  5017 sgd_solver.cpp:165] Iteration 24200, lr = 0.1
I1004 00:19:22.052975  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 00:21:39.220650  5017 solver.cpp:357] Iteration 24300 (0.606617 iter/s, 164.849s/100 iters), loss = 0.407499
I1004 00:21:39.220746  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.434269 (* 1 = 0.434269 loss)
I1004 00:21:39.220759  5017 sgd_solver.cpp:165] Iteration 24300, lr = 0.1
I1004 00:24:23.728235  5017 solver.cpp:357] Iteration 24400 (0.607866 iter/s, 164.51s/100 iters), loss = 0.296282
I1004 00:24:23.728382  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.304494 (* 1 = 0.304494 loss)
I1004 00:24:23.728394  5017 sgd_solver.cpp:165] Iteration 24400, lr = 0.1
I1004 00:27:06.591720  5017 solver.cpp:514] Iteration 24500, Testing net (#0)
I1004 00:27:48.896246  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 00:27:49.063787  5017 solver.cpp:580]     Test net output #0: Softmax1 = 1.31846 (* 1 = 1.31846 loss)
I1004 00:27:49.063812  5017 solver.cpp:580]     Test net output #1: prob = 0.6994
I1004 00:27:49.063820  5017 solver.cpp:593]     Max_acc: 0.838201  with iter: 20500
I1004 00:27:50.689288  5017 solver.cpp:357] Iteration 24500 (0.483175 iter/s, 206.964s/100 iters), loss = 0.37795
I1004 00:27:50.689342  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.317129 (* 1 = 0.317129 loss)
I1004 00:27:50.689355  5017 sgd_solver.cpp:165] Iteration 24500, lr = 0.1
I1004 00:30:35.025753  5017 solver.cpp:357] Iteration 24600 (0.608497 iter/s, 164.339s/100 iters), loss = 0.232607
I1004 00:30:35.025923  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.310674 (* 1 = 0.310674 loss)
I1004 00:30:35.025934  5017 sgd_solver.cpp:165] Iteration 24600, lr = 0.1
I1004 00:30:47.357008  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 00:33:19.624740  5017 solver.cpp:357] Iteration 24700 (0.607527 iter/s, 164.602s/100 iters), loss = 0.231892
I1004 00:33:19.624841  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.306102 (* 1 = 0.306102 loss)
I1004 00:33:19.624851  5017 sgd_solver.cpp:165] Iteration 24700, lr = 0.1
I1004 00:36:04.060243  5017 solver.cpp:357] Iteration 24800 (0.60813 iter/s, 164.439s/100 iters), loss = 0.272786
I1004 00:36:04.060336  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.347593 (* 1 = 0.347593 loss)
I1004 00:36:04.060353  5017 sgd_solver.cpp:165] Iteration 24800, lr = 0.1
I1004 00:38:48.848502  5017 solver.cpp:357] Iteration 24900 (0.606828 iter/s, 164.791s/100 iters), loss = 0.330784
I1004 00:38:48.848644  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.44394 (* 1 = 0.44394 loss)
I1004 00:38:48.848659  5017 sgd_solver.cpp:165] Iteration 24900, lr = 0.1
I1004 00:41:30.209039  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 00:41:31.849005  5017 solver.cpp:514] Iteration 25000, Testing net (#0)
I1004 00:42:14.131781  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 00:42:14.298918  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.781002 (* 1 = 0.781002 loss)
I1004 00:42:14.298943  5017 solver.cpp:580]     Test net output #1: prob = 0.7579
I1004 00:42:14.298949  5017 solver.cpp:593]     Max_acc: 0.838201  with iter: 20500
I1004 00:42:15.926367  5017 solver.cpp:357] Iteration 25000 (0.482901 iter/s, 207.082s/100 iters), loss = 0.311236
I1004 00:42:15.926420  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.41122 (* 1 = 0.41122 loss)
I1004 00:42:15.926431  5017 sgd_solver.cpp:165] Iteration 25000, lr = 0.1
I1004 00:45:00.313299  5017 solver.cpp:357] Iteration 25100 (0.608309 iter/s, 164.39s/100 iters), loss = 0.314466
I1004 00:45:00.316256  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.242349 (* 1 = 0.242349 loss)
I1004 00:45:00.316272  5017 sgd_solver.cpp:165] Iteration 25100, lr = 0.1
I1004 00:47:44.826783  5017 solver.cpp:357] Iteration 25200 (0.607852 iter/s, 164.514s/100 iters), loss = 0.398567
I1004 00:47:44.826881  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.288929 (* 1 = 0.288929 loss)
I1004 00:47:44.826891  5017 sgd_solver.cpp:165] Iteration 25200, lr = 0.1
I1004 00:50:29.532996  5017 solver.cpp:357] Iteration 25300 (0.60713 iter/s, 164.709s/100 iters), loss = 0.383627
I1004 00:50:29.533093  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.711995 (* 1 = 0.711995 loss)
I1004 00:50:29.533103  5017 sgd_solver.cpp:165] Iteration 25300, lr = 0.1
I1004 00:52:55.629554  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 00:53:14.143394  5017 solver.cpp:357] Iteration 25400 (0.607483 iter/s, 164.614s/100 iters), loss = 0.320369
I1004 00:53:14.143453  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.301877 (* 1 = 0.301877 loss)
I1004 00:53:14.143465  5017 sgd_solver.cpp:165] Iteration 25400, lr = 0.1
I1004 00:55:57.140204  5017 solver.cpp:514] Iteration 25500, Testing net (#0)
I1004 00:56:39.408493  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 00:56:39.576941  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.603837 (* 1 = 0.603837 loss)
I1004 00:56:39.576967  5017 solver.cpp:580]     Test net output #1: prob = 0.805001
I1004 00:56:39.576972  5017 solver.cpp:593]     Max_acc: 0.838201  with iter: 20500
I1004 00:56:41.204452  5017 solver.cpp:357] Iteration 25500 (0.48294 iter/s, 207.065s/100 iters), loss = 0.316573
I1004 00:56:41.204506  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.39171 (* 1 = 0.39171 loss)
I1004 00:56:41.204517  5017 sgd_solver.cpp:165] Iteration 25500, lr = 0.1
I1004 00:59:25.653740  5017 solver.cpp:357] Iteration 25600 (0.608078 iter/s, 164.453s/100 iters), loss = 0.296686
I1004 00:59:25.653888  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.332581 (* 1 = 0.332581 loss)
I1004 00:59:25.653908  5017 sgd_solver.cpp:165] Iteration 25600, lr = 0.1
I1004 01:02:10.053498  5017 solver.cpp:357] Iteration 25700 (0.608261 iter/s, 164.403s/100 iters), loss = 0.192191
I1004 01:02:10.053637  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.271496 (* 1 = 0.271496 loss)
I1004 01:02:10.053648  5017 sgd_solver.cpp:165] Iteration 25700, lr = 0.1
I1004 01:04:20.447911  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 01:04:54.577396  5017 solver.cpp:357] Iteration 25800 (0.607802 iter/s, 164.527s/100 iters), loss = 0.341821
I1004 01:04:54.577535  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.306762 (* 1 = 0.306762 loss)
I1004 01:04:54.577546  5017 sgd_solver.cpp:165] Iteration 25800, lr = 0.1
I1004 01:07:39.088870  5017 solver.cpp:357] Iteration 25900 (0.607848 iter/s, 164.515s/100 iters), loss = 0.358761
I1004 01:07:39.088963  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.272397 (* 1 = 0.272397 loss)
I1004 01:07:39.088975  5017 sgd_solver.cpp:165] Iteration 25900, lr = 0.1
I1004 01:10:22.030273  5017 solver.cpp:514] Iteration 26000, Testing net (#0)
I1004 01:11:04.328712  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 01:11:04.496526  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.459474 (* 1 = 0.459474 loss)
I1004 01:11:04.496552  5017 solver.cpp:580]     Test net output #1: prob = 0.848602
I1004 01:11:04.496564  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_26000.caffemodel
I1004 01:11:05.285755  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_26000.solverstate
I1004 01:11:05.593472  5017 solver.cpp:593]     Max_acc: 0.848602  with iter: 26000
I1004 01:11:07.221114  5017 solver.cpp:357] Iteration 26000 (0.480427 iter/s, 208.148s/100 iters), loss = 0.295164
I1004 01:11:07.221173  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.208079 (* 1 = 0.208079 loss)
I1004 01:11:07.221182  5017 sgd_solver.cpp:165] Iteration 26000, lr = 0.1
I1004 01:13:51.419569  5017 solver.cpp:357] Iteration 26100 (0.608953 iter/s, 164.216s/100 iters), loss = 0.250623
I1004 01:13:51.419715  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.1666 (* 1 = 0.1666 loss)
I1004 01:13:51.419726  5017 sgd_solver.cpp:165] Iteration 26100, lr = 0.1
I1004 01:15:46.601496  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 01:16:35.931360  5017 solver.cpp:357] Iteration 26200 (0.607806 iter/s, 164.526s/100 iters), loss = 0.341831
I1004 01:16:35.931500  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.458842 (* 1 = 0.458842 loss)
I1004 01:16:35.931511  5017 sgd_solver.cpp:165] Iteration 26200, lr = 0.1
I1004 01:19:20.551599  5017 solver.cpp:357] Iteration 26300 (0.607415 iter/s, 164.632s/100 iters), loss = 0.23465
I1004 01:19:20.551739  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.338428 (* 1 = 0.338428 loss)
I1004 01:19:20.551750  5017 sgd_solver.cpp:165] Iteration 26300, lr = 0.1
I1004 01:22:05.044137  5017 solver.cpp:357] Iteration 26400 (0.607893 iter/s, 164.503s/100 iters), loss = 0.189044
I1004 01:22:05.044229  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.157317 (* 1 = 0.157317 loss)
I1004 01:22:05.044240  5017 sgd_solver.cpp:165] Iteration 26400, lr = 0.1
I1004 01:24:47.996139  5017 solver.cpp:514] Iteration 26500, Testing net (#0)
I1004 01:25:30.289283  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 01:25:30.458717  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.517124 (* 1 = 0.517124 loss)
I1004 01:25:30.458742  5017 solver.cpp:580]     Test net output #1: prob = 0.8393
I1004 01:25:30.458748  5017 solver.cpp:593]     Max_acc: 0.848602  with iter: 26000
I1004 01:25:32.087213  5017 solver.cpp:357] Iteration 26500 (0.482965 iter/s, 207.054s/100 iters), loss = 0.28903
I1004 01:25:32.087260  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.375371 (* 1 = 0.375371 loss)
I1004 01:25:32.087270  5017 sgd_solver.cpp:165] Iteration 26500, lr = 0.1
I1004 01:27:11.424703  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 01:28:16.463076  5017 solver.cpp:357] Iteration 26600 (0.608333 iter/s, 164.384s/100 iters), loss = 0.245409
I1004 01:28:16.463212  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0761605 (* 1 = 0.0761605 loss)
I1004 01:28:16.463222  5017 sgd_solver.cpp:165] Iteration 26600, lr = 0.1
I1004 01:31:00.983208  5017 solver.cpp:357] Iteration 26700 (0.607802 iter/s, 164.527s/100 iters), loss = 0.403269
I1004 01:31:00.983306  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.496929 (* 1 = 0.496929 loss)
I1004 01:31:00.983317  5017 sgd_solver.cpp:165] Iteration 26700, lr = 0.1
I1004 01:33:45.514906  5017 solver.cpp:357] Iteration 26800 (0.607761 iter/s, 164.538s/100 iters), loss = 0.271344
I1004 01:33:45.515050  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.292195 (* 1 = 0.292195 loss)
I1004 01:33:45.515065  5017 sgd_solver.cpp:165] Iteration 26800, lr = 0.1
I1004 01:36:30.070397  5017 solver.cpp:357] Iteration 26900 (0.607674 iter/s, 164.562s/100 iters), loss = 0.298566
I1004 01:36:30.070536  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.199335 (* 1 = 0.199335 loss)
I1004 01:36:30.070547  5017 sgd_solver.cpp:165] Iteration 26900, lr = 0.1
I1004 01:37:54.416868  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 01:39:12.982331  5017 solver.cpp:514] Iteration 27000, Testing net (#0)
I1004 01:39:55.281294  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 01:39:55.450107  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.548204 (* 1 = 0.548204 loss)
I1004 01:39:55.450132  5017 solver.cpp:580]     Test net output #1: prob = 0.825901
I1004 01:39:55.450139  5017 solver.cpp:593]     Max_acc: 0.848602  with iter: 26000
I1004 01:39:57.076277  5017 solver.cpp:357] Iteration 27000 (0.48306 iter/s, 207.014s/100 iters), loss = 0.362483
I1004 01:39:57.076333  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.163152 (* 1 = 0.163152 loss)
I1004 01:39:57.076347  5017 sgd_solver.cpp:165] Iteration 27000, lr = 0.1
I1004 01:42:41.407161  5017 solver.cpp:357] Iteration 27100 (0.608506 iter/s, 164.337s/100 iters), loss = 0.374972
I1004 01:42:41.407297  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.369009 (* 1 = 0.369009 loss)
I1004 01:42:41.407307  5017 sgd_solver.cpp:165] Iteration 27100, lr = 0.1
I1004 01:45:25.946804  5017 solver.cpp:357] Iteration 27200 (0.607739 iter/s, 164.544s/100 iters), loss = 0.360217
I1004 01:45:25.946946  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.386233 (* 1 = 0.386233 loss)
I1004 01:45:25.946956  5017 sgd_solver.cpp:165] Iteration 27200, lr = 0.1
I1004 01:48:10.303293  5017 solver.cpp:357] Iteration 27300 (0.608417 iter/s, 164.361s/100 iters), loss = 0.306937
I1004 01:48:10.303390  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.255706 (* 1 = 0.255706 loss)
I1004 01:48:10.303401  5017 sgd_solver.cpp:165] Iteration 27300, lr = 0.1
I1004 01:49:19.141003  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 01:50:54.864778  5017 solver.cpp:357] Iteration 27400 (0.607658 iter/s, 164.566s/100 iters), loss = 0.248015
I1004 01:50:54.864873  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.238424 (* 1 = 0.238424 loss)
I1004 01:50:54.864887  5017 sgd_solver.cpp:165] Iteration 27400, lr = 0.1
I1004 01:53:37.816951  5017 solver.cpp:514] Iteration 27500, Testing net (#0)
I1004 01:54:20.132513  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 01:54:20.299118  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.447205 (* 1 = 0.447205 loss)
I1004 01:54:20.299142  5017 solver.cpp:580]     Test net output #1: prob = 0.855401
I1004 01:54:20.299154  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_27500.caffemodel
I1004 01:54:21.082757  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_27500.solverstate
I1004 01:54:21.389175  5017 solver.cpp:593]     Max_acc: 0.855401  with iter: 27500
I1004 01:54:23.013556  5017 solver.cpp:357] Iteration 27500 (0.480411 iter/s, 208.155s/100 iters), loss = 0.376308
I1004 01:54:23.013614  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.303045 (* 1 = 0.303045 loss)
I1004 01:54:23.013625  5017 sgd_solver.cpp:165] Iteration 27500, lr = 0.1
I1004 01:57:07.022476  5017 solver.cpp:357] Iteration 27600 (0.609704 iter/s, 164.014s/100 iters), loss = 0.357438
I1004 01:57:07.022609  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.422038 (* 1 = 0.422038 loss)
I1004 01:57:07.022620  5017 sgd_solver.cpp:165] Iteration 27600, lr = 0.1
I1004 01:59:51.533851  5017 solver.cpp:357] Iteration 27700 (0.607842 iter/s, 164.516s/100 iters), loss = 0.471734
I1004 01:59:51.534003  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.395144 (* 1 = 0.395144 loss)
I1004 01:59:51.534013  5017 sgd_solver.cpp:165] Iteration 27700, lr = 0.1
I1004 02:00:44.981567  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 02:02:35.976922  5017 solver.cpp:357] Iteration 27800 (0.608094 iter/s, 164.448s/100 iters), loss = 0.219366
I1004 02:02:35.977020  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.230093 (* 1 = 0.230093 loss)
I1004 02:02:35.977031  5017 sgd_solver.cpp:165] Iteration 27800, lr = 0.1
I1004 02:05:20.373981  5017 solver.cpp:357] Iteration 27900 (0.608264 iter/s, 164.402s/100 iters), loss = 0.334503
I1004 02:05:20.374123  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.314394 (* 1 = 0.314394 loss)
I1004 02:05:20.374133  5017 sgd_solver.cpp:165] Iteration 27900, lr = 0.1
I1004 02:08:03.174877  5017 solver.cpp:514] Iteration 28000, Testing net (#0)
I1004 02:08:45.444140  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 02:08:45.613243  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.65732 (* 1 = 0.65732 loss)
I1004 02:08:45.613268  5017 solver.cpp:580]     Test net output #1: prob = 0.7823
I1004 02:08:45.613274  5017 solver.cpp:593]     Max_acc: 0.855401  with iter: 27500
I1004 02:08:47.242085  5017 solver.cpp:357] Iteration 28000 (0.483385 iter/s, 206.875s/100 iters), loss = 0.333599
I1004 02:08:47.242138  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.492561 (* 1 = 0.492561 loss)
I1004 02:08:47.242148  5017 sgd_solver.cpp:165] Iteration 28000, lr = 0.1
I1004 02:11:31.513459  5017 solver.cpp:357] Iteration 28100 (0.608729 iter/s, 164.277s/100 iters), loss = 0.220382
I1004 02:11:31.513559  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.141623 (* 1 = 0.141623 loss)
I1004 02:11:31.513569  5017 sgd_solver.cpp:165] Iteration 28100, lr = 0.1
I1004 02:12:09.325493  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 02:14:16.010753  5017 solver.cpp:357] Iteration 28200 (0.607893 iter/s, 164.503s/100 iters), loss = 0.401246
I1004 02:14:16.010849  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.220881 (* 1 = 0.220881 loss)
I1004 02:14:16.010859  5017 sgd_solver.cpp:165] Iteration 28200, lr = 0.1
I1004 02:17:00.506295  5017 solver.cpp:357] Iteration 28300 (0.6079 iter/s, 164.501s/100 iters), loss = 0.237053
I1004 02:17:00.506434  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.284246 (* 1 = 0.284246 loss)
I1004 02:17:00.506445  5017 sgd_solver.cpp:165] Iteration 28300, lr = 0.1
I1004 02:19:44.957335  5017 solver.cpp:357] Iteration 28400 (0.608103 iter/s, 164.446s/100 iters), loss = 0.19754
I1004 02:19:44.957531  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0964872 (* 1 = 0.0964872 loss)
I1004 02:19:44.957543  5017 sgd_solver.cpp:165] Iteration 28400, lr = 0.1
I1004 02:22:27.800585  5017 solver.cpp:514] Iteration 28500, Testing net (#0)
I1004 02:23:10.082921  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 02:23:10.252382  5017 solver.cpp:580]     Test net output #0: Softmax1 = 1.04706 (* 1 = 1.04706 loss)
I1004 02:23:10.252408  5017 solver.cpp:580]     Test net output #1: prob = 0.719001
I1004 02:23:10.252414  5017 solver.cpp:593]     Max_acc: 0.855401  with iter: 27500
I1004 02:23:11.877887  5017 solver.cpp:357] Iteration 28500 (0.483292 iter/s, 206.914s/100 iters), loss = 0.258016
I1004 02:23:11.877943  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.340904 (* 1 = 0.340904 loss)
I1004 02:23:11.877959  5017 sgd_solver.cpp:165] Iteration 28500, lr = 0.1
I1004 02:23:34.450717  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 02:25:56.107283  5017 solver.cpp:357] Iteration 28600 (0.608913 iter/s, 164.227s/100 iters), loss = 0.371788
I1004 02:25:56.107386  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.379004 (* 1 = 0.379004 loss)
I1004 02:25:56.107398  5017 sgd_solver.cpp:165] Iteration 28600, lr = 0.1
I1004 02:28:40.449636  5017 solver.cpp:357] Iteration 28700 (0.608489 iter/s, 164.342s/100 iters), loss = 0.187541
I1004 02:28:40.449770  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.232882 (* 1 = 0.232882 loss)
I1004 02:28:40.449780  5017 sgd_solver.cpp:165] Iteration 28700, lr = 0.1
I1004 02:31:24.890954  5017 solver.cpp:357] Iteration 28800 (0.608118 iter/s, 164.442s/100 iters), loss = 0.252806
I1004 02:31:24.891053  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.442847 (* 1 = 0.442847 loss)
I1004 02:31:24.891064  5017 sgd_solver.cpp:165] Iteration 28800, lr = 0.1
I1004 02:34:09.222659  5017 solver.cpp:357] Iteration 28900 (0.60852 iter/s, 164.333s/100 iters), loss = 0.359559
I1004 02:34:09.222800  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.267274 (* 1 = 0.267274 loss)
I1004 02:34:09.222810  5017 sgd_solver.cpp:165] Iteration 28900, lr = 0.1
I1004 02:34:16.218444  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 02:36:52.209013  5017 solver.cpp:514] Iteration 29000, Testing net (#0)
I1004 02:37:34.463331  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 02:37:34.631808  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.943235 (* 1 = 0.943235 loss)
I1004 02:37:34.631834  5017 solver.cpp:580]     Test net output #1: prob = 0.7476
I1004 02:37:34.631840  5017 solver.cpp:593]     Max_acc: 0.855401  with iter: 27500
I1004 02:37:36.261286  5017 solver.cpp:357] Iteration 29000 (0.482996 iter/s, 207.041s/100 iters), loss = 0.349009
I1004 02:37:36.261340  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.488251 (* 1 = 0.488251 loss)
I1004 02:37:36.261351  5017 sgd_solver.cpp:165] Iteration 29000, lr = 0.1
I1004 02:40:20.564687  5017 solver.cpp:357] Iteration 29100 (0.608621 iter/s, 164.306s/100 iters), loss = 0.293768
I1004 02:40:20.564823  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.311591 (* 1 = 0.311591 loss)
I1004 02:40:20.564838  5017 sgd_solver.cpp:165] Iteration 29100, lr = 0.1
I1004 02:43:05.092470  5017 solver.cpp:357] Iteration 29200 (0.60779 iter/s, 164.531s/100 iters), loss = 0.376496
I1004 02:43:05.092605  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.569695 (* 1 = 0.569695 loss)
I1004 02:43:05.092617  5017 sgd_solver.cpp:165] Iteration 29200, lr = 0.1
I1004 02:45:41.369437  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 02:45:49.576170  5017 solver.cpp:357] Iteration 29300 (0.607952 iter/s, 164.487s/100 iters), loss = 0.314523
I1004 02:45:49.576231  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.254141 (* 1 = 0.254141 loss)
I1004 02:45:49.576241  5017 sgd_solver.cpp:165] Iteration 29300, lr = 0.1
I1004 02:48:34.079329  5017 solver.cpp:357] Iteration 29400 (0.607879 iter/s, 164.506s/100 iters), loss = 0.274111
I1004 02:48:34.079468  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.136668 (* 1 = 0.136668 loss)
I1004 02:48:34.079478  5017 sgd_solver.cpp:165] Iteration 29400, lr = 0.1
I1004 02:51:16.983510  5017 solver.cpp:514] Iteration 29500, Testing net (#0)
I1004 02:51:59.238435  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 02:51:59.406653  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.945402 (* 1 = 0.945402 loss)
I1004 02:51:59.406679  5017 solver.cpp:580]     Test net output #1: prob = 0.7507
I1004 02:51:59.406685  5017 solver.cpp:593]     Max_acc: 0.855401  with iter: 27500
I1004 02:52:01.032367  5017 solver.cpp:357] Iteration 29500 (0.483192 iter/s, 206.957s/100 iters), loss = 0.274348
I1004 02:52:01.032420  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.311052 (* 1 = 0.311052 loss)
I1004 02:52:01.032433  5017 sgd_solver.cpp:165] Iteration 29500, lr = 0.1
I1004 02:54:45.287171  5017 solver.cpp:357] Iteration 29600 (0.608792 iter/s, 164.26s/100 iters), loss = 0.271616
I1004 02:54:45.287314  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.269239 (* 1 = 0.269239 loss)
I1004 02:54:45.287325  5017 sgd_solver.cpp:165] Iteration 29600, lr = 0.1
I1004 02:57:05.679250  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 02:57:29.485952  5017 solver.cpp:357] Iteration 29700 (0.609 iter/s, 164.204s/100 iters), loss = 0.327694
I1004 02:57:29.486012  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.322443 (* 1 = 0.322443 loss)
I1004 02:57:29.486023  5017 sgd_solver.cpp:165] Iteration 29700, lr = 0.1
I1004 03:00:13.744638  5017 solver.cpp:357] Iteration 29800 (0.608779 iter/s, 164.263s/100 iters), loss = 0.255644
I1004 03:00:13.744776  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.336142 (* 1 = 0.336142 loss)
I1004 03:00:13.744786  5017 sgd_solver.cpp:165] Iteration 29800, lr = 0.1
I1004 03:02:58.098722  5017 solver.cpp:357] Iteration 29900 (0.608426 iter/s, 164.358s/100 iters), loss = 0.348664
I1004 03:02:58.098839  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.207035 (* 1 = 0.207035 loss)
I1004 03:02:58.098853  5017 sgd_solver.cpp:165] Iteration 29900, lr = 0.1
I1004 03:05:40.750406  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_30000.caffemodel
I1004 03:05:41.541663  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_30000.solverstate
I1004 03:05:41.847996  5017 solver.cpp:514] Iteration 30000, Testing net (#0)
I1004 03:06:24.153969  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 03:06:24.324026  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.740516 (* 1 = 0.740516 loss)
I1004 03:06:24.324051  5017 solver.cpp:580]     Test net output #1: prob = 0.769999
I1004 03:06:24.324057  5017 solver.cpp:593]     Max_acc: 0.855401  with iter: 27500
I1004 03:06:25.951181  5017 solver.cpp:357] Iteration 30000 (0.481098 iter/s, 207.858s/100 iters), loss = 0.206636
I1004 03:06:25.951237  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.203813 (* 1 = 0.203813 loss)
I1004 03:06:25.951253  5017 sgd_solver.cpp:165] Iteration 30000, lr = 0.1
I1004 03:08:31.194633  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 03:09:10.185914  5017 solver.cpp:357] Iteration 30100 (0.608869 iter/s, 164.239s/100 iters), loss = 0.386416
I1004 03:09:10.186031  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.15672 (* 1 = 0.15672 loss)
I1004 03:09:10.186041  5017 sgd_solver.cpp:165] Iteration 30100, lr = 0.1
I1004 03:11:54.432380  5017 solver.cpp:357] Iteration 30200 (0.608826 iter/s, 164.25s/100 iters), loss = 0.367699
I1004 03:11:54.432518  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.534729 (* 1 = 0.534729 loss)
I1004 03:11:54.432528  5017 sgd_solver.cpp:165] Iteration 30200, lr = 0.1
I1004 03:14:38.715356  5017 solver.cpp:357] Iteration 30300 (0.608691 iter/s, 164.287s/100 iters), loss = 0.38235
I1004 03:14:38.715492  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.442953 (* 1 = 0.442953 loss)
I1004 03:14:38.715507  5017 sgd_solver.cpp:165] Iteration 30300, lr = 0.1
I1004 03:17:23.044308  5017 solver.cpp:357] Iteration 30400 (0.608521 iter/s, 164.333s/100 iters), loss = 0.184746
I1004 03:17:23.044410  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.236306 (* 1 = 0.236306 loss)
I1004 03:17:23.044421  5017 sgd_solver.cpp:165] Iteration 30400, lr = 0.1
I1004 03:19:12.779484  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 03:20:05.757383  5017 solver.cpp:514] Iteration 30500, Testing net (#0)
I1004 03:20:48.084292  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 03:20:48.252003  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.605114 (* 1 = 0.605114 loss)
I1004 03:20:48.252029  5017 solver.cpp:580]     Test net output #1: prob = 0.813001
I1004 03:20:48.252035  5017 solver.cpp:593]     Max_acc: 0.855401  with iter: 27500
I1004 03:20:49.880811  5017 solver.cpp:357] Iteration 30500 (0.483462 iter/s, 206.841s/100 iters), loss = 0.277125
I1004 03:20:49.880865  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.257257 (* 1 = 0.257257 loss)
I1004 03:20:49.880878  5017 sgd_solver.cpp:165] Iteration 30500, lr = 0.1
I1004 03:23:34.147058  5017 solver.cpp:357] Iteration 30600 (0.608753 iter/s, 164.27s/100 iters), loss = 0.424251
I1004 03:23:34.147191  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.206765 (* 1 = 0.206765 loss)
I1004 03:23:34.147202  5017 sgd_solver.cpp:165] Iteration 30600, lr = 0.1
I1004 03:26:18.495368  5017 solver.cpp:357] Iteration 30700 (0.60845 iter/s, 164.352s/100 iters), loss = 0.353131
I1004 03:26:18.495502  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.281441 (* 1 = 0.281441 loss)
I1004 03:26:18.495513  5017 sgd_solver.cpp:165] Iteration 30700, lr = 0.1
I1004 03:29:02.918190  5017 solver.cpp:357] Iteration 30800 (0.608213 iter/s, 164.416s/100 iters), loss = 0.22868
I1004 03:29:02.918280  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.243694 (* 1 = 0.243694 loss)
I1004 03:29:02.918292  5017 sgd_solver.cpp:165] Iteration 30800, lr = 0.1
I1004 03:30:37.476912  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 03:31:47.334813  5017 solver.cpp:357] Iteration 30900 (0.608229 iter/s, 164.412s/100 iters), loss = 0.357747
I1004 03:31:47.334908  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.11806 (* 1 = 0.11806 loss)
I1004 03:31:47.334918  5017 sgd_solver.cpp:165] Iteration 30900, lr = 0.1
I1004 03:34:30.034086  5017 solver.cpp:514] Iteration 31000, Testing net (#0)
I1004 03:35:12.367027  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 03:35:12.535010  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.589608 (* 1 = 0.589608 loss)
I1004 03:35:12.535037  5017 solver.cpp:580]     Test net output #1: prob = 0.8079
I1004 03:35:12.535043  5017 solver.cpp:593]     Max_acc: 0.855401  with iter: 27500
I1004 03:35:14.163380  5017 solver.cpp:357] Iteration 31000 (0.4835 iter/s, 206.825s/100 iters), loss = 0.322334
I1004 03:35:14.163435  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.252826 (* 1 = 0.252826 loss)
I1004 03:35:14.163446  5017 sgd_solver.cpp:165] Iteration 31000, lr = 0.1
I1004 03:37:58.443855  5017 solver.cpp:357] Iteration 31100 (0.608719 iter/s, 164.279s/100 iters), loss = 0.278321
I1004 03:37:58.443990  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.294198 (* 1 = 0.294198 loss)
I1004 03:37:58.444000  5017 sgd_solver.cpp:165] Iteration 31100, lr = 0.1
I1004 03:40:43.117086  5017 solver.cpp:357] Iteration 31200 (0.607264 iter/s, 164.673s/100 iters), loss = 0.299937
I1004 03:40:43.117236  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.220579 (* 1 = 0.220579 loss)
I1004 03:40:43.117247  5017 sgd_solver.cpp:165] Iteration 31200, lr = 0.1
I1004 03:42:02.066892  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 03:43:27.598577  5017 solver.cpp:357] Iteration 31300 (0.607969 iter/s, 164.482s/100 iters), loss = 0.186122
I1004 03:43:27.598722  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0812939 (* 1 = 0.0812939 loss)
I1004 03:43:27.598733  5017 sgd_solver.cpp:165] Iteration 31300, lr = 0.1
I1004 03:46:12.097575  5017 solver.cpp:357] Iteration 31400 (0.607902 iter/s, 164.5s/100 iters), loss = 0.403287
I1004 03:46:12.097697  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.636119 (* 1 = 0.636119 loss)
I1004 03:46:12.097712  5017 sgd_solver.cpp:165] Iteration 31400, lr = 0.1
I1004 03:48:54.959703  5017 solver.cpp:514] Iteration 31500, Testing net (#0)
I1004 03:49:37.241858  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 03:49:37.410810  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.894434 (* 1 = 0.894434 loss)
I1004 03:49:37.410835  5017 solver.cpp:580]     Test net output #1: prob = 0.742
I1004 03:49:37.410841  5017 solver.cpp:593]     Max_acc: 0.855401  with iter: 27500
I1004 03:49:39.038671  5017 solver.cpp:357] Iteration 31500 (0.483225 iter/s, 206.943s/100 iters), loss = 0.354629
I1004 03:49:39.038727  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.442543 (* 1 = 0.442543 loss)
I1004 03:49:39.038738  5017 sgd_solver.cpp:165] Iteration 31500, lr = 0.1
I1004 03:52:23.353413  5017 solver.cpp:357] Iteration 31600 (0.608581 iter/s, 164.317s/100 iters), loss = 0.343827
I1004 03:52:23.353566  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.207859 (* 1 = 0.207859 loss)
I1004 03:52:23.353576  5017 sgd_solver.cpp:165] Iteration 31600, lr = 0.1
I1004 03:53:27.116080  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 03:55:07.704942  5017 solver.cpp:357] Iteration 31700 (0.608445 iter/s, 164.353s/100 iters), loss = 0.340814
I1004 03:55:07.705072  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.424753 (* 1 = 0.424753 loss)
I1004 03:55:07.705083  5017 sgd_solver.cpp:165] Iteration 31700, lr = 0.1
I1004 03:57:52.051520  5017 solver.cpp:357] Iteration 31800 (0.608463 iter/s, 164.349s/100 iters), loss = 0.312002
I1004 03:57:52.051656  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.199744 (* 1 = 0.199744 loss)
I1004 03:57:52.051667  5017 sgd_solver.cpp:165] Iteration 31800, lr = 0.1
I1004 04:00:36.496871  5017 solver.cpp:357] Iteration 31900 (0.608097 iter/s, 164.448s/100 iters), loss = 0.37863
I1004 04:00:36.496989  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.466809 (* 1 = 0.466809 loss)
I1004 04:00:36.497000  5017 sgd_solver.cpp:165] Iteration 31900, lr = 0.1
I1004 04:03:19.372093  5017 solver.cpp:514] Iteration 32000, Testing net (#0)
I1004 04:04:01.633193  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 04:04:01.801601  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.800976 (* 1 = 0.800976 loss)
I1004 04:04:01.801627  5017 solver.cpp:580]     Test net output #1: prob = 0.7591
I1004 04:04:01.801633  5017 solver.cpp:593]     Max_acc: 0.855401  with iter: 27500
I1004 04:04:03.428999  5017 solver.cpp:357] Iteration 32000 (0.483196 iter/s, 206.956s/100 iters), loss = 0.320384
I1004 04:04:03.429054  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.356731 (* 1 = 0.356731 loss)
I1004 04:04:03.429067  5017 sgd_solver.cpp:64] MultiStep Status: Iteration 32000, step = 1
I1004 04:04:03.429074  5017 sgd_solver.cpp:165] Iteration 32000, lr = 0.01
I1004 04:04:51.468684  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 04:06:47.634819  5017 solver.cpp:357] Iteration 32100 (0.608937 iter/s, 164.221s/100 iters), loss = 0.170044
I1004 04:06:47.634961  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.127327 (* 1 = 0.127327 loss)
I1004 04:06:47.634973  5017 sgd_solver.cpp:165] Iteration 32100, lr = 0.01
I1004 04:09:31.978390  5017 solver.cpp:357] Iteration 32200 (0.608437 iter/s, 164.356s/100 iters), loss = 0.224217
I1004 04:09:31.978488  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.132628 (* 1 = 0.132628 loss)
I1004 04:09:31.978498  5017 sgd_solver.cpp:165] Iteration 32200, lr = 0.01
I1004 04:12:16.286633  5017 solver.cpp:357] Iteration 32300 (0.608574 iter/s, 164.319s/100 iters), loss = 0.177699
I1004 04:12:16.286782  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.113348 (* 1 = 0.113348 loss)
I1004 04:12:16.286793  5017 sgd_solver.cpp:165] Iteration 32300, lr = 0.01
I1004 04:15:00.727360  5017 solver.cpp:357] Iteration 32400 (0.608089 iter/s, 164.45s/100 iters), loss = 0.120983
I1004 04:15:00.727505  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.158713 (* 1 = 0.158713 loss)
I1004 04:15:00.727516  5017 sgd_solver.cpp:165] Iteration 32400, lr = 0.01
I1004 04:15:33.656209  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 04:17:43.510687  5017 solver.cpp:514] Iteration 32500, Testing net (#0)
I1004 04:18:25.831065  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 04:18:25.999410  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.212265 (* 1 = 0.212265 loss)
I1004 04:18:25.999435  5017 solver.cpp:580]     Test net output #1: prob = 0.930902
I1004 04:18:25.999447  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_32500.caffemodel
I1004 04:18:26.787881  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_32500.solverstate
I1004 04:18:27.092360  5017 solver.cpp:593]     Max_acc: 0.930902  with iter: 32500
I1004 04:18:28.720762  5017 solver.cpp:357] Iteration 32500 (0.480761 iter/s, 208.003s/100 iters), loss = 0.159011
I1004 04:18:28.720819  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.114739 (* 1 = 0.114739 loss)
I1004 04:18:28.720830  5017 sgd_solver.cpp:165] Iteration 32500, lr = 0.01
I1004 04:21:12.689957  5017 solver.cpp:357] Iteration 32600 (0.609844 iter/s, 163.976s/100 iters), loss = 0.137659
I1004 04:21:12.690090  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0728329 (* 1 = 0.0728329 loss)
I1004 04:21:12.690101  5017 sgd_solver.cpp:165] Iteration 32600, lr = 0.01
I1004 04:23:56.915642  5017 solver.cpp:357] Iteration 32700 (0.608893 iter/s, 164.232s/100 iters), loss = 0.133024
I1004 04:23:56.915777  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.112224 (* 1 = 0.112224 loss)
I1004 04:23:56.915788  5017 sgd_solver.cpp:165] Iteration 32700, lr = 0.01
I1004 04:26:41.277715  5017 solver.cpp:357] Iteration 32800 (0.608389 iter/s, 164.368s/100 iters), loss = 0.109645
I1004 04:26:41.277851  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.11303 (* 1 = 0.11303 loss)
I1004 04:26:41.277861  5017 sgd_solver.cpp:165] Iteration 32800, lr = 0.01
I1004 04:26:58.556462  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 04:29:25.706960  5017 solver.cpp:357] Iteration 32900 (0.608142 iter/s, 164.435s/100 iters), loss = 0.126048
I1004 04:29:25.707103  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0441373 (* 1 = 0.0441373 loss)
I1004 04:29:25.707113  5017 sgd_solver.cpp:165] Iteration 32900, lr = 0.01
I1004 04:32:08.628221  5017 solver.cpp:514] Iteration 33000, Testing net (#0)
I1004 04:32:50.925621  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 04:32:51.092917  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.211433 (* 1 = 0.211433 loss)
I1004 04:32:51.092943  5017 solver.cpp:580]     Test net output #1: prob = 0.930903
I1004 04:32:51.092955  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_33000.caffemodel
I1004 04:32:51.881165  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_33000.solverstate
I1004 04:32:52.187238  5017 solver.cpp:593]     Max_acc: 0.930903  with iter: 33000
I1004 04:32:53.811269  5017 solver.cpp:357] Iteration 33000 (0.480511 iter/s, 208.112s/100 iters), loss = 0.0909255
I1004 04:32:53.811326  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0494713 (* 1 = 0.0494713 loss)
I1004 04:32:53.811336  5017 sgd_solver.cpp:165] Iteration 33000, lr = 0.01
I1004 04:35:37.815193  5017 solver.cpp:357] Iteration 33100 (0.609739 iter/s, 164.005s/100 iters), loss = 0.0857977
I1004 04:35:37.815345  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.165843 (* 1 = 0.165843 loss)
I1004 04:35:37.815356  5017 sgd_solver.cpp:165] Iteration 33100, lr = 0.01
I1004 04:38:22.059924  5017 solver.cpp:357] Iteration 33200 (0.608876 iter/s, 164.237s/100 iters), loss = 0.0717887
I1004 04:38:22.060066  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0584483 (* 1 = 0.0584483 loss)
I1004 04:38:22.060076  5017 sgd_solver.cpp:165] Iteration 33200, lr = 0.01
I1004 04:38:24.131450  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 04:41:06.477196  5017 solver.cpp:357] Iteration 33300 (0.608226 iter/s, 164.413s/100 iters), loss = 0.178983
I1004 04:41:06.477288  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.399012 (* 1 = 0.399012 loss)
I1004 04:41:06.477298  5017 sgd_solver.cpp:165] Iteration 33300, lr = 0.01
I1004 04:43:50.939998  5017 solver.cpp:357] Iteration 33400 (0.608049 iter/s, 164.46s/100 iters), loss = 0.0893768
I1004 04:43:50.940099  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0702216 (* 1 = 0.0702216 loss)
I1004 04:43:50.940114  5017 sgd_solver.cpp:165] Iteration 33400, lr = 0.01
I1004 04:46:33.679507  5017 solver.cpp:514] Iteration 33500, Testing net (#0)
I1004 04:47:15.950366  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 04:47:16.116806  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.186833 (* 1 = 0.186833 loss)
I1004 04:47:16.116832  5017 solver.cpp:580]     Test net output #1: prob = 0.938002
I1004 04:47:16.116843  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_33500.caffemodel
I1004 04:47:16.902223  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_33500.solverstate
I1004 04:47:17.207787  5017 solver.cpp:593]     Max_acc: 0.938002  with iter: 33500
I1004 04:47:18.832036  5017 solver.cpp:357] Iteration 33500 (0.48102 iter/s, 207.891s/100 iters), loss = 0.0655208
I1004 04:47:18.832093  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.046061 (* 1 = 0.046061 loss)
I1004 04:47:18.832103  5017 sgd_solver.cpp:165] Iteration 33500, lr = 0.01
I1004 04:49:49.257685  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 04:50:02.807718  5017 solver.cpp:357] Iteration 33600 (0.609844 iter/s, 163.976s/100 iters), loss = 0.13938
I1004 04:50:02.807778  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.128938 (* 1 = 0.128938 loss)
I1004 04:50:02.807788  5017 sgd_solver.cpp:165] Iteration 33600, lr = 0.01
I1004 04:52:47.155768  5017 solver.cpp:357] Iteration 33700 (0.608459 iter/s, 164.35s/100 iters), loss = 0.0815068
I1004 04:52:47.155908  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.115941 (* 1 = 0.115941 loss)
I1004 04:52:47.155918  5017 sgd_solver.cpp:165] Iteration 33700, lr = 0.01
I1004 04:55:31.681813  5017 solver.cpp:357] Iteration 33800 (0.607799 iter/s, 164.528s/100 iters), loss = 0.109835
I1004 04:55:31.681917  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0131602 (* 1 = 0.0131602 loss)
I1004 04:55:31.681931  5017 sgd_solver.cpp:165] Iteration 33800, lr = 0.01
I1004 04:58:16.021889  5017 solver.cpp:357] Iteration 33900 (0.608485 iter/s, 164.343s/100 iters), loss = 0.0746027
I1004 04:58:16.021989  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.067524 (* 1 = 0.067524 loss)
I1004 04:58:16.022001  5017 sgd_solver.cpp:165] Iteration 33900, lr = 0.01
I1004 05:00:31.553793  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 05:00:58.677582  5017 solver.cpp:514] Iteration 34000, Testing net (#0)
I1004 05:01:40.973672  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 05:01:41.140797  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.214211 (* 1 = 0.214211 loss)
I1004 05:01:41.140822  5017 solver.cpp:580]     Test net output #1: prob = 0.931602
I1004 05:01:41.140828  5017 solver.cpp:593]     Max_acc: 0.938002  with iter: 33500
I1004 05:01:42.769892  5017 solver.cpp:357] Iteration 34000 (0.483672 iter/s, 206.752s/100 iters), loss = 0.057326
I1004 05:01:42.769960  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0349925 (* 1 = 0.0349925 loss)
I1004 05:01:42.769971  5017 sgd_solver.cpp:165] Iteration 34000, lr = 0.01
I1004 05:04:27.068845  5017 solver.cpp:357] Iteration 34100 (0.608635 iter/s, 164.302s/100 iters), loss = 0.0861724
I1004 05:04:27.068994  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.174664 (* 1 = 0.174664 loss)
I1004 05:04:27.069008  5017 sgd_solver.cpp:165] Iteration 34100, lr = 0.01
I1004 05:07:11.524561  5017 solver.cpp:357] Iteration 34200 (0.608055 iter/s, 164.459s/100 iters), loss = 0.0982397
I1004 05:07:11.524662  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.157747 (* 1 = 0.157747 loss)
I1004 05:07:11.524673  5017 sgd_solver.cpp:165] Iteration 34200, lr = 0.01
I1004 05:09:55.799629  5017 solver.cpp:357] Iteration 34300 (0.608738 iter/s, 164.274s/100 iters), loss = 0.0619814
I1004 05:09:55.799727  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0412985 (* 1 = 0.0412985 loss)
I1004 05:09:55.799738  5017 sgd_solver.cpp:165] Iteration 34300, lr = 0.01
I1004 05:11:55.860596  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 05:12:40.257124  5017 solver.cpp:357] Iteration 34400 (0.608083 iter/s, 164.451s/100 iters), loss = 0.0953629
I1004 05:12:40.257266  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.017657 (* 1 = 0.017657 loss)
I1004 05:12:40.257277  5017 sgd_solver.cpp:165] Iteration 34400, lr = 0.01
I1004 05:15:23.015705  5017 solver.cpp:514] Iteration 34500, Testing net (#0)
I1004 05:16:05.323638  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 05:16:05.492169  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.204274 (* 1 = 0.204274 loss)
I1004 05:16:05.492195  5017 solver.cpp:580]     Test net output #1: prob = 0.935902
I1004 05:16:05.492202  5017 solver.cpp:593]     Max_acc: 0.938002  with iter: 33500
I1004 05:16:07.121510  5017 solver.cpp:357] Iteration 34500 (0.48342 iter/s, 206.86s/100 iters), loss = 0.0272329
I1004 05:16:07.121564  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0228184 (* 1 = 0.0228184 loss)
I1004 05:16:07.121575  5017 sgd_solver.cpp:165] Iteration 34500, lr = 0.01
I1004 05:18:51.359189  5017 solver.cpp:357] Iteration 34600 (0.608881 iter/s, 164.236s/100 iters), loss = 0.0997879
I1004 05:18:51.359333  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0335816 (* 1 = 0.0335816 loss)
I1004 05:18:51.359344  5017 sgd_solver.cpp:165] Iteration 34600, lr = 0.01
I1004 05:21:35.765825  5017 solver.cpp:357] Iteration 34700 (0.608252 iter/s, 164.406s/100 iters), loss = 0.076044
I1004 05:21:35.765965  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0154841 (* 1 = 0.0154841 loss)
I1004 05:21:35.765975  5017 sgd_solver.cpp:165] Iteration 34700, lr = 0.01
I1004 05:23:20.530817  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 05:24:20.109079  5017 solver.cpp:357] Iteration 34800 (0.608484 iter/s, 164.343s/100 iters), loss = 0.0294792
I1004 05:24:20.109177  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0705286 (* 1 = 0.0705286 loss)
I1004 05:24:20.109189  5017 sgd_solver.cpp:165] Iteration 34800, lr = 0.01
I1004 05:27:04.634165  5017 solver.cpp:357] Iteration 34900 (0.607809 iter/s, 164.525s/100 iters), loss = 0.108084
I1004 05:27:04.634253  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.105478 (* 1 = 0.105478 loss)
I1004 05:27:04.634263  5017 sgd_solver.cpp:165] Iteration 34900, lr = 0.01
I1004 05:29:47.489619  5017 solver.cpp:514] Iteration 35000, Testing net (#0)
I1004 05:30:29.812880  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 05:30:29.980617  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.193075 (* 1 = 0.193075 loss)
I1004 05:30:29.980643  5017 solver.cpp:580]     Test net output #1: prob = 0.940303
I1004 05:30:29.980654  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_35000.caffemodel
I1004 05:30:30.769723  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_35000.solverstate
I1004 05:30:31.074508  5017 solver.cpp:593]     Max_acc: 0.940303  with iter: 35000
I1004 05:30:32.698536  5017 solver.cpp:357] Iteration 35000 (0.480618 iter/s, 208.065s/100 iters), loss = 0.0288469
I1004 05:30:32.698592  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0353143 (* 1 = 0.0353143 loss)
I1004 05:30:32.698604  5017 sgd_solver.cpp:165] Iteration 35000, lr = 0.01
I1004 05:33:16.827443  5017 solver.cpp:357] Iteration 35100 (0.609273 iter/s, 164.13s/100 iters), loss = 0.0803266
I1004 05:33:16.827634  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0119012 (* 1 = 0.0119012 loss)
I1004 05:33:16.827646  5017 sgd_solver.cpp:165] Iteration 35100, lr = 0.01
I1004 05:34:45.970283  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 05:36:01.076606  5017 solver.cpp:357] Iteration 35200 (0.608827 iter/s, 164.25s/100 iters), loss = 0.0818316
I1004 05:36:01.076707  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0572913 (* 1 = 0.0572913 loss)
I1004 05:36:01.076717  5017 sgd_solver.cpp:165] Iteration 35200, lr = 0.01
I1004 05:38:45.285835  5017 solver.cpp:357] Iteration 35300 (0.608974 iter/s, 164.211s/100 iters), loss = 0.0562141
I1004 05:38:45.285936  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.136141 (* 1 = 0.136141 loss)
I1004 05:38:45.285948  5017 sgd_solver.cpp:165] Iteration 35300, lr = 0.01
I1004 05:41:29.530867  5017 solver.cpp:357] Iteration 35400 (0.608841 iter/s, 164.246s/100 iters), loss = 0.0356016
I1004 05:41:29.531008  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0614658 (* 1 = 0.0614658 loss)
I1004 05:41:29.531023  5017 sgd_solver.cpp:165] Iteration 35400, lr = 0.01
I1004 05:44:12.204740  5017 solver.cpp:514] Iteration 35500, Testing net (#0)
I1004 05:44:54.475361  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 05:44:54.643417  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.204857 (* 1 = 0.204857 loss)
I1004 05:44:54.643442  5017 solver.cpp:580]     Test net output #1: prob = 0.937602
I1004 05:44:54.643450  5017 solver.cpp:593]     Max_acc: 0.940303  with iter: 35000
I1004 05:44:56.267341  5017 solver.cpp:357] Iteration 35500 (0.483684 iter/s, 206.747s/100 iters), loss = 0.0478871
I1004 05:44:56.267395  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0325224 (* 1 = 0.0325224 loss)
I1004 05:44:56.267406  5017 sgd_solver.cpp:165] Iteration 35500, lr = 0.01
I1004 05:46:10.174149  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 05:47:40.469519  5017 solver.cpp:357] Iteration 35600 (0.608964 iter/s, 164.213s/100 iters), loss = 0.0382202
I1004 05:47:40.469660  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0239288 (* 1 = 0.0239288 loss)
I1004 05:47:40.469671  5017 sgd_solver.cpp:165] Iteration 35600, lr = 0.01
I1004 05:50:24.820978  5017 solver.cpp:357] Iteration 35700 (0.608419 iter/s, 164.36s/100 iters), loss = 0.0689952
I1004 05:50:24.821077  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0298866 (* 1 = 0.0298866 loss)
I1004 05:50:24.821092  5017 sgd_solver.cpp:165] Iteration 35700, lr = 0.01
I1004 05:53:09.183260  5017 solver.cpp:357] Iteration 35800 (0.608385 iter/s, 164.37s/100 iters), loss = 0.0589745
I1004 05:53:09.183399  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.118631 (* 1 = 0.118631 loss)
I1004 05:53:09.183410  5017 sgd_solver.cpp:165] Iteration 35800, lr = 0.01
I1004 05:55:53.397032  5017 solver.cpp:357] Iteration 35900 (0.60894 iter/s, 164.22s/100 iters), loss = 0.0347563
I1004 05:55:53.397130  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0303269 (* 1 = 0.0303269 loss)
I1004 05:55:53.397140  5017 sgd_solver.cpp:165] Iteration 35900, lr = 0.01
I1004 05:56:51.706395  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 05:58:36.042187  5017 solver.cpp:514] Iteration 36000, Testing net (#0)
I1004 05:59:18.342725  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 05:59:18.511060  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.192902 (* 1 = 0.192902 loss)
I1004 05:59:18.511085  5017 solver.cpp:580]     Test net output #1: prob = 0.939803
I1004 05:59:18.511091  5017 solver.cpp:593]     Max_acc: 0.940303  with iter: 35000
I1004 05:59:20.138259  5017 solver.cpp:357] Iteration 36000 (0.483681 iter/s, 206.748s/100 iters), loss = 0.0611519
I1004 05:59:20.138316  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0366004 (* 1 = 0.0366004 loss)
I1004 05:59:20.138326  5017 sgd_solver.cpp:165] Iteration 36000, lr = 0.01
I1004 06:02:04.266113  5017 solver.cpp:357] Iteration 36100 (0.609264 iter/s, 164.133s/100 iters), loss = 0.079774
I1004 06:02:04.266211  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0496723 (* 1 = 0.0496723 loss)
I1004 06:02:04.266222  5017 sgd_solver.cpp:165] Iteration 36100, lr = 0.01
I1004 06:04:48.521963  5017 solver.cpp:357] Iteration 36200 (0.608791 iter/s, 164.26s/100 iters), loss = 0.0163892
I1004 06:04:48.522063  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0275611 (* 1 = 0.0275611 loss)
I1004 06:04:48.522074  5017 sgd_solver.cpp:165] Iteration 36200, lr = 0.01
I1004 06:07:32.973415  5017 solver.cpp:357] Iteration 36300 (0.608068 iter/s, 164.455s/100 iters), loss = 0.0904822
I1004 06:07:32.973549  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0522627 (* 1 = 0.0522627 loss)
I1004 06:07:32.973561  5017 sgd_solver.cpp:165] Iteration 36300, lr = 0.01
I1004 06:08:16.123262  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 06:10:17.311754  5017 solver.cpp:357] Iteration 36400 (0.608487 iter/s, 164.342s/100 iters), loss = 0.0381015
I1004 06:10:17.311892  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.058757 (* 1 = 0.058757 loss)
I1004 06:10:17.311903  5017 sgd_solver.cpp:165] Iteration 36400, lr = 0.01
I1004 06:12:59.974269  5017 solver.cpp:514] Iteration 36500, Testing net (#0)
I1004 06:13:42.193770  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 06:13:42.362241  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.212719 (* 1 = 0.212719 loss)
I1004 06:13:42.362265  5017 solver.cpp:580]     Test net output #1: prob = 0.938702
I1004 06:13:42.362272  5017 solver.cpp:593]     Max_acc: 0.940303  with iter: 35000
I1004 06:13:43.990495  5017 solver.cpp:357] Iteration 36500 (0.483832 iter/s, 206.683s/100 iters), loss = 0.0422763
I1004 06:13:43.990550  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0186674 (* 1 = 0.0186674 loss)
I1004 06:13:43.990562  5017 sgd_solver.cpp:165] Iteration 36500, lr = 0.01
I1004 06:16:28.198220  5017 solver.cpp:357] Iteration 36600 (0.608972 iter/s, 164.211s/100 iters), loss = 0.0383246
I1004 06:16:28.198361  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0522788 (* 1 = 0.0522788 loss)
I1004 06:16:28.198371  5017 sgd_solver.cpp:165] Iteration 36600, lr = 0.01
I1004 06:19:12.432571  5017 solver.cpp:357] Iteration 36700 (0.608866 iter/s, 164.24s/100 iters), loss = 0.0445772
I1004 06:19:12.432714  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0126017 (* 1 = 0.0126017 loss)
I1004 06:19:12.432725  5017 sgd_solver.cpp:165] Iteration 36700, lr = 0.01
I1004 06:19:39.950464  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 06:21:56.650091  5017 solver.cpp:357] Iteration 36800 (0.608928 iter/s, 164.223s/100 iters), loss = 0.0525068
I1004 06:21:56.650228  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0172218 (* 1 = 0.0172218 loss)
I1004 06:21:56.650238  5017 sgd_solver.cpp:165] Iteration 36800, lr = 0.01
I1004 06:24:40.916769  5017 solver.cpp:357] Iteration 36900 (0.608748 iter/s, 164.272s/100 iters), loss = 0.0367399
I1004 06:24:40.916903  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0564207 (* 1 = 0.0564207 loss)
I1004 06:24:40.916913  5017 sgd_solver.cpp:165] Iteration 36900, lr = 0.01
I1004 06:27:23.598933  5017 solver.cpp:514] Iteration 37000, Testing net (#0)
I1004 06:28:05.894450  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 06:28:06.063082  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.207309 (* 1 = 0.207309 loss)
I1004 06:28:06.063108  5017 solver.cpp:580]     Test net output #1: prob = 0.939302
I1004 06:28:06.063114  5017 solver.cpp:593]     Max_acc: 0.940303  with iter: 35000
I1004 06:28:07.694260  5017 solver.cpp:357] Iteration 37000 (0.483598 iter/s, 206.783s/100 iters), loss = 0.0552937
I1004 06:28:07.694316  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00911144 (* 1 = 0.00911144 loss)
I1004 06:28:07.694326  5017 sgd_solver.cpp:165] Iteration 37000, lr = 0.01
I1004 06:30:51.886103  5017 solver.cpp:357] Iteration 37100 (0.609028 iter/s, 164.196s/100 iters), loss = 0.0260969
I1004 06:30:51.886248  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0143577 (* 1 = 0.0143577 loss)
I1004 06:30:51.886260  5017 sgd_solver.cpp:165] Iteration 37100, lr = 0.01
I1004 06:31:04.216030  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 06:33:36.191747  5017 solver.cpp:357] Iteration 37200 (0.608607 iter/s, 164.31s/100 iters), loss = 0.0679993
I1004 06:33:36.191885  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.146861 (* 1 = 0.146861 loss)
I1004 06:33:36.191895  5017 sgd_solver.cpp:165] Iteration 37200, lr = 0.01
I1004 06:36:20.525323  5017 solver.cpp:357] Iteration 37300 (0.608504 iter/s, 164.338s/100 iters), loss = 0.0749157
I1004 06:36:20.525467  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0216545 (* 1 = 0.0216545 loss)
I1004 06:36:20.525478  5017 sgd_solver.cpp:165] Iteration 37300, lr = 0.01
I1004 06:39:04.786543  5017 solver.cpp:357] Iteration 37400 (0.608772 iter/s, 164.265s/100 iters), loss = 0.0374579
I1004 06:39:04.786638  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0463614 (* 1 = 0.0463614 loss)
I1004 06:39:04.786648  5017 sgd_solver.cpp:165] Iteration 37400, lr = 0.01
I1004 06:41:45.839376  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 06:41:47.480792  5017 solver.cpp:514] Iteration 37500, Testing net (#0)
I1004 06:42:29.746824  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 06:42:29.914383  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.207382 (* 1 = 0.207382 loss)
I1004 06:42:29.914408  5017 solver.cpp:580]     Test net output #1: prob = 0.938702
I1004 06:42:29.914414  5017 solver.cpp:593]     Max_acc: 0.940303  with iter: 35000
I1004 06:42:31.542754  5017 solver.cpp:357] Iteration 37500 (0.48365 iter/s, 206.761s/100 iters), loss = 0.0340137
I1004 06:42:31.542810  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0950423 (* 1 = 0.0950423 loss)
I1004 06:42:31.542826  5017 sgd_solver.cpp:165] Iteration 37500, lr = 0.01
I1004 06:45:15.774796  5017 solver.cpp:357] Iteration 37600 (0.608881 iter/s, 164.236s/100 iters), loss = 0.0260048
I1004 06:45:15.774894  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0356341 (* 1 = 0.0356341 loss)
I1004 06:45:15.774909  5017 sgd_solver.cpp:165] Iteration 37600, lr = 0.01
I1004 06:48:00.138849  5017 solver.cpp:357] Iteration 37700 (0.608392 iter/s, 164.368s/100 iters), loss = 0.0552275
I1004 06:48:00.138994  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0261211 (* 1 = 0.0261211 loss)
I1004 06:48:00.139004  5017 sgd_solver.cpp:165] Iteration 37700, lr = 0.01
I1004 06:50:44.433326  5017 solver.cpp:357] Iteration 37800 (0.60865 iter/s, 164.298s/100 iters), loss = 0.0105633
I1004 06:50:44.433441  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0244713 (* 1 = 0.0244713 loss)
I1004 06:50:44.433455  5017 sgd_solver.cpp:165] Iteration 37800, lr = 0.01
I1004 06:53:10.262846  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 06:53:28.734171  5017 solver.cpp:357] Iteration 37900 (0.608613 iter/s, 164.308s/100 iters), loss = 0.0513835
I1004 06:53:28.734231  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.022725 (* 1 = 0.022725 loss)
I1004 06:53:28.734242  5017 sgd_solver.cpp:165] Iteration 37900, lr = 0.01
I1004 06:56:11.435752  5017 solver.cpp:514] Iteration 38000, Testing net (#0)
I1004 06:56:53.723078  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 06:56:53.891070  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.256789 (* 1 = 0.256789 loss)
I1004 06:56:53.891096  5017 solver.cpp:580]     Test net output #1: prob = 0.931602
I1004 06:56:53.891103  5017 solver.cpp:593]     Max_acc: 0.940303  with iter: 35000
I1004 06:56:55.517587  5017 solver.cpp:357] Iteration 38000 (0.483577 iter/s, 206.792s/100 iters), loss = 0.0391406
I1004 06:56:55.517642  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00567618 (* 1 = 0.00567618 loss)
I1004 06:56:55.517653  5017 sgd_solver.cpp:165] Iteration 38000, lr = 0.01
I1004 06:59:39.719511  5017 solver.cpp:357] Iteration 38100 (0.608983 iter/s, 164.208s/100 iters), loss = 0.033708
I1004 06:59:39.719609  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0276772 (* 1 = 0.0276772 loss)
I1004 06:59:39.719619  5017 sgd_solver.cpp:165] Iteration 38100, lr = 0.01
I1004 07:02:24.172503  5017 solver.cpp:357] Iteration 38200 (0.608056 iter/s, 164.459s/100 iters), loss = 0.0370734
I1004 07:02:24.172652  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0223607 (* 1 = 0.0223607 loss)
I1004 07:02:24.172662  5017 sgd_solver.cpp:165] Iteration 38200, lr = 0.01
I1004 07:04:34.409359  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 07:05:08.502766  5017 solver.cpp:357] Iteration 38300 (0.608511 iter/s, 164.335s/100 iters), loss = 0.0441658
I1004 07:05:08.502897  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0847963 (* 1 = 0.0847963 loss)
I1004 07:05:08.502907  5017 sgd_solver.cpp:165] Iteration 38300, lr = 0.01
I1004 07:07:52.830138  5017 solver.cpp:357] Iteration 38400 (0.608523 iter/s, 164.332s/100 iters), loss = 0.0452417
I1004 07:07:52.830276  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0425903 (* 1 = 0.0425903 loss)
I1004 07:07:52.830287  5017 sgd_solver.cpp:165] Iteration 38400, lr = 0.01
I1004 07:10:35.482147  5017 solver.cpp:514] Iteration 38500, Testing net (#0)
I1004 07:11:17.776479  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 07:11:17.945080  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.224325 (* 1 = 0.224325 loss)
I1004 07:11:17.945106  5017 solver.cpp:580]     Test net output #1: prob = 0.938302
I1004 07:11:17.945112  5017 solver.cpp:593]     Max_acc: 0.940303  with iter: 35000
I1004 07:11:19.572943  5017 solver.cpp:357] Iteration 38500 (0.483679 iter/s, 206.749s/100 iters), loss = 0.0722305
I1004 07:11:19.572999  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0741549 (* 1 = 0.0741549 loss)
I1004 07:11:19.573014  5017 sgd_solver.cpp:165] Iteration 38500, lr = 0.01
I1004 07:14:03.752197  5017 solver.cpp:357] Iteration 38600 (0.609073 iter/s, 164.184s/100 iters), loss = 0.0170308
I1004 07:14:03.752285  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00517121 (* 1 = 0.00517121 loss)
I1004 07:14:03.752296  5017 sgd_solver.cpp:165] Iteration 38600, lr = 0.01
I1004 07:15:58.860096  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 07:16:48.222504  5017 solver.cpp:357] Iteration 38700 (0.607996 iter/s, 164.475s/100 iters), loss = 0.0483134
I1004 07:16:48.222646  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0523558 (* 1 = 0.0523558 loss)
I1004 07:16:48.222656  5017 sgd_solver.cpp:165] Iteration 38700, lr = 0.01
I1004 07:19:32.630800  5017 solver.cpp:357] Iteration 38800 (0.608226 iter/s, 164.413s/100 iters), loss = 0.0490088
I1004 07:19:32.630934  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.108633 (* 1 = 0.108633 loss)
I1004 07:19:32.630944  5017 sgd_solver.cpp:165] Iteration 38800, lr = 0.01
I1004 07:22:16.938768  5017 solver.cpp:357] Iteration 38900 (0.608597 iter/s, 164.312s/100 iters), loss = 0.0428147
I1004 07:22:16.938911  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0142959 (* 1 = 0.0142959 loss)
I1004 07:22:16.938922  5017 sgd_solver.cpp:165] Iteration 38900, lr = 0.01
I1004 07:24:59.627084  5017 solver.cpp:514] Iteration 39000, Testing net (#0)
I1004 07:25:41.947149  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 07:25:42.115480  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.206484 (* 1 = 0.206484 loss)
I1004 07:25:42.115505  5017 solver.cpp:580]     Test net output #1: prob = 0.942203
I1004 07:25:42.115517  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_39000.caffemodel
I1004 07:25:42.906018  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_39000.solverstate
I1004 07:25:43.210538  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 07:25:44.835058  5017 solver.cpp:357] Iteration 39000 (0.480994 iter/s, 207.903s/100 iters), loss = 0.0154594
I1004 07:25:44.835115  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0236994 (* 1 = 0.0236994 loss)
I1004 07:25:44.835129  5017 sgd_solver.cpp:165] Iteration 39000, lr = 0.01
I1004 07:27:24.090925  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 07:28:28.931581  5017 solver.cpp:357] Iteration 39100 (0.609347 iter/s, 164.11s/100 iters), loss = 0.0256261
I1004 07:28:28.931679  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00315821 (* 1 = 0.00315821 loss)
I1004 07:28:28.931690  5017 sgd_solver.cpp:165] Iteration 39100, lr = 0.01
I1004 07:31:13.133009  5017 solver.cpp:357] Iteration 39200 (0.608966 iter/s, 164.213s/100 iters), loss = 0.0322649
I1004 07:31:13.133157  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0402524 (* 1 = 0.0402524 loss)
I1004 07:31:13.133167  5017 sgd_solver.cpp:165] Iteration 39200, lr = 0.01
I1004 07:33:57.572235  5017 solver.cpp:357] Iteration 39300 (0.608091 iter/s, 164.449s/100 iters), loss = 0.0256523
I1004 07:33:57.572384  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.02837 (* 1 = 0.02837 loss)
I1004 07:33:57.572394  5017 sgd_solver.cpp:165] Iteration 39300, lr = 0.01
I1004 07:36:41.841765  5017 solver.cpp:357] Iteration 39400 (0.608723 iter/s, 164.278s/100 iters), loss = 0.0334836
I1004 07:36:41.841908  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0117298 (* 1 = 0.0117298 loss)
I1004 07:36:41.841922  5017 sgd_solver.cpp:165] Iteration 39400, lr = 0.01
I1004 07:38:06.128670  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 07:39:24.643434  5017 solver.cpp:514] Iteration 39500, Testing net (#0)
I1004 07:40:06.915891  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 07:40:07.083199  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.215334 (* 1 = 0.215334 loss)
I1004 07:40:07.083223  5017 solver.cpp:580]     Test net output #1: prob = 0.940502
I1004 07:40:07.083230  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 07:40:08.706764  5017 solver.cpp:357] Iteration 39500 (0.483384 iter/s, 206.875s/100 iters), loss = 0.0484399
I1004 07:40:08.706820  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0136022 (* 1 = 0.0136022 loss)
I1004 07:40:08.706835  5017 sgd_solver.cpp:165] Iteration 39500, lr = 0.01
I1004 07:42:52.922274  5017 solver.cpp:357] Iteration 39600 (0.608929 iter/s, 164.223s/100 iters), loss = 0.0430381
I1004 07:42:52.922417  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0848194 (* 1 = 0.0848194 loss)
I1004 07:42:52.922427  5017 sgd_solver.cpp:165] Iteration 39600, lr = 0.01
I1004 07:45:37.321754  5017 solver.cpp:357] Iteration 39700 (0.608249 iter/s, 164.406s/100 iters), loss = 0.0193038
I1004 07:45:37.321859  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00521836 (* 1 = 0.00521836 loss)
I1004 07:45:37.321869  5017 sgd_solver.cpp:165] Iteration 39700, lr = 0.01
I1004 07:48:21.647155  5017 solver.cpp:357] Iteration 39800 (0.608524 iter/s, 164.332s/100 iters), loss = 0.017694
I1004 07:48:21.647294  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0279481 (* 1 = 0.0279481 loss)
I1004 07:48:21.647305  5017 sgd_solver.cpp:165] Iteration 39800, lr = 0.01
I1004 07:49:30.284224  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 07:51:05.966861  5017 solver.cpp:357] Iteration 39900 (0.608546 iter/s, 164.326s/100 iters), loss = 0.0184859
I1004 07:51:05.966962  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0283567 (* 1 = 0.0283567 loss)
I1004 07:51:05.966971  5017 sgd_solver.cpp:165] Iteration 39900, lr = 0.01
I1004 07:53:48.686640  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_40000.caffemodel
I1004 07:53:49.484163  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_40000.solverstate
I1004 07:53:49.792253  5017 solver.cpp:514] Iteration 40000, Testing net (#0)
I1004 07:54:32.071780  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 07:54:32.238827  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.242629 (* 1 = 0.242629 loss)
I1004 07:54:32.238852  5017 solver.cpp:580]     Test net output #1: prob = 0.935503
I1004 07:54:32.238858  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 07:54:33.865209  5017 solver.cpp:357] Iteration 40000 (0.480986 iter/s, 207.906s/100 iters), loss = 0.0303471
I1004 07:54:33.865264  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0114593 (* 1 = 0.0114593 loss)
I1004 07:54:33.865274  5017 sgd_solver.cpp:165] Iteration 40000, lr = 0.01
I1004 07:57:18.037930  5017 solver.cpp:357] Iteration 40100 (0.609092 iter/s, 164.179s/100 iters), loss = 0.0315011
I1004 07:57:18.038064  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0563084 (* 1 = 0.0563084 loss)
I1004 07:57:18.038075  5017 sgd_solver.cpp:165] Iteration 40100, lr = 0.01
I1004 08:00:02.446725  5017 solver.cpp:357] Iteration 40200 (0.608223 iter/s, 164.413s/100 iters), loss = 0.0647945
I1004 08:00:02.446861  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00973614 (* 1 = 0.00973614 loss)
I1004 08:00:02.446871  5017 sgd_solver.cpp:165] Iteration 40200, lr = 0.01
I1004 08:00:55.844976  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 08:02:46.692245  5017 solver.cpp:357] Iteration 40300 (0.608853 iter/s, 164.243s/100 iters), loss = 0.0169026
I1004 08:02:46.692386  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00786066 (* 1 = 0.00786066 loss)
I1004 08:02:46.692397  5017 sgd_solver.cpp:165] Iteration 40300, lr = 0.01
I1004 08:05:31.066857  5017 solver.cpp:357] Iteration 40400 (0.608368 iter/s, 164.374s/100 iters), loss = 0.075913
I1004 08:05:31.066957  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.139866 (* 1 = 0.139866 loss)
I1004 08:05:31.066972  5017 sgd_solver.cpp:165] Iteration 40400, lr = 0.01
I1004 08:08:13.761782  5017 solver.cpp:514] Iteration 40500, Testing net (#0)
I1004 08:08:56.053377  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 08:08:56.223088  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.244144 (* 1 = 0.244144 loss)
I1004 08:08:56.223111  5017 solver.cpp:580]     Test net output #1: prob = 0.937302
I1004 08:08:56.223119  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 08:08:57.851420  5017 solver.cpp:357] Iteration 40500 (0.483592 iter/s, 206.786s/100 iters), loss = 0.0105621
I1004 08:08:57.851475  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00961935 (* 1 = 0.00961935 loss)
I1004 08:08:57.851486  5017 sgd_solver.cpp:165] Iteration 40500, lr = 0.01
I1004 08:11:42.117411  5017 solver.cpp:357] Iteration 40600 (0.608761 iter/s, 164.268s/100 iters), loss = 0.0340706
I1004 08:11:42.117554  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0528878 (* 1 = 0.0528878 loss)
I1004 08:11:42.117564  5017 sgd_solver.cpp:165] Iteration 40600, lr = 0.01
I1004 08:12:19.946979  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 08:14:26.706254  5017 solver.cpp:357] Iteration 40700 (0.607565 iter/s, 164.592s/100 iters), loss = 0.0323986
I1004 08:14:26.706393  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0452585 (* 1 = 0.0452585 loss)
I1004 08:14:26.706408  5017 sgd_solver.cpp:165] Iteration 40700, lr = 0.01
I1004 08:17:11.175343  5017 solver.cpp:357] Iteration 40800 (0.608005 iter/s, 164.472s/100 iters), loss = 0.0562685
I1004 08:17:11.175489  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.039524 (* 1 = 0.039524 loss)
I1004 08:17:11.175500  5017 sgd_solver.cpp:165] Iteration 40800, lr = 0.01
I1004 08:19:55.753561  5017 solver.cpp:357] Iteration 40900 (0.607601 iter/s, 164.582s/100 iters), loss = 0.0433213
I1004 08:19:55.753703  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0192855 (* 1 = 0.0192855 loss)
I1004 08:19:55.753713  5017 sgd_solver.cpp:165] Iteration 40900, lr = 0.01
I1004 08:22:38.678695  5017 solver.cpp:514] Iteration 41000, Testing net (#0)
I1004 08:23:20.977735  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 08:23:21.146886  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.244557 (* 1 = 0.244557 loss)
I1004 08:23:21.146911  5017 solver.cpp:580]     Test net output #1: prob = 0.933402
I1004 08:23:21.146917  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 08:23:22.774864  5017 solver.cpp:357] Iteration 41000 (0.483031 iter/s, 207.026s/100 iters), loss = 0.0256223
I1004 08:23:22.774921  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0284462 (* 1 = 0.0284462 loss)
I1004 08:23:22.774931  5017 sgd_solver.cpp:165] Iteration 41000, lr = 0.01
I1004 08:23:45.327164  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 08:26:07.083026  5017 solver.cpp:357] Iteration 41100 (0.608598 iter/s, 164.312s/100 iters), loss = 0.0577345
I1004 08:26:07.083127  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.093525 (* 1 = 0.093525 loss)
I1004 08:26:07.083137  5017 sgd_solver.cpp:165] Iteration 41100, lr = 0.01
I1004 08:28:51.531582  5017 solver.cpp:357] Iteration 41200 (0.608078 iter/s, 164.453s/100 iters), loss = 0.0304777
I1004 08:28:51.531714  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0145934 (* 1 = 0.0145934 loss)
I1004 08:28:51.531725  5017 sgd_solver.cpp:165] Iteration 41200, lr = 0.01
I1004 08:31:35.877652  5017 solver.cpp:357] Iteration 41300 (0.608457 iter/s, 164.35s/100 iters), loss = 0.0152199
I1004 08:31:35.877776  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0438143 (* 1 = 0.0438143 loss)
I1004 08:31:35.877791  5017 sgd_solver.cpp:165] Iteration 41300, lr = 0.01
I1004 08:34:20.495239  5017 solver.cpp:357] Iteration 41400 (0.60747 iter/s, 164.617s/100 iters), loss = 0.021549
I1004 08:34:20.495379  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0223831 (* 1 = 0.0223831 loss)
I1004 08:34:20.495394  5017 sgd_solver.cpp:165] Iteration 41400, lr = 0.01
I1004 08:34:27.504294  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 08:37:03.417695  5017 solver.cpp:514] Iteration 41500, Testing net (#0)
I1004 08:37:45.725183  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 08:37:45.892799  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.262512 (* 1 = 0.262512 loss)
I1004 08:37:45.892825  5017 solver.cpp:580]     Test net output #1: prob = 0.931203
I1004 08:37:45.892832  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 08:37:47.519439  5017 solver.cpp:357] Iteration 41500 (0.483076 iter/s, 207.007s/100 iters), loss = 0.0152331
I1004 08:37:47.519495  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0285244 (* 1 = 0.0285244 loss)
I1004 08:37:47.519505  5017 sgd_solver.cpp:165] Iteration 41500, lr = 0.01
I1004 08:40:31.953027  5017 solver.cpp:357] Iteration 41600 (0.608182 iter/s, 164.425s/100 iters), loss = 0.0211406
I1004 08:40:31.953125  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0147364 (* 1 = 0.0147364 loss)
I1004 08:40:31.953136  5017 sgd_solver.cpp:165] Iteration 41600, lr = 0.01
I1004 08:43:16.492187  5017 solver.cpp:357] Iteration 41700 (0.60778 iter/s, 164.533s/100 iters), loss = 0.0360397
I1004 08:43:16.492285  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0336107 (* 1 = 0.0336107 loss)
I1004 08:43:16.492295  5017 sgd_solver.cpp:165] Iteration 41700, lr = 0.01
I1004 08:45:52.727953  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 08:46:00.927978  5017 solver.cpp:357] Iteration 41800 (0.608154 iter/s, 164.432s/100 iters), loss = 0.0482185
I1004 08:46:00.928038  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0168123 (* 1 = 0.0168123 loss)
I1004 08:46:00.928048  5017 sgd_solver.cpp:165] Iteration 41800, lr = 0.01
I1004 08:48:45.293567  5017 solver.cpp:357] Iteration 41900 (0.608408 iter/s, 164.363s/100 iters), loss = 0.0565514
I1004 08:48:45.293720  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0570808 (* 1 = 0.0570808 loss)
I1004 08:48:45.293730  5017 sgd_solver.cpp:165] Iteration 41900, lr = 0.01
I1004 08:51:27.957504  5017 solver.cpp:514] Iteration 42000, Testing net (#0)
I1004 08:52:10.257839  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 08:52:10.425153  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.265566 (* 1 = 0.265566 loss)
I1004 08:52:10.425179  5017 solver.cpp:580]     Test net output #1: prob = 0.929402
I1004 08:52:10.425184  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 08:52:12.057121  5017 solver.cpp:357] Iteration 42000 (0.483647 iter/s, 206.762s/100 iters), loss = 0.0456158
I1004 08:52:12.057176  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0536558 (* 1 = 0.0536558 loss)
I1004 08:52:12.057189  5017 sgd_solver.cpp:165] Iteration 42000, lr = 0.01
I1004 08:54:56.167683  5017 solver.cpp:357] Iteration 42100 (0.609346 iter/s, 164.11s/100 iters), loss = 0.0122522
I1004 08:54:56.167824  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00953068 (* 1 = 0.00953068 loss)
I1004 08:54:56.167834  5017 sgd_solver.cpp:165] Iteration 42100, lr = 0.01
I1004 08:57:16.584457  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 08:57:40.381525  5017 solver.cpp:357] Iteration 42200 (0.608961 iter/s, 164.214s/100 iters), loss = 0.0214584
I1004 08:57:40.381585  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00547039 (* 1 = 0.00547039 loss)
I1004 08:57:40.381599  5017 sgd_solver.cpp:165] Iteration 42200, lr = 0.01
I1004 09:00:24.632030  5017 solver.cpp:357] Iteration 42300 (0.608823 iter/s, 164.251s/100 iters), loss = 0.0300191
I1004 09:00:24.632169  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00580532 (* 1 = 0.00580532 loss)
I1004 09:00:24.632179  5017 sgd_solver.cpp:165] Iteration 42300, lr = 0.01
I1004 09:03:08.770725  5017 solver.cpp:357] Iteration 42400 (0.609237 iter/s, 164.14s/100 iters), loss = 0.0227189
I1004 09:03:08.770859  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0158797 (* 1 = 0.0158797 loss)
I1004 09:03:08.770869  5017 sgd_solver.cpp:165] Iteration 42400, lr = 0.01
I1004 09:05:51.342147  5017 solver.cpp:514] Iteration 42500, Testing net (#0)
I1004 09:06:33.620507  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 09:06:33.789229  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.231459 (* 1 = 0.231459 loss)
I1004 09:06:33.789254  5017 solver.cpp:580]     Test net output #1: prob = 0.934603
I1004 09:06:33.789261  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 09:06:35.415668  5017 solver.cpp:357] Iteration 42500 (0.483918 iter/s, 206.647s/100 iters), loss = 0.0385284
I1004 09:06:35.415721  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.051233 (* 1 = 0.051233 loss)
I1004 09:06:35.415735  5017 sgd_solver.cpp:165] Iteration 42500, lr = 0.01
I1004 09:08:40.633298  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 09:09:19.624231  5017 solver.cpp:357] Iteration 42600 (0.608962 iter/s, 164.214s/100 iters), loss = 0.0400733
I1004 09:09:19.624328  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00644053 (* 1 = 0.00644053 loss)
I1004 09:09:19.624338  5017 sgd_solver.cpp:165] Iteration 42600, lr = 0.01
I1004 09:12:03.838021  5017 solver.cpp:357] Iteration 42700 (0.608935 iter/s, 164.221s/100 iters), loss = 0.0315663
I1004 09:12:03.838107  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0664237 (* 1 = 0.0664237 loss)
I1004 09:12:03.838119  5017 sgd_solver.cpp:165] Iteration 42700, lr = 0.01
I1004 09:14:48.034271  5017 solver.cpp:357] Iteration 42800 (0.609005 iter/s, 164.202s/100 iters), loss = 0.0513293
I1004 09:14:48.034421  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.149268 (* 1 = 0.149268 loss)
I1004 09:14:48.034432  5017 sgd_solver.cpp:165] Iteration 42800, lr = 0.01
I1004 09:17:32.225908  5017 solver.cpp:357] Iteration 42900 (0.609026 iter/s, 164.197s/100 iters), loss = 0.0146419
I1004 09:17:32.226052  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0116788 (* 1 = 0.0116788 loss)
I1004 09:17:32.226063  5017 sgd_solver.cpp:165] Iteration 42900, lr = 0.01
I1004 09:19:21.819470  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 09:20:14.787345  5017 solver.cpp:514] Iteration 43000, Testing net (#0)
I1004 09:20:57.086607  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 09:20:57.253361  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.236761 (* 1 = 0.236761 loss)
I1004 09:20:57.253386  5017 solver.cpp:580]     Test net output #1: prob = 0.935103
I1004 09:20:57.253392  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 09:20:58.878911  5017 solver.cpp:357] Iteration 43000 (0.48389 iter/s, 206.658s/100 iters), loss = 0.0441044
I1004 09:20:58.878965  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00410221 (* 1 = 0.00410221 loss)
I1004 09:20:58.878976  5017 sgd_solver.cpp:165] Iteration 43000, lr = 0.01
I1004 09:23:43.046845  5017 solver.cpp:357] Iteration 43100 (0.609118 iter/s, 164.172s/100 iters), loss = 0.0346371
I1004 09:23:43.046983  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00344418 (* 1 = 0.00344418 loss)
I1004 09:23:43.046994  5017 sgd_solver.cpp:165] Iteration 43100, lr = 0.01
I1004 09:26:27.363767  5017 solver.cpp:357] Iteration 43200 (0.608567 iter/s, 164.32s/100 iters), loss = 0.0356208
I1004 09:26:27.363867  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0200501 (* 1 = 0.0200501 loss)
I1004 09:26:27.363876  5017 sgd_solver.cpp:165] Iteration 43200, lr = 0.01
I1004 09:29:11.429102  5017 solver.cpp:357] Iteration 43300 (0.609501 iter/s, 164.069s/100 iters), loss = 0.0163201
I1004 09:29:11.429241  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0174451 (* 1 = 0.0174451 loss)
I1004 09:29:11.429256  5017 sgd_solver.cpp:165] Iteration 43300, lr = 0.01
I1004 09:30:45.806962  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 09:31:55.689429  5017 solver.cpp:357] Iteration 43400 (0.608778 iter/s, 164.263s/100 iters), loss = 0.0504462
I1004 09:31:55.689527  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0104365 (* 1 = 0.0104365 loss)
I1004 09:31:55.689538  5017 sgd_solver.cpp:165] Iteration 43400, lr = 0.01
I1004 09:34:38.276973  5017 solver.cpp:514] Iteration 43500, Testing net (#0)
I1004 09:35:20.541497  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 09:35:20.710259  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.260887 (* 1 = 0.260887 loss)
I1004 09:35:20.710285  5017 solver.cpp:580]     Test net output #1: prob = 0.931402
I1004 09:35:20.710291  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 09:35:22.332273  5017 solver.cpp:357] Iteration 43500 (0.483918 iter/s, 206.647s/100 iters), loss = 0.0255125
I1004 09:35:22.332327  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0198871 (* 1 = 0.0198871 loss)
I1004 09:35:22.332337  5017 sgd_solver.cpp:165] Iteration 43500, lr = 0.01
I1004 09:38:06.439183  5017 solver.cpp:357] Iteration 43600 (0.609348 iter/s, 164.11s/100 iters), loss = 0.0328172
I1004 09:38:06.439275  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00414595 (* 1 = 0.00414595 loss)
I1004 09:38:06.439286  5017 sgd_solver.cpp:165] Iteration 43600, lr = 0.01
I1004 09:40:50.805866  5017 solver.cpp:357] Iteration 43700 (0.608385 iter/s, 164.37s/100 iters), loss = 0.0419572
I1004 09:40:50.805970  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.041907 (* 1 = 0.041907 loss)
I1004 09:40:50.805981  5017 sgd_solver.cpp:165] Iteration 43700, lr = 0.01
I1004 09:42:09.664095  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 09:43:35.067886  5017 solver.cpp:357] Iteration 43800 (0.608723 iter/s, 164.278s/100 iters), loss = 0.0360085
I1004 09:43:35.067982  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00320251 (* 1 = 0.00320251 loss)
I1004 09:43:35.067993  5017 sgd_solver.cpp:165] Iteration 43800, lr = 0.01
I1004 09:46:19.286377  5017 solver.cpp:357] Iteration 43900 (0.608862 iter/s, 164.241s/100 iters), loss = 0.108322
I1004 09:46:19.286471  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.321897 (* 1 = 0.321897 loss)
I1004 09:46:19.286481  5017 sgd_solver.cpp:165] Iteration 43900, lr = 0.01
I1004 09:49:01.857416  5017 solver.cpp:514] Iteration 44000, Testing net (#0)
I1004 09:49:44.148259  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 09:49:44.317111  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.238442 (* 1 = 0.238442 loss)
I1004 09:49:44.317137  5017 solver.cpp:580]     Test net output #1: prob = 0.934502
I1004 09:49:44.317142  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 09:49:45.944713  5017 solver.cpp:357] Iteration 44000 (0.483838 iter/s, 206.681s/100 iters), loss = 0.0206934
I1004 09:49:45.944768  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0173252 (* 1 = 0.0173252 loss)
I1004 09:49:45.944779  5017 sgd_solver.cpp:165] Iteration 44000, lr = 0.01
I1004 09:52:30.054278  5017 solver.cpp:357] Iteration 44100 (0.609296 iter/s, 164.124s/100 iters), loss = 0.056654
I1004 09:52:30.054373  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.014304 (* 1 = 0.014304 loss)
I1004 09:52:30.054385  5017 sgd_solver.cpp:165] Iteration 44100, lr = 0.01
I1004 09:53:33.685894  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 09:55:14.261229  5017 solver.cpp:357] Iteration 44200 (0.608942 iter/s, 164.219s/100 iters), loss = 0.0247449
I1004 09:55:14.261324  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0173527 (* 1 = 0.0173527 loss)
I1004 09:55:14.261334  5017 sgd_solver.cpp:165] Iteration 44200, lr = 0.01
I1004 09:57:58.336690  5017 solver.cpp:357] Iteration 44300 (0.609436 iter/s, 164.086s/100 iters), loss = 0.0478272
I1004 09:57:58.336830  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.111911 (* 1 = 0.111911 loss)
I1004 09:57:58.336841  5017 sgd_solver.cpp:165] Iteration 44300, lr = 0.01
I1004 10:00:42.490577  5017 solver.cpp:357] Iteration 44400 (0.609149 iter/s, 164.163s/100 iters), loss = 0.0202535
I1004 10:00:42.490674  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.013222 (* 1 = 0.013222 loss)
I1004 10:00:42.490685  5017 sgd_solver.cpp:165] Iteration 44400, lr = 0.01
I1004 10:03:24.994596  5017 solver.cpp:514] Iteration 44500, Testing net (#0)
I1004 10:04:07.292614  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 10:04:07.461448  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.245273 (* 1 = 0.245273 loss)
I1004 10:04:07.461473  5017 solver.cpp:580]     Test net output #1: prob = 0.932802
I1004 10:04:07.461479  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 10:04:09.087121  5017 solver.cpp:357] Iteration 44500 (0.484009 iter/s, 206.608s/100 iters), loss = 0.0132683
I1004 10:04:09.087175  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0271493 (* 1 = 0.0271493 loss)
I1004 10:04:09.087188  5017 sgd_solver.cpp:165] Iteration 44500, lr = 0.01
I1004 10:04:57.142278  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 10:06:53.297358  5017 solver.cpp:357] Iteration 44600 (0.608945 iter/s, 164.218s/100 iters), loss = 0.0547257
I1004 10:06:53.297513  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0135262 (* 1 = 0.0135262 loss)
I1004 10:06:53.297523  5017 sgd_solver.cpp:165] Iteration 44600, lr = 0.01
I1004 10:09:37.497478  5017 solver.cpp:357] Iteration 44700 (0.608984 iter/s, 164.208s/100 iters), loss = 0.0316129
I1004 10:09:37.497572  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0100313 (* 1 = 0.0100313 loss)
I1004 10:09:37.497583  5017 sgd_solver.cpp:165] Iteration 44700, lr = 0.01
I1004 10:12:21.641667  5017 solver.cpp:357] Iteration 44800 (0.609193 iter/s, 164.152s/100 iters), loss = 0.0284808
I1004 10:12:21.641814  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0116561 (* 1 = 0.0116561 loss)
I1004 10:12:21.641824  5017 sgd_solver.cpp:165] Iteration 44800, lr = 0.01
I1004 10:15:05.864254  5017 solver.cpp:357] Iteration 44900 (0.608903 iter/s, 164.23s/100 iters), loss = 0.0384054
I1004 10:15:05.864401  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0195907 (* 1 = 0.0195907 loss)
I1004 10:15:05.864413  5017 sgd_solver.cpp:165] Iteration 44900, lr = 0.01
I1004 10:15:38.698499  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 10:17:48.396862  5017 solver.cpp:514] Iteration 45000, Testing net (#0)
I1004 10:18:30.698508  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 10:18:30.866709  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.25379 (* 1 = 0.25379 loss)
I1004 10:18:30.866735  5017 solver.cpp:580]     Test net output #1: prob = 0.928803
I1004 10:18:30.866741  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 10:18:32.494539  5017 solver.cpp:357] Iteration 45000 (0.483935 iter/s, 206.639s/100 iters), loss = 0.0163558
I1004 10:18:32.494590  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00940794 (* 1 = 0.00940794 loss)
I1004 10:18:32.494603  5017 sgd_solver.cpp:165] Iteration 45000, lr = 0.01
I1004 10:21:16.640461  5017 solver.cpp:357] Iteration 45100 (0.609188 iter/s, 164.153s/100 iters), loss = 0.0276244
I1004 10:21:16.640610  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0221794 (* 1 = 0.0221794 loss)
I1004 10:21:16.640621  5017 sgd_solver.cpp:165] Iteration 45100, lr = 0.01
I1004 10:24:00.900142  5017 solver.cpp:357] Iteration 45200 (0.608767 iter/s, 164.267s/100 iters), loss = 0.0750784
I1004 10:24:00.900279  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.169621 (* 1 = 0.169621 loss)
I1004 10:24:00.900288  5017 sgd_solver.cpp:165] Iteration 45200, lr = 0.01
I1004 10:26:45.084424  5017 solver.cpp:357] Iteration 45300 (0.609046 iter/s, 164.191s/100 iters), loss = 0.0534639
I1004 10:26:45.084544  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.047914 (* 1 = 0.047914 loss)
I1004 10:26:45.084554  5017 sgd_solver.cpp:165] Iteration 45300, lr = 0.01
I1004 10:27:02.337347  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 10:29:29.295277  5017 solver.cpp:357] Iteration 45400 (0.608948 iter/s, 164.218s/100 iters), loss = 0.0460386
I1004 10:29:29.295411  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0116091 (* 1 = 0.0116091 loss)
I1004 10:29:29.295421  5017 sgd_solver.cpp:165] Iteration 45400, lr = 0.01
I1004 10:32:11.888167  5017 solver.cpp:514] Iteration 45500, Testing net (#0)
I1004 10:32:54.172847  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 10:32:54.341986  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.24383 (* 1 = 0.24383 loss)
I1004 10:32:54.342011  5017 solver.cpp:580]     Test net output #1: prob = 0.931003
I1004 10:32:54.342018  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 10:32:55.965492  5017 solver.cpp:357] Iteration 45500 (0.483843 iter/s, 206.679s/100 iters), loss = 0.0217235
I1004 10:32:55.965549  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0137617 (* 1 = 0.0137617 loss)
I1004 10:32:55.965559  5017 sgd_solver.cpp:165] Iteration 45500, lr = 0.01
I1004 10:35:40.152411  5017 solver.cpp:357] Iteration 45600 (0.609147 iter/s, 164.164s/100 iters), loss = 0.0191285
I1004 10:35:40.152551  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0427831 (* 1 = 0.0427831 loss)
I1004 10:35:40.152565  5017 sgd_solver.cpp:165] Iteration 45600, lr = 0.01
I1004 10:38:24.288220  5017 solver.cpp:357] Iteration 45700 (0.609305 iter/s, 164.121s/100 iters), loss = 0.0424392
I1004 10:38:24.288314  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.016239 (* 1 = 0.016239 loss)
I1004 10:38:24.288326  5017 sgd_solver.cpp:165] Iteration 45700, lr = 0.01
I1004 10:38:26.350991  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 10:41:08.439128  5017 solver.cpp:357] Iteration 45800 (0.609221 iter/s, 164.144s/100 iters), loss = 0.0605172
I1004 10:41:08.439265  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.141984 (* 1 = 0.141984 loss)
I1004 10:41:08.439275  5017 sgd_solver.cpp:165] Iteration 45800, lr = 0.01
I1004 10:43:52.601267  5017 solver.cpp:357] Iteration 45900 (0.609165 iter/s, 164.159s/100 iters), loss = 0.0301903
I1004 10:43:52.601370  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00811548 (* 1 = 0.00811548 loss)
I1004 10:43:52.601380  5017 sgd_solver.cpp:165] Iteration 45900, lr = 0.01
I1004 10:46:35.172225  5017 solver.cpp:514] Iteration 46000, Testing net (#0)
I1004 10:47:17.471052  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 10:47:17.637526  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.274553 (* 1 = 0.274553 loss)
I1004 10:47:17.637550  5017 solver.cpp:580]     Test net output #1: prob = 0.928302
I1004 10:47:17.637557  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 10:47:19.263552  5017 solver.cpp:357] Iteration 46000 (0.483884 iter/s, 206.661s/100 iters), loss = 0.0404139
I1004 10:47:19.263607  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0349981 (* 1 = 0.0349981 loss)
I1004 10:47:19.263617  5017 sgd_solver.cpp:165] Iteration 46000, lr = 0.01
I1004 10:49:49.947793  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 10:50:03.496100  5017 solver.cpp:357] Iteration 46100 (0.608891 iter/s, 164.233s/100 iters), loss = 0.0563818
I1004 10:50:03.496160  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.013472 (* 1 = 0.013472 loss)
I1004 10:50:03.496171  5017 sgd_solver.cpp:165] Iteration 46100, lr = 0.01
I1004 10:52:47.687019  5017 solver.cpp:357] Iteration 46200 (0.609045 iter/s, 164.191s/100 iters), loss = 0.0680642
I1004 10:52:47.687116  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.113709 (* 1 = 0.113709 loss)
I1004 10:52:47.687129  5017 sgd_solver.cpp:165] Iteration 46200, lr = 0.01
I1004 10:55:31.857161  5017 solver.cpp:357] Iteration 46300 (0.609122 iter/s, 164.171s/100 iters), loss = 0.0338667
I1004 10:55:31.857297  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0262042 (* 1 = 0.0262042 loss)
I1004 10:55:31.857307  5017 sgd_solver.cpp:165] Iteration 46300, lr = 0.01
I1004 10:58:16.098685  5017 solver.cpp:357] Iteration 46400 (0.608856 iter/s, 164.242s/100 iters), loss = 0.0377892
I1004 10:58:16.098778  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0279478 (* 1 = 0.0279478 loss)
I1004 10:58:16.098788  5017 sgd_solver.cpp:165] Iteration 46400, lr = 0.01
I1004 11:00:31.592435  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 11:00:58.676383  5017 solver.cpp:514] Iteration 46500, Testing net (#0)
I1004 11:01:40.940862  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 11:01:41.108647  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.235527 (* 1 = 0.235527 loss)
I1004 11:01:41.108674  5017 solver.cpp:580]     Test net output #1: prob = 0.934503
I1004 11:01:41.108680  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 11:01:42.735985  5017 solver.cpp:357] Iteration 46500 (0.483937 iter/s, 206.639s/100 iters), loss = 0.0541256
I1004 11:01:42.736040  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.014045 (* 1 = 0.014045 loss)
I1004 11:01:42.736052  5017 sgd_solver.cpp:165] Iteration 46500, lr = 0.01
I1004 11:04:26.908444  5017 solver.cpp:357] Iteration 46600 (0.609112 iter/s, 164.174s/100 iters), loss = 0.0404996
I1004 11:04:26.908540  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0484792 (* 1 = 0.0484792 loss)
I1004 11:04:26.908550  5017 sgd_solver.cpp:165] Iteration 46600, lr = 0.01
I1004 11:07:11.192760  5017 solver.cpp:357] Iteration 46700 (0.608697 iter/s, 164.285s/100 iters), loss = 0.0482313
I1004 11:07:11.192951  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0346522 (* 1 = 0.0346522 loss)
I1004 11:07:11.192962  5017 sgd_solver.cpp:165] Iteration 46700, lr = 0.01
I1004 11:09:55.488927  5017 solver.cpp:357] Iteration 46800 (0.608653 iter/s, 164.297s/100 iters), loss = 0.0467277
I1004 11:09:55.489073  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0177806 (* 1 = 0.0177806 loss)
I1004 11:09:55.489084  5017 sgd_solver.cpp:165] Iteration 46800, lr = 0.01
I1004 11:11:55.344746  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 11:12:39.668221  5017 solver.cpp:357] Iteration 46900 (0.609086 iter/s, 164.18s/100 iters), loss = 0.0485152
I1004 11:12:39.668316  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0347239 (* 1 = 0.0347239 loss)
I1004 11:12:39.668329  5017 sgd_solver.cpp:165] Iteration 46900, lr = 0.01
I1004 11:15:22.352740  5017 solver.cpp:514] Iteration 47000, Testing net (#0)
I1004 11:16:04.616330  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 11:16:04.784332  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.274454 (* 1 = 0.274454 loss)
I1004 11:16:04.784358  5017 solver.cpp:580]     Test net output #1: prob = 0.926603
I1004 11:16:04.784364  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 11:16:06.410719  5017 solver.cpp:357] Iteration 47000 (0.48369 iter/s, 206.744s/100 iters), loss = 0.0378265
I1004 11:16:06.410775  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0217713 (* 1 = 0.0217713 loss)
I1004 11:16:06.410790  5017 sgd_solver.cpp:165] Iteration 47000, lr = 0.01
I1004 11:18:50.595718  5017 solver.cpp:357] Iteration 47100 (0.609065 iter/s, 164.186s/100 iters), loss = 0.0662874
I1004 11:18:50.595863  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.108482 (* 1 = 0.108482 loss)
I1004 11:18:50.595875  5017 sgd_solver.cpp:165] Iteration 47100, lr = 0.01
I1004 11:21:34.978492  5017 solver.cpp:357] Iteration 47200 (0.608332 iter/s, 164.384s/100 iters), loss = 0.0460719
I1004 11:21:34.978628  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00337228 (* 1 = 0.00337228 loss)
I1004 11:21:34.978639  5017 sgd_solver.cpp:165] Iteration 47200, lr = 0.01
I1004 11:23:19.703055  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 11:24:19.227619  5017 solver.cpp:357] Iteration 47300 (0.608827 iter/s, 164.25s/100 iters), loss = 0.0176303
I1004 11:24:19.227761  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0274298 (* 1 = 0.0274298 loss)
I1004 11:24:19.227771  5017 sgd_solver.cpp:165] Iteration 47300, lr = 0.01
I1004 11:27:03.440270  5017 solver.cpp:357] Iteration 47400 (0.60895 iter/s, 164.217s/100 iters), loss = 0.0680444
I1004 11:27:03.440362  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0521745 (* 1 = 0.0521745 loss)
I1004 11:27:03.440373  5017 sgd_solver.cpp:165] Iteration 47400, lr = 0.01
I1004 11:29:46.000759  5017 solver.cpp:514] Iteration 47500, Testing net (#0)
I1004 11:30:28.278796  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 11:30:28.446894  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.262087 (* 1 = 0.262087 loss)
I1004 11:30:28.446920  5017 solver.cpp:580]     Test net output #1: prob = 0.929102
I1004 11:30:28.446926  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 11:30:30.076673  5017 solver.cpp:357] Iteration 47500 (0.483931 iter/s, 206.641s/100 iters), loss = 0.021177
I1004 11:30:30.076725  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0220195 (* 1 = 0.0220195 loss)
I1004 11:30:30.076735  5017 sgd_solver.cpp:165] Iteration 47500, lr = 0.01
I1004 11:33:14.237243  5017 solver.cpp:357] Iteration 47600 (0.609148 iter/s, 164.164s/100 iters), loss = 0.0612396
I1004 11:33:14.237381  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0287159 (* 1 = 0.0287159 loss)
I1004 11:33:14.237391  5017 sgd_solver.cpp:165] Iteration 47600, lr = 0.01
I1004 11:34:43.320925  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 11:35:58.426136  5017 solver.cpp:357] Iteration 47700 (0.609045 iter/s, 164.192s/100 iters), loss = 0.0594501
I1004 11:35:58.426285  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0108809 (* 1 = 0.0108809 loss)
I1004 11:35:58.426296  5017 sgd_solver.cpp:165] Iteration 47700, lr = 0.01
I1004 11:38:42.648167  5017 solver.cpp:357] Iteration 47800 (0.608923 iter/s, 164.224s/100 iters), loss = 0.0349523
I1004 11:38:42.648258  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0183411 (* 1 = 0.0183411 loss)
I1004 11:38:42.648269  5017 sgd_solver.cpp:165] Iteration 47800, lr = 0.01
I1004 11:41:26.862988  5017 solver.cpp:357] Iteration 47900 (0.60895 iter/s, 164.217s/100 iters), loss = 0.0219916
I1004 11:41:26.863129  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0349233 (* 1 = 0.0349233 loss)
I1004 11:41:26.863140  5017 sgd_solver.cpp:165] Iteration 47900, lr = 0.01
I1004 11:44:09.651351  5017 solver.cpp:514] Iteration 48000, Testing net (#0)
I1004 11:44:51.899452  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 11:44:52.067879  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.235992 (* 1 = 0.235992 loss)
I1004 11:44:52.067904  5017 solver.cpp:580]     Test net output #1: prob = 0.934502
I1004 11:44:52.067910  5017 solver.cpp:593]     Max_acc: 0.942203  with iter: 39000
I1004 11:44:53.694692  5017 solver.cpp:357] Iteration 48000 (0.483479 iter/s, 206.834s/100 iters), loss = 0.0818171
I1004 11:44:53.694746  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0815273 (* 1 = 0.0815273 loss)
I1004 11:44:53.694757  5017 sgd_solver.cpp:64] MultiStep Status: Iteration 48000, step = 2
I1004 11:44:53.694764  5017 sgd_solver.cpp:165] Iteration 48000, lr = 0.001
I1004 11:46:07.556105  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 11:47:37.832422  5017 solver.cpp:357] Iteration 48100 (0.609237 iter/s, 164.14s/100 iters), loss = 0.03997
I1004 11:47:37.832561  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.12227 (* 1 = 0.12227 loss)
I1004 11:47:37.832571  5017 sgd_solver.cpp:165] Iteration 48100, lr = 0.001
I1004 11:50:22.099010  5017 solver.cpp:357] Iteration 48200 (0.60876 iter/s, 164.268s/100 iters), loss = 0.0210181
I1004 11:50:22.099151  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0680205 (* 1 = 0.0680205 loss)
I1004 11:50:22.099161  5017 sgd_solver.cpp:165] Iteration 48200, lr = 0.001
I1004 11:53:06.574057  5017 solver.cpp:357] Iteration 48300 (0.607989 iter/s, 164.477s/100 iters), loss = 0.00510759
I1004 11:53:06.574192  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00403667 (* 1 = 0.00403667 loss)
I1004 11:53:06.574203  5017 sgd_solver.cpp:165] Iteration 48300, lr = 0.001
I1004 11:55:50.850399  5017 solver.cpp:357] Iteration 48400 (0.608724 iter/s, 164.278s/100 iters), loss = 0.0247808
I1004 11:55:50.850553  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00704832 (* 1 = 0.00704832 loss)
I1004 11:55:50.850564  5017 sgd_solver.cpp:165] Iteration 48400, lr = 0.001
I1004 11:56:49.171491  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 11:58:33.494176  5017 solver.cpp:514] Iteration 48500, Testing net (#0)
I1004 11:59:15.800626  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 11:59:15.968904  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.186296 (* 1 = 0.186296 loss)
I1004 11:59:15.968930  5017 solver.cpp:580]     Test net output #1: prob = 0.949402
I1004 11:59:15.968942  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_48500.caffemodel
I1004 11:59:16.761042  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_48500.solverstate
I1004 11:59:17.066468  5017 solver.cpp:593]     Max_acc: 0.949402  with iter: 48500
I1004 11:59:18.693377  5017 solver.cpp:357] Iteration 48500 (0.481114 iter/s, 207.851s/100 iters), loss = 0.017523
I1004 11:59:18.693455  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00239868 (* 1 = 0.00239868 loss)
I1004 11:59:18.693472  5017 sgd_solver.cpp:165] Iteration 48500, lr = 0.001
I1004 12:02:02.698549  5017 solver.cpp:357] Iteration 48600 (0.609657 iter/s, 164.027s/100 iters), loss = 0.0277401
I1004 12:02:02.698721  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00895328 (* 1 = 0.00895328 loss)
I1004 12:02:02.698734  5017 sgd_solver.cpp:165] Iteration 48600, lr = 0.001
I1004 12:04:47.134496  5017 solver.cpp:357] Iteration 48700 (0.608076 iter/s, 164.453s/100 iters), loss = 0.0077512
I1004 12:04:47.134642  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00387192 (* 1 = 0.00387192 loss)
I1004 12:04:47.134652  5017 sgd_solver.cpp:165] Iteration 48700, lr = 0.001
I1004 12:07:31.363883  5017 solver.cpp:357] Iteration 48800 (0.608853 iter/s, 164.243s/100 iters), loss = 0.010731
I1004 12:07:31.363979  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00710271 (* 1 = 0.00710271 loss)
I1004 12:07:31.363989  5017 sgd_solver.cpp:165] Iteration 48800, lr = 0.001
I1004 12:08:14.493741  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 12:10:15.690182  5017 solver.cpp:357] Iteration 48900 (0.608502 iter/s, 164.338s/100 iters), loss = 0.0080904
I1004 12:10:15.690275  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0129475 (* 1 = 0.0129475 loss)
I1004 12:10:15.690285  5017 sgd_solver.cpp:165] Iteration 48900, lr = 0.001
I1004 12:12:58.515198  5017 solver.cpp:514] Iteration 49000, Testing net (#0)
I1004 12:13:40.814942  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 12:13:40.983208  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.182458 (* 1 = 0.182458 loss)
I1004 12:13:40.983235  5017 solver.cpp:580]     Test net output #1: prob = 0.951902
I1004 12:13:40.983247  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_49000.caffemodel
I1004 12:13:41.777446  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_49000.solverstate
I1004 12:13:42.084666  5017 solver.cpp:593]     Max_acc: 0.951902  with iter: 49000
I1004 12:13:43.706194  5017 solver.cpp:357] Iteration 49000 (0.480704 iter/s, 208.028s/100 iters), loss = 0.0286645
I1004 12:13:43.706250  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00763552 (* 1 = 0.00763552 loss)
I1004 12:13:43.706261  5017 sgd_solver.cpp:165] Iteration 49000, lr = 0.001
I1004 12:16:27.769389  5017 solver.cpp:357] Iteration 49100 (0.60949 iter/s, 164.072s/100 iters), loss = 0.0217785
I1004 12:16:27.769487  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.068602 (* 1 = 0.068602 loss)
I1004 12:16:27.769497  5017 sgd_solver.cpp:165] Iteration 49100, lr = 0.001
I1004 12:19:12.076884  5017 solver.cpp:357] Iteration 49200 (0.608587 iter/s, 164.315s/100 iters), loss = 0.00435257
I1004 12:19:12.077018  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00197138 (* 1 = 0.00197138 loss)
I1004 12:19:12.077029  5017 sgd_solver.cpp:165] Iteration 49200, lr = 0.001
I1004 12:19:39.648602  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 12:21:56.416590  5017 solver.cpp:357] Iteration 49300 (0.60847 iter/s, 164.347s/100 iters), loss = 0.00945031
I1004 12:21:56.416734  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0131141 (* 1 = 0.0131141 loss)
I1004 12:21:56.416744  5017 sgd_solver.cpp:165] Iteration 49300, lr = 0.001
I1004 12:24:40.664341  5017 solver.cpp:357] Iteration 49400 (0.608812 iter/s, 164.254s/100 iters), loss = 0.00936483
I1004 12:24:40.664438  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0226497 (* 1 = 0.0226497 loss)
I1004 12:24:40.664454  5017 sgd_solver.cpp:165] Iteration 49400, lr = 0.001
I1004 12:27:23.252023  5017 solver.cpp:514] Iteration 49500, Testing net (#0)
I1004 12:28:05.531528  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 12:28:05.698158  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.180054 (* 1 = 0.180054 loss)
I1004 12:28:05.698184  5017 solver.cpp:580]     Test net output #1: prob = 0.954402
I1004 12:28:05.698195  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_49500.caffemodel
I1004 12:28:06.490157  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_49500.solverstate
I1004 12:28:06.796907  5017 solver.cpp:593]     Max_acc: 0.954402  with iter: 49500
I1004 12:28:08.421679  5017 solver.cpp:357] Iteration 49500 (0.481312 iter/s, 207.765s/100 iters), loss = 0.0097087
I1004 12:28:08.421737  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00424457 (* 1 = 0.00424457 loss)
I1004 12:28:08.421753  5017 sgd_solver.cpp:165] Iteration 49500, lr = 0.001
I1004 12:30:52.608974  5017 solver.cpp:357] Iteration 49600 (0.609038 iter/s, 164.193s/100 iters), loss = 0.00913987
I1004 12:30:52.609146  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0271871 (* 1 = 0.0271871 loss)
I1004 12:30:52.609156  5017 sgd_solver.cpp:165] Iteration 49600, lr = 0.001
I1004 12:31:04.945940  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 12:33:37.339146  5017 solver.cpp:357] Iteration 49700 (0.607063 iter/s, 164.727s/100 iters), loss = 0.010737
I1004 12:33:37.339260  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00680314 (* 1 = 0.00680314 loss)
I1004 12:33:37.339272  5017 sgd_solver.cpp:165] Iteration 49700, lr = 0.001
I1004 12:36:21.791250  5017 solver.cpp:357] Iteration 49800 (0.608143 iter/s, 164.435s/100 iters), loss = 0.0112403
I1004 12:36:21.791368  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00713231 (* 1 = 0.00713231 loss)
I1004 12:36:21.791378  5017 sgd_solver.cpp:165] Iteration 49800, lr = 0.001
I1004 12:39:06.209849  5017 solver.cpp:357] Iteration 49900 (0.608247 iter/s, 164.407s/100 iters), loss = 0.0119183
I1004 12:39:06.209946  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00477818 (* 1 = 0.00477818 loss)
I1004 12:39:06.209956  5017 sgd_solver.cpp:165] Iteration 49900, lr = 0.001
I1004 12:41:47.332877  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 12:41:48.971706  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_50000.caffemodel
I1004 12:41:49.761008  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_50000.solverstate
I1004 12:41:50.061684  5017 solver.cpp:514] Iteration 50000, Testing net (#0)
I1004 12:42:32.358908  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 12:42:32.527386  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.176789 (* 1 = 0.176789 loss)
I1004 12:42:32.527412  5017 solver.cpp:580]     Test net output #1: prob = 0.953402
I1004 12:42:32.527418  5017 solver.cpp:593]     Max_acc: 0.954402  with iter: 49500
I1004 12:42:34.156237  5017 solver.cpp:357] Iteration 50000 (0.480915 iter/s, 207.937s/100 iters), loss = 0.00925804
I1004 12:42:34.156296  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0105114 (* 1 = 0.0105114 loss)
I1004 12:42:34.156306  5017 sgd_solver.cpp:165] Iteration 50000, lr = 0.001
I1004 12:45:18.646101  5017 solver.cpp:357] Iteration 50100 (0.607957 iter/s, 164.485s/100 iters), loss = 0.00728001
I1004 12:45:18.646196  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00468869 (* 1 = 0.00468869 loss)
I1004 12:45:18.646209  5017 sgd_solver.cpp:165] Iteration 50100, lr = 0.001
I1004 12:48:02.908076  5017 solver.cpp:357] Iteration 50200 (0.608793 iter/s, 164.259s/100 iters), loss = 0.0125137
I1004 12:48:02.908217  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00554586 (* 1 = 0.00554586 loss)
I1004 12:48:02.908228  5017 sgd_solver.cpp:165] Iteration 50200, lr = 0.001
I1004 12:50:47.179913  5017 solver.cpp:357] Iteration 50300 (0.608752 iter/s, 164.271s/100 iters), loss = 0.00972451
I1004 12:50:47.180050  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0119253 (* 1 = 0.0119253 loss)
I1004 12:50:47.180061  5017 sgd_solver.cpp:165] Iteration 50300, lr = 0.001
I1004 12:53:13.190996  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 12:53:31.692723  5017 solver.cpp:357] Iteration 50400 (0.607857 iter/s, 164.513s/100 iters), loss = 0.010509
I1004 12:53:31.692782  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00599831 (* 1 = 0.00599831 loss)
I1004 12:53:31.692795  5017 sgd_solver.cpp:165] Iteration 50400, lr = 0.001
I1004 12:56:14.382836  5017 solver.cpp:514] Iteration 50500, Testing net (#0)
I1004 12:56:56.651522  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 12:56:56.818928  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.176496 (* 1 = 0.176496 loss)
I1004 12:56:56.818953  5017 solver.cpp:580]     Test net output #1: prob = 0.954002
I1004 12:56:56.818958  5017 solver.cpp:593]     Max_acc: 0.954402  with iter: 49500
I1004 12:56:58.448385  5017 solver.cpp:357] Iteration 50500 (0.483661 iter/s, 206.756s/100 iters), loss = 0.00912093
I1004 12:56:58.448439  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00215473 (* 1 = 0.00215473 loss)
I1004 12:56:58.448449  5017 sgd_solver.cpp:165] Iteration 50500, lr = 0.001
I1004 12:59:42.687940  5017 solver.cpp:357] Iteration 50600 (0.608863 iter/s, 164.241s/100 iters), loss = 0.00428688
I1004 12:59:42.688038  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00302358 (* 1 = 0.00302358 loss)
I1004 12:59:42.688050  5017 sgd_solver.cpp:165] Iteration 50600, lr = 0.001
I1004 13:02:27.088943  5017 solver.cpp:357] Iteration 50700 (0.608264 iter/s, 164.402s/100 iters), loss = 0.0037634
I1004 13:02:27.089079  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00235464 (* 1 = 0.00235464 loss)
I1004 13:02:27.089090  5017 sgd_solver.cpp:165] Iteration 50700, lr = 0.001
I1004 13:04:37.354387  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 13:05:11.423864  5017 solver.cpp:357] Iteration 50800 (0.608507 iter/s, 164.337s/100 iters), loss = 0.00586026
I1004 13:05:11.423959  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00867551 (* 1 = 0.00867551 loss)
I1004 13:05:11.423974  5017 sgd_solver.cpp:165] Iteration 50800, lr = 0.001
I1004 13:07:55.760264  5017 solver.cpp:357] Iteration 50900 (0.608468 iter/s, 164.347s/100 iters), loss = 0.00839579
I1004 13:07:55.760365  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00220757 (* 1 = 0.00220757 loss)
I1004 13:07:55.760380  5017 sgd_solver.cpp:165] Iteration 50900, lr = 0.001
I1004 13:10:38.541306  5017 solver.cpp:514] Iteration 51000, Testing net (#0)
I1004 13:11:20.833973  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 13:11:21.002532  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.178815 (* 1 = 0.178815 loss)
I1004 13:11:21.002557  5017 solver.cpp:580]     Test net output #1: prob = 0.953502
I1004 13:11:21.002563  5017 solver.cpp:593]     Max_acc: 0.954402  with iter: 49500
I1004 13:11:22.626394  5017 solver.cpp:357] Iteration 51000 (0.48334 iter/s, 206.894s/100 iters), loss = 0.00471016
I1004 13:11:22.626446  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00256949 (* 1 = 0.00256949 loss)
I1004 13:11:22.626461  5017 sgd_solver.cpp:165] Iteration 51000, lr = 0.001
I1004 13:14:06.965266  5017 solver.cpp:357] Iteration 51100 (0.608436 iter/s, 164.356s/100 iters), loss = 0.00227439
I1004 13:14:06.965368  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0017911 (* 1 = 0.0017911 loss)
I1004 13:14:06.965384  5017 sgd_solver.cpp:165] Iteration 51100, lr = 0.001
I1004 13:16:02.053768  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 13:16:51.453796  5017 solver.cpp:357] Iteration 51200 (0.607893 iter/s, 164.503s/100 iters), loss = 0.00619554
I1004 13:16:51.453893  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00825767 (* 1 = 0.00825767 loss)
I1004 13:16:51.453909  5017 sgd_solver.cpp:165] Iteration 51200, lr = 0.001
I1004 13:19:35.715135  5017 solver.cpp:357] Iteration 51300 (0.608742 iter/s, 164.273s/100 iters), loss = 0.00261061
I1004 13:19:35.715272  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00448285 (* 1 = 0.00448285 loss)
I1004 13:19:35.715283  5017 sgd_solver.cpp:165] Iteration 51300, lr = 0.001
I1004 13:22:19.974954  5017 solver.cpp:357] Iteration 51400 (0.608753 iter/s, 164.27s/100 iters), loss = 0.008568
I1004 13:22:19.975145  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.014115 (* 1 = 0.014115 loss)
I1004 13:22:19.975160  5017 sgd_solver.cpp:165] Iteration 51400, lr = 0.001
I1004 13:25:02.591217  5017 solver.cpp:514] Iteration 51500, Testing net (#0)
I1004 13:25:44.874917  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 13:25:45.043325  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.178154 (* 1 = 0.178154 loss)
I1004 13:25:45.043351  5017 solver.cpp:580]     Test net output #1: prob = 0.954602
I1004 13:25:45.043362  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_51500.caffemodel
I1004 13:25:45.830585  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_51500.solverstate
I1004 13:25:46.135005  5017 solver.cpp:593]     Max_acc: 0.954602  with iter: 51500
I1004 13:25:47.765843  5017 solver.cpp:357] Iteration 51500 (0.481226 iter/s, 207.802s/100 iters), loss = 0.0118137
I1004 13:25:47.765908  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0108969 (* 1 = 0.0108969 loss)
I1004 13:25:47.765924  5017 sgd_solver.cpp:165] Iteration 51500, lr = 0.001
I1004 13:27:27.069672  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 13:28:31.886024  5017 solver.cpp:357] Iteration 51600 (0.609279 iter/s, 164.128s/100 iters), loss = 0.0159099
I1004 13:28:31.886160  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00189304 (* 1 = 0.00189304 loss)
I1004 13:28:31.886171  5017 sgd_solver.cpp:165] Iteration 51600, lr = 0.001
I1004 13:31:16.266789  5017 solver.cpp:357] Iteration 51700 (0.608315 iter/s, 164.388s/100 iters), loss = 0.0104782
I1004 13:31:16.266925  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00733181 (* 1 = 0.00733181 loss)
I1004 13:31:16.266935  5017 sgd_solver.cpp:165] Iteration 51700, lr = 0.001
I1004 13:34:00.566854  5017 solver.cpp:357] Iteration 51800 (0.608615 iter/s, 164.307s/100 iters), loss = 0.00558247
I1004 13:34:00.566949  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00249433 (* 1 = 0.00249433 loss)
I1004 13:34:00.566959  5017 sgd_solver.cpp:165] Iteration 51800, lr = 0.001
I1004 13:36:45.171417  5017 solver.cpp:357] Iteration 51900 (0.607491 iter/s, 164.612s/100 iters), loss = 0.003052
I1004 13:36:45.175190  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00309853 (* 1 = 0.00309853 loss)
I1004 13:36:45.175205  5017 sgd_solver.cpp:165] Iteration 51900, lr = 0.001
I1004 13:38:09.551571  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 13:39:28.108486  5017 solver.cpp:514] Iteration 52000, Testing net (#0)
I1004 13:40:10.438133  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 13:40:10.606163  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.175918 (* 1 = 0.175918 loss)
I1004 13:40:10.606189  5017 solver.cpp:580]     Test net output #1: prob = 0.954202
I1004 13:40:10.606194  5017 solver.cpp:593]     Max_acc: 0.954602  with iter: 51500
I1004 13:40:12.233716  5017 solver.cpp:357] Iteration 52000 (0.482935 iter/s, 207.067s/100 iters), loss = 0.00609518
I1004 13:40:12.233772  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00335254 (* 1 = 0.00335254 loss)
I1004 13:40:12.233783  5017 sgd_solver.cpp:165] Iteration 52000, lr = 0.001
I1004 13:42:56.442437  5017 solver.cpp:357] Iteration 52100 (0.609025 iter/s, 164.197s/100 iters), loss = 0.0164783
I1004 13:42:56.442534  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0500907 (* 1 = 0.0500907 loss)
I1004 13:42:56.442548  5017 sgd_solver.cpp:165] Iteration 52100, lr = 0.001
I1004 13:45:40.787286  5017 solver.cpp:357] Iteration 52200 (0.608531 iter/s, 164.33s/100 iters), loss = 0.0111758
I1004 13:45:40.787385  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00260608 (* 1 = 0.00260608 loss)
I1004 13:45:40.787395  5017 sgd_solver.cpp:165] Iteration 52200, lr = 0.001
I1004 13:48:25.312863  5017 solver.cpp:357] Iteration 52300 (0.607845 iter/s, 164.516s/100 iters), loss = 0.00488682
I1004 13:48:25.313053  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00306077 (* 1 = 0.00306077 loss)
I1004 13:48:25.313066  5017 sgd_solver.cpp:165] Iteration 52300, lr = 0.001
I1004 13:49:34.020113  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 13:51:09.898363  5017 solver.cpp:357] Iteration 52400 (0.607611 iter/s, 164.579s/100 iters), loss = 0.00637136
I1004 13:51:09.898500  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0032431 (* 1 = 0.0032431 loss)
I1004 13:51:09.898512  5017 sgd_solver.cpp:165] Iteration 52400, lr = 0.001
I1004 13:53:52.643589  5017 solver.cpp:514] Iteration 52500, Testing net (#0)
I1004 13:54:34.935387  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 13:54:35.103058  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.178083 (* 1 = 0.178083 loss)
I1004 13:54:35.103085  5017 solver.cpp:580]     Test net output #1: prob = 0.955702
I1004 13:54:35.103097  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_52500.caffemodel
I1004 13:54:35.893761  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_52500.solverstate
I1004 13:54:36.196738  5017 solver.cpp:593]     Max_acc: 0.955702  with iter: 52500
I1004 13:54:37.823808  5017 solver.cpp:357] Iteration 52500 (0.480952 iter/s, 207.921s/100 iters), loss = 0.00590308
I1004 13:54:37.823866  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00352277 (* 1 = 0.00352277 loss)
I1004 13:54:37.823877  5017 sgd_solver.cpp:165] Iteration 52500, lr = 0.001
I1004 13:57:21.977723  5017 solver.cpp:357] Iteration 52600 (0.60919 iter/s, 164.152s/100 iters), loss = 0.0128572
I1004 13:57:21.977859  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.017323 (* 1 = 0.017323 loss)
I1004 13:57:21.977870  5017 sgd_solver.cpp:165] Iteration 52600, lr = 0.001
I1004 14:00:06.459326  5017 solver.cpp:357] Iteration 52700 (0.607972 iter/s, 164.481s/100 iters), loss = 0.0131612
I1004 14:00:06.459429  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00328967 (* 1 = 0.00328967 loss)
I1004 14:00:06.459444  5017 sgd_solver.cpp:165] Iteration 52700, lr = 0.001
I1004 14:00:59.872449  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 14:02:50.786032  5017 solver.cpp:357] Iteration 52800 (0.608541 iter/s, 164.327s/100 iters), loss = 0.00356562
I1004 14:02:50.786170  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00214068 (* 1 = 0.00214068 loss)
I1004 14:02:50.786180  5017 sgd_solver.cpp:165] Iteration 52800, lr = 0.001
I1004 14:05:35.112414  5017 solver.cpp:357] Iteration 52900 (0.60854 iter/s, 164.328s/100 iters), loss = 0.0122773
I1004 14:05:35.112553  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00409213 (* 1 = 0.00409213 loss)
I1004 14:05:35.112563  5017 sgd_solver.cpp:165] Iteration 52900, lr = 0.001
I1004 14:08:17.642546  5017 solver.cpp:514] Iteration 53000, Testing net (#0)
I1004 14:08:59.915446  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 14:09:00.082458  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.17762 (* 1 = 0.17762 loss)
I1004 14:09:00.082484  5017 solver.cpp:580]     Test net output #1: prob = 0.955902
I1004 14:09:00.082495  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_53000.caffemodel
I1004 14:09:00.876649  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_53000.solverstate
I1004 14:09:01.177964  5017 solver.cpp:593]     Max_acc: 0.955902  with iter: 53000
I1004 14:09:02.803181  5017 solver.cpp:357] Iteration 53000 (0.48148 iter/s, 207.693s/100 iters), loss = 0.0142527
I1004 14:09:02.803239  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0128216 (* 1 = 0.0128216 loss)
I1004 14:09:02.803251  5017 sgd_solver.cpp:165] Iteration 53000, lr = 0.001
I1004 14:11:47.300416  5017 solver.cpp:357] Iteration 53100 (0.607905 iter/s, 164.499s/100 iters), loss = 0.00373311
I1004 14:11:47.300607  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00711941 (* 1 = 0.00711941 loss)
I1004 14:11:47.300623  5017 sgd_solver.cpp:165] Iteration 53100, lr = 0.001
I1004 14:12:25.125555  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 14:14:31.902096  5017 solver.cpp:357] Iteration 53200 (0.607518 iter/s, 164.604s/100 iters), loss = 0.010233
I1004 14:14:31.902236  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0190101 (* 1 = 0.0190101 loss)
I1004 14:14:31.902247  5017 sgd_solver.cpp:165] Iteration 53200, lr = 0.001
I1004 14:17:16.983959  5017 solver.cpp:357] Iteration 53300 (0.605752 iter/s, 165.084s/100 iters), loss = 0.00310611
I1004 14:17:16.984099  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00165252 (* 1 = 0.00165252 loss)
I1004 14:17:16.984110  5017 sgd_solver.cpp:165] Iteration 53300, lr = 0.001
I1004 14:20:01.802554  5017 solver.cpp:357] Iteration 53400 (0.606719 iter/s, 164.821s/100 iters), loss = 0.00248776
I1004 14:20:01.802639  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.000831587 (* 1 = 0.000831587 loss)
I1004 14:20:01.802651  5017 sgd_solver.cpp:165] Iteration 53400, lr = 0.001
I1004 14:22:44.901270  5017 solver.cpp:514] Iteration 53500, Testing net (#0)
I1004 14:23:27.188272  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 14:23:27.357991  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.175735 (* 1 = 0.175735 loss)
I1004 14:23:27.358017  5017 solver.cpp:580]     Test net output #1: prob = 0.956302
I1004 14:23:27.358029  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_53500.caffemodel
I1004 14:23:28.148036  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_53500.solverstate
I1004 14:23:28.452142  5017 solver.cpp:593]     Max_acc: 0.956302  with iter: 53500
I1004 14:23:30.078954  5017 solver.cpp:357] Iteration 53500 (0.480124 iter/s, 208.28s/100 iters), loss = 0.0037405
I1004 14:23:30.079012  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00425183 (* 1 = 0.00425183 loss)
I1004 14:23:30.079023  5017 sgd_solver.cpp:165] Iteration 53500, lr = 0.001
I1004 14:23:52.667235  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 14:26:14.725263  5017 solver.cpp:357] Iteration 53600 (0.607353 iter/s, 164.649s/100 iters), loss = 0.00479877
I1004 14:26:14.725396  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00180358 (* 1 = 0.00180358 loss)
I1004 14:26:14.725406  5017 sgd_solver.cpp:165] Iteration 53600, lr = 0.001
I1004 14:28:59.439666  5017 solver.cpp:357] Iteration 53700 (0.607102 iter/s, 164.717s/100 iters), loss = 0.0114251
I1004 14:28:59.439765  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0151734 (* 1 = 0.0151734 loss)
I1004 14:28:59.439775  5017 sgd_solver.cpp:165] Iteration 53700, lr = 0.001
I1004 14:31:44.281082  5017 solver.cpp:357] Iteration 53800 (0.606633 iter/s, 164.844s/100 iters), loss = 0.00413479
I1004 14:31:44.281221  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00343566 (* 1 = 0.00343566 loss)
I1004 14:31:44.281232  5017 sgd_solver.cpp:165] Iteration 53800, lr = 0.001
I1004 14:34:29.382812  5017 solver.cpp:357] Iteration 53900 (0.605677 iter/s, 165.105s/100 iters), loss = 0.00327971
I1004 14:34:29.382953  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00322337 (* 1 = 0.00322337 loss)
I1004 14:34:29.382963  5017 sgd_solver.cpp:165] Iteration 53900, lr = 0.001
I1004 14:34:36.408350  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 14:37:12.519342  5017 solver.cpp:514] Iteration 54000, Testing net (#0)
I1004 14:37:54.792661  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 14:37:54.961691  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.177023 (* 1 = 0.177023 loss)
I1004 14:37:54.961716  5017 solver.cpp:580]     Test net output #1: prob = 0.955202
I1004 14:37:54.961722  5017 solver.cpp:593]     Max_acc: 0.956302  with iter: 53500
I1004 14:37:56.588621  5017 solver.cpp:357] Iteration 54000 (0.482604 iter/s, 207.209s/100 iters), loss = 0.0148333
I1004 14:37:56.588675  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00559495 (* 1 = 0.00559495 loss)
I1004 14:37:56.588688  5017 sgd_solver.cpp:165] Iteration 54000, lr = 0.001
I1004 14:40:41.322224  5017 solver.cpp:357] Iteration 54100 (0.60703 iter/s, 164.737s/100 iters), loss = 0.0085092
I1004 14:40:41.322367  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00221347 (* 1 = 0.00221347 loss)
I1004 14:40:41.322378  5017 sgd_solver.cpp:165] Iteration 54100, lr = 0.001
I1004 14:43:26.689709  5017 solver.cpp:357] Iteration 54200 (0.604703 iter/s, 165.37s/100 iters), loss = 0.0030779
I1004 14:43:26.689853  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00102469 (* 1 = 0.00102469 loss)
I1004 14:43:26.689863  5017 sgd_solver.cpp:165] Iteration 54200, lr = 0.001
I1004 14:46:03.283448  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 14:46:11.527091  5017 solver.cpp:357] Iteration 54300 (0.606648 iter/s, 164.84s/100 iters), loss = 0.00602227
I1004 14:46:11.527151  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00595685 (* 1 = 0.00595685 loss)
I1004 14:46:11.527161  5017 sgd_solver.cpp:165] Iteration 54300, lr = 0.001
I1004 14:48:56.587276  5017 solver.cpp:357] Iteration 54400 (0.605829 iter/s, 165.063s/100 iters), loss = 0.00309956
I1004 14:48:56.587400  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00195759 (* 1 = 0.00195759 loss)
I1004 14:48:56.587410  5017 sgd_solver.cpp:165] Iteration 54400, lr = 0.001
I1004 14:51:39.520690  5017 solver.cpp:514] Iteration 54500, Testing net (#0)
I1004 14:52:21.842559  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 14:52:22.010936  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.17573 (* 1 = 0.17573 loss)
I1004 14:52:22.010958  5017 solver.cpp:580]     Test net output #1: prob = 0.955502
I1004 14:52:22.010964  5017 solver.cpp:593]     Max_acc: 0.956302  with iter: 53500
I1004 14:52:23.635813  5017 solver.cpp:357] Iteration 54500 (0.48289 iter/s, 207.087s/100 iters), loss = 0.00490459
I1004 14:52:23.635866  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00341075 (* 1 = 0.00341075 loss)
I1004 14:52:23.635876  5017 sgd_solver.cpp:165] Iteration 54500, lr = 0.001
I1004 14:55:08.285117  5017 solver.cpp:357] Iteration 54600 (0.607254 iter/s, 164.676s/100 iters), loss = 0.0054263
I1004 14:55:08.285257  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00233467 (* 1 = 0.00233467 loss)
I1004 14:55:08.285269  5017 sgd_solver.cpp:165] Iteration 54600, lr = 0.001
I1004 14:57:29.278717  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 14:57:53.175652  5017 solver.cpp:357] Iteration 54700 (0.606384 iter/s, 164.912s/100 iters), loss = 0.00245191
I1004 14:57:53.175712  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00274878 (* 1 = 0.00274878 loss)
I1004 14:57:53.175724  5017 sgd_solver.cpp:165] Iteration 54700, lr = 0.001
I1004 15:00:38.083578  5017 solver.cpp:357] Iteration 54800 (0.606333 iter/s, 164.926s/100 iters), loss = 0.00149762
I1004 15:00:38.083673  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00106368 (* 1 = 0.00106368 loss)
I1004 15:00:38.083685  5017 sgd_solver.cpp:165] Iteration 54800, lr = 0.001
I1004 15:03:22.896718  5017 solver.cpp:357] Iteration 54900 (0.606691 iter/s, 164.829s/100 iters), loss = 0.0047282
I1004 15:03:22.896839  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0013307 (* 1 = 0.0013307 loss)
I1004 15:03:22.896853  5017 sgd_solver.cpp:165] Iteration 54900, lr = 0.001
I1004 15:06:06.440165  5017 solver.cpp:514] Iteration 55000, Testing net (#0)
I1004 15:06:48.713037  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 15:06:48.881724  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.180811 (* 1 = 0.180811 loss)
I1004 15:06:48.881750  5017 solver.cpp:580]     Test net output #1: prob = 0.955102
I1004 15:06:48.881757  5017 solver.cpp:593]     Max_acc: 0.956302  with iter: 53500
I1004 15:06:50.509485  5017 solver.cpp:357] Iteration 55000 (0.481627 iter/s, 207.63s/100 iters), loss = 0.00348311
I1004 15:06:50.509541  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00348721 (* 1 = 0.00348721 loss)
I1004 15:06:50.509557  5017 sgd_solver.cpp:165] Iteration 55000, lr = 0.001
I1004 15:08:55.981851  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 15:09:35.255676  5017 solver.cpp:357] Iteration 55100 (0.606951 iter/s, 164.758s/100 iters), loss = 0.0098243
I1004 15:09:35.255822  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00260448 (* 1 = 0.00260448 loss)
I1004 15:09:35.255833  5017 sgd_solver.cpp:165] Iteration 55100, lr = 0.001
I1004 15:12:20.189273  5017 solver.cpp:357] Iteration 55200 (0.606265 iter/s, 164.944s/100 iters), loss = 0.00225192
I1004 15:12:20.189406  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00120572 (* 1 = 0.00120572 loss)
I1004 15:12:20.189416  5017 sgd_solver.cpp:165] Iteration 55200, lr = 0.001
I1004 15:15:04.831073  5017 solver.cpp:357] Iteration 55300 (0.607342 iter/s, 164.652s/100 iters), loss = 0.00985339
I1004 15:15:04.831164  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00828295 (* 1 = 0.00828295 loss)
I1004 15:15:04.831176  5017 sgd_solver.cpp:165] Iteration 55300, lr = 0.001
I1004 15:17:49.502290  5017 solver.cpp:357] Iteration 55400 (0.607235 iter/s, 164.681s/100 iters), loss = 0.00406496
I1004 15:17:49.502413  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00342548 (* 1 = 0.00342548 loss)
I1004 15:17:49.502429  5017 sgd_solver.cpp:165] Iteration 55400, lr = 0.001
I1004 15:19:39.309445  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 15:20:32.331789  5017 solver.cpp:514] Iteration 55500, Testing net (#0)
I1004 15:21:14.611609  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 15:21:14.779634  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.175405 (* 1 = 0.175405 loss)
I1004 15:21:14.779659  5017 solver.cpp:580]     Test net output #1: prob = 0.956402
I1004 15:21:14.779671  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_55500.caffemodel
I1004 15:21:15.575299  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_55500.solverstate
I1004 15:21:15.882925  5017 solver.cpp:593]     Max_acc: 0.956402  with iter: 55500
I1004 15:21:17.512131  5017 solver.cpp:357] Iteration 55500 (0.480719 iter/s, 208.022s/100 iters), loss = 0.0030284
I1004 15:21:17.512188  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00165603 (* 1 = 0.00165603 loss)
I1004 15:21:17.512199  5017 sgd_solver.cpp:165] Iteration 55500, lr = 0.001
I1004 15:24:01.766567  5017 solver.cpp:357] Iteration 55600 (0.608808 iter/s, 164.255s/100 iters), loss = 0.00372233
I1004 15:24:01.766650  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00487848 (* 1 = 0.00487848 loss)
I1004 15:24:01.766666  5017 sgd_solver.cpp:165] Iteration 55600, lr = 0.001
I1004 15:26:46.345738  5017 solver.cpp:357] Iteration 55700 (0.607708 iter/s, 164.553s/100 iters), loss = 0.00437976
I1004 15:26:46.345881  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00134786 (* 1 = 0.00134786 loss)
I1004 15:26:46.345892  5017 sgd_solver.cpp:165] Iteration 55700, lr = 0.001
I1004 15:29:30.803342  5017 solver.cpp:357] Iteration 55800 (0.608128 iter/s, 164.439s/100 iters), loss = 0.00155343
I1004 15:29:30.803480  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.000708269 (* 1 = 0.000708269 loss)
I1004 15:29:30.803491  5017 sgd_solver.cpp:165] Iteration 55800, lr = 0.001
I1004 15:31:05.355494  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 15:32:15.211256  5017 solver.cpp:357] Iteration 55900 (0.608291 iter/s, 164.395s/100 iters), loss = 0.00723296
I1004 15:32:15.211395  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00393738 (* 1 = 0.00393738 loss)
I1004 15:32:15.211406  5017 sgd_solver.cpp:165] Iteration 55900, lr = 0.001
I1004 15:34:58.132764  5017 solver.cpp:514] Iteration 56000, Testing net (#0)
I1004 15:35:40.433099  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 15:35:40.601614  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.178872 (* 1 = 0.178872 loss)
I1004 15:35:40.601639  5017 solver.cpp:580]     Test net output #1: prob = 0.956302
I1004 15:35:40.601645  5017 solver.cpp:593]     Max_acc: 0.956402  with iter: 55500
I1004 15:35:42.228864  5017 solver.cpp:357] Iteration 56000 (0.483076 iter/s, 207.007s/100 iters), loss = 0.0025524
I1004 15:35:42.228919  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00274855 (* 1 = 0.00274855 loss)
I1004 15:35:42.228932  5017 sgd_solver.cpp:165] Iteration 56000, lr = 0.001
I1004 15:38:26.422694  5017 solver.cpp:357] Iteration 56100 (0.609056 iter/s, 164.189s/100 iters), loss = 0.00583483
I1004 15:38:26.422834  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0018709 (* 1 = 0.0018709 loss)
I1004 15:38:26.422844  5017 sgd_solver.cpp:165] Iteration 56100, lr = 0.001
I1004 15:41:10.840521  5017 solver.cpp:357] Iteration 56200 (0.608219 iter/s, 164.414s/100 iters), loss = 0.00285186
I1004 15:41:10.840661  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00128789 (* 1 = 0.00128789 loss)
I1004 15:41:10.840670  5017 sgd_solver.cpp:165] Iteration 56200, lr = 0.001
I1004 15:42:29.918570  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 15:43:55.420495  5017 solver.cpp:357] Iteration 56300 (0.607614 iter/s, 164.578s/100 iters), loss = 0.00287966
I1004 15:43:55.420588  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00598645 (* 1 = 0.00598645 loss)
I1004 15:43:55.420603  5017 sgd_solver.cpp:165] Iteration 56300, lr = 0.001
I1004 15:46:39.985373  5017 solver.cpp:357] Iteration 56400 (0.607666 iter/s, 164.564s/100 iters), loss = 0.00828472
I1004 15:46:39.985489  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00288936 (* 1 = 0.00288936 loss)
I1004 15:46:39.985500  5017 sgd_solver.cpp:165] Iteration 56400, lr = 0.001
I1004 15:49:23.041153  5017 solver.cpp:514] Iteration 56500, Testing net (#0)
I1004 15:50:05.292174  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 15:50:05.460075  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.178977 (* 1 = 0.178977 loss)
I1004 15:50:05.460101  5017 solver.cpp:580]     Test net output #1: prob = 0.954402
I1004 15:50:05.460108  5017 solver.cpp:593]     Max_acc: 0.956402  with iter: 55500
I1004 15:50:07.089327  5017 solver.cpp:357] Iteration 56500 (0.482849 iter/s, 207.104s/100 iters), loss = 0.00364131
I1004 15:50:07.089380  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00416493 (* 1 = 0.00416493 loss)
I1004 15:50:07.089390  5017 sgd_solver.cpp:165] Iteration 56500, lr = 0.001
I1004 15:52:51.449393  5017 solver.cpp:357] Iteration 56600 (0.608418 iter/s, 164.361s/100 iters), loss = 0.00541268
I1004 15:52:51.449492  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0012539 (* 1 = 0.0012539 loss)
I1004 15:52:51.449503  5017 sgd_solver.cpp:165] Iteration 56600, lr = 0.001
I1004 15:53:55.310468  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 15:55:35.972472  5017 solver.cpp:357] Iteration 56700 (0.607814 iter/s, 164.524s/100 iters), loss = 0.00428225
I1004 15:55:35.972607  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00309463 (* 1 = 0.00309463 loss)
I1004 15:55:35.972617  5017 sgd_solver.cpp:165] Iteration 56700, lr = 0.001
I1004 15:58:20.329983  5017 solver.cpp:357] Iteration 56800 (0.60842 iter/s, 164.36s/100 iters), loss = 0.00347232
I1004 15:58:20.330080  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00154324 (* 1 = 0.00154324 loss)
I1004 15:58:20.330090  5017 sgd_solver.cpp:165] Iteration 56800, lr = 0.001
I1004 16:01:04.792832  5017 solver.cpp:357] Iteration 56900 (0.608018 iter/s, 164.469s/100 iters), loss = 0.016794
I1004 16:01:04.792923  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00162175 (* 1 = 0.00162175 loss)
I1004 16:01:04.792934  5017 sgd_solver.cpp:165] Iteration 56900, lr = 0.001
I1004 16:03:47.747534  5017 solver.cpp:514] Iteration 57000, Testing net (#0)
I1004 16:04:30.036671  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 16:04:30.204823  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.17679 (* 1 = 0.17679 loss)
I1004 16:04:30.204849  5017 solver.cpp:580]     Test net output #1: prob = 0.956702
I1004 16:04:30.204861  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_57000.caffemodel
I1004 16:04:30.991609  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_57000.solverstate
I1004 16:04:31.301713  5017 solver.cpp:593]     Max_acc: 0.956702  with iter: 57000
I1004 16:04:32.930184  5017 solver.cpp:357] Iteration 57000 (0.480437 iter/s, 208.144s/100 iters), loss = 0.00270595
I1004 16:04:32.930241  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00286021 (* 1 = 0.00286021 loss)
I1004 16:04:32.930253  5017 sgd_solver.cpp:165] Iteration 57000, lr = 0.001
I1004 16:05:20.970937  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 16:07:17.314960  5017 solver.cpp:357] Iteration 57100 (0.608313 iter/s, 164.389s/100 iters), loss = 0.00582884
I1004 16:07:17.315054  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00137984 (* 1 = 0.00137984 loss)
I1004 16:07:17.315064  5017 sgd_solver.cpp:165] Iteration 57100, lr = 0.001
I1004 16:10:02.075284  5017 solver.cpp:357] Iteration 57200 (0.606928 iter/s, 164.764s/100 iters), loss = 0.00344174
I1004 16:10:02.075363  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0027161 (* 1 = 0.0027161 loss)
I1004 16:10:02.075374  5017 sgd_solver.cpp:165] Iteration 57200, lr = 0.001
I1004 16:12:47.087710  5017 solver.cpp:357] Iteration 57300 (0.606002 iter/s, 165.016s/100 iters), loss = 0.00285702
I1004 16:12:47.087863  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00224059 (* 1 = 0.00224059 loss)
I1004 16:12:47.087873  5017 sgd_solver.cpp:165] Iteration 57300, lr = 0.001
I1004 16:15:31.965371  5017 solver.cpp:357] Iteration 57400 (0.606499 iter/s, 164.881s/100 iters), loss = 0.0352615
I1004 16:15:31.965467  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00132553 (* 1 = 0.00132553 loss)
I1004 16:15:31.965477  5017 sgd_solver.cpp:165] Iteration 57400, lr = 0.001
I1004 16:16:04.941190  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 16:18:14.868114  5017 solver.cpp:514] Iteration 57500, Testing net (#0)
I1004 16:18:57.136881  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 16:18:57.306524  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.176053 (* 1 = 0.176053 loss)
I1004 16:18:57.306548  5017 solver.cpp:580]     Test net output #1: prob = 0.955702
I1004 16:18:57.306555  5017 solver.cpp:593]     Max_acc: 0.956702  with iter: 57000
I1004 16:18:58.931845  5017 solver.cpp:357] Iteration 57500 (0.483161 iter/s, 206.97s/100 iters), loss = 0.00307144
I1004 16:18:58.931900  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00188138 (* 1 = 0.00188138 loss)
I1004 16:18:58.931912  5017 sgd_solver.cpp:165] Iteration 57500, lr = 0.001
I1004 16:21:43.862175  5017 solver.cpp:357] Iteration 57600 (0.606306 iter/s, 164.933s/100 iters), loss = 0.00258183
I1004 16:21:43.862272  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0028007 (* 1 = 0.0028007 loss)
I1004 16:21:43.862282  5017 sgd_solver.cpp:165] Iteration 57600, lr = 0.001
I1004 16:24:28.868558  5017 solver.cpp:357] Iteration 57700 (0.606027 iter/s, 165.009s/100 iters), loss = 0.00398341
I1004 16:24:28.868701  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00360856 (* 1 = 0.00360856 loss)
I1004 16:24:28.868712  5017 sgd_solver.cpp:165] Iteration 57700, lr = 0.001
I1004 16:27:13.524969  5017 solver.cpp:357] Iteration 57800 (0.607316 iter/s, 164.659s/100 iters), loss = 0.0260502
I1004 16:27:13.525084  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0990222 (* 1 = 0.0990222 loss)
I1004 16:27:13.525100  5017 sgd_solver.cpp:165] Iteration 57800, lr = 0.001
I1004 16:27:30.789314  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 16:29:58.183073  5017 solver.cpp:357] Iteration 57900 (0.607309 iter/s, 164.661s/100 iters), loss = 0.0124748
I1004 16:29:58.183281  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00144717 (* 1 = 0.00144717 loss)
I1004 16:29:58.183293  5017 sgd_solver.cpp:165] Iteration 57900, lr = 0.001
I1004 16:32:40.979115  5017 solver.cpp:514] Iteration 58000, Testing net (#0)
I1004 16:33:23.272729  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 16:33:23.440341  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.174109 (* 1 = 0.174109 loss)
I1004 16:33:23.440366  5017 solver.cpp:580]     Test net output #1: prob = 0.955402
I1004 16:33:23.440372  5017 solver.cpp:593]     Max_acc: 0.956702  with iter: 57000
I1004 16:33:25.067715  5017 solver.cpp:357] Iteration 58000 (0.483317 iter/s, 206.904s/100 iters), loss = 0.00287023
I1004 16:33:25.067770  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00143332 (* 1 = 0.00143332 loss)
I1004 16:33:25.067780  5017 sgd_solver.cpp:165] Iteration 58000, lr = 0.001
I1004 16:36:09.943572  5017 solver.cpp:357] Iteration 58100 (0.606429 iter/s, 164.9s/100 iters), loss = 0.00248971
I1004 16:36:09.943724  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00183356 (* 1 = 0.00183356 loss)
I1004 16:36:09.943735  5017 sgd_solver.cpp:165] Iteration 58100, lr = 0.001
I1004 16:38:54.661386  5017 solver.cpp:357] Iteration 58200 (0.607028 iter/s, 164.737s/100 iters), loss = 0.00385077
I1004 16:38:54.661533  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00283532 (* 1 = 0.00283532 loss)
I1004 16:38:54.661545  5017 sgd_solver.cpp:165] Iteration 58200, lr = 0.001
I1004 16:38:56.774081  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 16:41:39.590890  5017 solver.cpp:357] Iteration 58300 (0.606261 iter/s, 164.945s/100 iters), loss = 0.00228812
I1004 16:41:39.591029  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.000946599 (* 1 = 0.000946599 loss)
I1004 16:41:39.591039  5017 sgd_solver.cpp:165] Iteration 58300, lr = 0.001
I1004 16:44:24.266763  5017 solver.cpp:357] Iteration 58400 (0.607204 iter/s, 164.689s/100 iters), loss = 0.00220792
I1004 16:44:24.266906  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00139107 (* 1 = 0.00139107 loss)
I1004 16:44:24.266916  5017 sgd_solver.cpp:165] Iteration 58400, lr = 0.001
I1004 16:47:07.135782  5017 solver.cpp:514] Iteration 58500, Testing net (#0)
I1004 16:47:49.442173  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 16:47:49.610190  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.177791 (* 1 = 0.177791 loss)
I1004 16:47:49.610216  5017 solver.cpp:580]     Test net output #1: prob = 0.954902
I1004 16:47:49.610222  5017 solver.cpp:593]     Max_acc: 0.956702  with iter: 57000
I1004 16:47:51.241125  5017 solver.cpp:357] Iteration 58500 (0.483118 iter/s, 206.989s/100 iters), loss = 0.00878166
I1004 16:47:51.241180  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00646902 (* 1 = 0.00646902 loss)
I1004 16:47:51.241191  5017 sgd_solver.cpp:165] Iteration 58500, lr = 0.001
I1004 16:50:22.013361  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 16:50:35.599831  5017 solver.cpp:357] Iteration 58600 (0.608388 iter/s, 164.369s/100 iters), loss = 0.00244466
I1004 16:50:35.599892  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00303442 (* 1 = 0.00303442 loss)
I1004 16:50:35.599902  5017 sgd_solver.cpp:165] Iteration 58600, lr = 0.001
I1004 16:53:20.240520  5017 solver.cpp:357] Iteration 58700 (0.607349 iter/s, 164.65s/100 iters), loss = 0.0029337
I1004 16:53:20.240654  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00607103 (* 1 = 0.00607103 loss)
I1004 16:53:20.240665  5017 sgd_solver.cpp:165] Iteration 58700, lr = 0.001
I1004 16:56:04.856817  5017 solver.cpp:357] Iteration 58800 (0.607441 iter/s, 164.625s/100 iters), loss = 0.0207634
I1004 16:56:04.856957  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00117937 (* 1 = 0.00117937 loss)
I1004 16:56:04.856968  5017 sgd_solver.cpp:165] Iteration 58800, lr = 0.001
I1004 16:58:49.450063  5017 solver.cpp:357] Iteration 58900 (0.607528 iter/s, 164.601s/100 iters), loss = 0.00300978
I1004 16:58:49.450163  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00310937 (* 1 = 0.00310937 loss)
I1004 16:58:49.450173  5017 sgd_solver.cpp:165] Iteration 58900, lr = 0.001
I1004 17:01:05.461941  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 17:01:32.630380  5017 solver.cpp:514] Iteration 59000, Testing net (#0)
I1004 17:02:14.930610  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 17:02:15.099431  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.173232 (* 1 = 0.173232 loss)
I1004 17:02:15.099457  5017 solver.cpp:580]     Test net output #1: prob = 0.956102
I1004 17:02:15.099463  5017 solver.cpp:593]     Max_acc: 0.956702  with iter: 57000
I1004 17:02:16.724061  5017 solver.cpp:357] Iteration 59000 (0.48243 iter/s, 207.284s/100 iters), loss = 0.00366442
I1004 17:02:16.724113  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0017809 (* 1 = 0.0017809 loss)
I1004 17:02:16.724126  5017 sgd_solver.cpp:165] Iteration 59000, lr = 0.001
I1004 17:05:01.135949  5017 solver.cpp:357] Iteration 59100 (0.6082 iter/s, 164.419s/100 iters), loss = 0.00181823
I1004 17:05:01.136046  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00259817 (* 1 = 0.00259817 loss)
I1004 17:05:01.136057  5017 sgd_solver.cpp:165] Iteration 59100, lr = 0.001
I1004 17:07:45.859952  5017 solver.cpp:357] Iteration 59200 (0.607131 iter/s, 164.709s/100 iters), loss = 0.0130634
I1004 17:07:45.860090  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00104176 (* 1 = 0.00104176 loss)
I1004 17:07:45.860100  5017 sgd_solver.cpp:165] Iteration 59200, lr = 0.001
I1004 17:10:30.648109  5017 solver.cpp:357] Iteration 59300 (0.606909 iter/s, 164.769s/100 iters), loss = 0.004301
I1004 17:10:30.648247  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00295052 (* 1 = 0.00295052 loss)
I1004 17:10:30.648257  5017 sgd_solver.cpp:165] Iteration 59300, lr = 0.001
I1004 17:12:30.735329  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 17:13:15.154728  5017 solver.cpp:357] Iteration 59400 (0.607925 iter/s, 164.494s/100 iters), loss = 0.00435874
I1004 17:13:15.154826  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00124725 (* 1 = 0.00124725 loss)
I1004 17:13:15.154836  5017 sgd_solver.cpp:165] Iteration 59400, lr = 0.001
I1004 17:15:58.118999  5017 solver.cpp:514] Iteration 59500, Testing net (#0)
I1004 17:16:40.428829  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 17:16:40.597434  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.175936 (* 1 = 0.175936 loss)
I1004 17:16:40.597460  5017 solver.cpp:580]     Test net output #1: prob = 0.956902
I1004 17:16:40.597470  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_59500.caffemodel
I1004 17:16:41.393071  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_59500.solverstate
I1004 17:16:41.699439  5017 solver.cpp:593]     Max_acc: 0.956902  with iter: 59500
I1004 17:16:43.326247  5017 solver.cpp:357] Iteration 59500 (0.480396 iter/s, 208.161s/100 iters), loss = 0.00360507
I1004 17:16:43.326308  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00348434 (* 1 = 0.00348434 loss)
I1004 17:16:43.326323  5017 sgd_solver.cpp:165] Iteration 59500, lr = 0.001
I1004 17:19:27.564959  5017 solver.cpp:357] Iteration 59600 (0.608887 iter/s, 164.234s/100 iters), loss = 0.00243678
I1004 17:19:27.565101  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00280506 (* 1 = 0.00280506 loss)
I1004 17:19:27.565111  5017 sgd_solver.cpp:165] Iteration 59600, lr = 0.001
I1004 17:22:12.346680  5017 solver.cpp:357] Iteration 59700 (0.606873 iter/s, 164.779s/100 iters), loss = 0.00335207
I1004 17:22:12.346827  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00398259 (* 1 = 0.00398259 loss)
I1004 17:22:12.346837  5017 sgd_solver.cpp:165] Iteration 59700, lr = 0.001
I1004 17:23:57.358513  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 17:24:57.063252  5017 solver.cpp:357] Iteration 59800 (0.607107 iter/s, 164.716s/100 iters), loss = 0.0034537
I1004 17:24:57.063397  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00141647 (* 1 = 0.00141647 loss)
I1004 17:24:57.063407  5017 sgd_solver.cpp:165] Iteration 59800, lr = 0.001
I1004 17:27:42.283828  5017 solver.cpp:357] Iteration 59900 (0.605251 iter/s, 165.221s/100 iters), loss = 0.00229389
I1004 17:27:42.283928  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00237948 (* 1 = 0.00237948 loss)
I1004 17:27:42.283938  5017 sgd_solver.cpp:165] Iteration 59900, lr = 0.001
I1004 17:30:25.249769  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_60000.caffemodel
I1004 17:30:26.048295  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_60000.solverstate
I1004 17:30:26.350694  5017 solver.cpp:514] Iteration 60000, Testing net (#0)
I1004 17:31:08.649504  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 17:31:08.819048  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.176749 (* 1 = 0.176749 loss)
I1004 17:31:08.819074  5017 solver.cpp:580]     Test net output #1: prob = 0.955502
I1004 17:31:08.819080  5017 solver.cpp:593]     Max_acc: 0.956902  with iter: 59500
I1004 17:31:10.444643  5017 solver.cpp:357] Iteration 60000 (0.480395 iter/s, 208.162s/100 iters), loss = 0.00202188
I1004 17:31:10.444696  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.000739415 (* 1 = 0.000739415 loss)
I1004 17:31:10.444707  5017 sgd_solver.cpp:165] Iteration 60000, lr = 0.001
I1004 17:33:54.879462  5017 solver.cpp:357] Iteration 60100 (0.608137 iter/s, 164.436s/100 iters), loss = 0.00342483
I1004 17:33:54.879601  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00389535 (* 1 = 0.00389535 loss)
I1004 17:33:54.879611  5017 sgd_solver.cpp:165] Iteration 60100, lr = 0.001
I1004 17:35:24.128880  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 17:36:39.250617  5017 solver.cpp:357] Iteration 60200 (0.608372 iter/s, 164.373s/100 iters), loss = 0.00251149
I1004 17:36:39.250753  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00191508 (* 1 = 0.00191508 loss)
I1004 17:36:39.250763  5017 sgd_solver.cpp:165] Iteration 60200, lr = 0.001
I1004 17:39:23.905920  5017 solver.cpp:357] Iteration 60300 (0.607321 iter/s, 164.658s/100 iters), loss = 0.0029306
I1004 17:39:23.906059  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00201898 (* 1 = 0.00201898 loss)
I1004 17:39:23.906069  5017 sgd_solver.cpp:165] Iteration 60300, lr = 0.001
I1004 17:42:08.292026  5017 solver.cpp:357] Iteration 60400 (0.608304 iter/s, 164.392s/100 iters), loss = 0.0149281
I1004 17:42:08.292165  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00425396 (* 1 = 0.00425396 loss)
I1004 17:42:08.292181  5017 sgd_solver.cpp:165] Iteration 60400, lr = 0.001
I1004 17:44:51.012389  5017 solver.cpp:514] Iteration 60500, Testing net (#0)
I1004 17:45:33.318624  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 17:45:33.487337  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.178003 (* 1 = 0.178003 loss)
I1004 17:45:33.487362  5017 solver.cpp:580]     Test net output #1: prob = 0.956202
I1004 17:45:33.487368  5017 solver.cpp:593]     Max_acc: 0.956902  with iter: 59500
I1004 17:45:35.112848  5017 solver.cpp:357] Iteration 60500 (0.483494 iter/s, 206.828s/100 iters), loss = 0.00325367
I1004 17:45:35.112902  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00241405 (* 1 = 0.00241405 loss)
I1004 17:45:35.112913  5017 sgd_solver.cpp:165] Iteration 60500, lr = 0.001
I1004 17:46:48.987460  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 17:48:19.291280  5017 solver.cpp:357] Iteration 60600 (0.609075 iter/s, 164.184s/100 iters), loss = 0.00183345
I1004 17:48:19.291422  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00228507 (* 1 = 0.00228507 loss)
I1004 17:48:19.291433  5017 sgd_solver.cpp:165] Iteration 60600, lr = 0.001
I1004 17:51:03.724655  5017 solver.cpp:357] Iteration 60700 (0.608132 iter/s, 164.438s/100 iters), loss = 0.00198066
I1004 17:51:03.724751  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00131979 (* 1 = 0.00131979 loss)
I1004 17:51:03.724761  5017 sgd_solver.cpp:165] Iteration 60700, lr = 0.001
I1004 17:53:48.020110  5017 solver.cpp:357] Iteration 60800 (0.608643 iter/s, 164.3s/100 iters), loss = 0.00381459
I1004 17:53:48.020208  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.000747179 (* 1 = 0.000747179 loss)
I1004 17:53:48.020220  5017 sgd_solver.cpp:165] Iteration 60800, lr = 0.001
I1004 17:56:32.329929  5017 solver.cpp:357] Iteration 60900 (0.608591 iter/s, 164.314s/100 iters), loss = 0.00400529
I1004 17:56:32.330018  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00772151 (* 1 = 0.00772151 loss)
I1004 17:56:32.330029  5017 sgd_solver.cpp:165] Iteration 60900, lr = 0.001
I1004 17:57:30.699685  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 17:59:15.086314  5017 solver.cpp:514] Iteration 61000, Testing net (#0)
I1004 17:59:57.399332  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 17:59:57.567667  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.176986 (* 1 = 0.176986 loss)
I1004 17:59:57.567692  5017 solver.cpp:580]     Test net output #1: prob = 0.955902
I1004 17:59:57.567698  5017 solver.cpp:593]     Max_acc: 0.956902  with iter: 59500
I1004 17:59:59.196413  5017 solver.cpp:357] Iteration 61000 (0.483392 iter/s, 206.872s/100 iters), loss = 0.00299502
I1004 17:59:59.196466  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00108571 (* 1 = 0.00108571 loss)
I1004 17:59:59.196480  5017 sgd_solver.cpp:165] Iteration 61000, lr = 0.001
I1004 18:02:43.373862  5017 solver.cpp:357] Iteration 61100 (0.609083 iter/s, 164.181s/100 iters), loss = 0.00580552
I1004 18:02:43.373960  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00245511 (* 1 = 0.00245511 loss)
I1004 18:02:43.373970  5017 sgd_solver.cpp:165] Iteration 61100, lr = 0.001
I1004 18:05:27.559703  5017 solver.cpp:357] Iteration 61200 (0.609052 iter/s, 164.19s/100 iters), loss = 0.00163476
I1004 18:05:27.559844  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00102501 (* 1 = 0.00102501 loss)
I1004 18:05:27.559854  5017 sgd_solver.cpp:165] Iteration 61200, lr = 0.001
I1004 18:08:11.873641  5017 solver.cpp:357] Iteration 61300 (0.608577 iter/s, 164.318s/100 iters), loss = 0.00264403
I1004 18:08:11.873734  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00541236 (* 1 = 0.00541236 loss)
I1004 18:08:11.873744  5017 sgd_solver.cpp:165] Iteration 61300, lr = 0.001
I1004 18:08:54.998383  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 18:10:56.342237  5017 solver.cpp:357] Iteration 61400 (0.608005 iter/s, 164.472s/100 iters), loss = 0.00278618
I1004 18:10:56.342339  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00174157 (* 1 = 0.00174157 loss)
I1004 18:10:56.342350  5017 sgd_solver.cpp:165] Iteration 61400, lr = 0.001
I1004 18:13:39.166885  5017 solver.cpp:514] Iteration 61500, Testing net (#0)
I1004 18:14:21.449565  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 18:14:21.618124  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.176976 (* 1 = 0.176976 loss)
I1004 18:14:21.618149  5017 solver.cpp:580]     Test net output #1: prob = 0.956402
I1004 18:14:21.618155  5017 solver.cpp:593]     Max_acc: 0.956902  with iter: 59500
I1004 18:14:23.242763  5017 solver.cpp:357] Iteration 61500 (0.483313 iter/s, 206.905s/100 iters), loss = 0.00311236
I1004 18:14:23.242816  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00176502 (* 1 = 0.00176502 loss)
I1004 18:14:23.242830  5017 sgd_solver.cpp:165] Iteration 61500, lr = 0.001
I1004 18:17:07.387828  5017 solver.cpp:357] Iteration 61600 (0.609201 iter/s, 164.15s/100 iters), loss = 0.0050349
I1004 18:17:07.387995  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00963343 (* 1 = 0.00963343 loss)
I1004 18:17:07.388006  5017 sgd_solver.cpp:165] Iteration 61600, lr = 0.001
I1004 18:19:51.610950  5017 solver.cpp:357] Iteration 61700 (0.608912 iter/s, 164.227s/100 iters), loss = 0.00413673
I1004 18:19:51.611097  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.000933902 (* 1 = 0.000933902 loss)
I1004 18:19:51.611112  5017 sgd_solver.cpp:165] Iteration 61700, lr = 0.001
I1004 18:20:19.143687  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 18:22:35.994990  5017 solver.cpp:357] Iteration 61800 (0.608316 iter/s, 164.388s/100 iters), loss = 0.00266549
I1004 18:22:35.995085  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00116384 (* 1 = 0.00116384 loss)
I1004 18:22:35.995097  5017 sgd_solver.cpp:165] Iteration 61800, lr = 0.001
I1004 18:25:20.366883  5017 solver.cpp:357] Iteration 61900 (0.608362 iter/s, 164.376s/100 iters), loss = 0.00457969
I1004 18:25:20.367028  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00418385 (* 1 = 0.00418385 loss)
I1004 18:25:20.367039  5017 sgd_solver.cpp:165] Iteration 61900, lr = 0.001
I1004 18:28:03.056691  5017 solver.cpp:514] Iteration 62000, Testing net (#0)
I1004 18:28:45.339500  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 18:28:45.509699  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.176462 (* 1 = 0.176462 loss)
I1004 18:28:45.509727  5017 solver.cpp:580]     Test net output #1: prob = 0.957202
I1004 18:28:45.509739  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_62000.caffemodel
I1004 18:28:46.297691  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_62000.solverstate
I1004 18:28:46.602825  5017 solver.cpp:593]     Max_acc: 0.957202  with iter: 62000
I1004 18:28:48.231976  5017 solver.cpp:357] Iteration 62000 (0.48107 iter/s, 207.87s/100 iters), loss = 0.00440496
I1004 18:28:48.232033  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00076287 (* 1 = 0.00076287 loss)
I1004 18:28:48.232043  5017 sgd_solver.cpp:165] Iteration 62000, lr = 0.001
I1004 18:31:32.438967  5017 solver.cpp:357] Iteration 62100 (0.608973 iter/s, 164.211s/100 iters), loss = 0.00394521
I1004 18:31:32.439067  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00771169 (* 1 = 0.00771169 loss)
I1004 18:31:32.439077  5017 sgd_solver.cpp:165] Iteration 62100, lr = 0.001
I1004 18:31:44.766808  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 18:34:16.624771  5017 solver.cpp:357] Iteration 62200 (0.609052 iter/s, 164.19s/100 iters), loss = 0.0107015
I1004 18:34:16.624866  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.012588 (* 1 = 0.012588 loss)
I1004 18:34:16.624877  5017 sgd_solver.cpp:165] Iteration 62200, lr = 0.001
I1004 18:37:00.796620  5017 solver.cpp:357] Iteration 62300 (0.609104 iter/s, 164.176s/100 iters), loss = 0.00729988
I1004 18:37:00.796753  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.0082938 (* 1 = 0.0082938 loss)
I1004 18:37:00.796763  5017 sgd_solver.cpp:165] Iteration 62300, lr = 0.001
I1004 18:39:45.102907  5017 solver.cpp:357] Iteration 62400 (0.608606 iter/s, 164.31s/100 iters), loss = 0.0114733
I1004 18:39:45.103047  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00252382 (* 1 = 0.00252382 loss)
I1004 18:39:45.103057  5017 sgd_solver.cpp:165] Iteration 62400, lr = 0.001
I1004 18:42:26.093658  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 18:42:27.728894  5017 solver.cpp:514] Iteration 62500, Testing net (#0)
I1004 18:43:10.075176  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 18:43:10.242943  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.177611 (* 1 = 0.177611 loss)
I1004 18:43:10.242967  5017 solver.cpp:580]     Test net output #1: prob = 0.956602
I1004 18:43:10.242974  5017 solver.cpp:593]     Max_acc: 0.957202  with iter: 62000
I1004 18:43:11.872571  5017 solver.cpp:357] Iteration 62500 (0.483619 iter/s, 206.774s/100 iters), loss = 0.00310165
I1004 18:43:11.872625  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00301488 (* 1 = 0.00301488 loss)
I1004 18:43:11.872637  5017 sgd_solver.cpp:165] Iteration 62500, lr = 0.001
I1004 18:45:56.013649  5017 solver.cpp:357] Iteration 62600 (0.609218 iter/s, 164.145s/100 iters), loss = 0.00869343
I1004 18:45:56.013800  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00443147 (* 1 = 0.00443147 loss)
I1004 18:45:56.013810  5017 sgd_solver.cpp:165] Iteration 62600, lr = 0.001
I1004 18:48:40.263550  5017 solver.cpp:357] Iteration 62700 (0.608805 iter/s, 164.256s/100 iters), loss = 0.00254083
I1004 18:48:40.263698  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00198129 (* 1 = 0.00198129 loss)
I1004 18:48:40.263710  5017 sgd_solver.cpp:165] Iteration 62700, lr = 0.001
I1004 18:51:24.552801  5017 solver.cpp:357] Iteration 62800 (0.608605 iter/s, 164.31s/100 iters), loss = 0.00330325
I1004 18:51:24.552939  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00710898 (* 1 = 0.00710898 loss)
I1004 18:51:24.552950  5017 sgd_solver.cpp:165] Iteration 62800, lr = 0.001
I1004 18:53:50.475319  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 18:54:08.954329  5017 solver.cpp:357] Iteration 62900 (0.608203 iter/s, 164.419s/100 iters), loss = 0.00366405
I1004 18:54:08.954390  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00558095 (* 1 = 0.00558095 loss)
I1004 18:54:08.954399  5017 sgd_solver.cpp:165] Iteration 62900, lr = 0.001
I1004 18:56:51.555563  5017 solver.cpp:514] Iteration 63000, Testing net (#0)
I1004 18:57:33.837074  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 18:57:34.005421  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.177664 (* 1 = 0.177664 loss)
I1004 18:57:34.005446  5017 solver.cpp:580]     Test net output #1: prob = 0.956202
I1004 18:57:34.005452  5017 solver.cpp:593]     Max_acc: 0.957202  with iter: 62000
I1004 18:57:35.635818  5017 solver.cpp:357] Iteration 63000 (0.483795 iter/s, 206.699s/100 iters), loss = 0.00515427
I1004 18:57:35.635874  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00179053 (* 1 = 0.00179053 loss)
I1004 18:57:35.635885  5017 sgd_solver.cpp:165] Iteration 63000, lr = 0.001
I1004 19:00:19.878069  5017 solver.cpp:357] Iteration 63100 (0.608812 iter/s, 164.254s/100 iters), loss = 0.00486886
I1004 19:00:19.878202  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00473582 (* 1 = 0.00473582 loss)
I1004 19:00:19.878213  5017 sgd_solver.cpp:165] Iteration 63100, lr = 0.001
I1004 19:03:04.151214  5017 solver.cpp:357] Iteration 63200 (0.608703 iter/s, 164.284s/100 iters), loss = 0.00236668
I1004 19:03:04.151341  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00178567 (* 1 = 0.00178567 loss)
I1004 19:03:04.151351  5017 sgd_solver.cpp:165] Iteration 63200, lr = 0.001
I1004 19:05:14.373544  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 19:05:48.450155  5017 solver.cpp:357] Iteration 63300 (0.608611 iter/s, 164.308s/100 iters), loss = 0.00159177
I1004 19:05:48.450291  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.000950001 (* 1 = 0.000950001 loss)
I1004 19:05:48.450307  5017 sgd_solver.cpp:165] Iteration 63300, lr = 0.001
I1004 19:08:32.634946  5017 solver.cpp:357] Iteration 63400 (0.609037 iter/s, 164.194s/100 iters), loss = 0.00386084
I1004 19:08:32.635035  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00166258 (* 1 = 0.00166258 loss)
I1004 19:08:32.635046  5017 sgd_solver.cpp:165] Iteration 63400, lr = 0.001
I1004 19:11:15.246168  5017 solver.cpp:514] Iteration 63500, Testing net (#0)
I1004 19:11:57.534211  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 19:11:57.702947  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.178377 (* 1 = 0.178377 loss)
I1004 19:11:57.702973  5017 solver.cpp:580]     Test net output #1: prob = 0.956502
I1004 19:11:57.702980  5017 solver.cpp:593]     Max_acc: 0.957202  with iter: 62000
I1004 19:11:59.331737  5017 solver.cpp:357] Iteration 63500 (0.483776 iter/s, 206.707s/100 iters), loss = 0.00693675
I1004 19:11:59.331790  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00335904 (* 1 = 0.00335904 loss)
I1004 19:11:59.331801  5017 sgd_solver.cpp:165] Iteration 63500, lr = 0.001
I1004 19:14:43.597146  5017 solver.cpp:357] Iteration 63600 (0.608742 iter/s, 164.273s/100 iters), loss = 0.0023802
I1004 19:14:43.597321  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.000723039 (* 1 = 0.000723039 loss)
I1004 19:14:43.597333  5017 sgd_solver.cpp:165] Iteration 63600, lr = 0.001
I1004 19:16:38.744290  5023 data_layer.cpp:73] Restarting data prefetching from start.
I1004 19:17:28.136111  5017 solver.cpp:357] Iteration 63700 (0.607731 iter/s, 164.547s/100 iters), loss = 0.00499647
I1004 19:17:28.136262  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00197755 (* 1 = 0.00197755 loss)
I1004 19:17:28.136273  5017 sgd_solver.cpp:165] Iteration 63700, lr = 0.001
I1004 19:20:12.494536  5017 solver.cpp:357] Iteration 63800 (0.608399 iter/s, 164.366s/100 iters), loss = 0.00124575
I1004 19:20:12.494680  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00103967 (* 1 = 0.00103967 loss)
I1004 19:20:12.494691  5017 sgd_solver.cpp:165] Iteration 63800, lr = 0.001
I1004 19:22:56.777380  5017 solver.cpp:357] Iteration 63900 (0.608706 iter/s, 164.283s/100 iters), loss = 0.00486307
I1004 19:22:56.777531  5017 solver.cpp:376]     Train net output #0: Softmax1 = 0.00214093 (* 1 = 0.00214093 loss)
I1004 19:22:56.777541  5017 sgd_solver.cpp:165] Iteration 63900, lr = 0.001
I1004 19:25:39.563168  5017 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_WRN_28_iter_64000.caffemodel
I1004 19:25:40.350219  5017 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_WRN_28_iter_64000.solverstate
I1004 19:25:40.771267  5017 solver.cpp:472] Iteration 64000, loss = 0.00132992
I1004 19:25:40.771317  5017 solver.cpp:514] Iteration 64000, Testing net (#0)
I1004 19:26:23.063171  5024 data_layer.cpp:73] Restarting data prefetching from start.
I1004 19:26:23.232195  5017 solver.cpp:580]     Test net output #0: Softmax1 = 0.176646 (* 1 = 0.176646 loss)
I1004 19:26:23.232220  5017 solver.cpp:580]     Test net output #1: prob = 0.956002
I1004 19:26:23.232226  5017 solver.cpp:593]     Max_acc: 0.957202  with iter: 62000
I1004 19:26:23.232234  5017 solver.cpp:479] Optimization Done.
I1004 19:26:23.232239  5017 caffe.cpp:326] Optimization Done.
