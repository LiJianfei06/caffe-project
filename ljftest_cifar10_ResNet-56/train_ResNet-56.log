WARNING: Logging before InitGoogleLogging() is written to STDERR
I0818 10:58:36.424931  3083 caffe.cpp:530] argc:5 lijianfei debug!!!!!!!!!!
I0818 10:58:36.425072  3083 caffe.cpp:533] argv[0]:../../build/tools/caffe lijianfei debug!!!!!!!!!!
I0818 10:58:36.425078  3083 caffe.cpp:533] argv[1]:train lijianfei debug!!!!!!!!!!
I0818 10:58:36.425082  3083 caffe.cpp:533] argv[2]:--solver=./solver.prototxt lijianfei debug!!!!!!!!!!
I0818 10:58:36.425086  3083 caffe.cpp:533] argv[3]:--weights= lijianfei debug!!!!!!!!!!
I0818 10:58:36.425089  3083 caffe.cpp:533] argv[4]:--gpu=0 lijianfei debug!!!!!!!!!!
I0818 10:58:36.425151  3083 caffe.cpp:548] use WITH_PYTHON_LAYER lijianfei debug!!!!!!!!!!
I0818 10:58:36.425328  3083 caffe.cpp:553] caffe::string(argv[1]):train lijianfei debug!!!!!!!!!!
I0818 10:58:36.427117  3083 caffe.cpp:238] stages: lijianfei debug!!!!!!!!!!!!
I0818 10:58:36.427150  3083 caffe.cpp:269] Using GPUs 0
I0818 10:58:36.433266  3083 caffe.cpp:274] GPU 0: GeForce GTX 1060 6GB
I0818 10:58:37.220713  3083 solver_factory.hpp:111] function Solver<Dtype>* CreateSolver()  lijianfei debug!!!!!!!!!!
I0818 10:58:37.220762  3083 solver_factory.hpp:113] type:Nesterov lijianfei debug!!!!!!!!!!
I0818 10:58:37.357043  3083 solver.cpp:97] Initializing solver from parameters: 
train_net: "./train_ResNet_56.prototxt"
test_net: "./test_ResNet_56.prototxt"
test_iter: 1000
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "./model_save/cifar10_ResNet_56"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
stepvalue: 32000
stepvalue: 48000
iter_size: 2
type: "Nesterov"
I0818 10:58:37.357319  3083 solver.cpp:167] Creating training net from train_net file: ./train_ResNet_56.prototxt
I0818 10:58:37.359341  3083 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./train_ResNet_56.prototxt
I0818 10:58:37.359375  3083 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0818 10:58:37.359818  3083 net.cpp:390] layer_param.include_size():1
I0818 10:58:37.359835  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359844  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359848  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359853  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359858  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359861  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359865  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359869  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359874  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359877  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359880  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359886  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359890  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359894  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359899  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359902  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359906  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359910  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359913  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359920  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359922  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359926  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359930  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359935  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359939  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359943  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359947  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359952  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359956  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359961  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359963  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359968  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359972  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359975  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359979  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359983  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.359987  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.359992  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360023  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360028  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360033  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360036  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360040  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360044  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360047  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360051  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360055  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360059  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360064  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360067  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360071  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360075  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360080  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360082  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360086  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360090  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360095  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360098  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360102  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360106  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360110  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360114  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360118  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360122  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360126  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360129  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360133  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360137  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360141  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360146  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360149  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360153  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360157  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360160  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360164  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360168  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360172  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360177  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360180  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360184  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360188  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360193  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360196  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360200  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360203  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360208  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360211  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360215  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360219  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360224  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360227  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360231  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360234  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360239  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360242  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360246  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360250  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360261  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360265  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360270  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360273  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360277  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360281  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360285  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360289  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360293  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360297  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360301  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360304  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360308  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360312  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360316  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360319  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360324  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360327  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360332  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360335  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360339  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360342  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360347  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360350  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360354  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360358  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360363  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360365  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360369  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360373  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360378  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360381  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360385  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360388  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360393  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360396  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360400  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360404  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360409  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360411  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360416  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360419  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360424  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360427  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360431  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360435  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360440  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360442  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360447  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360451  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360455  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360458  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360462  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360466  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360471  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360474  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360478  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360481  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360493  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360497  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360502  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360505  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360509  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360513  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360517  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360522  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360525  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360529  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360533  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360536  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360541  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360544  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360548  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360553  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360556  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360559  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360564  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360568  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360571  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360575  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360579  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360584  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360587  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360590  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360594  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360599  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360602  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360606  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360610  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360613  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360618  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360622  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360626  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360630  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360635  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360637  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360641  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360646  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360649  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360653  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360657  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360661  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360666  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360668  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360672  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360677  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360680  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360683  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360688  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360692  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360695  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360699  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360703  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360707  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360710  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360714  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360718  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360729  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360733  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360738  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360741  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360745  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360749  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360752  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360756  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360760  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360764  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360767  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360772  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360775  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360780  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360783  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360787  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360790  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360795  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360798  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360802  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360805  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360810  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360813  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360817  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360821  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360824  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360828  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360832  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360836  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360839  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360843  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360847  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360851  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360854  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360858  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360862  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360865  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360869  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360873  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360877  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360882  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360884  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360888  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360893  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360895  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360900  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360903  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360908  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360911  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360914  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360918  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360922  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360926  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360929  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360934  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360937  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360941  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360945  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360955  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360960  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360962  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360966  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360970  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360975  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360978  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360982  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360985  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360990  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.360993  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.360997  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361001  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361004  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361008  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361012  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361016  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361019  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361023  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361027  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361032  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361034  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361038  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361042  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361047  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361050  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361053  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361057  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361061  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361065  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361069  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361073  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361076  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361080  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361084  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361088  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361093  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361095  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361099  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361104  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361106  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361111  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361114  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361119  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361122  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361126  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361129  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361133  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361137  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361141  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361145  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361148  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361152  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361156  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361160  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361163  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361167  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361171  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361174  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361186  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361189  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361193  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361197  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361202  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361205  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361209  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361212  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361217  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361220  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361224  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361227  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361232  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361235  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361239  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361243  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361248  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361250  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361254  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361258  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361263  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361265  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361269  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361274  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361277  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361281  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361284  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361289  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361292  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361295  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361299  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361304  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361307  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361310  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361315  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361318  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361322  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361326  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361330  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361333  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361337  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361341  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361346  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361349  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361353  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361357  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361361  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361364  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361368  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361372  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361376  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361379  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361383  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361387  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361392  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361394  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361398  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361402  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361413  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361415  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361420  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361423  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361428  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361431  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361435  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361438  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361443  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361446  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361450  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361454  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361457  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361461  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361465  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361469  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361472  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361476  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361480  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361483  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361487  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361491  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361495  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361500  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361502  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361506  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361510  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361513  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361517  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361521  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361526  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361528  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361532  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361536  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361541  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361543  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361547  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361552  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361555  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361558  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361562  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361567  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361570  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361573  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361577  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361582  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361585  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361588  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361593  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361596  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361600  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361604  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361608  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361611  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361615  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361619  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361624  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361626  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361630  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361641  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361645  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361649  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361652  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361656  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361660  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361663  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361668  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361671  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361675  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361680  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361683  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361686  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361690  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361694  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361698  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361701  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361706  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361709  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361713  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361716  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361721  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361724  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361728  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361732  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361735  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361739  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361743  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361747  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361750  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361754  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361757  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361762  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361765  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361769  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361773  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361776  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361780  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361784  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361788  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361791  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361795  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361799  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361804  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361807  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361811  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361814  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361819  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361822  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361826  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361829  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361834  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361837  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361841  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361845  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361848  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361852  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361856  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361865  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361871  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361873  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361878  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361881  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.361886  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:37.361889  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:37.363559  3083 net.cpp:82] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215684
    mirror: true
    crop_size: 32
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/train_lmdb"
    batch_size: 64
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution29"
  top: "Convolution29"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Convolution29"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution30"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution31"
  top: "Convolution31"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Convolution31"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution32"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwi
I0818 10:58:37.364755  3083 layer_factory.hpp:77] Creating layer Data1
I0818 10:58:37.364943  3083 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/train_lmdb
I0818 10:58:37.365000  3083 net.cpp:128] Creating Layer Data1
I0818 10:58:37.365011  3083 net.cpp:522] Data1 -> Data1
I0818 10:58:37.365044  3083 net.cpp:522] Data1 -> Data2
I0818 10:58:37.366796  3083 data_layer.cpp:45] output data size: 64,3,32,32
I0818 10:58:37.378634  3083 net.cpp:172] Setting up Data1
I0818 10:58:37.378695  3083 net.cpp:186] Top shape: 64 3 32 32 (196608)
I0818 10:58:37.378700  3083 net.cpp:186] Top shape: 64 (64)
I0818 10:58:37.378705  3083 net.cpp:194] Memory required for data: 786688
I0818 10:58:37.378718  3083 layer_factory.hpp:77] Creating layer Convolution1
I0818 10:58:37.378749  3083 net.cpp:128] Creating Layer Convolution1
I0818 10:58:37.378760  3083 net.cpp:558] Convolution1 <- Data1
I0818 10:58:37.378779  3083 net.cpp:522] Convolution1 -> Convolution1
I0818 10:58:38.534807  3083 net.cpp:172] Setting up Convolution1
I0818 10:58:38.534871  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.534876  3083 net.cpp:194] Memory required for data: 4980992
I0818 10:58:38.534924  3083 layer_factory.hpp:77] Creating layer BatchNorm1
I0818 10:58:38.535008  3083 net.cpp:128] Creating Layer BatchNorm1
I0818 10:58:38.535027  3083 net.cpp:558] BatchNorm1 <- Convolution1
I0818 10:58:38.535050  3083 net.cpp:509] BatchNorm1 -> Convolution1 (in-place)
I0818 10:58:38.535303  3083 net.cpp:172] Setting up BatchNorm1
I0818 10:58:38.535315  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.535320  3083 net.cpp:194] Memory required for data: 9175296
I0818 10:58:38.535334  3083 layer_factory.hpp:77] Creating layer Scale1
I0818 10:58:38.535346  3083 net.cpp:128] Creating Layer Scale1
I0818 10:58:38.535351  3083 net.cpp:558] Scale1 <- Convolution1
I0818 10:58:38.535378  3083 net.cpp:509] Scale1 -> Convolution1 (in-place)
I0818 10:58:38.535446  3083 layer_factory.hpp:77] Creating layer Scale1
I0818 10:58:38.535578  3083 net.cpp:172] Setting up Scale1
I0818 10:58:38.535588  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.535593  3083 net.cpp:194] Memory required for data: 13369600
I0818 10:58:38.535622  3083 layer_factory.hpp:77] Creating layer ReLU1
I0818 10:58:38.535670  3083 net.cpp:128] Creating Layer ReLU1
I0818 10:58:38.535689  3083 net.cpp:558] ReLU1 <- Convolution1
I0818 10:58:38.535709  3083 net.cpp:509] ReLU1 -> Convolution1 (in-place)
I0818 10:58:38.536495  3083 net.cpp:172] Setting up ReLU1
I0818 10:58:38.536526  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.536545  3083 net.cpp:194] Memory required for data: 17563904
I0818 10:58:38.536556  3083 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0818 10:58:38.536566  3083 net.cpp:128] Creating Layer Convolution1_ReLU1_0_split
I0818 10:58:38.536569  3083 net.cpp:558] Convolution1_ReLU1_0_split <- Convolution1
I0818 10:58:38.536577  3083 net.cpp:522] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0818 10:58:38.536586  3083 net.cpp:522] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0818 10:58:38.536634  3083 net.cpp:172] Setting up Convolution1_ReLU1_0_split
I0818 10:58:38.536643  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.536648  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.536653  3083 net.cpp:194] Memory required for data: 25952512
I0818 10:58:38.536658  3083 layer_factory.hpp:77] Creating layer Convolution2
I0818 10:58:38.536672  3083 net.cpp:128] Creating Layer Convolution2
I0818 10:58:38.536677  3083 net.cpp:558] Convolution2 <- Convolution1_ReLU1_0_split_0
I0818 10:58:38.536684  3083 net.cpp:522] Convolution2 -> Convolution2
I0818 10:58:38.548725  3083 net.cpp:172] Setting up Convolution2
I0818 10:58:38.548761  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.548766  3083 net.cpp:194] Memory required for data: 30146816
I0818 10:58:38.548782  3083 layer_factory.hpp:77] Creating layer BatchNorm2
I0818 10:58:38.548830  3083 net.cpp:128] Creating Layer BatchNorm2
I0818 10:58:38.548844  3083 net.cpp:558] BatchNorm2 <- Convolution2
I0818 10:58:38.548866  3083 net.cpp:509] BatchNorm2 -> Convolution2 (in-place)
I0818 10:58:38.549103  3083 net.cpp:172] Setting up BatchNorm2
I0818 10:58:38.549115  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.549119  3083 net.cpp:194] Memory required for data: 34341120
I0818 10:58:38.549130  3083 layer_factory.hpp:77] Creating layer Scale2
I0818 10:58:38.549160  3083 net.cpp:128] Creating Layer Scale2
I0818 10:58:38.549175  3083 net.cpp:558] Scale2 <- Convolution2
I0818 10:58:38.549193  3083 net.cpp:509] Scale2 -> Convolution2 (in-place)
I0818 10:58:38.549252  3083 layer_factory.hpp:77] Creating layer Scale2
I0818 10:58:38.549389  3083 net.cpp:172] Setting up Scale2
I0818 10:58:38.549401  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.549405  3083 net.cpp:194] Memory required for data: 38535424
I0818 10:58:38.549413  3083 layer_factory.hpp:77] Creating layer ReLU2
I0818 10:58:38.549439  3083 net.cpp:128] Creating Layer ReLU2
I0818 10:58:38.549454  3083 net.cpp:558] ReLU2 <- Convolution2
I0818 10:58:38.549470  3083 net.cpp:509] ReLU2 -> Convolution2 (in-place)
I0818 10:58:38.552919  3083 net.cpp:172] Setting up ReLU2
I0818 10:58:38.552939  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.552943  3083 net.cpp:194] Memory required for data: 42729728
I0818 10:58:38.552949  3083 layer_factory.hpp:77] Creating layer Convolution3
I0818 10:58:38.552963  3083 net.cpp:128] Creating Layer Convolution3
I0818 10:58:38.552968  3083 net.cpp:558] Convolution3 <- Convolution2
I0818 10:58:38.552975  3083 net.cpp:522] Convolution3 -> Convolution3
I0818 10:58:38.565724  3083 net.cpp:172] Setting up Convolution3
I0818 10:58:38.565750  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.565754  3083 net.cpp:194] Memory required for data: 46924032
I0818 10:58:38.565764  3083 layer_factory.hpp:77] Creating layer BatchNorm3
I0818 10:58:38.565775  3083 net.cpp:128] Creating Layer BatchNorm3
I0818 10:58:38.565779  3083 net.cpp:558] BatchNorm3 <- Convolution3
I0818 10:58:38.565788  3083 net.cpp:509] BatchNorm3 -> Convolution3 (in-place)
I0818 10:58:38.566004  3083 net.cpp:172] Setting up BatchNorm3
I0818 10:58:38.566061  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.566076  3083 net.cpp:194] Memory required for data: 51118336
I0818 10:58:38.566099  3083 layer_factory.hpp:77] Creating layer Scale3
I0818 10:58:38.566118  3083 net.cpp:128] Creating Layer Scale3
I0818 10:58:38.566135  3083 net.cpp:558] Scale3 <- Convolution3
I0818 10:58:38.566153  3083 net.cpp:509] Scale3 -> Convolution3 (in-place)
I0818 10:58:38.566211  3083 layer_factory.hpp:77] Creating layer Scale3
I0818 10:58:38.566349  3083 net.cpp:172] Setting up Scale3
I0818 10:58:38.566371  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.566385  3083 net.cpp:194] Memory required for data: 55312640
I0818 10:58:38.566404  3083 layer_factory.hpp:77] Creating layer Eltwise1
I0818 10:58:38.566423  3083 net.cpp:128] Creating Layer Eltwise1
I0818 10:58:38.566440  3083 net.cpp:558] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0818 10:58:38.566455  3083 net.cpp:558] Eltwise1 <- Convolution3
I0818 10:58:38.566473  3083 net.cpp:522] Eltwise1 -> Eltwise1
I0818 10:58:38.566515  3083 net.cpp:172] Setting up Eltwise1
I0818 10:58:38.566534  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.566546  3083 net.cpp:194] Memory required for data: 59506944
I0818 10:58:38.566560  3083 layer_factory.hpp:77] Creating layer ReLU3
I0818 10:58:38.566577  3083 net.cpp:128] Creating Layer ReLU3
I0818 10:58:38.566591  3083 net.cpp:558] ReLU3 <- Eltwise1
I0818 10:58:38.566606  3083 net.cpp:509] ReLU3 -> Eltwise1 (in-place)
I0818 10:58:38.567883  3083 net.cpp:172] Setting up ReLU3
I0818 10:58:38.567909  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.567914  3083 net.cpp:194] Memory required for data: 63701248
I0818 10:58:38.567919  3083 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0818 10:58:38.567929  3083 net.cpp:128] Creating Layer Eltwise1_ReLU3_0_split
I0818 10:58:38.567934  3083 net.cpp:558] Eltwise1_ReLU3_0_split <- Eltwise1
I0818 10:58:38.567940  3083 net.cpp:522] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0818 10:58:38.567951  3083 net.cpp:522] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0818 10:58:38.567996  3083 net.cpp:172] Setting up Eltwise1_ReLU3_0_split
I0818 10:58:38.568037  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.568053  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.568066  3083 net.cpp:194] Memory required for data: 72089856
I0818 10:58:38.568080  3083 layer_factory.hpp:77] Creating layer Convolution4
I0818 10:58:38.568102  3083 net.cpp:128] Creating Layer Convolution4
I0818 10:58:38.568117  3083 net.cpp:558] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0818 10:58:38.568135  3083 net.cpp:522] Convolution4 -> Convolution4
I0818 10:58:38.574712  3083 net.cpp:172] Setting up Convolution4
I0818 10:58:38.574736  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.574740  3083 net.cpp:194] Memory required for data: 76284160
I0818 10:58:38.574751  3083 layer_factory.hpp:77] Creating layer BatchNorm4
I0818 10:58:38.574761  3083 net.cpp:128] Creating Layer BatchNorm4
I0818 10:58:38.574766  3083 net.cpp:558] BatchNorm4 <- Convolution4
I0818 10:58:38.574774  3083 net.cpp:509] BatchNorm4 -> Convolution4 (in-place)
I0818 10:58:38.574996  3083 net.cpp:172] Setting up BatchNorm4
I0818 10:58:38.575036  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.575057  3083 net.cpp:194] Memory required for data: 80478464
I0818 10:58:38.575080  3083 layer_factory.hpp:77] Creating layer Scale4
I0818 10:58:38.575098  3083 net.cpp:128] Creating Layer Scale4
I0818 10:58:38.575116  3083 net.cpp:558] Scale4 <- Convolution4
I0818 10:58:38.575132  3083 net.cpp:509] Scale4 -> Convolution4 (in-place)
I0818 10:58:38.575191  3083 layer_factory.hpp:77] Creating layer Scale4
I0818 10:58:38.575331  3083 net.cpp:172] Setting up Scale4
I0818 10:58:38.575354  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.575368  3083 net.cpp:194] Memory required for data: 84672768
I0818 10:58:38.575387  3083 layer_factory.hpp:77] Creating layer ReLU4
I0818 10:58:38.575414  3083 net.cpp:128] Creating Layer ReLU4
I0818 10:58:38.575428  3083 net.cpp:558] ReLU4 <- Convolution4
I0818 10:58:38.575443  3083 net.cpp:509] ReLU4 -> Convolution4 (in-place)
I0818 10:58:38.576829  3083 net.cpp:172] Setting up ReLU4
I0818 10:58:38.576848  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.576853  3083 net.cpp:194] Memory required for data: 88867072
I0818 10:58:38.576856  3083 layer_factory.hpp:77] Creating layer Convolution5
I0818 10:58:38.576869  3083 net.cpp:128] Creating Layer Convolution5
I0818 10:58:38.576874  3083 net.cpp:558] Convolution5 <- Convolution4
I0818 10:58:38.576881  3083 net.cpp:522] Convolution5 -> Convolution5
I0818 10:58:38.583729  3083 net.cpp:172] Setting up Convolution5
I0818 10:58:38.583777  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.583796  3083 net.cpp:194] Memory required for data: 93061376
I0818 10:58:38.583817  3083 layer_factory.hpp:77] Creating layer BatchNorm5
I0818 10:58:38.583837  3083 net.cpp:128] Creating Layer BatchNorm5
I0818 10:58:38.583851  3083 net.cpp:558] BatchNorm5 <- Convolution5
I0818 10:58:38.583868  3083 net.cpp:509] BatchNorm5 -> Convolution5 (in-place)
I0818 10:58:38.584116  3083 net.cpp:172] Setting up BatchNorm5
I0818 10:58:38.584141  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.584163  3083 net.cpp:194] Memory required for data: 97255680
I0818 10:58:38.584187  3083 layer_factory.hpp:77] Creating layer Scale5
I0818 10:58:38.584204  3083 net.cpp:128] Creating Layer Scale5
I0818 10:58:38.584221  3083 net.cpp:558] Scale5 <- Convolution5
I0818 10:58:38.584237  3083 net.cpp:509] Scale5 -> Convolution5 (in-place)
I0818 10:58:38.584295  3083 layer_factory.hpp:77] Creating layer Scale5
I0818 10:58:38.584436  3083 net.cpp:172] Setting up Scale5
I0818 10:58:38.584458  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.584475  3083 net.cpp:194] Memory required for data: 101449984
I0818 10:58:38.584494  3083 layer_factory.hpp:77] Creating layer Eltwise2
I0818 10:58:38.584514  3083 net.cpp:128] Creating Layer Eltwise2
I0818 10:58:38.584530  3083 net.cpp:558] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0818 10:58:38.584545  3083 net.cpp:558] Eltwise2 <- Convolution5
I0818 10:58:38.584564  3083 net.cpp:522] Eltwise2 -> Eltwise2
I0818 10:58:38.584606  3083 net.cpp:172] Setting up Eltwise2
I0818 10:58:38.584625  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.584640  3083 net.cpp:194] Memory required for data: 105644288
I0818 10:58:38.584655  3083 layer_factory.hpp:77] Creating layer ReLU5
I0818 10:58:38.584672  3083 net.cpp:128] Creating Layer ReLU5
I0818 10:58:38.584686  3083 net.cpp:558] ReLU5 <- Eltwise2
I0818 10:58:38.584703  3083 net.cpp:509] ReLU5 -> Eltwise2 (in-place)
I0818 10:58:38.587930  3083 net.cpp:172] Setting up ReLU5
I0818 10:58:38.587947  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.587951  3083 net.cpp:194] Memory required for data: 109838592
I0818 10:58:38.587956  3083 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0818 10:58:38.587965  3083 net.cpp:128] Creating Layer Eltwise2_ReLU5_0_split
I0818 10:58:38.587968  3083 net.cpp:558] Eltwise2_ReLU5_0_split <- Eltwise2
I0818 10:58:38.587976  3083 net.cpp:522] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0818 10:58:38.588014  3083 net.cpp:522] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0818 10:58:38.588081  3083 net.cpp:172] Setting up Eltwise2_ReLU5_0_split
I0818 10:58:38.588101  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.588120  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.588133  3083 net.cpp:194] Memory required for data: 118227200
I0818 10:58:38.588148  3083 layer_factory.hpp:77] Creating layer Convolution6
I0818 10:58:38.588169  3083 net.cpp:128] Creating Layer Convolution6
I0818 10:58:38.588183  3083 net.cpp:558] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0818 10:58:38.588201  3083 net.cpp:522] Convolution6 -> Convolution6
I0818 10:58:38.601079  3083 net.cpp:172] Setting up Convolution6
I0818 10:58:38.601121  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.601125  3083 net.cpp:194] Memory required for data: 122421504
I0818 10:58:38.601136  3083 layer_factory.hpp:77] Creating layer BatchNorm6
I0818 10:58:38.601145  3083 net.cpp:128] Creating Layer BatchNorm6
I0818 10:58:38.601150  3083 net.cpp:558] BatchNorm6 <- Convolution6
I0818 10:58:38.601156  3083 net.cpp:509] BatchNorm6 -> Convolution6 (in-place)
I0818 10:58:38.601423  3083 net.cpp:172] Setting up BatchNorm6
I0818 10:58:38.601433  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.601438  3083 net.cpp:194] Memory required for data: 126615808
I0818 10:58:38.601449  3083 layer_factory.hpp:77] Creating layer Scale6
I0818 10:58:38.601477  3083 net.cpp:128] Creating Layer Scale6
I0818 10:58:38.601491  3083 net.cpp:558] Scale6 <- Convolution6
I0818 10:58:38.601513  3083 net.cpp:509] Scale6 -> Convolution6 (in-place)
I0818 10:58:38.601579  3083 layer_factory.hpp:77] Creating layer Scale6
I0818 10:58:38.601728  3083 net.cpp:172] Setting up Scale6
I0818 10:58:38.601739  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.601744  3083 net.cpp:194] Memory required for data: 130810112
I0818 10:58:38.601752  3083 layer_factory.hpp:77] Creating layer ReLU6
I0818 10:58:38.601779  3083 net.cpp:128] Creating Layer ReLU6
I0818 10:58:38.601794  3083 net.cpp:558] ReLU6 <- Convolution6
I0818 10:58:38.601809  3083 net.cpp:509] ReLU6 -> Convolution6 (in-place)
I0818 10:58:38.605312  3083 net.cpp:172] Setting up ReLU6
I0818 10:58:38.605340  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.605346  3083 net.cpp:194] Memory required for data: 135004416
I0818 10:58:38.605351  3083 layer_factory.hpp:77] Creating layer Convolution7
I0818 10:58:38.605365  3083 net.cpp:128] Creating Layer Convolution7
I0818 10:58:38.605399  3083 net.cpp:558] Convolution7 <- Convolution6
I0818 10:58:38.605418  3083 net.cpp:522] Convolution7 -> Convolution7
I0818 10:58:38.616103  3083 net.cpp:172] Setting up Convolution7
I0818 10:58:38.616133  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.616138  3083 net.cpp:194] Memory required for data: 139198720
I0818 10:58:38.616148  3083 layer_factory.hpp:77] Creating layer BatchNorm7
I0818 10:58:38.616158  3083 net.cpp:128] Creating Layer BatchNorm7
I0818 10:58:38.616161  3083 net.cpp:558] BatchNorm7 <- Convolution7
I0818 10:58:38.616171  3083 net.cpp:509] BatchNorm7 -> Convolution7 (in-place)
I0818 10:58:38.616411  3083 net.cpp:172] Setting up BatchNorm7
I0818 10:58:38.616456  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.616470  3083 net.cpp:194] Memory required for data: 143393024
I0818 10:58:38.616490  3083 layer_factory.hpp:77] Creating layer Scale7
I0818 10:58:38.616516  3083 net.cpp:128] Creating Layer Scale7
I0818 10:58:38.616533  3083 net.cpp:558] Scale7 <- Convolution7
I0818 10:58:38.616549  3083 net.cpp:509] Scale7 -> Convolution7 (in-place)
I0818 10:58:38.616611  3083 layer_factory.hpp:77] Creating layer Scale7
I0818 10:58:38.616765  3083 net.cpp:172] Setting up Scale7
I0818 10:58:38.616788  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.616801  3083 net.cpp:194] Memory required for data: 147587328
I0818 10:58:38.616819  3083 layer_factory.hpp:77] Creating layer Eltwise3
I0818 10:58:38.616839  3083 net.cpp:128] Creating Layer Eltwise3
I0818 10:58:38.616863  3083 net.cpp:558] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0818 10:58:38.616879  3083 net.cpp:558] Eltwise3 <- Convolution7
I0818 10:58:38.616896  3083 net.cpp:522] Eltwise3 -> Eltwise3
I0818 10:58:38.616940  3083 net.cpp:172] Setting up Eltwise3
I0818 10:58:38.616956  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.616969  3083 net.cpp:194] Memory required for data: 151781632
I0818 10:58:38.616983  3083 layer_factory.hpp:77] Creating layer ReLU7
I0818 10:58:38.616999  3083 net.cpp:128] Creating Layer ReLU7
I0818 10:58:38.617012  3083 net.cpp:558] ReLU7 <- Eltwise3
I0818 10:58:38.617031  3083 net.cpp:509] ReLU7 -> Eltwise3 (in-place)
I0818 10:58:38.618196  3083 net.cpp:172] Setting up ReLU7
I0818 10:58:38.618212  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.618218  3083 net.cpp:194] Memory required for data: 155975936
I0818 10:58:38.618223  3083 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0818 10:58:38.618230  3083 net.cpp:128] Creating Layer Eltwise3_ReLU7_0_split
I0818 10:58:38.618235  3083 net.cpp:558] Eltwise3_ReLU7_0_split <- Eltwise3
I0818 10:58:38.618244  3083 net.cpp:522] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0818 10:58:38.618252  3083 net.cpp:522] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0818 10:58:38.618300  3083 net.cpp:172] Setting up Eltwise3_ReLU7_0_split
I0818 10:58:38.618335  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.618351  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.618365  3083 net.cpp:194] Memory required for data: 164364544
I0818 10:58:38.618378  3083 layer_factory.hpp:77] Creating layer Convolution8
I0818 10:58:38.618402  3083 net.cpp:128] Creating Layer Convolution8
I0818 10:58:38.618415  3083 net.cpp:558] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0818 10:58:38.618435  3083 net.cpp:522] Convolution8 -> Convolution8
I0818 10:58:38.625003  3083 net.cpp:172] Setting up Convolution8
I0818 10:58:38.625052  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.625071  3083 net.cpp:194] Memory required for data: 168558848
I0818 10:58:38.625092  3083 layer_factory.hpp:77] Creating layer BatchNorm8
I0818 10:58:38.625113  3083 net.cpp:128] Creating Layer BatchNorm8
I0818 10:58:38.625126  3083 net.cpp:558] BatchNorm8 <- Convolution8
I0818 10:58:38.625145  3083 net.cpp:509] BatchNorm8 -> Convolution8 (in-place)
I0818 10:58:38.625403  3083 net.cpp:172] Setting up BatchNorm8
I0818 10:58:38.625427  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.625442  3083 net.cpp:194] Memory required for data: 172753152
I0818 10:58:38.625461  3083 layer_factory.hpp:77] Creating layer Scale8
I0818 10:58:38.625483  3083 net.cpp:128] Creating Layer Scale8
I0818 10:58:38.625499  3083 net.cpp:558] Scale8 <- Convolution8
I0818 10:58:38.625514  3083 net.cpp:509] Scale8 -> Convolution8 (in-place)
I0818 10:58:38.625574  3083 layer_factory.hpp:77] Creating layer Scale8
I0818 10:58:38.625727  3083 net.cpp:172] Setting up Scale8
I0818 10:58:38.625747  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.625761  3083 net.cpp:194] Memory required for data: 176947456
I0818 10:58:38.625779  3083 layer_factory.hpp:77] Creating layer ReLU8
I0818 10:58:38.625800  3083 net.cpp:128] Creating Layer ReLU8
I0818 10:58:38.625815  3083 net.cpp:558] ReLU8 <- Convolution8
I0818 10:58:38.625830  3083 net.cpp:509] ReLU8 -> Convolution8 (in-place)
I0818 10:58:38.629256  3083 net.cpp:172] Setting up ReLU8
I0818 10:58:38.629272  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.629277  3083 net.cpp:194] Memory required for data: 181141760
I0818 10:58:38.629283  3083 layer_factory.hpp:77] Creating layer Convolution9
I0818 10:58:38.629299  3083 net.cpp:128] Creating Layer Convolution9
I0818 10:58:38.629304  3083 net.cpp:558] Convolution9 <- Convolution8
I0818 10:58:38.629341  3083 net.cpp:522] Convolution9 -> Convolution9
I0818 10:58:38.637145  3083 net.cpp:172] Setting up Convolution9
I0818 10:58:38.637171  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.637176  3083 net.cpp:194] Memory required for data: 185336064
I0818 10:58:38.637187  3083 layer_factory.hpp:77] Creating layer BatchNorm9
I0818 10:58:38.637197  3083 net.cpp:128] Creating Layer BatchNorm9
I0818 10:58:38.637202  3083 net.cpp:558] BatchNorm9 <- Convolution9
I0818 10:58:38.637238  3083 net.cpp:509] BatchNorm9 -> Convolution9 (in-place)
I0818 10:58:38.637495  3083 net.cpp:172] Setting up BatchNorm9
I0818 10:58:38.637506  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.637509  3083 net.cpp:194] Memory required for data: 189530368
I0818 10:58:38.637519  3083 layer_factory.hpp:77] Creating layer Scale9
I0818 10:58:38.637545  3083 net.cpp:128] Creating Layer Scale9
I0818 10:58:38.637571  3083 net.cpp:558] Scale9 <- Convolution9
I0818 10:58:38.637590  3083 net.cpp:509] Scale9 -> Convolution9 (in-place)
I0818 10:58:38.637655  3083 layer_factory.hpp:77] Creating layer Scale9
I0818 10:58:38.637794  3083 net.cpp:172] Setting up Scale9
I0818 10:58:38.637804  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.637807  3083 net.cpp:194] Memory required for data: 193724672
I0818 10:58:38.637833  3083 layer_factory.hpp:77] Creating layer Eltwise4
I0818 10:58:38.637851  3083 net.cpp:128] Creating Layer Eltwise4
I0818 10:58:38.637868  3083 net.cpp:558] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0818 10:58:38.637883  3083 net.cpp:558] Eltwise4 <- Convolution9
I0818 10:58:38.637903  3083 net.cpp:522] Eltwise4 -> Eltwise4
I0818 10:58:38.637948  3083 net.cpp:172] Setting up Eltwise4
I0818 10:58:38.637966  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.637981  3083 net.cpp:194] Memory required for data: 197918976
I0818 10:58:38.637995  3083 layer_factory.hpp:77] Creating layer ReLU9
I0818 10:58:38.638011  3083 net.cpp:128] Creating Layer ReLU9
I0818 10:58:38.638025  3083 net.cpp:558] ReLU9 <- Eltwise4
I0818 10:58:38.638043  3083 net.cpp:509] ReLU9 -> Eltwise4 (in-place)
I0818 10:58:38.638295  3083 net.cpp:172] Setting up ReLU9
I0818 10:58:38.638309  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.638314  3083 net.cpp:194] Memory required for data: 202113280
I0818 10:58:38.638319  3083 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0818 10:58:38.638345  3083 net.cpp:128] Creating Layer Eltwise4_ReLU9_0_split
I0818 10:58:38.638362  3083 net.cpp:558] Eltwise4_ReLU9_0_split <- Eltwise4
I0818 10:58:38.638382  3083 net.cpp:522] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0818 10:58:38.638402  3083 net.cpp:522] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0818 10:58:38.638464  3083 net.cpp:172] Setting up Eltwise4_ReLU9_0_split
I0818 10:58:38.638484  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.638501  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.638515  3083 net.cpp:194] Memory required for data: 210501888
I0818 10:58:38.638532  3083 layer_factory.hpp:77] Creating layer Convolution10
I0818 10:58:38.638556  3083 net.cpp:128] Creating Layer Convolution10
I0818 10:58:38.638572  3083 net.cpp:558] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0818 10:58:38.638593  3083 net.cpp:522] Convolution10 -> Convolution10
I0818 10:58:38.639969  3083 net.cpp:172] Setting up Convolution10
I0818 10:58:38.639997  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.640002  3083 net.cpp:194] Memory required for data: 214696192
I0818 10:58:38.640019  3083 layer_factory.hpp:77] Creating layer BatchNorm10
I0818 10:58:38.640058  3083 net.cpp:128] Creating Layer BatchNorm10
I0818 10:58:38.640074  3083 net.cpp:558] BatchNorm10 <- Convolution10
I0818 10:58:38.640094  3083 net.cpp:509] BatchNorm10 -> Convolution10 (in-place)
I0818 10:58:38.640354  3083 net.cpp:172] Setting up BatchNorm10
I0818 10:58:38.640367  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.640370  3083 net.cpp:194] Memory required for data: 218890496
I0818 10:58:38.640381  3083 layer_factory.hpp:77] Creating layer Scale10
I0818 10:58:38.640404  3083 net.cpp:128] Creating Layer Scale10
I0818 10:58:38.640421  3083 net.cpp:558] Scale10 <- Convolution10
I0818 10:58:38.640444  3083 net.cpp:509] Scale10 -> Convolution10 (in-place)
I0818 10:58:38.640511  3083 layer_factory.hpp:77] Creating layer Scale10
I0818 10:58:38.640666  3083 net.cpp:172] Setting up Scale10
I0818 10:58:38.640677  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.640681  3083 net.cpp:194] Memory required for data: 223084800
I0818 10:58:38.640691  3083 layer_factory.hpp:77] Creating layer ReLU10
I0818 10:58:38.640713  3083 net.cpp:128] Creating Layer ReLU10
I0818 10:58:38.640727  3083 net.cpp:558] ReLU10 <- Convolution10
I0818 10:58:38.640745  3083 net.cpp:509] ReLU10 -> Convolution10 (in-place)
I0818 10:58:38.641286  3083 net.cpp:172] Setting up ReLU10
I0818 10:58:38.641322  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.641327  3083 net.cpp:194] Memory required for data: 227279104
I0818 10:58:38.641332  3083 layer_factory.hpp:77] Creating layer Convolution11
I0818 10:58:38.641345  3083 net.cpp:128] Creating Layer Convolution11
I0818 10:58:38.641353  3083 net.cpp:558] Convolution11 <- Convolution10
I0818 10:58:38.641363  3083 net.cpp:522] Convolution11 -> Convolution11
I0818 10:58:38.649549  3083 net.cpp:172] Setting up Convolution11
I0818 10:58:38.649585  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.649590  3083 net.cpp:194] Memory required for data: 231473408
I0818 10:58:38.649605  3083 layer_factory.hpp:77] Creating layer BatchNorm11
I0818 10:58:38.649617  3083 net.cpp:128] Creating Layer BatchNorm11
I0818 10:58:38.649652  3083 net.cpp:558] BatchNorm11 <- Convolution11
I0818 10:58:38.649673  3083 net.cpp:509] BatchNorm11 -> Convolution11 (in-place)
I0818 10:58:38.649948  3083 net.cpp:172] Setting up BatchNorm11
I0818 10:58:38.649960  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.649966  3083 net.cpp:194] Memory required for data: 235667712
I0818 10:58:38.649976  3083 layer_factory.hpp:77] Creating layer Scale11
I0818 10:58:38.650003  3083 net.cpp:128] Creating Layer Scale11
I0818 10:58:38.650017  3083 net.cpp:558] Scale11 <- Convolution11
I0818 10:58:38.650033  3083 net.cpp:509] Scale11 -> Convolution11 (in-place)
I0818 10:58:38.650099  3083 layer_factory.hpp:77] Creating layer Scale11
I0818 10:58:38.650260  3083 net.cpp:172] Setting up Scale11
I0818 10:58:38.650271  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.650276  3083 net.cpp:194] Memory required for data: 239862016
I0818 10:58:38.650285  3083 layer_factory.hpp:77] Creating layer Eltwise5
I0818 10:58:38.650317  3083 net.cpp:128] Creating Layer Eltwise5
I0818 10:58:38.650333  3083 net.cpp:558] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0818 10:58:38.650351  3083 net.cpp:558] Eltwise5 <- Convolution11
I0818 10:58:38.650367  3083 net.cpp:522] Eltwise5 -> Eltwise5
I0818 10:58:38.650410  3083 net.cpp:172] Setting up Eltwise5
I0818 10:58:38.650429  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.650442  3083 net.cpp:194] Memory required for data: 244056320
I0818 10:58:38.650460  3083 layer_factory.hpp:77] Creating layer ReLU11
I0818 10:58:38.650476  3083 net.cpp:128] Creating Layer ReLU11
I0818 10:58:38.650491  3083 net.cpp:558] ReLU11 <- Eltwise5
I0818 10:58:38.650509  3083 net.cpp:509] ReLU11 -> Eltwise5 (in-place)
I0818 10:58:38.652395  3083 net.cpp:172] Setting up ReLU11
I0818 10:58:38.652416  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.652420  3083 net.cpp:194] Memory required for data: 248250624
I0818 10:58:38.652426  3083 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0818 10:58:38.652434  3083 net.cpp:128] Creating Layer Eltwise5_ReLU11_0_split
I0818 10:58:38.652441  3083 net.cpp:558] Eltwise5_ReLU11_0_split <- Eltwise5
I0818 10:58:38.652449  3083 net.cpp:522] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0818 10:58:38.652457  3083 net.cpp:522] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0818 10:58:38.652539  3083 net.cpp:172] Setting up Eltwise5_ReLU11_0_split
I0818 10:58:38.652559  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.652582  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.652597  3083 net.cpp:194] Memory required for data: 256639232
I0818 10:58:38.652611  3083 layer_factory.hpp:77] Creating layer Convolution12
I0818 10:58:38.652637  3083 net.cpp:128] Creating Layer Convolution12
I0818 10:58:38.652654  3083 net.cpp:558] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0818 10:58:38.652676  3083 net.cpp:522] Convolution12 -> Convolution12
I0818 10:58:38.659242  3083 net.cpp:172] Setting up Convolution12
I0818 10:58:38.659271  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.659276  3083 net.cpp:194] Memory required for data: 260833536
I0818 10:58:38.659286  3083 layer_factory.hpp:77] Creating layer BatchNorm12
I0818 10:58:38.659312  3083 net.cpp:128] Creating Layer BatchNorm12
I0818 10:58:38.659317  3083 net.cpp:558] BatchNorm12 <- Convolution12
I0818 10:58:38.659327  3083 net.cpp:509] BatchNorm12 -> Convolution12 (in-place)
I0818 10:58:38.659579  3083 net.cpp:172] Setting up BatchNorm12
I0818 10:58:38.659618  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.659632  3083 net.cpp:194] Memory required for data: 265027840
I0818 10:58:38.659653  3083 layer_factory.hpp:77] Creating layer Scale12
I0818 10:58:38.659672  3083 net.cpp:128] Creating Layer Scale12
I0818 10:58:38.659687  3083 net.cpp:558] Scale12 <- Convolution12
I0818 10:58:38.659704  3083 net.cpp:509] Scale12 -> Convolution12 (in-place)
I0818 10:58:38.659765  3083 layer_factory.hpp:77] Creating layer Scale12
I0818 10:58:38.659917  3083 net.cpp:172] Setting up Scale12
I0818 10:58:38.659943  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.659957  3083 net.cpp:194] Memory required for data: 269222144
I0818 10:58:38.659979  3083 layer_factory.hpp:77] Creating layer ReLU12
I0818 10:58:38.659996  3083 net.cpp:128] Creating Layer ReLU12
I0818 10:58:38.660009  3083 net.cpp:558] ReLU12 <- Convolution12
I0818 10:58:38.660025  3083 net.cpp:509] ReLU12 -> Convolution12 (in-place)
I0818 10:58:38.661348  3083 net.cpp:172] Setting up ReLU12
I0818 10:58:38.661367  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.661371  3083 net.cpp:194] Memory required for data: 273416448
I0818 10:58:38.661376  3083 layer_factory.hpp:77] Creating layer Convolution13
I0818 10:58:38.661389  3083 net.cpp:128] Creating Layer Convolution13
I0818 10:58:38.661394  3083 net.cpp:558] Convolution13 <- Convolution12
I0818 10:58:38.661401  3083 net.cpp:522] Convolution13 -> Convolution13
I0818 10:58:38.668292  3083 net.cpp:172] Setting up Convolution13
I0818 10:58:38.668314  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.668319  3083 net.cpp:194] Memory required for data: 277610752
I0818 10:58:38.668330  3083 layer_factory.hpp:77] Creating layer BatchNorm13
I0818 10:58:38.668341  3083 net.cpp:128] Creating Layer BatchNorm13
I0818 10:58:38.668380  3083 net.cpp:558] BatchNorm13 <- Convolution13
I0818 10:58:38.668395  3083 net.cpp:509] BatchNorm13 -> Convolution13 (in-place)
I0818 10:58:38.668649  3083 net.cpp:172] Setting up BatchNorm13
I0818 10:58:38.668661  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.668665  3083 net.cpp:194] Memory required for data: 281805056
I0818 10:58:38.668675  3083 layer_factory.hpp:77] Creating layer Scale13
I0818 10:58:38.668684  3083 net.cpp:128] Creating Layer Scale13
I0818 10:58:38.668687  3083 net.cpp:558] Scale13 <- Convolution13
I0818 10:58:38.668694  3083 net.cpp:509] Scale13 -> Convolution13 (in-place)
I0818 10:58:38.668740  3083 layer_factory.hpp:77] Creating layer Scale13
I0818 10:58:38.668877  3083 net.cpp:172] Setting up Scale13
I0818 10:58:38.668889  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.668915  3083 net.cpp:194] Memory required for data: 285999360
I0818 10:58:38.668928  3083 layer_factory.hpp:77] Creating layer Eltwise6
I0818 10:58:38.668938  3083 net.cpp:128] Creating Layer Eltwise6
I0818 10:58:38.668946  3083 net.cpp:558] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0818 10:58:38.668951  3083 net.cpp:558] Eltwise6 <- Convolution13
I0818 10:58:38.668984  3083 net.cpp:522] Eltwise6 -> Eltwise6
I0818 10:58:38.669039  3083 net.cpp:172] Setting up Eltwise6
I0818 10:58:38.669051  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.669055  3083 net.cpp:194] Memory required for data: 290193664
I0818 10:58:38.669060  3083 layer_factory.hpp:77] Creating layer ReLU13
I0818 10:58:38.669093  3083 net.cpp:128] Creating Layer ReLU13
I0818 10:58:38.669101  3083 net.cpp:558] ReLU13 <- Eltwise6
I0818 10:58:38.669107  3083 net.cpp:509] ReLU13 -> Eltwise6 (in-place)
I0818 10:58:38.670434  3083 net.cpp:172] Setting up ReLU13
I0818 10:58:38.670478  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.670495  3083 net.cpp:194] Memory required for data: 294387968
I0818 10:58:38.670526  3083 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0818 10:58:38.670547  3083 net.cpp:128] Creating Layer Eltwise6_ReLU13_0_split
I0818 10:58:38.670565  3083 net.cpp:558] Eltwise6_ReLU13_0_split <- Eltwise6
I0818 10:58:38.670585  3083 net.cpp:522] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0818 10:58:38.670608  3083 net.cpp:522] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0818 10:58:38.670691  3083 net.cpp:172] Setting up Eltwise6_ReLU13_0_split
I0818 10:58:38.670712  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.670727  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.670740  3083 net.cpp:194] Memory required for data: 302776576
I0818 10:58:38.670754  3083 layer_factory.hpp:77] Creating layer Convolution14
I0818 10:58:38.670776  3083 net.cpp:128] Creating Layer Convolution14
I0818 10:58:38.670791  3083 net.cpp:558] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0818 10:58:38.670811  3083 net.cpp:522] Convolution14 -> Convolution14
I0818 10:58:38.683557  3083 net.cpp:172] Setting up Convolution14
I0818 10:58:38.683578  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.683583  3083 net.cpp:194] Memory required for data: 306970880
I0818 10:58:38.683593  3083 layer_factory.hpp:77] Creating layer BatchNorm14
I0818 10:58:38.683605  3083 net.cpp:128] Creating Layer BatchNorm14
I0818 10:58:38.683610  3083 net.cpp:558] BatchNorm14 <- Convolution14
I0818 10:58:38.683617  3083 net.cpp:509] BatchNorm14 -> Convolution14 (in-place)
I0818 10:58:38.683869  3083 net.cpp:172] Setting up BatchNorm14
I0818 10:58:38.683908  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.683923  3083 net.cpp:194] Memory required for data: 311165184
I0818 10:58:38.683943  3083 layer_factory.hpp:77] Creating layer Scale14
I0818 10:58:38.683961  3083 net.cpp:128] Creating Layer Scale14
I0818 10:58:38.683979  3083 net.cpp:558] Scale14 <- Convolution14
I0818 10:58:38.683995  3083 net.cpp:509] Scale14 -> Convolution14 (in-place)
I0818 10:58:38.684060  3083 layer_factory.hpp:77] Creating layer Scale14
I0818 10:58:38.684216  3083 net.cpp:172] Setting up Scale14
I0818 10:58:38.684238  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.684252  3083 net.cpp:194] Memory required for data: 315359488
I0818 10:58:38.684270  3083 layer_factory.hpp:77] Creating layer ReLU14
I0818 10:58:38.684288  3083 net.cpp:128] Creating Layer ReLU14
I0818 10:58:38.684303  3083 net.cpp:558] ReLU14 <- Convolution14
I0818 10:58:38.684327  3083 net.cpp:509] ReLU14 -> Convolution14 (in-place)
I0818 10:58:38.687773  3083 net.cpp:172] Setting up ReLU14
I0818 10:58:38.687793  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.687798  3083 net.cpp:194] Memory required for data: 319553792
I0818 10:58:38.687803  3083 layer_factory.hpp:77] Creating layer Convolution15
I0818 10:58:38.687819  3083 net.cpp:128] Creating Layer Convolution15
I0818 10:58:38.687824  3083 net.cpp:558] Convolution15 <- Convolution14
I0818 10:58:38.687834  3083 net.cpp:522] Convolution15 -> Convolution15
I0818 10:58:38.700798  3083 net.cpp:172] Setting up Convolution15
I0818 10:58:38.700822  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.700826  3083 net.cpp:194] Memory required for data: 323748096
I0818 10:58:38.700836  3083 layer_factory.hpp:77] Creating layer BatchNorm15
I0818 10:58:38.700847  3083 net.cpp:128] Creating Layer BatchNorm15
I0818 10:58:38.700852  3083 net.cpp:558] BatchNorm15 <- Convolution15
I0818 10:58:38.700862  3083 net.cpp:509] BatchNorm15 -> Convolution15 (in-place)
I0818 10:58:38.701112  3083 net.cpp:172] Setting up BatchNorm15
I0818 10:58:38.701153  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.701166  3083 net.cpp:194] Memory required for data: 327942400
I0818 10:58:38.701189  3083 layer_factory.hpp:77] Creating layer Scale15
I0818 10:58:38.701207  3083 net.cpp:128] Creating Layer Scale15
I0818 10:58:38.701228  3083 net.cpp:558] Scale15 <- Convolution15
I0818 10:58:38.701256  3083 net.cpp:509] Scale15 -> Convolution15 (in-place)
I0818 10:58:38.701321  3083 layer_factory.hpp:77] Creating layer Scale15
I0818 10:58:38.701478  3083 net.cpp:172] Setting up Scale15
I0818 10:58:38.701501  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.701515  3083 net.cpp:194] Memory required for data: 332136704
I0818 10:58:38.701534  3083 layer_factory.hpp:77] Creating layer Eltwise7
I0818 10:58:38.701555  3083 net.cpp:128] Creating Layer Eltwise7
I0818 10:58:38.701575  3083 net.cpp:558] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0818 10:58:38.701589  3083 net.cpp:558] Eltwise7 <- Convolution15
I0818 10:58:38.701606  3083 net.cpp:522] Eltwise7 -> Eltwise7
I0818 10:58:38.701649  3083 net.cpp:172] Setting up Eltwise7
I0818 10:58:38.701666  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.701679  3083 net.cpp:194] Memory required for data: 336331008
I0818 10:58:38.701694  3083 layer_factory.hpp:77] Creating layer ReLU15
I0818 10:58:38.701709  3083 net.cpp:128] Creating Layer ReLU15
I0818 10:58:38.701722  3083 net.cpp:558] ReLU15 <- Eltwise7
I0818 10:58:38.701741  3083 net.cpp:509] ReLU15 -> Eltwise7 (in-place)
I0818 10:58:38.702925  3083 net.cpp:172] Setting up ReLU15
I0818 10:58:38.702942  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.702947  3083 net.cpp:194] Memory required for data: 340525312
I0818 10:58:38.702951  3083 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0818 10:58:38.702960  3083 net.cpp:128] Creating Layer Eltwise7_ReLU15_0_split
I0818 10:58:38.702963  3083 net.cpp:558] Eltwise7_ReLU15_0_split <- Eltwise7
I0818 10:58:38.702972  3083 net.cpp:522] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0818 10:58:38.702980  3083 net.cpp:522] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0818 10:58:38.703032  3083 net.cpp:172] Setting up Eltwise7_ReLU15_0_split
I0818 10:58:38.703066  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.703083  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.703095  3083 net.cpp:194] Memory required for data: 348913920
I0818 10:58:38.703110  3083 layer_factory.hpp:77] Creating layer Convolution16
I0818 10:58:38.703133  3083 net.cpp:128] Creating Layer Convolution16
I0818 10:58:38.703147  3083 net.cpp:558] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0818 10:58:38.703167  3083 net.cpp:522] Convolution16 -> Convolution16
I0818 10:58:38.708822  3083 net.cpp:172] Setting up Convolution16
I0818 10:58:38.708849  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.708854  3083 net.cpp:194] Memory required for data: 353108224
I0818 10:58:38.708864  3083 layer_factory.hpp:77] Creating layer BatchNorm16
I0818 10:58:38.708873  3083 net.cpp:128] Creating Layer BatchNorm16
I0818 10:58:38.708880  3083 net.cpp:558] BatchNorm16 <- Convolution16
I0818 10:58:38.708889  3083 net.cpp:509] BatchNorm16 -> Convolution16 (in-place)
I0818 10:58:38.709180  3083 net.cpp:172] Setting up BatchNorm16
I0818 10:58:38.709203  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.709219  3083 net.cpp:194] Memory required for data: 357302528
I0818 10:58:38.709233  3083 layer_factory.hpp:77] Creating layer Scale16
I0818 10:58:38.709244  3083 net.cpp:128] Creating Layer Scale16
I0818 10:58:38.709250  3083 net.cpp:558] Scale16 <- Convolution16
I0818 10:58:38.709259  3083 net.cpp:509] Scale16 -> Convolution16 (in-place)
I0818 10:58:38.709334  3083 layer_factory.hpp:77] Creating layer Scale16
I0818 10:58:38.709478  3083 net.cpp:172] Setting up Scale16
I0818 10:58:38.709491  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.709496  3083 net.cpp:194] Memory required for data: 361496832
I0818 10:58:38.709506  3083 layer_factory.hpp:77] Creating layer ReLU16
I0818 10:58:38.709514  3083 net.cpp:128] Creating Layer ReLU16
I0818 10:58:38.709518  3083 net.cpp:558] ReLU16 <- Convolution16
I0818 10:58:38.709524  3083 net.cpp:509] ReLU16 -> Convolution16 (in-place)
I0818 10:58:38.710093  3083 net.cpp:172] Setting up ReLU16
I0818 10:58:38.710114  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.710136  3083 net.cpp:194] Memory required for data: 365691136
I0818 10:58:38.710141  3083 layer_factory.hpp:77] Creating layer Convolution17
I0818 10:58:38.710180  3083 net.cpp:128] Creating Layer Convolution17
I0818 10:58:38.710191  3083 net.cpp:558] Convolution17 <- Convolution16
I0818 10:58:38.710198  3083 net.cpp:522] Convolution17 -> Convolution17
I0818 10:58:38.720695  3083 net.cpp:172] Setting up Convolution17
I0818 10:58:38.720722  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.720726  3083 net.cpp:194] Memory required for data: 369885440
I0818 10:58:38.720737  3083 layer_factory.hpp:77] Creating layer BatchNorm17
I0818 10:58:38.720748  3083 net.cpp:128] Creating Layer BatchNorm17
I0818 10:58:38.720753  3083 net.cpp:558] BatchNorm17 <- Convolution17
I0818 10:58:38.720762  3083 net.cpp:509] BatchNorm17 -> Convolution17 (in-place)
I0818 10:58:38.721057  3083 net.cpp:172] Setting up BatchNorm17
I0818 10:58:38.721078  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.721092  3083 net.cpp:194] Memory required for data: 374079744
I0818 10:58:38.721114  3083 layer_factory.hpp:77] Creating layer Scale17
I0818 10:58:38.721141  3083 net.cpp:128] Creating Layer Scale17
I0818 10:58:38.721155  3083 net.cpp:558] Scale17 <- Convolution17
I0818 10:58:38.721171  3083 net.cpp:509] Scale17 -> Convolution17 (in-place)
I0818 10:58:38.721235  3083 layer_factory.hpp:77] Creating layer Scale17
I0818 10:58:38.721402  3083 net.cpp:172] Setting up Scale17
I0818 10:58:38.721422  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.721436  3083 net.cpp:194] Memory required for data: 378274048
I0818 10:58:38.721455  3083 layer_factory.hpp:77] Creating layer Eltwise8
I0818 10:58:38.721472  3083 net.cpp:128] Creating Layer Eltwise8
I0818 10:58:38.721487  3083 net.cpp:558] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0818 10:58:38.721503  3083 net.cpp:558] Eltwise8 <- Convolution17
I0818 10:58:38.721526  3083 net.cpp:522] Eltwise8 -> Eltwise8
I0818 10:58:38.721570  3083 net.cpp:172] Setting up Eltwise8
I0818 10:58:38.721587  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.721601  3083 net.cpp:194] Memory required for data: 382468352
I0818 10:58:38.721614  3083 layer_factory.hpp:77] Creating layer ReLU17
I0818 10:58:38.721634  3083 net.cpp:128] Creating Layer ReLU17
I0818 10:58:38.721648  3083 net.cpp:558] ReLU17 <- Eltwise8
I0818 10:58:38.721666  3083 net.cpp:509] ReLU17 -> Eltwise8 (in-place)
I0818 10:58:38.724922  3083 net.cpp:172] Setting up ReLU17
I0818 10:58:38.724942  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.724947  3083 net.cpp:194] Memory required for data: 386662656
I0818 10:58:38.724952  3083 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0818 10:58:38.724959  3083 net.cpp:128] Creating Layer Eltwise8_ReLU17_0_split
I0818 10:58:38.724964  3083 net.cpp:558] Eltwise8_ReLU17_0_split <- Eltwise8
I0818 10:58:38.724973  3083 net.cpp:522] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0818 10:58:38.724982  3083 net.cpp:522] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0818 10:58:38.725031  3083 net.cpp:172] Setting up Eltwise8_ReLU17_0_split
I0818 10:58:38.725076  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.725092  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.725113  3083 net.cpp:194] Memory required for data: 395051264
I0818 10:58:38.725127  3083 layer_factory.hpp:77] Creating layer Convolution18
I0818 10:58:38.725152  3083 net.cpp:128] Creating Layer Convolution18
I0818 10:58:38.725167  3083 net.cpp:558] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0818 10:58:38.725188  3083 net.cpp:522] Convolution18 -> Convolution18
I0818 10:58:38.738003  3083 net.cpp:172] Setting up Convolution18
I0818 10:58:38.738030  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.738035  3083 net.cpp:194] Memory required for data: 399245568
I0818 10:58:38.738045  3083 layer_factory.hpp:77] Creating layer BatchNorm18
I0818 10:58:38.738055  3083 net.cpp:128] Creating Layer BatchNorm18
I0818 10:58:38.738104  3083 net.cpp:558] BatchNorm18 <- Convolution18
I0818 10:58:38.738123  3083 net.cpp:509] BatchNorm18 -> Convolution18 (in-place)
I0818 10:58:38.738399  3083 net.cpp:172] Setting up BatchNorm18
I0818 10:58:38.738411  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.738415  3083 net.cpp:194] Memory required for data: 403439872
I0818 10:58:38.738426  3083 layer_factory.hpp:77] Creating layer Scale18
I0818 10:58:38.738456  3083 net.cpp:128] Creating Layer Scale18
I0818 10:58:38.738471  3083 net.cpp:558] Scale18 <- Convolution18
I0818 10:58:38.738489  3083 net.cpp:509] Scale18 -> Convolution18 (in-place)
I0818 10:58:38.738554  3083 layer_factory.hpp:77] Creating layer Scale18
I0818 10:58:38.738720  3083 net.cpp:172] Setting up Scale18
I0818 10:58:38.738732  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.738736  3083 net.cpp:194] Memory required for data: 407634176
I0818 10:58:38.738745  3083 layer_factory.hpp:77] Creating layer ReLU18
I0818 10:58:38.738777  3083 net.cpp:128] Creating Layer ReLU18
I0818 10:58:38.738792  3083 net.cpp:558] ReLU18 <- Convolution18
I0818 10:58:38.738811  3083 net.cpp:509] ReLU18 -> Convolution18 (in-place)
I0818 10:58:38.741708  3083 net.cpp:172] Setting up ReLU18
I0818 10:58:38.741724  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.741730  3083 net.cpp:194] Memory required for data: 411828480
I0818 10:58:38.741735  3083 layer_factory.hpp:77] Creating layer Convolution19
I0818 10:58:38.741753  3083 net.cpp:128] Creating Layer Convolution19
I0818 10:58:38.741758  3083 net.cpp:558] Convolution19 <- Convolution18
I0818 10:58:38.741766  3083 net.cpp:522] Convolution19 -> Convolution19
I0818 10:58:38.748530  3083 net.cpp:172] Setting up Convolution19
I0818 10:58:38.748556  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.748560  3083 net.cpp:194] Memory required for data: 416022784
I0818 10:58:38.748570  3083 layer_factory.hpp:77] Creating layer BatchNorm19
I0818 10:58:38.748581  3083 net.cpp:128] Creating Layer BatchNorm19
I0818 10:58:38.748587  3083 net.cpp:558] BatchNorm19 <- Convolution19
I0818 10:58:38.748594  3083 net.cpp:509] BatchNorm19 -> Convolution19 (in-place)
I0818 10:58:38.748853  3083 net.cpp:172] Setting up BatchNorm19
I0818 10:58:38.748893  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.748908  3083 net.cpp:194] Memory required for data: 420217088
I0818 10:58:38.748942  3083 layer_factory.hpp:77] Creating layer Scale19
I0818 10:58:38.748962  3083 net.cpp:128] Creating Layer Scale19
I0818 10:58:38.748977  3083 net.cpp:558] Scale19 <- Convolution19
I0818 10:58:38.748994  3083 net.cpp:509] Scale19 -> Convolution19 (in-place)
I0818 10:58:38.749060  3083 layer_factory.hpp:77] Creating layer Scale19
I0818 10:58:38.749219  3083 net.cpp:172] Setting up Scale19
I0818 10:58:38.749243  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.749256  3083 net.cpp:194] Memory required for data: 424411392
I0818 10:58:38.749274  3083 layer_factory.hpp:77] Creating layer Eltwise9
I0818 10:58:38.749291  3083 net.cpp:128] Creating Layer Eltwise9
I0818 10:58:38.749306  3083 net.cpp:558] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0818 10:58:38.749321  3083 net.cpp:558] Eltwise9 <- Convolution19
I0818 10:58:38.749339  3083 net.cpp:522] Eltwise9 -> Eltwise9
I0818 10:58:38.749393  3083 net.cpp:172] Setting up Eltwise9
I0818 10:58:38.749411  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.749428  3083 net.cpp:194] Memory required for data: 428605696
I0818 10:58:38.749445  3083 layer_factory.hpp:77] Creating layer ReLU19
I0818 10:58:38.749467  3083 net.cpp:128] Creating Layer ReLU19
I0818 10:58:38.749482  3083 net.cpp:558] ReLU19 <- Eltwise9
I0818 10:58:38.749497  3083 net.cpp:509] ReLU19 -> Eltwise9 (in-place)
I0818 10:58:38.750620  3083 net.cpp:172] Setting up ReLU19
I0818 10:58:38.750634  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.750639  3083 net.cpp:194] Memory required for data: 432800000
I0818 10:58:38.750643  3083 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0818 10:58:38.750674  3083 net.cpp:128] Creating Layer Eltwise9_ReLU19_0_split
I0818 10:58:38.750679  3083 net.cpp:558] Eltwise9_ReLU19_0_split <- Eltwise9
I0818 10:58:38.750689  3083 net.cpp:522] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0818 10:58:38.750697  3083 net.cpp:522] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0818 10:58:38.750749  3083 net.cpp:172] Setting up Eltwise9_ReLU19_0_split
I0818 10:58:38.750790  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.750810  3083 net.cpp:186] Top shape: 64 16 32 32 (1048576)
I0818 10:58:38.750828  3083 net.cpp:194] Memory required for data: 441188608
I0818 10:58:38.750845  3083 layer_factory.hpp:77] Creating layer Convolution20
I0818 10:58:38.750870  3083 net.cpp:128] Creating Layer Convolution20
I0818 10:58:38.750887  3083 net.cpp:558] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0818 10:58:38.750910  3083 net.cpp:522] Convolution20 -> Convolution20
I0818 10:58:38.757828  3083 net.cpp:172] Setting up Convolution20
I0818 10:58:38.757879  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.757899  3083 net.cpp:194] Memory required for data: 443285760
I0818 10:58:38.757921  3083 layer_factory.hpp:77] Creating layer BatchNorm20
I0818 10:58:38.757939  3083 net.cpp:128] Creating Layer BatchNorm20
I0818 10:58:38.757954  3083 net.cpp:558] BatchNorm20 <- Convolution20
I0818 10:58:38.757974  3083 net.cpp:509] BatchNorm20 -> Convolution20 (in-place)
I0818 10:58:38.758252  3083 net.cpp:172] Setting up BatchNorm20
I0818 10:58:38.758275  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.758288  3083 net.cpp:194] Memory required for data: 445382912
I0818 10:58:38.758311  3083 layer_factory.hpp:77] Creating layer Scale20
I0818 10:58:38.758330  3083 net.cpp:128] Creating Layer Scale20
I0818 10:58:38.758345  3083 net.cpp:558] Scale20 <- Convolution20
I0818 10:58:38.758361  3083 net.cpp:509] Scale20 -> Convolution20 (in-place)
I0818 10:58:38.758426  3083 layer_factory.hpp:77] Creating layer Scale20
I0818 10:58:38.758591  3083 net.cpp:172] Setting up Scale20
I0818 10:58:38.758613  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.758630  3083 net.cpp:194] Memory required for data: 447480064
I0818 10:58:38.758649  3083 layer_factory.hpp:77] Creating layer Convolution21
I0818 10:58:38.758685  3083 net.cpp:128] Creating Layer Convolution21
I0818 10:58:38.758702  3083 net.cpp:558] Convolution21 <- Eltwise9_ReLU19_0_split_1
I0818 10:58:38.758719  3083 net.cpp:522] Convolution21 -> Convolution21
I0818 10:58:38.770570  3083 net.cpp:172] Setting up Convolution21
I0818 10:58:38.770599  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.770604  3083 net.cpp:194] Memory required for data: 449577216
I0818 10:58:38.770617  3083 layer_factory.hpp:77] Creating layer BatchNorm21
I0818 10:58:38.770628  3083 net.cpp:128] Creating Layer BatchNorm21
I0818 10:58:38.770633  3083 net.cpp:558] BatchNorm21 <- Convolution21
I0818 10:58:38.770644  3083 net.cpp:509] BatchNorm21 -> Convolution21 (in-place)
I0818 10:58:38.770907  3083 net.cpp:172] Setting up BatchNorm21
I0818 10:58:38.770948  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.770962  3083 net.cpp:194] Memory required for data: 451674368
I0818 10:58:38.770983  3083 layer_factory.hpp:77] Creating layer Scale21
I0818 10:58:38.771015  3083 net.cpp:128] Creating Layer Scale21
I0818 10:58:38.771030  3083 net.cpp:558] Scale21 <- Convolution21
I0818 10:58:38.771049  3083 net.cpp:509] Scale21 -> Convolution21 (in-place)
I0818 10:58:38.771114  3083 layer_factory.hpp:77] Creating layer Scale21
I0818 10:58:38.771275  3083 net.cpp:172] Setting up Scale21
I0818 10:58:38.771301  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.771314  3083 net.cpp:194] Memory required for data: 453771520
I0818 10:58:38.771332  3083 layer_factory.hpp:77] Creating layer ReLU20
I0818 10:58:38.771350  3083 net.cpp:128] Creating Layer ReLU20
I0818 10:58:38.771366  3083 net.cpp:558] ReLU20 <- Convolution21
I0818 10:58:38.771395  3083 net.cpp:509] ReLU20 -> Convolution21 (in-place)
I0818 10:58:38.774771  3083 net.cpp:172] Setting up ReLU20
I0818 10:58:38.774794  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.774799  3083 net.cpp:194] Memory required for data: 455868672
I0818 10:58:38.774804  3083 layer_factory.hpp:77] Creating layer Convolution22
I0818 10:58:38.774822  3083 net.cpp:128] Creating Layer Convolution22
I0818 10:58:38.774827  3083 net.cpp:558] Convolution22 <- Convolution21
I0818 10:58:38.774837  3083 net.cpp:522] Convolution22 -> Convolution22
I0818 10:58:38.787883  3083 net.cpp:172] Setting up Convolution22
I0818 10:58:38.787909  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.787912  3083 net.cpp:194] Memory required for data: 457965824
I0818 10:58:38.787925  3083 layer_factory.hpp:77] Creating layer BatchNorm22
I0818 10:58:38.787936  3083 net.cpp:128] Creating Layer BatchNorm22
I0818 10:58:38.787941  3083 net.cpp:558] BatchNorm22 <- Convolution22
I0818 10:58:38.787952  3083 net.cpp:509] BatchNorm22 -> Convolution22 (in-place)
I0818 10:58:38.788198  3083 net.cpp:172] Setting up BatchNorm22
I0818 10:58:38.788213  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.788216  3083 net.cpp:194] Memory required for data: 460062976
I0818 10:58:38.788226  3083 layer_factory.hpp:77] Creating layer Scale22
I0818 10:58:38.788234  3083 net.cpp:128] Creating Layer Scale22
I0818 10:58:38.788239  3083 net.cpp:558] Scale22 <- Convolution22
I0818 10:58:38.788245  3083 net.cpp:509] Scale22 -> Convolution22 (in-place)
I0818 10:58:38.788291  3083 layer_factory.hpp:77] Creating layer Scale22
I0818 10:58:38.788436  3083 net.cpp:172] Setting up Scale22
I0818 10:58:38.788444  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.788447  3083 net.cpp:194] Memory required for data: 462160128
I0818 10:58:38.788455  3083 layer_factory.hpp:77] Creating layer Eltwise10
I0818 10:58:38.788470  3083 net.cpp:128] Creating Layer Eltwise10
I0818 10:58:38.788475  3083 net.cpp:558] Eltwise10 <- Convolution20
I0818 10:58:38.788480  3083 net.cpp:558] Eltwise10 <- Convolution22
I0818 10:58:38.788486  3083 net.cpp:522] Eltwise10 -> Eltwise10
I0818 10:58:38.788511  3083 net.cpp:172] Setting up Eltwise10
I0818 10:58:38.788527  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.788532  3083 net.cpp:194] Memory required for data: 464257280
I0818 10:58:38.788537  3083 layer_factory.hpp:77] Creating layer ReLU21
I0818 10:58:38.788543  3083 net.cpp:128] Creating Layer ReLU21
I0818 10:58:38.788547  3083 net.cpp:558] ReLU21 <- Eltwise10
I0818 10:58:38.788553  3083 net.cpp:509] ReLU21 -> Eltwise10 (in-place)
I0818 10:58:38.789952  3083 net.cpp:172] Setting up ReLU21
I0818 10:58:38.789968  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.789974  3083 net.cpp:194] Memory required for data: 466354432
I0818 10:58:38.789979  3083 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0818 10:58:38.789986  3083 net.cpp:128] Creating Layer Eltwise10_ReLU21_0_split
I0818 10:58:38.789991  3083 net.cpp:558] Eltwise10_ReLU21_0_split <- Eltwise10
I0818 10:58:38.789999  3083 net.cpp:522] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0818 10:58:38.790009  3083 net.cpp:522] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0818 10:58:38.790058  3083 net.cpp:172] Setting up Eltwise10_ReLU21_0_split
I0818 10:58:38.790069  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.790076  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.790079  3083 net.cpp:194] Memory required for data: 470548736
I0818 10:58:38.790083  3083 layer_factory.hpp:77] Creating layer Convolution23
I0818 10:58:38.790097  3083 net.cpp:128] Creating Layer Convolution23
I0818 10:58:38.790102  3083 net.cpp:558] Convolution23 <- Eltwise10_ReLU21_0_split_0
I0818 10:58:38.790109  3083 net.cpp:522] Convolution23 -> Convolution23
I0818 10:58:38.797086  3083 net.cpp:172] Setting up Convolution23
I0818 10:58:38.797112  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.797132  3083 net.cpp:194] Memory required for data: 472645888
I0818 10:58:38.797143  3083 layer_factory.hpp:77] Creating layer BatchNorm23
I0818 10:58:38.797155  3083 net.cpp:128] Creating Layer BatchNorm23
I0818 10:58:38.797160  3083 net.cpp:558] BatchNorm23 <- Convolution23
I0818 10:58:38.797174  3083 net.cpp:509] BatchNorm23 -> Convolution23 (in-place)
I0818 10:58:38.797444  3083 net.cpp:172] Setting up BatchNorm23
I0818 10:58:38.797453  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.797458  3083 net.cpp:194] Memory required for data: 474743040
I0818 10:58:38.797468  3083 layer_factory.hpp:77] Creating layer Scale23
I0818 10:58:38.797478  3083 net.cpp:128] Creating Layer Scale23
I0818 10:58:38.797483  3083 net.cpp:558] Scale23 <- Convolution23
I0818 10:58:38.797490  3083 net.cpp:509] Scale23 -> Convolution23 (in-place)
I0818 10:58:38.797535  3083 layer_factory.hpp:77] Creating layer Scale23
I0818 10:58:38.797682  3083 net.cpp:172] Setting up Scale23
I0818 10:58:38.797691  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.797695  3083 net.cpp:194] Memory required for data: 476840192
I0818 10:58:38.797703  3083 layer_factory.hpp:77] Creating layer ReLU22
I0818 10:58:38.797713  3083 net.cpp:128] Creating Layer ReLU22
I0818 10:58:38.797718  3083 net.cpp:558] ReLU22 <- Convolution23
I0818 10:58:38.797724  3083 net.cpp:509] ReLU22 -> Convolution23 (in-place)
I0818 10:58:38.798928  3083 net.cpp:172] Setting up ReLU22
I0818 10:58:38.798941  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.798946  3083 net.cpp:194] Memory required for data: 478937344
I0818 10:58:38.798951  3083 layer_factory.hpp:77] Creating layer Convolution24
I0818 10:58:38.798964  3083 net.cpp:128] Creating Layer Convolution24
I0818 10:58:38.798969  3083 net.cpp:558] Convolution24 <- Convolution23
I0818 10:58:38.798985  3083 net.cpp:522] Convolution24 -> Convolution24
I0818 10:58:38.805779  3083 net.cpp:172] Setting up Convolution24
I0818 10:58:38.805804  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.805807  3083 net.cpp:194] Memory required for data: 481034496
I0818 10:58:38.805819  3083 layer_factory.hpp:77] Creating layer BatchNorm24
I0818 10:58:38.805830  3083 net.cpp:128] Creating Layer BatchNorm24
I0818 10:58:38.805838  3083 net.cpp:558] BatchNorm24 <- Convolution24
I0818 10:58:38.805848  3083 net.cpp:509] BatchNorm24 -> Convolution24 (in-place)
I0818 10:58:38.806105  3083 net.cpp:172] Setting up BatchNorm24
I0818 10:58:38.806116  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.806120  3083 net.cpp:194] Memory required for data: 483131648
I0818 10:58:38.806130  3083 layer_factory.hpp:77] Creating layer Scale24
I0818 10:58:38.806139  3083 net.cpp:128] Creating Layer Scale24
I0818 10:58:38.806144  3083 net.cpp:558] Scale24 <- Convolution24
I0818 10:58:38.806149  3083 net.cpp:509] Scale24 -> Convolution24 (in-place)
I0818 10:58:38.806197  3083 layer_factory.hpp:77] Creating layer Scale24
I0818 10:58:38.806342  3083 net.cpp:172] Setting up Scale24
I0818 10:58:38.806352  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.806356  3083 net.cpp:194] Memory required for data: 485228800
I0818 10:58:38.806365  3083 layer_factory.hpp:77] Creating layer Eltwise11
I0818 10:58:38.806377  3083 net.cpp:128] Creating Layer Eltwise11
I0818 10:58:38.806386  3083 net.cpp:558] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0818 10:58:38.806391  3083 net.cpp:558] Eltwise11 <- Convolution24
I0818 10:58:38.806397  3083 net.cpp:522] Eltwise11 -> Eltwise11
I0818 10:58:38.806421  3083 net.cpp:172] Setting up Eltwise11
I0818 10:58:38.806427  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.806432  3083 net.cpp:194] Memory required for data: 487325952
I0818 10:58:38.806435  3083 layer_factory.hpp:77] Creating layer ReLU23
I0818 10:58:38.806442  3083 net.cpp:128] Creating Layer ReLU23
I0818 10:58:38.806447  3083 net.cpp:558] ReLU23 <- Eltwise11
I0818 10:58:38.806454  3083 net.cpp:509] ReLU23 -> Eltwise11 (in-place)
I0818 10:58:38.809978  3083 net.cpp:172] Setting up ReLU23
I0818 10:58:38.810019  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.810024  3083 net.cpp:194] Memory required for data: 489423104
I0818 10:58:38.810029  3083 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0818 10:58:38.810036  3083 net.cpp:128] Creating Layer Eltwise11_ReLU23_0_split
I0818 10:58:38.810041  3083 net.cpp:558] Eltwise11_ReLU23_0_split <- Eltwise11
I0818 10:58:38.810052  3083 net.cpp:522] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0818 10:58:38.810067  3083 net.cpp:522] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0818 10:58:38.810122  3083 net.cpp:172] Setting up Eltwise11_ReLU23_0_split
I0818 10:58:38.810129  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.810135  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.810139  3083 net.cpp:194] Memory required for data: 493617408
I0818 10:58:38.810143  3083 layer_factory.hpp:77] Creating layer Convolution25
I0818 10:58:38.810158  3083 net.cpp:128] Creating Layer Convolution25
I0818 10:58:38.810163  3083 net.cpp:558] Convolution25 <- Eltwise11_ReLU23_0_split_0
I0818 10:58:38.810169  3083 net.cpp:522] Convolution25 -> Convolution25
I0818 10:58:38.823163  3083 net.cpp:172] Setting up Convolution25
I0818 10:58:38.823184  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.823189  3083 net.cpp:194] Memory required for data: 495714560
I0818 10:58:38.823199  3083 layer_factory.hpp:77] Creating layer BatchNorm25
I0818 10:58:38.823210  3083 net.cpp:128] Creating Layer BatchNorm25
I0818 10:58:38.823216  3083 net.cpp:558] BatchNorm25 <- Convolution25
I0818 10:58:38.823225  3083 net.cpp:509] BatchNorm25 -> Convolution25 (in-place)
I0818 10:58:38.823482  3083 net.cpp:172] Setting up BatchNorm25
I0818 10:58:38.823494  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.823498  3083 net.cpp:194] Memory required for data: 497811712
I0818 10:58:38.823508  3083 layer_factory.hpp:77] Creating layer Scale25
I0818 10:58:38.823520  3083 net.cpp:128] Creating Layer Scale25
I0818 10:58:38.823524  3083 net.cpp:558] Scale25 <- Convolution25
I0818 10:58:38.823530  3083 net.cpp:509] Scale25 -> Convolution25 (in-place)
I0818 10:58:38.823578  3083 layer_factory.hpp:77] Creating layer Scale25
I0818 10:58:38.823729  3083 net.cpp:172] Setting up Scale25
I0818 10:58:38.823736  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.823740  3083 net.cpp:194] Memory required for data: 499908864
I0818 10:58:38.823748  3083 layer_factory.hpp:77] Creating layer ReLU24
I0818 10:58:38.823756  3083 net.cpp:128] Creating Layer ReLU24
I0818 10:58:38.823761  3083 net.cpp:558] ReLU24 <- Convolution25
I0818 10:58:38.823766  3083 net.cpp:509] ReLU24 -> Convolution25 (in-place)
I0818 10:58:38.827371  3083 net.cpp:172] Setting up ReLU24
I0818 10:58:38.827391  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.827396  3083 net.cpp:194] Memory required for data: 502006016
I0818 10:58:38.827401  3083 layer_factory.hpp:77] Creating layer Convolution26
I0818 10:58:38.827415  3083 net.cpp:128] Creating Layer Convolution26
I0818 10:58:38.827421  3083 net.cpp:558] Convolution26 <- Convolution25
I0818 10:58:38.827430  3083 net.cpp:522] Convolution26 -> Convolution26
I0818 10:58:38.838397  3083 net.cpp:172] Setting up Convolution26
I0818 10:58:38.838423  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.838428  3083 net.cpp:194] Memory required for data: 504103168
I0818 10:58:38.838438  3083 layer_factory.hpp:77] Creating layer BatchNorm26
I0818 10:58:38.838449  3083 net.cpp:128] Creating Layer BatchNorm26
I0818 10:58:38.838454  3083 net.cpp:558] BatchNorm26 <- Convolution26
I0818 10:58:38.838464  3083 net.cpp:509] BatchNorm26 -> Convolution26 (in-place)
I0818 10:58:38.838742  3083 net.cpp:172] Setting up BatchNorm26
I0818 10:58:38.838755  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.838759  3083 net.cpp:194] Memory required for data: 506200320
I0818 10:58:38.838769  3083 layer_factory.hpp:77] Creating layer Scale26
I0818 10:58:38.838776  3083 net.cpp:128] Creating Layer Scale26
I0818 10:58:38.838795  3083 net.cpp:558] Scale26 <- Convolution26
I0818 10:58:38.838804  3083 net.cpp:509] Scale26 -> Convolution26 (in-place)
I0818 10:58:38.838852  3083 layer_factory.hpp:77] Creating layer Scale26
I0818 10:58:38.839004  3083 net.cpp:172] Setting up Scale26
I0818 10:58:38.839011  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.839015  3083 net.cpp:194] Memory required for data: 508297472
I0818 10:58:38.839022  3083 layer_factory.hpp:77] Creating layer Eltwise12
I0818 10:58:38.839030  3083 net.cpp:128] Creating Layer Eltwise12
I0818 10:58:38.839035  3083 net.cpp:558] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0818 10:58:38.839040  3083 net.cpp:558] Eltwise12 <- Convolution26
I0818 10:58:38.839048  3083 net.cpp:522] Eltwise12 -> Eltwise12
I0818 10:58:38.839071  3083 net.cpp:172] Setting up Eltwise12
I0818 10:58:38.839079  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.839083  3083 net.cpp:194] Memory required for data: 510394624
I0818 10:58:38.839087  3083 layer_factory.hpp:77] Creating layer ReLU25
I0818 10:58:38.839093  3083 net.cpp:128] Creating Layer ReLU25
I0818 10:58:38.839098  3083 net.cpp:558] ReLU25 <- Eltwise12
I0818 10:58:38.839103  3083 net.cpp:509] ReLU25 -> Eltwise12 (in-place)
I0818 10:58:38.840492  3083 net.cpp:172] Setting up ReLU25
I0818 10:58:38.840508  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.840513  3083 net.cpp:194] Memory required for data: 512491776
I0818 10:58:38.840517  3083 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0818 10:58:38.840538  3083 net.cpp:128] Creating Layer Eltwise12_ReLU25_0_split
I0818 10:58:38.840543  3083 net.cpp:558] Eltwise12_ReLU25_0_split <- Eltwise12
I0818 10:58:38.840551  3083 net.cpp:522] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0818 10:58:38.840567  3083 net.cpp:522] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0818 10:58:38.840625  3083 net.cpp:172] Setting up Eltwise12_ReLU25_0_split
I0818 10:58:38.840636  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.840642  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.840646  3083 net.cpp:194] Memory required for data: 516686080
I0818 10:58:38.840651  3083 layer_factory.hpp:77] Creating layer Convolution27
I0818 10:58:38.840662  3083 net.cpp:128] Creating Layer Convolution27
I0818 10:58:38.840667  3083 net.cpp:558] Convolution27 <- Eltwise12_ReLU25_0_split_0
I0818 10:58:38.840675  3083 net.cpp:522] Convolution27 -> Convolution27
I0818 10:58:38.847338  3083 net.cpp:172] Setting up Convolution27
I0818 10:58:38.847363  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.847368  3083 net.cpp:194] Memory required for data: 518783232
I0818 10:58:38.847378  3083 layer_factory.hpp:77] Creating layer BatchNorm27
I0818 10:58:38.847388  3083 net.cpp:128] Creating Layer BatchNorm27
I0818 10:58:38.847393  3083 net.cpp:558] BatchNorm27 <- Convolution27
I0818 10:58:38.847400  3083 net.cpp:509] BatchNorm27 -> Convolution27 (in-place)
I0818 10:58:38.847666  3083 net.cpp:172] Setting up BatchNorm27
I0818 10:58:38.847679  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.847683  3083 net.cpp:194] Memory required for data: 520880384
I0818 10:58:38.847693  3083 layer_factory.hpp:77] Creating layer Scale27
I0818 10:58:38.847700  3083 net.cpp:128] Creating Layer Scale27
I0818 10:58:38.847704  3083 net.cpp:558] Scale27 <- Convolution27
I0818 10:58:38.847709  3083 net.cpp:509] Scale27 -> Convolution27 (in-place)
I0818 10:58:38.847759  3083 layer_factory.hpp:77] Creating layer Scale27
I0818 10:58:38.847913  3083 net.cpp:172] Setting up Scale27
I0818 10:58:38.847920  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.847925  3083 net.cpp:194] Memory required for data: 522977536
I0818 10:58:38.847934  3083 layer_factory.hpp:77] Creating layer ReLU26
I0818 10:58:38.847940  3083 net.cpp:128] Creating Layer ReLU26
I0818 10:58:38.847944  3083 net.cpp:558] ReLU26 <- Convolution27
I0818 10:58:38.847952  3083 net.cpp:509] ReLU26 -> Convolution27 (in-place)
I0818 10:58:38.849439  3083 net.cpp:172] Setting up ReLU26
I0818 10:58:38.849462  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.849467  3083 net.cpp:194] Memory required for data: 525074688
I0818 10:58:38.849472  3083 layer_factory.hpp:77] Creating layer Convolution28
I0818 10:58:38.849485  3083 net.cpp:128] Creating Layer Convolution28
I0818 10:58:38.849493  3083 net.cpp:558] Convolution28 <- Convolution27
I0818 10:58:38.849503  3083 net.cpp:522] Convolution28 -> Convolution28
I0818 10:58:38.858386  3083 net.cpp:172] Setting up Convolution28
I0818 10:58:38.858415  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.858420  3083 net.cpp:194] Memory required for data: 527171840
I0818 10:58:38.858430  3083 layer_factory.hpp:77] Creating layer BatchNorm28
I0818 10:58:38.858438  3083 net.cpp:128] Creating Layer BatchNorm28
I0818 10:58:38.858443  3083 net.cpp:558] BatchNorm28 <- Convolution28
I0818 10:58:38.858453  3083 net.cpp:509] BatchNorm28 -> Convolution28 (in-place)
I0818 10:58:38.858741  3083 net.cpp:172] Setting up BatchNorm28
I0818 10:58:38.858752  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.858757  3083 net.cpp:194] Memory required for data: 529268992
I0818 10:58:38.858767  3083 layer_factory.hpp:77] Creating layer Scale28
I0818 10:58:38.858777  3083 net.cpp:128] Creating Layer Scale28
I0818 10:58:38.858781  3083 net.cpp:558] Scale28 <- Convolution28
I0818 10:58:38.858786  3083 net.cpp:509] Scale28 -> Convolution28 (in-place)
I0818 10:58:38.858834  3083 layer_factory.hpp:77] Creating layer Scale28
I0818 10:58:38.858981  3083 net.cpp:172] Setting up Scale28
I0818 10:58:38.858994  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.858999  3083 net.cpp:194] Memory required for data: 531366144
I0818 10:58:38.859005  3083 layer_factory.hpp:77] Creating layer Eltwise13
I0818 10:58:38.859017  3083 net.cpp:128] Creating Layer Eltwise13
I0818 10:58:38.859022  3083 net.cpp:558] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0818 10:58:38.859027  3083 net.cpp:558] Eltwise13 <- Convolution28
I0818 10:58:38.859033  3083 net.cpp:522] Eltwise13 -> Eltwise13
I0818 10:58:38.859057  3083 net.cpp:172] Setting up Eltwise13
I0818 10:58:38.859064  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.859068  3083 net.cpp:194] Memory required for data: 533463296
I0818 10:58:38.859072  3083 layer_factory.hpp:77] Creating layer ReLU27
I0818 10:58:38.859079  3083 net.cpp:128] Creating Layer ReLU27
I0818 10:58:38.859083  3083 net.cpp:558] ReLU27 <- Eltwise13
I0818 10:58:38.859091  3083 net.cpp:509] ReLU27 -> Eltwise13 (in-place)
I0818 10:58:38.862586  3083 net.cpp:172] Setting up ReLU27
I0818 10:58:38.862603  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.862608  3083 net.cpp:194] Memory required for data: 535560448
I0818 10:58:38.862613  3083 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0818 10:58:38.862620  3083 net.cpp:128] Creating Layer Eltwise13_ReLU27_0_split
I0818 10:58:38.862625  3083 net.cpp:558] Eltwise13_ReLU27_0_split <- Eltwise13
I0818 10:58:38.862634  3083 net.cpp:522] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0818 10:58:38.862646  3083 net.cpp:522] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0818 10:58:38.862709  3083 net.cpp:172] Setting up Eltwise13_ReLU27_0_split
I0818 10:58:38.862720  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.862726  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.862730  3083 net.cpp:194] Memory required for data: 539754752
I0818 10:58:38.862735  3083 layer_factory.hpp:77] Creating layer Convolution29
I0818 10:58:38.862746  3083 net.cpp:128] Creating Layer Convolution29
I0818 10:58:38.862751  3083 net.cpp:558] Convolution29 <- Eltwise13_ReLU27_0_split_0
I0818 10:58:38.862761  3083 net.cpp:522] Convolution29 -> Convolution29
I0818 10:58:38.875747  3083 net.cpp:172] Setting up Convolution29
I0818 10:58:38.875773  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.875778  3083 net.cpp:194] Memory required for data: 541851904
I0818 10:58:38.875804  3083 layer_factory.hpp:77] Creating layer BatchNorm29
I0818 10:58:38.875813  3083 net.cpp:128] Creating Layer BatchNorm29
I0818 10:58:38.875818  3083 net.cpp:558] BatchNorm29 <- Convolution29
I0818 10:58:38.875826  3083 net.cpp:509] BatchNorm29 -> Convolution29 (in-place)
I0818 10:58:38.876092  3083 net.cpp:172] Setting up BatchNorm29
I0818 10:58:38.876106  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.876109  3083 net.cpp:194] Memory required for data: 543949056
I0818 10:58:38.876119  3083 layer_factory.hpp:77] Creating layer Scale29
I0818 10:58:38.876127  3083 net.cpp:128] Creating Layer Scale29
I0818 10:58:38.876130  3083 net.cpp:558] Scale29 <- Convolution29
I0818 10:58:38.876138  3083 net.cpp:509] Scale29 -> Convolution29 (in-place)
I0818 10:58:38.876184  3083 layer_factory.hpp:77] Creating layer Scale29
I0818 10:58:38.876334  3083 net.cpp:172] Setting up Scale29
I0818 10:58:38.876341  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.876345  3083 net.cpp:194] Memory required for data: 546046208
I0818 10:58:38.876353  3083 layer_factory.hpp:77] Creating layer ReLU28
I0818 10:58:38.876360  3083 net.cpp:128] Creating Layer ReLU28
I0818 10:58:38.876364  3083 net.cpp:558] ReLU28 <- Convolution29
I0818 10:58:38.876369  3083 net.cpp:509] ReLU28 -> Convolution29 (in-place)
I0818 10:58:38.879933  3083 net.cpp:172] Setting up ReLU28
I0818 10:58:38.879952  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.879957  3083 net.cpp:194] Memory required for data: 548143360
I0818 10:58:38.879962  3083 layer_factory.hpp:77] Creating layer Convolution30
I0818 10:58:38.879976  3083 net.cpp:128] Creating Layer Convolution30
I0818 10:58:38.879981  3083 net.cpp:558] Convolution30 <- Convolution29
I0818 10:58:38.879990  3083 net.cpp:522] Convolution30 -> Convolution30
I0818 10:58:38.889091  3083 net.cpp:172] Setting up Convolution30
I0818 10:58:38.889119  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.889124  3083 net.cpp:194] Memory required for data: 550240512
I0818 10:58:38.889134  3083 layer_factory.hpp:77] Creating layer BatchNorm30
I0818 10:58:38.889142  3083 net.cpp:128] Creating Layer BatchNorm30
I0818 10:58:38.889147  3083 net.cpp:558] BatchNorm30 <- Convolution30
I0818 10:58:38.889156  3083 net.cpp:509] BatchNorm30 -> Convolution30 (in-place)
I0818 10:58:38.889420  3083 net.cpp:172] Setting up BatchNorm30
I0818 10:58:38.889432  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.889436  3083 net.cpp:194] Memory required for data: 552337664
I0818 10:58:38.889446  3083 layer_factory.hpp:77] Creating layer Scale30
I0818 10:58:38.889453  3083 net.cpp:128] Creating Layer Scale30
I0818 10:58:38.889458  3083 net.cpp:558] Scale30 <- Convolution30
I0818 10:58:38.889463  3083 net.cpp:509] Scale30 -> Convolution30 (in-place)
I0818 10:58:38.889513  3083 layer_factory.hpp:77] Creating layer Scale30
I0818 10:58:38.889658  3083 net.cpp:172] Setting up Scale30
I0818 10:58:38.889665  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.889669  3083 net.cpp:194] Memory required for data: 554434816
I0818 10:58:38.889678  3083 layer_factory.hpp:77] Creating layer Eltwise14
I0818 10:58:38.889686  3083 net.cpp:128] Creating Layer Eltwise14
I0818 10:58:38.889691  3083 net.cpp:558] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0818 10:58:38.889696  3083 net.cpp:558] Eltwise14 <- Convolution30
I0818 10:58:38.889703  3083 net.cpp:522] Eltwise14 -> Eltwise14
I0818 10:58:38.889727  3083 net.cpp:172] Setting up Eltwise14
I0818 10:58:38.889734  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.889737  3083 net.cpp:194] Memory required for data: 556531968
I0818 10:58:38.889741  3083 layer_factory.hpp:77] Creating layer ReLU29
I0818 10:58:38.889748  3083 net.cpp:128] Creating Layer ReLU29
I0818 10:58:38.889752  3083 net.cpp:558] ReLU29 <- Eltwise14
I0818 10:58:38.889760  3083 net.cpp:509] ReLU29 -> Eltwise14 (in-place)
I0818 10:58:38.891204  3083 net.cpp:172] Setting up ReLU29
I0818 10:58:38.891221  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.891240  3083 net.cpp:194] Memory required for data: 558629120
I0818 10:58:38.891245  3083 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0818 10:58:38.891255  3083 net.cpp:128] Creating Layer Eltwise14_ReLU29_0_split
I0818 10:58:38.891261  3083 net.cpp:558] Eltwise14_ReLU29_0_split <- Eltwise14
I0818 10:58:38.891270  3083 net.cpp:522] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0818 10:58:38.891279  3083 net.cpp:522] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0818 10:58:38.891336  3083 net.cpp:172] Setting up Eltwise14_ReLU29_0_split
I0818 10:58:38.891347  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.891353  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.891357  3083 net.cpp:194] Memory required for data: 562823424
I0818 10:58:38.891361  3083 layer_factory.hpp:77] Creating layer Convolution31
I0818 10:58:38.891373  3083 net.cpp:128] Creating Layer Convolution31
I0818 10:58:38.891378  3083 net.cpp:558] Convolution31 <- Eltwise14_ReLU29_0_split_0
I0818 10:58:38.891388  3083 net.cpp:522] Convolution31 -> Convolution31
I0818 10:58:38.898069  3083 net.cpp:172] Setting up Convolution31
I0818 10:58:38.898097  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.898100  3083 net.cpp:194] Memory required for data: 564920576
I0818 10:58:38.898110  3083 layer_factory.hpp:77] Creating layer BatchNorm31
I0818 10:58:38.898119  3083 net.cpp:128] Creating Layer BatchNorm31
I0818 10:58:38.898124  3083 net.cpp:558] BatchNorm31 <- Convolution31
I0818 10:58:38.898142  3083 net.cpp:509] BatchNorm31 -> Convolution31 (in-place)
I0818 10:58:38.898413  3083 net.cpp:172] Setting up BatchNorm31
I0818 10:58:38.898423  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.898427  3083 net.cpp:194] Memory required for data: 567017728
I0818 10:58:38.898437  3083 layer_factory.hpp:77] Creating layer Scale31
I0818 10:58:38.898447  3083 net.cpp:128] Creating Layer Scale31
I0818 10:58:38.898452  3083 net.cpp:558] Scale31 <- Convolution31
I0818 10:58:38.898456  3083 net.cpp:509] Scale31 -> Convolution31 (in-place)
I0818 10:58:38.898505  3083 layer_factory.hpp:77] Creating layer Scale31
I0818 10:58:38.898663  3083 net.cpp:172] Setting up Scale31
I0818 10:58:38.898676  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.898681  3083 net.cpp:194] Memory required for data: 569114880
I0818 10:58:38.898689  3083 layer_factory.hpp:77] Creating layer ReLU30
I0818 10:58:38.898699  3083 net.cpp:128] Creating Layer ReLU30
I0818 10:58:38.898703  3083 net.cpp:558] ReLU30 <- Convolution31
I0818 10:58:38.898708  3083 net.cpp:509] ReLU30 -> Convolution31 (in-place)
I0818 10:58:38.900146  3083 net.cpp:172] Setting up ReLU30
I0818 10:58:38.900168  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.900173  3083 net.cpp:194] Memory required for data: 571212032
I0818 10:58:38.900178  3083 layer_factory.hpp:77] Creating layer Convolution32
I0818 10:58:38.900193  3083 net.cpp:128] Creating Layer Convolution32
I0818 10:58:38.900202  3083 net.cpp:558] Convolution32 <- Convolution31
I0818 10:58:38.900210  3083 net.cpp:522] Convolution32 -> Convolution32
I0818 10:58:38.905352  3083 net.cpp:172] Setting up Convolution32
I0818 10:58:38.905375  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.905380  3083 net.cpp:194] Memory required for data: 573309184
I0818 10:58:38.905390  3083 layer_factory.hpp:77] Creating layer BatchNorm32
I0818 10:58:38.905401  3083 net.cpp:128] Creating Layer BatchNorm32
I0818 10:58:38.905407  3083 net.cpp:558] BatchNorm32 <- Convolution32
I0818 10:58:38.905418  3083 net.cpp:509] BatchNorm32 -> Convolution32 (in-place)
I0818 10:58:38.905688  3083 net.cpp:172] Setting up BatchNorm32
I0818 10:58:38.905697  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.905701  3083 net.cpp:194] Memory required for data: 575406336
I0818 10:58:38.905712  3083 layer_factory.hpp:77] Creating layer Scale32
I0818 10:58:38.905721  3083 net.cpp:128] Creating Layer Scale32
I0818 10:58:38.905740  3083 net.cpp:558] Scale32 <- Convolution32
I0818 10:58:38.905750  3083 net.cpp:509] Scale32 -> Convolution32 (in-place)
I0818 10:58:38.905799  3083 layer_factory.hpp:77] Creating layer Scale32
I0818 10:58:38.905956  3083 net.cpp:172] Setting up Scale32
I0818 10:58:38.905967  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.905972  3083 net.cpp:194] Memory required for data: 577503488
I0818 10:58:38.905979  3083 layer_factory.hpp:77] Creating layer Eltwise15
I0818 10:58:38.905989  3083 net.cpp:128] Creating Layer Eltwise15
I0818 10:58:38.905995  3083 net.cpp:558] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0818 10:58:38.906002  3083 net.cpp:558] Eltwise15 <- Convolution32
I0818 10:58:38.906010  3083 net.cpp:522] Eltwise15 -> Eltwise15
I0818 10:58:38.906035  3083 net.cpp:172] Setting up Eltwise15
I0818 10:58:38.906042  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.906046  3083 net.cpp:194] Memory required for data: 579600640
I0818 10:58:38.906050  3083 layer_factory.hpp:77] Creating layer ReLU31
I0818 10:58:38.906059  3083 net.cpp:128] Creating Layer ReLU31
I0818 10:58:38.906064  3083 net.cpp:558] ReLU31 <- Eltwise15
I0818 10:58:38.906069  3083 net.cpp:509] ReLU31 -> Eltwise15 (in-place)
I0818 10:58:38.906602  3083 net.cpp:172] Setting up ReLU31
I0818 10:58:38.906621  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.906626  3083 net.cpp:194] Memory required for data: 581697792
I0818 10:58:38.906631  3083 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0818 10:58:38.906646  3083 net.cpp:128] Creating Layer Eltwise15_ReLU31_0_split
I0818 10:58:38.906664  3083 net.cpp:558] Eltwise15_ReLU31_0_split <- Eltwise15
I0818 10:58:38.906674  3083 net.cpp:522] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0818 10:58:38.906684  3083 net.cpp:522] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0818 10:58:38.906744  3083 net.cpp:172] Setting up Eltwise15_ReLU31_0_split
I0818 10:58:38.906754  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.906759  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.906764  3083 net.cpp:194] Memory required for data: 585892096
I0818 10:58:38.906767  3083 layer_factory.hpp:77] Creating layer Convolution33
I0818 10:58:38.906780  3083 net.cpp:128] Creating Layer Convolution33
I0818 10:58:38.906788  3083 net.cpp:558] Convolution33 <- Eltwise15_ReLU31_0_split_0
I0818 10:58:38.906795  3083 net.cpp:522] Convolution33 -> Convolution33
I0818 10:58:38.913192  3083 net.cpp:172] Setting up Convolution33
I0818 10:58:38.913219  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.913224  3083 net.cpp:194] Memory required for data: 587989248
I0818 10:58:38.913234  3083 layer_factory.hpp:77] Creating layer BatchNorm33
I0818 10:58:38.913244  3083 net.cpp:128] Creating Layer BatchNorm33
I0818 10:58:38.913251  3083 net.cpp:558] BatchNorm33 <- Convolution33
I0818 10:58:38.913261  3083 net.cpp:509] BatchNorm33 -> Convolution33 (in-place)
I0818 10:58:38.913547  3083 net.cpp:172] Setting up BatchNorm33
I0818 10:58:38.913559  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.913563  3083 net.cpp:194] Memory required for data: 590086400
I0818 10:58:38.913574  3083 layer_factory.hpp:77] Creating layer Scale33
I0818 10:58:38.913583  3083 net.cpp:128] Creating Layer Scale33
I0818 10:58:38.913589  3083 net.cpp:558] Scale33 <- Convolution33
I0818 10:58:38.913594  3083 net.cpp:509] Scale33 -> Convolution33 (in-place)
I0818 10:58:38.913643  3083 layer_factory.hpp:77] Creating layer Scale33
I0818 10:58:38.913800  3083 net.cpp:172] Setting up Scale33
I0818 10:58:38.913807  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.913811  3083 net.cpp:194] Memory required for data: 592183552
I0818 10:58:38.913820  3083 layer_factory.hpp:77] Creating layer ReLU32
I0818 10:58:38.913827  3083 net.cpp:128] Creating Layer ReLU32
I0818 10:58:38.913832  3083 net.cpp:558] ReLU32 <- Convolution33
I0818 10:58:38.913837  3083 net.cpp:509] ReLU32 -> Convolution33 (in-place)
I0818 10:58:38.914947  3083 net.cpp:172] Setting up ReLU32
I0818 10:58:38.914976  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.914980  3083 net.cpp:194] Memory required for data: 594280704
I0818 10:58:38.914985  3083 layer_factory.hpp:77] Creating layer Convolution34
I0818 10:58:38.915000  3083 net.cpp:128] Creating Layer Convolution34
I0818 10:58:38.915005  3083 net.cpp:558] Convolution34 <- Convolution33
I0818 10:58:38.915014  3083 net.cpp:522] Convolution34 -> Convolution34
I0818 10:58:38.916548  3083 net.cpp:172] Setting up Convolution34
I0818 10:58:38.916571  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.916576  3083 net.cpp:194] Memory required for data: 596377856
I0818 10:58:38.916586  3083 layer_factory.hpp:77] Creating layer BatchNorm34
I0818 10:58:38.916597  3083 net.cpp:128] Creating Layer BatchNorm34
I0818 10:58:38.916602  3083 net.cpp:558] BatchNorm34 <- Convolution34
I0818 10:58:38.916611  3083 net.cpp:509] BatchNorm34 -> Convolution34 (in-place)
I0818 10:58:38.916877  3083 net.cpp:172] Setting up BatchNorm34
I0818 10:58:38.916888  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.916893  3083 net.cpp:194] Memory required for data: 598475008
I0818 10:58:38.916903  3083 layer_factory.hpp:77] Creating layer Scale34
I0818 10:58:38.916909  3083 net.cpp:128] Creating Layer Scale34
I0818 10:58:38.916913  3083 net.cpp:558] Scale34 <- Convolution34
I0818 10:58:38.916923  3083 net.cpp:509] Scale34 -> Convolution34 (in-place)
I0818 10:58:38.916970  3083 layer_factory.hpp:77] Creating layer Scale34
I0818 10:58:38.917124  3083 net.cpp:172] Setting up Scale34
I0818 10:58:38.917135  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.917138  3083 net.cpp:194] Memory required for data: 600572160
I0818 10:58:38.917146  3083 layer_factory.hpp:77] Creating layer Eltwise16
I0818 10:58:38.917153  3083 net.cpp:128] Creating Layer Eltwise16
I0818 10:58:38.917158  3083 net.cpp:558] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0818 10:58:38.917163  3083 net.cpp:558] Eltwise16 <- Convolution34
I0818 10:58:38.917171  3083 net.cpp:522] Eltwise16 -> Eltwise16
I0818 10:58:38.917194  3083 net.cpp:172] Setting up Eltwise16
I0818 10:58:38.917203  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.917207  3083 net.cpp:194] Memory required for data: 602669312
I0818 10:58:38.917212  3083 layer_factory.hpp:77] Creating layer ReLU33
I0818 10:58:38.917217  3083 net.cpp:128] Creating Layer ReLU33
I0818 10:58:38.917222  3083 net.cpp:558] ReLU33 <- Eltwise16
I0818 10:58:38.917227  3083 net.cpp:509] ReLU33 -> Eltwise16 (in-place)
I0818 10:58:38.917768  3083 net.cpp:172] Setting up ReLU33
I0818 10:58:38.917789  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.917793  3083 net.cpp:194] Memory required for data: 604766464
I0818 10:58:38.917798  3083 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0818 10:58:38.917809  3083 net.cpp:128] Creating Layer Eltwise16_ReLU33_0_split
I0818 10:58:38.917814  3083 net.cpp:558] Eltwise16_ReLU33_0_split <- Eltwise16
I0818 10:58:38.917824  3083 net.cpp:522] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0818 10:58:38.917832  3083 net.cpp:522] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0818 10:58:38.917886  3083 net.cpp:172] Setting up Eltwise16_ReLU33_0_split
I0818 10:58:38.917896  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.917901  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.917906  3083 net.cpp:194] Memory required for data: 608960768
I0818 10:58:38.917909  3083 layer_factory.hpp:77] Creating layer Convolution35
I0818 10:58:38.917922  3083 net.cpp:128] Creating Layer Convolution35
I0818 10:58:38.917925  3083 net.cpp:558] Convolution35 <- Eltwise16_ReLU33_0_split_0
I0818 10:58:38.917932  3083 net.cpp:522] Convolution35 -> Convolution35
I0818 10:58:38.919603  3083 net.cpp:172] Setting up Convolution35
I0818 10:58:38.919627  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.919631  3083 net.cpp:194] Memory required for data: 611057920
I0818 10:58:38.919657  3083 layer_factory.hpp:77] Creating layer BatchNorm35
I0818 10:58:38.919668  3083 net.cpp:128] Creating Layer BatchNorm35
I0818 10:58:38.919673  3083 net.cpp:558] BatchNorm35 <- Convolution35
I0818 10:58:38.919684  3083 net.cpp:509] BatchNorm35 -> Convolution35 (in-place)
I0818 10:58:38.919957  3083 net.cpp:172] Setting up BatchNorm35
I0818 10:58:38.919965  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.919968  3083 net.cpp:194] Memory required for data: 613155072
I0818 10:58:38.919978  3083 layer_factory.hpp:77] Creating layer Scale35
I0818 10:58:38.919986  3083 net.cpp:128] Creating Layer Scale35
I0818 10:58:38.919989  3083 net.cpp:558] Scale35 <- Convolution35
I0818 10:58:38.919994  3083 net.cpp:509] Scale35 -> Convolution35 (in-place)
I0818 10:58:38.920043  3083 layer_factory.hpp:77] Creating layer Scale35
I0818 10:58:38.920197  3083 net.cpp:172] Setting up Scale35
I0818 10:58:38.920204  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.920208  3083 net.cpp:194] Memory required for data: 615252224
I0818 10:58:38.920215  3083 layer_factory.hpp:77] Creating layer ReLU34
I0818 10:58:38.920224  3083 net.cpp:128] Creating Layer ReLU34
I0818 10:58:38.920228  3083 net.cpp:558] ReLU34 <- Convolution35
I0818 10:58:38.920234  3083 net.cpp:509] ReLU34 -> Convolution35 (in-place)
I0818 10:58:38.920478  3083 net.cpp:172] Setting up ReLU34
I0818 10:58:38.920487  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.920491  3083 net.cpp:194] Memory required for data: 617349376
I0818 10:58:38.920496  3083 layer_factory.hpp:77] Creating layer Convolution36
I0818 10:58:38.920508  3083 net.cpp:128] Creating Layer Convolution36
I0818 10:58:38.920513  3083 net.cpp:558] Convolution36 <- Convolution35
I0818 10:58:38.920522  3083 net.cpp:522] Convolution36 -> Convolution36
I0818 10:58:38.927038  3083 net.cpp:172] Setting up Convolution36
I0818 10:58:38.927067  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.927072  3083 net.cpp:194] Memory required for data: 619446528
I0818 10:58:38.927083  3083 layer_factory.hpp:77] Creating layer BatchNorm36
I0818 10:58:38.927100  3083 net.cpp:128] Creating Layer BatchNorm36
I0818 10:58:38.927106  3083 net.cpp:558] BatchNorm36 <- Convolution36
I0818 10:58:38.927114  3083 net.cpp:509] BatchNorm36 -> Convolution36 (in-place)
I0818 10:58:38.927392  3083 net.cpp:172] Setting up BatchNorm36
I0818 10:58:38.927402  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.927407  3083 net.cpp:194] Memory required for data: 621543680
I0818 10:58:38.927417  3083 layer_factory.hpp:77] Creating layer Scale36
I0818 10:58:38.927428  3083 net.cpp:128] Creating Layer Scale36
I0818 10:58:38.927433  3083 net.cpp:558] Scale36 <- Convolution36
I0818 10:58:38.927439  3083 net.cpp:509] Scale36 -> Convolution36 (in-place)
I0818 10:58:38.927489  3083 layer_factory.hpp:77] Creating layer Scale36
I0818 10:58:38.927650  3083 net.cpp:172] Setting up Scale36
I0818 10:58:38.927660  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.927664  3083 net.cpp:194] Memory required for data: 623640832
I0818 10:58:38.927672  3083 layer_factory.hpp:77] Creating layer Eltwise17
I0818 10:58:38.927685  3083 net.cpp:128] Creating Layer Eltwise17
I0818 10:58:38.927690  3083 net.cpp:558] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0818 10:58:38.927695  3083 net.cpp:558] Eltwise17 <- Convolution36
I0818 10:58:38.927705  3083 net.cpp:522] Eltwise17 -> Eltwise17
I0818 10:58:38.927727  3083 net.cpp:172] Setting up Eltwise17
I0818 10:58:38.927734  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.927738  3083 net.cpp:194] Memory required for data: 625737984
I0818 10:58:38.927743  3083 layer_factory.hpp:77] Creating layer ReLU35
I0818 10:58:38.927754  3083 net.cpp:128] Creating Layer ReLU35
I0818 10:58:38.927759  3083 net.cpp:558] ReLU35 <- Eltwise17
I0818 10:58:38.927767  3083 net.cpp:509] ReLU35 -> Eltwise17 (in-place)
I0818 10:58:38.930109  3083 net.cpp:172] Setting up ReLU35
I0818 10:58:38.930126  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.930155  3083 net.cpp:194] Memory required for data: 627835136
I0818 10:58:38.930160  3083 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0818 10:58:38.930171  3083 net.cpp:128] Creating Layer Eltwise17_ReLU35_0_split
I0818 10:58:38.930176  3083 net.cpp:558] Eltwise17_ReLU35_0_split <- Eltwise17
I0818 10:58:38.930183  3083 net.cpp:522] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0818 10:58:38.930194  3083 net.cpp:522] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0818 10:58:38.930250  3083 net.cpp:172] Setting up Eltwise17_ReLU35_0_split
I0818 10:58:38.930260  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.930266  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.930270  3083 net.cpp:194] Memory required for data: 632029440
I0818 10:58:38.930274  3083 layer_factory.hpp:77] Creating layer Convolution37
I0818 10:58:38.930289  3083 net.cpp:128] Creating Layer Convolution37
I0818 10:58:38.930294  3083 net.cpp:558] Convolution37 <- Eltwise17_ReLU35_0_split_0
I0818 10:58:38.930305  3083 net.cpp:522] Convolution37 -> Convolution37
I0818 10:58:38.936976  3083 net.cpp:172] Setting up Convolution37
I0818 10:58:38.937003  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.937008  3083 net.cpp:194] Memory required for data: 634126592
I0818 10:58:38.937018  3083 layer_factory.hpp:77] Creating layer BatchNorm37
I0818 10:58:38.937029  3083 net.cpp:128] Creating Layer BatchNorm37
I0818 10:58:38.937038  3083 net.cpp:558] BatchNorm37 <- Convolution37
I0818 10:58:38.937045  3083 net.cpp:509] BatchNorm37 -> Convolution37 (in-place)
I0818 10:58:38.937319  3083 net.cpp:172] Setting up BatchNorm37
I0818 10:58:38.937330  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.937335  3083 net.cpp:194] Memory required for data: 636223744
I0818 10:58:38.937366  3083 layer_factory.hpp:77] Creating layer Scale37
I0818 10:58:38.937377  3083 net.cpp:128] Creating Layer Scale37
I0818 10:58:38.937382  3083 net.cpp:558] Scale37 <- Convolution37
I0818 10:58:38.937388  3083 net.cpp:509] Scale37 -> Convolution37 (in-place)
I0818 10:58:38.937438  3083 layer_factory.hpp:77] Creating layer Scale37
I0818 10:58:38.937597  3083 net.cpp:172] Setting up Scale37
I0818 10:58:38.937606  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.937611  3083 net.cpp:194] Memory required for data: 638320896
I0818 10:58:38.937618  3083 layer_factory.hpp:77] Creating layer ReLU36
I0818 10:58:38.937628  3083 net.cpp:128] Creating Layer ReLU36
I0818 10:58:38.937634  3083 net.cpp:558] ReLU36 <- Convolution37
I0818 10:58:38.937640  3083 net.cpp:509] ReLU36 -> Convolution37 (in-place)
I0818 10:58:38.939087  3083 net.cpp:172] Setting up ReLU36
I0818 10:58:38.939107  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.939112  3083 net.cpp:194] Memory required for data: 640418048
I0818 10:58:38.939117  3083 layer_factory.hpp:77] Creating layer Convolution38
I0818 10:58:38.939131  3083 net.cpp:128] Creating Layer Convolution38
I0818 10:58:38.939136  3083 net.cpp:558] Convolution38 <- Convolution37
I0818 10:58:38.939153  3083 net.cpp:522] Convolution38 -> Convolution38
I0818 10:58:38.946050  3083 net.cpp:172] Setting up Convolution38
I0818 10:58:38.946074  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.946079  3083 net.cpp:194] Memory required for data: 642515200
I0818 10:58:38.946089  3083 layer_factory.hpp:77] Creating layer BatchNorm38
I0818 10:58:38.946097  3083 net.cpp:128] Creating Layer BatchNorm38
I0818 10:58:38.946102  3083 net.cpp:558] BatchNorm38 <- Convolution38
I0818 10:58:38.946111  3083 net.cpp:509] BatchNorm38 -> Convolution38 (in-place)
I0818 10:58:38.946395  3083 net.cpp:172] Setting up BatchNorm38
I0818 10:58:38.946406  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.946410  3083 net.cpp:194] Memory required for data: 644612352
I0818 10:58:38.946420  3083 layer_factory.hpp:77] Creating layer Scale38
I0818 10:58:38.946431  3083 net.cpp:128] Creating Layer Scale38
I0818 10:58:38.946436  3083 net.cpp:558] Scale38 <- Convolution38
I0818 10:58:38.946463  3083 net.cpp:509] Scale38 -> Convolution38 (in-place)
I0818 10:58:38.946517  3083 layer_factory.hpp:77] Creating layer Scale38
I0818 10:58:38.946686  3083 net.cpp:172] Setting up Scale38
I0818 10:58:38.946698  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.946702  3083 net.cpp:194] Memory required for data: 646709504
I0818 10:58:38.946710  3083 layer_factory.hpp:77] Creating layer Eltwise18
I0818 10:58:38.946722  3083 net.cpp:128] Creating Layer Eltwise18
I0818 10:58:38.946727  3083 net.cpp:558] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0818 10:58:38.946735  3083 net.cpp:558] Eltwise18 <- Convolution38
I0818 10:58:38.946744  3083 net.cpp:522] Eltwise18 -> Eltwise18
I0818 10:58:38.946770  3083 net.cpp:172] Setting up Eltwise18
I0818 10:58:38.946780  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.946784  3083 net.cpp:194] Memory required for data: 648806656
I0818 10:58:38.946789  3083 layer_factory.hpp:77] Creating layer ReLU37
I0818 10:58:38.946795  3083 net.cpp:128] Creating Layer ReLU37
I0818 10:58:38.946805  3083 net.cpp:558] ReLU37 <- Eltwise18
I0818 10:58:38.946811  3083 net.cpp:509] ReLU37 -> Eltwise18 (in-place)
I0818 10:58:38.948168  3083 net.cpp:172] Setting up ReLU37
I0818 10:58:38.948181  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.948186  3083 net.cpp:194] Memory required for data: 650903808
I0818 10:58:38.948190  3083 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0818 10:58:38.948200  3083 net.cpp:128] Creating Layer Eltwise18_ReLU37_0_split
I0818 10:58:38.948210  3083 net.cpp:558] Eltwise18_ReLU37_0_split <- Eltwise18
I0818 10:58:38.948216  3083 net.cpp:522] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0818 10:58:38.948225  3083 net.cpp:522] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0818 10:58:38.948284  3083 net.cpp:172] Setting up Eltwise18_ReLU37_0_split
I0818 10:58:38.948295  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.948302  3083 net.cpp:186] Top shape: 64 32 16 16 (524288)
I0818 10:58:38.948305  3083 net.cpp:194] Memory required for data: 655098112
I0818 10:58:38.948313  3083 layer_factory.hpp:77] Creating layer Convolution39
I0818 10:58:38.948325  3083 net.cpp:128] Creating Layer Convolution39
I0818 10:58:38.948334  3083 net.cpp:558] Convolution39 <- Eltwise18_ReLU37_0_split_0
I0818 10:58:38.948343  3083 net.cpp:522] Convolution39 -> Convolution39
I0818 10:58:38.961326  3083 net.cpp:172] Setting up Convolution39
I0818 10:58:38.961354  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.961357  3083 net.cpp:194] Memory required for data: 656146688
I0818 10:58:38.961369  3083 layer_factory.hpp:77] Creating layer BatchNorm39
I0818 10:58:38.961378  3083 net.cpp:128] Creating Layer BatchNorm39
I0818 10:58:38.961385  3083 net.cpp:558] BatchNorm39 <- Convolution39
I0818 10:58:38.961400  3083 net.cpp:509] BatchNorm39 -> Convolution39 (in-place)
I0818 10:58:38.961681  3083 net.cpp:172] Setting up BatchNorm39
I0818 10:58:38.961691  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.961695  3083 net.cpp:194] Memory required for data: 657195264
I0818 10:58:38.961705  3083 layer_factory.hpp:77] Creating layer Scale39
I0818 10:58:38.961717  3083 net.cpp:128] Creating Layer Scale39
I0818 10:58:38.961722  3083 net.cpp:558] Scale39 <- Convolution39
I0818 10:58:38.961729  3083 net.cpp:509] Scale39 -> Convolution39 (in-place)
I0818 10:58:38.961778  3083 layer_factory.hpp:77] Creating layer Scale39
I0818 10:58:38.961941  3083 net.cpp:172] Setting up Scale39
I0818 10:58:38.961951  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.961956  3083 net.cpp:194] Memory required for data: 658243840
I0818 10:58:38.961963  3083 layer_factory.hpp:77] Creating layer Convolution40
I0818 10:58:38.961980  3083 net.cpp:128] Creating Layer Convolution40
I0818 10:58:38.961987  3083 net.cpp:558] Convolution40 <- Eltwise18_ReLU37_0_split_1
I0818 10:58:38.961995  3083 net.cpp:522] Convolution40 -> Convolution40
I0818 10:58:38.974617  3083 net.cpp:172] Setting up Convolution40
I0818 10:58:38.974683  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.974689  3083 net.cpp:194] Memory required for data: 659292416
I0818 10:58:38.974700  3083 layer_factory.hpp:77] Creating layer BatchNorm40
I0818 10:58:38.974710  3083 net.cpp:128] Creating Layer BatchNorm40
I0818 10:58:38.974715  3083 net.cpp:558] BatchNorm40 <- Convolution40
I0818 10:58:38.974725  3083 net.cpp:509] BatchNorm40 -> Convolution40 (in-place)
I0818 10:58:38.975028  3083 net.cpp:172] Setting up BatchNorm40
I0818 10:58:38.975064  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.975085  3083 net.cpp:194] Memory required for data: 660340992
I0818 10:58:38.975107  3083 layer_factory.hpp:77] Creating layer Scale40
I0818 10:58:38.975124  3083 net.cpp:128] Creating Layer Scale40
I0818 10:58:38.975139  3083 net.cpp:558] Scale40 <- Convolution40
I0818 10:58:38.975158  3083 net.cpp:509] Scale40 -> Convolution40 (in-place)
I0818 10:58:38.975226  3083 layer_factory.hpp:77] Creating layer Scale40
I0818 10:58:38.975411  3083 net.cpp:172] Setting up Scale40
I0818 10:58:38.975430  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.975443  3083 net.cpp:194] Memory required for data: 661389568
I0818 10:58:38.975461  3083 layer_factory.hpp:77] Creating layer ReLU38
I0818 10:58:38.975479  3083 net.cpp:128] Creating Layer ReLU38
I0818 10:58:38.975497  3083 net.cpp:558] ReLU38 <- Convolution40
I0818 10:58:38.975515  3083 net.cpp:509] ReLU38 -> Convolution40 (in-place)
I0818 10:58:38.978420  3083 net.cpp:172] Setting up ReLU38
I0818 10:58:38.978438  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.978443  3083 net.cpp:194] Memory required for data: 662438144
I0818 10:58:38.978447  3083 layer_factory.hpp:77] Creating layer Convolution41
I0818 10:58:38.978462  3083 net.cpp:128] Creating Layer Convolution41
I0818 10:58:38.978467  3083 net.cpp:558] Convolution41 <- Convolution40
I0818 10:58:38.978477  3083 net.cpp:522] Convolution41 -> Convolution41
I0818 10:58:38.985513  3083 net.cpp:172] Setting up Convolution41
I0818 10:58:38.985540  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.985544  3083 net.cpp:194] Memory required for data: 663486720
I0818 10:58:38.985554  3083 layer_factory.hpp:77] Creating layer BatchNorm41
I0818 10:58:38.985565  3083 net.cpp:128] Creating Layer BatchNorm41
I0818 10:58:38.985571  3083 net.cpp:558] BatchNorm41 <- Convolution41
I0818 10:58:38.985580  3083 net.cpp:509] BatchNorm41 -> Convolution41 (in-place)
I0818 10:58:38.985882  3083 net.cpp:172] Setting up BatchNorm41
I0818 10:58:38.985895  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.985899  3083 net.cpp:194] Memory required for data: 664535296
I0818 10:58:38.985909  3083 layer_factory.hpp:77] Creating layer Scale41
I0818 10:58:38.985916  3083 net.cpp:128] Creating Layer Scale41
I0818 10:58:38.985921  3083 net.cpp:558] Scale41 <- Convolution41
I0818 10:58:38.985929  3083 net.cpp:509] Scale41 -> Convolution41 (in-place)
I0818 10:58:38.985977  3083 layer_factory.hpp:77] Creating layer Scale41
I0818 10:58:38.986142  3083 net.cpp:172] Setting up Scale41
I0818 10:58:38.986155  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.986160  3083 net.cpp:194] Memory required for data: 665583872
I0818 10:58:38.986169  3083 layer_factory.hpp:77] Creating layer Eltwise19
I0818 10:58:38.986178  3083 net.cpp:128] Creating Layer Eltwise19
I0818 10:58:38.986183  3083 net.cpp:558] Eltwise19 <- Convolution39
I0818 10:58:38.986188  3083 net.cpp:558] Eltwise19 <- Convolution41
I0818 10:58:38.986197  3083 net.cpp:522] Eltwise19 -> Eltwise19
I0818 10:58:38.986229  3083 net.cpp:172] Setting up Eltwise19
I0818 10:58:38.986237  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.986239  3083 net.cpp:194] Memory required for data: 666632448
I0818 10:58:38.986244  3083 layer_factory.hpp:77] Creating layer ReLU39
I0818 10:58:38.986250  3083 net.cpp:128] Creating Layer ReLU39
I0818 10:58:38.986254  3083 net.cpp:558] ReLU39 <- Eltwise19
I0818 10:58:38.986261  3083 net.cpp:509] ReLU39 -> Eltwise19 (in-place)
I0818 10:58:38.987326  3083 net.cpp:172] Setting up ReLU39
I0818 10:58:38.987344  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.987349  3083 net.cpp:194] Memory required for data: 667681024
I0818 10:58:38.987354  3083 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0818 10:58:38.987361  3083 net.cpp:128] Creating Layer Eltwise19_ReLU39_0_split
I0818 10:58:38.987366  3083 net.cpp:558] Eltwise19_ReLU39_0_split <- Eltwise19
I0818 10:58:38.987377  3083 net.cpp:522] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0818 10:58:38.987386  3083 net.cpp:522] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0818 10:58:38.987444  3083 net.cpp:172] Setting up Eltwise19_ReLU39_0_split
I0818 10:58:38.987454  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.987460  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.987464  3083 net.cpp:194] Memory required for data: 669778176
I0818 10:58:38.987468  3083 layer_factory.hpp:77] Creating layer Convolution42
I0818 10:58:38.987480  3083 net.cpp:128] Creating Layer Convolution42
I0818 10:58:38.987485  3083 net.cpp:558] Convolution42 <- Eltwise19_ReLU39_0_split_0
I0818 10:58:38.987494  3083 net.cpp:522] Convolution42 -> Convolution42
I0818 10:58:38.991778  3083 net.cpp:172] Setting up Convolution42
I0818 10:58:38.991829  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.991849  3083 net.cpp:194] Memory required for data: 670826752
I0818 10:58:38.991870  3083 layer_factory.hpp:77] Creating layer BatchNorm42
I0818 10:58:38.991891  3083 net.cpp:128] Creating Layer BatchNorm42
I0818 10:58:38.991906  3083 net.cpp:558] BatchNorm42 <- Convolution42
I0818 10:58:38.991930  3083 net.cpp:509] BatchNorm42 -> Convolution42 (in-place)
I0818 10:58:38.992239  3083 net.cpp:172] Setting up BatchNorm42
I0818 10:58:38.992261  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.992274  3083 net.cpp:194] Memory required for data: 671875328
I0818 10:58:38.992295  3083 layer_factory.hpp:77] Creating layer Scale42
I0818 10:58:38.992316  3083 net.cpp:128] Creating Layer Scale42
I0818 10:58:38.992331  3083 net.cpp:558] Scale42 <- Convolution42
I0818 10:58:38.992347  3083 net.cpp:509] Scale42 -> Convolution42 (in-place)
I0818 10:58:38.992419  3083 layer_factory.hpp:77] Creating layer Scale42
I0818 10:58:38.992600  3083 net.cpp:172] Setting up Scale42
I0818 10:58:38.992622  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.992636  3083 net.cpp:194] Memory required for data: 672923904
I0818 10:58:38.992655  3083 layer_factory.hpp:77] Creating layer ReLU40
I0818 10:58:38.992673  3083 net.cpp:128] Creating Layer ReLU40
I0818 10:58:38.992692  3083 net.cpp:558] ReLU40 <- Convolution42
I0818 10:58:38.992708  3083 net.cpp:509] ReLU40 -> Convolution42 (in-place)
I0818 10:58:38.995990  3083 net.cpp:172] Setting up ReLU40
I0818 10:58:38.996014  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:38.996019  3083 net.cpp:194] Memory required for data: 673972480
I0818 10:58:38.996024  3083 layer_factory.hpp:77] Creating layer Convolution43
I0818 10:58:38.996042  3083 net.cpp:128] Creating Layer Convolution43
I0818 10:58:38.996047  3083 net.cpp:558] Convolution43 <- Convolution42
I0818 10:58:38.996055  3083 net.cpp:522] Convolution43 -> Convolution43
I0818 10:58:39.009433  3083 net.cpp:172] Setting up Convolution43
I0818 10:58:39.009461  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.009466  3083 net.cpp:194] Memory required for data: 675021056
I0818 10:58:39.009477  3083 layer_factory.hpp:77] Creating layer BatchNorm43
I0818 10:58:39.009486  3083 net.cpp:128] Creating Layer BatchNorm43
I0818 10:58:39.009491  3083 net.cpp:558] BatchNorm43 <- Convolution43
I0818 10:58:39.009500  3083 net.cpp:509] BatchNorm43 -> Convolution43 (in-place)
I0818 10:58:39.009802  3083 net.cpp:172] Setting up BatchNorm43
I0818 10:58:39.009845  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.009862  3083 net.cpp:194] Memory required for data: 676069632
I0818 10:58:39.009883  3083 layer_factory.hpp:77] Creating layer Scale43
I0818 10:58:39.009914  3083 net.cpp:128] Creating Layer Scale43
I0818 10:58:39.009928  3083 net.cpp:558] Scale43 <- Convolution43
I0818 10:58:39.009948  3083 net.cpp:509] Scale43 -> Convolution43 (in-place)
I0818 10:58:39.010021  3083 layer_factory.hpp:77] Creating layer Scale43
I0818 10:58:39.010211  3083 net.cpp:172] Setting up Scale43
I0818 10:58:39.010231  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.010246  3083 net.cpp:194] Memory required for data: 677118208
I0818 10:58:39.010264  3083 layer_factory.hpp:77] Creating layer Eltwise20
I0818 10:58:39.010284  3083 net.cpp:128] Creating Layer Eltwise20
I0818 10:58:39.010300  3083 net.cpp:558] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0818 10:58:39.010315  3083 net.cpp:558] Eltwise20 <- Convolution43
I0818 10:58:39.010332  3083 net.cpp:522] Eltwise20 -> Eltwise20
I0818 10:58:39.010380  3083 net.cpp:172] Setting up Eltwise20
I0818 10:58:39.010401  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.010414  3083 net.cpp:194] Memory required for data: 678166784
I0818 10:58:39.010428  3083 layer_factory.hpp:77] Creating layer ReLU41
I0818 10:58:39.010448  3083 net.cpp:128] Creating Layer ReLU41
I0818 10:58:39.010462  3083 net.cpp:558] ReLU41 <- Eltwise20
I0818 10:58:39.010480  3083 net.cpp:509] ReLU41 -> Eltwise20 (in-place)
I0818 10:58:39.013325  3083 net.cpp:172] Setting up ReLU41
I0818 10:58:39.013346  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.013350  3083 net.cpp:194] Memory required for data: 679215360
I0818 10:58:39.013355  3083 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0818 10:58:39.013363  3083 net.cpp:128] Creating Layer Eltwise20_ReLU41_0_split
I0818 10:58:39.013370  3083 net.cpp:558] Eltwise20_ReLU41_0_split <- Eltwise20
I0818 10:58:39.013378  3083 net.cpp:522] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0818 10:58:39.013387  3083 net.cpp:522] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0818 10:58:39.013449  3083 net.cpp:172] Setting up Eltwise20_ReLU41_0_split
I0818 10:58:39.013489  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.013504  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.013519  3083 net.cpp:194] Memory required for data: 681312512
I0818 10:58:39.013532  3083 layer_factory.hpp:77] Creating layer Convolution44
I0818 10:58:39.013556  3083 net.cpp:128] Creating Layer Convolution44
I0818 10:58:39.013571  3083 net.cpp:558] Convolution44 <- Eltwise20_ReLU41_0_split_0
I0818 10:58:39.013590  3083 net.cpp:522] Convolution44 -> Convolution44
I0818 10:58:39.022948  3083 net.cpp:172] Setting up Convolution44
I0818 10:58:39.022971  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.022975  3083 net.cpp:194] Memory required for data: 682361088
I0818 10:58:39.022989  3083 layer_factory.hpp:77] Creating layer BatchNorm44
I0818 10:58:39.023000  3083 net.cpp:128] Creating Layer BatchNorm44
I0818 10:58:39.023005  3083 net.cpp:558] BatchNorm44 <- Convolution44
I0818 10:58:39.023012  3083 net.cpp:509] BatchNorm44 -> Convolution44 (in-place)
I0818 10:58:39.023304  3083 net.cpp:172] Setting up BatchNorm44
I0818 10:58:39.023344  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.023361  3083 net.cpp:194] Memory required for data: 683409664
I0818 10:58:39.023383  3083 layer_factory.hpp:77] Creating layer Scale44
I0818 10:58:39.023409  3083 net.cpp:128] Creating Layer Scale44
I0818 10:58:39.023423  3083 net.cpp:558] Scale44 <- Convolution44
I0818 10:58:39.023445  3083 net.cpp:509] Scale44 -> Convolution44 (in-place)
I0818 10:58:39.023524  3083 layer_factory.hpp:77] Creating layer Scale44
I0818 10:58:39.023711  3083 net.cpp:172] Setting up Scale44
I0818 10:58:39.023731  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.023744  3083 net.cpp:194] Memory required for data: 684458240
I0818 10:58:39.023763  3083 layer_factory.hpp:77] Creating layer ReLU42
I0818 10:58:39.023779  3083 net.cpp:128] Creating Layer ReLU42
I0818 10:58:39.023793  3083 net.cpp:558] ReLU42 <- Convolution44
I0818 10:58:39.023818  3083 net.cpp:509] ReLU42 -> Convolution44 (in-place)
I0818 10:58:39.025017  3083 net.cpp:172] Setting up ReLU42
I0818 10:58:39.025038  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.025041  3083 net.cpp:194] Memory required for data: 685506816
I0818 10:58:39.025046  3083 layer_factory.hpp:77] Creating layer Convolution45
I0818 10:58:39.025060  3083 net.cpp:128] Creating Layer Convolution45
I0818 10:58:39.025065  3083 net.cpp:558] Convolution45 <- Convolution44
I0818 10:58:39.025075  3083 net.cpp:522] Convolution45 -> Convolution45
I0818 10:58:39.032135  3083 net.cpp:172] Setting up Convolution45
I0818 10:58:39.032158  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.032163  3083 net.cpp:194] Memory required for data: 686555392
I0818 10:58:39.032174  3083 layer_factory.hpp:77] Creating layer BatchNorm45
I0818 10:58:39.032186  3083 net.cpp:128] Creating Layer BatchNorm45
I0818 10:58:39.032192  3083 net.cpp:558] BatchNorm45 <- Convolution45
I0818 10:58:39.032200  3083 net.cpp:509] BatchNorm45 -> Convolution45 (in-place)
I0818 10:58:39.032505  3083 net.cpp:172] Setting up BatchNorm45
I0818 10:58:39.032516  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.032519  3083 net.cpp:194] Memory required for data: 687603968
I0818 10:58:39.032558  3083 layer_factory.hpp:77] Creating layer Scale45
I0818 10:58:39.032580  3083 net.cpp:128] Creating Layer Scale45
I0818 10:58:39.032594  3083 net.cpp:558] Scale45 <- Convolution45
I0818 10:58:39.032615  3083 net.cpp:509] Scale45 -> Convolution45 (in-place)
I0818 10:58:39.032688  3083 layer_factory.hpp:77] Creating layer Scale45
I0818 10:58:39.032861  3083 net.cpp:172] Setting up Scale45
I0818 10:58:39.032874  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.032899  3083 net.cpp:194] Memory required for data: 688652544
I0818 10:58:39.032912  3083 layer_factory.hpp:77] Creating layer Eltwise21
I0818 10:58:39.032919  3083 net.cpp:128] Creating Layer Eltwise21
I0818 10:58:39.032924  3083 net.cpp:558] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0818 10:58:39.032930  3083 net.cpp:558] Eltwise21 <- Convolution45
I0818 10:58:39.032936  3083 net.cpp:522] Eltwise21 -> Eltwise21
I0818 10:58:39.032990  3083 net.cpp:172] Setting up Eltwise21
I0818 10:58:39.033001  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.033005  3083 net.cpp:194] Memory required for data: 689701120
I0818 10:58:39.033010  3083 layer_factory.hpp:77] Creating layer ReLU43
I0818 10:58:39.033036  3083 net.cpp:128] Creating Layer ReLU43
I0818 10:58:39.033054  3083 net.cpp:558] ReLU43 <- Eltwise21
I0818 10:58:39.033063  3083 net.cpp:509] ReLU43 -> Eltwise21 (in-place)
I0818 10:58:39.033951  3083 net.cpp:172] Setting up ReLU43
I0818 10:58:39.033972  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.033977  3083 net.cpp:194] Memory required for data: 690749696
I0818 10:58:39.033982  3083 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0818 10:58:39.033993  3083 net.cpp:128] Creating Layer Eltwise21_ReLU43_0_split
I0818 10:58:39.034000  3083 net.cpp:558] Eltwise21_ReLU43_0_split <- Eltwise21
I0818 10:58:39.034008  3083 net.cpp:522] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0818 10:58:39.034021  3083 net.cpp:522] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0818 10:58:39.034082  3083 net.cpp:172] Setting up Eltwise21_ReLU43_0_split
I0818 10:58:39.034093  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.034098  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.034102  3083 net.cpp:194] Memory required for data: 692846848
I0818 10:58:39.034106  3083 layer_factory.hpp:77] Creating layer Convolution46
I0818 10:58:39.034119  3083 net.cpp:128] Creating Layer Convolution46
I0818 10:58:39.034127  3083 net.cpp:558] Convolution46 <- Eltwise21_ReLU43_0_split_0
I0818 10:58:39.034137  3083 net.cpp:522] Convolution46 -> Convolution46
I0818 10:58:39.044956  3083 net.cpp:172] Setting up Convolution46
I0818 10:58:39.044984  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.044989  3083 net.cpp:194] Memory required for data: 693895424
I0818 10:58:39.045017  3083 layer_factory.hpp:77] Creating layer BatchNorm46
I0818 10:58:39.045035  3083 net.cpp:128] Creating Layer BatchNorm46
I0818 10:58:39.045042  3083 net.cpp:558] BatchNorm46 <- Convolution46
I0818 10:58:39.045047  3083 net.cpp:509] BatchNorm46 -> Convolution46 (in-place)
I0818 10:58:39.045351  3083 net.cpp:172] Setting up BatchNorm46
I0818 10:58:39.045358  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.045362  3083 net.cpp:194] Memory required for data: 694944000
I0818 10:58:39.045372  3083 layer_factory.hpp:77] Creating layer Scale46
I0818 10:58:39.045379  3083 net.cpp:128] Creating Layer Scale46
I0818 10:58:39.045383  3083 net.cpp:558] Scale46 <- Convolution46
I0818 10:58:39.045392  3083 net.cpp:509] Scale46 -> Convolution46 (in-place)
I0818 10:58:39.045444  3083 layer_factory.hpp:77] Creating layer Scale46
I0818 10:58:39.045619  3083 net.cpp:172] Setting up Scale46
I0818 10:58:39.045627  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.045631  3083 net.cpp:194] Memory required for data: 695992576
I0818 10:58:39.045639  3083 layer_factory.hpp:77] Creating layer ReLU44
I0818 10:58:39.045645  3083 net.cpp:128] Creating Layer ReLU44
I0818 10:58:39.045650  3083 net.cpp:558] ReLU44 <- Convolution46
I0818 10:58:39.045657  3083 net.cpp:509] ReLU44 -> Convolution46 (in-place)
I0818 10:58:39.049126  3083 net.cpp:172] Setting up ReLU44
I0818 10:58:39.049142  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.049147  3083 net.cpp:194] Memory required for data: 697041152
I0818 10:58:39.049151  3083 layer_factory.hpp:77] Creating layer Convolution47
I0818 10:58:39.049165  3083 net.cpp:128] Creating Layer Convolution47
I0818 10:58:39.049170  3083 net.cpp:558] Convolution47 <- Convolution46
I0818 10:58:39.049180  3083 net.cpp:522] Convolution47 -> Convolution47
I0818 10:58:39.062593  3083 net.cpp:172] Setting up Convolution47
I0818 10:58:39.062619  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.062624  3083 net.cpp:194] Memory required for data: 698089728
I0818 10:58:39.062635  3083 layer_factory.hpp:77] Creating layer BatchNorm47
I0818 10:58:39.062646  3083 net.cpp:128] Creating Layer BatchNorm47
I0818 10:58:39.062659  3083 net.cpp:558] BatchNorm47 <- Convolution47
I0818 10:58:39.062666  3083 net.cpp:509] BatchNorm47 -> Convolution47 (in-place)
I0818 10:58:39.062973  3083 net.cpp:172] Setting up BatchNorm47
I0818 10:58:39.062985  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.062989  3083 net.cpp:194] Memory required for data: 699138304
I0818 10:58:39.063000  3083 layer_factory.hpp:77] Creating layer Scale47
I0818 10:58:39.063006  3083 net.cpp:128] Creating Layer Scale47
I0818 10:58:39.063011  3083 net.cpp:558] Scale47 <- Convolution47
I0818 10:58:39.063016  3083 net.cpp:509] Scale47 -> Convolution47 (in-place)
I0818 10:58:39.063071  3083 layer_factory.hpp:77] Creating layer Scale47
I0818 10:58:39.063242  3083 net.cpp:172] Setting up Scale47
I0818 10:58:39.063257  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.063261  3083 net.cpp:194] Memory required for data: 700186880
I0818 10:58:39.063271  3083 layer_factory.hpp:77] Creating layer Eltwise22
I0818 10:58:39.063279  3083 net.cpp:128] Creating Layer Eltwise22
I0818 10:58:39.063284  3083 net.cpp:558] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0818 10:58:39.063289  3083 net.cpp:558] Eltwise22 <- Convolution47
I0818 10:58:39.063297  3083 net.cpp:522] Eltwise22 -> Eltwise22
I0818 10:58:39.063326  3083 net.cpp:172] Setting up Eltwise22
I0818 10:58:39.063336  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.063340  3083 net.cpp:194] Memory required for data: 701235456
I0818 10:58:39.063344  3083 layer_factory.hpp:77] Creating layer ReLU45
I0818 10:58:39.063351  3083 net.cpp:128] Creating Layer ReLU45
I0818 10:58:39.063355  3083 net.cpp:558] ReLU45 <- Eltwise22
I0818 10:58:39.063361  3083 net.cpp:509] ReLU45 -> Eltwise22 (in-place)
I0818 10:58:39.066329  3083 net.cpp:172] Setting up ReLU45
I0818 10:58:39.066349  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.066370  3083 net.cpp:194] Memory required for data: 702284032
I0818 10:58:39.066375  3083 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0818 10:58:39.066383  3083 net.cpp:128] Creating Layer Eltwise22_ReLU45_0_split
I0818 10:58:39.066388  3083 net.cpp:558] Eltwise22_ReLU45_0_split <- Eltwise22
I0818 10:58:39.066399  3083 net.cpp:522] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0818 10:58:39.066408  3083 net.cpp:522] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0818 10:58:39.066468  3083 net.cpp:172] Setting up Eltwise22_ReLU45_0_split
I0818 10:58:39.066480  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.066486  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.066489  3083 net.cpp:194] Memory required for data: 704381184
I0818 10:58:39.066494  3083 layer_factory.hpp:77] Creating layer Convolution48
I0818 10:58:39.066509  3083 net.cpp:128] Creating Layer Convolution48
I0818 10:58:39.066514  3083 net.cpp:558] Convolution48 <- Eltwise22_ReLU45_0_split_0
I0818 10:58:39.066520  3083 net.cpp:522] Convolution48 -> Convolution48
I0818 10:58:39.073221  3083 net.cpp:172] Setting up Convolution48
I0818 10:58:39.073247  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.073251  3083 net.cpp:194] Memory required for data: 705429760
I0818 10:58:39.073261  3083 layer_factory.hpp:77] Creating layer BatchNorm48
I0818 10:58:39.073273  3083 net.cpp:128] Creating Layer BatchNorm48
I0818 10:58:39.073278  3083 net.cpp:558] BatchNorm48 <- Convolution48
I0818 10:58:39.073287  3083 net.cpp:509] BatchNorm48 -> Convolution48 (in-place)
I0818 10:58:39.073585  3083 net.cpp:172] Setting up BatchNorm48
I0818 10:58:39.073597  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.073601  3083 net.cpp:194] Memory required for data: 706478336
I0818 10:58:39.073611  3083 layer_factory.hpp:77] Creating layer Scale48
I0818 10:58:39.073618  3083 net.cpp:128] Creating Layer Scale48
I0818 10:58:39.073622  3083 net.cpp:558] Scale48 <- Convolution48
I0818 10:58:39.073628  3083 net.cpp:509] Scale48 -> Convolution48 (in-place)
I0818 10:58:39.073679  3083 layer_factory.hpp:77] Creating layer Scale48
I0818 10:58:39.073853  3083 net.cpp:172] Setting up Scale48
I0818 10:58:39.073863  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.073866  3083 net.cpp:194] Memory required for data: 707526912
I0818 10:58:39.073874  3083 layer_factory.hpp:77] Creating layer ReLU46
I0818 10:58:39.073882  3083 net.cpp:128] Creating Layer ReLU46
I0818 10:58:39.073886  3083 net.cpp:558] ReLU46 <- Convolution48
I0818 10:58:39.073892  3083 net.cpp:509] ReLU46 -> Convolution48 (in-place)
I0818 10:58:39.075284  3083 net.cpp:172] Setting up ReLU46
I0818 10:58:39.075309  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.075314  3083 net.cpp:194] Memory required for data: 708575488
I0818 10:58:39.075318  3083 layer_factory.hpp:77] Creating layer Convolution49
I0818 10:58:39.075335  3083 net.cpp:128] Creating Layer Convolution49
I0818 10:58:39.075345  3083 net.cpp:558] Convolution49 <- Convolution48
I0818 10:58:39.075356  3083 net.cpp:522] Convolution49 -> Convolution49
I0818 10:58:39.082466  3083 net.cpp:172] Setting up Convolution49
I0818 10:58:39.082494  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.082499  3083 net.cpp:194] Memory required for data: 709624064
I0818 10:58:39.082509  3083 layer_factory.hpp:77] Creating layer BatchNorm49
I0818 10:58:39.082520  3083 net.cpp:128] Creating Layer BatchNorm49
I0818 10:58:39.082526  3083 net.cpp:558] BatchNorm49 <- Convolution49
I0818 10:58:39.082535  3083 net.cpp:509] BatchNorm49 -> Convolution49 (in-place)
I0818 10:58:39.082860  3083 net.cpp:172] Setting up BatchNorm49
I0818 10:58:39.082870  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.082875  3083 net.cpp:194] Memory required for data: 710672640
I0818 10:58:39.082885  3083 layer_factory.hpp:77] Creating layer Scale49
I0818 10:58:39.082897  3083 net.cpp:128] Creating Layer Scale49
I0818 10:58:39.082919  3083 net.cpp:558] Scale49 <- Convolution49
I0818 10:58:39.082926  3083 net.cpp:509] Scale49 -> Convolution49 (in-place)
I0818 10:58:39.082984  3083 layer_factory.hpp:77] Creating layer Scale49
I0818 10:58:39.083163  3083 net.cpp:172] Setting up Scale49
I0818 10:58:39.083173  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.083178  3083 net.cpp:194] Memory required for data: 711721216
I0818 10:58:39.083189  3083 layer_factory.hpp:77] Creating layer Eltwise23
I0818 10:58:39.083199  3083 net.cpp:128] Creating Layer Eltwise23
I0818 10:58:39.083207  3083 net.cpp:558] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0818 10:58:39.083212  3083 net.cpp:558] Eltwise23 <- Convolution49
I0818 10:58:39.083223  3083 net.cpp:522] Eltwise23 -> Eltwise23
I0818 10:58:39.083256  3083 net.cpp:172] Setting up Eltwise23
I0818 10:58:39.083266  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.083273  3083 net.cpp:194] Memory required for data: 712769792
I0818 10:58:39.083277  3083 layer_factory.hpp:77] Creating layer ReLU47
I0818 10:58:39.083287  3083 net.cpp:128] Creating Layer ReLU47
I0818 10:58:39.083293  3083 net.cpp:558] ReLU47 <- Eltwise23
I0818 10:58:39.083298  3083 net.cpp:509] ReLU47 -> Eltwise23 (in-place)
I0818 10:58:39.084234  3083 net.cpp:172] Setting up ReLU47
I0818 10:58:39.084249  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.084252  3083 net.cpp:194] Memory required for data: 713818368
I0818 10:58:39.084257  3083 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0818 10:58:39.084269  3083 net.cpp:128] Creating Layer Eltwise23_ReLU47_0_split
I0818 10:58:39.084275  3083 net.cpp:558] Eltwise23_ReLU47_0_split <- Eltwise23
I0818 10:58:39.084286  3083 net.cpp:522] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0818 10:58:39.084297  3083 net.cpp:522] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0818 10:58:39.084362  3083 net.cpp:172] Setting up Eltwise23_ReLU47_0_split
I0818 10:58:39.084373  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.084379  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.084385  3083 net.cpp:194] Memory required for data: 715915520
I0818 10:58:39.084390  3083 layer_factory.hpp:77] Creating layer Convolution50
I0818 10:58:39.084403  3083 net.cpp:128] Creating Layer Convolution50
I0818 10:58:39.084411  3083 net.cpp:558] Convolution50 <- Eltwise23_ReLU47_0_split_0
I0818 10:58:39.084420  3083 net.cpp:522] Convolution50 -> Convolution50
I0818 10:58:39.097391  3083 net.cpp:172] Setting up Convolution50
I0818 10:58:39.097424  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.097429  3083 net.cpp:194] Memory required for data: 716964096
I0818 10:58:39.097440  3083 layer_factory.hpp:77] Creating layer BatchNorm50
I0818 10:58:39.097448  3083 net.cpp:128] Creating Layer BatchNorm50
I0818 10:58:39.097457  3083 net.cpp:558] BatchNorm50 <- Convolution50
I0818 10:58:39.097465  3083 net.cpp:509] BatchNorm50 -> Convolution50 (in-place)
I0818 10:58:39.097769  3083 net.cpp:172] Setting up BatchNorm50
I0818 10:58:39.097779  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.097782  3083 net.cpp:194] Memory required for data: 718012672
I0818 10:58:39.097795  3083 layer_factory.hpp:77] Creating layer Scale50
I0818 10:58:39.097803  3083 net.cpp:128] Creating Layer Scale50
I0818 10:58:39.097808  3083 net.cpp:558] Scale50 <- Convolution50
I0818 10:58:39.097817  3083 net.cpp:509] Scale50 -> Convolution50 (in-place)
I0818 10:58:39.097868  3083 layer_factory.hpp:77] Creating layer Scale50
I0818 10:58:39.098037  3083 net.cpp:172] Setting up Scale50
I0818 10:58:39.098048  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.098052  3083 net.cpp:194] Memory required for data: 719061248
I0818 10:58:39.098060  3083 layer_factory.hpp:77] Creating layer ReLU48
I0818 10:58:39.098073  3083 net.cpp:128] Creating Layer ReLU48
I0818 10:58:39.098080  3083 net.cpp:558] ReLU48 <- Convolution50
I0818 10:58:39.098086  3083 net.cpp:509] ReLU48 -> Convolution50 (in-place)
I0818 10:58:39.101546  3083 net.cpp:172] Setting up ReLU48
I0818 10:58:39.101580  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.101585  3083 net.cpp:194] Memory required for data: 720109824
I0818 10:58:39.101590  3083 layer_factory.hpp:77] Creating layer Convolution51
I0818 10:58:39.101606  3083 net.cpp:128] Creating Layer Convolution51
I0818 10:58:39.101615  3083 net.cpp:558] Convolution51 <- Convolution50
I0818 10:58:39.101624  3083 net.cpp:522] Convolution51 -> Convolution51
I0818 10:58:39.115036  3083 net.cpp:172] Setting up Convolution51
I0818 10:58:39.115059  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.115067  3083 net.cpp:194] Memory required for data: 721158400
I0818 10:58:39.115077  3083 layer_factory.hpp:77] Creating layer BatchNorm51
I0818 10:58:39.115085  3083 net.cpp:128] Creating Layer BatchNorm51
I0818 10:58:39.115090  3083 net.cpp:558] BatchNorm51 <- Convolution51
I0818 10:58:39.115099  3083 net.cpp:509] BatchNorm51 -> Convolution51 (in-place)
I0818 10:58:39.115414  3083 net.cpp:172] Setting up BatchNorm51
I0818 10:58:39.115427  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.115432  3083 net.cpp:194] Memory required for data: 722206976
I0818 10:58:39.115442  3083 layer_factory.hpp:77] Creating layer Scale51
I0818 10:58:39.115448  3083 net.cpp:128] Creating Layer Scale51
I0818 10:58:39.115453  3083 net.cpp:558] Scale51 <- Convolution51
I0818 10:58:39.115460  3083 net.cpp:509] Scale51 -> Convolution51 (in-place)
I0818 10:58:39.115510  3083 layer_factory.hpp:77] Creating layer Scale51
I0818 10:58:39.115682  3083 net.cpp:172] Setting up Scale51
I0818 10:58:39.115694  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.115698  3083 net.cpp:194] Memory required for data: 723255552
I0818 10:58:39.115705  3083 layer_factory.hpp:77] Creating layer Eltwise24
I0818 10:58:39.115715  3083 net.cpp:128] Creating Layer Eltwise24
I0818 10:58:39.115720  3083 net.cpp:558] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0818 10:58:39.115725  3083 net.cpp:558] Eltwise24 <- Convolution51
I0818 10:58:39.115731  3083 net.cpp:522] Eltwise24 -> Eltwise24
I0818 10:58:39.115762  3083 net.cpp:172] Setting up Eltwise24
I0818 10:58:39.115769  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.115773  3083 net.cpp:194] Memory required for data: 724304128
I0818 10:58:39.115777  3083 layer_factory.hpp:77] Creating layer ReLU49
I0818 10:58:39.115783  3083 net.cpp:128] Creating Layer ReLU49
I0818 10:58:39.115788  3083 net.cpp:558] ReLU49 <- Eltwise24
I0818 10:58:39.115797  3083 net.cpp:509] ReLU49 -> Eltwise24 (in-place)
I0818 10:58:39.117040  3083 net.cpp:172] Setting up ReLU49
I0818 10:58:39.117055  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.117060  3083 net.cpp:194] Memory required for data: 725352704
I0818 10:58:39.117065  3083 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0818 10:58:39.117072  3083 net.cpp:128] Creating Layer Eltwise24_ReLU49_0_split
I0818 10:58:39.117077  3083 net.cpp:558] Eltwise24_ReLU49_0_split <- Eltwise24
I0818 10:58:39.117086  3083 net.cpp:522] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0818 10:58:39.117094  3083 net.cpp:522] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0818 10:58:39.117154  3083 net.cpp:172] Setting up Eltwise24_ReLU49_0_split
I0818 10:58:39.117166  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.117172  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.117177  3083 net.cpp:194] Memory required for data: 727449856
I0818 10:58:39.117180  3083 layer_factory.hpp:77] Creating layer Convolution52
I0818 10:58:39.117192  3083 net.cpp:128] Creating Layer Convolution52
I0818 10:58:39.117197  3083 net.cpp:558] Convolution52 <- Eltwise24_ReLU49_0_split_0
I0818 10:58:39.117208  3083 net.cpp:522] Convolution52 -> Convolution52
I0818 10:58:39.123916  3083 net.cpp:172] Setting up Convolution52
I0818 10:58:39.123941  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.123946  3083 net.cpp:194] Memory required for data: 728498432
I0818 10:58:39.123957  3083 layer_factory.hpp:77] Creating layer BatchNorm52
I0818 10:58:39.123986  3083 net.cpp:128] Creating Layer BatchNorm52
I0818 10:58:39.123992  3083 net.cpp:558] BatchNorm52 <- Convolution52
I0818 10:58:39.123998  3083 net.cpp:509] BatchNorm52 -> Convolution52 (in-place)
I0818 10:58:39.124305  3083 net.cpp:172] Setting up BatchNorm52
I0818 10:58:39.124315  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.124318  3083 net.cpp:194] Memory required for data: 729547008
I0818 10:58:39.124330  3083 layer_factory.hpp:77] Creating layer Scale52
I0818 10:58:39.124339  3083 net.cpp:128] Creating Layer Scale52
I0818 10:58:39.124343  3083 net.cpp:558] Scale52 <- Convolution52
I0818 10:58:39.124349  3083 net.cpp:509] Scale52 -> Convolution52 (in-place)
I0818 10:58:39.124404  3083 layer_factory.hpp:77] Creating layer Scale52
I0818 10:58:39.124572  3083 net.cpp:172] Setting up Scale52
I0818 10:58:39.124585  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.124589  3083 net.cpp:194] Memory required for data: 730595584
I0818 10:58:39.124598  3083 layer_factory.hpp:77] Creating layer ReLU50
I0818 10:58:39.124608  3083 net.cpp:128] Creating Layer ReLU50
I0818 10:58:39.124611  3083 net.cpp:558] ReLU50 <- Convolution52
I0818 10:58:39.124616  3083 net.cpp:509] ReLU50 -> Convolution52 (in-place)
I0818 10:58:39.125972  3083 net.cpp:172] Setting up ReLU50
I0818 10:58:39.125998  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.126003  3083 net.cpp:194] Memory required for data: 731644160
I0818 10:58:39.126008  3083 layer_factory.hpp:77] Creating layer Convolution53
I0818 10:58:39.126037  3083 net.cpp:128] Creating Layer Convolution53
I0818 10:58:39.126045  3083 net.cpp:558] Convolution53 <- Convolution52
I0818 10:58:39.126054  3083 net.cpp:522] Convolution53 -> Convolution53
I0818 10:58:39.133193  3083 net.cpp:172] Setting up Convolution53
I0818 10:58:39.133224  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.133229  3083 net.cpp:194] Memory required for data: 732692736
I0818 10:58:39.133240  3083 layer_factory.hpp:77] Creating layer BatchNorm53
I0818 10:58:39.133251  3083 net.cpp:128] Creating Layer BatchNorm53
I0818 10:58:39.133258  3083 net.cpp:558] BatchNorm53 <- Convolution53
I0818 10:58:39.133270  3083 net.cpp:509] BatchNorm53 -> Convolution53 (in-place)
I0818 10:58:39.133589  3083 net.cpp:172] Setting up BatchNorm53
I0818 10:58:39.133599  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.133604  3083 net.cpp:194] Memory required for data: 733741312
I0818 10:58:39.133613  3083 layer_factory.hpp:77] Creating layer Scale53
I0818 10:58:39.133623  3083 net.cpp:128] Creating Layer Scale53
I0818 10:58:39.133628  3083 net.cpp:558] Scale53 <- Convolution53
I0818 10:58:39.133636  3083 net.cpp:509] Scale53 -> Convolution53 (in-place)
I0818 10:58:39.133692  3083 layer_factory.hpp:77] Creating layer Scale53
I0818 10:58:39.133872  3083 net.cpp:172] Setting up Scale53
I0818 10:58:39.133882  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.133885  3083 net.cpp:194] Memory required for data: 734789888
I0818 10:58:39.133896  3083 layer_factory.hpp:77] Creating layer Eltwise25
I0818 10:58:39.133906  3083 net.cpp:128] Creating Layer Eltwise25
I0818 10:58:39.133914  3083 net.cpp:558] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0818 10:58:39.133919  3083 net.cpp:558] Eltwise25 <- Convolution53
I0818 10:58:39.133930  3083 net.cpp:522] Eltwise25 -> Eltwise25
I0818 10:58:39.133965  3083 net.cpp:172] Setting up Eltwise25
I0818 10:58:39.133973  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.133980  3083 net.cpp:194] Memory required for data: 735838464
I0818 10:58:39.133985  3083 layer_factory.hpp:77] Creating layer ReLU51
I0818 10:58:39.133991  3083 net.cpp:128] Creating Layer ReLU51
I0818 10:58:39.133999  3083 net.cpp:558] ReLU51 <- Eltwise25
I0818 10:58:39.134006  3083 net.cpp:509] ReLU51 -> Eltwise25 (in-place)
I0818 10:58:39.134986  3083 net.cpp:172] Setting up ReLU51
I0818 10:58:39.135006  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.135011  3083 net.cpp:194] Memory required for data: 736887040
I0818 10:58:39.135036  3083 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0818 10:58:39.135044  3083 net.cpp:128] Creating Layer Eltwise25_ReLU51_0_split
I0818 10:58:39.135052  3083 net.cpp:558] Eltwise25_ReLU51_0_split <- Eltwise25
I0818 10:58:39.135059  3083 net.cpp:522] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0818 10:58:39.135071  3083 net.cpp:522] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0818 10:58:39.135133  3083 net.cpp:172] Setting up Eltwise25_ReLU51_0_split
I0818 10:58:39.135144  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.135150  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.135154  3083 net.cpp:194] Memory required for data: 738984192
I0818 10:58:39.135160  3083 layer_factory.hpp:77] Creating layer Convolution54
I0818 10:58:39.135171  3083 net.cpp:128] Creating Layer Convolution54
I0818 10:58:39.135179  3083 net.cpp:558] Convolution54 <- Eltwise25_ReLU51_0_split_0
I0818 10:58:39.135185  3083 net.cpp:522] Convolution54 -> Convolution54
I0818 10:58:39.148197  3083 net.cpp:172] Setting up Convolution54
I0818 10:58:39.148232  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.148238  3083 net.cpp:194] Memory required for data: 740032768
I0818 10:58:39.148252  3083 layer_factory.hpp:77] Creating layer BatchNorm54
I0818 10:58:39.148263  3083 net.cpp:128] Creating Layer BatchNorm54
I0818 10:58:39.148273  3083 net.cpp:558] BatchNorm54 <- Convolution54
I0818 10:58:39.148283  3083 net.cpp:509] BatchNorm54 -> Convolution54 (in-place)
I0818 10:58:39.148591  3083 net.cpp:172] Setting up BatchNorm54
I0818 10:58:39.148602  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.148607  3083 net.cpp:194] Memory required for data: 741081344
I0818 10:58:39.148617  3083 layer_factory.hpp:77] Creating layer Scale54
I0818 10:58:39.148628  3083 net.cpp:128] Creating Layer Scale54
I0818 10:58:39.148633  3083 net.cpp:558] Scale54 <- Convolution54
I0818 10:58:39.148640  3083 net.cpp:509] Scale54 -> Convolution54 (in-place)
I0818 10:58:39.148695  3083 layer_factory.hpp:77] Creating layer Scale54
I0818 10:58:39.148872  3083 net.cpp:172] Setting up Scale54
I0818 10:58:39.148882  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.148886  3083 net.cpp:194] Memory required for data: 742129920
I0818 10:58:39.148895  3083 layer_factory.hpp:77] Creating layer ReLU52
I0818 10:58:39.148906  3083 net.cpp:128] Creating Layer ReLU52
I0818 10:58:39.148911  3083 net.cpp:558] ReLU52 <- Convolution54
I0818 10:58:39.148916  3083 net.cpp:509] ReLU52 -> Convolution54 (in-place)
I0818 10:58:39.152338  3083 net.cpp:172] Setting up ReLU52
I0818 10:58:39.152359  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.152362  3083 net.cpp:194] Memory required for data: 743178496
I0818 10:58:39.152367  3083 layer_factory.hpp:77] Creating layer Convolution55
I0818 10:58:39.152387  3083 net.cpp:128] Creating Layer Convolution55
I0818 10:58:39.152392  3083 net.cpp:558] Convolution55 <- Convolution54
I0818 10:58:39.152400  3083 net.cpp:522] Convolution55 -> Convolution55
I0818 10:58:39.169049  3083 net.cpp:172] Setting up Convolution55
I0818 10:58:39.169075  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.169080  3083 net.cpp:194] Memory required for data: 744227072
I0818 10:58:39.169090  3083 layer_factory.hpp:77] Creating layer BatchNorm55
I0818 10:58:39.169137  3083 net.cpp:128] Creating Layer BatchNorm55
I0818 10:58:39.169152  3083 net.cpp:558] BatchNorm55 <- Convolution55
I0818 10:58:39.169174  3083 net.cpp:509] BatchNorm55 -> Convolution55 (in-place)
I0818 10:58:39.169510  3083 net.cpp:172] Setting up BatchNorm55
I0818 10:58:39.169523  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.169526  3083 net.cpp:194] Memory required for data: 745275648
I0818 10:58:39.169538  3083 layer_factory.hpp:77] Creating layer Scale55
I0818 10:58:39.169564  3083 net.cpp:128] Creating Layer Scale55
I0818 10:58:39.169577  3083 net.cpp:558] Scale55 <- Convolution55
I0818 10:58:39.169597  3083 net.cpp:509] Scale55 -> Convolution55 (in-place)
I0818 10:58:39.169677  3083 layer_factory.hpp:77] Creating layer Scale55
I0818 10:58:39.169873  3083 net.cpp:172] Setting up Scale55
I0818 10:58:39.169884  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.169888  3083 net.cpp:194] Memory required for data: 746324224
I0818 10:58:39.169898  3083 layer_factory.hpp:77] Creating layer Eltwise26
I0818 10:58:39.169924  3083 net.cpp:128] Creating Layer Eltwise26
I0818 10:58:39.169939  3083 net.cpp:558] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0818 10:58:39.169957  3083 net.cpp:558] Eltwise26 <- Convolution55
I0818 10:58:39.169973  3083 net.cpp:522] Eltwise26 -> Eltwise26
I0818 10:58:39.170027  3083 net.cpp:172] Setting up Eltwise26
I0818 10:58:39.170045  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.170058  3083 net.cpp:194] Memory required for data: 747372800
I0818 10:58:39.170075  3083 layer_factory.hpp:77] Creating layer ReLU53
I0818 10:58:39.170094  3083 net.cpp:128] Creating Layer ReLU53
I0818 10:58:39.170109  3083 net.cpp:558] ReLU53 <- Eltwise26
I0818 10:58:39.170126  3083 net.cpp:509] ReLU53 -> Eltwise26 (in-place)
I0818 10:58:39.170714  3083 net.cpp:172] Setting up ReLU53
I0818 10:58:39.170735  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.170740  3083 net.cpp:194] Memory required for data: 748421376
I0818 10:58:39.170745  3083 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0818 10:58:39.170754  3083 net.cpp:128] Creating Layer Eltwise26_ReLU53_0_split
I0818 10:58:39.170763  3083 net.cpp:558] Eltwise26_ReLU53_0_split <- Eltwise26
I0818 10:58:39.170773  3083 net.cpp:522] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0818 10:58:39.170783  3083 net.cpp:522] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0818 10:58:39.170848  3083 net.cpp:172] Setting up Eltwise26_ReLU53_0_split
I0818 10:58:39.170859  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.170864  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.170868  3083 net.cpp:194] Memory required for data: 750518528
I0818 10:58:39.170872  3083 layer_factory.hpp:77] Creating layer Convolution56
I0818 10:58:39.170886  3083 net.cpp:128] Creating Layer Convolution56
I0818 10:58:39.170893  3083 net.cpp:558] Convolution56 <- Eltwise26_ReLU53_0_split_0
I0818 10:58:39.170903  3083 net.cpp:522] Convolution56 -> Convolution56
I0818 10:58:39.176893  3083 net.cpp:172] Setting up Convolution56
I0818 10:58:39.176923  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.176928  3083 net.cpp:194] Memory required for data: 751567104
I0818 10:58:39.176940  3083 layer_factory.hpp:77] Creating layer BatchNorm56
I0818 10:58:39.176952  3083 net.cpp:128] Creating Layer BatchNorm56
I0818 10:58:39.176964  3083 net.cpp:558] BatchNorm56 <- Convolution56
I0818 10:58:39.176971  3083 net.cpp:509] BatchNorm56 -> Convolution56 (in-place)
I0818 10:58:39.177357  3083 net.cpp:172] Setting up BatchNorm56
I0818 10:58:39.177368  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.177373  3083 net.cpp:194] Memory required for data: 752615680
I0818 10:58:39.177386  3083 layer_factory.hpp:77] Creating layer Scale56
I0818 10:58:39.177400  3083 net.cpp:128] Creating Layer Scale56
I0818 10:58:39.177407  3083 net.cpp:558] Scale56 <- Convolution56
I0818 10:58:39.177413  3083 net.cpp:509] Scale56 -> Convolution56 (in-place)
I0818 10:58:39.177479  3083 layer_factory.hpp:77] Creating layer Scale56
I0818 10:58:39.177695  3083 net.cpp:172] Setting up Scale56
I0818 10:58:39.177706  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.177711  3083 net.cpp:194] Memory required for data: 753664256
I0818 10:58:39.177721  3083 layer_factory.hpp:77] Creating layer ReLU54
I0818 10:58:39.177733  3083 net.cpp:128] Creating Layer ReLU54
I0818 10:58:39.177739  3083 net.cpp:558] ReLU54 <- Convolution56
I0818 10:58:39.177749  3083 net.cpp:509] ReLU54 -> Convolution56 (in-place)
I0818 10:58:39.178948  3083 net.cpp:172] Setting up ReLU54
I0818 10:58:39.178966  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.179014  3083 net.cpp:194] Memory required for data: 754712832
I0818 10:58:39.179036  3083 layer_factory.hpp:77] Creating layer Convolution57
I0818 10:58:39.179069  3083 net.cpp:128] Creating Layer Convolution57
I0818 10:58:39.179091  3083 net.cpp:558] Convolution57 <- Convolution56
I0818 10:58:39.179114  3083 net.cpp:522] Convolution57 -> Convolution57
I0818 10:58:39.185062  3083 net.cpp:172] Setting up Convolution57
I0818 10:58:39.185089  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.185096  3083 net.cpp:194] Memory required for data: 755761408
I0818 10:58:39.185108  3083 layer_factory.hpp:77] Creating layer BatchNorm57
I0818 10:58:39.185156  3083 net.cpp:128] Creating Layer BatchNorm57
I0818 10:58:39.185171  3083 net.cpp:558] BatchNorm57 <- Convolution57
I0818 10:58:39.185192  3083 net.cpp:509] BatchNorm57 -> Convolution57 (in-place)
I0818 10:58:39.185528  3083 net.cpp:172] Setting up BatchNorm57
I0818 10:58:39.185539  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.185544  3083 net.cpp:194] Memory required for data: 756809984
I0818 10:58:39.185554  3083 layer_factory.hpp:77] Creating layer Scale57
I0818 10:58:39.185580  3083 net.cpp:128] Creating Layer Scale57
I0818 10:58:39.185595  3083 net.cpp:558] Scale57 <- Convolution57
I0818 10:58:39.185613  3083 net.cpp:509] Scale57 -> Convolution57 (in-place)
I0818 10:58:39.185683  3083 layer_factory.hpp:77] Creating layer Scale57
I0818 10:58:39.185875  3083 net.cpp:172] Setting up Scale57
I0818 10:58:39.185886  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.185890  3083 net.cpp:194] Memory required for data: 757858560
I0818 10:58:39.185899  3083 layer_factory.hpp:77] Creating layer Eltwise27
I0818 10:58:39.185925  3083 net.cpp:128] Creating Layer Eltwise27
I0818 10:58:39.185940  3083 net.cpp:558] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0818 10:58:39.185958  3083 net.cpp:558] Eltwise27 <- Convolution57
I0818 10:58:39.185977  3083 net.cpp:522] Eltwise27 -> Eltwise27
I0818 10:58:39.186026  3083 net.cpp:172] Setting up Eltwise27
I0818 10:58:39.186044  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.186058  3083 net.cpp:194] Memory required for data: 758907136
I0818 10:58:39.186074  3083 layer_factory.hpp:77] Creating layer ReLU55
I0818 10:58:39.186094  3083 net.cpp:128] Creating Layer ReLU55
I0818 10:58:39.186110  3083 net.cpp:558] ReLU55 <- Eltwise27
I0818 10:58:39.186125  3083 net.cpp:509] ReLU55 -> Eltwise27 (in-place)
I0818 10:58:39.186388  3083 net.cpp:172] Setting up ReLU55
I0818 10:58:39.186403  3083 net.cpp:186] Top shape: 64 64 8 8 (262144)
I0818 10:58:39.186406  3083 net.cpp:194] Memory required for data: 759955712
I0818 10:58:39.186411  3083 layer_factory.hpp:77] Creating layer Pooling1
I0818 10:58:39.186422  3083 net.cpp:128] Creating Layer Pooling1
I0818 10:58:39.186448  3083 net.cpp:558] Pooling1 <- Eltwise27
I0818 10:58:39.186466  3083 net.cpp:522] Pooling1 -> Pooling1
I0818 10:58:39.187127  3083 net.cpp:172] Setting up Pooling1
I0818 10:58:39.187155  3083 net.cpp:186] Top shape: 64 64 1 1 (4096)
I0818 10:58:39.187160  3083 net.cpp:194] Memory required for data: 759972096
I0818 10:58:39.187163  3083 layer_factory.hpp:77] Creating layer InnerProduct1
I0818 10:58:39.187176  3083 net.cpp:128] Creating Layer InnerProduct1
I0818 10:58:39.187181  3083 net.cpp:558] InnerProduct1 <- Pooling1
I0818 10:58:39.187220  3083 net.cpp:522] InnerProduct1 -> InnerProduct1
I0818 10:58:39.187441  3083 net.cpp:172] Setting up InnerProduct1
I0818 10:58:39.187456  3083 net.cpp:186] Top shape: 64 10 (640)
I0818 10:58:39.187460  3083 net.cpp:194] Memory required for data: 759974656
I0818 10:58:39.187469  3083 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0818 10:58:39.187496  3083 net.cpp:128] Creating Layer SoftmaxWithLoss1
I0818 10:58:39.187510  3083 net.cpp:558] SoftmaxWithLoss1 <- InnerProduct1
I0818 10:58:39.187528  3083 net.cpp:558] SoftmaxWithLoss1 <- Data2
I0818 10:58:39.187546  3083 net.cpp:522] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0818 10:58:39.187572  3083 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0818 10:58:39.187995  3083 net.cpp:172] Setting up SoftmaxWithLoss1
I0818 10:58:39.188016  3083 net.cpp:186] Top shape: (1)
I0818 10:58:39.188020  3083 net.cpp:189]     with loss weight 1
I0818 10:58:39.188073  3083 net.cpp:194] Memory required for data: 759974660
I0818 10:58:39.188093  3083 net.cpp:301] SoftmaxWithLoss1 needs backward computation.
I0818 10:58:39.188113  3083 net.cpp:301] InnerProduct1 needs backward computation.
I0818 10:58:39.188127  3083 net.cpp:301] Pooling1 needs backward computation.
I0818 10:58:39.188144  3083 net.cpp:301] ReLU55 needs backward computation.
I0818 10:58:39.188158  3083 net.cpp:301] Eltwise27 needs backward computation.
I0818 10:58:39.188172  3083 net.cpp:301] Scale57 needs backward computation.
I0818 10:58:39.188187  3083 net.cpp:301] BatchNorm57 needs backward computation.
I0818 10:58:39.188201  3083 net.cpp:301] Convolution57 needs backward computation.
I0818 10:58:39.188216  3083 net.cpp:301] ReLU54 needs backward computation.
I0818 10:58:39.188230  3083 net.cpp:301] Scale56 needs backward computation.
I0818 10:58:39.188243  3083 net.cpp:301] BatchNorm56 needs backward computation.
I0818 10:58:39.188256  3083 net.cpp:301] Convolution56 needs backward computation.
I0818 10:58:39.188271  3083 net.cpp:301] Eltwise26_ReLU53_0_split needs backward computation.
I0818 10:58:39.188287  3083 net.cpp:301] ReLU53 needs backward computation.
I0818 10:58:39.188302  3083 net.cpp:301] Eltwise26 needs backward computation.
I0818 10:58:39.188318  3083 net.cpp:301] Scale55 needs backward computation.
I0818 10:58:39.188331  3083 net.cpp:301] BatchNorm55 needs backward computation.
I0818 10:58:39.188345  3083 net.cpp:301] Convolution55 needs backward computation.
I0818 10:58:39.188359  3083 net.cpp:301] ReLU52 needs backward computation.
I0818 10:58:39.188372  3083 net.cpp:301] Scale54 needs backward computation.
I0818 10:58:39.188385  3083 net.cpp:301] BatchNorm54 needs backward computation.
I0818 10:58:39.188400  3083 net.cpp:301] Convolution54 needs backward computation.
I0818 10:58:39.188414  3083 net.cpp:301] Eltwise25_ReLU51_0_split needs backward computation.
I0818 10:58:39.188432  3083 net.cpp:301] ReLU51 needs backward computation.
I0818 10:58:39.188446  3083 net.cpp:301] Eltwise25 needs backward computation.
I0818 10:58:39.188462  3083 net.cpp:301] Scale53 needs backward computation.
I0818 10:58:39.188475  3083 net.cpp:301] BatchNorm53 needs backward computation.
I0818 10:58:39.188489  3083 net.cpp:301] Convolution53 needs backward computation.
I0818 10:58:39.188503  3083 net.cpp:301] ReLU50 needs backward computation.
I0818 10:58:39.188518  3083 net.cpp:301] Scale52 needs backward computation.
I0818 10:58:39.188531  3083 net.cpp:301] BatchNorm52 needs backward computation.
I0818 10:58:39.188545  3083 net.cpp:301] Convolution52 needs backward computation.
I0818 10:58:39.188560  3083 net.cpp:301] Eltwise24_ReLU49_0_split needs backward computation.
I0818 10:58:39.188575  3083 net.cpp:301] ReLU49 needs backward computation.
I0818 10:58:39.188588  3083 net.cpp:301] Eltwise24 needs backward computation.
I0818 10:58:39.188606  3083 net.cpp:301] Scale51 needs backward computation.
I0818 10:58:39.188619  3083 net.cpp:301] BatchNorm51 needs backward computation.
I0818 10:58:39.188633  3083 net.cpp:301] Convolution51 needs backward computation.
I0818 10:58:39.188649  3083 net.cpp:301] ReLU48 needs backward computation.
I0818 10:58:39.188669  3083 net.cpp:301] Scale50 needs backward computation.
I0818 10:58:39.188683  3083 net.cpp:301] BatchNorm50 needs backward computation.
I0818 10:58:39.188697  3083 net.cpp:301] Convolution50 needs backward computation.
I0818 10:58:39.188712  3083 net.cpp:301] Eltwise23_ReLU47_0_split needs backward computation.
I0818 10:58:39.188726  3083 net.cpp:301] ReLU47 needs backward computation.
I0818 10:58:39.188740  3083 net.cpp:301] Eltwise23 needs backward computation.
I0818 10:58:39.188755  3083 net.cpp:301] Scale49 needs backward computation.
I0818 10:58:39.188768  3083 net.cpp:301] BatchNorm49 needs backward computation.
I0818 10:58:39.188782  3083 net.cpp:301] Convolution49 needs backward computation.
I0818 10:58:39.188803  3083 net.cpp:301] ReLU46 needs backward computation.
I0818 10:58:39.188817  3083 net.cpp:301] Scale48 needs backward computation.
I0818 10:58:39.188833  3083 net.cpp:301] BatchNorm48 needs backward computation.
I0818 10:58:39.188846  3083 net.cpp:301] Convolution48 needs backward computation.
I0818 10:58:39.188861  3083 net.cpp:301] Eltwise22_ReLU45_0_split needs backward computation.
I0818 10:58:39.188875  3083 net.cpp:301] ReLU45 needs backward computation.
I0818 10:58:39.188890  3083 net.cpp:301] Eltwise22 needs backward computation.
I0818 10:58:39.188907  3083 net.cpp:301] Scale47 needs backward computation.
I0818 10:58:39.188921  3083 net.cpp:301] BatchNorm47 needs backward computation.
I0818 10:58:39.188935  3083 net.cpp:301] Convolution47 needs backward computation.
I0818 10:58:39.188949  3083 net.cpp:301] ReLU44 needs backward computation.
I0818 10:58:39.188963  3083 net.cpp:301] Scale46 needs backward computation.
I0818 10:58:39.188977  3083 net.cpp:301] BatchNorm46 needs backward computation.
I0818 10:58:39.188990  3083 net.cpp:301] Convolution46 needs backward computation.
I0818 10:58:39.189005  3083 net.cpp:301] Eltwise21_ReLU43_0_split needs backward computation.
I0818 10:58:39.189019  3083 net.cpp:301] ReLU43 needs backward computation.
I0818 10:58:39.189033  3083 net.cpp:301] Eltwise21 needs backward computation.
I0818 10:58:39.189049  3083 net.cpp:301] Scale45 needs backward computation.
I0818 10:58:39.189062  3083 net.cpp:301] BatchNorm45 needs backward computation.
I0818 10:58:39.189076  3083 net.cpp:301] Convolution45 needs backward computation.
I0818 10:58:39.189090  3083 net.cpp:301] ReLU42 needs backward computation.
I0818 10:58:39.189105  3083 net.cpp:301] Scale44 needs backward computation.
I0818 10:58:39.189121  3083 net.cpp:301] BatchNorm44 needs backward computation.
I0818 10:58:39.189134  3083 net.cpp:301] Convolution44 needs backward computation.
I0818 10:58:39.189149  3083 net.cpp:301] Eltwise20_ReLU41_0_split needs backward computation.
I0818 10:58:39.189165  3083 net.cpp:301] ReLU41 needs backward computation.
I0818 10:58:39.189179  3083 net.cpp:301] Eltwise20 needs backward computation.
I0818 10:58:39.189194  3083 net.cpp:301] Scale43 needs backward computation.
I0818 10:58:39.189208  3083 net.cpp:301] BatchNorm43 needs backward computation.
I0818 10:58:39.189222  3083 net.cpp:301] Convolution43 needs backward computation.
I0818 10:58:39.189236  3083 net.cpp:301] ReLU40 needs backward computation.
I0818 10:58:39.189250  3083 net.cpp:301] Scale42 needs backward computation.
I0818 10:58:39.189263  3083 net.cpp:301] BatchNorm42 needs backward computation.
I0818 10:58:39.189277  3083 net.cpp:301] Convolution42 needs backward computation.
I0818 10:58:39.189291  3083 net.cpp:301] Eltwise19_ReLU39_0_split needs backward computation.
I0818 10:58:39.189306  3083 net.cpp:301] ReLU39 needs backward computation.
I0818 10:58:39.189319  3083 net.cpp:301] Eltwise19 needs backward computation.
I0818 10:58:39.189334  3083 net.cpp:301] Scale41 needs backward computation.
I0818 10:58:39.189348  3083 net.cpp:301] BatchNorm41 needs backward computation.
I0818 10:58:39.189363  3083 net.cpp:301] Convolution41 needs backward computation.
I0818 10:58:39.189376  3083 net.cpp:301] ReLU38 needs backward computation.
I0818 10:58:39.189390  3083 net.cpp:301] Scale40 needs backward computation.
I0818 10:58:39.189409  3083 net.cpp:301] BatchNorm40 needs backward computation.
I0818 10:58:39.189422  3083 net.cpp:301] Convolution40 needs backward computation.
I0818 10:58:39.189438  3083 net.cpp:301] Scale39 needs backward computation.
I0818 10:58:39.189452  3083 net.cpp:301] BatchNorm39 needs backward computation.
I0818 10:58:39.189466  3083 net.cpp:301] Convolution39 needs backward computation.
I0818 10:58:39.189481  3083 net.cpp:301] Eltwise18_ReLU37_0_split needs backward computation.
I0818 10:58:39.189501  3083 net.cpp:301] ReLU37 needs backward computation.
I0818 10:58:39.189514  3083 net.cpp:301] Eltwise18 needs backward computation.
I0818 10:58:39.189529  3083 net.cpp:301] Scale38 needs backward computation.
I0818 10:58:39.189549  3083 net.cpp:301] BatchNorm38 needs backward computation.
I0818 10:58:39.189563  3083 net.cpp:301] Convolution38 needs backward computation.
I0818 10:58:39.189579  3083 net.cpp:301] ReLU36 needs backward computation.
I0818 10:58:39.189591  3083 net.cpp:301] Scale37 needs backward computation.
I0818 10:58:39.189605  3083 net.cpp:301] BatchNorm37 needs backward computation.
I0818 10:58:39.189620  3083 net.cpp:301] Convolution37 needs backward computation.
I0818 10:58:39.189633  3083 net.cpp:301] Eltwise17_ReLU35_0_split needs backward computation.
I0818 10:58:39.189648  3083 net.cpp:301] ReLU35 needs backward computation.
I0818 10:58:39.189662  3083 net.cpp:301] Eltwise17 needs backward computation.
I0818 10:58:39.189677  3083 net.cpp:301] Scale36 needs backward computation.
I0818 10:58:39.189690  3083 net.cpp:301] BatchNorm36 needs backward computation.
I0818 10:58:39.189704  3083 net.cpp:301] Convolution36 needs backward computation.
I0818 10:58:39.189719  3083 net.cpp:301] ReLU34 needs backward computation.
I0818 10:58:39.189733  3083 net.cpp:301] Scale35 needs backward computation.
I0818 10:58:39.189746  3083 net.cpp:301] BatchNorm35 needs backward computation.
I0818 10:58:39.189760  3083 net.cpp:301] Convolution35 needs backward computation.
I0818 10:58:39.189774  3083 net.cpp:301] Eltwise16_ReLU33_0_split needs backward computation.
I0818 10:58:39.189788  3083 net.cpp:301] ReLU33 needs backward computation.
I0818 10:58:39.189805  3083 net.cpp:301] Eltwise16 needs backward computation.
I0818 10:58:39.189821  3083 net.cpp:301] Scale34 needs backward computation.
I0818 10:58:39.189834  3083 net.cpp:301] BatchNorm34 needs backward computation.
I0818 10:58:39.189848  3083 net.cpp:301] Convolution34 needs backward computation.
I0818 10:58:39.189862  3083 net.cpp:301] ReLU32 needs backward computation.
I0818 10:58:39.189878  3083 net.cpp:301] Scale33 needs backward computation.
I0818 10:58:39.189893  3083 net.cpp:301] BatchNorm33 needs backward computation.
I0818 10:58:39.189905  3083 net.cpp:301] Convolution33 needs backward computation.
I0818 10:58:39.189920  3083 net.cpp:301] Eltwise15_ReLU31_0_split needs backward computation.
I0818 10:58:39.189934  3083 net.cpp:301] ReLU31 needs backward computation.
I0818 10:58:39.189949  3083 net.cpp:301] Eltwise15 needs backward computation.
I0818 10:58:39.189963  3083 net.cpp:301] Scale32 needs backward computation.
I0818 10:58:39.189976  3083 net.cpp:301] BatchNorm32 needs backward computation.
I0818 10:58:39.189990  3083 net.cpp:301] Convolution32 needs backward computation.
I0818 10:58:39.190004  3083 net.cpp:301] ReLU30 needs backward computation.
I0818 10:58:39.190018  3083 net.cpp:301] Scale31 needs backward computation.
I0818 10:58:39.190032  3083 net.cpp:301] BatchNorm31 needs backward computation.
I0818 10:58:39.190047  3083 net.cpp:301] Convolution31 needs backward computation.
I0818 10:58:39.190062  3083 net.cpp:301] Eltwise14_ReLU29_0_split needs backward computation.
I0818 10:58:39.190075  3083 net.cpp:301] ReLU29 needs backward computation.
I0818 10:58:39.190089  3083 net.cpp:301] Eltwise14 needs backward computation.
I0818 10:58:39.190105  3083 net.cpp:301] Scale30 needs backward computation.
I0818 10:58:39.190119  3083 net.cpp:301] BatchNorm30 needs backward computation.
I0818 10:58:39.190134  3083 net.cpp:301] Convolution30 needs backward computation.
I0818 10:58:39.190152  3083 net.cpp:301] ReLU28 needs backward computation.
I0818 10:58:39.190166  3083 net.cpp:301] Scale29 needs backward computation.
I0818 10:58:39.190181  3083 net.cpp:301] BatchNorm29 needs backward computation.
I0818 10:58:39.190194  3083 net.cpp:301] Convolution29 needs backward computation.
I0818 10:58:39.190208  3083 net.cpp:301] Eltwise13_ReLU27_0_split needs backward computation.
I0818 10:58:39.190223  3083 net.cpp:301] ReLU27 needs backward computation.
I0818 10:58:39.190239  3083 net.cpp:301] Eltwise13 needs backward computation.
I0818 10:58:39.190253  3083 net.cpp:301] Scale28 needs backward computation.
I0818 10:58:39.190274  3083 net.cpp:301] BatchNorm28 needs backward computation.
I0818 10:58:39.190287  3083 net.cpp:301] Convolution28 needs backward computation.
I0818 10:58:39.190301  3083 net.cpp:301] ReLU26 needs backward computation.
I0818 10:58:39.190318  3083 net.cpp:301] Scale27 needs backward computation.
I0818 10:58:39.190332  3083 net.cpp:301] BatchNorm27 needs backward computation.
I0818 10:58:39.190346  3083 net.cpp:301] Convolution27 needs backward computation.
I0818 10:58:39.190361  3083 net.cpp:301] Eltwise12_ReLU25_0_split needs backward computation.
I0818 10:58:39.190374  3083 net.cpp:301] ReLU25 needs backward computation.
I0818 10:58:39.190388  3083 net.cpp:301] Eltwise12 needs backward computation.
I0818 10:58:39.190403  3083 net.cpp:301] Scale26 needs backward computation.
I0818 10:58:39.190418  3083 net.cpp:301] BatchNorm26 needs backward computation.
I0818 10:58:39.190431  3083 net.cpp:301] Convolution26 needs backward computation.
I0818 10:58:39.190445  3083 net.cpp:301] ReLU24 needs backward computation.
I0818 10:58:39.190459  3083 net.cpp:301] Scale25 needs backward computation.
I0818 10:58:39.190474  3083 net.cpp:301] BatchNorm25 needs backward computation.
I0818 10:58:39.190487  3083 net.cpp:301] Convolution25 needs backward computation.
I0818 10:58:39.190501  3083 net.cpp:301] Eltwise11_ReLU23_0_split needs backward computation.
I0818 10:58:39.190516  3083 net.cpp:301] ReLU23 needs backward computation.
I0818 10:58:39.190529  3083 net.cpp:301] Eltwise11 needs backward computation.
I0818 10:58:39.190544  3083 net.cpp:301] Scale24 needs backward computation.
I0818 10:58:39.190558  3083 net.cpp:301] BatchNorm24 needs backward computation.
I0818 10:58:39.190572  3083 net.cpp:301] Convolution24 needs backward computation.
I0818 10:58:39.190587  3083 net.cpp:301] ReLU22 needs backward computation.
I0818 10:58:39.190600  3083 net.cpp:301] Scale23 needs backward computation.
I0818 10:58:39.190614  3083 net.cpp:301] BatchNorm23 needs backward computation.
I0818 10:58:39.190629  3083 net.cpp:301] Convolution23 needs backward computation.
I0818 10:58:39.190644  3083 net.cpp:301] Eltwise10_ReLU21_0_split needs backward computation.
I0818 10:58:39.190665  3083 net.cpp:301] ReLU21 needs backward computation.
I0818 10:58:39.190680  3083 net.cpp:301] Eltwise10 needs backward computation.
I0818 10:58:39.190697  3083 net.cpp:301] Scale22 needs backward computation.
I0818 10:58:39.190711  3083 net.cpp:301] BatchNorm22 needs backward computation.
I0818 10:58:39.190726  3083 net.cpp:301] Convolution22 needs backward computation.
I0818 10:58:39.190742  3083 net.cpp:301] ReLU20 needs backward computation.
I0818 10:58:39.190757  3083 net.cpp:301] Scale21 needs backward computation.
I0818 10:58:39.190770  3083 net.cpp:301] BatchNorm21 needs backward computation.
I0818 10:58:39.190783  3083 net.cpp:301] Convolution21 needs backward computation.
I0818 10:58:39.190798  3083 net.cpp:301] Scale20 needs backward computation.
I0818 10:58:39.190812  3083 net.cpp:301] BatchNorm20 needs backward computation.
I0818 10:58:39.190829  3083 net.cpp:301] Convolution20 needs backward computation.
I0818 10:58:39.190843  3083 net.cpp:301] Eltwise9_ReLU19_0_split needs backward computation.
I0818 10:58:39.190857  3083 net.cpp:301] ReLU19 needs backward computation.
I0818 10:58:39.190871  3083 net.cpp:301] Eltwise9 needs backward computation.
I0818 10:58:39.190891  3083 net.cpp:301] Scale19 needs backward computation.
I0818 10:58:39.190904  3083 net.cpp:301] BatchNorm19 needs backward computation.
I0818 10:58:39.190918  3083 net.cpp:301] Convolution19 needs backward computation.
I0818 10:58:39.190932  3083 net.cpp:301] ReLU18 needs backward computation.
I0818 10:58:39.190946  3083 net.cpp:301] Scale18 needs backward computation.
I0818 10:58:39.190959  3083 net.cpp:301] BatchNorm18 needs backward computation.
I0818 10:58:39.190974  3083 net.cpp:301] Convolution18 needs backward computation.
I0818 10:58:39.190989  3083 net.cpp:301] Eltwise8_ReLU17_0_split needs backward computation.
I0818 10:58:39.191002  3083 net.cpp:301] ReLU17 needs backward computation.
I0818 10:58:39.191023  3083 net.cpp:301] Eltwise8 needs backward computation.
I0818 10:58:39.191038  3083 net.cpp:301] Scale17 needs backward computation.
I0818 10:58:39.191052  3083 net.cpp:301] BatchNorm17 needs backward computation.
I0818 10:58:39.191066  3083 net.cpp:301] Convolution17 needs backward computation.
I0818 10:58:39.191081  3083 net.cpp:301] ReLU16 needs backward computation.
I0818 10:58:39.191094  3083 net.cpp:301] Scale16 needs backward computation.
I0818 10:58:39.191108  3083 net.cpp:301] BatchNorm16 needs backward computation.
I0818 10:58:39.191123  3083 net.cpp:301] Convolution16 needs backward computation.
I0818 10:58:39.191138  3083 net.cpp:301] Eltwise7_ReLU15_0_split needs backward computation.
I0818 10:58:39.191151  3083 net.cpp:301] ReLU15 needs backward computation.
I0818 10:58:39.191165  3083 net.cpp:301] Eltwise7 needs backward computation.
I0818 10:58:39.191181  3083 net.cpp:301] Scale15 needs backward computation.
I0818 10:58:39.191195  3083 net.cpp:301] BatchNorm15 needs backward computation.
I0818 10:58:39.191210  3083 net.cpp:301] Convolution15 needs backward computation.
I0818 10:58:39.191223  3083 net.cpp:301] ReLU14 needs backward computation.
I0818 10:58:39.191237  3083 net.cpp:301] Scale14 needs backward computation.
I0818 10:58:39.191251  3083 net.cpp:301] BatchNorm14 needs backward computation.
I0818 10:58:39.191265  3083 net.cpp:301] Convolution14 needs backward computation.
I0818 10:58:39.191280  3083 net.cpp:301] Eltwise6_ReLU13_0_split needs backward computation.
I0818 10:58:39.191295  3083 net.cpp:301] ReLU13 needs backward computation.
I0818 10:58:39.191309  3083 net.cpp:301] Eltwise6 needs backward computation.
I0818 10:58:39.191325  3083 net.cpp:301] Scale13 needs backward computation.
I0818 10:58:39.191339  3083 net.cpp:301] BatchNorm13 needs backward computation.
I0818 10:58:39.191354  3083 net.cpp:301] Convolution13 needs backward computation.
I0818 10:58:39.191370  3083 net.cpp:301] ReLU12 needs backward computation.
I0818 10:58:39.191388  3083 net.cpp:301] Scale12 needs backward computation.
I0818 10:58:39.191401  3083 net.cpp:301] BatchNorm12 needs backward computation.
I0818 10:58:39.191416  3083 net.cpp:301] Convolution12 needs backward computation.
I0818 10:58:39.191431  3083 net.cpp:301] Eltwise5_ReLU11_0_split needs backward computation.
I0818 10:58:39.191444  3083 net.cpp:301] ReLU11 needs backward computation.
I0818 10:58:39.191458  3083 net.cpp:301] Eltwise5 needs backward computation.
I0818 10:58:39.191474  3083 net.cpp:301] Scale11 needs backward computation.
I0818 10:58:39.191484  3083 net.cpp:301] BatchNorm11 needs backward computation.
I0818 10:58:39.191489  3083 net.cpp:301] Convolution11 needs backward computation.
I0818 10:58:39.191494  3083 net.cpp:301] ReLU10 needs backward computation.
I0818 10:58:39.191498  3083 net.cpp:301] Scale10 needs backward computation.
I0818 10:58:39.191504  3083 net.cpp:301] BatchNorm10 needs backward computation.
I0818 10:58:39.191509  3083 net.cpp:301] Convolution10 needs backward computation.
I0818 10:58:39.191514  3083 net.cpp:301] Eltwise4_ReLU9_0_split needs backward computation.
I0818 10:58:39.191524  3083 net.cpp:301] ReLU9 needs backward computation.
I0818 10:58:39.191527  3083 net.cpp:301] Eltwise4 needs backward computation.
I0818 10:58:39.191535  3083 net.cpp:301] Scale9 needs backward computation.
I0818 10:58:39.191543  3083 net.cpp:301] BatchNorm9 needs backward computation.
I0818 10:58:39.191548  3083 net.cpp:301] Convolution9 needs backward computation.
I0818 10:58:39.191553  3083 net.cpp:301] ReLU8 needs backward computation.
I0818 10:58:39.191558  3083 net.cpp:301] Scale8 needs backward computation.
I0818 10:58:39.191563  3083 net.cpp:301] BatchNorm8 needs backward computation.
I0818 10:58:39.191570  3083 net.cpp:301] Convolution8 needs backward computation.
I0818 10:58:39.191576  3083 net.cpp:301] Eltwise3_ReLU7_0_split needs backward computation.
I0818 10:58:39.191582  3083 net.cpp:301] ReLU7 needs backward computation.
I0818 10:58:39.191586  3083 net.cpp:301] Eltwise3 needs backward computation.
I0818 10:58:39.191606  3083 net.cpp:301] Scale7 needs backward computation.
I0818 10:58:39.191610  3083 net.cpp:301] BatchNorm7 needs backward computation.
I0818 10:58:39.191615  3083 net.cpp:301] Convolution7 needs backward computation.
I0818 10:58:39.191619  3083 net.cpp:301] ReLU6 needs backward computation.
I0818 10:58:39.191625  3083 net.cpp:301] Scale6 needs backward computation.
I0818 10:58:39.191629  3083 net.cpp:301] BatchNorm6 needs backward computation.
I0818 10:58:39.191634  3083 net.cpp:301] Convolution6 needs backward computation.
I0818 10:58:39.191639  3083 net.cpp:301] Eltwise2_ReLU5_0_split needs backward computation.
I0818 10:58:39.191646  3083 net.cpp:301] ReLU5 needs backward computation.
I0818 10:58:39.191651  3083 net.cpp:301] Eltwise2 needs backward computation.
I0818 10:58:39.191663  3083 net.cpp:301] Scale5 needs backward computation.
I0818 10:58:39.191670  3083 net.cpp:301] BatchNorm5 needs backward computation.
I0818 10:58:39.191674  3083 net.cpp:301] Convolution5 needs backward computation.
I0818 10:58:39.191681  3083 net.cpp:301] ReLU4 needs backward computation.
I0818 10:58:39.191685  3083 net.cpp:301] Scale4 needs backward computation.
I0818 10:58:39.191694  3083 net.cpp:301] BatchNorm4 needs backward computation.
I0818 10:58:39.191697  3083 net.cpp:301] Convolution4 needs backward computation.
I0818 10:58:39.191706  3083 net.cpp:301] Eltwise1_ReLU3_0_split needs backward computation.
I0818 10:58:39.191711  3083 net.cpp:301] ReLU3 needs backward computation.
I0818 10:58:39.191717  3083 net.cpp:301] Eltwise1 needs backward computation.
I0818 10:58:39.191725  3083 net.cpp:301] Scale3 needs backward computation.
I0818 10:58:39.191731  3083 net.cpp:301] BatchNorm3 needs backward computation.
I0818 10:58:39.191735  3083 net.cpp:301] Convolution3 needs backward computation.
I0818 10:58:39.191740  3083 net.cpp:301] ReLU2 needs backward computation.
I0818 10:58:39.191747  3083 net.cpp:301] Scale2 needs backward computation.
I0818 10:58:39.191752  3083 net.cpp:301] BatchNorm2 needs backward computation.
I0818 10:58:39.191756  3083 net.cpp:301] Convolution2 needs backward computation.
I0818 10:58:39.191762  3083 net.cpp:301] Convolution1_ReLU1_0_split needs backward computation.
I0818 10:58:39.191767  3083 net.cpp:301] ReLU1 needs backward computation.
I0818 10:58:39.191776  3083 net.cpp:301] Scale1 needs backward computation.
I0818 10:58:39.191779  3083 net.cpp:301] BatchNorm1 needs backward computation.
I0818 10:58:39.191785  3083 net.cpp:301] Convolution1 needs backward computation.
I0818 10:58:39.191792  3083 net.cpp:303] Data1 does not need backward computation.
I0818 10:58:39.191797  3083 net.cpp:348] This network produces output SoftmaxWithLoss1
I0818 10:58:39.191937  3083 net.cpp:363] Network initialization done.
I0818 10:58:39.194736  3083 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./test_ResNet_56.prototxt
I0818 10:58:39.194766  3083 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0818 10:58:39.194778  3083 solver.cpp:277] Creating test net (#0) specified by test_net file: ./test_ResNet_56.prototxt
I0818 10:58:39.194995  3083 net.cpp:390] layer_param.include_size():1
I0818 10:58:39.195008  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195013  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195017  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195021  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195025  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195029  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195032  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195036  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195040  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195044  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195047  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195052  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195071  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195076  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195080  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195083  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195087  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195091  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195094  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195099  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195102  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195106  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195111  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195114  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195117  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195122  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195125  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195129  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195132  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195137  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195140  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195144  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195148  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195152  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195155  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195159  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195163  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195168  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195171  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195175  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195179  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195183  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195186  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195191  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195194  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195199  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195202  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195206  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195210  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195214  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195217  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195221  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195225  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195230  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195232  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195237  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195240  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195245  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195248  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195252  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195256  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195261  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195264  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195268  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195271  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195276  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195279  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195283  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195287  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195291  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195296  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195305  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195309  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195314  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195318  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195322  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195325  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195329  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195333  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195338  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195340  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195344  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195348  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195353  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195356  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195360  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195363  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195367  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195371  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195374  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195379  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195382  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195386  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195390  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195394  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195397  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195401  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195405  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195408  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195412  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195416  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195420  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195427  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195431  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195436  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195439  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195442  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195446  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195451  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195454  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195457  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195461  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195466  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195469  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195472  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195477  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195480  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195484  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195487  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195492  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195495  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195499  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195503  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195508  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195511  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195514  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195518  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195523  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195526  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195538  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195541  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195544  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195552  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195557  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195561  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195565  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195574  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195578  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195586  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195591  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195595  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195598  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195606  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195611  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195614  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195621  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195626  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195631  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195636  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195641  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195644  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195648  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195655  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195659  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195662  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195667  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195670  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195674  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195678  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195683  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195686  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195691  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195695  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195699  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195703  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195708  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195711  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195715  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195719  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195722  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195726  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195731  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195734  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195739  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195745  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195749  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195752  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195760  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195763  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195767  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195771  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195775  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195780  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195785  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195792  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195796  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195801  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195807  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195817  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195822  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195824  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195828  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195832  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195837  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195839  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195843  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195847  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195852  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195855  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195859  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195863  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195866  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195870  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195874  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195878  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195881  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195885  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195889  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195894  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195896  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195900  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195904  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195909  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195912  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195915  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195919  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195924  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195927  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195930  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195935  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195938  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195942  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195946  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195950  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195953  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195957  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195964  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195968  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195976  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195979  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195983  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195989  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.195993  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.195997  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196003  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196007  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196012  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196015  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196018  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196022  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196029  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196033  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196040  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196045  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196048  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196054  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196068  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196071  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196079  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196082  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196086  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196094  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196096  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196105  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196108  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196112  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196117  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196121  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196125  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196132  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196136  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196143  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196146  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196151  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196156  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196161  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196164  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196171  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196174  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196178  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196183  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196187  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196192  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196197  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196202  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196208  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196213  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196218  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196223  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196226  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196230  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196236  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196240  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196249  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196252  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196256  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196261  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196266  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196270  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196276  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196280  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196285  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196290  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196293  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196297  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196301  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196305  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196310  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196312  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196316  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196321  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196324  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196328  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196332  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196339  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196352  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196357  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196363  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196367  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196372  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196377  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196382  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196384  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196388  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196393  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196396  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196400  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196403  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196408  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196411  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196415  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196419  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196422  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196426  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196430  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196434  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196437  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196441  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196445  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196449  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196454  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196457  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196460  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196465  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196468  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196472  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196475  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196480  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196483  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196487  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196491  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196494  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196498  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196502  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196506  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196509  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196513  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196517  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196521  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196528  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196532  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196537  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196542  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196545  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196549  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196553  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196559  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196563  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196570  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196574  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196581  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196585  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196589  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196599  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196604  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196612  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196615  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196624  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196626  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196631  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196636  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196640  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196645  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196650  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196655  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196662  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196666  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196671  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196676  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196681  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196683  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196689  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196693  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196700  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196704  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196708  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196712  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196715  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196719  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196723  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196727  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196730  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196734  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196738  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196743  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196745  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196749  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196753  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196758  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196761  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196764  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196768  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196772  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196776  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196779  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196784  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196787  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196791  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196794  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196799  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196802  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196806  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196810  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196813  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196817  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196821  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196825  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196828  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196832  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196836  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196841  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196844  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196853  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196858  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196861  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196866  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196869  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196873  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196877  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196882  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196884  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196888  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196892  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196897  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196899  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196903  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196907  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196911  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196914  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196918  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196923  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196926  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196930  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196934  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196938  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196941  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196945  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196949  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196952  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196956  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196960  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196964  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196969  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196972  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196975  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196979  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196983  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196987  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196990  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.196995  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.196998  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197002  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197005  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197010  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197013  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197017  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197021  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197024  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197028  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197032  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197036  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197039  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197043  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197047  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197052  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197055  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197058  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197062  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197067  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197069  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197079  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197083  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197088  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197091  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197094  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197098  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197103  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197108  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197110  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197114  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197118  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197122  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197125  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197129  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197134  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197137  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197140  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197144  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197149  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197152  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197156  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197160  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197163  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197167  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197171  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197175  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197178  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197182  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197186  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197190  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197193  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197198  3083 net.cpp:390] layer_param.include_size():0
I0818 10:58:39.197201  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.197206  3083 net.cpp:390] layer_param.include_size():1
I0818 10:58:39.197209  3083 net.cpp:391] layer_param.exclude_size():0
I0818 10:58:39.198784  3083 net.cpp:82] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0039215684
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/test_lmdb"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution12"
  top: "Convolution12"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Convolution12"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution13"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution14"
  top: "Convolution14"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution15"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution17"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution19"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution20"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution23"
  top: "Convolution23"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Eltwise10"
  bottom: "Convolution24"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution25"
  top: "Convolution25"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution26"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution27"
  top: "Convolution27"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution28"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution29"
  top: "Convolution29"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Convolution29"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution30"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "Convolution31"
  top: "Convolution31"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Convolution31"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "Convolution32"
  top: "Convolution32"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise15"
  type: "Eltwise"
  bottom: "Eltwise14"
  bottom: "Convolution32"
  top: "Eltwise15"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "Eltwise15"
  top: "Eltwise15"
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Eltwise15"
 
I0818 10:58:39.199764  3083 layer_factory.hpp:77] Creating layer Data1
I0818 10:58:39.199841  3083 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/test_lmdb
I0818 10:58:39.199867  3083 net.cpp:128] Creating Layer Data1
I0818 10:58:39.199874  3083 net.cpp:522] Data1 -> Data1
I0818 10:58:39.199885  3083 net.cpp:522] Data1 -> Data2
I0818 10:58:39.200084  3083 data_layer.cpp:45] output data size: 10,3,32,32
I0818 10:58:39.201056  3083 net.cpp:172] Setting up Data1
I0818 10:58:39.201071  3083 net.cpp:186] Top shape: 10 3 32 32 (30720)
I0818 10:58:39.201077  3083 net.cpp:186] Top shape: 10 (10)
I0818 10:58:39.201081  3083 net.cpp:194] Memory required for data: 122920
I0818 10:58:39.201086  3083 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0818 10:58:39.201099  3083 net.cpp:128] Creating Layer Data2_Data1_1_split
I0818 10:58:39.201104  3083 net.cpp:558] Data2_Data1_1_split <- Data2
I0818 10:58:39.201112  3083 net.cpp:522] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0818 10:58:39.201120  3083 net.cpp:522] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0818 10:58:39.201182  3083 net.cpp:172] Setting up Data2_Data1_1_split
I0818 10:58:39.201189  3083 net.cpp:186] Top shape: 10 (10)
I0818 10:58:39.201195  3083 net.cpp:186] Top shape: 10 (10)
I0818 10:58:39.201198  3083 net.cpp:194] Memory required for data: 123000
I0818 10:58:39.201202  3083 layer_factory.hpp:77] Creating layer Convolution1
I0818 10:58:39.201216  3083 net.cpp:128] Creating Layer Convolution1
I0818 10:58:39.201221  3083 net.cpp:558] Convolution1 <- Data1
I0818 10:58:39.202713  3083 net.cpp:522] Convolution1 -> Convolution1
I0818 10:58:39.208042  3083 net.cpp:172] Setting up Convolution1
I0818 10:58:39.208070  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.208077  3083 net.cpp:194] Memory required for data: 778360
I0818 10:58:39.208101  3083 layer_factory.hpp:77] Creating layer BatchNorm1
I0818 10:58:39.208120  3083 net.cpp:128] Creating Layer BatchNorm1
I0818 10:58:39.208128  3083 net.cpp:558] BatchNorm1 <- Convolution1
I0818 10:58:39.208238  3083 net.cpp:509] BatchNorm1 -> Convolution1 (in-place)
I0818 10:58:39.208792  3083 net.cpp:172] Setting up BatchNorm1
I0818 10:58:39.208807  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.208813  3083 net.cpp:194] Memory required for data: 1433720
I0818 10:58:39.208930  3083 layer_factory.hpp:77] Creating layer Scale1
I0818 10:58:39.208950  3083 net.cpp:128] Creating Layer Scale1
I0818 10:58:39.208957  3083 net.cpp:558] Scale1 <- Convolution1
I0818 10:58:39.208967  3083 net.cpp:509] Scale1 -> Convolution1 (in-place)
I0818 10:58:39.209077  3083 layer_factory.hpp:77] Creating layer Scale1
I0818 10:58:39.209391  3083 net.cpp:172] Setting up Scale1
I0818 10:58:39.209484  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.209491  3083 net.cpp:194] Memory required for data: 2089080
I0818 10:58:39.209517  3083 layer_factory.hpp:77] Creating layer ReLU1
I0818 10:58:39.209532  3083 net.cpp:128] Creating Layer ReLU1
I0818 10:58:39.209537  3083 net.cpp:558] ReLU1 <- Convolution1
I0818 10:58:39.209545  3083 net.cpp:509] ReLU1 -> Convolution1 (in-place)
I0818 10:58:39.209910  3083 net.cpp:172] Setting up ReLU1
I0818 10:58:39.209928  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.209939  3083 net.cpp:194] Memory required for data: 2744440
I0818 10:58:39.209944  3083 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0818 10:58:39.209961  3083 net.cpp:128] Creating Layer Convolution1_ReLU1_0_split
I0818 10:58:39.209970  3083 net.cpp:558] Convolution1_ReLU1_0_split <- Convolution1
I0818 10:58:39.209982  3083 net.cpp:522] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0818 10:58:39.209995  3083 net.cpp:522] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0818 10:58:39.210106  3083 net.cpp:172] Setting up Convolution1_ReLU1_0_split
I0818 10:58:39.210124  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.210136  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.210144  3083 net.cpp:194] Memory required for data: 4055160
I0818 10:58:39.210150  3083 layer_factory.hpp:77] Creating layer Convolution2
I0818 10:58:39.210170  3083 net.cpp:128] Creating Layer Convolution2
I0818 10:58:39.210177  3083 net.cpp:558] Convolution2 <- Convolution1_ReLU1_0_split_0
I0818 10:58:39.210187  3083 net.cpp:522] Convolution2 -> Convolution2
I0818 10:58:39.219144  3083 net.cpp:172] Setting up Convolution2
I0818 10:58:39.219168  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.219174  3083 net.cpp:194] Memory required for data: 4710520
I0818 10:58:39.219192  3083 layer_factory.hpp:77] Creating layer BatchNorm2
I0818 10:58:39.219208  3083 net.cpp:128] Creating Layer BatchNorm2
I0818 10:58:39.219218  3083 net.cpp:558] BatchNorm2 <- Convolution2
I0818 10:58:39.219226  3083 net.cpp:509] BatchNorm2 -> Convolution2 (in-place)
I0818 10:58:39.219681  3083 net.cpp:172] Setting up BatchNorm2
I0818 10:58:39.219697  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.219702  3083 net.cpp:194] Memory required for data: 5365880
I0818 10:58:39.219715  3083 layer_factory.hpp:77] Creating layer Scale2
I0818 10:58:39.219729  3083 net.cpp:128] Creating Layer Scale2
I0818 10:58:39.219738  3083 net.cpp:558] Scale2 <- Convolution2
I0818 10:58:39.219748  3083 net.cpp:509] Scale2 -> Convolution2 (in-place)
I0818 10:58:39.219820  3083 layer_factory.hpp:77] Creating layer Scale2
I0818 10:58:39.220074  3083 net.cpp:172] Setting up Scale2
I0818 10:58:39.220090  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.220098  3083 net.cpp:194] Memory required for data: 6021240
I0818 10:58:39.220109  3083 layer_factory.hpp:77] Creating layer ReLU2
I0818 10:58:39.220120  3083 net.cpp:128] Creating Layer ReLU2
I0818 10:58:39.220129  3083 net.cpp:558] ReLU2 <- Convolution2
I0818 10:58:39.220137  3083 net.cpp:509] ReLU2 -> Convolution2 (in-place)
I0818 10:58:39.221156  3083 net.cpp:172] Setting up ReLU2
I0818 10:58:39.221179  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.221184  3083 net.cpp:194] Memory required for data: 6676600
I0818 10:58:39.221190  3083 layer_factory.hpp:77] Creating layer Convolution3
I0818 10:58:39.221211  3083 net.cpp:128] Creating Layer Convolution3
I0818 10:58:39.221220  3083 net.cpp:558] Convolution3 <- Convolution2
I0818 10:58:39.221230  3083 net.cpp:522] Convolution3 -> Convolution3
I0818 10:58:39.232306  3083 net.cpp:172] Setting up Convolution3
I0818 10:58:39.232332  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.232338  3083 net.cpp:194] Memory required for data: 7331960
I0818 10:58:39.232348  3083 layer_factory.hpp:77] Creating layer BatchNorm3
I0818 10:58:39.232358  3083 net.cpp:128] Creating Layer BatchNorm3
I0818 10:58:39.232363  3083 net.cpp:558] BatchNorm3 <- Convolution3
I0818 10:58:39.232373  3083 net.cpp:509] BatchNorm3 -> Convolution3 (in-place)
I0818 10:58:39.232800  3083 net.cpp:172] Setting up BatchNorm3
I0818 10:58:39.232815  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.232820  3083 net.cpp:194] Memory required for data: 7987320
I0818 10:58:39.232832  3083 layer_factory.hpp:77] Creating layer Scale3
I0818 10:58:39.232844  3083 net.cpp:128] Creating Layer Scale3
I0818 10:58:39.232848  3083 net.cpp:558] Scale3 <- Convolution3
I0818 10:58:39.232856  3083 net.cpp:509] Scale3 -> Convolution3 (in-place)
I0818 10:58:39.232913  3083 layer_factory.hpp:77] Creating layer Scale3
I0818 10:58:39.233088  3083 net.cpp:172] Setting up Scale3
I0818 10:58:39.233100  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.233104  3083 net.cpp:194] Memory required for data: 8642680
I0818 10:58:39.233112  3083 layer_factory.hpp:77] Creating layer Eltwise1
I0818 10:58:39.233121  3083 net.cpp:128] Creating Layer Eltwise1
I0818 10:58:39.233126  3083 net.cpp:558] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0818 10:58:39.233131  3083 net.cpp:558] Eltwise1 <- Convolution3
I0818 10:58:39.233139  3083 net.cpp:522] Eltwise1 -> Eltwise1
I0818 10:58:39.233173  3083 net.cpp:172] Setting up Eltwise1
I0818 10:58:39.233181  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.233184  3083 net.cpp:194] Memory required for data: 9298040
I0818 10:58:39.233189  3083 layer_factory.hpp:77] Creating layer ReLU3
I0818 10:58:39.233196  3083 net.cpp:128] Creating Layer ReLU3
I0818 10:58:39.233199  3083 net.cpp:558] ReLU3 <- Eltwise1
I0818 10:58:39.233206  3083 net.cpp:509] ReLU3 -> Eltwise1 (in-place)
I0818 10:58:39.240687  3083 net.cpp:172] Setting up ReLU3
I0818 10:58:39.240721  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.240728  3083 net.cpp:194] Memory required for data: 9953400
I0818 10:58:39.240736  3083 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0818 10:58:39.240752  3083 net.cpp:128] Creating Layer Eltwise1_ReLU3_0_split
I0818 10:58:39.240759  3083 net.cpp:558] Eltwise1_ReLU3_0_split <- Eltwise1
I0818 10:58:39.240770  3083 net.cpp:522] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0818 10:58:39.240783  3083 net.cpp:522] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0818 10:58:39.240887  3083 net.cpp:172] Setting up Eltwise1_ReLU3_0_split
I0818 10:58:39.240898  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.240907  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.240913  3083 net.cpp:194] Memory required for data: 11264120
I0818 10:58:39.240919  3083 layer_factory.hpp:77] Creating layer Convolution4
I0818 10:58:39.240938  3083 net.cpp:128] Creating Layer Convolution4
I0818 10:58:39.240947  3083 net.cpp:558] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0818 10:58:39.240959  3083 net.cpp:522] Convolution4 -> Convolution4
I0818 10:58:39.253590  3083 net.cpp:172] Setting up Convolution4
I0818 10:58:39.253618  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.253624  3083 net.cpp:194] Memory required for data: 11919480
I0818 10:58:39.253638  3083 layer_factory.hpp:77] Creating layer BatchNorm4
I0818 10:58:39.253650  3083 net.cpp:128] Creating Layer BatchNorm4
I0818 10:58:39.253657  3083 net.cpp:558] BatchNorm4 <- Convolution4
I0818 10:58:39.253670  3083 net.cpp:509] BatchNorm4 -> Convolution4 (in-place)
I0818 10:58:39.254146  3083 net.cpp:172] Setting up BatchNorm4
I0818 10:58:39.254163  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.254168  3083 net.cpp:194] Memory required for data: 12574840
I0818 10:58:39.254184  3083 layer_factory.hpp:77] Creating layer Scale4
I0818 10:58:39.254194  3083 net.cpp:128] Creating Layer Scale4
I0818 10:58:39.254200  3083 net.cpp:558] Scale4 <- Convolution4
I0818 10:58:39.254212  3083 net.cpp:509] Scale4 -> Convolution4 (in-place)
I0818 10:58:39.254293  3083 layer_factory.hpp:77] Creating layer Scale4
I0818 10:58:39.254551  3083 net.cpp:172] Setting up Scale4
I0818 10:58:39.254571  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.254577  3083 net.cpp:194] Memory required for data: 13230200
I0818 10:58:39.254590  3083 layer_factory.hpp:77] Creating layer ReLU4
I0818 10:58:39.254600  3083 net.cpp:128] Creating Layer ReLU4
I0818 10:58:39.254606  3083 net.cpp:558] ReLU4 <- Convolution4
I0818 10:58:39.254616  3083 net.cpp:509] ReLU4 -> Convolution4 (in-place)
I0818 10:58:39.255640  3083 net.cpp:172] Setting up ReLU4
I0818 10:58:39.255708  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.255728  3083 net.cpp:194] Memory required for data: 13885560
I0818 10:58:39.255748  3083 layer_factory.hpp:77] Creating layer Convolution5
I0818 10:58:39.255796  3083 net.cpp:128] Creating Layer Convolution5
I0818 10:58:39.255817  3083 net.cpp:558] Convolution5 <- Convolution4
I0818 10:58:39.255849  3083 net.cpp:522] Convolution5 -> Convolution5
I0818 10:58:39.262619  3083 net.cpp:172] Setting up Convolution5
I0818 10:58:39.262717  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.262722  3083 net.cpp:194] Memory required for data: 14540920
I0818 10:58:39.262732  3083 layer_factory.hpp:77] Creating layer BatchNorm5
I0818 10:58:39.262743  3083 net.cpp:128] Creating Layer BatchNorm5
I0818 10:58:39.262748  3083 net.cpp:558] BatchNorm5 <- Convolution5
I0818 10:58:39.262759  3083 net.cpp:509] BatchNorm5 -> Convolution5 (in-place)
I0818 10:58:39.263087  3083 net.cpp:172] Setting up BatchNorm5
I0818 10:58:39.263098  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.263103  3083 net.cpp:194] Memory required for data: 15196280
I0818 10:58:39.263118  3083 layer_factory.hpp:77] Creating layer Scale5
I0818 10:58:39.263144  3083 net.cpp:128] Creating Layer Scale5
I0818 10:58:39.263150  3083 net.cpp:558] Scale5 <- Convolution5
I0818 10:58:39.263157  3083 net.cpp:509] Scale5 -> Convolution5 (in-place)
I0818 10:58:39.263216  3083 layer_factory.hpp:77] Creating layer Scale5
I0818 10:58:39.263398  3083 net.cpp:172] Setting up Scale5
I0818 10:58:39.263409  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.263413  3083 net.cpp:194] Memory required for data: 15851640
I0818 10:58:39.263423  3083 layer_factory.hpp:77] Creating layer Eltwise2
I0818 10:58:39.263442  3083 net.cpp:128] Creating Layer Eltwise2
I0818 10:58:39.263453  3083 net.cpp:558] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0818 10:58:39.263459  3083 net.cpp:558] Eltwise2 <- Convolution5
I0818 10:58:39.263468  3083 net.cpp:522] Eltwise2 -> Eltwise2
I0818 10:58:39.263505  3083 net.cpp:172] Setting up Eltwise2
I0818 10:58:39.263514  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.263519  3083 net.cpp:194] Memory required for data: 16507000
I0818 10:58:39.263527  3083 layer_factory.hpp:77] Creating layer ReLU5
I0818 10:58:39.263533  3083 net.cpp:128] Creating Layer ReLU5
I0818 10:58:39.263540  3083 net.cpp:558] ReLU5 <- Eltwise2
I0818 10:58:39.263550  3083 net.cpp:509] ReLU5 -> Eltwise2 (in-place)
I0818 10:58:39.263803  3083 net.cpp:172] Setting up ReLU5
I0818 10:58:39.263818  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.263823  3083 net.cpp:194] Memory required for data: 17162360
I0818 10:58:39.263826  3083 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0818 10:58:39.263834  3083 net.cpp:128] Creating Layer Eltwise2_ReLU5_0_split
I0818 10:58:39.263839  3083 net.cpp:558] Eltwise2_ReLU5_0_split <- Eltwise2
I0818 10:58:39.263847  3083 net.cpp:522] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0818 10:58:39.263855  3083 net.cpp:522] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0818 10:58:39.263921  3083 net.cpp:172] Setting up Eltwise2_ReLU5_0_split
I0818 10:58:39.263929  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.263936  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.263941  3083 net.cpp:194] Memory required for data: 18473080
I0818 10:58:39.263944  3083 layer_factory.hpp:77] Creating layer Convolution6
I0818 10:58:39.263957  3083 net.cpp:128] Creating Layer Convolution6
I0818 10:58:39.263962  3083 net.cpp:558] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0818 10:58:39.263968  3083 net.cpp:522] Convolution6 -> Convolution6
I0818 10:58:39.276427  3083 net.cpp:172] Setting up Convolution6
I0818 10:58:39.276453  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.276458  3083 net.cpp:194] Memory required for data: 19128440
I0818 10:58:39.276468  3083 layer_factory.hpp:77] Creating layer BatchNorm6
I0818 10:58:39.276479  3083 net.cpp:128] Creating Layer BatchNorm6
I0818 10:58:39.276484  3083 net.cpp:558] BatchNorm6 <- Convolution6
I0818 10:58:39.276494  3083 net.cpp:509] BatchNorm6 -> Convolution6 (in-place)
I0818 10:58:39.276823  3083 net.cpp:172] Setting up BatchNorm6
I0818 10:58:39.276831  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.276835  3083 net.cpp:194] Memory required for data: 19783800
I0818 10:58:39.276844  3083 layer_factory.hpp:77] Creating layer Scale6
I0818 10:58:39.276854  3083 net.cpp:128] Creating Layer Scale6
I0818 10:58:39.276859  3083 net.cpp:558] Scale6 <- Convolution6
I0818 10:58:39.276865  3083 net.cpp:509] Scale6 -> Convolution6 (in-place)
I0818 10:58:39.276919  3083 layer_factory.hpp:77] Creating layer Scale6
I0818 10:58:39.277093  3083 net.cpp:172] Setting up Scale6
I0818 10:58:39.277101  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.277106  3083 net.cpp:194] Memory required for data: 20439160
I0818 10:58:39.277113  3083 layer_factory.hpp:77] Creating layer ReLU6
I0818 10:58:39.277119  3083 net.cpp:128] Creating Layer ReLU6
I0818 10:58:39.277123  3083 net.cpp:558] ReLU6 <- Convolution6
I0818 10:58:39.277132  3083 net.cpp:509] ReLU6 -> Convolution6 (in-place)
I0818 10:58:39.280261  3083 net.cpp:172] Setting up ReLU6
I0818 10:58:39.280302  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.280306  3083 net.cpp:194] Memory required for data: 21094520
I0818 10:58:39.280311  3083 layer_factory.hpp:77] Creating layer Convolution7
I0818 10:58:39.280328  3083 net.cpp:128] Creating Layer Convolution7
I0818 10:58:39.280333  3083 net.cpp:558] Convolution7 <- Convolution6
I0818 10:58:39.280342  3083 net.cpp:522] Convolution7 -> Convolution7
I0818 10:58:39.293416  3083 net.cpp:172] Setting up Convolution7
I0818 10:58:39.293442  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.293447  3083 net.cpp:194] Memory required for data: 21749880
I0818 10:58:39.293457  3083 layer_factory.hpp:77] Creating layer BatchNorm7
I0818 10:58:39.293471  3083 net.cpp:128] Creating Layer BatchNorm7
I0818 10:58:39.293478  3083 net.cpp:558] BatchNorm7 <- Convolution7
I0818 10:58:39.293483  3083 net.cpp:509] BatchNorm7 -> Convolution7 (in-place)
I0818 10:58:39.293802  3083 net.cpp:172] Setting up BatchNorm7
I0818 10:58:39.293809  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.293813  3083 net.cpp:194] Memory required for data: 22405240
I0818 10:58:39.293823  3083 layer_factory.hpp:77] Creating layer Scale7
I0818 10:58:39.293833  3083 net.cpp:128] Creating Layer Scale7
I0818 10:58:39.293836  3083 net.cpp:558] Scale7 <- Convolution7
I0818 10:58:39.293843  3083 net.cpp:509] Scale7 -> Convolution7 (in-place)
I0818 10:58:39.293897  3083 layer_factory.hpp:77] Creating layer Scale7
I0818 10:58:39.294071  3083 net.cpp:172] Setting up Scale7
I0818 10:58:39.294080  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.294083  3083 net.cpp:194] Memory required for data: 23060600
I0818 10:58:39.294091  3083 layer_factory.hpp:77] Creating layer Eltwise3
I0818 10:58:39.294101  3083 net.cpp:128] Creating Layer Eltwise3
I0818 10:58:39.294106  3083 net.cpp:558] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0818 10:58:39.294111  3083 net.cpp:558] Eltwise3 <- Convolution7
I0818 10:58:39.294121  3083 net.cpp:522] Eltwise3 -> Eltwise3
I0818 10:58:39.294152  3083 net.cpp:172] Setting up Eltwise3
I0818 10:58:39.294157  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.294162  3083 net.cpp:194] Memory required for data: 23715960
I0818 10:58:39.294165  3083 layer_factory.hpp:77] Creating layer ReLU7
I0818 10:58:39.294173  3083 net.cpp:128] Creating Layer ReLU7
I0818 10:58:39.294176  3083 net.cpp:558] ReLU7 <- Eltwise3
I0818 10:58:39.294184  3083 net.cpp:509] ReLU7 -> Eltwise3 (in-place)
I0818 10:58:39.295651  3083 net.cpp:172] Setting up ReLU7
I0818 10:58:39.295662  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.295666  3083 net.cpp:194] Memory required for data: 24371320
I0818 10:58:39.295670  3083 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0818 10:58:39.295678  3083 net.cpp:128] Creating Layer Eltwise3_ReLU7_0_split
I0818 10:58:39.295682  3083 net.cpp:558] Eltwise3_ReLU7_0_split <- Eltwise3
I0818 10:58:39.295692  3083 net.cpp:522] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0818 10:58:39.295701  3083 net.cpp:522] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0818 10:58:39.295763  3083 net.cpp:172] Setting up Eltwise3_ReLU7_0_split
I0818 10:58:39.295769  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.295775  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.295779  3083 net.cpp:194] Memory required for data: 25682040
I0818 10:58:39.295783  3083 layer_factory.hpp:77] Creating layer Convolution8
I0818 10:58:39.295796  3083 net.cpp:128] Creating Layer Convolution8
I0818 10:58:39.295801  3083 net.cpp:558] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0818 10:58:39.295810  3083 net.cpp:522] Convolution8 -> Convolution8
I0818 10:58:39.302472  3083 net.cpp:172] Setting up Convolution8
I0818 10:58:39.302498  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.302503  3083 net.cpp:194] Memory required for data: 26337400
I0818 10:58:39.302513  3083 layer_factory.hpp:77] Creating layer BatchNorm8
I0818 10:58:39.302525  3083 net.cpp:128] Creating Layer BatchNorm8
I0818 10:58:39.302546  3083 net.cpp:558] BatchNorm8 <- Convolution8
I0818 10:58:39.302552  3083 net.cpp:509] BatchNorm8 -> Convolution8 (in-place)
I0818 10:58:39.302893  3083 net.cpp:172] Setting up BatchNorm8
I0818 10:58:39.302906  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.302911  3083 net.cpp:194] Memory required for data: 26992760
I0818 10:58:39.302922  3083 layer_factory.hpp:77] Creating layer Scale8
I0818 10:58:39.302928  3083 net.cpp:128] Creating Layer Scale8
I0818 10:58:39.302932  3083 net.cpp:558] Scale8 <- Convolution8
I0818 10:58:39.302938  3083 net.cpp:509] Scale8 -> Convolution8 (in-place)
I0818 10:58:39.302997  3083 layer_factory.hpp:77] Creating layer Scale8
I0818 10:58:39.303172  3083 net.cpp:172] Setting up Scale8
I0818 10:58:39.303179  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.303184  3083 net.cpp:194] Memory required for data: 27648120
I0818 10:58:39.303191  3083 layer_factory.hpp:77] Creating layer ReLU8
I0818 10:58:39.303200  3083 net.cpp:128] Creating Layer ReLU8
I0818 10:58:39.303203  3083 net.cpp:558] ReLU8 <- Convolution8
I0818 10:58:39.303211  3083 net.cpp:509] ReLU8 -> Convolution8 (in-place)
I0818 10:58:39.304527  3083 net.cpp:172] Setting up ReLU8
I0818 10:58:39.304545  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.304550  3083 net.cpp:194] Memory required for data: 28303480
I0818 10:58:39.304554  3083 layer_factory.hpp:77] Creating layer Convolution9
I0818 10:58:39.304567  3083 net.cpp:128] Creating Layer Convolution9
I0818 10:58:39.304572  3083 net.cpp:558] Convolution9 <- Convolution8
I0818 10:58:39.304581  3083 net.cpp:522] Convolution9 -> Convolution9
I0818 10:58:39.311408  3083 net.cpp:172] Setting up Convolution9
I0818 10:58:39.311429  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.311434  3083 net.cpp:194] Memory required for data: 28958840
I0818 10:58:39.311444  3083 layer_factory.hpp:77] Creating layer BatchNorm9
I0818 10:58:39.311455  3083 net.cpp:128] Creating Layer BatchNorm9
I0818 10:58:39.311460  3083 net.cpp:558] BatchNorm9 <- Convolution9
I0818 10:58:39.311468  3083 net.cpp:509] BatchNorm9 -> Convolution9 (in-place)
I0818 10:58:39.311790  3083 net.cpp:172] Setting up BatchNorm9
I0818 10:58:39.311801  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.311805  3083 net.cpp:194] Memory required for data: 29614200
I0818 10:58:39.311816  3083 layer_factory.hpp:77] Creating layer Scale9
I0818 10:58:39.311826  3083 net.cpp:128] Creating Layer Scale9
I0818 10:58:39.311831  3083 net.cpp:558] Scale9 <- Convolution9
I0818 10:58:39.311836  3083 net.cpp:509] Scale9 -> Convolution9 (in-place)
I0818 10:58:39.311893  3083 layer_factory.hpp:77] Creating layer Scale9
I0818 10:58:39.312069  3083 net.cpp:172] Setting up Scale9
I0818 10:58:39.312077  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.312081  3083 net.cpp:194] Memory required for data: 30269560
I0818 10:58:39.312088  3083 layer_factory.hpp:77] Creating layer Eltwise4
I0818 10:58:39.312098  3083 net.cpp:128] Creating Layer Eltwise4
I0818 10:58:39.312103  3083 net.cpp:558] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I0818 10:58:39.312108  3083 net.cpp:558] Eltwise4 <- Convolution9
I0818 10:58:39.312114  3083 net.cpp:522] Eltwise4 -> Eltwise4
I0818 10:58:39.312149  3083 net.cpp:172] Setting up Eltwise4
I0818 10:58:39.312155  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.312160  3083 net.cpp:194] Memory required for data: 30924920
I0818 10:58:39.312163  3083 layer_factory.hpp:77] Creating layer ReLU9
I0818 10:58:39.312170  3083 net.cpp:128] Creating Layer ReLU9
I0818 10:58:39.312173  3083 net.cpp:558] ReLU9 <- Eltwise4
I0818 10:58:39.312182  3083 net.cpp:509] ReLU9 -> Eltwise4 (in-place)
I0818 10:58:39.315610  3083 net.cpp:172] Setting up ReLU9
I0818 10:58:39.315635  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.315640  3083 net.cpp:194] Memory required for data: 31580280
I0818 10:58:39.315645  3083 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0818 10:58:39.315670  3083 net.cpp:128] Creating Layer Eltwise4_ReLU9_0_split
I0818 10:58:39.315675  3083 net.cpp:558] Eltwise4_ReLU9_0_split <- Eltwise4
I0818 10:58:39.315683  3083 net.cpp:522] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0818 10:58:39.315692  3083 net.cpp:522] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0818 10:58:39.315759  3083 net.cpp:172] Setting up Eltwise4_ReLU9_0_split
I0818 10:58:39.315766  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.315773  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.315776  3083 net.cpp:194] Memory required for data: 32891000
I0818 10:58:39.315780  3083 layer_factory.hpp:77] Creating layer Convolution10
I0818 10:58:39.315793  3083 net.cpp:128] Creating Layer Convolution10
I0818 10:58:39.315798  3083 net.cpp:558] Convolution10 <- Eltwise4_ReLU9_0_split_0
I0818 10:58:39.315807  3083 net.cpp:522] Convolution10 -> Convolution10
I0818 10:58:39.328771  3083 net.cpp:172] Setting up Convolution10
I0818 10:58:39.328799  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.328804  3083 net.cpp:194] Memory required for data: 33546360
I0818 10:58:39.328824  3083 layer_factory.hpp:77] Creating layer BatchNorm10
I0818 10:58:39.328835  3083 net.cpp:128] Creating Layer BatchNorm10
I0818 10:58:39.328840  3083 net.cpp:558] BatchNorm10 <- Convolution10
I0818 10:58:39.328850  3083 net.cpp:509] BatchNorm10 -> Convolution10 (in-place)
I0818 10:58:39.329169  3083 net.cpp:172] Setting up BatchNorm10
I0818 10:58:39.329180  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.329185  3083 net.cpp:194] Memory required for data: 34201720
I0818 10:58:39.329195  3083 layer_factory.hpp:77] Creating layer Scale10
I0818 10:58:39.329203  3083 net.cpp:128] Creating Layer Scale10
I0818 10:58:39.329207  3083 net.cpp:558] Scale10 <- Convolution10
I0818 10:58:39.329213  3083 net.cpp:509] Scale10 -> Convolution10 (in-place)
I0818 10:58:39.329270  3083 layer_factory.hpp:77] Creating layer Scale10
I0818 10:58:39.329445  3083 net.cpp:172] Setting up Scale10
I0818 10:58:39.329453  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.329457  3083 net.cpp:194] Memory required for data: 34857080
I0818 10:58:39.329464  3083 layer_factory.hpp:77] Creating layer ReLU10
I0818 10:58:39.329471  3083 net.cpp:128] Creating Layer ReLU10
I0818 10:58:39.329475  3083 net.cpp:558] ReLU10 <- Convolution10
I0818 10:58:39.329483  3083 net.cpp:509] ReLU10 -> Convolution10 (in-place)
I0818 10:58:39.332921  3083 net.cpp:172] Setting up ReLU10
I0818 10:58:39.332940  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.332944  3083 net.cpp:194] Memory required for data: 35512440
I0818 10:58:39.332949  3083 layer_factory.hpp:77] Creating layer Convolution11
I0818 10:58:39.332962  3083 net.cpp:128] Creating Layer Convolution11
I0818 10:58:39.332967  3083 net.cpp:558] Convolution11 <- Convolution10
I0818 10:58:39.332978  3083 net.cpp:522] Convolution11 -> Convolution11
I0818 10:58:39.343701  3083 net.cpp:172] Setting up Convolution11
I0818 10:58:39.343727  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.343732  3083 net.cpp:194] Memory required for data: 36167800
I0818 10:58:39.343742  3083 layer_factory.hpp:77] Creating layer BatchNorm11
I0818 10:58:39.343750  3083 net.cpp:128] Creating Layer BatchNorm11
I0818 10:58:39.343755  3083 net.cpp:558] BatchNorm11 <- Convolution11
I0818 10:58:39.343765  3083 net.cpp:509] BatchNorm11 -> Convolution11 (in-place)
I0818 10:58:39.344086  3083 net.cpp:172] Setting up BatchNorm11
I0818 10:58:39.344094  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.344097  3083 net.cpp:194] Memory required for data: 36823160
I0818 10:58:39.344107  3083 layer_factory.hpp:77] Creating layer Scale11
I0818 10:58:39.344115  3083 net.cpp:128] Creating Layer Scale11
I0818 10:58:39.344118  3083 net.cpp:558] Scale11 <- Convolution11
I0818 10:58:39.344127  3083 net.cpp:509] Scale11 -> Convolution11 (in-place)
I0818 10:58:39.344182  3083 layer_factory.hpp:77] Creating layer Scale11
I0818 10:58:39.344357  3083 net.cpp:172] Setting up Scale11
I0818 10:58:39.344383  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.344388  3083 net.cpp:194] Memory required for data: 37478520
I0818 10:58:39.344395  3083 layer_factory.hpp:77] Creating layer Eltwise5
I0818 10:58:39.344403  3083 net.cpp:128] Creating Layer Eltwise5
I0818 10:58:39.344408  3083 net.cpp:558] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0818 10:58:39.344413  3083 net.cpp:558] Eltwise5 <- Convolution11
I0818 10:58:39.344420  3083 net.cpp:522] Eltwise5 -> Eltwise5
I0818 10:58:39.344453  3083 net.cpp:172] Setting up Eltwise5
I0818 10:58:39.344463  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.344467  3083 net.cpp:194] Memory required for data: 38133880
I0818 10:58:39.344471  3083 layer_factory.hpp:77] Creating layer ReLU11
I0818 10:58:39.344477  3083 net.cpp:128] Creating Layer ReLU11
I0818 10:58:39.344482  3083 net.cpp:558] ReLU11 <- Eltwise5
I0818 10:58:39.344487  3083 net.cpp:509] ReLU11 -> Eltwise5 (in-place)
I0818 10:58:39.345799  3083 net.cpp:172] Setting up ReLU11
I0818 10:58:39.345810  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.345814  3083 net.cpp:194] Memory required for data: 38789240
I0818 10:58:39.345819  3083 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0818 10:58:39.345829  3083 net.cpp:128] Creating Layer Eltwise5_ReLU11_0_split
I0818 10:58:39.345834  3083 net.cpp:558] Eltwise5_ReLU11_0_split <- Eltwise5
I0818 10:58:39.345840  3083 net.cpp:522] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0818 10:58:39.345851  3083 net.cpp:522] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0818 10:58:39.345911  3083 net.cpp:172] Setting up Eltwise5_ReLU11_0_split
I0818 10:58:39.345917  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.345923  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.345927  3083 net.cpp:194] Memory required for data: 40099960
I0818 10:58:39.345932  3083 layer_factory.hpp:77] Creating layer Convolution12
I0818 10:58:39.345945  3083 net.cpp:128] Creating Layer Convolution12
I0818 10:58:39.345950  3083 net.cpp:558] Convolution12 <- Eltwise5_ReLU11_0_split_0
I0818 10:58:39.345957  3083 net.cpp:522] Convolution12 -> Convolution12
I0818 10:58:39.352607  3083 net.cpp:172] Setting up Convolution12
I0818 10:58:39.352634  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.352640  3083 net.cpp:194] Memory required for data: 40755320
I0818 10:58:39.352650  3083 layer_factory.hpp:77] Creating layer BatchNorm12
I0818 10:58:39.352661  3083 net.cpp:128] Creating Layer BatchNorm12
I0818 10:58:39.352666  3083 net.cpp:558] BatchNorm12 <- Convolution12
I0818 10:58:39.352674  3083 net.cpp:509] BatchNorm12 -> Convolution12 (in-place)
I0818 10:58:39.352994  3083 net.cpp:172] Setting up BatchNorm12
I0818 10:58:39.353005  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.353009  3083 net.cpp:194] Memory required for data: 41410680
I0818 10:58:39.353019  3083 layer_factory.hpp:77] Creating layer Scale12
I0818 10:58:39.353026  3083 net.cpp:128] Creating Layer Scale12
I0818 10:58:39.353030  3083 net.cpp:558] Scale12 <- Convolution12
I0818 10:58:39.353035  3083 net.cpp:509] Scale12 -> Convolution12 (in-place)
I0818 10:58:39.353094  3083 layer_factory.hpp:77] Creating layer Scale12
I0818 10:58:39.353273  3083 net.cpp:172] Setting up Scale12
I0818 10:58:39.353283  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.353287  3083 net.cpp:194] Memory required for data: 42066040
I0818 10:58:39.353296  3083 layer_factory.hpp:77] Creating layer ReLU12
I0818 10:58:39.353307  3083 net.cpp:128] Creating Layer ReLU12
I0818 10:58:39.353312  3083 net.cpp:558] ReLU12 <- Convolution12
I0818 10:58:39.353320  3083 net.cpp:509] ReLU12 -> Convolution12 (in-place)
I0818 10:58:39.354706  3083 net.cpp:172] Setting up ReLU12
I0818 10:58:39.354722  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.354725  3083 net.cpp:194] Memory required for data: 42721400
I0818 10:58:39.354730  3083 layer_factory.hpp:77] Creating layer Convolution13
I0818 10:58:39.354760  3083 net.cpp:128] Creating Layer Convolution13
I0818 10:58:39.354765  3083 net.cpp:558] Convolution13 <- Convolution12
I0818 10:58:39.354773  3083 net.cpp:522] Convolution13 -> Convolution13
I0818 10:58:39.363905  3083 net.cpp:172] Setting up Convolution13
I0818 10:58:39.363931  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.363936  3083 net.cpp:194] Memory required for data: 43376760
I0818 10:58:39.363946  3083 layer_factory.hpp:77] Creating layer BatchNorm13
I0818 10:58:39.363956  3083 net.cpp:128] Creating Layer BatchNorm13
I0818 10:58:39.363970  3083 net.cpp:558] BatchNorm13 <- Convolution13
I0818 10:58:39.363978  3083 net.cpp:509] BatchNorm13 -> Convolution13 (in-place)
I0818 10:58:39.364302  3083 net.cpp:172] Setting up BatchNorm13
I0818 10:58:39.364313  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.364317  3083 net.cpp:194] Memory required for data: 44032120
I0818 10:58:39.364327  3083 layer_factory.hpp:77] Creating layer Scale13
I0818 10:58:39.364339  3083 net.cpp:128] Creating Layer Scale13
I0818 10:58:39.364344  3083 net.cpp:558] Scale13 <- Convolution13
I0818 10:58:39.364351  3083 net.cpp:509] Scale13 -> Convolution13 (in-place)
I0818 10:58:39.364408  3083 layer_factory.hpp:77] Creating layer Scale13
I0818 10:58:39.364588  3083 net.cpp:172] Setting up Scale13
I0818 10:58:39.364598  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.364601  3083 net.cpp:194] Memory required for data: 44687480
I0818 10:58:39.364609  3083 layer_factory.hpp:77] Creating layer Eltwise6
I0818 10:58:39.364629  3083 net.cpp:128] Creating Layer Eltwise6
I0818 10:58:39.364637  3083 net.cpp:558] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0818 10:58:39.364642  3083 net.cpp:558] Eltwise6 <- Convolution13
I0818 10:58:39.364650  3083 net.cpp:522] Eltwise6 -> Eltwise6
I0818 10:58:39.364681  3083 net.cpp:172] Setting up Eltwise6
I0818 10:58:39.364687  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.364691  3083 net.cpp:194] Memory required for data: 45342840
I0818 10:58:39.364696  3083 layer_factory.hpp:77] Creating layer ReLU13
I0818 10:58:39.364702  3083 net.cpp:128] Creating Layer ReLU13
I0818 10:58:39.364706  3083 net.cpp:558] ReLU13 <- Eltwise6
I0818 10:58:39.364712  3083 net.cpp:509] ReLU13 -> Eltwise6 (in-place)
I0818 10:58:39.368062  3083 net.cpp:172] Setting up ReLU13
I0818 10:58:39.368088  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.368093  3083 net.cpp:194] Memory required for data: 45998200
I0818 10:58:39.368098  3083 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0818 10:58:39.368108  3083 net.cpp:128] Creating Layer Eltwise6_ReLU13_0_split
I0818 10:58:39.368113  3083 net.cpp:558] Eltwise6_ReLU13_0_split <- Eltwise6
I0818 10:58:39.368124  3083 net.cpp:522] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0818 10:58:39.368137  3083 net.cpp:522] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0818 10:58:39.368206  3083 net.cpp:172] Setting up Eltwise6_ReLU13_0_split
I0818 10:58:39.368216  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.368221  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.368225  3083 net.cpp:194] Memory required for data: 47308920
I0818 10:58:39.368229  3083 layer_factory.hpp:77] Creating layer Convolution14
I0818 10:58:39.368242  3083 net.cpp:128] Creating Layer Convolution14
I0818 10:58:39.368247  3083 net.cpp:558] Convolution14 <- Eltwise6_ReLU13_0_split_0
I0818 10:58:39.368253  3083 net.cpp:522] Convolution14 -> Convolution14
I0818 10:58:39.381214  3083 net.cpp:172] Setting up Convolution14
I0818 10:58:39.381240  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.381244  3083 net.cpp:194] Memory required for data: 47964280
I0818 10:58:39.381254  3083 layer_factory.hpp:77] Creating layer BatchNorm14
I0818 10:58:39.381266  3083 net.cpp:128] Creating Layer BatchNorm14
I0818 10:58:39.381271  3083 net.cpp:558] BatchNorm14 <- Convolution14
I0818 10:58:39.381278  3083 net.cpp:509] BatchNorm14 -> Convolution14 (in-place)
I0818 10:58:39.381624  3083 net.cpp:172] Setting up BatchNorm14
I0818 10:58:39.381637  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.381641  3083 net.cpp:194] Memory required for data: 48619640
I0818 10:58:39.381651  3083 layer_factory.hpp:77] Creating layer Scale14
I0818 10:58:39.381659  3083 net.cpp:128] Creating Layer Scale14
I0818 10:58:39.381664  3083 net.cpp:558] Scale14 <- Convolution14
I0818 10:58:39.381669  3083 net.cpp:509] Scale14 -> Convolution14 (in-place)
I0818 10:58:39.381729  3083 layer_factory.hpp:77] Creating layer Scale14
I0818 10:58:39.381916  3083 net.cpp:172] Setting up Scale14
I0818 10:58:39.381927  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.381932  3083 net.cpp:194] Memory required for data: 49275000
I0818 10:58:39.381940  3083 layer_factory.hpp:77] Creating layer ReLU14
I0818 10:58:39.381947  3083 net.cpp:128] Creating Layer ReLU14
I0818 10:58:39.381950  3083 net.cpp:558] ReLU14 <- Convolution14
I0818 10:58:39.381959  3083 net.cpp:509] ReLU14 -> Convolution14 (in-place)
I0818 10:58:39.385377  3083 net.cpp:172] Setting up ReLU14
I0818 10:58:39.385396  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.385401  3083 net.cpp:194] Memory required for data: 49930360
I0818 10:58:39.385406  3083 layer_factory.hpp:77] Creating layer Convolution15
I0818 10:58:39.385419  3083 net.cpp:128] Creating Layer Convolution15
I0818 10:58:39.385426  3083 net.cpp:558] Convolution15 <- Convolution14
I0818 10:58:39.385435  3083 net.cpp:522] Convolution15 -> Convolution15
I0818 10:58:39.393671  3083 net.cpp:172] Setting up Convolution15
I0818 10:58:39.393697  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.393700  3083 net.cpp:194] Memory required for data: 50585720
I0818 10:58:39.393710  3083 layer_factory.hpp:77] Creating layer BatchNorm15
I0818 10:58:39.393721  3083 net.cpp:128] Creating Layer BatchNorm15
I0818 10:58:39.393726  3083 net.cpp:558] BatchNorm15 <- Convolution15
I0818 10:58:39.393734  3083 net.cpp:509] BatchNorm15 -> Convolution15 (in-place)
I0818 10:58:39.394063  3083 net.cpp:172] Setting up BatchNorm15
I0818 10:58:39.394074  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.394079  3083 net.cpp:194] Memory required for data: 51241080
I0818 10:58:39.394089  3083 layer_factory.hpp:77] Creating layer Scale15
I0818 10:58:39.394098  3083 net.cpp:128] Creating Layer Scale15
I0818 10:58:39.394104  3083 net.cpp:558] Scale15 <- Convolution15
I0818 10:58:39.394109  3083 net.cpp:509] Scale15 -> Convolution15 (in-place)
I0818 10:58:39.394165  3083 layer_factory.hpp:77] Creating layer Scale15
I0818 10:58:39.394351  3083 net.cpp:172] Setting up Scale15
I0818 10:58:39.394362  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.394366  3083 net.cpp:194] Memory required for data: 51896440
I0818 10:58:39.394374  3083 layer_factory.hpp:77] Creating layer Eltwise7
I0818 10:58:39.394383  3083 net.cpp:128] Creating Layer Eltwise7
I0818 10:58:39.394388  3083 net.cpp:558] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I0818 10:58:39.394393  3083 net.cpp:558] Eltwise7 <- Convolution15
I0818 10:58:39.394402  3083 net.cpp:522] Eltwise7 -> Eltwise7
I0818 10:58:39.394433  3083 net.cpp:172] Setting up Eltwise7
I0818 10:58:39.394443  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.394448  3083 net.cpp:194] Memory required for data: 52551800
I0818 10:58:39.394453  3083 layer_factory.hpp:77] Creating layer ReLU15
I0818 10:58:39.394460  3083 net.cpp:128] Creating Layer ReLU15
I0818 10:58:39.394465  3083 net.cpp:558] ReLU15 <- Eltwise7
I0818 10:58:39.394471  3083 net.cpp:509] ReLU15 -> Eltwise7 (in-place)
I0818 10:58:39.395748  3083 net.cpp:172] Setting up ReLU15
I0818 10:58:39.395768  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.395772  3083 net.cpp:194] Memory required for data: 53207160
I0818 10:58:39.395777  3083 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0818 10:58:39.395787  3083 net.cpp:128] Creating Layer Eltwise7_ReLU15_0_split
I0818 10:58:39.395792  3083 net.cpp:558] Eltwise7_ReLU15_0_split <- Eltwise7
I0818 10:58:39.395814  3083 net.cpp:522] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0818 10:58:39.395825  3083 net.cpp:522] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0818 10:58:39.395889  3083 net.cpp:172] Setting up Eltwise7_ReLU15_0_split
I0818 10:58:39.395900  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.395906  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.395910  3083 net.cpp:194] Memory required for data: 54517880
I0818 10:58:39.395915  3083 layer_factory.hpp:77] Creating layer Convolution16
I0818 10:58:39.395926  3083 net.cpp:128] Creating Layer Convolution16
I0818 10:58:39.395931  3083 net.cpp:558] Convolution16 <- Eltwise7_ReLU15_0_split_0
I0818 10:58:39.395941  3083 net.cpp:522] Convolution16 -> Convolution16
I0818 10:58:39.404713  3083 net.cpp:172] Setting up Convolution16
I0818 10:58:39.404759  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.404774  3083 net.cpp:194] Memory required for data: 55173240
I0818 10:58:39.404794  3083 layer_factory.hpp:77] Creating layer BatchNorm16
I0818 10:58:39.404815  3083 net.cpp:128] Creating Layer BatchNorm16
I0818 10:58:39.404830  3083 net.cpp:558] BatchNorm16 <- Convolution16
I0818 10:58:39.404847  3083 net.cpp:509] BatchNorm16 -> Convolution16 (in-place)
I0818 10:58:39.405256  3083 net.cpp:172] Setting up BatchNorm16
I0818 10:58:39.405287  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.405306  3083 net.cpp:194] Memory required for data: 55828600
I0818 10:58:39.405333  3083 layer_factory.hpp:77] Creating layer Scale16
I0818 10:58:39.405354  3083 net.cpp:128] Creating Layer Scale16
I0818 10:58:39.405371  3083 net.cpp:558] Scale16 <- Convolution16
I0818 10:58:39.405391  3083 net.cpp:509] Scale16 -> Convolution16 (in-place)
I0818 10:58:39.405478  3083 layer_factory.hpp:77] Creating layer Scale16
I0818 10:58:39.405683  3083 net.cpp:172] Setting up Scale16
I0818 10:58:39.405707  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.405725  3083 net.cpp:194] Memory required for data: 56483960
I0818 10:58:39.405748  3083 layer_factory.hpp:77] Creating layer ReLU16
I0818 10:58:39.405767  3083 net.cpp:128] Creating Layer ReLU16
I0818 10:58:39.405786  3083 net.cpp:558] ReLU16 <- Convolution16
I0818 10:58:39.405807  3083 net.cpp:509] ReLU16 -> Convolution16 (in-place)
I0818 10:58:39.408882  3083 net.cpp:172] Setting up ReLU16
I0818 10:58:39.408908  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.408913  3083 net.cpp:194] Memory required for data: 57139320
I0818 10:58:39.408918  3083 layer_factory.hpp:77] Creating layer Convolution17
I0818 10:58:39.408932  3083 net.cpp:128] Creating Layer Convolution17
I0818 10:58:39.408965  3083 net.cpp:558] Convolution17 <- Convolution16
I0818 10:58:39.408989  3083 net.cpp:522] Convolution17 -> Convolution17
I0818 10:58:39.422005  3083 net.cpp:172] Setting up Convolution17
I0818 10:58:39.422034  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.422039  3083 net.cpp:194] Memory required for data: 57794680
I0818 10:58:39.422049  3083 layer_factory.hpp:77] Creating layer BatchNorm17
I0818 10:58:39.422056  3083 net.cpp:128] Creating Layer BatchNorm17
I0818 10:58:39.422061  3083 net.cpp:558] BatchNorm17 <- Convolution17
I0818 10:58:39.422070  3083 net.cpp:509] BatchNorm17 -> Convolution17 (in-place)
I0818 10:58:39.422408  3083 net.cpp:172] Setting up BatchNorm17
I0818 10:58:39.422456  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.422475  3083 net.cpp:194] Memory required for data: 58450040
I0818 10:58:39.422502  3083 layer_factory.hpp:77] Creating layer Scale17
I0818 10:58:39.422523  3083 net.cpp:128] Creating Layer Scale17
I0818 10:58:39.422538  3083 net.cpp:558] Scale17 <- Convolution17
I0818 10:58:39.422560  3083 net.cpp:509] Scale17 -> Convolution17 (in-place)
I0818 10:58:39.422642  3083 layer_factory.hpp:77] Creating layer Scale17
I0818 10:58:39.422854  3083 net.cpp:172] Setting up Scale17
I0818 10:58:39.422881  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.422899  3083 net.cpp:194] Memory required for data: 59105400
I0818 10:58:39.422935  3083 layer_factory.hpp:77] Creating layer Eltwise8
I0818 10:58:39.422958  3083 net.cpp:128] Creating Layer Eltwise8
I0818 10:58:39.422976  3083 net.cpp:558] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0818 10:58:39.422996  3083 net.cpp:558] Eltwise8 <- Convolution17
I0818 10:58:39.423015  3083 net.cpp:522] Eltwise8 -> Eltwise8
I0818 10:58:39.423074  3083 net.cpp:172] Setting up Eltwise8
I0818 10:58:39.423096  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.423115  3083 net.cpp:194] Memory required for data: 59760760
I0818 10:58:39.423131  3083 layer_factory.hpp:77] Creating layer ReLU17
I0818 10:58:39.423151  3083 net.cpp:128] Creating Layer ReLU17
I0818 10:58:39.423166  3083 net.cpp:558] ReLU17 <- Eltwise8
I0818 10:58:39.423183  3083 net.cpp:509] ReLU17 -> Eltwise8 (in-place)
I0818 10:58:39.426234  3083 net.cpp:172] Setting up ReLU17
I0818 10:58:39.426254  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.426259  3083 net.cpp:194] Memory required for data: 60416120
I0818 10:58:39.426265  3083 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0818 10:58:39.426275  3083 net.cpp:128] Creating Layer Eltwise8_ReLU17_0_split
I0818 10:58:39.426280  3083 net.cpp:558] Eltwise8_ReLU17_0_split <- Eltwise8
I0818 10:58:39.426287  3083 net.cpp:522] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0818 10:58:39.426295  3083 net.cpp:522] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0818 10:58:39.426360  3083 net.cpp:172] Setting up Eltwise8_ReLU17_0_split
I0818 10:58:39.426400  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.426420  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.426437  3083 net.cpp:194] Memory required for data: 61726840
I0818 10:58:39.426455  3083 layer_factory.hpp:77] Creating layer Convolution18
I0818 10:58:39.426481  3083 net.cpp:128] Creating Layer Convolution18
I0818 10:58:39.426499  3083 net.cpp:558] Convolution18 <- Eltwise8_ReLU17_0_split_0
I0818 10:58:39.426522  3083 net.cpp:522] Convolution18 -> Convolution18
I0818 10:58:39.435402  3083 net.cpp:172] Setting up Convolution18
I0818 10:58:39.435425  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.435429  3083 net.cpp:194] Memory required for data: 62382200
I0818 10:58:39.435441  3083 layer_factory.hpp:77] Creating layer BatchNorm18
I0818 10:58:39.435448  3083 net.cpp:128] Creating Layer BatchNorm18
I0818 10:58:39.435453  3083 net.cpp:558] BatchNorm18 <- Convolution18
I0818 10:58:39.435490  3083 net.cpp:509] BatchNorm18 -> Convolution18 (in-place)
I0818 10:58:39.435837  3083 net.cpp:172] Setting up BatchNorm18
I0818 10:58:39.435847  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.435851  3083 net.cpp:194] Memory required for data: 63037560
I0818 10:58:39.435885  3083 layer_factory.hpp:77] Creating layer Scale18
I0818 10:58:39.435895  3083 net.cpp:128] Creating Layer Scale18
I0818 10:58:39.435900  3083 net.cpp:558] Scale18 <- Convolution18
I0818 10:58:39.435912  3083 net.cpp:509] Scale18 -> Convolution18 (in-place)
I0818 10:58:39.435979  3083 layer_factory.hpp:77] Creating layer Scale18
I0818 10:58:39.436178  3083 net.cpp:172] Setting up Scale18
I0818 10:58:39.436211  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.436219  3083 net.cpp:194] Memory required for data: 63692920
I0818 10:58:39.436229  3083 layer_factory.hpp:77] Creating layer ReLU18
I0818 10:58:39.436237  3083 net.cpp:128] Creating Layer ReLU18
I0818 10:58:39.436241  3083 net.cpp:558] ReLU18 <- Convolution18
I0818 10:58:39.436247  3083 net.cpp:509] ReLU18 -> Convolution18 (in-place)
I0818 10:58:39.437475  3083 net.cpp:172] Setting up ReLU18
I0818 10:58:39.437515  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.437533  3083 net.cpp:194] Memory required for data: 64348280
I0818 10:58:39.437551  3083 layer_factory.hpp:77] Creating layer Convolution19
I0818 10:58:39.437577  3083 net.cpp:128] Creating Layer Convolution19
I0818 10:58:39.437598  3083 net.cpp:558] Convolution19 <- Convolution18
I0818 10:58:39.437633  3083 net.cpp:522] Convolution19 -> Convolution19
I0818 10:58:39.444358  3083 net.cpp:172] Setting up Convolution19
I0818 10:58:39.444381  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.444386  3083 net.cpp:194] Memory required for data: 65003640
I0818 10:58:39.444396  3083 layer_factory.hpp:77] Creating layer BatchNorm19
I0818 10:58:39.444408  3083 net.cpp:128] Creating Layer BatchNorm19
I0818 10:58:39.444413  3083 net.cpp:558] BatchNorm19 <- Convolution19
I0818 10:58:39.444422  3083 net.cpp:509] BatchNorm19 -> Convolution19 (in-place)
I0818 10:58:39.444756  3083 net.cpp:172] Setting up BatchNorm19
I0818 10:58:39.444766  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.444770  3083 net.cpp:194] Memory required for data: 65659000
I0818 10:58:39.444792  3083 layer_factory.hpp:77] Creating layer Scale19
I0818 10:58:39.444829  3083 net.cpp:128] Creating Layer Scale19
I0818 10:58:39.444847  3083 net.cpp:558] Scale19 <- Convolution19
I0818 10:58:39.444866  3083 net.cpp:509] Scale19 -> Convolution19 (in-place)
I0818 10:58:39.444998  3083 layer_factory.hpp:77] Creating layer Scale19
I0818 10:58:39.445209  3083 net.cpp:172] Setting up Scale19
I0818 10:58:39.445221  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.445241  3083 net.cpp:194] Memory required for data: 66314360
I0818 10:58:39.445271  3083 layer_factory.hpp:77] Creating layer Eltwise9
I0818 10:58:39.445293  3083 net.cpp:128] Creating Layer Eltwise9
I0818 10:58:39.445312  3083 net.cpp:558] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0818 10:58:39.445328  3083 net.cpp:558] Eltwise9 <- Convolution19
I0818 10:58:39.445348  3083 net.cpp:522] Eltwise9 -> Eltwise9
I0818 10:58:39.445400  3083 net.cpp:172] Setting up Eltwise9
I0818 10:58:39.445422  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.445437  3083 net.cpp:194] Memory required for data: 66969720
I0818 10:58:39.445453  3083 layer_factory.hpp:77] Creating layer ReLU19
I0818 10:58:39.445473  3083 net.cpp:128] Creating Layer ReLU19
I0818 10:58:39.445490  3083 net.cpp:558] ReLU19 <- Eltwise9
I0818 10:58:39.445510  3083 net.cpp:509] ReLU19 -> Eltwise9 (in-place)
I0818 10:58:39.446454  3083 net.cpp:172] Setting up ReLU19
I0818 10:58:39.446476  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.446480  3083 net.cpp:194] Memory required for data: 67625080
I0818 10:58:39.446485  3083 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I0818 10:58:39.446493  3083 net.cpp:128] Creating Layer Eltwise9_ReLU19_0_split
I0818 10:58:39.446498  3083 net.cpp:558] Eltwise9_ReLU19_0_split <- Eltwise9
I0818 10:58:39.446508  3083 net.cpp:522] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I0818 10:58:39.446521  3083 net.cpp:522] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I0818 10:58:39.446588  3083 net.cpp:172] Setting up Eltwise9_ReLU19_0_split
I0818 10:58:39.446595  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.446601  3083 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0818 10:58:39.446605  3083 net.cpp:194] Memory required for data: 68935800
I0818 10:58:39.446610  3083 layer_factory.hpp:77] Creating layer Convolution20
I0818 10:58:39.446624  3083 net.cpp:128] Creating Layer Convolution20
I0818 10:58:39.446630  3083 net.cpp:558] Convolution20 <- Eltwise9_ReLU19_0_split_0
I0818 10:58:39.446641  3083 net.cpp:522] Convolution20 -> Convolution20
I0818 10:58:39.453691  3083 net.cpp:172] Setting up Convolution20
I0818 10:58:39.453716  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.453721  3083 net.cpp:194] Memory required for data: 69263480
I0818 10:58:39.453730  3083 layer_factory.hpp:77] Creating layer BatchNorm20
I0818 10:58:39.453745  3083 net.cpp:128] Creating Layer BatchNorm20
I0818 10:58:39.453750  3083 net.cpp:558] BatchNorm20 <- Convolution20
I0818 10:58:39.453758  3083 net.cpp:509] BatchNorm20 -> Convolution20 (in-place)
I0818 10:58:39.454082  3083 net.cpp:172] Setting up BatchNorm20
I0818 10:58:39.454092  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.454131  3083 net.cpp:194] Memory required for data: 69591160
I0818 10:58:39.454143  3083 layer_factory.hpp:77] Creating layer Scale20
I0818 10:58:39.454150  3083 net.cpp:128] Creating Layer Scale20
I0818 10:58:39.454155  3083 net.cpp:558] Scale20 <- Convolution20
I0818 10:58:39.454164  3083 net.cpp:509] Scale20 -> Convolution20 (in-place)
I0818 10:58:39.454227  3083 layer_factory.hpp:77] Creating layer Scale20
I0818 10:58:39.454414  3083 net.cpp:172] Setting up Scale20
I0818 10:58:39.454442  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.454448  3083 net.cpp:194] Memory required for data: 69918840
I0818 10:58:39.454457  3083 layer_factory.hpp:77] Creating layer Convolution21
I0818 10:58:39.454469  3083 net.cpp:128] Creating Layer Convolution21
I0818 10:58:39.454474  3083 net.cpp:558] Convolution21 <- Eltwise9_ReLU19_0_split_1
I0818 10:58:39.454484  3083 net.cpp:522] Convolution21 -> Convolution21
I0818 10:58:39.464848  3083 net.cpp:172] Setting up Convolution21
I0818 10:58:39.464875  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.464879  3083 net.cpp:194] Memory required for data: 70246520
I0818 10:58:39.464891  3083 layer_factory.hpp:77] Creating layer BatchNorm21
I0818 10:58:39.464900  3083 net.cpp:128] Creating Layer BatchNorm21
I0818 10:58:39.464905  3083 net.cpp:558] BatchNorm21 <- Convolution21
I0818 10:58:39.464913  3083 net.cpp:509] BatchNorm21 -> Convolution21 (in-place)
I0818 10:58:39.465235  3083 net.cpp:172] Setting up BatchNorm21
I0818 10:58:39.465248  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.465252  3083 net.cpp:194] Memory required for data: 70574200
I0818 10:58:39.465262  3083 layer_factory.hpp:77] Creating layer Scale21
I0818 10:58:39.465270  3083 net.cpp:128] Creating Layer Scale21
I0818 10:58:39.465273  3083 net.cpp:558] Scale21 <- Convolution21
I0818 10:58:39.465282  3083 net.cpp:509] Scale21 -> Convolution21 (in-place)
I0818 10:58:39.465337  3083 layer_factory.hpp:77] Creating layer Scale21
I0818 10:58:39.465517  3083 net.cpp:172] Setting up Scale21
I0818 10:58:39.465528  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.465533  3083 net.cpp:194] Memory required for data: 70901880
I0818 10:58:39.465539  3083 layer_factory.hpp:77] Creating layer ReLU20
I0818 10:58:39.465546  3083 net.cpp:128] Creating Layer ReLU20
I0818 10:58:39.465550  3083 net.cpp:558] ReLU20 <- Convolution21
I0818 10:58:39.465556  3083 net.cpp:509] ReLU20 -> Convolution21 (in-place)
I0818 10:58:39.466895  3083 net.cpp:172] Setting up ReLU20
I0818 10:58:39.466912  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.466917  3083 net.cpp:194] Memory required for data: 71229560
I0818 10:58:39.466922  3083 layer_factory.hpp:77] Creating layer Convolution22
I0818 10:58:39.466935  3083 net.cpp:128] Creating Layer Convolution22
I0818 10:58:39.466941  3083 net.cpp:558] Convolution22 <- Convolution21
I0818 10:58:39.466951  3083 net.cpp:522] Convolution22 -> Convolution22
I0818 10:58:39.472879  3083 net.cpp:172] Setting up Convolution22
I0818 10:58:39.472905  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.472909  3083 net.cpp:194] Memory required for data: 71557240
I0818 10:58:39.472919  3083 layer_factory.hpp:77] Creating layer BatchNorm22
I0818 10:58:39.472930  3083 net.cpp:128] Creating Layer BatchNorm22
I0818 10:58:39.472935  3083 net.cpp:558] BatchNorm22 <- Convolution22
I0818 10:58:39.472944  3083 net.cpp:509] BatchNorm22 -> Convolution22 (in-place)
I0818 10:58:39.473268  3083 net.cpp:172] Setting up BatchNorm22
I0818 10:58:39.473279  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.473284  3083 net.cpp:194] Memory required for data: 71884920
I0818 10:58:39.473294  3083 layer_factory.hpp:77] Creating layer Scale22
I0818 10:58:39.473300  3083 net.cpp:128] Creating Layer Scale22
I0818 10:58:39.473304  3083 net.cpp:558] Scale22 <- Convolution22
I0818 10:58:39.473310  3083 net.cpp:509] Scale22 -> Convolution22 (in-place)
I0818 10:58:39.473369  3083 layer_factory.hpp:77] Creating layer Scale22
I0818 10:58:39.473549  3083 net.cpp:172] Setting up Scale22
I0818 10:58:39.473577  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.473582  3083 net.cpp:194] Memory required for data: 72212600
I0818 10:58:39.473589  3083 layer_factory.hpp:77] Creating layer Eltwise10
I0818 10:58:39.473599  3083 net.cpp:128] Creating Layer Eltwise10
I0818 10:58:39.473604  3083 net.cpp:558] Eltwise10 <- Convolution20
I0818 10:58:39.473609  3083 net.cpp:558] Eltwise10 <- Convolution22
I0818 10:58:39.473615  3083 net.cpp:522] Eltwise10 -> Eltwise10
I0818 10:58:39.473646  3083 net.cpp:172] Setting up Eltwise10
I0818 10:58:39.473654  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.473657  3083 net.cpp:194] Memory required for data: 72540280
I0818 10:58:39.473661  3083 layer_factory.hpp:77] Creating layer ReLU21
I0818 10:58:39.473667  3083 net.cpp:128] Creating Layer ReLU21
I0818 10:58:39.473671  3083 net.cpp:558] ReLU21 <- Eltwise10
I0818 10:58:39.473680  3083 net.cpp:509] ReLU21 -> Eltwise10 (in-place)
I0818 10:58:39.473950  3083 net.cpp:172] Setting up ReLU21
I0818 10:58:39.473960  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.473965  3083 net.cpp:194] Memory required for data: 72867960
I0818 10:58:39.473969  3083 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I0818 10:58:39.473978  3083 net.cpp:128] Creating Layer Eltwise10_ReLU21_0_split
I0818 10:58:39.473984  3083 net.cpp:558] Eltwise10_ReLU21_0_split <- Eltwise10
I0818 10:58:39.473991  3083 net.cpp:522] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I0818 10:58:39.474000  3083 net.cpp:522] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I0818 10:58:39.474061  3083 net.cpp:172] Setting up Eltwise10_ReLU21_0_split
I0818 10:58:39.474073  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.474079  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.474083  3083 net.cpp:194] Memory required for data: 73523320
I0818 10:58:39.474087  3083 layer_factory.hpp:77] Creating layer Convolution23
I0818 10:58:39.474098  3083 net.cpp:128] Creating Layer Convolution23
I0818 10:58:39.474103  3083 net.cpp:558] Convolution23 <- Eltwise10_ReLU21_0_split_0
I0818 10:58:39.474112  3083 net.cpp:522] Convolution23 -> Convolution23
I0818 10:58:39.477174  3083 net.cpp:172] Setting up Convolution23
I0818 10:58:39.477198  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.477203  3083 net.cpp:194] Memory required for data: 73851000
I0818 10:58:39.477213  3083 layer_factory.hpp:77] Creating layer BatchNorm23
I0818 10:58:39.477227  3083 net.cpp:128] Creating Layer BatchNorm23
I0818 10:58:39.477232  3083 net.cpp:558] BatchNorm23 <- Convolution23
I0818 10:58:39.477241  3083 net.cpp:509] BatchNorm23 -> Convolution23 (in-place)
I0818 10:58:39.477560  3083 net.cpp:172] Setting up BatchNorm23
I0818 10:58:39.477576  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.477579  3083 net.cpp:194] Memory required for data: 74178680
I0818 10:58:39.477589  3083 layer_factory.hpp:77] Creating layer Scale23
I0818 10:58:39.477600  3083 net.cpp:128] Creating Layer Scale23
I0818 10:58:39.477605  3083 net.cpp:558] Scale23 <- Convolution23
I0818 10:58:39.477610  3083 net.cpp:509] Scale23 -> Convolution23 (in-place)
I0818 10:58:39.477669  3083 layer_factory.hpp:77] Creating layer Scale23
I0818 10:58:39.477851  3083 net.cpp:172] Setting up Scale23
I0818 10:58:39.477862  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.477867  3083 net.cpp:194] Memory required for data: 74506360
I0818 10:58:39.477874  3083 layer_factory.hpp:77] Creating layer ReLU22
I0818 10:58:39.477883  3083 net.cpp:128] Creating Layer ReLU22
I0818 10:58:39.477887  3083 net.cpp:558] ReLU22 <- Convolution23
I0818 10:58:39.477931  3083 net.cpp:509] ReLU22 -> Convolution23 (in-place)
I0818 10:58:39.478202  3083 net.cpp:172] Setting up ReLU22
I0818 10:58:39.478220  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.478224  3083 net.cpp:194] Memory required for data: 74834040
I0818 10:58:39.478229  3083 layer_factory.hpp:77] Creating layer Convolution24
I0818 10:58:39.478261  3083 net.cpp:128] Creating Layer Convolution24
I0818 10:58:39.478267  3083 net.cpp:558] Convolution24 <- Convolution23
I0818 10:58:39.478276  3083 net.cpp:522] Convolution24 -> Convolution24
I0818 10:58:39.480048  3083 net.cpp:172] Setting up Convolution24
I0818 10:58:39.480075  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.480080  3083 net.cpp:194] Memory required for data: 75161720
I0818 10:58:39.480090  3083 layer_factory.hpp:77] Creating layer BatchNorm24
I0818 10:58:39.480101  3083 net.cpp:128] Creating Layer BatchNorm24
I0818 10:58:39.480110  3083 net.cpp:558] BatchNorm24 <- Convolution24
I0818 10:58:39.480119  3083 net.cpp:509] BatchNorm24 -> Convolution24 (in-place)
I0818 10:58:39.480453  3083 net.cpp:172] Setting up BatchNorm24
I0818 10:58:39.480464  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.480468  3083 net.cpp:194] Memory required for data: 75489400
I0818 10:58:39.480479  3083 layer_factory.hpp:77] Creating layer Scale24
I0818 10:58:39.480504  3083 net.cpp:128] Creating Layer Scale24
I0818 10:58:39.480509  3083 net.cpp:558] Scale24 <- Convolution24
I0818 10:58:39.480517  3083 net.cpp:509] Scale24 -> Convolution24 (in-place)
I0818 10:58:39.480576  3083 layer_factory.hpp:77] Creating layer Scale24
I0818 10:58:39.480765  3083 net.cpp:172] Setting up Scale24
I0818 10:58:39.480775  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.480779  3083 net.cpp:194] Memory required for data: 75817080
I0818 10:58:39.480787  3083 layer_factory.hpp:77] Creating layer Eltwise11
I0818 10:58:39.480798  3083 net.cpp:128] Creating Layer Eltwise11
I0818 10:58:39.480803  3083 net.cpp:558] Eltwise11 <- Eltwise10_ReLU21_0_split_1
I0818 10:58:39.480808  3083 net.cpp:558] Eltwise11 <- Convolution24
I0818 10:58:39.480815  3083 net.cpp:522] Eltwise11 -> Eltwise11
I0818 10:58:39.480857  3083 net.cpp:172] Setting up Eltwise11
I0818 10:58:39.480866  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.480872  3083 net.cpp:194] Memory required for data: 76144760
I0818 10:58:39.480876  3083 layer_factory.hpp:77] Creating layer ReLU23
I0818 10:58:39.480883  3083 net.cpp:128] Creating Layer ReLU23
I0818 10:58:39.480887  3083 net.cpp:558] ReLU23 <- Eltwise11
I0818 10:58:39.480892  3083 net.cpp:509] ReLU23 -> Eltwise11 (in-place)
I0818 10:58:39.481518  3083 net.cpp:172] Setting up ReLU23
I0818 10:58:39.481540  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.481544  3083 net.cpp:194] Memory required for data: 76472440
I0818 10:58:39.481549  3083 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I0818 10:58:39.481559  3083 net.cpp:128] Creating Layer Eltwise11_ReLU23_0_split
I0818 10:58:39.481564  3083 net.cpp:558] Eltwise11_ReLU23_0_split <- Eltwise11
I0818 10:58:39.481577  3083 net.cpp:522] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I0818 10:58:39.481590  3083 net.cpp:522] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I0818 10:58:39.481657  3083 net.cpp:172] Setting up Eltwise11_ReLU23_0_split
I0818 10:58:39.481670  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.481679  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.481685  3083 net.cpp:194] Memory required for data: 77127800
I0818 10:58:39.481690  3083 layer_factory.hpp:77] Creating layer Convolution25
I0818 10:58:39.481704  3083 net.cpp:128] Creating Layer Convolution25
I0818 10:58:39.481711  3083 net.cpp:558] Convolution25 <- Eltwise11_ReLU23_0_split_0
I0818 10:58:39.481719  3083 net.cpp:522] Convolution25 -> Convolution25
I0818 10:58:39.487248  3083 net.cpp:172] Setting up Convolution25
I0818 10:58:39.487278  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.487283  3083 net.cpp:194] Memory required for data: 77455480
I0818 10:58:39.487294  3083 layer_factory.hpp:77] Creating layer BatchNorm25
I0818 10:58:39.487303  3083 net.cpp:128] Creating Layer BatchNorm25
I0818 10:58:39.487313  3083 net.cpp:558] BatchNorm25 <- Convolution25
I0818 10:58:39.487323  3083 net.cpp:509] BatchNorm25 -> Convolution25 (in-place)
I0818 10:58:39.487715  3083 net.cpp:172] Setting up BatchNorm25
I0818 10:58:39.487741  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.487747  3083 net.cpp:194] Memory required for data: 77783160
I0818 10:58:39.487759  3083 layer_factory.hpp:77] Creating layer Scale25
I0818 10:58:39.487772  3083 net.cpp:128] Creating Layer Scale25
I0818 10:58:39.487781  3083 net.cpp:558] Scale25 <- Convolution25
I0818 10:58:39.487787  3083 net.cpp:509] Scale25 -> Convolution25 (in-place)
I0818 10:58:39.487854  3083 layer_factory.hpp:77] Creating layer Scale25
I0818 10:58:39.488046  3083 net.cpp:172] Setting up Scale25
I0818 10:58:39.488057  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.488061  3083 net.cpp:194] Memory required for data: 78110840
I0818 10:58:39.488072  3083 layer_factory.hpp:77] Creating layer ReLU24
I0818 10:58:39.488085  3083 net.cpp:128] Creating Layer ReLU24
I0818 10:58:39.488092  3083 net.cpp:558] ReLU24 <- Convolution25
I0818 10:58:39.488098  3083 net.cpp:509] ReLU24 -> Convolution25 (in-place)
I0818 10:58:39.488996  3083 net.cpp:172] Setting up ReLU24
I0818 10:58:39.489014  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.489019  3083 net.cpp:194] Memory required for data: 78438520
I0818 10:58:39.489024  3083 layer_factory.hpp:77] Creating layer Convolution26
I0818 10:58:39.489039  3083 net.cpp:128] Creating Layer Convolution26
I0818 10:58:39.489046  3083 net.cpp:558] Convolution26 <- Convolution25
I0818 10:58:39.489055  3083 net.cpp:522] Convolution26 -> Convolution26
I0818 10:58:39.494333  3083 net.cpp:172] Setting up Convolution26
I0818 10:58:39.494362  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.494367  3083 net.cpp:194] Memory required for data: 78766200
I0818 10:58:39.494379  3083 layer_factory.hpp:77] Creating layer BatchNorm26
I0818 10:58:39.494388  3083 net.cpp:128] Creating Layer BatchNorm26
I0818 10:58:39.494393  3083 net.cpp:558] BatchNorm26 <- Convolution26
I0818 10:58:39.494402  3083 net.cpp:509] BatchNorm26 -> Convolution26 (in-place)
I0818 10:58:39.494758  3083 net.cpp:172] Setting up BatchNorm26
I0818 10:58:39.494772  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.494777  3083 net.cpp:194] Memory required for data: 79093880
I0818 10:58:39.494787  3083 layer_factory.hpp:77] Creating layer Scale26
I0818 10:58:39.494794  3083 net.cpp:128] Creating Layer Scale26
I0818 10:58:39.494798  3083 net.cpp:558] Scale26 <- Convolution26
I0818 10:58:39.494807  3083 net.cpp:509] Scale26 -> Convolution26 (in-place)
I0818 10:58:39.494869  3083 layer_factory.hpp:77] Creating layer Scale26
I0818 10:58:39.495103  3083 net.cpp:172] Setting up Scale26
I0818 10:58:39.495115  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.495120  3083 net.cpp:194] Memory required for data: 79421560
I0818 10:58:39.495128  3083 layer_factory.hpp:77] Creating layer Eltwise12
I0818 10:58:39.495139  3083 net.cpp:128] Creating Layer Eltwise12
I0818 10:58:39.495144  3083 net.cpp:558] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I0818 10:58:39.495151  3083 net.cpp:558] Eltwise12 <- Convolution26
I0818 10:58:39.495167  3083 net.cpp:522] Eltwise12 -> Eltwise12
I0818 10:58:39.495203  3083 net.cpp:172] Setting up Eltwise12
I0818 10:58:39.495215  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.495219  3083 net.cpp:194] Memory required for data: 79749240
I0818 10:58:39.495229  3083 layer_factory.hpp:77] Creating layer ReLU25
I0818 10:58:39.495244  3083 net.cpp:128] Creating Layer ReLU25
I0818 10:58:39.495251  3083 net.cpp:558] ReLU25 <- Eltwise12
I0818 10:58:39.495259  3083 net.cpp:509] ReLU25 -> Eltwise12 (in-place)
I0818 10:58:39.495528  3083 net.cpp:172] Setting up ReLU25
I0818 10:58:39.495543  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.495548  3083 net.cpp:194] Memory required for data: 80076920
I0818 10:58:39.495553  3083 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I0818 10:58:39.495560  3083 net.cpp:128] Creating Layer Eltwise12_ReLU25_0_split
I0818 10:58:39.495565  3083 net.cpp:558] Eltwise12_ReLU25_0_split <- Eltwise12
I0818 10:58:39.495594  3083 net.cpp:522] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I0818 10:58:39.495621  3083 net.cpp:522] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I0818 10:58:39.495694  3083 net.cpp:172] Setting up Eltwise12_ReLU25_0_split
I0818 10:58:39.495705  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.495712  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.495715  3083 net.cpp:194] Memory required for data: 80732280
I0818 10:58:39.495719  3083 layer_factory.hpp:77] Creating layer Convolution27
I0818 10:58:39.495733  3083 net.cpp:128] Creating Layer Convolution27
I0818 10:58:39.495739  3083 net.cpp:558] Convolution27 <- Eltwise12_ReLU25_0_split_0
I0818 10:58:39.495750  3083 net.cpp:522] Convolution27 -> Convolution27
I0818 10:58:39.506222  3083 net.cpp:172] Setting up Convolution27
I0818 10:58:39.506253  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.506258  3083 net.cpp:194] Memory required for data: 81059960
I0818 10:58:39.506271  3083 layer_factory.hpp:77] Creating layer BatchNorm27
I0818 10:58:39.506285  3083 net.cpp:128] Creating Layer BatchNorm27
I0818 10:58:39.506295  3083 net.cpp:558] BatchNorm27 <- Convolution27
I0818 10:58:39.506302  3083 net.cpp:509] BatchNorm27 -> Convolution27 (in-place)
I0818 10:58:39.506714  3083 net.cpp:172] Setting up BatchNorm27
I0818 10:58:39.506726  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.506731  3083 net.cpp:194] Memory required for data: 81387640
I0818 10:58:39.506742  3083 layer_factory.hpp:77] Creating layer Scale27
I0818 10:58:39.506754  3083 net.cpp:128] Creating Layer Scale27
I0818 10:58:39.506759  3083 net.cpp:558] Scale27 <- Convolution27
I0818 10:58:39.506765  3083 net.cpp:509] Scale27 -> Convolution27 (in-place)
I0818 10:58:39.506844  3083 layer_factory.hpp:77] Creating layer Scale27
I0818 10:58:39.507051  3083 net.cpp:172] Setting up Scale27
I0818 10:58:39.507064  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.507069  3083 net.cpp:194] Memory required for data: 81715320
I0818 10:58:39.507078  3083 layer_factory.hpp:77] Creating layer ReLU26
I0818 10:58:39.507086  3083 net.cpp:128] Creating Layer ReLU26
I0818 10:58:39.507107  3083 net.cpp:558] ReLU26 <- Convolution27
I0818 10:58:39.507117  3083 net.cpp:509] ReLU26 -> Convolution27 (in-place)
I0818 10:58:39.510393  3083 net.cpp:172] Setting up ReLU26
I0818 10:58:39.510418  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.510423  3083 net.cpp:194] Memory required for data: 82043000
I0818 10:58:39.510428  3083 layer_factory.hpp:77] Creating layer Convolution28
I0818 10:58:39.510445  3083 net.cpp:128] Creating Layer Convolution28
I0818 10:58:39.510452  3083 net.cpp:558] Convolution28 <- Convolution27
I0818 10:58:39.510462  3083 net.cpp:522] Convolution28 -> Convolution28
I0818 10:58:39.521772  3083 net.cpp:172] Setting up Convolution28
I0818 10:58:39.521801  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.521806  3083 net.cpp:194] Memory required for data: 82370680
I0818 10:58:39.521816  3083 layer_factory.hpp:77] Creating layer BatchNorm28
I0818 10:58:39.521824  3083 net.cpp:128] Creating Layer BatchNorm28
I0818 10:58:39.521829  3083 net.cpp:558] BatchNorm28 <- Convolution28
I0818 10:58:39.521839  3083 net.cpp:509] BatchNorm28 -> Convolution28 (in-place)
I0818 10:58:39.522178  3083 net.cpp:172] Setting up BatchNorm28
I0818 10:58:39.522191  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.522195  3083 net.cpp:194] Memory required for data: 82698360
I0818 10:58:39.522205  3083 layer_factory.hpp:77] Creating layer Scale28
I0818 10:58:39.522212  3083 net.cpp:128] Creating Layer Scale28
I0818 10:58:39.522217  3083 net.cpp:558] Scale28 <- Convolution28
I0818 10:58:39.522222  3083 net.cpp:509] Scale28 -> Convolution28 (in-place)
I0818 10:58:39.522282  3083 layer_factory.hpp:77] Creating layer Scale28
I0818 10:58:39.522476  3083 net.cpp:172] Setting up Scale28
I0818 10:58:39.522485  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.522511  3083 net.cpp:194] Memory required for data: 83026040
I0818 10:58:39.522518  3083 layer_factory.hpp:77] Creating layer Eltwise13
I0818 10:58:39.522528  3083 net.cpp:128] Creating Layer Eltwise13
I0818 10:58:39.522533  3083 net.cpp:558] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I0818 10:58:39.522539  3083 net.cpp:558] Eltwise13 <- Convolution28
I0818 10:58:39.522562  3083 net.cpp:522] Eltwise13 -> Eltwise13
I0818 10:58:39.522594  3083 net.cpp:172] Setting up Eltwise13
I0818 10:58:39.522608  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.522613  3083 net.cpp:194] Memory required for data: 83353720
I0818 10:58:39.522617  3083 layer_factory.hpp:77] Creating layer ReLU27
I0818 10:58:39.522624  3083 net.cpp:128] Creating Layer ReLU27
I0818 10:58:39.522629  3083 net.cpp:558] ReLU27 <- Eltwise13
I0818 10:58:39.522636  3083 net.cpp:509] ReLU27 -> Eltwise13 (in-place)
I0818 10:58:39.523844  3083 net.cpp:172] Setting up ReLU27
I0818 10:58:39.523866  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.523870  3083 net.cpp:194] Memory required for data: 83681400
I0818 10:58:39.523875  3083 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I0818 10:58:39.523886  3083 net.cpp:128] Creating Layer Eltwise13_ReLU27_0_split
I0818 10:58:39.523891  3083 net.cpp:558] Eltwise13_ReLU27_0_split <- Eltwise13
I0818 10:58:39.523901  3083 net.cpp:522] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I0818 10:58:39.523910  3083 net.cpp:522] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I0818 10:58:39.523980  3083 net.cpp:172] Setting up Eltwise13_ReLU27_0_split
I0818 10:58:39.523993  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.523998  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.524003  3083 net.cpp:194] Memory required for data: 84336760
I0818 10:58:39.524006  3083 layer_factory.hpp:77] Creating layer Convolution29
I0818 10:58:39.524019  3083 net.cpp:128] Creating Layer Convolution29
I0818 10:58:39.524024  3083 net.cpp:558] Convolution29 <- Eltwise13_ReLU27_0_split_0
I0818 10:58:39.524035  3083 net.cpp:522] Convolution29 -> Convolution29
I0818 10:58:39.530746  3083 net.cpp:172] Setting up Convolution29
I0818 10:58:39.530768  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.530772  3083 net.cpp:194] Memory required for data: 84664440
I0818 10:58:39.530783  3083 layer_factory.hpp:77] Creating layer BatchNorm29
I0818 10:58:39.530791  3083 net.cpp:128] Creating Layer BatchNorm29
I0818 10:58:39.530802  3083 net.cpp:558] BatchNorm29 <- Convolution29
I0818 10:58:39.530812  3083 net.cpp:509] BatchNorm29 -> Convolution29 (in-place)
I0818 10:58:39.531155  3083 net.cpp:172] Setting up BatchNorm29
I0818 10:58:39.531167  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.531200  3083 net.cpp:194] Memory required for data: 84992120
I0818 10:58:39.531211  3083 layer_factory.hpp:77] Creating layer Scale29
I0818 10:58:39.531239  3083 net.cpp:128] Creating Layer Scale29
I0818 10:58:39.531247  3083 net.cpp:558] Scale29 <- Convolution29
I0818 10:58:39.531256  3083 net.cpp:509] Scale29 -> Convolution29 (in-place)
I0818 10:58:39.531318  3083 layer_factory.hpp:77] Creating layer Scale29
I0818 10:58:39.531515  3083 net.cpp:172] Setting up Scale29
I0818 10:58:39.531525  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.531529  3083 net.cpp:194] Memory required for data: 85319800
I0818 10:58:39.531538  3083 layer_factory.hpp:77] Creating layer ReLU28
I0818 10:58:39.531544  3083 net.cpp:128] Creating Layer ReLU28
I0818 10:58:39.531549  3083 net.cpp:558] ReLU28 <- Convolution29
I0818 10:58:39.531555  3083 net.cpp:509] ReLU28 -> Convolution29 (in-place)
I0818 10:58:39.532829  3083 net.cpp:172] Setting up ReLU28
I0818 10:58:39.532848  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.532853  3083 net.cpp:194] Memory required for data: 85647480
I0818 10:58:39.532858  3083 layer_factory.hpp:77] Creating layer Convolution30
I0818 10:58:39.532872  3083 net.cpp:128] Creating Layer Convolution30
I0818 10:58:39.532883  3083 net.cpp:558] Convolution30 <- Convolution29
I0818 10:58:39.532912  3083 net.cpp:522] Convolution30 -> Convolution30
I0818 10:58:39.539741  3083 net.cpp:172] Setting up Convolution30
I0818 10:58:39.539764  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.539768  3083 net.cpp:194] Memory required for data: 85975160
I0818 10:58:39.539779  3083 layer_factory.hpp:77] Creating layer BatchNorm30
I0818 10:58:39.539790  3083 net.cpp:128] Creating Layer BatchNorm30
I0818 10:58:39.539826  3083 net.cpp:558] BatchNorm30 <- Convolution30
I0818 10:58:39.539849  3083 net.cpp:509] BatchNorm30 -> Convolution30 (in-place)
I0818 10:58:39.540212  3083 net.cpp:172] Setting up BatchNorm30
I0818 10:58:39.540256  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.540271  3083 net.cpp:194] Memory required for data: 86302840
I0818 10:58:39.540297  3083 layer_factory.hpp:77] Creating layer Scale30
I0818 10:58:39.540314  3083 net.cpp:128] Creating Layer Scale30
I0818 10:58:39.540328  3083 net.cpp:558] Scale30 <- Convolution30
I0818 10:58:39.540345  3083 net.cpp:509] Scale30 -> Convolution30 (in-place)
I0818 10:58:39.540427  3083 layer_factory.hpp:77] Creating layer Scale30
I0818 10:58:39.540660  3083 net.cpp:172] Setting up Scale30
I0818 10:58:39.540684  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.540700  3083 net.cpp:194] Memory required for data: 86630520
I0818 10:58:39.540721  3083 layer_factory.hpp:77] Creating layer Eltwise14
I0818 10:58:39.540743  3083 net.cpp:128] Creating Layer Eltwise14
I0818 10:58:39.540758  3083 net.cpp:558] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I0818 10:58:39.540776  3083 net.cpp:558] Eltwise14 <- Convolution30
I0818 10:58:39.540792  3083 net.cpp:522] Eltwise14 -> Eltwise14
I0818 10:58:39.540839  3083 net.cpp:172] Setting up Eltwise14
I0818 10:58:39.540858  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.540872  3083 net.cpp:194] Memory required for data: 86958200
I0818 10:58:39.540886  3083 layer_factory.hpp:77] Creating layer ReLU29
I0818 10:58:39.540904  3083 net.cpp:128] Creating Layer ReLU29
I0818 10:58:39.540917  3083 net.cpp:558] ReLU29 <- Eltwise14
I0818 10:58:39.540938  3083 net.cpp:509] ReLU29 -> Eltwise14 (in-place)
I0818 10:58:39.543880  3083 net.cpp:172] Setting up ReLU29
I0818 10:58:39.543907  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.543911  3083 net.cpp:194] Memory required for data: 87285880
I0818 10:58:39.543917  3083 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I0818 10:58:39.543926  3083 net.cpp:128] Creating Layer Eltwise14_ReLU29_0_split
I0818 10:58:39.543931  3083 net.cpp:558] Eltwise14_ReLU29_0_split <- Eltwise14
I0818 10:58:39.543941  3083 net.cpp:522] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I0818 10:58:39.543979  3083 net.cpp:522] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I0818 10:58:39.544065  3083 net.cpp:172] Setting up Eltwise14_ReLU29_0_split
I0818 10:58:39.544086  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.544104  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.544117  3083 net.cpp:194] Memory required for data: 87941240
I0818 10:58:39.544133  3083 layer_factory.hpp:77] Creating layer Convolution31
I0818 10:58:39.544158  3083 net.cpp:128] Creating Layer Convolution31
I0818 10:58:39.544174  3083 net.cpp:558] Convolution31 <- Eltwise14_ReLU29_0_split_0
I0818 10:58:39.544199  3083 net.cpp:522] Convolution31 -> Convolution31
I0818 10:58:39.557005  3083 net.cpp:172] Setting up Convolution31
I0818 10:58:39.557031  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.557035  3083 net.cpp:194] Memory required for data: 88268920
I0818 10:58:39.557046  3083 layer_factory.hpp:77] Creating layer BatchNorm31
I0818 10:58:39.557060  3083 net.cpp:128] Creating Layer BatchNorm31
I0818 10:58:39.557091  3083 net.cpp:558] BatchNorm31 <- Convolution31
I0818 10:58:39.557112  3083 net.cpp:509] BatchNorm31 -> Convolution31 (in-place)
I0818 10:58:39.557469  3083 net.cpp:172] Setting up BatchNorm31
I0818 10:58:39.557483  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.557499  3083 net.cpp:194] Memory required for data: 88596600
I0818 10:58:39.557512  3083 layer_factory.hpp:77] Creating layer Scale31
I0818 10:58:39.557520  3083 net.cpp:128] Creating Layer Scale31
I0818 10:58:39.557528  3083 net.cpp:558] Scale31 <- Convolution31
I0818 10:58:39.557533  3083 net.cpp:509] Scale31 -> Convolution31 (in-place)
I0818 10:58:39.557597  3083 layer_factory.hpp:77] Creating layer Scale31
I0818 10:58:39.557840  3083 net.cpp:172] Setting up Scale31
I0818 10:58:39.557862  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.557876  3083 net.cpp:194] Memory required for data: 88924280
I0818 10:58:39.557900  3083 layer_factory.hpp:77] Creating layer ReLU30
I0818 10:58:39.557920  3083 net.cpp:128] Creating Layer ReLU30
I0818 10:58:39.557935  3083 net.cpp:558] ReLU30 <- Convolution31
I0818 10:58:39.557951  3083 net.cpp:509] ReLU30 -> Convolution31 (in-place)
I0818 10:58:39.561185  3083 net.cpp:172] Setting up ReLU30
I0818 10:58:39.561208  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.561213  3083 net.cpp:194] Memory required for data: 89251960
I0818 10:58:39.561218  3083 layer_factory.hpp:77] Creating layer Convolution32
I0818 10:58:39.561233  3083 net.cpp:128] Creating Layer Convolution32
I0818 10:58:39.561239  3083 net.cpp:558] Convolution32 <- Convolution31
I0818 10:58:39.561246  3083 net.cpp:522] Convolution32 -> Convolution32
I0818 10:58:39.569705  3083 net.cpp:172] Setting up Convolution32
I0818 10:58:39.569730  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.569734  3083 net.cpp:194] Memory required for data: 89579640
I0818 10:58:39.569744  3083 layer_factory.hpp:77] Creating layer BatchNorm32
I0818 10:58:39.569756  3083 net.cpp:128] Creating Layer BatchNorm32
I0818 10:58:39.569761  3083 net.cpp:558] BatchNorm32 <- Convolution32
I0818 10:58:39.569770  3083 net.cpp:509] BatchNorm32 -> Convolution32 (in-place)
I0818 10:58:39.570106  3083 net.cpp:172] Setting up BatchNorm32
I0818 10:58:39.570145  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.570163  3083 net.cpp:194] Memory required for data: 89907320
I0818 10:58:39.570184  3083 layer_factory.hpp:77] Creating layer Scale32
I0818 10:58:39.570204  3083 net.cpp:128] Creating Layer Scale32
I0818 10:58:39.570219  3083 net.cpp:558] Scale32 <- Convolution32
I0818 10:58:39.570238  3083 net.cpp:509] Scale32 -> Convolution32 (in-place)
I0818 10:58:39.570319  3083 layer_factory.hpp:77] Creating layer Scale32
I0818 10:58:39.570559  3083 net.cpp:172] Setting up Scale32
I0818 10:58:39.570574  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.570577  3083 net.cpp:194] Memory required for data: 90235000
I0818 10:58:39.570586  3083 layer_factory.hpp:77] Creating layer Eltwise15
I0818 10:58:39.570595  3083 net.cpp:128] Creating Layer Eltwise15
I0818 10:58:39.570600  3083 net.cpp:558] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I0818 10:58:39.570605  3083 net.cpp:558] Eltwise15 <- Convolution32
I0818 10:58:39.570613  3083 net.cpp:522] Eltwise15 -> Eltwise15
I0818 10:58:39.570641  3083 net.cpp:172] Setting up Eltwise15
I0818 10:58:39.570686  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.570700  3083 net.cpp:194] Memory required for data: 90562680
I0818 10:58:39.570714  3083 layer_factory.hpp:77] Creating layer ReLU31
I0818 10:58:39.570747  3083 net.cpp:128] Creating Layer ReLU31
I0818 10:58:39.570770  3083 net.cpp:558] ReLU31 <- Eltwise15
I0818 10:58:39.570785  3083 net.cpp:509] ReLU31 -> Eltwise15 (in-place)
I0818 10:58:39.571063  3083 net.cpp:172] Setting up ReLU31
I0818 10:58:39.571094  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.571108  3083 net.cpp:194] Memory required for data: 90890360
I0818 10:58:39.571122  3083 layer_factory.hpp:77] Creating layer Eltwise15_ReLU31_0_split
I0818 10:58:39.571139  3083 net.cpp:128] Creating Layer Eltwise15_ReLU31_0_split
I0818 10:58:39.571154  3083 net.cpp:558] Eltwise15_ReLU31_0_split <- Eltwise15
I0818 10:58:39.571173  3083 net.cpp:522] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_0
I0818 10:58:39.571204  3083 net.cpp:522] Eltwise15_ReLU31_0_split -> Eltwise15_ReLU31_0_split_1
I0818 10:58:39.571293  3083 net.cpp:172] Setting up Eltwise15_ReLU31_0_split
I0818 10:58:39.571346  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.571365  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.571382  3083 net.cpp:194] Memory required for data: 91545720
I0818 10:58:39.571399  3083 layer_factory.hpp:77] Creating layer Convolution33
I0818 10:58:39.571426  3083 net.cpp:128] Creating Layer Convolution33
I0818 10:58:39.571444  3083 net.cpp:558] Convolution33 <- Eltwise15_ReLU31_0_split_0
I0818 10:58:39.571465  3083 net.cpp:522] Convolution33 -> Convolution33
I0818 10:58:39.580713  3083 net.cpp:172] Setting up Convolution33
I0818 10:58:39.580759  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.580775  3083 net.cpp:194] Memory required for data: 91873400
I0818 10:58:39.580798  3083 layer_factory.hpp:77] Creating layer BatchNorm33
I0818 10:58:39.580822  3083 net.cpp:128] Creating Layer BatchNorm33
I0818 10:58:39.580838  3083 net.cpp:558] BatchNorm33 <- Convolution33
I0818 10:58:39.580860  3083 net.cpp:509] BatchNorm33 -> Convolution33 (in-place)
I0818 10:58:39.581275  3083 net.cpp:172] Setting up BatchNorm33
I0818 10:58:39.581291  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.581295  3083 net.cpp:194] Memory required for data: 92201080
I0818 10:58:39.581306  3083 layer_factory.hpp:77] Creating layer Scale33
I0818 10:58:39.581324  3083 net.cpp:128] Creating Layer Scale33
I0818 10:58:39.581329  3083 net.cpp:558] Scale33 <- Convolution33
I0818 10:58:39.581336  3083 net.cpp:509] Scale33 -> Convolution33 (in-place)
I0818 10:58:39.581401  3083 layer_factory.hpp:77] Creating layer Scale33
I0818 10:58:39.581614  3083 net.cpp:172] Setting up Scale33
I0818 10:58:39.581625  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.581629  3083 net.cpp:194] Memory required for data: 92528760
I0818 10:58:39.581637  3083 layer_factory.hpp:77] Creating layer ReLU32
I0818 10:58:39.581650  3083 net.cpp:128] Creating Layer ReLU32
I0818 10:58:39.581655  3083 net.cpp:558] ReLU32 <- Convolution33
I0818 10:58:39.581660  3083 net.cpp:509] ReLU32 -> Convolution33 (in-place)
I0818 10:58:39.584903  3083 net.cpp:172] Setting up ReLU32
I0818 10:58:39.584925  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.584930  3083 net.cpp:194] Memory required for data: 92856440
I0818 10:58:39.584935  3083 layer_factory.hpp:77] Creating layer Convolution34
I0818 10:58:39.584952  3083 net.cpp:128] Creating Layer Convolution34
I0818 10:58:39.584961  3083 net.cpp:558] Convolution34 <- Convolution33
I0818 10:58:39.584969  3083 net.cpp:522] Convolution34 -> Convolution34
I0818 10:58:39.598075  3083 net.cpp:172] Setting up Convolution34
I0818 10:58:39.598101  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.598106  3083 net.cpp:194] Memory required for data: 93184120
I0818 10:58:39.598116  3083 layer_factory.hpp:77] Creating layer BatchNorm34
I0818 10:58:39.598127  3083 net.cpp:128] Creating Layer BatchNorm34
I0818 10:58:39.598139  3083 net.cpp:558] BatchNorm34 <- Convolution34
I0818 10:58:39.598145  3083 net.cpp:509] BatchNorm34 -> Convolution34 (in-place)
I0818 10:58:39.598482  3083 net.cpp:172] Setting up BatchNorm34
I0818 10:58:39.598493  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.598497  3083 net.cpp:194] Memory required for data: 93511800
I0818 10:58:39.598507  3083 layer_factory.hpp:77] Creating layer Scale34
I0818 10:58:39.598515  3083 net.cpp:128] Creating Layer Scale34
I0818 10:58:39.598520  3083 net.cpp:558] Scale34 <- Convolution34
I0818 10:58:39.598532  3083 net.cpp:509] Scale34 -> Convolution34 (in-place)
I0818 10:58:39.598613  3083 layer_factory.hpp:77] Creating layer Scale34
I0818 10:58:39.598829  3083 net.cpp:172] Setting up Scale34
I0818 10:58:39.598841  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.598845  3083 net.cpp:194] Memory required for data: 93839480
I0818 10:58:39.598855  3083 layer_factory.hpp:77] Creating layer Eltwise16
I0818 10:58:39.598883  3083 net.cpp:128] Creating Layer Eltwise16
I0818 10:58:39.598889  3083 net.cpp:558] Eltwise16 <- Eltwise15_ReLU31_0_split_1
I0818 10:58:39.598896  3083 net.cpp:558] Eltwise16 <- Convolution34
I0818 10:58:39.598904  3083 net.cpp:522] Eltwise16 -> Eltwise16
I0818 10:58:39.598953  3083 net.cpp:172] Setting up Eltwise16
I0818 10:58:39.598965  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.598969  3083 net.cpp:194] Memory required for data: 94167160
I0818 10:58:39.598974  3083 layer_factory.hpp:77] Creating layer ReLU33
I0818 10:58:39.598980  3083 net.cpp:128] Creating Layer ReLU33
I0818 10:58:39.598985  3083 net.cpp:558] ReLU33 <- Eltwise16
I0818 10:58:39.598990  3083 net.cpp:509] ReLU33 -> Eltwise16 (in-place)
I0818 10:58:39.601588  3083 net.cpp:172] Setting up ReLU33
I0818 10:58:39.601614  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.601619  3083 net.cpp:194] Memory required for data: 94494840
I0818 10:58:39.601624  3083 layer_factory.hpp:77] Creating layer Eltwise16_ReLU33_0_split
I0818 10:58:39.601635  3083 net.cpp:128] Creating Layer Eltwise16_ReLU33_0_split
I0818 10:58:39.601640  3083 net.cpp:558] Eltwise16_ReLU33_0_split <- Eltwise16
I0818 10:58:39.601647  3083 net.cpp:522] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_0
I0818 10:58:39.601660  3083 net.cpp:522] Eltwise16_ReLU33_0_split -> Eltwise16_ReLU33_0_split_1
I0818 10:58:39.601730  3083 net.cpp:172] Setting up Eltwise16_ReLU33_0_split
I0818 10:58:39.601742  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.601748  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.601752  3083 net.cpp:194] Memory required for data: 95150200
I0818 10:58:39.601757  3083 layer_factory.hpp:77] Creating layer Convolution35
I0818 10:58:39.601769  3083 net.cpp:128] Creating Layer Convolution35
I0818 10:58:39.601773  3083 net.cpp:558] Convolution35 <- Eltwise16_ReLU33_0_split_0
I0818 10:58:39.601784  3083 net.cpp:522] Convolution35 -> Convolution35
I0818 10:58:39.608783  3083 net.cpp:172] Setting up Convolution35
I0818 10:58:39.608809  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.608814  3083 net.cpp:194] Memory required for data: 95477880
I0818 10:58:39.608824  3083 layer_factory.hpp:77] Creating layer BatchNorm35
I0818 10:58:39.608834  3083 net.cpp:128] Creating Layer BatchNorm35
I0818 10:58:39.608840  3083 net.cpp:558] BatchNorm35 <- Convolution35
I0818 10:58:39.608850  3083 net.cpp:509] BatchNorm35 -> Convolution35 (in-place)
I0818 10:58:39.609202  3083 net.cpp:172] Setting up BatchNorm35
I0818 10:58:39.609216  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.609220  3083 net.cpp:194] Memory required for data: 95805560
I0818 10:58:39.609230  3083 layer_factory.hpp:77] Creating layer Scale35
I0818 10:58:39.609241  3083 net.cpp:128] Creating Layer Scale35
I0818 10:58:39.609246  3083 net.cpp:558] Scale35 <- Convolution35
I0818 10:58:39.609251  3083 net.cpp:509] Scale35 -> Convolution35 (in-place)
I0818 10:58:39.609313  3083 layer_factory.hpp:77] Creating layer Scale35
I0818 10:58:39.609515  3083 net.cpp:172] Setting up Scale35
I0818 10:58:39.609524  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.609527  3083 net.cpp:194] Memory required for data: 96133240
I0818 10:58:39.609551  3083 layer_factory.hpp:77] Creating layer ReLU34
I0818 10:58:39.609560  3083 net.cpp:128] Creating Layer ReLU34
I0818 10:58:39.609565  3083 net.cpp:558] ReLU34 <- Convolution35
I0818 10:58:39.609570  3083 net.cpp:509] ReLU34 -> Convolution35 (in-place)
I0818 10:58:39.610560  3083 net.cpp:172] Setting up ReLU34
I0818 10:58:39.610580  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.610584  3083 net.cpp:194] Memory required for data: 96460920
I0818 10:58:39.610589  3083 layer_factory.hpp:77] Creating layer Convolution36
I0818 10:58:39.610605  3083 net.cpp:128] Creating Layer Convolution36
I0818 10:58:39.610610  3083 net.cpp:558] Convolution36 <- Convolution35
I0818 10:58:39.610618  3083 net.cpp:522] Convolution36 -> Convolution36
I0818 10:58:39.617522  3083 net.cpp:172] Setting up Convolution36
I0818 10:58:39.617545  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.617549  3083 net.cpp:194] Memory required for data: 96788600
I0818 10:58:39.617560  3083 layer_factory.hpp:77] Creating layer BatchNorm36
I0818 10:58:39.617571  3083 net.cpp:128] Creating Layer BatchNorm36
I0818 10:58:39.617576  3083 net.cpp:558] BatchNorm36 <- Convolution36
I0818 10:58:39.617583  3083 net.cpp:509] BatchNorm36 -> Convolution36 (in-place)
I0818 10:58:39.617928  3083 net.cpp:172] Setting up BatchNorm36
I0818 10:58:39.617940  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.617945  3083 net.cpp:194] Memory required for data: 97116280
I0818 10:58:39.617954  3083 layer_factory.hpp:77] Creating layer Scale36
I0818 10:58:39.617961  3083 net.cpp:128] Creating Layer Scale36
I0818 10:58:39.617966  3083 net.cpp:558] Scale36 <- Convolution36
I0818 10:58:39.617974  3083 net.cpp:509] Scale36 -> Convolution36 (in-place)
I0818 10:58:39.618034  3083 layer_factory.hpp:77] Creating layer Scale36
I0818 10:58:39.618232  3083 net.cpp:172] Setting up Scale36
I0818 10:58:39.618243  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.618247  3083 net.cpp:194] Memory required for data: 97443960
I0818 10:58:39.618257  3083 layer_factory.hpp:77] Creating layer Eltwise17
I0818 10:58:39.618266  3083 net.cpp:128] Creating Layer Eltwise17
I0818 10:58:39.618288  3083 net.cpp:558] Eltwise17 <- Eltwise16_ReLU33_0_split_1
I0818 10:58:39.618294  3083 net.cpp:558] Eltwise17 <- Convolution36
I0818 10:58:39.618301  3083 net.cpp:522] Eltwise17 -> Eltwise17
I0818 10:58:39.618330  3083 net.cpp:172] Setting up Eltwise17
I0818 10:58:39.618343  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.618347  3083 net.cpp:194] Memory required for data: 97771640
I0818 10:58:39.618351  3083 layer_factory.hpp:77] Creating layer ReLU35
I0818 10:58:39.618358  3083 net.cpp:128] Creating Layer ReLU35
I0818 10:58:39.618362  3083 net.cpp:558] ReLU35 <- Eltwise17
I0818 10:58:39.618368  3083 net.cpp:509] ReLU35 -> Eltwise17 (in-place)
I0818 10:58:39.621683  3083 net.cpp:172] Setting up ReLU35
I0818 10:58:39.621707  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.621711  3083 net.cpp:194] Memory required for data: 98099320
I0818 10:58:39.621716  3083 layer_factory.hpp:77] Creating layer Eltwise17_ReLU35_0_split
I0818 10:58:39.621726  3083 net.cpp:128] Creating Layer Eltwise17_ReLU35_0_split
I0818 10:58:39.621732  3083 net.cpp:558] Eltwise17_ReLU35_0_split <- Eltwise17
I0818 10:58:39.621744  3083 net.cpp:522] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_0
I0818 10:58:39.621757  3083 net.cpp:522] Eltwise17_ReLU35_0_split -> Eltwise17_ReLU35_0_split_1
I0818 10:58:39.621827  3083 net.cpp:172] Setting up Eltwise17_ReLU35_0_split
I0818 10:58:39.621835  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.621841  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.621845  3083 net.cpp:194] Memory required for data: 98754680
I0818 10:58:39.621850  3083 layer_factory.hpp:77] Creating layer Convolution37
I0818 10:58:39.621865  3083 net.cpp:128] Creating Layer Convolution37
I0818 10:58:39.621873  3083 net.cpp:558] Convolution37 <- Eltwise17_ReLU35_0_split_0
I0818 10:58:39.621881  3083 net.cpp:522] Convolution37 -> Convolution37
I0818 10:58:39.634850  3083 net.cpp:172] Setting up Convolution37
I0818 10:58:39.634872  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.634877  3083 net.cpp:194] Memory required for data: 99082360
I0818 10:58:39.634888  3083 layer_factory.hpp:77] Creating layer BatchNorm37
I0818 10:58:39.634899  3083 net.cpp:128] Creating Layer BatchNorm37
I0818 10:58:39.634904  3083 net.cpp:558] BatchNorm37 <- Convolution37
I0818 10:58:39.634913  3083 net.cpp:509] BatchNorm37 -> Convolution37 (in-place)
I0818 10:58:39.636693  3083 net.cpp:172] Setting up BatchNorm37
I0818 10:58:39.636720  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.636724  3083 net.cpp:194] Memory required for data: 99410040
I0818 10:58:39.636778  3083 layer_factory.hpp:77] Creating layer Scale37
I0818 10:58:39.636790  3083 net.cpp:128] Creating Layer Scale37
I0818 10:58:39.636795  3083 net.cpp:558] Scale37 <- Convolution37
I0818 10:58:39.636802  3083 net.cpp:509] Scale37 -> Convolution37 (in-place)
I0818 10:58:39.636857  3083 layer_factory.hpp:77] Creating layer Scale37
I0818 10:58:39.637032  3083 net.cpp:172] Setting up Scale37
I0818 10:58:39.637051  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.637065  3083 net.cpp:194] Memory required for data: 99737720
I0818 10:58:39.637084  3083 layer_factory.hpp:77] Creating layer ReLU36
I0818 10:58:39.637102  3083 net.cpp:128] Creating Layer ReLU36
I0818 10:58:39.637120  3083 net.cpp:558] ReLU36 <- Convolution37
I0818 10:58:39.637140  3083 net.cpp:509] ReLU36 -> Convolution37 (in-place)
I0818 10:58:39.638991  3083 net.cpp:172] Setting up ReLU36
I0818 10:58:39.639014  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.639020  3083 net.cpp:194] Memory required for data: 100065400
I0818 10:58:39.639026  3083 layer_factory.hpp:77] Creating layer Convolution38
I0818 10:58:39.639041  3083 net.cpp:128] Creating Layer Convolution38
I0818 10:58:39.639047  3083 net.cpp:558] Convolution38 <- Convolution37
I0818 10:58:39.639057  3083 net.cpp:522] Convolution38 -> Convolution38
I0818 10:58:39.649849  3083 net.cpp:172] Setting up Convolution38
I0818 10:58:39.649876  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.649881  3083 net.cpp:194] Memory required for data: 100393080
I0818 10:58:39.649891  3083 layer_factory.hpp:77] Creating layer BatchNorm38
I0818 10:58:39.649899  3083 net.cpp:128] Creating Layer BatchNorm38
I0818 10:58:39.649904  3083 net.cpp:558] BatchNorm38 <- Convolution38
I0818 10:58:39.649914  3083 net.cpp:509] BatchNorm38 -> Convolution38 (in-place)
I0818 10:58:39.650136  3083 net.cpp:172] Setting up BatchNorm38
I0818 10:58:39.650182  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.650197  3083 net.cpp:194] Memory required for data: 100720760
I0818 10:58:39.650216  3083 layer_factory.hpp:77] Creating layer Scale38
I0818 10:58:39.650233  3083 net.cpp:128] Creating Layer Scale38
I0818 10:58:39.650252  3083 net.cpp:558] Scale38 <- Convolution38
I0818 10:58:39.650276  3083 net.cpp:509] Scale38 -> Convolution38 (in-place)
I0818 10:58:39.650336  3083 layer_factory.hpp:77] Creating layer Scale38
I0818 10:58:39.650481  3083 net.cpp:172] Setting up Scale38
I0818 10:58:39.650506  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.650519  3083 net.cpp:194] Memory required for data: 101048440
I0818 10:58:39.650537  3083 layer_factory.hpp:77] Creating layer Eltwise18
I0818 10:58:39.650555  3083 net.cpp:128] Creating Layer Eltwise18
I0818 10:58:39.650570  3083 net.cpp:558] Eltwise18 <- Eltwise17_ReLU35_0_split_1
I0818 10:58:39.650586  3083 net.cpp:558] Eltwise18 <- Convolution38
I0818 10:58:39.650604  3083 net.cpp:522] Eltwise18 -> Eltwise18
I0818 10:58:39.650640  3083 net.cpp:172] Setting up Eltwise18
I0818 10:58:39.650668  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.650682  3083 net.cpp:194] Memory required for data: 101376120
I0818 10:58:39.650696  3083 layer_factory.hpp:77] Creating layer ReLU37
I0818 10:58:39.650712  3083 net.cpp:128] Creating Layer ReLU37
I0818 10:58:39.650725  3083 net.cpp:558] ReLU37 <- Eltwise18
I0818 10:58:39.650743  3083 net.cpp:509] ReLU37 -> Eltwise18 (in-place)
I0818 10:58:39.651948  3083 net.cpp:172] Setting up ReLU37
I0818 10:58:39.651968  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.651973  3083 net.cpp:194] Memory required for data: 101703800
I0818 10:58:39.651978  3083 layer_factory.hpp:77] Creating layer Eltwise18_ReLU37_0_split
I0818 10:58:39.651986  3083 net.cpp:128] Creating Layer Eltwise18_ReLU37_0_split
I0818 10:58:39.651995  3083 net.cpp:558] Eltwise18_ReLU37_0_split <- Eltwise18
I0818 10:58:39.652004  3083 net.cpp:522] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_0
I0818 10:58:39.652011  3083 net.cpp:522] Eltwise18_ReLU37_0_split -> Eltwise18_ReLU37_0_split_1
I0818 10:58:39.652112  3083 net.cpp:172] Setting up Eltwise18_ReLU37_0_split
I0818 10:58:39.652132  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.652148  3083 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0818 10:58:39.652160  3083 net.cpp:194] Memory required for data: 102359160
I0818 10:58:39.652174  3083 layer_factory.hpp:77] Creating layer Convolution39
I0818 10:58:39.652196  3083 net.cpp:128] Creating Layer Convolution39
I0818 10:58:39.652211  3083 net.cpp:558] Convolution39 <- Eltwise18_ReLU37_0_split_0
I0818 10:58:39.652233  3083 net.cpp:522] Convolution39 -> Convolution39
I0818 10:58:39.659092  3083 net.cpp:172] Setting up Convolution39
I0818 10:58:39.659118  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.659124  3083 net.cpp:194] Memory required for data: 102523000
I0818 10:58:39.659134  3083 layer_factory.hpp:77] Creating layer BatchNorm39
I0818 10:58:39.659145  3083 net.cpp:128] Creating Layer BatchNorm39
I0818 10:58:39.659152  3083 net.cpp:558] BatchNorm39 <- Convolution39
I0818 10:58:39.659158  3083 net.cpp:509] BatchNorm39 -> Convolution39 (in-place)
I0818 10:58:39.659390  3083 net.cpp:172] Setting up BatchNorm39
I0818 10:58:39.659431  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.659449  3083 net.cpp:194] Memory required for data: 102686840
I0818 10:58:39.659474  3083 layer_factory.hpp:77] Creating layer Scale39
I0818 10:58:39.659495  3083 net.cpp:128] Creating Layer Scale39
I0818 10:58:39.659513  3083 net.cpp:558] Scale39 <- Convolution39
I0818 10:58:39.659533  3083 net.cpp:509] Scale39 -> Convolution39 (in-place)
I0818 10:58:39.659600  3083 layer_factory.hpp:77] Creating layer Scale39
I0818 10:58:39.659755  3083 net.cpp:172] Setting up Scale39
I0818 10:58:39.659778  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.659791  3083 net.cpp:194] Memory required for data: 102850680
I0818 10:58:39.659813  3083 layer_factory.hpp:77] Creating layer Convolution40
I0818 10:58:39.659837  3083 net.cpp:128] Creating Layer Convolution40
I0818 10:58:39.659857  3083 net.cpp:558] Convolution40 <- Eltwise18_ReLU37_0_split_1
I0818 10:58:39.659899  3083 net.cpp:522] Convolution40 -> Convolution40
I0818 10:58:39.665637  3083 net.cpp:172] Setting up Convolution40
I0818 10:58:39.665684  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.665702  3083 net.cpp:194] Memory required for data: 103014520
I0818 10:58:39.665724  3083 layer_factory.hpp:77] Creating layer BatchNorm40
I0818 10:58:39.665745  3083 net.cpp:128] Creating Layer BatchNorm40
I0818 10:58:39.665760  3083 net.cpp:558] BatchNorm40 <- Convolution40
I0818 10:58:39.665779  3083 net.cpp:509] BatchNorm40 -> Convolution40 (in-place)
I0818 10:58:39.666035  3083 net.cpp:172] Setting up BatchNorm40
I0818 10:58:39.666055  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.666069  3083 net.cpp:194] Memory required for data: 103178360
I0818 10:58:39.666088  3083 layer_factory.hpp:77] Creating layer Scale40
I0818 10:58:39.666108  3083 net.cpp:128] Creating Layer Scale40
I0818 10:58:39.666122  3083 net.cpp:558] Scale40 <- Convolution40
I0818 10:58:39.666144  3083 net.cpp:509] Scale40 -> Convolution40 (in-place)
I0818 10:58:39.666209  3083 layer_factory.hpp:77] Creating layer Scale40
I0818 10:58:39.666379  3083 net.cpp:172] Setting up Scale40
I0818 10:58:39.666400  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.666421  3083 net.cpp:194] Memory required for data: 103342200
I0818 10:58:39.666440  3083 layer_factory.hpp:77] Creating layer ReLU38
I0818 10:58:39.666456  3083 net.cpp:128] Creating Layer ReLU38
I0818 10:58:39.666471  3083 net.cpp:558] ReLU38 <- Convolution40
I0818 10:58:39.666489  3083 net.cpp:509] ReLU38 -> Convolution40 (in-place)
I0818 10:58:39.669842  3083 net.cpp:172] Setting up ReLU38
I0818 10:58:39.669862  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.669867  3083 net.cpp:194] Memory required for data: 103506040
I0818 10:58:39.669873  3083 layer_factory.hpp:77] Creating layer Convolution41
I0818 10:58:39.669888  3083 net.cpp:128] Creating Layer Convolution41
I0818 10:58:39.669935  3083 net.cpp:558] Convolution41 <- Convolution40
I0818 10:58:39.669960  3083 net.cpp:522] Convolution41 -> Convolution41
I0818 10:58:39.682927  3083 net.cpp:172] Setting up Convolution41
I0818 10:58:39.682951  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.682955  3083 net.cpp:194] Memory required for data: 103669880
I0818 10:58:39.682966  3083 layer_factory.hpp:77] Creating layer BatchNorm41
I0818 10:58:39.682979  3083 net.cpp:128] Creating Layer BatchNorm41
I0818 10:58:39.682984  3083 net.cpp:558] BatchNorm41 <- Convolution41
I0818 10:58:39.682991  3083 net.cpp:509] BatchNorm41 -> Convolution41 (in-place)
I0818 10:58:39.683228  3083 net.cpp:172] Setting up BatchNorm41
I0818 10:58:39.683269  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.683284  3083 net.cpp:194] Memory required for data: 103833720
I0818 10:58:39.683303  3083 layer_factory.hpp:77] Creating layer Scale41
I0818 10:58:39.683324  3083 net.cpp:128] Creating Layer Scale41
I0818 10:58:39.683341  3083 net.cpp:558] Scale41 <- Convolution41
I0818 10:58:39.683358  3083 net.cpp:509] Scale41 -> Convolution41 (in-place)
I0818 10:58:39.683424  3083 layer_factory.hpp:77] Creating layer Scale41
I0818 10:58:39.683574  3083 net.cpp:172] Setting up Scale41
I0818 10:58:39.683598  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.683612  3083 net.cpp:194] Memory required for data: 103997560
I0818 10:58:39.683630  3083 layer_factory.hpp:77] Creating layer Eltwise19
I0818 10:58:39.683647  3083 net.cpp:128] Creating Layer Eltwise19
I0818 10:58:39.683666  3083 net.cpp:558] Eltwise19 <- Convolution39
I0818 10:58:39.683686  3083 net.cpp:558] Eltwise19 <- Convolution41
I0818 10:58:39.683702  3083 net.cpp:522] Eltwise19 -> Eltwise19
I0818 10:58:39.683743  3083 net.cpp:172] Setting up Eltwise19
I0818 10:58:39.683761  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.683774  3083 net.cpp:194] Memory required for data: 104161400
I0818 10:58:39.683787  3083 layer_factory.hpp:77] Creating layer ReLU39
I0818 10:58:39.683805  3083 net.cpp:128] Creating Layer ReLU39
I0818 10:58:39.683820  3083 net.cpp:558] ReLU39 <- Eltwise19
I0818 10:58:39.683835  3083 net.cpp:509] ReLU39 -> Eltwise19 (in-place)
I0818 10:58:39.687152  3083 net.cpp:172] Setting up ReLU39
I0818 10:58:39.687175  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.687178  3083 net.cpp:194] Memory required for data: 104325240
I0818 10:58:39.687183  3083 layer_factory.hpp:77] Creating layer Eltwise19_ReLU39_0_split
I0818 10:58:39.687196  3083 net.cpp:128] Creating Layer Eltwise19_ReLU39_0_split
I0818 10:58:39.687202  3083 net.cpp:558] Eltwise19_ReLU39_0_split <- Eltwise19
I0818 10:58:39.687209  3083 net.cpp:522] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_0
I0818 10:58:39.687222  3083 net.cpp:522] Eltwise19_ReLU39_0_split -> Eltwise19_ReLU39_0_split_1
I0818 10:58:39.687273  3083 net.cpp:172] Setting up Eltwise19_ReLU39_0_split
I0818 10:58:39.687311  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.687327  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.687341  3083 net.cpp:194] Memory required for data: 104652920
I0818 10:58:39.687355  3083 layer_factory.hpp:77] Creating layer Convolution42
I0818 10:58:39.687376  3083 net.cpp:128] Creating Layer Convolution42
I0818 10:58:39.687391  3083 net.cpp:558] Convolution42 <- Eltwise19_ReLU39_0_split_0
I0818 10:58:39.687418  3083 net.cpp:522] Convolution42 -> Convolution42
I0818 10:58:39.697984  3083 net.cpp:172] Setting up Convolution42
I0818 10:58:39.698011  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.698016  3083 net.cpp:194] Memory required for data: 104816760
I0818 10:58:39.698029  3083 layer_factory.hpp:77] Creating layer BatchNorm42
I0818 10:58:39.698040  3083 net.cpp:128] Creating Layer BatchNorm42
I0818 10:58:39.698045  3083 net.cpp:558] BatchNorm42 <- Convolution42
I0818 10:58:39.698055  3083 net.cpp:509] BatchNorm42 -> Convolution42 (in-place)
I0818 10:58:39.698300  3083 net.cpp:172] Setting up BatchNorm42
I0818 10:58:39.698345  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.698370  3083 net.cpp:194] Memory required for data: 104980600
I0818 10:58:39.698398  3083 layer_factory.hpp:77] Creating layer Scale42
I0818 10:58:39.698420  3083 net.cpp:128] Creating Layer Scale42
I0818 10:58:39.698434  3083 net.cpp:558] Scale42 <- Convolution42
I0818 10:58:39.698451  3083 net.cpp:509] Scale42 -> Convolution42 (in-place)
I0818 10:58:39.698516  3083 layer_factory.hpp:77] Creating layer Scale42
I0818 10:58:39.698678  3083 net.cpp:172] Setting up Scale42
I0818 10:58:39.698704  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.698717  3083 net.cpp:194] Memory required for data: 105144440
I0818 10:58:39.698740  3083 layer_factory.hpp:77] Creating layer ReLU40
I0818 10:58:39.698761  3083 net.cpp:128] Creating Layer ReLU40
I0818 10:58:39.698776  3083 net.cpp:558] ReLU40 <- Convolution42
I0818 10:58:39.698794  3083 net.cpp:509] ReLU40 -> Convolution42 (in-place)
I0818 10:58:39.699812  3083 net.cpp:172] Setting up ReLU40
I0818 10:58:39.699832  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.699838  3083 net.cpp:194] Memory required for data: 105308280
I0818 10:58:39.699843  3083 layer_factory.hpp:77] Creating layer Convolution43
I0818 10:58:39.699857  3083 net.cpp:128] Creating Layer Convolution43
I0818 10:58:39.699863  3083 net.cpp:558] Convolution43 <- Convolution42
I0818 10:58:39.699874  3083 net.cpp:522] Convolution43 -> Convolution43
I0818 10:58:39.706647  3083 net.cpp:172] Setting up Convolution43
I0818 10:58:39.706688  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.706692  3083 net.cpp:194] Memory required for data: 105472120
I0818 10:58:39.706706  3083 layer_factory.hpp:77] Creating layer BatchNorm43
I0818 10:58:39.706717  3083 net.cpp:128] Creating Layer BatchNorm43
I0818 10:58:39.706722  3083 net.cpp:558] BatchNorm43 <- Convolution43
I0818 10:58:39.706728  3083 net.cpp:509] BatchNorm43 -> Convolution43 (in-place)
I0818 10:58:39.706964  3083 net.cpp:172] Setting up BatchNorm43
I0818 10:58:39.707002  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.707016  3083 net.cpp:194] Memory required for data: 105635960
I0818 10:58:39.707037  3083 layer_factory.hpp:77] Creating layer Scale43
I0818 10:58:39.707054  3083 net.cpp:128] Creating Layer Scale43
I0818 10:58:39.707073  3083 net.cpp:558] Scale43 <- Convolution43
I0818 10:58:39.707092  3083 net.cpp:509] Scale43 -> Convolution43 (in-place)
I0818 10:58:39.707164  3083 layer_factory.hpp:77] Creating layer Scale43
I0818 10:58:39.707319  3083 net.cpp:172] Setting up Scale43
I0818 10:58:39.707342  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.707360  3083 net.cpp:194] Memory required for data: 105799800
I0818 10:58:39.707381  3083 layer_factory.hpp:77] Creating layer Eltwise20
I0818 10:58:39.707401  3083 net.cpp:128] Creating Layer Eltwise20
I0818 10:58:39.707419  3083 net.cpp:558] Eltwise20 <- Eltwise19_ReLU39_0_split_1
I0818 10:58:39.707435  3083 net.cpp:558] Eltwise20 <- Convolution43
I0818 10:58:39.707454  3083 net.cpp:522] Eltwise20 -> Eltwise20
I0818 10:58:39.707511  3083 net.cpp:172] Setting up Eltwise20
I0818 10:58:39.707536  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.707554  3083 net.cpp:194] Memory required for data: 105963640
I0818 10:58:39.707571  3083 layer_factory.hpp:77] Creating layer ReLU41
I0818 10:58:39.707592  3083 net.cpp:128] Creating Layer ReLU41
I0818 10:58:39.707615  3083 net.cpp:558] ReLU41 <- Eltwise20
I0818 10:58:39.707634  3083 net.cpp:509] ReLU41 -> Eltwise20 (in-place)
I0818 10:58:39.708797  3083 net.cpp:172] Setting up ReLU41
I0818 10:58:39.708837  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.708851  3083 net.cpp:194] Memory required for data: 106127480
I0818 10:58:39.708866  3083 layer_factory.hpp:77] Creating layer Eltwise20_ReLU41_0_split
I0818 10:58:39.708884  3083 net.cpp:128] Creating Layer Eltwise20_ReLU41_0_split
I0818 10:58:39.708902  3083 net.cpp:558] Eltwise20_ReLU41_0_split <- Eltwise20
I0818 10:58:39.708925  3083 net.cpp:522] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_0
I0818 10:58:39.708961  3083 net.cpp:522] Eltwise20_ReLU41_0_split -> Eltwise20_ReLU41_0_split_1
I0818 10:58:39.709025  3083 net.cpp:172] Setting up Eltwise20_ReLU41_0_split
I0818 10:58:39.709048  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.709066  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.709084  3083 net.cpp:194] Memory required for data: 106455160
I0818 10:58:39.709100  3083 layer_factory.hpp:77] Creating layer Convolution44
I0818 10:58:39.709128  3083 net.cpp:128] Creating Layer Convolution44
I0818 10:58:39.709164  3083 net.cpp:558] Convolution44 <- Eltwise20_ReLU41_0_split_0
I0818 10:58:39.709185  3083 net.cpp:522] Convolution44 -> Convolution44
I0818 10:58:39.719035  3083 net.cpp:172] Setting up Convolution44
I0818 10:58:39.719061  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.719066  3083 net.cpp:194] Memory required for data: 106619000
I0818 10:58:39.719079  3083 layer_factory.hpp:77] Creating layer BatchNorm44
I0818 10:58:39.719115  3083 net.cpp:128] Creating Layer BatchNorm44
I0818 10:58:39.719131  3083 net.cpp:558] BatchNorm44 <- Convolution44
I0818 10:58:39.719154  3083 net.cpp:509] BatchNorm44 -> Convolution44 (in-place)
I0818 10:58:39.719418  3083 net.cpp:172] Setting up BatchNorm44
I0818 10:58:39.719429  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.719434  3083 net.cpp:194] Memory required for data: 106782840
I0818 10:58:39.719444  3083 layer_factory.hpp:77] Creating layer Scale44
I0818 10:58:39.719486  3083 net.cpp:128] Creating Layer Scale44
I0818 10:58:39.719503  3083 net.cpp:558] Scale44 <- Convolution44
I0818 10:58:39.719524  3083 net.cpp:509] Scale44 -> Convolution44 (in-place)
I0818 10:58:39.719585  3083 layer_factory.hpp:77] Creating layer Scale44
I0818 10:58:39.719748  3083 net.cpp:172] Setting up Scale44
I0818 10:58:39.719760  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.719764  3083 net.cpp:194] Memory required for data: 106946680
I0818 10:58:39.719790  3083 layer_factory.hpp:77] Creating layer ReLU42
I0818 10:58:39.719818  3083 net.cpp:128] Creating Layer ReLU42
I0818 10:58:39.719835  3083 net.cpp:558] ReLU42 <- Convolution44
I0818 10:58:39.719854  3083 net.cpp:509] ReLU42 -> Convolution44 (in-place)
I0818 10:58:39.721928  3083 net.cpp:172] Setting up ReLU42
I0818 10:58:39.721951  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.721956  3083 net.cpp:194] Memory required for data: 107110520
I0818 10:58:39.721961  3083 layer_factory.hpp:77] Creating layer Convolution45
I0818 10:58:39.721976  3083 net.cpp:128] Creating Layer Convolution45
I0818 10:58:39.721985  3083 net.cpp:558] Convolution45 <- Convolution44
I0818 10:58:39.721993  3083 net.cpp:522] Convolution45 -> Convolution45
I0818 10:58:39.733940  3083 net.cpp:172] Setting up Convolution45
I0818 10:58:39.733968  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.733971  3083 net.cpp:194] Memory required for data: 107274360
I0818 10:58:39.733981  3083 layer_factory.hpp:77] Creating layer BatchNorm45
I0818 10:58:39.733992  3083 net.cpp:128] Creating Layer BatchNorm45
I0818 10:58:39.733999  3083 net.cpp:558] BatchNorm45 <- Convolution45
I0818 10:58:39.734007  3083 net.cpp:509] BatchNorm45 -> Convolution45 (in-place)
I0818 10:58:39.734241  3083 net.cpp:172] Setting up BatchNorm45
I0818 10:58:39.734253  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.734257  3083 net.cpp:194] Memory required for data: 107438200
I0818 10:58:39.734267  3083 layer_factory.hpp:77] Creating layer Scale45
I0818 10:58:39.734277  3083 net.cpp:128] Creating Layer Scale45
I0818 10:58:39.734282  3083 net.cpp:558] Scale45 <- Convolution45
I0818 10:58:39.734288  3083 net.cpp:509] Scale45 -> Convolution45 (in-place)
I0818 10:58:39.734333  3083 layer_factory.hpp:77] Creating layer Scale45
I0818 10:58:39.734472  3083 net.cpp:172] Setting up Scale45
I0818 10:58:39.734478  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.734483  3083 net.cpp:194] Memory required for data: 107602040
I0818 10:58:39.734489  3083 layer_factory.hpp:77] Creating layer Eltwise21
I0818 10:58:39.734515  3083 net.cpp:128] Creating Layer Eltwise21
I0818 10:58:39.734522  3083 net.cpp:558] Eltwise21 <- Eltwise20_ReLU41_0_split_1
I0818 10:58:39.734529  3083 net.cpp:558] Eltwise21 <- Convolution45
I0818 10:58:39.734534  3083 net.cpp:522] Eltwise21 -> Eltwise21
I0818 10:58:39.734561  3083 net.cpp:172] Setting up Eltwise21
I0818 10:58:39.734568  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.734572  3083 net.cpp:194] Memory required for data: 107765880
I0818 10:58:39.734576  3083 layer_factory.hpp:77] Creating layer ReLU43
I0818 10:58:39.734582  3083 net.cpp:128] Creating Layer ReLU43
I0818 10:58:39.734587  3083 net.cpp:558] ReLU43 <- Eltwise21
I0818 10:58:39.734592  3083 net.cpp:509] ReLU43 -> Eltwise21 (in-place)
I0818 10:58:39.737689  3083 net.cpp:172] Setting up ReLU43
I0818 10:58:39.737716  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.737721  3083 net.cpp:194] Memory required for data: 107929720
I0818 10:58:39.737726  3083 layer_factory.hpp:77] Creating layer Eltwise21_ReLU43_0_split
I0818 10:58:39.737735  3083 net.cpp:128] Creating Layer Eltwise21_ReLU43_0_split
I0818 10:58:39.737740  3083 net.cpp:558] Eltwise21_ReLU43_0_split <- Eltwise21
I0818 10:58:39.737749  3083 net.cpp:522] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_0
I0818 10:58:39.737759  3083 net.cpp:522] Eltwise21_ReLU43_0_split -> Eltwise21_ReLU43_0_split_1
I0818 10:58:39.737809  3083 net.cpp:172] Setting up Eltwise21_ReLU43_0_split
I0818 10:58:39.737823  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.737828  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.737831  3083 net.cpp:194] Memory required for data: 108257400
I0818 10:58:39.737836  3083 layer_factory.hpp:77] Creating layer Convolution46
I0818 10:58:39.737850  3083 net.cpp:128] Creating Layer Convolution46
I0818 10:58:39.737855  3083 net.cpp:558] Convolution46 <- Eltwise21_ReLU43_0_split_0
I0818 10:58:39.737864  3083 net.cpp:522] Convolution46 -> Convolution46
I0818 10:58:39.744850  3083 net.cpp:172] Setting up Convolution46
I0818 10:58:39.744876  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.744881  3083 net.cpp:194] Memory required for data: 108421240
I0818 10:58:39.744892  3083 layer_factory.hpp:77] Creating layer BatchNorm46
I0818 10:58:39.744900  3083 net.cpp:128] Creating Layer BatchNorm46
I0818 10:58:39.744906  3083 net.cpp:558] BatchNorm46 <- Convolution46
I0818 10:58:39.744915  3083 net.cpp:509] BatchNorm46 -> Convolution46 (in-place)
I0818 10:58:39.745165  3083 net.cpp:172] Setting up BatchNorm46
I0818 10:58:39.745177  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.745182  3083 net.cpp:194] Memory required for data: 108585080
I0818 10:58:39.745190  3083 layer_factory.hpp:77] Creating layer Scale46
I0818 10:58:39.745199  3083 net.cpp:128] Creating Layer Scale46
I0818 10:58:39.745203  3083 net.cpp:558] Scale46 <- Convolution46
I0818 10:58:39.745209  3083 net.cpp:509] Scale46 -> Convolution46 (in-place)
I0818 10:58:39.745255  3083 layer_factory.hpp:77] Creating layer Scale46
I0818 10:58:39.745393  3083 net.cpp:172] Setting up Scale46
I0818 10:58:39.745400  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.745404  3083 net.cpp:194] Memory required for data: 108748920
I0818 10:58:39.745412  3083 layer_factory.hpp:77] Creating layer ReLU44
I0818 10:58:39.745420  3083 net.cpp:128] Creating Layer ReLU44
I0818 10:58:39.745425  3083 net.cpp:558] ReLU44 <- Convolution46
I0818 10:58:39.745430  3083 net.cpp:509] ReLU44 -> Convolution46 (in-place)
I0818 10:58:39.746659  3083 net.cpp:172] Setting up ReLU44
I0818 10:58:39.746680  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.746685  3083 net.cpp:194] Memory required for data: 108912760
I0818 10:58:39.746690  3083 layer_factory.hpp:77] Creating layer Convolution47
I0818 10:58:39.746703  3083 net.cpp:128] Creating Layer Convolution47
I0818 10:58:39.746708  3083 net.cpp:558] Convolution47 <- Convolution46
I0818 10:58:39.746716  3083 net.cpp:522] Convolution47 -> Convolution47
I0818 10:58:39.753584  3083 net.cpp:172] Setting up Convolution47
I0818 10:58:39.753609  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.753614  3083 net.cpp:194] Memory required for data: 109076600
I0818 10:58:39.753626  3083 layer_factory.hpp:77] Creating layer BatchNorm47
I0818 10:58:39.753635  3083 net.cpp:128] Creating Layer BatchNorm47
I0818 10:58:39.753674  3083 net.cpp:558] BatchNorm47 <- Convolution47
I0818 10:58:39.753688  3083 net.cpp:509] BatchNorm47 -> Convolution47 (in-place)
I0818 10:58:39.753945  3083 net.cpp:172] Setting up BatchNorm47
I0818 10:58:39.753957  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.753960  3083 net.cpp:194] Memory required for data: 109240440
I0818 10:58:39.753971  3083 layer_factory.hpp:77] Creating layer Scale47
I0818 10:58:39.754004  3083 net.cpp:128] Creating Layer Scale47
I0818 10:58:39.754011  3083 net.cpp:558] Scale47 <- Convolution47
I0818 10:58:39.754017  3083 net.cpp:509] Scale47 -> Convolution47 (in-place)
I0818 10:58:39.754071  3083 layer_factory.hpp:77] Creating layer Scale47
I0818 10:58:39.754218  3083 net.cpp:172] Setting up Scale47
I0818 10:58:39.754228  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.754251  3083 net.cpp:194] Memory required for data: 109404280
I0818 10:58:39.754266  3083 layer_factory.hpp:77] Creating layer Eltwise22
I0818 10:58:39.754277  3083 net.cpp:128] Creating Layer Eltwise22
I0818 10:58:39.754285  3083 net.cpp:558] Eltwise22 <- Eltwise21_ReLU43_0_split_1
I0818 10:58:39.754292  3083 net.cpp:558] Eltwise22 <- Convolution47
I0818 10:58:39.754302  3083 net.cpp:522] Eltwise22 -> Eltwise22
I0818 10:58:39.754335  3083 net.cpp:172] Setting up Eltwise22
I0818 10:58:39.754345  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.754369  3083 net.cpp:194] Memory required for data: 109568120
I0818 10:58:39.754376  3083 layer_factory.hpp:77] Creating layer ReLU45
I0818 10:58:39.754415  3083 net.cpp:128] Creating Layer ReLU45
I0818 10:58:39.754423  3083 net.cpp:558] ReLU45 <- Eltwise22
I0818 10:58:39.754433  3083 net.cpp:509] ReLU45 -> Eltwise22 (in-place)
I0818 10:58:39.755707  3083 net.cpp:172] Setting up ReLU45
I0818 10:58:39.755744  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.755761  3083 net.cpp:194] Memory required for data: 109731960
I0818 10:58:39.755779  3083 layer_factory.hpp:77] Creating layer Eltwise22_ReLU45_0_split
I0818 10:58:39.755800  3083 net.cpp:128] Creating Layer Eltwise22_ReLU45_0_split
I0818 10:58:39.755818  3083 net.cpp:558] Eltwise22_ReLU45_0_split <- Eltwise22
I0818 10:58:39.755836  3083 net.cpp:522] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_0
I0818 10:58:39.755858  3083 net.cpp:522] Eltwise22_ReLU45_0_split -> Eltwise22_ReLU45_0_split_1
I0818 10:58:39.755924  3083 net.cpp:172] Setting up Eltwise22_ReLU45_0_split
I0818 10:58:39.755944  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.755959  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.755972  3083 net.cpp:194] Memory required for data: 110059640
I0818 10:58:39.755990  3083 layer_factory.hpp:77] Creating layer Convolution48
I0818 10:58:39.756012  3083 net.cpp:128] Creating Layer Convolution48
I0818 10:58:39.756027  3083 net.cpp:558] Convolution48 <- Eltwise22_ReLU45_0_split_0
I0818 10:58:39.756047  3083 net.cpp:522] Convolution48 -> Convolution48
I0818 10:58:39.765805  3083 net.cpp:172] Setting up Convolution48
I0818 10:58:39.765831  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.765836  3083 net.cpp:194] Memory required for data: 110223480
I0818 10:58:39.765847  3083 layer_factory.hpp:77] Creating layer BatchNorm48
I0818 10:58:39.765859  3083 net.cpp:128] Creating Layer BatchNorm48
I0818 10:58:39.765866  3083 net.cpp:558] BatchNorm48 <- Convolution48
I0818 10:58:39.765874  3083 net.cpp:509] BatchNorm48 -> Convolution48 (in-place)
I0818 10:58:39.766163  3083 net.cpp:172] Setting up BatchNorm48
I0818 10:58:39.766175  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.766180  3083 net.cpp:194] Memory required for data: 110387320
I0818 10:58:39.766223  3083 layer_factory.hpp:77] Creating layer Scale48
I0818 10:58:39.766247  3083 net.cpp:128] Creating Layer Scale48
I0818 10:58:39.766263  3083 net.cpp:558] Scale48 <- Convolution48
I0818 10:58:39.766283  3083 net.cpp:509] Scale48 -> Convolution48 (in-place)
I0818 10:58:39.766397  3083 layer_factory.hpp:77] Creating layer Scale48
I0818 10:58:39.766568  3083 net.cpp:172] Setting up Scale48
I0818 10:58:39.766580  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.766585  3083 net.cpp:194] Memory required for data: 110551160
I0818 10:58:39.766593  3083 layer_factory.hpp:77] Creating layer ReLU46
I0818 10:58:39.766619  3083 net.cpp:128] Creating Layer ReLU46
I0818 10:58:39.766634  3083 net.cpp:558] ReLU46 <- Convolution48
I0818 10:58:39.766677  3083 net.cpp:509] ReLU46 -> Convolution48 (in-place)
I0818 10:58:39.767581  3083 net.cpp:172] Setting up ReLU46
I0818 10:58:39.767607  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.767611  3083 net.cpp:194] Memory required for data: 110715000
I0818 10:58:39.767616  3083 layer_factory.hpp:77] Creating layer Convolution49
I0818 10:58:39.767632  3083 net.cpp:128] Creating Layer Convolution49
I0818 10:58:39.767666  3083 net.cpp:558] Convolution49 <- Convolution48
I0818 10:58:39.767688  3083 net.cpp:522] Convolution49 -> Convolution49
I0818 10:58:39.773996  3083 net.cpp:172] Setting up Convolution49
I0818 10:58:39.774024  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.774029  3083 net.cpp:194] Memory required for data: 110878840
I0818 10:58:39.774039  3083 layer_factory.hpp:77] Creating layer BatchNorm49
I0818 10:58:39.774047  3083 net.cpp:128] Creating Layer BatchNorm49
I0818 10:58:39.774052  3083 net.cpp:558] BatchNorm49 <- Convolution49
I0818 10:58:39.774060  3083 net.cpp:509] BatchNorm49 -> Convolution49 (in-place)
I0818 10:58:39.774294  3083 net.cpp:172] Setting up BatchNorm49
I0818 10:58:39.774333  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.774345  3083 net.cpp:194] Memory required for data: 111042680
I0818 10:58:39.774366  3083 layer_factory.hpp:77] Creating layer Scale49
I0818 10:58:39.774384  3083 net.cpp:128] Creating Layer Scale49
I0818 10:58:39.774401  3083 net.cpp:558] Scale49 <- Convolution49
I0818 10:58:39.774421  3083 net.cpp:509] Scale49 -> Convolution49 (in-place)
I0818 10:58:39.774484  3083 layer_factory.hpp:77] Creating layer Scale49
I0818 10:58:39.774643  3083 net.cpp:172] Setting up Scale49
I0818 10:58:39.774675  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.774689  3083 net.cpp:194] Memory required for data: 111206520
I0818 10:58:39.774708  3083 layer_factory.hpp:77] Creating layer Eltwise23
I0818 10:58:39.774729  3083 net.cpp:128] Creating Layer Eltwise23
I0818 10:58:39.774744  3083 net.cpp:558] Eltwise23 <- Eltwise22_ReLU45_0_split_1
I0818 10:58:39.774758  3083 net.cpp:558] Eltwise23 <- Convolution49
I0818 10:58:39.774777  3083 net.cpp:522] Eltwise23 -> Eltwise23
I0818 10:58:39.774824  3083 net.cpp:172] Setting up Eltwise23
I0818 10:58:39.774842  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.774855  3083 net.cpp:194] Memory required for data: 111370360
I0818 10:58:39.774869  3083 layer_factory.hpp:77] Creating layer ReLU47
I0818 10:58:39.774886  3083 net.cpp:128] Creating Layer ReLU47
I0818 10:58:39.774900  3083 net.cpp:558] ReLU47 <- Eltwise23
I0818 10:58:39.774915  3083 net.cpp:509] ReLU47 -> Eltwise23 (in-place)
I0818 10:58:39.775255  3083 net.cpp:172] Setting up ReLU47
I0818 10:58:39.775290  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.775305  3083 net.cpp:194] Memory required for data: 111534200
I0818 10:58:39.775319  3083 layer_factory.hpp:77] Creating layer Eltwise23_ReLU47_0_split
I0818 10:58:39.775338  3083 net.cpp:128] Creating Layer Eltwise23_ReLU47_0_split
I0818 10:58:39.775353  3083 net.cpp:558] Eltwise23_ReLU47_0_split <- Eltwise23
I0818 10:58:39.775373  3083 net.cpp:522] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_0
I0818 10:58:39.775393  3083 net.cpp:522] Eltwise23_ReLU47_0_split -> Eltwise23_ReLU47_0_split_1
I0818 10:58:39.775468  3083 net.cpp:172] Setting up Eltwise23_ReLU47_0_split
I0818 10:58:39.775504  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.775521  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.775537  3083 net.cpp:194] Memory required for data: 111861880
I0818 10:58:39.775554  3083 layer_factory.hpp:77] Creating layer Convolution50
I0818 10:58:39.775578  3083 net.cpp:128] Creating Layer Convolution50
I0818 10:58:39.775591  3083 net.cpp:558] Convolution50 <- Eltwise23_ReLU47_0_split_0
I0818 10:58:39.775609  3083 net.cpp:522] Convolution50 -> Convolution50
I0818 10:58:39.778523  3083 net.cpp:172] Setting up Convolution50
I0818 10:58:39.778573  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.778592  3083 net.cpp:194] Memory required for data: 112025720
I0818 10:58:39.778614  3083 layer_factory.hpp:77] Creating layer BatchNorm50
I0818 10:58:39.778631  3083 net.cpp:128] Creating Layer BatchNorm50
I0818 10:58:39.778646  3083 net.cpp:558] BatchNorm50 <- Convolution50
I0818 10:58:39.778684  3083 net.cpp:509] BatchNorm50 -> Convolution50 (in-place)
I0818 10:58:39.778959  3083 net.cpp:172] Setting up BatchNorm50
I0818 10:58:39.778982  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.778995  3083 net.cpp:194] Memory required for data: 112189560
I0818 10:58:39.779016  3083 layer_factory.hpp:77] Creating layer Scale50
I0818 10:58:39.779032  3083 net.cpp:128] Creating Layer Scale50
I0818 10:58:39.779047  3083 net.cpp:558] Scale50 <- Convolution50
I0818 10:58:39.779067  3083 net.cpp:509] Scale50 -> Convolution50 (in-place)
I0818 10:58:39.779130  3083 layer_factory.hpp:77] Creating layer Scale50
I0818 10:58:39.779305  3083 net.cpp:172] Setting up Scale50
I0818 10:58:39.779326  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.779340  3083 net.cpp:194] Memory required for data: 112353400
I0818 10:58:39.779358  3083 layer_factory.hpp:77] Creating layer ReLU48
I0818 10:58:39.779376  3083 net.cpp:128] Creating Layer ReLU48
I0818 10:58:39.779390  3083 net.cpp:558] ReLU48 <- Convolution50
I0818 10:58:39.779405  3083 net.cpp:509] ReLU48 -> Convolution50 (in-place)
I0818 10:58:39.779692  3083 net.cpp:172] Setting up ReLU48
I0818 10:58:39.779727  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.779742  3083 net.cpp:194] Memory required for data: 112517240
I0818 10:58:39.779757  3083 layer_factory.hpp:77] Creating layer Convolution51
I0818 10:58:39.779798  3083 net.cpp:128] Creating Layer Convolution51
I0818 10:58:39.779815  3083 net.cpp:558] Convolution51 <- Convolution50
I0818 10:58:39.779839  3083 net.cpp:522] Convolution51 -> Convolution51
I0818 10:58:39.782160  3083 net.cpp:172] Setting up Convolution51
I0818 10:58:39.782205  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.782214  3083 net.cpp:194] Memory required for data: 112681080
I0818 10:58:39.782227  3083 layer_factory.hpp:77] Creating layer BatchNorm51
I0818 10:58:39.782238  3083 net.cpp:128] Creating Layer BatchNorm51
I0818 10:58:39.782248  3083 net.cpp:558] BatchNorm51 <- Convolution51
I0818 10:58:39.782258  3083 net.cpp:509] BatchNorm51 -> Convolution51 (in-place)
I0818 10:58:39.782515  3083 net.cpp:172] Setting up BatchNorm51
I0818 10:58:39.782524  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.782529  3083 net.cpp:194] Memory required for data: 112844920
I0818 10:58:39.782541  3083 layer_factory.hpp:77] Creating layer Scale51
I0818 10:58:39.782549  3083 net.cpp:128] Creating Layer Scale51
I0818 10:58:39.782553  3083 net.cpp:558] Scale51 <- Convolution51
I0818 10:58:39.782562  3083 net.cpp:509] Scale51 -> Convolution51 (in-place)
I0818 10:58:39.782608  3083 layer_factory.hpp:77] Creating layer Scale51
I0818 10:58:39.782763  3083 net.cpp:172] Setting up Scale51
I0818 10:58:39.782773  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.782781  3083 net.cpp:194] Memory required for data: 113008760
I0818 10:58:39.782789  3083 layer_factory.hpp:77] Creating layer Eltwise24
I0818 10:58:39.782799  3083 net.cpp:128] Creating Layer Eltwise24
I0818 10:58:39.782806  3083 net.cpp:558] Eltwise24 <- Eltwise23_ReLU47_0_split_1
I0818 10:58:39.782829  3083 net.cpp:558] Eltwise24 <- Convolution51
I0818 10:58:39.782840  3083 net.cpp:522] Eltwise24 -> Eltwise24
I0818 10:58:39.782871  3083 net.cpp:172] Setting up Eltwise24
I0818 10:58:39.782881  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.782886  3083 net.cpp:194] Memory required for data: 113172600
I0818 10:58:39.782891  3083 layer_factory.hpp:77] Creating layer ReLU49
I0818 10:58:39.782899  3083 net.cpp:128] Creating Layer ReLU49
I0818 10:58:39.782905  3083 net.cpp:558] ReLU49 <- Eltwise24
I0818 10:58:39.782912  3083 net.cpp:509] ReLU49 -> Eltwise24 (in-place)
I0818 10:58:39.783516  3083 net.cpp:172] Setting up ReLU49
I0818 10:58:39.783541  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.783545  3083 net.cpp:194] Memory required for data: 113336440
I0818 10:58:39.783550  3083 layer_factory.hpp:77] Creating layer Eltwise24_ReLU49_0_split
I0818 10:58:39.783560  3083 net.cpp:128] Creating Layer Eltwise24_ReLU49_0_split
I0818 10:58:39.783568  3083 net.cpp:558] Eltwise24_ReLU49_0_split <- Eltwise24
I0818 10:58:39.783581  3083 net.cpp:522] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_0
I0818 10:58:39.783591  3083 net.cpp:522] Eltwise24_ReLU49_0_split -> Eltwise24_ReLU49_0_split_1
I0818 10:58:39.783656  3083 net.cpp:172] Setting up Eltwise24_ReLU49_0_split
I0818 10:58:39.783666  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.783675  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.783680  3083 net.cpp:194] Memory required for data: 113664120
I0818 10:58:39.783685  3083 layer_factory.hpp:77] Creating layer Convolution52
I0818 10:58:39.783697  3083 net.cpp:128] Creating Layer Convolution52
I0818 10:58:39.783704  3083 net.cpp:558] Convolution52 <- Eltwise24_ReLU49_0_split_0
I0818 10:58:39.783715  3083 net.cpp:522] Convolution52 -> Convolution52
I0818 10:58:39.788594  3083 net.cpp:172] Setting up Convolution52
I0818 10:58:39.788616  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.788621  3083 net.cpp:194] Memory required for data: 113827960
I0818 10:58:39.788631  3083 layer_factory.hpp:77] Creating layer BatchNorm52
I0818 10:58:39.788643  3083 net.cpp:128] Creating Layer BatchNorm52
I0818 10:58:39.788648  3083 net.cpp:558] BatchNorm52 <- Convolution52
I0818 10:58:39.788655  3083 net.cpp:509] BatchNorm52 -> Convolution52 (in-place)
I0818 10:58:39.788928  3083 net.cpp:172] Setting up BatchNorm52
I0818 10:58:39.788939  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.788944  3083 net.cpp:194] Memory required for data: 113991800
I0818 10:58:39.788954  3083 layer_factory.hpp:77] Creating layer Scale52
I0818 10:58:39.788967  3083 net.cpp:128] Creating Layer Scale52
I0818 10:58:39.788972  3083 net.cpp:558] Scale52 <- Convolution52
I0818 10:58:39.788978  3083 net.cpp:509] Scale52 -> Convolution52 (in-place)
I0818 10:58:39.789026  3083 layer_factory.hpp:77] Creating layer Scale52
I0818 10:58:39.789238  3083 net.cpp:172] Setting up Scale52
I0818 10:58:39.789250  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.789254  3083 net.cpp:194] Memory required for data: 114155640
I0818 10:58:39.789263  3083 layer_factory.hpp:77] Creating layer ReLU50
I0818 10:58:39.789284  3083 net.cpp:128] Creating Layer ReLU50
I0818 10:58:39.789289  3083 net.cpp:558] ReLU50 <- Convolution52
I0818 10:58:39.789296  3083 net.cpp:509] ReLU50 -> Convolution52 (in-place)
I0818 10:58:39.790330  3083 net.cpp:172] Setting up ReLU50
I0818 10:58:39.790351  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.790355  3083 net.cpp:194] Memory required for data: 114319480
I0818 10:58:39.790361  3083 layer_factory.hpp:77] Creating layer Convolution53
I0818 10:58:39.790372  3083 net.cpp:128] Creating Layer Convolution53
I0818 10:58:39.790379  3083 net.cpp:558] Convolution53 <- Convolution52
I0818 10:58:39.790393  3083 net.cpp:522] Convolution53 -> Convolution53
I0818 10:58:39.795549  3083 net.cpp:172] Setting up Convolution53
I0818 10:58:39.795575  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.795595  3083 net.cpp:194] Memory required for data: 114483320
I0818 10:58:39.795606  3083 layer_factory.hpp:77] Creating layer BatchNorm53
I0818 10:58:39.795616  3083 net.cpp:128] Creating Layer BatchNorm53
I0818 10:58:39.795622  3083 net.cpp:558] BatchNorm53 <- Convolution53
I0818 10:58:39.795629  3083 net.cpp:509] BatchNorm53 -> Convolution53 (in-place)
I0818 10:58:39.795883  3083 net.cpp:172] Setting up BatchNorm53
I0818 10:58:39.795897  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.795902  3083 net.cpp:194] Memory required for data: 114647160
I0818 10:58:39.795912  3083 layer_factory.hpp:77] Creating layer Scale53
I0818 10:58:39.795918  3083 net.cpp:128] Creating Layer Scale53
I0818 10:58:39.795923  3083 net.cpp:558] Scale53 <- Convolution53
I0818 10:58:39.795933  3083 net.cpp:509] Scale53 -> Convolution53 (in-place)
I0818 10:58:39.795984  3083 layer_factory.hpp:77] Creating layer Scale53
I0818 10:58:39.796128  3083 net.cpp:172] Setting up Scale53
I0818 10:58:39.796140  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.796150  3083 net.cpp:194] Memory required for data: 114811000
I0818 10:58:39.796159  3083 layer_factory.hpp:77] Creating layer Eltwise25
I0818 10:58:39.796167  3083 net.cpp:128] Creating Layer Eltwise25
I0818 10:58:39.796176  3083 net.cpp:558] Eltwise25 <- Eltwise24_ReLU49_0_split_1
I0818 10:58:39.796182  3083 net.cpp:558] Eltwise25 <- Convolution53
I0818 10:58:39.796190  3083 net.cpp:522] Eltwise25 -> Eltwise25
I0818 10:58:39.796219  3083 net.cpp:172] Setting up Eltwise25
I0818 10:58:39.796233  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.796238  3083 net.cpp:194] Memory required for data: 114974840
I0818 10:58:39.796243  3083 layer_factory.hpp:77] Creating layer ReLU51
I0818 10:58:39.796252  3083 net.cpp:128] Creating Layer ReLU51
I0818 10:58:39.796258  3083 net.cpp:558] ReLU51 <- Eltwise25
I0818 10:58:39.796264  3083 net.cpp:509] ReLU51 -> Eltwise25 (in-place)
I0818 10:58:39.796578  3083 net.cpp:172] Setting up ReLU51
I0818 10:58:39.796595  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.796599  3083 net.cpp:194] Memory required for data: 115138680
I0818 10:58:39.796604  3083 layer_factory.hpp:77] Creating layer Eltwise25_ReLU51_0_split
I0818 10:58:39.796617  3083 net.cpp:128] Creating Layer Eltwise25_ReLU51_0_split
I0818 10:58:39.796625  3083 net.cpp:558] Eltwise25_ReLU51_0_split <- Eltwise25
I0818 10:58:39.796633  3083 net.cpp:522] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_0
I0818 10:58:39.796643  3083 net.cpp:522] Eltwise25_ReLU51_0_split -> Eltwise25_ReLU51_0_split_1
I0818 10:58:39.796700  3083 net.cpp:172] Setting up Eltwise25_ReLU51_0_split
I0818 10:58:39.796710  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.796715  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.796721  3083 net.cpp:194] Memory required for data: 115466360
I0818 10:58:39.796725  3083 layer_factory.hpp:77] Creating layer Convolution54
I0818 10:58:39.796737  3083 net.cpp:128] Creating Layer Convolution54
I0818 10:58:39.796746  3083 net.cpp:558] Convolution54 <- Eltwise25_ReLU51_0_split_0
I0818 10:58:39.796754  3083 net.cpp:522] Convolution54 -> Convolution54
I0818 10:58:39.803886  3083 net.cpp:172] Setting up Convolution54
I0818 10:58:39.803917  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.803925  3083 net.cpp:194] Memory required for data: 115630200
I0818 10:58:39.803938  3083 layer_factory.hpp:77] Creating layer BatchNorm54
I0818 10:58:39.803949  3083 net.cpp:128] Creating Layer BatchNorm54
I0818 10:58:39.803954  3083 net.cpp:558] BatchNorm54 <- Convolution54
I0818 10:58:39.803964  3083 net.cpp:509] BatchNorm54 -> Convolution54 (in-place)
I0818 10:58:39.804237  3083 net.cpp:172] Setting up BatchNorm54
I0818 10:58:39.804247  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.804251  3083 net.cpp:194] Memory required for data: 115794040
I0818 10:58:39.804261  3083 layer_factory.hpp:77] Creating layer Scale54
I0818 10:58:39.804272  3083 net.cpp:128] Creating Layer Scale54
I0818 10:58:39.804277  3083 net.cpp:558] Scale54 <- Convolution54
I0818 10:58:39.804303  3083 net.cpp:509] Scale54 -> Convolution54 (in-place)
I0818 10:58:39.804355  3083 layer_factory.hpp:77] Creating layer Scale54
I0818 10:58:39.804560  3083 net.cpp:172] Setting up Scale54
I0818 10:58:39.804572  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.804577  3083 net.cpp:194] Memory required for data: 115957880
I0818 10:58:39.804585  3083 layer_factory.hpp:77] Creating layer ReLU52
I0818 10:58:39.804595  3083 net.cpp:128] Creating Layer ReLU52
I0818 10:58:39.804600  3083 net.cpp:558] ReLU52 <- Convolution54
I0818 10:58:39.804610  3083 net.cpp:509] ReLU52 -> Convolution54 (in-place)
I0818 10:58:39.807727  3083 net.cpp:172] Setting up ReLU52
I0818 10:58:39.807749  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.807754  3083 net.cpp:194] Memory required for data: 116121720
I0818 10:58:39.807760  3083 layer_factory.hpp:77] Creating layer Convolution55
I0818 10:58:39.807775  3083 net.cpp:128] Creating Layer Convolution55
I0818 10:58:39.807785  3083 net.cpp:558] Convolution55 <- Convolution54
I0818 10:58:39.807796  3083 net.cpp:522] Convolution55 -> Convolution55
I0818 10:58:39.817653  3083 net.cpp:172] Setting up Convolution55
I0818 10:58:39.817679  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.817684  3083 net.cpp:194] Memory required for data: 116285560
I0818 10:58:39.817694  3083 layer_factory.hpp:77] Creating layer BatchNorm55
I0818 10:58:39.817703  3083 net.cpp:128] Creating Layer BatchNorm55
I0818 10:58:39.817708  3083 net.cpp:558] BatchNorm55 <- Convolution55
I0818 10:58:39.817716  3083 net.cpp:509] BatchNorm55 -> Convolution55 (in-place)
I0818 10:58:39.817968  3083 net.cpp:172] Setting up BatchNorm55
I0818 10:58:39.817981  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.817986  3083 net.cpp:194] Memory required for data: 116449400
I0818 10:58:39.817996  3083 layer_factory.hpp:77] Creating layer Scale55
I0818 10:58:39.818004  3083 net.cpp:128] Creating Layer Scale55
I0818 10:58:39.818008  3083 net.cpp:558] Scale55 <- Convolution55
I0818 10:58:39.818014  3083 net.cpp:509] Scale55 -> Convolution55 (in-place)
I0818 10:58:39.818063  3083 layer_factory.hpp:77] Creating layer Scale55
I0818 10:58:39.818212  3083 net.cpp:172] Setting up Scale55
I0818 10:58:39.818220  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.818224  3083 net.cpp:194] Memory required for data: 116613240
I0818 10:58:39.818233  3083 layer_factory.hpp:77] Creating layer Eltwise26
I0818 10:58:39.818244  3083 net.cpp:128] Creating Layer Eltwise26
I0818 10:58:39.818250  3083 net.cpp:558] Eltwise26 <- Eltwise25_ReLU51_0_split_1
I0818 10:58:39.818256  3083 net.cpp:558] Eltwise26 <- Convolution55
I0818 10:58:39.818264  3083 net.cpp:522] Eltwise26 -> Eltwise26
I0818 10:58:39.818292  3083 net.cpp:172] Setting up Eltwise26
I0818 10:58:39.818305  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.818308  3083 net.cpp:194] Memory required for data: 116777080
I0818 10:58:39.818313  3083 layer_factory.hpp:77] Creating layer ReLU53
I0818 10:58:39.818322  3083 net.cpp:128] Creating Layer ReLU53
I0818 10:58:39.818327  3083 net.cpp:558] ReLU53 <- Eltwise26
I0818 10:58:39.818332  3083 net.cpp:509] ReLU53 -> Eltwise26 (in-place)
I0818 10:58:39.820104  3083 net.cpp:172] Setting up ReLU53
I0818 10:58:39.820130  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.820134  3083 net.cpp:194] Memory required for data: 116940920
I0818 10:58:39.820139  3083 layer_factory.hpp:77] Creating layer Eltwise26_ReLU53_0_split
I0818 10:58:39.820152  3083 net.cpp:128] Creating Layer Eltwise26_ReLU53_0_split
I0818 10:58:39.820158  3083 net.cpp:558] Eltwise26_ReLU53_0_split <- Eltwise26
I0818 10:58:39.820168  3083 net.cpp:522] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_0
I0818 10:58:39.820178  3083 net.cpp:522] Eltwise26_ReLU53_0_split -> Eltwise26_ReLU53_0_split_1
I0818 10:58:39.820235  3083 net.cpp:172] Setting up Eltwise26_ReLU53_0_split
I0818 10:58:39.820243  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.820273  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.820277  3083 net.cpp:194] Memory required for data: 117268600
I0818 10:58:39.820281  3083 layer_factory.hpp:77] Creating layer Convolution56
I0818 10:58:39.820294  3083 net.cpp:128] Creating Layer Convolution56
I0818 10:58:39.820299  3083 net.cpp:558] Convolution56 <- Eltwise26_ReLU53_0_split_0
I0818 10:58:39.820307  3083 net.cpp:522] Convolution56 -> Convolution56
I0818 10:58:39.826967  3083 net.cpp:172] Setting up Convolution56
I0818 10:58:39.826988  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.826993  3083 net.cpp:194] Memory required for data: 117432440
I0818 10:58:39.827003  3083 layer_factory.hpp:77] Creating layer BatchNorm56
I0818 10:58:39.827015  3083 net.cpp:128] Creating Layer BatchNorm56
I0818 10:58:39.827025  3083 net.cpp:558] BatchNorm56 <- Convolution56
I0818 10:58:39.827035  3083 net.cpp:509] BatchNorm56 -> Convolution56 (in-place)
I0818 10:58:39.827306  3083 net.cpp:172] Setting up BatchNorm56
I0818 10:58:39.827316  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.827320  3083 net.cpp:194] Memory required for data: 117596280
I0818 10:58:39.827330  3083 layer_factory.hpp:77] Creating layer Scale56
I0818 10:58:39.827339  3083 net.cpp:128] Creating Layer Scale56
I0818 10:58:39.827344  3083 net.cpp:558] Scale56 <- Convolution56
I0818 10:58:39.827349  3083 net.cpp:509] Scale56 -> Convolution56 (in-place)
I0818 10:58:39.827399  3083 layer_factory.hpp:77] Creating layer Scale56
I0818 10:58:39.827603  3083 net.cpp:172] Setting up Scale56
I0818 10:58:39.827615  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.827620  3083 net.cpp:194] Memory required for data: 117760120
I0818 10:58:39.827627  3083 layer_factory.hpp:77] Creating layer ReLU54
I0818 10:58:39.827642  3083 net.cpp:128] Creating Layer ReLU54
I0818 10:58:39.827651  3083 net.cpp:558] ReLU54 <- Convolution56
I0818 10:58:39.827657  3083 net.cpp:509] ReLU54 -> Convolution56 (in-place)
I0818 10:58:39.828728  3083 net.cpp:172] Setting up ReLU54
I0818 10:58:39.828747  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.828752  3083 net.cpp:194] Memory required for data: 117923960
I0818 10:58:39.828757  3083 layer_factory.hpp:77] Creating layer Convolution57
I0818 10:58:39.828770  3083 net.cpp:128] Creating Layer Convolution57
I0818 10:58:39.828778  3083 net.cpp:558] Convolution57 <- Convolution56
I0818 10:58:39.828788  3083 net.cpp:522] Convolution57 -> Convolution57
I0818 10:58:39.837702  3083 net.cpp:172] Setting up Convolution57
I0818 10:58:39.837729  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.837733  3083 net.cpp:194] Memory required for data: 118087800
I0818 10:58:39.837744  3083 layer_factory.hpp:77] Creating layer BatchNorm57
I0818 10:58:39.837754  3083 net.cpp:128] Creating Layer BatchNorm57
I0818 10:58:39.837760  3083 net.cpp:558] BatchNorm57 <- Convolution57
I0818 10:58:39.837774  3083 net.cpp:509] BatchNorm57 -> Convolution57 (in-place)
I0818 10:58:39.838032  3083 net.cpp:172] Setting up BatchNorm57
I0818 10:58:39.838042  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.838045  3083 net.cpp:194] Memory required for data: 118251640
I0818 10:58:39.838055  3083 layer_factory.hpp:77] Creating layer Scale57
I0818 10:58:39.838066  3083 net.cpp:128] Creating Layer Scale57
I0818 10:58:39.838070  3083 net.cpp:558] Scale57 <- Convolution57
I0818 10:58:39.838078  3083 net.cpp:509] Scale57 -> Convolution57 (in-place)
I0818 10:58:39.838125  3083 layer_factory.hpp:77] Creating layer Scale57
I0818 10:58:39.838304  3083 net.cpp:172] Setting up Scale57
I0818 10:58:39.838315  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.838320  3083 net.cpp:194] Memory required for data: 118415480
I0818 10:58:39.838328  3083 layer_factory.hpp:77] Creating layer Eltwise27
I0818 10:58:39.838340  3083 net.cpp:128] Creating Layer Eltwise27
I0818 10:58:39.838344  3083 net.cpp:558] Eltwise27 <- Eltwise26_ReLU53_0_split_1
I0818 10:58:39.838351  3083 net.cpp:558] Eltwise27 <- Convolution57
I0818 10:58:39.838358  3083 net.cpp:522] Eltwise27 -> Eltwise27
I0818 10:58:39.838405  3083 net.cpp:172] Setting up Eltwise27
I0818 10:58:39.838413  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.838416  3083 net.cpp:194] Memory required for data: 118579320
I0818 10:58:39.838420  3083 layer_factory.hpp:77] Creating layer ReLU55
I0818 10:58:39.838428  3083 net.cpp:128] Creating Layer ReLU55
I0818 10:58:39.838433  3083 net.cpp:558] ReLU55 <- Eltwise27
I0818 10:58:39.838438  3083 net.cpp:509] ReLU55 -> Eltwise27 (in-place)
I0818 10:58:39.841920  3083 net.cpp:172] Setting up ReLU55
I0818 10:58:39.841945  3083 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0818 10:58:39.841950  3083 net.cpp:194] Memory required for data: 118743160
I0818 10:58:39.841955  3083 layer_factory.hpp:77] Creating layer Pooling1
I0818 10:58:39.841965  3083 net.cpp:128] Creating Layer Pooling1
I0818 10:58:39.841970  3083 net.cpp:558] Pooling1 <- Eltwise27
I0818 10:58:39.841981  3083 net.cpp:522] Pooling1 -> Pooling1
I0818 10:58:39.846261  3083 net.cpp:172] Setting up Pooling1
I0818 10:58:39.846288  3083 net.cpp:186] Top shape: 10 64 1 1 (640)
I0818 10:58:39.846292  3083 net.cpp:194] Memory required for data: 118745720
I0818 10:58:39.846297  3083 layer_factory.hpp:77] Creating layer InnerProduct1
I0818 10:58:39.846310  3083 net.cpp:128] Creating Layer InnerProduct1
I0818 10:58:39.846316  3083 net.cpp:558] InnerProduct1 <- Pooling1
I0818 10:58:39.846328  3083 net.cpp:522] InnerProduct1 -> InnerProduct1
I0818 10:58:39.846515  3083 net.cpp:172] Setting up InnerProduct1
I0818 10:58:39.846559  3083 net.cpp:186] Top shape: 10 10 (100)
I0818 10:58:39.846576  3083 net.cpp:194] Memory required for data: 118746120
I0818 10:58:39.846601  3083 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0818 10:58:39.846621  3083 net.cpp:128] Creating Layer InnerProduct1_InnerProduct1_0_split
I0818 10:58:39.846640  3083 net.cpp:558] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0818 10:58:39.846673  3083 net.cpp:522] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0818 10:58:39.846698  3083 net.cpp:522] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0818 10:58:39.846766  3083 net.cpp:172] Setting up InnerProduct1_InnerProduct1_0_split
I0818 10:58:39.846789  3083 net.cpp:186] Top shape: 10 10 (100)
I0818 10:58:39.846804  3083 net.cpp:186] Top shape: 10 10 (100)
I0818 10:58:39.846817  3083 net.cpp:194] Memory required for data: 118746920
I0818 10:58:39.846830  3083 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0818 10:58:39.846848  3083 net.cpp:128] Creating Layer SoftmaxWithLoss1
I0818 10:58:39.846863  3083 net.cpp:558] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0818 10:58:39.846879  3083 net.cpp:558] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0818 10:58:39.846897  3083 net.cpp:522] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0818 10:58:39.846923  3083 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0818 10:58:39.850740  3083 net.cpp:172] Setting up SoftmaxWithLoss1
I0818 10:58:39.850761  3083 net.cpp:186] Top shape: (1)
I0818 10:58:39.850766  3083 net.cpp:189]     with loss weight 1
I0818 10:58:39.850781  3083 net.cpp:194] Memory required for data: 118746924
I0818 10:58:39.850786  3083 layer_factory.hpp:77] Creating layer Accuracy1
I0818 10:58:39.850824  3083 net.cpp:128] Creating Layer Accuracy1
I0818 10:58:39.850850  3083 net.cpp:558] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0818 10:58:39.850870  3083 net.cpp:558] Accuracy1 <- Data2_Data1_1_split_1
I0818 10:58:39.850894  3083 net.cpp:522] Accuracy1 -> Accuracy1
I0818 10:58:39.850919  3083 net.cpp:172] Setting up Accuracy1
I0818 10:58:39.850937  3083 net.cpp:186] Top shape: (1)
I0818 10:58:39.850952  3083 net.cpp:194] Memory required for data: 118746928
I0818 10:58:39.850970  3083 net.cpp:303] Accuracy1 does not need backward computation.
I0818 10:58:39.850986  3083 net.cpp:301] SoftmaxWithLoss1 needs backward computation.
I0818 10:58:39.851003  3083 net.cpp:301] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0818 10:58:39.851032  3083 net.cpp:301] InnerProduct1 needs backward computation.
I0818 10:58:39.851047  3083 net.cpp:301] Pooling1 needs backward computation.
I0818 10:58:39.851063  3083 net.cpp:301] ReLU55 needs backward computation.
I0818 10:58:39.851079  3083 net.cpp:301] Eltwise27 needs backward computation.
I0818 10:58:39.851096  3083 net.cpp:301] Scale57 needs backward computation.
I0818 10:58:39.851112  3083 net.cpp:301] BatchNorm57 needs backward computation.
I0818 10:58:39.851128  3083 net.cpp:301] Convolution57 needs backward computation.
I0818 10:58:39.851145  3083 net.cpp:301] ReLU54 needs backward computation.
I0818 10:58:39.851161  3083 net.cpp:301] Scale56 needs backward computation.
I0818 10:58:39.851177  3083 net.cpp:301] BatchNorm56 needs backward computation.
I0818 10:58:39.851194  3083 net.cpp:301] Convolution56 needs backward computation.
I0818 10:58:39.851225  3083 net.cpp:301] Eltwise26_ReLU53_0_split needs backward computation.
I0818 10:58:39.851243  3083 net.cpp:301] ReLU53 needs backward computation.
I0818 10:58:39.851258  3083 net.cpp:301] Eltwise26 needs backward computation.
I0818 10:58:39.851277  3083 net.cpp:301] Scale55 needs backward computation.
I0818 10:58:39.851294  3083 net.cpp:301] BatchNorm55 needs backward computation.
I0818 10:58:39.851310  3083 net.cpp:301] Convolution55 needs backward computation.
I0818 10:58:39.851327  3083 net.cpp:301] ReLU52 needs backward computation.
I0818 10:58:39.851344  3083 net.cpp:301] Scale54 needs backward computation.
I0818 10:58:39.851361  3083 net.cpp:301] BatchNorm54 needs backward computation.
I0818 10:58:39.851377  3083 net.cpp:301] Convolution54 needs backward computation.
I0818 10:58:39.851393  3083 net.cpp:301] Eltwise25_ReLU51_0_split needs backward computation.
I0818 10:58:39.851410  3083 net.cpp:301] ReLU51 needs backward computation.
I0818 10:58:39.851426  3083 net.cpp:301] Eltwise25 needs backward computation.
I0818 10:58:39.851444  3083 net.cpp:301] Scale53 needs backward computation.
I0818 10:58:39.851460  3083 net.cpp:301] BatchNorm53 needs backward computation.
I0818 10:58:39.851477  3083 net.cpp:301] Convolution53 needs backward computation.
I0818 10:58:39.851493  3083 net.cpp:301] ReLU50 needs backward computation.
I0818 10:58:39.851510  3083 net.cpp:301] Scale52 needs backward computation.
I0818 10:58:39.851541  3083 net.cpp:301] BatchNorm52 needs backward computation.
I0818 10:58:39.851557  3083 net.cpp:301] Convolution52 needs backward computation.
I0818 10:58:39.851575  3083 net.cpp:301] Eltwise24_ReLU49_0_split needs backward computation.
I0818 10:58:39.851591  3083 net.cpp:301] ReLU49 needs backward computation.
I0818 10:58:39.851608  3083 net.cpp:301] Eltwise24 needs backward computation.
I0818 10:58:39.851624  3083 net.cpp:301] Scale51 needs backward computation.
I0818 10:58:39.851640  3083 net.cpp:301] BatchNorm51 needs backward computation.
I0818 10:58:39.851656  3083 net.cpp:301] Convolution51 needs backward computation.
I0818 10:58:39.851673  3083 net.cpp:301] ReLU48 needs backward computation.
I0818 10:58:39.851689  3083 net.cpp:301] Scale50 needs backward computation.
I0818 10:58:39.851703  3083 net.cpp:301] BatchNorm50 needs backward computation.
I0818 10:58:39.851721  3083 net.cpp:301] Convolution50 needs backward computation.
I0818 10:58:39.851734  3083 net.cpp:301] Eltwise23_ReLU47_0_split needs backward computation.
I0818 10:58:39.851757  3083 net.cpp:301] ReLU47 needs backward computation.
I0818 10:58:39.851773  3083 net.cpp:301] Eltwise23 needs backward computation.
I0818 10:58:39.851790  3083 net.cpp:301] Scale49 needs backward computation.
I0818 10:58:39.851807  3083 net.cpp:301] BatchNorm49 needs backward computation.
I0818 10:58:39.851825  3083 net.cpp:301] Convolution49 needs backward computation.
I0818 10:58:39.851841  3083 net.cpp:301] ReLU46 needs backward computation.
I0818 10:58:39.851891  3083 net.cpp:301] Scale48 needs backward computation.
I0818 10:58:39.851910  3083 net.cpp:301] BatchNorm48 needs backward computation.
I0818 10:58:39.851927  3083 net.cpp:301] Convolution48 needs backward computation.
I0818 10:58:39.851950  3083 net.cpp:301] Eltwise22_ReLU45_0_split needs backward computation.
I0818 10:58:39.851969  3083 net.cpp:301] ReLU45 needs backward computation.
I0818 10:58:39.851985  3083 net.cpp:301] Eltwise22 needs backward computation.
I0818 10:58:39.852003  3083 net.cpp:301] Scale47 needs backward computation.
I0818 10:58:39.852020  3083 net.cpp:301] BatchNorm47 needs backward computation.
I0818 10:58:39.852035  3083 net.cpp:301] Convolution47 needs backward computation.
I0818 10:58:39.852052  3083 net.cpp:301] ReLU44 needs backward computation.
I0818 10:58:39.852068  3083 net.cpp:301] Scale46 needs backward computation.
I0818 10:58:39.852084  3083 net.cpp:301] BatchNorm46 needs backward computation.
I0818 10:58:39.852102  3083 net.cpp:301] Convolution46 needs backward computation.
I0818 10:58:39.852119  3083 net.cpp:301] Eltwise21_ReLU43_0_split needs backward computation.
I0818 10:58:39.852139  3083 net.cpp:301] ReLU43 needs backward computation.
I0818 10:58:39.852155  3083 net.cpp:301] Eltwise21 needs backward computation.
I0818 10:58:39.852186  3083 net.cpp:301] Scale45 needs backward computation.
I0818 10:58:39.852200  3083 net.cpp:301] BatchNorm45 needs backward computation.
I0818 10:58:39.852217  3083 net.cpp:301] Convolution45 needs backward computation.
I0818 10:58:39.852234  3083 net.cpp:301] ReLU42 needs backward computation.
I0818 10:58:39.852248  3083 net.cpp:301] Scale44 needs backward computation.
I0818 10:58:39.852265  3083 net.cpp:301] BatchNorm44 needs backward computation.
I0818 10:58:39.852279  3083 net.cpp:301] Convolution44 needs backward computation.
I0818 10:58:39.852298  3083 net.cpp:301] Eltwise20_ReLU41_0_split needs backward computation.
I0818 10:58:39.852314  3083 net.cpp:301] ReLU41 needs backward computation.
I0818 10:58:39.852329  3083 net.cpp:301] Eltwise20 needs backward computation.
I0818 10:58:39.852344  3083 net.cpp:301] Scale43 needs backward computation.
I0818 10:58:39.852361  3083 net.cpp:301] BatchNorm43 needs backward computation.
I0818 10:58:39.852378  3083 net.cpp:301] Convolution43 needs backward computation.
I0818 10:58:39.852394  3083 net.cpp:301] ReLU40 needs backward computation.
I0818 10:58:39.852409  3083 net.cpp:301] Scale42 needs backward computation.
I0818 10:58:39.852427  3083 net.cpp:301] BatchNorm42 needs backward computation.
I0818 10:58:39.852440  3083 net.cpp:301] Convolution42 needs backward computation.
I0818 10:58:39.852458  3083 net.cpp:301] Eltwise19_ReLU39_0_split needs backward computation.
I0818 10:58:39.852489  3083 net.cpp:301] ReLU39 needs backward computation.
I0818 10:58:39.852506  3083 net.cpp:301] Eltwise19 needs backward computation.
I0818 10:58:39.852524  3083 net.cpp:301] Scale41 needs backward computation.
I0818 10:58:39.852540  3083 net.cpp:301] BatchNorm41 needs backward computation.
I0818 10:58:39.852556  3083 net.cpp:301] Convolution41 needs backward computation.
I0818 10:58:39.852573  3083 net.cpp:301] ReLU38 needs backward computation.
I0818 10:58:39.852591  3083 net.cpp:301] Scale40 needs backward computation.
I0818 10:58:39.852607  3083 net.cpp:301] BatchNorm40 needs backward computation.
I0818 10:58:39.852622  3083 net.cpp:301] Convolution40 needs backward computation.
I0818 10:58:39.852640  3083 net.cpp:301] Scale39 needs backward computation.
I0818 10:58:39.852656  3083 net.cpp:301] BatchNorm39 needs backward computation.
I0818 10:58:39.852676  3083 net.cpp:301] Convolution39 needs backward computation.
I0818 10:58:39.852725  3083 net.cpp:301] Eltwise18_ReLU37_0_split needs backward computation.
I0818 10:58:39.852742  3083 net.cpp:301] ReLU37 needs backward computation.
I0818 10:58:39.852758  3083 net.cpp:301] Eltwise18 needs backward computation.
I0818 10:58:39.852777  3083 net.cpp:301] Scale38 needs backward computation.
I0818 10:58:39.852795  3083 net.cpp:301] BatchNorm38 needs backward computation.
I0818 10:58:39.852813  3083 net.cpp:301] Convolution38 needs backward computation.
I0818 10:58:39.852829  3083 net.cpp:301] ReLU36 needs backward computation.
I0818 10:58:39.852847  3083 net.cpp:301] Scale37 needs backward computation.
I0818 10:58:39.852870  3083 net.cpp:301] BatchNorm37 needs backward computation.
I0818 10:58:39.852903  3083 net.cpp:301] Convolution37 needs backward computation.
I0818 10:58:39.852921  3083 net.cpp:301] Eltwise17_ReLU35_0_split needs backward computation.
I0818 10:58:39.852938  3083 net.cpp:301] ReLU35 needs backward computation.
I0818 10:58:39.852955  3083 net.cpp:301] Eltwise17 needs backward computation.
I0818 10:58:39.852972  3083 net.cpp:301] Scale36 needs backward computation.
I0818 10:58:39.853003  3083 net.cpp:301] BatchNorm36 needs backward computation.
I0818 10:58:39.853019  3083 net.cpp:301] Convolution36 needs backward computation.
I0818 10:58:39.853036  3083 net.cpp:301] ReLU34 needs backward computation.
I0818 10:58:39.853052  3083 net.cpp:301] Scale35 needs backward computation.
I0818 10:58:39.853068  3083 net.cpp:301] BatchNorm35 needs backward computation.
I0818 10:58:39.853083  3083 net.cpp:301] Convolution35 needs backward computation.
I0818 10:58:39.853101  3083 net.cpp:301] Eltwise16_ReLU33_0_split needs backward computation.
I0818 10:58:39.853118  3083 net.cpp:301] ReLU33 needs backward computation.
I0818 10:58:39.853134  3083 net.cpp:301] Eltwise16 needs backward computation.
I0818 10:58:39.853152  3083 net.cpp:301] Scale34 needs backward computation.
I0818 10:58:39.853168  3083 net.cpp:301] BatchNorm34 needs backward computation.
I0818 10:58:39.853185  3083 net.cpp:301] Convolution34 needs backward computation.
I0818 10:58:39.853202  3083 net.cpp:301] ReLU32 needs backward computation.
I0818 10:58:39.853219  3083 net.cpp:301] Scale33 needs backward computation.
I0818 10:58:39.853232  3083 net.cpp:301] BatchNorm33 needs backward computation.
I0818 10:58:39.853250  3083 net.cpp:301] Convolution33 needs backward computation.
I0818 10:58:39.853267  3083 net.cpp:301] Eltwise15_ReLU31_0_split needs backward computation.
I0818 10:58:39.853282  3083 net.cpp:301] ReLU31 needs backward computation.
I0818 10:58:39.853298  3083 net.cpp:301] Eltwise15 needs backward computation.
I0818 10:58:39.853315  3083 net.cpp:301] Scale32 needs backward computation.
I0818 10:58:39.853330  3083 net.cpp:301] BatchNorm32 needs backward computation.
I0818 10:58:39.853346  3083 net.cpp:301] Convolution32 needs backward computation.
I0818 10:58:39.853360  3083 net.cpp:301] ReLU30 needs backward computation.
I0818 10:58:39.853375  3083 net.cpp:301] Scale31 needs backward computation.
I0818 10:58:39.853392  3083 net.cpp:301] BatchNorm31 needs backward computation.
I0818 10:58:39.853408  3083 net.cpp:301] Convolution31 needs backward computation.
I0818 10:58:39.853426  3083 net.cpp:301] Eltwise14_ReLU29_0_split needs backward computation.
I0818 10:58:39.853440  3083 net.cpp:301] ReLU29 needs backward computation.
I0818 10:58:39.853457  3083 net.cpp:301] Eltwise14 needs backward computation.
I0818 10:58:39.853472  3083 net.cpp:301] Scale30 needs backward computation.
I0818 10:58:39.853487  3083 net.cpp:301] BatchNorm30 needs backward computation.
I0818 10:58:39.853534  3083 net.cpp:301] Convolution30 needs backward computation.
I0818 10:58:39.853554  3083 net.cpp:301] ReLU28 needs backward computation.
I0818 10:58:39.853570  3083 net.cpp:301] Scale29 needs backward computation.
I0818 10:58:39.853585  3083 net.cpp:301] BatchNorm29 needs backward computation.
I0818 10:58:39.853600  3083 net.cpp:301] Convolution29 needs backward computation.
I0818 10:58:39.853619  3083 net.cpp:301] Eltwise13_ReLU27_0_split needs backward computation.
I0818 10:58:39.853636  3083 net.cpp:301] ReLU27 needs backward computation.
I0818 10:58:39.853652  3083 net.cpp:301] Eltwise13 needs backward computation.
I0818 10:58:39.853672  3083 net.cpp:301] Scale28 needs backward computation.
I0818 10:58:39.853689  3083 net.cpp:301] BatchNorm28 needs backward computation.
I0818 10:58:39.853732  3083 net.cpp:301] Convolution28 needs backward computation.
I0818 10:58:39.853751  3083 net.cpp:301] ReLU26 needs backward computation.
I0818 10:58:39.853768  3083 net.cpp:301] Scale27 needs backward computation.
I0818 10:58:39.853785  3083 net.cpp:301] BatchNorm27 needs backward computation.
I0818 10:58:39.853806  3083 net.cpp:301] Convolution27 needs backward computation.
I0818 10:58:39.853837  3083 net.cpp:301] Eltwise12_ReLU25_0_split needs backward computation.
I0818 10:58:39.853854  3083 net.cpp:301] ReLU25 needs backward computation.
I0818 10:58:39.853871  3083 net.cpp:301] Eltwise12 needs backward computation.
I0818 10:58:39.853888  3083 net.cpp:301] Scale26 needs backward computation.
I0818 10:58:39.853905  3083 net.cpp:301] BatchNorm26 needs backward computation.
I0818 10:58:39.853922  3083 net.cpp:301] Convolution26 needs backward computation.
I0818 10:58:39.853940  3083 net.cpp:301] ReLU24 needs backward computation.
I0818 10:58:39.853955  3083 net.cpp:301] Scale25 needs backward computation.
I0818 10:58:39.853972  3083 net.cpp:301] BatchNorm25 needs backward computation.
I0818 10:58:39.853988  3083 net.cpp:301] Convolution25 needs backward computation.
I0818 10:58:39.854005  3083 net.cpp:301] Eltwise11_ReLU23_0_split needs backward computation.
I0818 10:58:39.854022  3083 net.cpp:301] ReLU23 needs backward computation.
I0818 10:58:39.854038  3083 net.cpp:301] Eltwise11 needs backward computation.
I0818 10:58:39.854055  3083 net.cpp:301] Scale24 needs backward computation.
I0818 10:58:39.854073  3083 net.cpp:301] BatchNorm24 needs backward computation.
I0818 10:58:39.854089  3083 net.cpp:301] Convolution24 needs backward computation.
I0818 10:58:39.854105  3083 net.cpp:301] ReLU22 needs backward computation.
I0818 10:58:39.854122  3083 net.cpp:301] Scale23 needs backward computation.
I0818 10:58:39.854137  3083 net.cpp:301] BatchNorm23 needs backward computation.
I0818 10:58:39.854154  3083 net.cpp:301] Convolution23 needs backward computation.
I0818 10:58:39.854172  3083 net.cpp:301] Eltwise10_ReLU21_0_split needs backward computation.
I0818 10:58:39.854189  3083 net.cpp:301] ReLU21 needs backward computation.
I0818 10:58:39.854207  3083 net.cpp:301] Eltwise10 needs backward computation.
I0818 10:58:39.854223  3083 net.cpp:301] Scale22 needs backward computation.
I0818 10:58:39.854240  3083 net.cpp:301] BatchNorm22 needs backward computation.
I0818 10:58:39.854256  3083 net.cpp:301] Convolution22 needs backward computation.
I0818 10:58:39.854274  3083 net.cpp:301] ReLU20 needs backward computation.
I0818 10:58:39.854290  3083 net.cpp:301] Scale21 needs backward computation.
I0818 10:58:39.854306  3083 net.cpp:301] BatchNorm21 needs backward computation.
I0818 10:58:39.854323  3083 net.cpp:301] Convolution21 needs backward computation.
I0818 10:58:39.854344  3083 net.cpp:301] Scale20 needs backward computation.
I0818 10:58:39.854362  3083 net.cpp:301] BatchNorm20 needs backward computation.
I0818 10:58:39.854408  3083 net.cpp:301] Convolution20 needs backward computation.
I0818 10:58:39.854426  3083 net.cpp:301] Eltwise9_ReLU19_0_split needs backward computation.
I0818 10:58:39.854442  3083 net.cpp:301] ReLU19 needs backward computation.
I0818 10:58:39.854460  3083 net.cpp:301] Eltwise9 needs backward computation.
I0818 10:58:39.854476  3083 net.cpp:301] Scale19 needs backward computation.
I0818 10:58:39.854492  3083 net.cpp:301] BatchNorm19 needs backward computation.
I0818 10:58:39.854509  3083 net.cpp:301] Convolution19 needs backward computation.
I0818 10:58:39.854526  3083 net.cpp:301] ReLU18 needs backward computation.
I0818 10:58:39.854542  3083 net.cpp:301] Scale18 needs backward computation.
I0818 10:58:39.854560  3083 net.cpp:301] BatchNorm18 needs backward computation.
I0818 10:58:39.854590  3083 net.cpp:301] Convolution18 needs backward computation.
I0818 10:58:39.854607  3083 net.cpp:301] Eltwise8_ReLU17_0_split needs backward computation.
I0818 10:58:39.854624  3083 net.cpp:301] ReLU17 needs backward computation.
I0818 10:58:39.854640  3083 net.cpp:301] Eltwise8 needs backward computation.
I0818 10:58:39.854660  3083 net.cpp:301] Scale17 needs backward computation.
I0818 10:58:39.854692  3083 net.cpp:301] BatchNorm17 needs backward computation.
I0818 10:58:39.854709  3083 net.cpp:301] Convolution17 needs backward computation.
I0818 10:58:39.854733  3083 net.cpp:301] ReLU16 needs backward computation.
I0818 10:58:39.854748  3083 net.cpp:301] Scale16 needs backward computation.
I0818 10:58:39.854765  3083 net.cpp:301] BatchNorm16 needs backward computation.
I0818 10:58:39.854782  3083 net.cpp:301] Convolution16 needs backward computation.
I0818 10:58:39.854799  3083 net.cpp:301] Eltwise7_ReLU15_0_split needs backward computation.
I0818 10:58:39.854813  3083 net.cpp:301] ReLU15 needs backward computation.
I0818 10:58:39.854830  3083 net.cpp:301] Eltwise7 needs backward computation.
I0818 10:58:39.854845  3083 net.cpp:301] Scale15 needs backward computation.
I0818 10:58:39.854858  3083 net.cpp:301] BatchNorm15 needs backward computation.
I0818 10:58:39.854874  3083 net.cpp:301] Convolution15 needs backward computation.
I0818 10:58:39.854892  3083 net.cpp:301] ReLU14 needs backward computation.
I0818 10:58:39.854908  3083 net.cpp:301] Scale14 needs backward computation.
I0818 10:58:39.854923  3083 net.cpp:301] BatchNorm14 needs backward computation.
I0818 10:58:39.854939  3083 net.cpp:301] Convolution14 needs backward computation.
I0818 10:58:39.854954  3083 net.cpp:301] Eltwise6_ReLU13_0_split needs backward computation.
I0818 10:58:39.854971  3083 net.cpp:301] ReLU13 needs backward computation.
I0818 10:58:39.854988  3083 net.cpp:301] Eltwise6 needs backward computation.
I0818 10:58:39.855005  3083 net.cpp:301] Scale13 needs backward computation.
I0818 10:58:39.855022  3083 net.cpp:301] BatchNorm13 needs backward computation.
I0818 10:58:39.855036  3083 net.cpp:301] Convolution13 needs backward computation.
I0818 10:58:39.855053  3083 net.cpp:301] ReLU12 needs backward computation.
I0818 10:58:39.855068  3083 net.cpp:301] Scale12 needs backward computation.
I0818 10:58:39.855082  3083 net.cpp:301] BatchNorm12 needs backward computation.
I0818 10:58:39.855098  3083 net.cpp:301] Convolution12 needs backward computation.
I0818 10:58:39.855116  3083 net.cpp:301] Eltwise5_ReLU11_0_split needs backward computation.
I0818 10:58:39.855134  3083 net.cpp:301] ReLU11 needs backward computation.
I0818 10:58:39.855147  3083 net.cpp:301] Eltwise5 needs backward computation.
I0818 10:58:39.855168  3083 net.cpp:301] Scale11 needs backward computation.
I0818 10:58:39.855212  3083 net.cpp:301] BatchNorm11 needs backward computation.
I0818 10:58:39.855229  3083 net.cpp:301] Convolution11 needs backward computation.
I0818 10:58:39.855247  3083 net.cpp:301] ReLU10 needs backward computation.
I0818 10:58:39.855263  3083 net.cpp:301] Scale10 needs backward computation.
I0818 10:58:39.855280  3083 net.cpp:301] BatchNorm10 needs backward computation.
I0818 10:58:39.855296  3083 net.cpp:301] Convolution10 needs backward computation.
I0818 10:58:39.855314  3083 net.cpp:301] Eltwise4_ReLU9_0_split needs backward computation.
I0818 10:58:39.855330  3083 net.cpp:301] ReLU9 needs backward computation.
I0818 10:58:39.855347  3083 net.cpp:301] Eltwise4 needs backward computation.
I0818 10:58:39.855365  3083 net.cpp:301] Scale9 needs backward computation.
I0818 10:58:39.855406  3083 net.cpp:301] BatchNorm9 needs backward computation.
I0818 10:58:39.855424  3083 net.cpp:301] Convolution9 needs backward computation.
I0818 10:58:39.855442  3083 net.cpp:301] ReLU8 needs backward computation.
I0818 10:58:39.855458  3083 net.cpp:301] Scale8 needs backward computation.
I0818 10:58:39.855487  3083 net.cpp:301] BatchNorm8 needs backward computation.
I0818 10:58:39.855509  3083 net.cpp:301] Convolution8 needs backward computation.
I0818 10:58:39.855525  3083 net.cpp:301] Eltwise3_ReLU7_0_split needs backward computation.
I0818 10:58:39.855543  3083 net.cpp:301] ReLU7 needs backward computation.
I0818 10:58:39.855559  3083 net.cpp:301] Eltwise3 needs backward computation.
I0818 10:58:39.855577  3083 net.cpp:301] Scale7 needs backward computation.
I0818 10:58:39.855593  3083 net.cpp:301] BatchNorm7 needs backward computation.
I0818 10:58:39.855609  3083 net.cpp:301] Convolution7 needs backward computation.
I0818 10:58:39.855628  3083 net.cpp:301] ReLU6 needs backward computation.
I0818 10:58:39.855649  3083 net.cpp:301] Scale6 needs backward computation.
I0818 10:58:39.855665  3083 net.cpp:301] BatchNorm6 needs backward computation.
I0818 10:58:39.855681  3083 net.cpp:301] Convolution6 needs backward computation.
I0818 10:58:39.855700  3083 net.cpp:301] Eltwise2_ReLU5_0_split needs backward computation.
I0818 10:58:39.855717  3083 net.cpp:301] ReLU5 needs backward computation.
I0818 10:58:39.855733  3083 net.cpp:301] Eltwise2 needs backward computation.
I0818 10:58:39.855751  3083 net.cpp:301] Scale5 needs backward computation.
I0818 10:58:39.855767  3083 net.cpp:301] BatchNorm5 needs backward computation.
I0818 10:58:39.855783  3083 net.cpp:301] Convolution5 needs backward computation.
I0818 10:58:39.855800  3083 net.cpp:301] ReLU4 needs backward computation.
I0818 10:58:39.855816  3083 net.cpp:301] Scale4 needs backward computation.
I0818 10:58:39.855834  3083 net.cpp:301] BatchNorm4 needs backward computation.
I0818 10:58:39.855849  3083 net.cpp:301] Convolution4 needs backward computation.
I0818 10:58:39.855870  3083 net.cpp:301] Eltwise1_ReLU3_0_split needs backward computation.
I0818 10:58:39.855886  3083 net.cpp:301] ReLU3 needs backward computation.
I0818 10:58:39.855902  3083 net.cpp:301] Eltwise1 needs backward computation.
I0818 10:58:39.855919  3083 net.cpp:301] Scale3 needs backward computation.
I0818 10:58:39.855937  3083 net.cpp:301] BatchNorm3 needs backward computation.
I0818 10:58:39.855952  3083 net.cpp:301] Convolution3 needs backward computation.
I0818 10:58:39.855969  3083 net.cpp:301] ReLU2 needs backward computation.
I0818 10:58:39.855986  3083 net.cpp:301] Scale2 needs backward computation.
I0818 10:58:39.856003  3083 net.cpp:301] BatchNorm2 needs backward computation.
I0818 10:58:39.856020  3083 net.cpp:301] Convolution2 needs backward computation.
I0818 10:58:39.856035  3083 net.cpp:301] Convolution1_ReLU1_0_split needs backward computation.
I0818 10:58:39.856052  3083 net.cpp:301] ReLU1 needs backward computation.
I0818 10:58:39.856093  3083 net.cpp:301] Scale1 needs backward computation.
I0818 10:58:39.856111  3083 net.cpp:301] BatchNorm1 needs backward computation.
I0818 10:58:39.856127  3083 net.cpp:301] Convolution1 needs backward computation.
I0818 10:58:39.856144  3083 net.cpp:303] Data2_Data1_1_split does not need backward computation.
I0818 10:58:39.856159  3083 net.cpp:303] Data1 does not need backward computation.
I0818 10:58:39.856176  3083 net.cpp:348] This network produces output Accuracy1
I0818 10:58:39.856190  3083 net.cpp:348] This network produces output SoftmaxWithLoss1
I0818 10:58:39.856341  3083 net.cpp:363] Network initialization done.
I0818 10:58:39.857540  3083 solver.cpp:110] Solver scaffolding done.
I0818 10:58:39.876405  3083 caffe.cpp:313] Starting Optimization
I0818 10:58:39.876430  3083 solver.cpp:425] Solving resnet_cifar10
I0818 10:58:39.876435  3083 solver.cpp:427] Learning Rate Policy: multistep
I0818 10:58:39.886920  3083 solver.cpp:514] Iteration 0, Testing net (#0)
I0818 10:59:47.139878  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 10:59:47.457500  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0
I0818 10:59:47.457566  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 2.30259 (* 1 = 2.30259 loss)
I0818 10:59:48.663471  3083 solver.cpp:357] Iteration 0 (0 iter/s, 68.7873s/100 iters), loss = 4.73426
I0818 10:59:48.663553  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 5.08002 (* 1 = 5.08002 loss)
I0818 10:59:48.663600  3083 sgd_solver.cpp:165] Iteration 0, lr = 0.1
I0818 11:01:30.572109  3083 solver.cpp:357] Iteration 100 (0.981233 iter/s, 101.913s/100 iters), loss = 2.10186
I0818 11:01:30.572325  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 2.12054 (* 1 = 2.12054 loss)
I0818 11:01:30.572396  3083 sgd_solver.cpp:165] Iteration 100, lr = 0.1
I0818 11:03:17.783535  3083 solver.cpp:357] Iteration 200 (0.93271 iter/s, 107.214s/100 iters), loss = 1.85887
I0818 11:03:17.783812  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 1.94819 (* 1 = 1.94819 loss)
I0818 11:03:17.783843  3083 sgd_solver.cpp:165] Iteration 200, lr = 0.1
I0818 11:05:04.490046  3083 solver.cpp:357] Iteration 300 (0.937113 iter/s, 106.711s/100 iters), loss = 1.86524
I0818 11:05:04.490255  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 2.00068 (* 1 = 2.00068 loss)
I0818 11:05:04.490280  3083 sgd_solver.cpp:165] Iteration 300, lr = 0.1
I0818 11:06:30.087469  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:06:40.991932  3083 solver.cpp:357] Iteration 400 (1.03624 iter/s, 96.5028s/100 iters), loss = 1.63528
I0818 11:06:40.992002  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 1.51018 (* 1 = 1.51018 loss)
I0818 11:06:40.992013  3083 sgd_solver.cpp:165] Iteration 400, lr = 0.1
I0818 11:08:26.154772  3083 solver.cpp:514] Iteration 500, Testing net (#0)
I0818 11:09:33.935487  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:09:34.223412  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.2204
I0818 11:09:34.223475  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 2.17456 (* 1 = 2.17456 loss)
I0818 11:09:35.111204  3083 solver.cpp:357] Iteration 500 (0.574298 iter/s, 174.126s/100 iters), loss = 1.5518
I0818 11:09:35.111277  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 1.61749 (* 1 = 1.61749 loss)
I0818 11:09:35.111289  3083 sgd_solver.cpp:165] Iteration 500, lr = 0.1
I0818 11:11:22.515331  3083 solver.cpp:357] Iteration 600 (0.931057 iter/s, 107.405s/100 iters), loss = 1.48753
I0818 11:11:22.515499  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 1.60216 (* 1 = 1.60216 loss)
I0818 11:11:22.515511  3083 sgd_solver.cpp:165] Iteration 600, lr = 0.1
I0818 11:12:56.701910  3083 solver.cpp:357] Iteration 700 (1.06172 iter/s, 94.1865s/100 iters), loss = 1.28891
I0818 11:12:56.702064  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 1.3114 (* 1 = 1.3114 loss)
I0818 11:12:56.702075  3083 sgd_solver.cpp:165] Iteration 700, lr = 0.1
I0818 11:14:21.569804  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:14:44.693202  3083 solver.cpp:357] Iteration 800 (0.925979 iter/s, 107.994s/100 iters), loss = 1.21451
I0818 11:14:44.693272  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 1.18266 (* 1 = 1.18266 loss)
I0818 11:14:44.693282  3083 sgd_solver.cpp:165] Iteration 800, lr = 0.1
I0818 11:16:32.353055  3083 solver.cpp:357] Iteration 900 (0.928812 iter/s, 107.664s/100 iters), loss = 1.14303
I0818 11:16:32.353195  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 1.29903 (* 1 = 1.29903 loss)
I0818 11:16:32.353207  3083 sgd_solver.cpp:165] Iteration 900, lr = 0.1
I0818 11:18:11.934952  3083 solver.cpp:514] Iteration 1000, Testing net (#0)
I0818 11:19:17.102354  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:19:17.326007  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.1681
I0818 11:19:17.326104  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 2.81594 (* 1 = 2.81594 loss)
I0818 11:19:18.107269  3083 solver.cpp:357] Iteration 1000 (0.603301 iter/s, 165.755s/100 iters), loss = 0.95589
I0818 11:19:18.107342  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.880434 (* 1 = 0.880434 loss)
I0818 11:19:18.107355  3083 sgd_solver.cpp:165] Iteration 1000, lr = 0.1
I0818 11:21:02.029964  3083 solver.cpp:357] Iteration 1100 (0.962263 iter/s, 103.922s/100 iters), loss = 0.81073
I0818 11:21:02.030076  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.711935 (* 1 = 0.711935 loss)
I0818 11:21:02.030086  3083 sgd_solver.cpp:165] Iteration 1100, lr = 0.1
I0818 11:22:13.854341  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:22:42.440451  3083 solver.cpp:357] Iteration 1200 (0.995901 iter/s, 100.412s/100 iters), loss = 0.864926
I0818 11:22:42.440521  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.776523 (* 1 = 0.776523 loss)
I0818 11:22:42.440532  3083 sgd_solver.cpp:165] Iteration 1200, lr = 0.1
I0818 11:24:29.900754  3083 solver.cpp:357] Iteration 1300 (0.930563 iter/s, 107.462s/100 iters), loss = 0.760262
I0818 11:24:29.900992  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.792702 (* 1 = 0.792702 loss)
I0818 11:24:29.901006  3083 sgd_solver.cpp:165] Iteration 1300, lr = 0.1
I0818 11:26:15.776686  3083 solver.cpp:357] Iteration 1400 (0.944507 iter/s, 105.875s/100 iters), loss = 0.711837
I0818 11:26:15.777007  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.695926 (* 1 = 0.695926 loss)
I0818 11:26:15.777070  3083 sgd_solver.cpp:165] Iteration 1400, lr = 0.1
I0818 11:27:52.304991  3083 solver.cpp:514] Iteration 1500, Testing net (#0)
I0818 11:28:58.481520  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:28:58.818090  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.129499
I0818 11:28:58.818150  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 3.23569 (* 1 = 3.23569 loss)
I0818 11:28:59.674932  3083 solver.cpp:357] Iteration 1500 (0.610128 iter/s, 163.9s/100 iters), loss = 0.772475
I0818 11:28:59.674998  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.757674 (* 1 = 0.757674 loss)
I0818 11:28:59.675009  3083 sgd_solver.cpp:165] Iteration 1500, lr = 0.1
I0818 11:30:03.901216  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:30:47.589290  3083 solver.cpp:357] Iteration 1600 (0.926645 iter/s, 107.916s/100 iters), loss = 0.762863
I0818 11:30:47.589409  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.748712 (* 1 = 0.748712 loss)
I0818 11:30:47.589421  3083 sgd_solver.cpp:165] Iteration 1600, lr = 0.1
I0818 11:32:35.264153  3083 solver.cpp:357] Iteration 1700 (0.928706 iter/s, 107.677s/100 iters), loss = 0.859435
I0818 11:32:35.264286  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.852028 (* 1 = 0.852028 loss)
I0818 11:32:35.264297  3083 sgd_solver.cpp:165] Iteration 1700, lr = 0.1
I0818 11:34:09.674244  3083 solver.cpp:357] Iteration 1800 (1.05919 iter/s, 94.4116s/100 iters), loss = 0.841631
I0818 11:34:09.674422  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.788889 (* 1 = 0.788889 loss)
I0818 11:34:09.674435  3083 sgd_solver.cpp:165] Iteration 1800, lr = 0.1
I0818 11:35:57.071478  3083 solver.cpp:357] Iteration 1900 (0.931124 iter/s, 107.397s/100 iters), loss = 0.649493
I0818 11:35:57.071645  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.696697 (* 1 = 0.696697 loss)
I0818 11:35:57.071657  3083 sgd_solver.cpp:165] Iteration 1900, lr = 0.1
I0818 11:36:51.620925  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:37:44.073261  3083 solver.cpp:514] Iteration 2000, Testing net (#0)
I0818 11:38:44.150254  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:38:44.325466  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.102699
I0818 11:38:44.325527  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 2.58428 (* 1 = 2.58428 loss)
I0818 11:38:45.242854  3083 solver.cpp:357] Iteration 2000 (0.594616 iter/s, 168.176s/100 iters), loss = 0.591632
I0818 11:38:45.242928  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.434537 (* 1 = 0.434537 loss)
I0818 11:38:45.242939  3083 sgd_solver.cpp:165] Iteration 2000, lr = 0.1
I0818 11:40:29.412945  3083 solver.cpp:357] Iteration 2100 (0.959958 iter/s, 104.171s/100 iters), loss = 0.766456
I0818 11:40:29.413091  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.744704 (* 1 = 0.744704 loss)
I0818 11:40:29.413105  3083 sgd_solver.cpp:165] Iteration 2100, lr = 0.1
I0818 11:42:14.595855  3083 solver.cpp:357] Iteration 2200 (0.950707 iter/s, 105.185s/100 iters), loss = 0.761884
I0818 11:42:14.596040  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.674044 (* 1 = 0.674044 loss)
I0818 11:42:14.596065  3083 sgd_solver.cpp:165] Iteration 2200, lr = 0.1
I0818 11:43:54.825002  3083 solver.cpp:357] Iteration 2300 (0.997717 iter/s, 100.229s/100 iters), loss = 0.526883
I0818 11:43:54.825284  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.517989 (* 1 = 0.517989 loss)
I0818 11:43:54.825314  3083 sgd_solver.cpp:165] Iteration 2300, lr = 0.1
I0818 11:44:39.146716  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:45:42.375128  3083 solver.cpp:357] Iteration 2400 (0.929799 iter/s, 107.55s/100 iters), loss = 0.541534
I0818 11:45:42.375319  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.582891 (* 1 = 0.582891 loss)
I0818 11:45:42.375331  3083 sgd_solver.cpp:165] Iteration 2400, lr = 0.1
I0818 11:47:26.626818  3083 solver.cpp:514] Iteration 2500, Testing net (#0)
I0818 11:48:28.854249  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:48:29.120213  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.131899
I0818 11:48:29.120271  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 2.55097 (* 1 = 2.55097 loss)
I0818 11:48:29.881117  3083 solver.cpp:357] Iteration 2500 (0.596985 iter/s, 167.508s/100 iters), loss = 0.571101
I0818 11:48:29.881184  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.571265 (* 1 = 0.571265 loss)
I0818 11:48:29.881196  3083 sgd_solver.cpp:165] Iteration 2500, lr = 0.1
I0818 11:50:11.864441  3083 solver.cpp:357] Iteration 2600 (0.980534 iter/s, 101.985s/100 iters), loss = 0.784474
I0818 11:50:11.864593  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.630043 (* 1 = 0.630043 loss)
I0818 11:50:11.864605  3083 sgd_solver.cpp:165] Iteration 2600, lr = 0.1
I0818 11:51:59.422665  3083 solver.cpp:357] Iteration 2700 (0.929711 iter/s, 107.56s/100 iters), loss = 0.771617
I0818 11:51:59.422797  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.849419 (* 1 = 0.849419 loss)
I0818 11:51:59.422807  3083 sgd_solver.cpp:165] Iteration 2700, lr = 0.1
I0818 11:52:33.541352  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:53:46.803632  3083 solver.cpp:357] Iteration 2800 (0.931227 iter/s, 107.385s/100 iters), loss = 0.475336
I0818 11:53:46.803735  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.520535 (* 1 = 0.520535 loss)
I0818 11:53:46.803745  3083 sgd_solver.cpp:165] Iteration 2800, lr = 0.1
I0818 11:55:21.729014  3083 solver.cpp:357] Iteration 2900 (1.05342 iter/s, 94.929s/100 iters), loss = 0.525492
I0818 11:55:21.729187  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.435823 (* 1 = 0.435823 loss)
I0818 11:55:21.729198  3083 sgd_solver.cpp:165] Iteration 2900, lr = 0.1
I0818 11:57:08.546219  3083 solver.cpp:514] Iteration 3000, Testing net (#0)
I0818 11:58:16.105659  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 11:58:16.361887  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.2343
I0818 11:58:16.361956  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 2.09345 (* 1 = 2.09345 loss)
I0818 11:58:17.199381  3083 solver.cpp:357] Iteration 3000 (0.569881 iter/s, 175.475s/100 iters), loss = 0.481321
I0818 11:58:17.199452  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.560751 (* 1 = 0.560751 loss)
I0818 11:58:17.199463  3083 sgd_solver.cpp:165] Iteration 3000, lr = 0.1
I0818 11:59:57.534821  3083 solver.cpp:357] Iteration 3100 (0.996638 iter/s, 100.337s/100 iters), loss = 0.752727
I0818 11:59:57.534955  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.908817 (* 1 = 0.908817 loss)
I0818 11:59:57.534970  3083 sgd_solver.cpp:165] Iteration 3100, lr = 0.1
I0818 12:00:21.460001  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:01:40.603492  3083 solver.cpp:357] Iteration 3200 (0.970228 iter/s, 103.069s/100 iters), loss = 0.593167
I0818 12:01:40.603652  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.376168 (* 1 = 0.376168 loss)
I0818 12:01:40.603665  3083 sgd_solver.cpp:165] Iteration 3200, lr = 0.1
I0818 12:03:26.608350  3083 solver.cpp:357] Iteration 3300 (0.943346 iter/s, 106.006s/100 iters), loss = 0.58648
I0818 12:03:26.609875  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.562506 (* 1 = 0.562506 loss)
I0818 12:03:26.609890  3083 sgd_solver.cpp:165] Iteration 3300, lr = 0.1
I0818 12:05:06.838649  3083 solver.cpp:357] Iteration 3400 (0.997684 iter/s, 100.232s/100 iters), loss = 0.47789
I0818 12:05:06.838826  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.401103 (* 1 = 0.401103 loss)
I0818 12:05:06.838840  3083 sgd_solver.cpp:165] Iteration 3400, lr = 0.1
I0818 12:06:53.388015  3083 solver.cpp:514] Iteration 3500, Testing net (#0)
I0818 12:08:00.952529  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:08:01.243759  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.2955
I0818 12:08:01.243818  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.94588 (* 1 = 1.94588 loss)
I0818 12:08:02.013788  3083 solver.cpp:357] Iteration 3500 (0.570848 iter/s, 175.178s/100 iters), loss = 0.605592
I0818 12:08:02.013852  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.653696 (* 1 = 0.653696 loss)
I0818 12:08:02.013864  3083 sgd_solver.cpp:165] Iteration 3500, lr = 0.1
I0818 12:08:14.946861  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:09:42.171164  3083 solver.cpp:357] Iteration 3600 (0.998405 iter/s, 100.16s/100 iters), loss = 0.55317
I0818 12:09:42.171270  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.564756 (* 1 = 0.564756 loss)
I0818 12:09:42.171281  3083 sgd_solver.cpp:165] Iteration 3600, lr = 0.1
I0818 12:11:24.543208  3083 solver.cpp:357] Iteration 3700 (0.97686 iter/s, 102.369s/100 iters), loss = 0.482575
I0818 12:11:24.543329  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.499641 (* 1 = 0.499641 loss)
I0818 12:11:24.543339  3083 sgd_solver.cpp:165] Iteration 3700, lr = 0.1
I0818 12:13:12.253486  3083 solver.cpp:357] Iteration 3800 (0.92845 iter/s, 107.706s/100 iters), loss = 0.46694
I0818 12:13:12.253631  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.623705 (* 1 = 0.623705 loss)
I0818 12:13:12.253643  3083 sgd_solver.cpp:165] Iteration 3800, lr = 0.1
I0818 12:14:59.451931  3083 solver.cpp:357] Iteration 3900 (0.932875 iter/s, 107.195s/100 iters), loss = 0.543106
I0818 12:14:59.452069  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.629617 (* 1 = 0.629617 loss)
I0818 12:14:59.452082  3083 sgd_solver.cpp:165] Iteration 3900, lr = 0.1
I0818 12:15:02.833915  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:16:33.885035  3083 solver.cpp:514] Iteration 4000, Testing net (#0)
I0818 12:17:41.674253  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:17:41.926838  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6258
I0818 12:17:41.926897  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.08477 (* 1 = 1.08477 loss)
I0818 12:17:42.820816  3083 solver.cpp:357] Iteration 4000 (0.61212 iter/s, 163.367s/100 iters), loss = 0.646246
I0818 12:17:42.820891  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.511368 (* 1 = 0.511368 loss)
I0818 12:17:42.820901  3083 sgd_solver.cpp:165] Iteration 4000, lr = 0.1
I0818 12:19:30.112381  3083 solver.cpp:357] Iteration 4100 (0.932052 iter/s, 107.29s/100 iters), loss = 0.560636
I0818 12:19:30.112675  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.644731 (* 1 = 0.644731 loss)
I0818 12:19:30.112740  3083 sgd_solver.cpp:165] Iteration 4100, lr = 0.1
I0818 12:21:10.445060  3083 solver.cpp:357] Iteration 4200 (0.996715 iter/s, 100.33s/100 iters), loss = 0.507713
I0818 12:21:10.445263  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.385157 (* 1 = 0.385157 loss)
I0818 12:21:10.445292  3083 sgd_solver.cpp:165] Iteration 4200, lr = 0.1
I0818 12:22:47.169450  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:22:52.842417  3083 solver.cpp:357] Iteration 4300 (0.976594 iter/s, 102.397s/100 iters), loss = 0.536877
I0818 12:22:52.842492  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.424401 (* 1 = 0.424401 loss)
I0818 12:22:52.842504  3083 sgd_solver.cpp:165] Iteration 4300, lr = 0.1
I0818 12:24:40.146373  3083 solver.cpp:357] Iteration 4400 (0.931953 iter/s, 107.302s/100 iters), loss = 0.459674
I0818 12:24:40.146524  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.489897 (* 1 = 0.489897 loss)
I0818 12:24:40.146538  3083 sgd_solver.cpp:165] Iteration 4400, lr = 0.1
I0818 12:26:19.119318  3083 solver.cpp:514] Iteration 4500, Testing net (#0)
I0818 12:27:26.933374  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:27:27.103735  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.636
I0818 12:27:27.103785  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.07665 (* 1 = 1.07665 loss)
I0818 12:27:27.965095  3083 solver.cpp:357] Iteration 4500 (0.595884 iter/s, 167.818s/100 iters), loss = 0.638984
I0818 12:27:27.965170  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.478099 (* 1 = 0.478099 loss)
I0818 12:27:27.965180  3083 sgd_solver.cpp:165] Iteration 4500, lr = 0.1
I0818 12:29:13.773983  3083 solver.cpp:357] Iteration 4600 (0.945098 iter/s, 105.809s/100 iters), loss = 0.432495
I0818 12:29:13.774144  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.418171 (* 1 = 0.418171 loss)
I0818 12:29:13.774158  3083 sgd_solver.cpp:165] Iteration 4600, lr = 0.1
I0818 12:30:39.894052  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:30:54.239722  3083 solver.cpp:357] Iteration 4700 (0.995363 iter/s, 100.466s/100 iters), loss = 0.519501
I0818 12:30:54.239791  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.429143 (* 1 = 0.429143 loss)
I0818 12:30:54.239804  3083 sgd_solver.cpp:165] Iteration 4700, lr = 0.1
I0818 12:32:36.875804  3083 solver.cpp:357] Iteration 4800 (0.974322 iter/s, 102.636s/100 iters), loss = 0.505113
I0818 12:32:36.875942  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.623796 (* 1 = 0.623796 loss)
I0818 12:32:36.875954  3083 sgd_solver.cpp:165] Iteration 4800, lr = 0.1
I0818 12:34:24.412899  3083 solver.cpp:357] Iteration 4900 (0.929906 iter/s, 107.538s/100 iters), loss = 0.488488
I0818 12:34:24.413018  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.407874 (* 1 = 0.407874 loss)
I0818 12:34:24.413029  3083 sgd_solver.cpp:165] Iteration 4900, lr = 0.1
I0818 12:36:09.982864  3083 solver.cpp:514] Iteration 5000, Testing net (#0)
I0818 12:37:04.963659  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:37:05.248329  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.667
I0818 12:37:05.248389  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.03348 (* 1 = 1.03348 loss)
I0818 12:37:06.173940  3083 solver.cpp:357] Iteration 5000 (0.618188 iter/s, 161.763s/100 iters), loss = 0.320357
I0818 12:37:06.174015  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.394513 (* 1 = 0.394513 loss)
I0818 12:37:06.174026  3083 sgd_solver.cpp:165] Iteration 5000, lr = 0.1
I0818 12:38:27.182931  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:38:53.487484  3083 solver.cpp:357] Iteration 5100 (0.931861 iter/s, 107.312s/100 iters), loss = 0.508599
I0818 12:38:53.487565  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.444878 (* 1 = 0.444878 loss)
I0818 12:38:53.487576  3083 sgd_solver.cpp:165] Iteration 5100, lr = 0.1
I0818 12:40:40.656900  3083 solver.cpp:357] Iteration 5200 (0.933095 iter/s, 107.17s/100 iters), loss = 0.705452
I0818 12:40:40.657019  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.735491 (* 1 = 0.735491 loss)
I0818 12:40:40.657030  3083 sgd_solver.cpp:165] Iteration 5200, lr = 0.1
I0818 12:42:21.020965  3083 solver.cpp:357] Iteration 5300 (0.996346 iter/s, 100.367s/100 iters), loss = 0.651191
I0818 12:42:21.021123  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.676131 (* 1 = 0.676131 loss)
I0818 12:42:21.021133  3083 sgd_solver.cpp:165] Iteration 5300, lr = 0.1
I0818 12:44:02.776561  3083 solver.cpp:357] Iteration 5400 (0.982755 iter/s, 101.755s/100 iters), loss = 0.34289
I0818 12:44:02.776866  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.37926 (* 1 = 0.37926 loss)
I0818 12:44:02.776928  3083 sgd_solver.cpp:165] Iteration 5400, lr = 0.1
I0818 12:45:13.691313  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:45:49.040491  3083 solver.cpp:514] Iteration 5500, Testing net (#0)
I0818 12:46:53.251132  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:46:53.432848  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.565
I0818 12:46:53.432938  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.42513 (* 1 = 1.42513 loss)
I0818 12:46:54.196455  3083 solver.cpp:357] Iteration 5500 (0.583405 iter/s, 171.407s/100 iters), loss = 0.38312
I0818 12:46:54.196524  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.421026 (* 1 = 0.421026 loss)
I0818 12:46:54.196537  3083 sgd_solver.cpp:165] Iteration 5500, lr = 0.1
I0818 12:48:37.951102  3083 solver.cpp:357] Iteration 5600 (0.963873 iter/s, 103.748s/100 iters), loss = 0.434525
I0818 12:48:37.951220  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.34958 (* 1 = 0.34958 loss)
I0818 12:48:37.951230  3083 sgd_solver.cpp:165] Iteration 5600, lr = 0.1
I0818 12:50:23.443974  3083 solver.cpp:357] Iteration 5700 (0.94798 iter/s, 105.487s/100 iters), loss = 0.468624
I0818 12:50:23.445492  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.397003 (* 1 = 0.397003 loss)
I0818 12:50:23.445523  3083 sgd_solver.cpp:165] Iteration 5700, lr = 0.1
I0818 12:52:04.885558  3083 solver.cpp:357] Iteration 5800 (0.985853 iter/s, 101.435s/100 iters), loss = 0.355817
I0818 12:52:04.885712  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.360906 (* 1 = 0.360906 loss)
I0818 12:52:04.885725  3083 sgd_solver.cpp:165] Iteration 5800, lr = 0.1
I0818 12:53:00.565227  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:53:47.374719  3083 solver.cpp:357] Iteration 5900 (0.975748 iter/s, 102.485s/100 iters), loss = 0.614144
I0818 12:53:47.374861  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.497918 (* 1 = 0.497918 loss)
I0818 12:53:47.374872  3083 sgd_solver.cpp:165] Iteration 5900, lr = 0.1
I0818 12:55:34.172446  3083 solver.cpp:514] Iteration 6000, Testing net (#0)
I0818 12:56:42.050317  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 12:56:42.372128  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6928
I0818 12:56:42.372229  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.877602 (* 1 = 0.877602 loss)
I0818 12:56:43.206424  3083 solver.cpp:357] Iteration 6000 (0.568744 iter/s, 175.826s/100 iters), loss = 0.558098
I0818 12:56:43.206501  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.393068 (* 1 = 0.393068 loss)
I0818 12:56:43.206514  3083 sgd_solver.cpp:165] Iteration 6000, lr = 0.1
I0818 12:58:18.177628  3083 solver.cpp:357] Iteration 6100 (1.053 iter/s, 94.9668s/100 iters), loss = 0.53587
I0818 12:58:18.177846  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.55024 (* 1 = 0.55024 loss)
I0818 12:58:18.177875  3083 sgd_solver.cpp:165] Iteration 6100, lr = 0.1
I0818 13:00:05.751858  3083 solver.cpp:357] Iteration 6200 (0.92962 iter/s, 107.571s/100 iters), loss = 0.475185
I0818 13:00:05.752171  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.346378 (* 1 = 0.346378 loss)
I0818 13:00:05.752236  3083 sgd_solver.cpp:165] Iteration 6200, lr = 0.1
I0818 13:00:56.446224  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:01:53.235910  3083 solver.cpp:357] Iteration 6300 (0.930403 iter/s, 107.48s/100 iters), loss = 0.489962
I0818 13:01:53.236218  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.421178 (* 1 = 0.421178 loss)
I0818 13:01:53.236281  3083 sgd_solver.cpp:165] Iteration 6300, lr = 0.1
I0818 13:03:33.466529  3083 solver.cpp:357] Iteration 6400 (0.997714 iter/s, 100.229s/100 iters), loss = 0.629753
I0818 13:03:33.466739  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.728488 (* 1 = 0.728488 loss)
I0818 13:03:33.466753  3083 sgd_solver.cpp:165] Iteration 6400, lr = 0.1
I0818 13:05:14.283674  3083 solver.cpp:514] Iteration 6500, Testing net (#0)
I0818 13:06:22.233315  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:06:22.464509  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6712
I0818 13:06:22.464579  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.05124 (* 1 = 1.05124 loss)
I0818 13:06:23.371093  3083 solver.cpp:357] Iteration 6500 (0.588575 iter/s, 169.902s/100 iters), loss = 0.346237
I0818 13:06:23.371168  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.405396 (* 1 = 0.405396 loss)
I0818 13:06:23.371181  3083 sgd_solver.cpp:165] Iteration 6500, lr = 0.1
I0818 13:08:07.148799  3083 solver.cpp:357] Iteration 6600 (0.963627 iter/s, 103.775s/100 iters), loss = 0.455227
I0818 13:08:07.149178  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.448972 (* 1 = 0.448972 loss)
I0818 13:08:07.149207  3083 sgd_solver.cpp:165] Iteration 6600, lr = 0.1
I0818 13:08:45.067589  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:09:51.481245  3083 solver.cpp:357] Iteration 6700 (0.958479 iter/s, 104.332s/100 iters), loss = 0.445063
I0818 13:09:51.481369  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.467266 (* 1 = 0.467266 loss)
I0818 13:09:51.481380  3083 sgd_solver.cpp:165] Iteration 6700, lr = 0.1
I0818 13:11:35.602676  3083 solver.cpp:357] Iteration 6800 (0.960424 iter/s, 104.121s/100 iters), loss = 0.463552
I0818 13:11:35.602809  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.430735 (* 1 = 0.430735 loss)
I0818 13:11:35.602821  3083 sgd_solver.cpp:165] Iteration 6800, lr = 0.1
I0818 13:13:17.859776  3083 solver.cpp:357] Iteration 6900 (0.977934 iter/s, 102.256s/100 iters), loss = 0.421624
I0818 13:13:17.859894  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.334898 (* 1 = 0.334898 loss)
I0818 13:13:17.859906  3083 sgd_solver.cpp:165] Iteration 6900, lr = 0.1
I0818 13:14:59.961504  3083 solver.cpp:514] Iteration 7000, Testing net (#0)
I0818 13:16:07.757808  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:16:08.102171  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.7206
I0818 13:16:08.102231  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.803604 (* 1 = 0.803604 loss)
I0818 13:16:08.938938  3083 solver.cpp:357] Iteration 7000 (0.58453 iter/s, 171.077s/100 iters), loss = 0.470246
I0818 13:16:08.939003  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.508587 (* 1 = 0.508587 loss)
I0818 13:16:08.939014  3083 sgd_solver.cpp:165] Iteration 7000, lr = 0.1
I0818 13:16:39.666718  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:17:56.428267  3083 solver.cpp:357] Iteration 7100 (0.9303 iter/s, 107.492s/100 iters), loss = 0.431074
I0818 13:17:56.428373  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.490151 (* 1 = 0.490151 loss)
I0818 13:17:56.428385  3083 sgd_solver.cpp:165] Iteration 7100, lr = 0.1
I0818 13:19:31.238512  3083 solver.cpp:357] Iteration 7200 (1.05466 iter/s, 94.8173s/100 iters), loss = 0.647947
I0818 13:19:31.238632  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.583309 (* 1 = 0.583309 loss)
I0818 13:19:31.238644  3083 sgd_solver.cpp:165] Iteration 7200, lr = 0.1
I0818 13:21:18.748522  3083 solver.cpp:357] Iteration 7300 (0.930121 iter/s, 107.513s/100 iters), loss = 0.364194
I0818 13:21:18.748730  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.310932 (* 1 = 0.310932 loss)
I0818 13:21:18.748759  3083 sgd_solver.cpp:165] Iteration 7300, lr = 0.1
I0818 13:23:06.223680  3083 solver.cpp:357] Iteration 7400 (0.930411 iter/s, 107.479s/100 iters), loss = 0.472215
I0818 13:23:06.223887  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.462836 (* 1 = 0.462836 loss)
I0818 13:23:06.223898  3083 sgd_solver.cpp:165] Iteration 7400, lr = 0.1
I0818 13:23:26.971732  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:24:45.405462  3083 solver.cpp:514] Iteration 7500, Testing net (#0)
I0818 13:25:47.141767  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:25:47.372413  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.577301
I0818 13:25:47.372467  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.36749 (* 1 = 1.36749 loss)
I0818 13:25:48.169360  3083 solver.cpp:357] Iteration 7500 (0.617459 iter/s, 161.954s/100 iters), loss = 0.442116
I0818 13:25:48.169507  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.452447 (* 1 = 0.452447 loss)
I0818 13:25:48.169538  3083 sgd_solver.cpp:165] Iteration 7500, lr = 0.1
I0818 13:27:35.405385  3083 solver.cpp:357] Iteration 7600 (0.932516 iter/s, 107.237s/100 iters), loss = 0.495916
I0818 13:27:35.405531  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.313715 (* 1 = 0.313715 loss)
I0818 13:27:35.405542  3083 sgd_solver.cpp:165] Iteration 7600, lr = 0.1
I0818 13:29:18.802706  3083 solver.cpp:357] Iteration 7700 (0.967121 iter/s, 103.4s/100 iters), loss = 0.457589
I0818 13:29:18.802888  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.554888 (* 1 = 0.554888 loss)
I0818 13:29:18.802906  3083 sgd_solver.cpp:165] Iteration 7700, lr = 0.1
I0818 13:31:03.388252  3083 solver.cpp:357] Iteration 7800 (0.956137 iter/s, 104.588s/100 iters), loss = 0.416771
I0818 13:31:03.388417  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.465961 (* 1 = 0.465961 loss)
I0818 13:31:03.388429  3083 sgd_solver.cpp:165] Iteration 7800, lr = 0.1
I0818 13:31:13.668843  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:32:46.577081  3083 solver.cpp:357] Iteration 7900 (0.969101 iter/s, 103.188s/100 iters), loss = 0.346268
I0818 13:32:46.577215  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.426516 (* 1 = 0.426516 loss)
I0818 13:32:46.577229  3083 sgd_solver.cpp:165] Iteration 7900, lr = 0.1
I0818 13:34:28.740628  3083 solver.cpp:514] Iteration 8000, Testing net (#0)
I0818 13:35:31.706997  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:35:31.992780  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.733299
I0818 13:35:31.992841  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.84002 (* 1 = 0.84002 loss)
I0818 13:35:32.889780  3083 solver.cpp:357] Iteration 8000 (0.601263 iter/s, 166.316s/100 iters), loss = 0.443739
I0818 13:35:32.889945  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.524513 (* 1 = 0.524513 loss)
I0818 13:35:32.889989  3083 sgd_solver.cpp:165] Iteration 8000, lr = 0.1
I0818 13:37:20.475878  3083 solver.cpp:357] Iteration 8100 (0.929476 iter/s, 107.588s/100 iters), loss = 0.429224
I0818 13:37:20.476089  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.407396 (* 1 = 0.407396 loss)
I0818 13:37:20.476115  3083 sgd_solver.cpp:165] Iteration 8100, lr = 0.1
I0818 13:39:07.876590  3083 solver.cpp:357] Iteration 8200 (0.931081 iter/s, 107.402s/100 iters), loss = 0.616918
I0818 13:39:07.876741  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.654464 (* 1 = 0.654464 loss)
I0818 13:39:07.876754  3083 sgd_solver.cpp:165] Iteration 8200, lr = 0.1
I0818 13:39:08.502941  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:40:42.596484  3083 solver.cpp:357] Iteration 8300 (1.05574 iter/s, 94.7206s/100 iters), loss = 0.553566
I0818 13:40:42.596629  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.520015 (* 1 = 0.520015 loss)
I0818 13:40:42.596642  3083 sgd_solver.cpp:165] Iteration 8300, lr = 0.1
I0818 13:42:30.021409  3083 solver.cpp:357] Iteration 8400 (0.930891 iter/s, 107.424s/100 iters), loss = 0.411044
I0818 13:42:30.021600  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.437858 (* 1 = 0.437858 loss)
I0818 13:42:30.021612  3083 sgd_solver.cpp:165] Iteration 8400, lr = 0.1
I0818 13:44:16.398620  3083 solver.cpp:514] Iteration 8500, Testing net (#0)
I0818 13:45:18.199040  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:45:18.464349  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6816
I0818 13:45:18.464406  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.02593 (* 1 = 1.02593 loss)
I0818 13:45:19.223376  3083 solver.cpp:357] Iteration 8500 (0.591007 iter/s, 169.203s/100 iters), loss = 0.345859
I0818 13:45:19.223448  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.396848 (* 1 = 0.396848 loss)
I0818 13:45:19.223461  3083 sgd_solver.cpp:165] Iteration 8500, lr = 0.1
I0818 13:46:50.600335  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:46:59.509299  3083 solver.cpp:357] Iteration 8600 (0.997162 iter/s, 100.285s/100 iters), loss = 0.454339
I0818 13:46:59.509369  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.413249 (* 1 = 0.413249 loss)
I0818 13:46:59.509380  3083 sgd_solver.cpp:165] Iteration 8600, lr = 0.1
I0818 13:48:47.111507  3083 solver.cpp:357] Iteration 8700 (0.929341 iter/s, 107.603s/100 iters), loss = 0.41886
I0818 13:48:47.111626  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.408768 (* 1 = 0.408768 loss)
I0818 13:48:47.111639  3083 sgd_solver.cpp:165] Iteration 8700, lr = 0.1
I0818 13:50:29.928663  3083 solver.cpp:357] Iteration 8800 (0.972573 iter/s, 102.82s/100 iters), loss = 0.433143
I0818 13:50:29.928783  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.43126 (* 1 = 0.43126 loss)
I0818 13:50:29.928795  3083 sgd_solver.cpp:165] Iteration 8800, lr = 0.1
I0818 13:52:14.838724  3083 solver.cpp:357] Iteration 8900 (0.953203 iter/s, 104.909s/100 iters), loss = 0.475298
I0818 13:52:14.838853  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.381307 (* 1 = 0.381307 loss)
I0818 13:52:14.838865  3083 sgd_solver.cpp:165] Iteration 8900, lr = 0.1
I0818 13:53:39.094188  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:53:56.106936  3083 solver.cpp:514] Iteration 9000, Testing net (#0)
I0818 13:55:03.061094  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 13:55:03.250013  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.7302
I0818 13:55:03.250077  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.842203 (* 1 = 0.842203 loss)
I0818 13:55:04.132047  3083 solver.cpp:357] Iteration 9000 (0.590699 iter/s, 169.291s/100 iters), loss = 0.34288
I0818 13:55:04.132244  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.418768 (* 1 = 0.418768 loss)
I0818 13:55:04.132289  3083 sgd_solver.cpp:165] Iteration 9000, lr = 0.1
I0818 13:56:44.313699  3083 solver.cpp:357] Iteration 9100 (0.998204 iter/s, 100.18s/100 iters), loss = 0.452545
I0818 13:56:44.313838  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.523668 (* 1 = 0.523668 loss)
I0818 13:56:44.313848  3083 sgd_solver.cpp:165] Iteration 9100, lr = 0.1
I0818 13:58:31.663065  3083 solver.cpp:357] Iteration 9200 (0.931549 iter/s, 107.348s/100 iters), loss = 0.483858
I0818 13:58:31.663239  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.4112 (* 1 = 0.4112 loss)
I0818 13:58:31.663250  3083 sgd_solver.cpp:165] Iteration 9200, lr = 0.1
I0818 14:00:18.237866  3083 solver.cpp:357] Iteration 9300 (0.938335 iter/s, 106.572s/100 iters), loss = 0.445001
I0818 14:00:18.237987  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.474939 (* 1 = 0.474939 loss)
I0818 14:00:18.238000  3083 sgd_solver.cpp:165] Iteration 9300, lr = 0.1
I0818 14:01:23.599063  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:01:53.249195  3083 solver.cpp:357] Iteration 9400 (1.05254 iter/s, 95.0083s/100 iters), loss = 0.483484
I0818 14:01:53.249269  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.331649 (* 1 = 0.331649 loss)
I0818 14:01:53.249279  3083 sgd_solver.cpp:165] Iteration 9400, lr = 0.1
I0818 14:03:39.752902  3083 solver.cpp:514] Iteration 9500, Testing net (#0)
I0818 14:04:47.864104  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:04:48.031677  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.5083
I0818 14:04:48.031744  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 2.06272 (* 1 = 2.06272 loss)
I0818 14:04:48.927436  3083 solver.cpp:357] Iteration 9500 (0.569224 iter/s, 175.678s/100 iters), loss = 0.44212
I0818 14:04:48.927510  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.489061 (* 1 = 0.489061 loss)
I0818 14:04:48.927520  3083 sgd_solver.cpp:165] Iteration 9500, lr = 0.1
I0818 14:06:30.713953  3083 solver.cpp:357] Iteration 9600 (0.982452 iter/s, 101.786s/100 iters), loss = 0.41626
I0818 14:06:30.714064  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.445084 (* 1 = 0.445084 loss)
I0818 14:06:30.714074  3083 sgd_solver.cpp:165] Iteration 9600, lr = 0.1
I0818 14:08:11.175302  3083 solver.cpp:357] Iteration 9700 (0.995411 iter/s, 100.461s/100 iters), loss = 0.351258
I0818 14:08:11.175487  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.356698 (* 1 = 0.356698 loss)
I0818 14:08:11.175513  3083 sgd_solver.cpp:165] Iteration 9700, lr = 0.1
I0818 14:09:19.059537  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:09:58.647758  3083 solver.cpp:357] Iteration 9800 (0.93049 iter/s, 107.47s/100 iters), loss = 0.431978
I0818 14:09:58.647907  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.563012 (* 1 = 0.563012 loss)
I0818 14:09:58.647919  3083 sgd_solver.cpp:165] Iteration 9800, lr = 0.1
I0818 14:11:41.389026  3083 solver.cpp:357] Iteration 9900 (0.973339 iter/s, 102.739s/100 iters), loss = 0.341865
I0818 14:11:41.389180  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.35861 (* 1 = 0.35861 loss)
I0818 14:11:41.389194  3083 sgd_solver.cpp:165] Iteration 9900, lr = 0.1
I0818 14:13:25.589372  3083 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_56_iter_10000.caffemodel
I0818 14:13:25.639256  3083 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_56_iter_10000.solverstate
I0818 14:13:25.648475  3083 solver.cpp:514] Iteration 10000, Testing net (#0)
I0818 14:14:30.251513  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:14:30.518705  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.7445
I0818 14:14:30.518764  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.777113 (* 1 = 0.777113 loss)
I0818 14:14:31.275027  3083 solver.cpp:357] Iteration 10000 (0.588625 iter/s, 169.887s/100 iters), loss = 0.408836
I0818 14:14:31.275094  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.369451 (* 1 = 0.369451 loss)
I0818 14:14:31.275104  3083 sgd_solver.cpp:165] Iteration 10000, lr = 0.1
I0818 14:16:15.769278  3083 solver.cpp:357] Iteration 10100 (0.95697 iter/s, 104.496s/100 iters), loss = 0.513401
I0818 14:16:15.769412  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.566283 (* 1 = 0.566283 loss)
I0818 14:16:15.769423  3083 sgd_solver.cpp:165] Iteration 10100, lr = 0.1
I0818 14:17:06.863261  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:17:56.070369  3083 solver.cpp:357] Iteration 10200 (0.996998 iter/s, 100.301s/100 iters), loss = 0.379607
I0818 14:17:56.070530  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.401817 (* 1 = 0.401817 loss)
I0818 14:17:56.070542  3083 sgd_solver.cpp:165] Iteration 10200, lr = 0.1
I0818 14:19:43.552525  3083 solver.cpp:357] Iteration 10300 (0.930385 iter/s, 107.482s/100 iters), loss = 0.41248
I0818 14:19:43.552718  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.50879 (* 1 = 0.50879 loss)
I0818 14:19:43.552747  3083 sgd_solver.cpp:165] Iteration 10300, lr = 0.1
I0818 14:21:27.202456  3083 solver.cpp:357] Iteration 10400 (0.964784 iter/s, 103.65s/100 iters), loss = 0.546024
I0818 14:21:27.203140  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.736304 (* 1 = 0.736304 loss)
I0818 14:21:27.203320  3083 sgd_solver.cpp:165] Iteration 10400, lr = 0.1
I0818 14:22:59.636379  3083 solver.cpp:514] Iteration 10500, Testing net (#0)
I0818 14:24:06.903158  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:24:07.217128  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.437799
I0818 14:24:07.217177  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 2.5036 (* 1 = 2.5036 loss)
I0818 14:24:08.047806  3083 solver.cpp:357] Iteration 10500 (0.621709 iter/s, 160.847s/100 iters), loss = 0.536067
I0818 14:24:08.047884  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.667635 (* 1 = 0.667635 loss)
I0818 14:24:08.047896  3083 sgd_solver.cpp:165] Iteration 10500, lr = 0.1
I0818 14:24:55.681267  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:25:55.722800  3083 solver.cpp:357] Iteration 10600 (0.928737 iter/s, 107.673s/100 iters), loss = 0.464362
I0818 14:25:55.726845  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.482318 (* 1 = 0.482318 loss)
I0818 14:25:55.726877  3083 sgd_solver.cpp:165] Iteration 10600, lr = 0.1
I0818 14:27:37.425933  3083 solver.cpp:357] Iteration 10700 (0.983384 iter/s, 101.69s/100 iters), loss = 0.399747
I0818 14:27:37.426245  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.415444 (* 1 = 0.415444 loss)
I0818 14:27:37.426309  3083 sgd_solver.cpp:165] Iteration 10700, lr = 0.1
I0818 14:29:17.357039  3083 solver.cpp:357] Iteration 10800 (1.00077 iter/s, 99.923s/100 iters), loss = 0.358462
I0818 14:29:17.357177  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.375693 (* 1 = 0.375693 loss)
I0818 14:29:17.357189  3083 sgd_solver.cpp:165] Iteration 10800, lr = 0.1
I0818 14:31:05.048125  3083 solver.cpp:357] Iteration 10900 (0.928651 iter/s, 107.683s/100 iters), loss = 0.509463
I0818 14:31:05.048261  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.620761 (* 1 = 0.620761 loss)
I0818 14:31:05.048271  3083 sgd_solver.cpp:165] Iteration 10900, lr = 0.1
I0818 14:31:42.052039  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:32:46.618223  3083 solver.cpp:514] Iteration 11000, Testing net (#0)
I0818 14:33:50.609197  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:33:50.910740  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6487
I0818 14:33:50.910874  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.14577 (* 1 = 1.14577 loss)
I0818 14:33:51.802563  3083 solver.cpp:357] Iteration 11000 (0.599705 iter/s, 166.749s/100 iters), loss = 0.346076
I0818 14:33:51.806805  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.399822 (* 1 = 0.399822 loss)
I0818 14:33:51.806866  3083 sgd_solver.cpp:165] Iteration 11000, lr = 0.1
I0818 14:35:33.126756  3083 solver.cpp:357] Iteration 11100 (0.987028 iter/s, 101.314s/100 iters), loss = 0.387173
I0818 14:35:33.126974  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.485996 (* 1 = 0.485996 loss)
I0818 14:35:33.127002  3083 sgd_solver.cpp:165] Iteration 11100, lr = 0.1
I0818 14:37:17.521019  3083 solver.cpp:357] Iteration 11200 (0.957936 iter/s, 104.391s/100 iters), loss = 0.315975
I0818 14:37:17.526904  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.258551 (* 1 = 0.258551 loss)
I0818 14:37:17.526970  3083 sgd_solver.cpp:165] Iteration 11200, lr = 0.1
I0818 14:38:55.914764  3083 solver.cpp:357] Iteration 11300 (1.01641 iter/s, 98.3858s/100 iters), loss = 0.420658
I0818 14:38:55.915772  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.363371 (* 1 = 0.363371 loss)
I0818 14:38:55.915870  3083 sgd_solver.cpp:165] Iteration 11300, lr = 0.1
I0818 14:39:22.111057  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:40:40.772140  3083 solver.cpp:357] Iteration 11400 (0.953696 iter/s, 104.855s/100 iters), loss = 0.510407
I0818 14:40:40.772434  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.411799 (* 1 = 0.411799 loss)
I0818 14:40:40.772462  3083 sgd_solver.cpp:165] Iteration 11400, lr = 0.1
I0818 14:42:20.682636  3083 solver.cpp:514] Iteration 11500, Testing net (#0)
I0818 14:43:21.224333  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:43:21.466740  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6924
I0818 14:43:21.466879  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.89826 (* 1 = 0.89826 loss)
I0818 14:43:22.266027  3083 solver.cpp:357] Iteration 11500 (0.619239 iter/s, 161.489s/100 iters), loss = 0.508648
I0818 14:43:22.266232  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.453775 (* 1 = 0.453775 loss)
I0818 14:43:22.266278  3083 sgd_solver.cpp:165] Iteration 11500, lr = 0.1
I0818 14:45:05.090876  3083 solver.cpp:357] Iteration 11600 (0.972571 iter/s, 102.82s/100 iters), loss = 0.483072
I0818 14:45:05.094944  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.515668 (* 1 = 0.515668 loss)
I0818 14:45:05.095052  3083 sgd_solver.cpp:165] Iteration 11600, lr = 0.1
I0818 14:46:50.894768  3083 solver.cpp:357] Iteration 11700 (0.945207 iter/s, 105.797s/100 iters), loss = 0.355592
I0818 14:46:50.895175  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.178728 (* 1 = 0.178728 loss)
I0818 14:46:50.895272  3083 sgd_solver.cpp:165] Iteration 11700, lr = 0.1
I0818 14:47:08.219688  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:48:33.254724  3083 solver.cpp:357] Iteration 11800 (0.976997 iter/s, 102.354s/100 iters), loss = 0.537299
I0818 14:48:33.254935  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.447879 (* 1 = 0.447879 loss)
I0818 14:48:33.254961  3083 sgd_solver.cpp:165] Iteration 11800, lr = 0.1
I0818 14:50:07.531735  3083 solver.cpp:357] Iteration 11900 (1.06071 iter/s, 94.2766s/100 iters), loss = 0.435449
I0818 14:50:07.534818  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.426287 (* 1 = 0.426287 loss)
I0818 14:50:07.534858  3083 sgd_solver.cpp:165] Iteration 11900, lr = 0.1
I0818 14:51:52.012595  3083 solver.cpp:514] Iteration 12000, Testing net (#0)
I0818 14:52:59.757972  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:53:00.002756  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6602
I0818 14:53:00.002948  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.985912 (* 1 = 0.985912 loss)
I0818 14:53:00.861891  3083 solver.cpp:357] Iteration 12000 (0.576946 iter/s, 173.326s/100 iters), loss = 0.417418
I0818 14:53:00.862035  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.42803 (* 1 = 0.42803 loss)
I0818 14:53:00.862067  3083 sgd_solver.cpp:165] Iteration 12000, lr = 0.1
I0818 14:54:38.098810  3083 solver.cpp:357] Iteration 12100 (1.02844 iter/s, 97.2351s/100 iters), loss = 0.356784
I0818 14:54:38.099028  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.373118 (* 1 = 0.373118 loss)
I0818 14:54:38.099057  3083 sgd_solver.cpp:165] Iteration 12100, lr = 0.1
I0818 14:54:45.339840  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 14:56:16.415412  3083 solver.cpp:357] Iteration 12200 (1.01714 iter/s, 98.3149s/100 iters), loss = 0.317041
I0818 14:56:16.418786  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.316842 (* 1 = 0.316842 loss)
I0818 14:56:16.418825  3083 sgd_solver.cpp:165] Iteration 12200, lr = 0.1
I0818 14:58:01.509178  3083 solver.cpp:357] Iteration 12300 (0.951565 iter/s, 105.09s/100 iters), loss = 0.387066
I0818 14:58:01.514811  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.301282 (* 1 = 0.301282 loss)
I0818 14:58:01.514854  3083 sgd_solver.cpp:165] Iteration 12300, lr = 0.1
I0818 14:59:42.161056  3083 solver.cpp:357] Iteration 12400 (0.993583 iter/s, 100.646s/100 iters), loss = 0.57993
I0818 14:59:42.166774  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.56837 (* 1 = 0.56837 loss)
I0818 14:59:42.166808  3083 sgd_solver.cpp:165] Iteration 12400, lr = 0.1
I0818 15:01:25.156110  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:01:27.001835  3083 solver.cpp:514] Iteration 12500, Testing net (#0)
I0818 15:02:31.121057  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:02:31.407550  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.586
I0818 15:02:31.407714  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.48368 (* 1 = 1.48368 loss)
I0818 15:02:32.204423  3083 solver.cpp:357] Iteration 12500 (0.588024 iter/s, 170.061s/100 iters), loss = 0.456506
I0818 15:02:32.204634  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.379784 (* 1 = 0.379784 loss)
I0818 15:02:32.204681  3083 sgd_solver.cpp:165] Iteration 12500, lr = 0.1
I0818 15:04:11.115859  3083 solver.cpp:357] Iteration 12600 (1.01091 iter/s, 98.9206s/100 iters), loss = 0.517984
I0818 15:04:11.118770  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.466419 (* 1 = 0.466419 loss)
I0818 15:04:11.118804  3083 sgd_solver.cpp:165] Iteration 12600, lr = 0.1
I0818 15:05:48.654834  3083 solver.cpp:357] Iteration 12700 (1.02516 iter/s, 97.5461s/100 iters), loss = 0.539975
I0818 15:05:48.655452  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.464854 (* 1 = 0.464854 loss)
I0818 15:05:48.655633  3083 sgd_solver.cpp:165] Iteration 12700, lr = 0.1
I0818 15:07:35.897277  3083 solver.cpp:357] Iteration 12800 (0.932408 iter/s, 107.249s/100 iters), loss = 0.364076
I0818 15:07:35.897423  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.471811 (* 1 = 0.471811 loss)
I0818 15:07:35.897434  3083 sgd_solver.cpp:165] Iteration 12800, lr = 0.1
I0818 15:09:10.993631  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:09:23.266736  3083 solver.cpp:357] Iteration 12900 (0.931286 iter/s, 107.378s/100 iters), loss = 0.486753
I0818 15:09:23.266813  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.369082 (* 1 = 0.369082 loss)
I0818 15:09:23.266824  3083 sgd_solver.cpp:165] Iteration 12900, lr = 0.1
I0818 15:10:54.696131  3083 solver.cpp:514] Iteration 13000, Testing net (#0)
I0818 15:11:59.647828  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:11:59.917616  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.371899
I0818 15:11:59.917790  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 3.33075 (* 1 = 3.33075 loss)
I0818 15:12:00.800144  3083 solver.cpp:357] Iteration 13000 (0.634745 iter/s, 157.543s/100 iters), loss = 0.360064
I0818 15:12:00.800330  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.402406 (* 1 = 0.402406 loss)
I0818 15:12:00.800377  3083 sgd_solver.cpp:165] Iteration 13000, lr = 0.1
I0818 15:13:46.801823  3083 solver.cpp:357] Iteration 13100 (0.943356 iter/s, 106.005s/100 iters), loss = 0.393435
I0818 15:13:46.802039  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.443362 (* 1 = 0.443362 loss)
I0818 15:13:46.802068  3083 sgd_solver.cpp:165] Iteration 13100, lr = 0.1
I0818 15:15:26.918761  3083 solver.cpp:357] Iteration 13200 (0.998792 iter/s, 100.121s/100 iters), loss = 0.362292
I0818 15:15:26.922904  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.370059 (* 1 = 0.370059 loss)
I0818 15:15:26.922969  3083 sgd_solver.cpp:165] Iteration 13200, lr = 0.1
I0818 15:16:45.351518  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:17:06.919018  3083 solver.cpp:357] Iteration 13300 (0.999983 iter/s, 100.002s/100 iters), loss = 0.483307
I0818 15:17:06.919083  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.45029 (* 1 = 0.45029 loss)
I0818 15:17:06.919095  3083 sgd_solver.cpp:165] Iteration 13300, lr = 0.1
I0818 15:18:54.674891  3083 solver.cpp:357] Iteration 13400 (0.927993 iter/s, 107.759s/100 iters), loss = 0.57977
I0818 15:18:54.675127  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.529474 (* 1 = 0.529474 loss)
I0818 15:18:54.675139  3083 sgd_solver.cpp:165] Iteration 13400, lr = 0.1
I0818 15:20:36.148504  3083 solver.cpp:514] Iteration 13500, Testing net (#0)
I0818 15:21:42.014935  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:21:42.323843  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6829
I0818 15:21:42.323906  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.06656 (* 1 = 1.06656 loss)
I0818 15:21:43.185953  3083 solver.cpp:357] Iteration 13500 (0.593419 iter/s, 168.515s/100 iters), loss = 0.388623
I0818 15:21:43.186017  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.411719 (* 1 = 0.411719 loss)
I0818 15:21:43.186028  3083 sgd_solver.cpp:165] Iteration 13500, lr = 0.1
I0818 15:23:28.186658  3083 solver.cpp:357] Iteration 13600 (0.952332 iter/s, 105.005s/100 iters), loss = 0.35841
I0818 15:23:28.186786  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.303741 (* 1 = 0.303741 loss)
I0818 15:23:28.186799  3083 sgd_solver.cpp:165] Iteration 13600, lr = 0.1
I0818 15:24:39.144999  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:25:12.053913  3083 solver.cpp:357] Iteration 13700 (0.962741 iter/s, 103.87s/100 iters), loss = 0.424604
I0818 15:25:12.058797  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.417683 (* 1 = 0.417683 loss)
I0818 15:25:12.058835  3083 sgd_solver.cpp:165] Iteration 13700, lr = 0.1
I0818 15:26:50.001435  3083 solver.cpp:357] Iteration 13800 (1.02098 iter/s, 97.945s/100 iters), loss = 0.366935
I0818 15:26:50.007066  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.406183 (* 1 = 0.406183 loss)
I0818 15:26:50.007254  3083 sgd_solver.cpp:165] Iteration 13800, lr = 0.1
I0818 15:28:35.653235  3083 solver.cpp:357] Iteration 13900 (0.946526 iter/s, 105.65s/100 iters), loss = 0.416488
I0818 15:28:35.654206  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.357178 (* 1 = 0.357178 loss)
I0818 15:28:35.654259  3083 sgd_solver.cpp:165] Iteration 13900, lr = 0.1
I0818 15:30:20.244462  3083 solver.cpp:514] Iteration 14000, Testing net (#0)
I0818 15:31:15.847671  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:31:16.127575  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.616001
I0818 15:31:16.127624  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.24753 (* 1 = 1.24753 loss)
I0818 15:31:17.040664  3083 solver.cpp:357] Iteration 14000 (0.619611 iter/s, 161.392s/100 iters), loss = 0.368498
I0818 15:31:17.040735  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.41239 (* 1 = 0.41239 loss)
I0818 15:31:17.040746  3083 sgd_solver.cpp:165] Iteration 14000, lr = 0.1
I0818 15:32:21.160292  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:33:04.687934  3083 solver.cpp:357] Iteration 14100 (0.928962 iter/s, 107.647s/100 iters), loss = 0.368475
I0818 15:33:04.688057  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.332646 (* 1 = 0.332646 loss)
I0818 15:33:04.688071  3083 sgd_solver.cpp:165] Iteration 14100, lr = 0.1
I0818 15:34:52.541772  3083 solver.cpp:357] Iteration 14200 (0.927217 iter/s, 107.85s/100 iters), loss = 0.507892
I0818 15:34:52.541920  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.50068 (* 1 = 0.50068 loss)
I0818 15:34:52.541931  3083 sgd_solver.cpp:165] Iteration 14200, lr = 0.1
I0818 15:36:33.451635  3083 solver.cpp:357] Iteration 14300 (0.991053 iter/s, 100.903s/100 iters), loss = 0.490689
I0818 15:36:33.451885  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.328757 (* 1 = 0.328757 loss)
I0818 15:36:33.451933  3083 sgd_solver.cpp:165] Iteration 14300, lr = 0.1
I0818 15:38:14.210120  3083 solver.cpp:357] Iteration 14400 (0.992529 iter/s, 100.753s/100 iters), loss = 0.379892
I0818 15:38:14.210292  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.280648 (* 1 = 0.280648 loss)
I0818 15:38:14.210305  3083 sgd_solver.cpp:165] Iteration 14400, lr = 0.1
I0818 15:39:08.648716  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:40:00.823945  3083 solver.cpp:514] Iteration 14500, Testing net (#0)
I0818 15:41:08.711800  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:41:08.835764  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.644701
I0818 15:41:08.835824  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.20057 (* 1 = 1.20057 loss)
I0818 15:41:09.592450  3083 solver.cpp:357] Iteration 14500 (0.570209 iter/s, 175.374s/100 iters), loss = 0.453218
I0818 15:41:09.592587  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.336083 (* 1 = 0.336083 loss)
I0818 15:41:09.592619  3083 sgd_solver.cpp:165] Iteration 14500, lr = 0.1
I0818 15:42:49.922328  3083 solver.cpp:357] Iteration 14600 (0.996745 iter/s, 100.327s/100 iters), loss = 0.449015
I0818 15:42:49.922603  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.442299 (* 1 = 0.442299 loss)
I0818 15:42:49.922659  3083 sgd_solver.cpp:165] Iteration 14600, lr = 0.1
I0818 15:44:32.188199  3083 solver.cpp:357] Iteration 14700 (0.977889 iter/s, 102.261s/100 iters), loss = 0.411989
I0818 15:44:32.190788  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.452359 (* 1 = 0.452359 loss)
I0818 15:44:32.190829  3083 sgd_solver.cpp:165] Iteration 14700, lr = 0.1
I0818 15:46:15.482758  3083 solver.cpp:357] Iteration 14800 (0.968184 iter/s, 103.286s/100 iters), loss = 0.383808
I0818 15:46:15.482980  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.285099 (* 1 = 0.285099 loss)
I0818 15:46:15.483007  3083 sgd_solver.cpp:165] Iteration 14800, lr = 0.1
I0818 15:46:53.379428  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:47:52.380190  3083 solver.cpp:357] Iteration 14900 (1.03202 iter/s, 96.8974s/100 iters), loss = 0.279239
I0818 15:47:52.380442  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.278079 (* 1 = 0.278079 loss)
I0818 15:47:52.380470  3083 sgd_solver.cpp:165] Iteration 14900, lr = 0.1
I0818 15:49:35.755698  3083 solver.cpp:514] Iteration 15000, Testing net (#0)
I0818 15:50:44.123203  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:50:44.325855  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.544801
I0818 15:50:44.326040  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.55634 (* 1 = 1.55634 loss)
I0818 15:50:45.156236  3083 solver.cpp:357] Iteration 15000 (0.578793 iter/s, 172.773s/100 iters), loss = 0.491062
I0818 15:50:45.156471  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.422412 (* 1 = 0.422412 loss)
I0818 15:50:45.156519  3083 sgd_solver.cpp:165] Iteration 15000, lr = 0.1
I0818 15:52:16.729432  3083 solver.cpp:357] Iteration 15100 (1.09206 iter/s, 91.5701s/100 iters), loss = 0.386521
I0818 15:52:16.734870  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.297178 (* 1 = 0.297178 loss)
I0818 15:52:16.734927  3083 sgd_solver.cpp:165] Iteration 15100, lr = 0.1
I0818 15:53:59.887485  3083 solver.cpp:357] Iteration 15200 (0.969424 iter/s, 103.154s/100 iters), loss = 0.604006
I0818 15:53:59.905519  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.546277 (* 1 = 0.546277 loss)
I0818 15:53:59.905577  3083 sgd_solver.cpp:165] Iteration 15200, lr = 0.1
I0818 15:54:33.611743  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 15:55:45.699743  3083 solver.cpp:357] Iteration 15300 (0.945224 iter/s, 105.795s/100 iters), loss = 0.357643
I0818 15:55:45.702806  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.412271 (* 1 = 0.412271 loss)
I0818 15:55:45.702901  3083 sgd_solver.cpp:165] Iteration 15300, lr = 0.1
I0818 15:57:28.694795  3083 solver.cpp:357] Iteration 15400 (0.970944 iter/s, 102.993s/100 iters), loss = 0.464261
I0818 15:57:28.695001  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.394369 (* 1 = 0.394369 loss)
I0818 15:57:28.695027  3083 sgd_solver.cpp:165] Iteration 15400, lr = 0.1
I0818 15:59:00.770799  3083 solver.cpp:514] Iteration 15500, Testing net (#0)
I0818 16:00:08.738050  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:00:09.009060  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.541
I0818 16:00:09.009414  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.82271 (* 1 = 1.82271 loss)
I0818 16:00:09.801307  3083 solver.cpp:357] Iteration 15500 (0.620712 iter/s, 161.105s/100 iters), loss = 0.381133
I0818 16:00:09.801718  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.417387 (* 1 = 0.417387 loss)
I0818 16:00:09.801892  3083 sgd_solver.cpp:165] Iteration 15500, lr = 0.1
I0818 16:01:53.863755  3083 solver.cpp:357] Iteration 15600 (0.960962 iter/s, 104.062s/100 iters), loss = 0.379439
I0818 16:01:53.864317  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.457279 (* 1 = 0.457279 loss)
I0818 16:01:53.864495  3083 sgd_solver.cpp:165] Iteration 15600, lr = 0.1
I0818 16:02:17.816201  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:03:29.695060  3083 solver.cpp:357] Iteration 15700 (1.04353 iter/s, 95.829s/100 iters), loss = 0.454043
I0818 16:03:29.695367  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.300893 (* 1 = 0.300893 loss)
I0818 16:03:29.695396  3083 sgd_solver.cpp:165] Iteration 15700, lr = 0.1
I0818 16:05:07.626729  3083 solver.cpp:357] Iteration 15800 (1.02116 iter/s, 97.9281s/100 iters), loss = 0.391436
I0818 16:05:07.626968  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.425851 (* 1 = 0.425851 loss)
I0818 16:05:07.626994  3083 sgd_solver.cpp:165] Iteration 15800, lr = 0.1
I0818 16:06:52.144127  3083 solver.cpp:357] Iteration 15900 (0.956771 iter/s, 104.518s/100 iters), loss = 0.302813
I0818 16:06:52.146772  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.300175 (* 1 = 0.300175 loss)
I0818 16:06:52.146806  3083 sgd_solver.cpp:165] Iteration 15900, lr = 0.1
I0818 16:08:30.745791  3083 solver.cpp:514] Iteration 16000, Testing net (#0)
I0818 16:09:35.863821  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:09:36.172906  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6974
I0818 16:09:36.173079  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.03822 (* 1 = 1.03822 loss)
I0818 16:09:37.016119  3083 solver.cpp:357] Iteration 16000 (0.606536 iter/s, 164.871s/100 iters), loss = 0.382777
I0818 16:09:37.016314  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.38744 (* 1 = 0.38744 loss)
I0818 16:09:37.016345  3083 sgd_solver.cpp:165] Iteration 16000, lr = 0.1
I0818 16:09:50.818799  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:11:21.115563  3083 solver.cpp:357] Iteration 16100 (0.960633 iter/s, 104.098s/100 iters), loss = 0.357741
I0818 16:11:21.118937  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.28555 (* 1 = 0.28555 loss)
I0818 16:11:21.119041  3083 sgd_solver.cpp:165] Iteration 16100, lr = 0.1
I0818 16:13:00.622155  3083 solver.cpp:357] Iteration 16200 (1.00498 iter/s, 99.504s/100 iters), loss = 0.392357
I0818 16:13:00.622339  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.368385 (* 1 = 0.368385 loss)
I0818 16:13:00.622364  3083 sgd_solver.cpp:165] Iteration 16200, lr = 0.1
I0818 16:14:39.644878  3083 solver.cpp:357] Iteration 16300 (1.00989 iter/s, 99.0202s/100 iters), loss = 0.267705
I0818 16:14:39.646791  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.383777 (* 1 = 0.383777 loss)
I0818 16:14:39.646838  3083 sgd_solver.cpp:165] Iteration 16300, lr = 0.1
I0818 16:16:25.614794  3083 solver.cpp:357] Iteration 16400 (0.943694 iter/s, 105.967s/100 iters), loss = 0.397628
I0818 16:16:25.615048  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.460378 (* 1 = 0.460378 loss)
I0818 16:16:25.615080  3083 sgd_solver.cpp:165] Iteration 16400, lr = 0.1
I0818 16:16:29.855386  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:18:11.473999  3083 solver.cpp:514] Iteration 16500, Testing net (#0)
I0818 16:19:03.524209  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:19:03.706751  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6593
I0818 16:19:03.706926  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.112 (* 1 = 1.112 loss)
I0818 16:19:04.591496  3083 solver.cpp:357] Iteration 16500 (0.629015 iter/s, 158.979s/100 iters), loss = 0.353715
I0818 16:19:04.591653  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.320102 (* 1 = 0.320102 loss)
I0818 16:19:04.591684  3083 sgd_solver.cpp:165] Iteration 16500, lr = 0.1
I0818 16:20:49.558743  3083 solver.cpp:357] Iteration 16600 (0.952769 iter/s, 104.957s/100 iters), loss = 0.366083
I0818 16:20:49.558974  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.455711 (* 1 = 0.455711 loss)
I0818 16:20:49.559001  3083 sgd_solver.cpp:165] Iteration 16600, lr = 0.1
I0818 16:22:35.831750  3083 solver.cpp:357] Iteration 16700 (0.94096 iter/s, 106.274s/100 iters), loss = 0.328184
I0818 16:22:35.834790  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.256717 (* 1 = 0.256717 loss)
I0818 16:22:35.834831  3083 sgd_solver.cpp:165] Iteration 16700, lr = 0.1
I0818 16:24:11.471777  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:24:16.819300  3083 solver.cpp:357] Iteration 16800 (0.990243 iter/s, 100.985s/100 iters), loss = 0.366669
I0818 16:24:16.819509  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.367402 (* 1 = 0.367402 loss)
I0818 16:24:16.819558  3083 sgd_solver.cpp:165] Iteration 16800, lr = 0.1
I0818 16:25:52.910738  3083 solver.cpp:357] Iteration 16900 (1.04072 iter/s, 96.0869s/100 iters), loss = 0.427971
I0818 16:25:52.935739  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.464677 (* 1 = 0.464677 loss)
I0818 16:25:52.935788  3083 sgd_solver.cpp:165] Iteration 16900, lr = 0.1
I0818 16:27:38.491916  3083 solver.cpp:514] Iteration 17000, Testing net (#0)
I0818 16:28:45.975157  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:28:46.331537  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.7259
I0818 16:28:46.331668  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.881523 (* 1 = 0.881523 loss)
I0818 16:28:47.159703  3083 solver.cpp:357] Iteration 17000 (0.573963 iter/s, 174.227s/100 iters), loss = 0.480969
I0818 16:28:47.159886  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.39306 (* 1 = 0.39306 loss)
I0818 16:28:47.159934  3083 sgd_solver.cpp:165] Iteration 17000, lr = 0.1
I0818 16:30:23.078397  3083 solver.cpp:357] Iteration 17100 (1.04255 iter/s, 95.9186s/100 iters), loss = 0.395511
I0818 16:30:23.082864  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.355253 (* 1 = 0.355253 loss)
I0818 16:30:23.082927  3083 sgd_solver.cpp:165] Iteration 17100, lr = 0.1
I0818 16:31:51.689422  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:32:07.098443  3083 solver.cpp:357] Iteration 17200 (0.961411 iter/s, 104.014s/100 iters), loss = 0.348018
I0818 16:32:07.098646  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.27067 (* 1 = 0.27067 loss)
I0818 16:32:07.098702  3083 sgd_solver.cpp:165] Iteration 17200, lr = 0.1
I0818 16:33:48.804567  3083 solver.cpp:357] Iteration 17300 (0.98323 iter/s, 101.706s/100 iters), loss = 0.355071
I0818 16:33:48.805130  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.338865 (* 1 = 0.338865 loss)
I0818 16:33:48.805387  3083 sgd_solver.cpp:165] Iteration 17300, lr = 0.1
I0818 16:35:28.647871  3083 solver.cpp:357] Iteration 17400 (1.00159 iter/s, 99.8413s/100 iters), loss = 0.399815
I0818 16:35:28.654798  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.314352 (* 1 = 0.314352 loss)
I0818 16:35:28.654836  3083 sgd_solver.cpp:165] Iteration 17400, lr = 0.1
I0818 16:37:13.442548  3083 solver.cpp:514] Iteration 17500, Testing net (#0)
I0818 16:38:18.724676  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:38:18.957545  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.652101
I0818 16:38:18.957919  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.1303 (* 1 = 1.1303 loss)
I0818 16:38:19.790271  3083 solver.cpp:357] Iteration 17500 (0.584325 iter/s, 171.138s/100 iters), loss = 0.335963
I0818 16:38:19.790711  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.314593 (* 1 = 0.314593 loss)
I0818 16:38:19.790892  3083 sgd_solver.cpp:165] Iteration 17500, lr = 0.1
I0818 16:39:34.911950  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:39:56.915413  3083 solver.cpp:357] Iteration 17600 (1.0296 iter/s, 97.1251s/100 iters), loss = 0.368735
I0818 16:39:56.915627  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.209614 (* 1 = 0.209614 loss)
I0818 16:39:56.915675  3083 sgd_solver.cpp:165] Iteration 17600, lr = 0.1
I0818 16:41:40.969301  3083 solver.cpp:357] Iteration 17700 (0.961058 iter/s, 104.052s/100 iters), loss = 0.53518
I0818 16:41:40.974805  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.554213 (* 1 = 0.554213 loss)
I0818 16:41:40.974846  3083 sgd_solver.cpp:165] Iteration 17700, lr = 0.1
I0818 16:43:27.222381  3083 solver.cpp:357] Iteration 17800 (0.941153 iter/s, 106.253s/100 iters), loss = 0.401046
I0818 16:43:27.222522  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.410281 (* 1 = 0.410281 loss)
I0818 16:43:27.222535  3083 sgd_solver.cpp:165] Iteration 17800, lr = 0.1
I0818 16:45:12.071130  3083 solver.cpp:357] Iteration 17900 (0.953699 iter/s, 104.855s/100 iters), loss = 0.26485
I0818 16:45:12.071331  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.2447 (* 1 = 0.2447 loss)
I0818 16:45:12.071367  3083 sgd_solver.cpp:165] Iteration 17900, lr = 0.1
I0818 16:46:13.439388  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:46:47.273295  3083 solver.cpp:514] Iteration 18000, Testing net (#0)
I0818 16:47:53.751395  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:47:53.899638  3083 blocking_queue.cpp:49] Waiting for data
I0818 16:47:54.214784  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6511
I0818 16:47:54.214845  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.14478 (* 1 = 1.14478 loss)
I0818 16:47:55.010681  3083 solver.cpp:357] Iteration 18000 (0.613691 iter/s, 162.948s/100 iters), loss = 0.256052
I0818 16:47:55.010756  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.278383 (* 1 = 0.278383 loss)
I0818 16:47:55.010771  3083 sgd_solver.cpp:165] Iteration 18000, lr = 0.1
I0818 16:49:41.740851  3083 solver.cpp:357] Iteration 18100 (0.936924 iter/s, 106.732s/100 iters), loss = 0.365247
I0818 16:49:41.751835  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.304847 (* 1 = 0.304847 loss)
I0818 16:49:41.751858  3083 sgd_solver.cpp:165] Iteration 18100, lr = 0.1
I0818 16:51:21.619158  3083 solver.cpp:357] Iteration 18200 (1.00129 iter/s, 99.8708s/100 iters), loss = 0.352071
I0818 16:51:21.619297  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.234178 (* 1 = 0.234178 loss)
I0818 16:51:21.619310  3083 sgd_solver.cpp:165] Iteration 18200, lr = 0.1
I0818 16:53:04.281306  3083 solver.cpp:357] Iteration 18300 (0.974061 iter/s, 102.663s/100 iters), loss = 0.297106
I0818 16:53:04.281472  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.376824 (* 1 = 0.376824 loss)
I0818 16:53:04.281486  3083 sgd_solver.cpp:165] Iteration 18300, lr = 0.1
I0818 16:54:03.786190  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:54:50.404376  3083 solver.cpp:357] Iteration 18400 (0.942297 iter/s, 106.124s/100 iters), loss = 0.613144
I0818 16:54:50.404520  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.529683 (* 1 = 0.529683 loss)
I0818 16:54:50.404532  3083 sgd_solver.cpp:165] Iteration 18400, lr = 0.1
I0818 16:56:26.691506  3083 solver.cpp:514] Iteration 18500, Testing net (#0)
I0818 16:57:32.329967  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 16:57:32.502813  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.7205
I0818 16:57:32.502879  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.82924 (* 1 = 0.82924 loss)
I0818 16:57:33.378908  3083 solver.cpp:357] Iteration 18500 (0.613575 iter/s, 162.979s/100 iters), loss = 0.336894
I0818 16:57:33.378978  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.260143 (* 1 = 0.260143 loss)
I0818 16:57:33.378989  3083 sgd_solver.cpp:165] Iteration 18500, lr = 0.1
I0818 16:59:20.045691  3083 solver.cpp:357] Iteration 18600 (0.9375 iter/s, 106.667s/100 iters), loss = 0.49744
I0818 16:59:20.045967  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.437974 (* 1 = 0.437974 loss)
I0818 16:59:20.046000  3083 sgd_solver.cpp:165] Iteration 18600, lr = 0.1
I0818 17:00:58.105528  3083 solver.cpp:357] Iteration 18700 (1.01979 iter/s, 98.0592s/100 iters), loss = 0.241942
I0818 17:00:58.106076  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.155491 (* 1 = 0.155491 loss)
I0818 17:00:58.106251  3083 sgd_solver.cpp:165] Iteration 18700, lr = 0.1
I0818 17:01:43.511598  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:02:40.013453  3083 solver.cpp:357] Iteration 18800 (0.981263 iter/s, 101.91s/100 iters), loss = 0.329588
I0818 17:02:40.013746  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.29122 (* 1 = 0.29122 loss)
I0818 17:02:40.013798  3083 sgd_solver.cpp:165] Iteration 18800, lr = 0.1
I0818 17:04:26.092859  3083 solver.cpp:357] Iteration 18900 (0.942676 iter/s, 106.081s/100 iters), loss = 0.535684
I0818 17:04:26.093003  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.583116 (* 1 = 0.583116 loss)
I0818 17:04:26.093015  3083 sgd_solver.cpp:165] Iteration 18900, lr = 0.1
I0818 17:06:11.901254  3083 solver.cpp:514] Iteration 19000, Testing net (#0)
I0818 17:07:06.430573  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:07:06.604338  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6188
I0818 17:07:06.610858  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.45342 (* 1 = 1.45342 loss)
I0818 17:07:07.504161  3083 solver.cpp:357] Iteration 19000 (0.619522 iter/s, 161.415s/100 iters), loss = 0.379481
I0818 17:07:07.504361  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.496966 (* 1 = 0.496966 loss)
I0818 17:07:07.504408  3083 sgd_solver.cpp:165] Iteration 19000, lr = 0.1
I0818 17:08:52.256258  3083 solver.cpp:357] Iteration 19100 (0.954643 iter/s, 104.751s/100 iters), loss = 0.395251
I0818 17:08:52.262957  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.352964 (* 1 = 0.352964 loss)
I0818 17:08:52.263063  3083 sgd_solver.cpp:165] Iteration 19100, lr = 0.1
I0818 17:09:32.803097  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:10:37.998405  3083 solver.cpp:357] Iteration 19200 (0.945743 iter/s, 105.737s/100 iters), loss = 0.384572
I0818 17:10:38.002792  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.381812 (* 1 = 0.381812 loss)
I0818 17:10:38.002830  3083 sgd_solver.cpp:165] Iteration 19200, lr = 0.1
I0818 17:12:16.459518  3083 solver.cpp:357] Iteration 19300 (1.01569 iter/s, 98.4557s/100 iters), loss = 0.338135
I0818 17:12:16.459678  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.321935 (* 1 = 0.321935 loss)
I0818 17:12:16.459692  3083 sgd_solver.cpp:165] Iteration 19300, lr = 0.1
I0818 17:13:55.072451  3083 solver.cpp:357] Iteration 19400 (1.01408 iter/s, 98.6117s/100 iters), loss = 0.412144
I0818 17:13:55.078908  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.368727 (* 1 = 0.368727 loss)
I0818 17:13:55.078963  3083 sgd_solver.cpp:165] Iteration 19400, lr = 0.1
I0818 17:15:38.917716  3083 solver.cpp:514] Iteration 19500, Testing net (#0)
I0818 17:16:44.541312  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:16:44.718741  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.4542
I0818 17:16:44.718919  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 2.45135 (* 1 = 2.45135 loss)
I0818 17:16:45.478732  3083 solver.cpp:357] Iteration 19500 (0.586839 iter/s, 170.404s/100 iters), loss = 0.401684
I0818 17:16:45.478945  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.484338 (* 1 = 0.484338 loss)
I0818 17:16:45.478996  3083 sgd_solver.cpp:165] Iteration 19500, lr = 0.1
I0818 17:17:12.319505  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:18:26.076619  3083 solver.cpp:357] Iteration 19600 (0.994117 iter/s, 100.592s/100 iters), loss = 0.335797
I0818 17:18:26.076875  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.404766 (* 1 = 0.404766 loss)
I0818 17:18:26.076905  3083 sgd_solver.cpp:165] Iteration 19600, lr = 0.1
I0818 17:20:08.948129  3083 solver.cpp:357] Iteration 19700 (0.972137 iter/s, 102.866s/100 iters), loss = 0.459781
I0818 17:20:08.949462  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.395188 (* 1 = 0.395188 loss)
I0818 17:20:08.949558  3083 sgd_solver.cpp:165] Iteration 19700, lr = 0.1
I0818 17:21:51.458775  3083 solver.cpp:357] Iteration 19800 (0.975632 iter/s, 102.498s/100 iters), loss = 0.384829
I0818 17:21:51.458992  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.329668 (* 1 = 0.329668 loss)
I0818 17:21:51.459022  3083 sgd_solver.cpp:165] Iteration 19800, lr = 0.1
I0818 17:23:27.484695  3083 solver.cpp:357] Iteration 19900 (1.04142 iter/s, 96.0223s/100 iters), loss = 0.491461
I0818 17:23:27.486857  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.445127 (* 1 = 0.445127 loss)
I0818 17:23:27.486912  3083 sgd_solver.cpp:165] Iteration 19900, lr = 0.1
I0818 17:23:47.934900  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:25:10.642859  3083 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_56_iter_20000.caffemodel
I0818 17:25:10.731416  3083 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_56_iter_20000.solverstate
I0818 17:25:10.741135  3083 solver.cpp:514] Iteration 20000, Testing net (#0)
I0818 17:26:18.200521  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:26:18.537500  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.7243
I0818 17:26:18.542780  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.795637 (* 1 = 0.795637 loss)
I0818 17:26:19.424571  3083 solver.cpp:357] Iteration 20000 (0.581617 iter/s, 171.934s/100 iters), loss = 0.318957
I0818 17:26:19.426759  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.294978 (* 1 = 0.294978 loss)
I0818 17:26:19.426825  3083 sgd_solver.cpp:165] Iteration 20000, lr = 0.1
I0818 17:27:49.123819  3083 solver.cpp:357] Iteration 20100 (1.11492 iter/s, 89.6926s/100 iters), loss = 0.433895
I0818 17:27:49.124060  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.305422 (* 1 = 0.305422 loss)
I0818 17:27:49.124086  3083 sgd_solver.cpp:165] Iteration 20100, lr = 0.1
I0818 17:29:34.532246  3083 solver.cpp:357] Iteration 20200 (0.948727 iter/s, 105.404s/100 iters), loss = 0.362538
I0818 17:29:34.534840  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.404797 (* 1 = 0.404797 loss)
I0818 17:29:34.534895  3083 sgd_solver.cpp:165] Iteration 20200, lr = 0.1
I0818 17:31:20.565342  3083 solver.cpp:357] Iteration 20300 (0.943136 iter/s, 106.029s/100 iters), loss = 0.367125
I0818 17:31:20.567032  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.397227 (* 1 = 0.397227 loss)
I0818 17:31:20.567229  3083 sgd_solver.cpp:165] Iteration 20300, lr = 0.1
I0818 17:31:30.543676  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:33:01.105120  3083 solver.cpp:357] Iteration 20400 (0.994667 iter/s, 100.536s/100 iters), loss = 0.382923
I0818 17:33:01.105526  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.377152 (* 1 = 0.377152 loss)
I0818 17:33:01.105623  3083 sgd_solver.cpp:165] Iteration 20400, lr = 0.1
I0818 17:34:34.598506  3083 solver.cpp:514] Iteration 20500, Testing net (#0)
I0818 17:35:42.526057  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:35:42.770057  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6836
I0818 17:35:42.770242  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.998769 (* 1 = 0.998769 loss)
I0818 17:35:43.760825  3083 solver.cpp:357] Iteration 20500 (0.614797 iter/s, 162.655s/100 iters), loss = 0.266028
I0818 17:35:43.761049  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.267694 (* 1 = 0.267694 loss)
I0818 17:35:43.761098  3083 sgd_solver.cpp:165] Iteration 20500, lr = 0.1
I0818 17:37:29.582792  3083 solver.cpp:357] Iteration 20600 (0.945023 iter/s, 105.818s/100 iters), loss = 0.407007
I0818 17:37:29.583215  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.412531 (* 1 = 0.412531 loss)
I0818 17:37:29.583309  3083 sgd_solver.cpp:165] Iteration 20600, lr = 0.1
I0818 17:39:07.786798  3083 solver.cpp:357] Iteration 20700 (1.01831 iter/s, 98.2019s/100 iters), loss = 0.397492
I0818 17:39:07.787199  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.536255 (* 1 = 0.536255 loss)
I0818 17:39:07.787289  3083 sgd_solver.cpp:165] Iteration 20700, lr = 0.1
I0818 17:39:08.515980  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:40:46.896767  3083 solver.cpp:357] Iteration 20800 (1.00898 iter/s, 99.1102s/100 iters), loss = 0.49259
I0818 17:40:46.902875  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.521839 (* 1 = 0.521839 loss)
I0818 17:40:46.902935  3083 sgd_solver.cpp:165] Iteration 20800, lr = 0.1
I0818 17:42:30.258746  3083 solver.cpp:357] Iteration 20900 (0.967546 iter/s, 103.354s/100 iters), loss = 0.36718
I0818 17:42:30.258968  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.419894 (* 1 = 0.419894 loss)
I0818 17:42:30.258996  3083 sgd_solver.cpp:165] Iteration 20900, lr = 0.1
I0818 17:44:08.904960  3083 solver.cpp:514] Iteration 21000, Testing net (#0)
I0818 17:45:13.780463  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:45:14.054301  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.595201
I0818 17:45:14.054437  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.59727 (* 1 = 1.59727 loss)
I0818 17:45:14.940297  3083 solver.cpp:357] Iteration 21000 (0.607229 iter/s, 164.683s/100 iters), loss = 0.318171
I0818 17:45:14.940492  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.40889 (* 1 = 0.40889 loss)
I0818 17:45:14.940538  3083 sgd_solver.cpp:165] Iteration 21000, lr = 0.1
I0818 17:46:51.176527  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:47:00.695677  3083 solver.cpp:357] Iteration 21100 (0.945602 iter/s, 105.753s/100 iters), loss = 0.414984
I0818 17:47:00.695741  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.477867 (* 1 = 0.477867 loss)
I0818 17:47:00.695753  3083 sgd_solver.cpp:165] Iteration 21100, lr = 0.1
I0818 17:48:40.530642  3083 solver.cpp:357] Iteration 21200 (1.00166 iter/s, 99.8344s/100 iters), loss = 0.361368
I0818 17:48:40.530771  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.371072 (* 1 = 0.371072 loss)
I0818 17:48:40.530782  3083 sgd_solver.cpp:165] Iteration 21200, lr = 0.1
I0818 17:50:22.319206  3083 solver.cpp:357] Iteration 21300 (0.982433 iter/s, 101.788s/100 iters), loss = 0.42081
I0818 17:50:22.319368  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.407027 (* 1 = 0.407027 loss)
I0818 17:50:22.319381  3083 sgd_solver.cpp:165] Iteration 21300, lr = 0.1
I0818 17:52:09.502360  3083 solver.cpp:357] Iteration 21400 (0.932976 iter/s, 107.184s/100 iters), loss = 0.429413
I0818 17:52:09.502532  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.452142 (* 1 = 0.452142 loss)
I0818 17:52:09.502542  3083 sgd_solver.cpp:165] Iteration 21400, lr = 0.1
I0818 17:53:37.123759  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:53:55.661003  3083 solver.cpp:514] Iteration 21500, Testing net (#0)
I0818 17:54:50.305883  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 17:54:50.539083  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.7312
I0818 17:54:50.539175  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.847634 (* 1 = 0.847634 loss)
I0818 17:54:51.337435  3083 solver.cpp:357] Iteration 21500 (0.617904 iter/s, 161.837s/100 iters), loss = 0.250724
I0818 17:54:51.337513  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.311519 (* 1 = 0.311519 loss)
I0818 17:54:51.337527  3083 sgd_solver.cpp:165] Iteration 21500, lr = 0.1
I0818 17:56:37.755139  3083 solver.cpp:357] Iteration 21600 (0.939701 iter/s, 106.417s/100 iters), loss = 0.505479
I0818 17:56:37.755290  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.546391 (* 1 = 0.546391 loss)
I0818 17:56:37.755301  3083 sgd_solver.cpp:165] Iteration 21600, lr = 0.1
I0818 17:58:25.370326  3083 solver.cpp:357] Iteration 21700 (0.929216 iter/s, 107.618s/100 iters), loss = 0.415125
I0818 17:58:25.370491  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.419889 (* 1 = 0.419889 loss)
I0818 17:58:25.370502  3083 sgd_solver.cpp:165] Iteration 21700, lr = 0.1
I0818 18:00:05.344406  3083 solver.cpp:357] Iteration 21800 (1.00028 iter/s, 99.9723s/100 iters), loss = 0.316911
I0818 18:00:05.344553  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.372857 (* 1 = 0.372857 loss)
I0818 18:00:05.344566  3083 sgd_solver.cpp:165] Iteration 21800, lr = 0.1
I0818 18:01:21.755203  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:01:48.832258  3083 solver.cpp:357] Iteration 21900 (0.966315 iter/s, 103.486s/100 iters), loss = 0.461669
I0818 18:01:48.832332  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.270027 (* 1 = 0.270027 loss)
I0818 18:01:48.832342  3083 sgd_solver.cpp:165] Iteration 21900, lr = 0.1
I0818 18:03:33.141404  3083 solver.cpp:514] Iteration 22000, Testing net (#0)
I0818 18:04:37.982478  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:04:38.139696  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6993
I0818 18:04:38.139766  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.940229 (* 1 = 0.940229 loss)
I0818 18:04:38.898942  3083 solver.cpp:357] Iteration 22000 (0.587992 iter/s, 170.07s/100 iters), loss = 0.348123
I0818 18:04:38.899010  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.349661 (* 1 = 0.349661 loss)
I0818 18:04:38.899025  3083 sgd_solver.cpp:165] Iteration 22000, lr = 0.1
I0818 18:06:22.244091  3083 solver.cpp:357] Iteration 22100 (0.967632 iter/s, 103.345s/100 iters), loss = 0.412367
I0818 18:06:22.244257  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.503293 (* 1 = 0.503293 loss)
I0818 18:06:22.244269  3083 sgd_solver.cpp:165] Iteration 22100, lr = 0.1
I0818 18:08:09.528383  3083 solver.cpp:357] Iteration 22200 (0.932121 iter/s, 107.282s/100 iters), loss = 0.287351
I0818 18:08:09.528532  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.299149 (* 1 = 0.299149 loss)
I0818 18:08:09.528542  3083 sgd_solver.cpp:165] Iteration 22200, lr = 0.1
I0818 18:09:11.494956  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:09:49.261979  3083 solver.cpp:357] Iteration 22300 (1.00267 iter/s, 99.7335s/100 iters), loss = 0.435065
I0818 18:09:49.262099  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.522875 (* 1 = 0.522875 loss)
I0818 18:09:49.262109  3083 sgd_solver.cpp:165] Iteration 22300, lr = 0.1
I0818 18:11:31.282225  3083 solver.cpp:357] Iteration 22400 (0.980179 iter/s, 102.022s/100 iters), loss = 0.36093
I0818 18:11:31.282371  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.369534 (* 1 = 0.369534 loss)
I0818 18:11:31.282383  3083 sgd_solver.cpp:165] Iteration 22400, lr = 0.1
I0818 18:13:17.546689  3083 solver.cpp:514] Iteration 22500, Testing net (#0)
I0818 18:14:25.679013  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:14:25.855201  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6665
I0818 18:14:25.855268  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.06027 (* 1 = 1.06027 loss)
I0818 18:14:26.750677  3083 solver.cpp:357] Iteration 22500 (0.569905 iter/s, 175.468s/100 iters), loss = 0.275069
I0818 18:14:26.750753  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.273424 (* 1 = 0.273424 loss)
I0818 18:14:26.750764  3083 sgd_solver.cpp:165] Iteration 22500, lr = 0.1
I0818 18:16:01.486169  3083 solver.cpp:357] Iteration 22600 (1.05557 iter/s, 94.7352s/100 iters), loss = 0.44591
I0818 18:16:01.486272  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.460741 (* 1 = 0.460741 loss)
I0818 18:16:01.486284  3083 sgd_solver.cpp:165] Iteration 22600, lr = 0.1
I0818 18:16:58.770697  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:17:48.641103  3083 solver.cpp:357] Iteration 22700 (0.933247 iter/s, 107.153s/100 iters), loss = 0.439323
I0818 18:17:48.641420  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.418155 (* 1 = 0.418155 loss)
I0818 18:17:48.641484  3083 sgd_solver.cpp:165] Iteration 22700, lr = 0.1
I0818 18:19:35.907881  3083 solver.cpp:357] Iteration 22800 (0.932256 iter/s, 107.267s/100 iters), loss = 0.356062
I0818 18:19:35.910779  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.441037 (* 1 = 0.441037 loss)
I0818 18:19:35.910814  3083 sgd_solver.cpp:165] Iteration 22800, lr = 0.1
I0818 18:21:16.406927  3083 solver.cpp:357] Iteration 22900 (0.995057 iter/s, 100.497s/100 iters), loss = 0.325073
I0818 18:21:16.410924  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.36212 (* 1 = 0.36212 loss)
I0818 18:21:16.411027  3083 sgd_solver.cpp:165] Iteration 22900, lr = 0.1
I0818 18:22:54.854517  3083 solver.cpp:514] Iteration 23000, Testing net (#0)
I0818 18:23:59.563319  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:23:59.845166  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6613
I0818 18:23:59.845511  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.39165 (* 1 = 1.39165 loss)
I0818 18:24:00.526701  3083 solver.cpp:357] Iteration 23000 (0.609315 iter/s, 164.119s/100 iters), loss = 0.389169
I0818 18:24:00.527061  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.342756 (* 1 = 0.342756 loss)
I0818 18:24:00.527237  3083 sgd_solver.cpp:165] Iteration 23000, lr = 0.1
I0818 18:24:47.474737  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:25:42.625494  3083 solver.cpp:357] Iteration 23100 (0.979397 iter/s, 102.104s/100 iters), loss = 0.477929
I0818 18:25:42.625686  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.38656 (* 1 = 0.38656 loss)
I0818 18:25:42.625713  3083 sgd_solver.cpp:165] Iteration 23100, lr = 0.1
I0818 18:27:24.847961  3083 solver.cpp:357] Iteration 23200 (0.978198 iter/s, 102.229s/100 iters), loss = 0.318744
I0818 18:27:24.848223  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.344843 (* 1 = 0.344843 loss)
I0818 18:27:24.848269  3083 sgd_solver.cpp:165] Iteration 23200, lr = 0.1
I0818 18:29:11.691568  3083 solver.cpp:357] Iteration 23300 (0.935898 iter/s, 106.849s/100 iters), loss = 0.314208
I0818 18:29:11.691702  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.343659 (* 1 = 0.343659 loss)
I0818 18:29:11.691715  3083 sgd_solver.cpp:165] Iteration 23300, lr = 0.1
I0818 18:30:52.635833  3083 solver.cpp:357] Iteration 23400 (0.990602 iter/s, 100.949s/100 iters), loss = 0.439526
I0818 18:30:52.635977  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.399402 (* 1 = 0.399402 loss)
I0818 18:30:52.635987  3083 sgd_solver.cpp:165] Iteration 23400, lr = 0.1
I0818 18:31:24.647354  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:32:32.571110  3083 solver.cpp:514] Iteration 23500, Testing net (#0)
I0818 18:33:40.377756  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:33:40.617265  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.5849
I0818 18:33:40.617326  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.29534 (* 1 = 1.29534 loss)
I0818 18:33:41.486960  3083 solver.cpp:357] Iteration 23500 (0.592204 iter/s, 168.861s/100 iters), loss = 0.332557
I0818 18:33:41.487030  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.290886 (* 1 = 0.290886 loss)
I0818 18:33:41.487042  3083 sgd_solver.cpp:165] Iteration 23500, lr = 0.1
I0818 18:35:28.820233  3083 solver.cpp:357] Iteration 23600 (0.931667 iter/s, 107.334s/100 iters), loss = 0.353266
I0818 18:35:28.820381  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.413013 (* 1 = 0.413013 loss)
I0818 18:35:28.820394  3083 sgd_solver.cpp:165] Iteration 23600, lr = 0.1
I0818 18:37:03.069095  3083 solver.cpp:357] Iteration 23700 (1.06102 iter/s, 94.249s/100 iters), loss = 0.315895
I0818 18:37:03.069311  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.233774 (* 1 = 0.233774 loss)
I0818 18:37:03.069347  3083 sgd_solver.cpp:165] Iteration 23700, lr = 0.1
I0818 18:38:48.970363  3083 solver.cpp:357] Iteration 23800 (0.944273 iter/s, 105.902s/100 iters), loss = 0.458608
I0818 18:38:48.974967  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.466651 (* 1 = 0.466651 loss)
I0818 18:38:48.975095  3083 sgd_solver.cpp:165] Iteration 23800, lr = 0.1
I0818 18:39:15.967077  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:40:34.653189  3083 solver.cpp:357] Iteration 23900 (0.946264 iter/s, 105.679s/100 iters), loss = 0.419793
I0818 18:40:34.653301  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.448928 (* 1 = 0.448928 loss)
I0818 18:40:34.653313  3083 sgd_solver.cpp:165] Iteration 23900, lr = 0.1
I0818 18:42:14.107278  3083 solver.cpp:514] Iteration 24000, Testing net (#0)
I0818 18:43:16.815371  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:43:17.009917  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.635101
I0818 18:43:17.009966  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.05251 (* 1 = 1.05251 loss)
I0818 18:43:17.823098  3083 solver.cpp:357] Iteration 24000 (0.612842 iter/s, 163.174s/100 iters), loss = 0.447067
I0818 18:43:17.823176  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.457143 (* 1 = 0.457143 loss)
I0818 18:43:17.823189  3083 sgd_solver.cpp:165] Iteration 24000, lr = 0.1
I0818 18:45:01.303390  3083 solver.cpp:357] Iteration 24100 (0.966352 iter/s, 103.482s/100 iters), loss = 0.404235
I0818 18:45:01.303529  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.405418 (* 1 = 0.405418 loss)
I0818 18:45:01.303539  3083 sgd_solver.cpp:165] Iteration 24100, lr = 0.1
I0818 18:46:47.664037  3083 solver.cpp:357] Iteration 24200 (0.940165 iter/s, 106.364s/100 iters), loss = 0.364727
I0818 18:46:47.664182  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.248796 (* 1 = 0.248796 loss)
I0818 18:46:47.664196  3083 sgd_solver.cpp:165] Iteration 24200, lr = 0.1
I0818 18:47:02.732422  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:48:29.021456  3083 solver.cpp:357] Iteration 24300 (0.986614 iter/s, 101.357s/100 iters), loss = 0.527524
I0818 18:48:29.021598  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.407538 (* 1 = 0.407538 loss)
I0818 18:48:29.021610  3083 sgd_solver.cpp:165] Iteration 24300, lr = 0.1
I0818 18:50:15.326094  3083 solver.cpp:357] Iteration 24400 (0.940679 iter/s, 106.306s/100 iters), loss = 0.37181
I0818 18:50:15.326222  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.383357 (* 1 = 0.383357 loss)
I0818 18:50:15.326233  3083 sgd_solver.cpp:165] Iteration 24400, lr = 0.1
I0818 18:51:57.248661  3083 solver.cpp:514] Iteration 24500, Testing net (#0)
I0818 18:52:57.366729  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:52:57.526129  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.648
I0818 18:52:57.526183  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.0706 (* 1 = 1.0706 loss)
I0818 18:52:58.395750  3083 solver.cpp:357] Iteration 24500 (0.613215 iter/s, 163.075s/100 iters), loss = 0.408015
I0818 18:52:58.395822  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.446827 (* 1 = 0.446827 loss)
I0818 18:52:58.395833  3083 sgd_solver.cpp:165] Iteration 24500, lr = 0.1
I0818 18:54:43.875046  3083 solver.cpp:357] Iteration 24600 (0.948042 iter/s, 105.481s/100 iters), loss = 0.374327
I0818 18:54:43.875239  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.448434 (* 1 = 0.448434 loss)
I0818 18:54:43.875264  3083 sgd_solver.cpp:165] Iteration 24600, lr = 0.1
I0818 18:54:51.239825  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 18:56:30.179563  3083 solver.cpp:357] Iteration 24700 (0.940701 iter/s, 106.304s/100 iters), loss = 0.421214
I0818 18:56:30.182773  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.437855 (* 1 = 0.437855 loss)
I0818 18:56:30.182807  3083 sgd_solver.cpp:165] Iteration 24700, lr = 0.1
I0818 18:57:58.994719  3083 solver.cpp:357] Iteration 24800 (1.12598 iter/s, 88.8113s/100 iters), loss = 0.443123
I0818 18:57:58.994920  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.308319 (* 1 = 0.308319 loss)
I0818 18:57:58.994946  3083 sgd_solver.cpp:165] Iteration 24800, lr = 0.1
I0818 18:59:44.831569  3083 solver.cpp:357] Iteration 24900 (0.94485 iter/s, 105.837s/100 iters), loss = 0.597317
I0818 18:59:44.831959  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.656718 (* 1 = 0.656718 loss)
I0818 18:59:44.832051  3083 sgd_solver.cpp:165] Iteration 24900, lr = 0.1
I0818 19:01:27.180199  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:01:29.269048  3083 solver.cpp:514] Iteration 25000, Testing net (#0)
I0818 19:02:36.317226  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:02:36.553997  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.5357
I0818 19:02:36.554381  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.80957 (* 1 = 1.80957 loss)
I0818 19:02:37.266762  3083 solver.cpp:357] Iteration 25000 (0.579957 iter/s, 172.427s/100 iters), loss = 0.402559
I0818 19:02:37.267179  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.457416 (* 1 = 0.457416 loss)
I0818 19:02:37.267352  3083 sgd_solver.cpp:165] Iteration 25000, lr = 0.1
I0818 19:04:11.304674  3083 solver.cpp:357] Iteration 25100 (1.06343 iter/s, 94.0355s/100 iters), loss = 0.409021
I0818 19:04:11.310842  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.270523 (* 1 = 0.270523 loss)
I0818 19:04:11.310884  3083 sgd_solver.cpp:165] Iteration 25100, lr = 0.1
I0818 19:05:55.326728  3083 solver.cpp:357] Iteration 25200 (0.961424 iter/s, 104.012s/100 iters), loss = 0.440931
I0818 19:05:55.326938  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.317386 (* 1 = 0.317386 loss)
I0818 19:05:55.326966  3083 sgd_solver.cpp:165] Iteration 25200, lr = 0.1
I0818 19:07:41.105428  3083 solver.cpp:357] Iteration 25300 (0.945396 iter/s, 105.776s/100 iters), loss = 0.383982
I0818 19:07:41.105675  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.528709 (* 1 = 0.528709 loss)
I0818 19:07:41.105710  3083 sgd_solver.cpp:165] Iteration 25300, lr = 0.1
I0818 19:09:04.951093  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:09:17.839059  3083 solver.cpp:357] Iteration 25400 (1.03381 iter/s, 96.7293s/100 iters), loss = 0.414217
I0818 19:09:17.839279  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.299285 (* 1 = 0.299285 loss)
I0818 19:09:17.839326  3083 sgd_solver.cpp:165] Iteration 25400, lr = 0.1
I0818 19:11:00.215685  3083 solver.cpp:514] Iteration 25500, Testing net (#0)
I0818 19:12:01.354305  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:12:01.627348  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.5064
I0818 19:12:01.627658  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 2.087 (* 1 = 2.087 loss)
I0818 19:12:02.522722  3083 solver.cpp:357] Iteration 25500 (0.607237 iter/s, 164.68s/100 iters), loss = 0.356993
I0818 19:12:02.522919  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.348352 (* 1 = 0.348352 loss)
I0818 19:12:02.522964  3083 sgd_solver.cpp:165] Iteration 25500, lr = 0.1
I0818 19:13:42.230741  3083 solver.cpp:357] Iteration 25600 (1.00292 iter/s, 99.7086s/100 iters), loss = 0.418288
I0818 19:13:42.231010  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.34972 (* 1 = 0.34972 loss)
I0818 19:13:42.231056  3083 sgd_solver.cpp:165] Iteration 25600, lr = 0.1
I0818 19:15:27.757298  3083 solver.cpp:357] Iteration 25700 (0.947621 iter/s, 105.527s/100 iters), loss = 0.314666
I0818 19:15:27.757534  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.248846 (* 1 = 0.248846 loss)
I0818 19:15:27.757560  3083 sgd_solver.cpp:165] Iteration 25700, lr = 0.1
I0818 19:16:51.495448  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:17:13.776715  3083 solver.cpp:357] Iteration 25800 (0.94323 iter/s, 106.019s/100 iters), loss = 0.416135
I0818 19:17:13.776962  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.412336 (* 1 = 0.412336 loss)
I0818 19:17:13.777052  3083 sgd_solver.cpp:165] Iteration 25800, lr = 0.1
I0818 19:18:46.970772  3083 solver.cpp:357] Iteration 25900 (1.07311 iter/s, 93.1874s/100 iters), loss = 0.493475
I0818 19:18:46.971240  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.461542 (* 1 = 0.461542 loss)
I0818 19:18:46.971357  3083 sgd_solver.cpp:165] Iteration 25900, lr = 0.1
I0818 19:20:27.554072  3083 solver.cpp:514] Iteration 26000, Testing net (#0)
I0818 19:21:36.018210  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:21:36.251132  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.768299
I0818 19:21:36.251474  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.729879 (* 1 = 0.729879 loss)
I0818 19:21:37.026767  3083 solver.cpp:357] Iteration 26000 (0.588037 iter/s, 170.057s/100 iters), loss = 0.384219
I0818 19:21:37.027192  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.381507 (* 1 = 0.381507 loss)
I0818 19:21:37.027364  3083 sgd_solver.cpp:165] Iteration 26000, lr = 0.1
I0818 19:23:22.278717  3083 solver.cpp:357] Iteration 26100 (0.950125 iter/s, 105.249s/100 iters), loss = 0.245704
I0818 19:23:22.278952  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.233656 (* 1 = 0.233656 loss)
I0818 19:23:22.278978  3083 sgd_solver.cpp:165] Iteration 26100, lr = 0.1
I0818 19:24:25.767868  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:24:50.846598  3083 solver.cpp:357] Iteration 26200 (1.12906 iter/s, 88.5689s/100 iters), loss = 0.387651
I0818 19:24:50.850813  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.390687 (* 1 = 0.390687 loss)
I0818 19:24:50.850883  3083 sgd_solver.cpp:165] Iteration 26200, lr = 0.1
I0818 19:26:35.649534  3083 solver.cpp:357] Iteration 26300 (0.954195 iter/s, 104.8s/100 iters), loss = 0.26631
I0818 19:26:35.650775  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.298488 (* 1 = 0.298488 loss)
I0818 19:26:35.650807  3083 sgd_solver.cpp:165] Iteration 26300, lr = 0.1
I0818 19:28:21.123159  3083 solver.cpp:357] Iteration 26400 (0.948105 iter/s, 105.474s/100 iters), loss = 0.285408
I0818 19:28:21.126782  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.227843 (* 1 = 0.227843 loss)
I0818 19:28:21.126828  3083 sgd_solver.cpp:165] Iteration 26400, lr = 0.1
I0818 19:30:00.413401  3083 solver.cpp:514] Iteration 26500, Testing net (#0)
I0818 19:31:04.465054  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:31:04.668298  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6042
I0818 19:31:04.668632  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.29682 (* 1 = 1.29682 loss)
I0818 19:31:05.342592  3083 solver.cpp:357] Iteration 26500 (0.608945 iter/s, 164.218s/100 iters), loss = 0.27664
I0818 19:31:05.343014  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.231429 (* 1 = 0.231429 loss)
I0818 19:31:05.343189  3083 sgd_solver.cpp:165] Iteration 26500, lr = 0.1
I0818 19:32:02.744171  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:32:44.415582  3083 solver.cpp:357] Iteration 26600 (1.00936 iter/s, 99.0729s/100 iters), loss = 0.257766
I0818 19:32:44.422842  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.245121 (* 1 = 0.245121 loss)
I0818 19:32:44.422888  3083 sgd_solver.cpp:165] Iteration 26600, lr = 0.1
I0818 19:34:29.474369  3083 solver.cpp:357] Iteration 26700 (0.951926 iter/s, 105.05s/100 iters), loss = 0.432897
I0818 19:34:29.474495  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.440191 (* 1 = 0.440191 loss)
I0818 19:34:29.474509  3083 sgd_solver.cpp:165] Iteration 26700, lr = 0.1
I0818 19:36:12.359020  3083 solver.cpp:357] Iteration 26800 (0.971984 iter/s, 102.882s/100 iters), loss = 0.587545
I0818 19:36:12.359184  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.569492 (* 1 = 0.569492 loss)
I0818 19:36:12.359195  3083 sgd_solver.cpp:165] Iteration 26800, lr = 0.1
I0818 19:37:59.766619  3083 solver.cpp:357] Iteration 26900 (0.93105 iter/s, 107.406s/100 iters), loss = 0.34402
I0818 19:37:59.766784  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.225362 (* 1 = 0.225362 loss)
I0818 19:37:59.766796  3083 sgd_solver.cpp:165] Iteration 26900, lr = 0.1
I0818 19:38:49.051574  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:39:39.036845  3083 solver.cpp:514] Iteration 27000, Testing net (#0)
I0818 19:40:40.118964  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:40:40.392067  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6944
I0818 19:40:40.392129  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.10006 (* 1 = 1.10006 loss)
I0818 19:40:41.282101  3083 solver.cpp:357] Iteration 27000 (0.61914 iter/s, 161.514s/100 iters), loss = 0.294627
I0818 19:40:41.282178  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.146051 (* 1 = 0.146051 loss)
I0818 19:40:41.282191  3083 sgd_solver.cpp:165] Iteration 27000, lr = 0.1
I0818 19:42:28.171957  3083 solver.cpp:357] Iteration 27100 (0.935572 iter/s, 106.887s/100 iters), loss = 0.435502
I0818 19:42:28.172119  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.450099 (* 1 = 0.450099 loss)
I0818 19:42:28.172130  3083 sgd_solver.cpp:165] Iteration 27100, lr = 0.1
I0818 19:44:15.610396  3083 solver.cpp:357] Iteration 27200 (0.930775 iter/s, 107.437s/100 iters), loss = 0.355623
I0818 19:44:15.610563  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.351178 (* 1 = 0.351178 loss)
I0818 19:44:15.610575  3083 sgd_solver.cpp:165] Iteration 27200, lr = 0.1
I0818 19:45:50.461380  3083 solver.cpp:357] Iteration 27300 (1.0543 iter/s, 94.85s/100 iters), loss = 0.362951
I0818 19:45:50.461532  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.290529 (* 1 = 0.290529 loss)
I0818 19:45:50.461545  3083 sgd_solver.cpp:165] Iteration 27300, lr = 0.1
I0818 19:46:34.332335  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:47:37.119925  3083 solver.cpp:357] Iteration 27400 (0.937574 iter/s, 106.658s/100 iters), loss = 0.306934
I0818 19:47:37.120065  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.311531 (* 1 = 0.311531 loss)
I0818 19:47:37.120077  3083 sgd_solver.cpp:165] Iteration 27400, lr = 0.1
I0818 19:49:23.629312  3083 solver.cpp:514] Iteration 27500, Testing net (#0)
I0818 19:50:27.620496  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:50:27.787662  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.7863
I0818 19:50:27.787755  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.624387 (* 1 = 0.624387 loss)
I0818 19:50:28.553180  3083 solver.cpp:357] Iteration 27500 (0.583316 iter/s, 171.434s/100 iters), loss = 0.418338
I0818 19:50:28.553253  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.404661 (* 1 = 0.404661 loss)
I0818 19:50:28.553267  3083 sgd_solver.cpp:165] Iteration 27500, lr = 0.1
I0818 19:52:11.585678  3083 solver.cpp:357] Iteration 27600 (0.970573 iter/s, 103.032s/100 iters), loss = 0.364089
I0818 19:52:11.585886  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.272686 (* 1 = 0.272686 loss)
I0818 19:52:11.585898  3083 sgd_solver.cpp:165] Iteration 27600, lr = 0.1
I0818 19:53:54.173161  3083 solver.cpp:357] Iteration 27700 (0.974783 iter/s, 102.587s/100 iters), loss = 0.528988
I0818 19:53:54.173301  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.560877 (* 1 = 0.560877 loss)
I0818 19:53:54.173313  3083 sgd_solver.cpp:165] Iteration 27700, lr = 0.1
I0818 19:54:27.944216  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 19:55:38.330504  3083 solver.cpp:357] Iteration 27800 (0.96009 iter/s, 104.157s/100 iters), loss = 0.31968
I0818 19:55:38.334764  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.377776 (* 1 = 0.377776 loss)
I0818 19:55:38.334825  3083 sgd_solver.cpp:165] Iteration 27800, lr = 0.1
I0818 19:57:20.980880  3083 solver.cpp:357] Iteration 27900 (0.974217 iter/s, 102.647s/100 iters), loss = 0.40111
I0818 19:57:20.981047  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.313819 (* 1 = 0.313819 loss)
I0818 19:57:20.981073  3083 sgd_solver.cpp:165] Iteration 27900, lr = 0.1
I0818 19:59:07.228495  3083 solver.cpp:514] Iteration 28000, Testing net (#0)
I0818 20:00:08.043674  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:00:08.400096  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6751
I0818 20:00:08.400151  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.15457 (* 1 = 1.15457 loss)
I0818 20:00:09.245414  3083 solver.cpp:357] Iteration 28000 (0.594299 iter/s, 168.265s/100 iters), loss = 0.463281
I0818 20:00:09.245489  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.572382 (* 1 = 0.572382 loss)
I0818 20:00:09.245501  3083 sgd_solver.cpp:165] Iteration 28000, lr = 0.1
I0818 20:01:49.090155  3083 solver.cpp:357] Iteration 28100 (1.00156 iter/s, 99.8443s/100 iters), loss = 0.393502
I0818 20:01:49.090286  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.381945 (* 1 = 0.381945 loss)
I0818 20:01:49.090296  3083 sgd_solver.cpp:165] Iteration 28100, lr = 0.1
I0818 20:02:12.838956  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:03:35.918912  3083 solver.cpp:357] Iteration 28200 (0.93608 iter/s, 106.829s/100 iters), loss = 0.401382
I0818 20:03:35.919056  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.237936 (* 1 = 0.237936 loss)
I0818 20:03:35.919068  3083 sgd_solver.cpp:165] Iteration 28200, lr = 0.1
I0818 20:05:21.380486  3083 solver.cpp:357] Iteration 28300 (0.948215 iter/s, 105.461s/100 iters), loss = 0.441251
I0818 20:05:21.380609  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.524274 (* 1 = 0.524274 loss)
I0818 20:05:21.380621  3083 sgd_solver.cpp:165] Iteration 28300, lr = 0.1
I0818 20:06:55.947203  3083 solver.cpp:357] Iteration 28400 (1.05746 iter/s, 94.5661s/100 iters), loss = 0.242664
I0818 20:06:55.947332  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.241532 (* 1 = 0.241532 loss)
I0818 20:06:55.947346  3083 sgd_solver.cpp:165] Iteration 28400, lr = 0.1
I0818 20:08:42.113096  3083 solver.cpp:514] Iteration 28500, Testing net (#0)
I0818 20:09:49.902024  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:09:50.164191  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.757999
I0818 20:09:50.164252  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.728335 (* 1 = 0.728335 loss)
I0818 20:09:51.129556  3083 solver.cpp:357] Iteration 28500 (0.570871 iter/s, 175.171s/100 iters), loss = 0.342817
I0818 20:09:51.129638  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.343356 (* 1 = 0.343356 loss)
I0818 20:09:51.129649  3083 sgd_solver.cpp:165] Iteration 28500, lr = 0.1
I0818 20:10:05.259017  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:11:34.998679  3083 solver.cpp:357] Iteration 28600 (0.962826 iter/s, 103.861s/100 iters), loss = 0.406899
I0818 20:11:34.998852  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.332521 (* 1 = 0.332521 loss)
I0818 20:11:34.998864  3083 sgd_solver.cpp:165] Iteration 28600, lr = 0.1
I0818 20:13:17.364126  3083 solver.cpp:357] Iteration 28700 (0.976923 iter/s, 102.362s/100 iters), loss = 0.273921
I0818 20:13:17.364290  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.337838 (* 1 = 0.337838 loss)
I0818 20:13:17.364303  3083 sgd_solver.cpp:165] Iteration 28700, lr = 0.1
I0818 20:15:00.474951  3083 solver.cpp:357] Iteration 28800 (0.969874 iter/s, 103.106s/100 iters), loss = 0.278343
I0818 20:15:00.475241  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.385404 (* 1 = 0.385404 loss)
I0818 20:15:00.475306  3083 sgd_solver.cpp:165] Iteration 28800, lr = 0.1
I0818 20:16:44.344650  3083 solver.cpp:357] Iteration 28900 (0.962782 iter/s, 103.866s/100 iters), loss = 0.421024
I0818 20:16:44.344768  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.419326 (* 1 = 0.419326 loss)
I0818 20:16:44.344779  3083 sgd_solver.cpp:165] Iteration 28900, lr = 0.1
I0818 20:16:47.653506  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:18:25.377941  3083 solver.cpp:514] Iteration 29000, Testing net (#0)
I0818 20:19:33.137559  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:19:33.417488  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.654901
I0818 20:19:33.417537  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.07547 (* 1 = 1.07547 loss)
I0818 20:19:34.258782  3083 solver.cpp:357] Iteration 29000 (0.58854 iter/s, 169.912s/100 iters), loss = 0.398863
I0818 20:19:34.258854  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.337716 (* 1 = 0.337716 loss)
I0818 20:19:34.258865  3083 sgd_solver.cpp:165] Iteration 29000, lr = 0.1
I0818 20:21:15.566939  3083 solver.cpp:357] Iteration 29100 (0.987102 iter/s, 101.307s/100 iters), loss = 0.410213
I0818 20:21:15.567075  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.366822 (* 1 = 0.366822 loss)
I0818 20:21:15.567088  3083 sgd_solver.cpp:165] Iteration 29100, lr = 0.1
I0818 20:22:55.721287  3083 solver.cpp:357] Iteration 29200 (0.998507 iter/s, 100.15s/100 iters), loss = 0.352806
I0818 20:22:55.721418  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.214009 (* 1 = 0.214009 loss)
I0818 20:22:55.721431  3083 sgd_solver.cpp:165] Iteration 29200, lr = 0.1
I0818 20:24:36.385447  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:24:42.283186  3083 solver.cpp:357] Iteration 29300 (0.938437 iter/s, 106.56s/100 iters), loss = 0.353104
I0818 20:24:42.283594  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.2657 (* 1 = 0.2657 loss)
I0818 20:24:42.283767  3083 sgd_solver.cpp:165] Iteration 29300, lr = 0.1
I0818 20:26:28.187623  3083 solver.cpp:357] Iteration 29400 (0.944268 iter/s, 105.902s/100 iters), loss = 0.264607
I0818 20:26:28.187933  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.269731 (* 1 = 0.269731 loss)
I0818 20:26:28.187996  3083 sgd_solver.cpp:165] Iteration 29400, lr = 0.1
I0818 20:28:01.411451  3083 solver.cpp:514] Iteration 29500, Testing net (#0)
I0818 20:29:09.195257  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:29:09.461267  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.5808
I0818 20:29:09.461324  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.5833 (* 1 = 1.5833 loss)
I0818 20:29:10.382165  3083 solver.cpp:357] Iteration 29500 (0.616551 iter/s, 162.192s/100 iters), loss = 0.380057
I0818 20:29:10.382241  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.321386 (* 1 = 0.321386 loss)
I0818 20:29:10.382252  3083 sgd_solver.cpp:165] Iteration 29500, lr = 0.1
I0818 20:30:57.524302  3083 solver.cpp:357] Iteration 29600 (0.933375 iter/s, 107.138s/100 iters), loss = 0.358138
I0818 20:30:57.524504  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.266671 (* 1 = 0.266671 loss)
I0818 20:30:57.524519  3083 sgd_solver.cpp:165] Iteration 29600, lr = 0.1
I0818 20:32:26.168169  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:32:40.413327  3083 solver.cpp:357] Iteration 29700 (0.971957 iter/s, 102.885s/100 iters), loss = 0.355204
I0818 20:32:40.413401  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.288311 (* 1 = 0.288311 loss)
I0818 20:32:40.413414  3083 sgd_solver.cpp:165] Iteration 29700, lr = 0.1
I0818 20:34:21.293364  3083 solver.cpp:357] Iteration 29800 (0.991315 iter/s, 100.876s/100 iters), loss = 0.385321
I0818 20:34:21.293536  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.412867 (* 1 = 0.412867 loss)
I0818 20:34:21.293550  3083 sgd_solver.cpp:165] Iteration 29800, lr = 0.1
I0818 20:36:04.840292  3083 solver.cpp:357] Iteration 29900 (0.965782 iter/s, 103.543s/100 iters), loss = 0.452255
I0818 20:36:04.840415  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.494204 (* 1 = 0.494204 loss)
I0818 20:36:04.840427  3083 sgd_solver.cpp:165] Iteration 29900, lr = 0.1
I0818 20:37:49.677732  3083 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_56_iter_30000.caffemodel
I0818 20:37:49.707922  3083 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_56_iter_30000.solverstate
I0818 20:37:49.716884  3083 solver.cpp:514] Iteration 30000, Testing net (#0)
I0818 20:38:51.238245  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:38:51.602761  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.631301
I0818 20:38:51.602815  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.44694 (* 1 = 1.44694 loss)
I0818 20:38:52.426508  3083 solver.cpp:357] Iteration 30000 (0.596705 iter/s, 167.587s/100 iters), loss = 0.328718
I0818 20:38:52.426586  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.459867 (* 1 = 0.459867 loss)
I0818 20:38:52.426597  3083 sgd_solver.cpp:165] Iteration 30000, lr = 0.1
I0818 20:40:13.427403  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:40:39.477541  3083 solver.cpp:357] Iteration 30100 (0.934167 iter/s, 107.047s/100 iters), loss = 0.41755
I0818 20:40:39.477615  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.340662 (* 1 = 0.340662 loss)
I0818 20:40:39.477627  3083 sgd_solver.cpp:165] Iteration 30100, lr = 0.1
I0818 20:42:19.254318  3083 solver.cpp:357] Iteration 30200 (1.00224 iter/s, 99.7768s/100 iters), loss = 0.564392
I0818 20:42:19.254472  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.622481 (* 1 = 0.622481 loss)
I0818 20:42:19.254483  3083 sgd_solver.cpp:165] Iteration 30200, lr = 0.1
I0818 20:43:59.490531  3083 solver.cpp:357] Iteration 30300 (0.99762 iter/s, 100.239s/100 iters), loss = 0.494748
I0818 20:43:59.490872  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.453503 (* 1 = 0.453503 loss)
I0818 20:43:59.490934  3083 sgd_solver.cpp:165] Iteration 30300, lr = 0.1
I0818 20:45:46.710670  3083 solver.cpp:357] Iteration 30400 (0.932652 iter/s, 107.221s/100 iters), loss = 0.245758
I0818 20:45:46.710935  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.18535 (* 1 = 0.18535 loss)
I0818 20:45:46.710965  3083 sgd_solver.cpp:165] Iteration 30400, lr = 0.1
I0818 20:46:57.879179  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:47:33.195133  3083 solver.cpp:514] Iteration 30500, Testing net (#0)
I0818 20:48:29.212749  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:48:29.348181  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.7188
I0818 20:48:29.348517  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.911274 (* 1 = 0.911274 loss)
I0818 20:48:29.857275  3083 solver.cpp:357] Iteration 30500 (0.612946 iter/s, 163.146s/100 iters), loss = 0.316819
I0818 20:48:29.857666  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.323629 (* 1 = 0.323629 loss)
I0818 20:48:29.857839  3083 sgd_solver.cpp:165] Iteration 30500, lr = 0.1
I0818 20:50:04.189734  3083 solver.cpp:357] Iteration 30600 (1.0601 iter/s, 94.3303s/100 iters), loss = 0.34007
I0818 20:50:04.189930  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.303276 (* 1 = 0.303276 loss)
I0818 20:50:04.189942  3083 sgd_solver.cpp:165] Iteration 30600, lr = 0.1
I0818 20:51:49.845077  3083 solver.cpp:357] Iteration 30700 (0.946457 iter/s, 105.657s/100 iters), loss = 0.38884
I0818 20:51:49.850940  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.283992 (* 1 = 0.283992 loss)
I0818 20:51:49.851050  3083 sgd_solver.cpp:165] Iteration 30700, lr = 0.1
I0818 20:53:34.037545  3083 solver.cpp:357] Iteration 30800 (0.959805 iter/s, 104.188s/100 iters), loss = 0.32186
I0818 20:53:34.037731  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.446081 (* 1 = 0.446081 loss)
I0818 20:53:34.037761  3083 sgd_solver.cpp:165] Iteration 30800, lr = 0.1
I0818 20:54:30.599486  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:55:13.867951  3083 solver.cpp:357] Iteration 30900 (1.00172 iter/s, 99.8278s/100 iters), loss = 0.489324
I0818 20:55:13.874940  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.331374 (* 1 = 0.331374 loss)
I0818 20:55:13.875044  3083 sgd_solver.cpp:165] Iteration 30900, lr = 0.1
I0818 20:56:53.913985  3083 solver.cpp:514] Iteration 31000, Testing net (#0)
I0818 20:57:58.757324  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 20:57:59.012562  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.717701
I0818 20:57:59.012949  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.843573 (* 1 = 0.843573 loss)
I0818 20:57:59.746512  3083 solver.cpp:357] Iteration 31000 (0.602872 iter/s, 165.873s/100 iters), loss = 0.353808
I0818 20:57:59.746867  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.307205 (* 1 = 0.307205 loss)
I0818 20:57:59.746981  3083 sgd_solver.cpp:165] Iteration 31000, lr = 0.1
I0818 20:59:39.625694  3083 solver.cpp:357] Iteration 31100 (1.00124 iter/s, 99.8763s/100 iters), loss = 0.341948
I0818 20:59:39.625804  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.338687 (* 1 = 0.338687 loss)
I0818 20:59:39.625816  3083 sgd_solver.cpp:165] Iteration 31100, lr = 0.1
I0818 21:01:26.876796  3083 solver.cpp:357] Iteration 31200 (0.932398 iter/s, 107.25s/100 iters), loss = 0.342905
I0818 21:01:26.876924  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.345827 (* 1 = 0.345827 loss)
I0818 21:01:26.876935  3083 sgd_solver.cpp:165] Iteration 31200, lr = 0.1
I0818 21:02:11.840059  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:03:05.660156  3083 solver.cpp:357] Iteration 31300 (1.01233 iter/s, 98.7824s/100 iters), loss = 0.311945
I0818 21:03:05.662940  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.301978 (* 1 = 0.301978 loss)
I0818 21:03:05.663043  3083 sgd_solver.cpp:165] Iteration 31300, lr = 0.1
I0818 21:04:42.795806  3083 solver.cpp:357] Iteration 31400 (1.02952 iter/s, 97.1325s/100 iters), loss = 0.448571
I0818 21:04:42.798784  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.459932 (* 1 = 0.459932 loss)
I0818 21:04:42.798830  3083 sgd_solver.cpp:165] Iteration 31400, lr = 0.1
I0818 21:06:27.822787  3083 solver.cpp:514] Iteration 31500, Testing net (#0)
I0818 21:07:32.391407  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:07:32.646980  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.6532
I0818 21:07:32.647157  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 1.26533 (* 1 = 1.26533 loss)
I0818 21:07:33.471928  3083 solver.cpp:357] Iteration 31500 (0.585913 iter/s, 170.674s/100 iters), loss = 0.371181
I0818 21:07:33.472100  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.43176 (* 1 = 0.43176 loss)
I0818 21:07:33.472146  3083 sgd_solver.cpp:165] Iteration 31500, lr = 0.1
I0818 21:09:14.849226  3083 solver.cpp:357] Iteration 31600 (0.986405 iter/s, 101.378s/100 iters), loss = 0.361721
I0818 21:09:14.854846  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.371492 (* 1 = 0.371492 loss)
I0818 21:09:14.854884  3083 sgd_solver.cpp:165] Iteration 31600, lr = 0.1
I0818 21:09:47.090782  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:10:51.799767  3083 solver.cpp:357] Iteration 31700 (1.0315 iter/s, 96.946s/100 iters), loss = 0.449022
I0818 21:10:51.806988  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.477911 (* 1 = 0.477911 loss)
I0818 21:10:51.807104  3083 sgd_solver.cpp:165] Iteration 31700, lr = 0.1
I0818 21:12:36.797276  3083 solver.cpp:357] Iteration 31800 (0.952471 iter/s, 104.99s/100 iters), loss = 0.305555
I0818 21:12:36.802881  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.263477 (* 1 = 0.263477 loss)
I0818 21:12:36.802932  3083 sgd_solver.cpp:165] Iteration 31800, lr = 0.1
I0818 21:14:22.842769  3083 solver.cpp:357] Iteration 31900 (0.943069 iter/s, 106.037s/100 iters), loss = 0.455108
I0818 21:14:22.843026  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.461495 (* 1 = 0.461495 loss)
I0818 21:14:22.843057  3083 sgd_solver.cpp:165] Iteration 31900, lr = 0.1
I0818 21:15:56.368609  3083 solver.cpp:514] Iteration 32000, Testing net (#0)
I0818 21:16:58.399253  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:16:58.735226  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.7097
I0818 21:16:58.735400  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.89788 (* 1 = 0.89788 loss)
I0818 21:16:59.551478  3083 solver.cpp:357] Iteration 32000 (0.638085 iter/s, 156.719s/100 iters), loss = 0.330798
I0818 21:16:59.551698  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.458073 (* 1 = 0.458073 loss)
I0818 21:16:59.551743  3083 sgd_solver.cpp:64] MultiStep Status: Iteration 32000, step = 1
I0818 21:16:59.551780  3083 sgd_solver.cpp:165] Iteration 32000, lr = 0.01
I0818 21:17:29.279387  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:18:44.168377  3083 solver.cpp:357] Iteration 32100 (0.955797 iter/s, 104.625s/100 iters), loss = 0.217541
I0818 21:18:44.175055  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.245608 (* 1 = 0.245608 loss)
I0818 21:18:44.175248  3083 sgd_solver.cpp:165] Iteration 32100, lr = 0.01
I0818 21:20:23.231499  3083 solver.cpp:357] Iteration 32200 (1.00944 iter/s, 99.0643s/100 iters), loss = 0.429548
I0818 21:20:23.234844  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.375199 (* 1 = 0.375199 loss)
I0818 21:20:23.234885  3083 sgd_solver.cpp:165] Iteration 32200, lr = 0.01
I0818 21:22:07.999778  3083 solver.cpp:357] Iteration 32300 (0.954442 iter/s, 104.773s/100 iters), loss = 0.218217
I0818 21:22:08.006760  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.216132 (* 1 = 0.216132 loss)
I0818 21:22:08.006789  3083 sgd_solver.cpp:165] Iteration 32300, lr = 0.01
I0818 21:23:47.219107  3083 solver.cpp:357] Iteration 32400 (1.00788 iter/s, 99.2184s/100 iters), loss = 0.176422
I0818 21:23:47.219702  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.147387 (* 1 = 0.147387 loss)
I0818 21:23:47.219910  3083 sgd_solver.cpp:165] Iteration 32400, lr = 0.01
I0818 21:24:07.339798  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:25:28.715154  3083 solver.cpp:514] Iteration 32500, Testing net (#0)
I0818 21:26:32.990701  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:26:33.297691  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.889902
I0818 21:26:33.297755  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.330143 (* 1 = 0.330143 loss)
I0818 21:26:34.104081  3083 solver.cpp:357] Iteration 32500 (0.59919 iter/s, 166.892s/100 iters), loss = 0.1594
I0818 21:26:34.104153  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.183798 (* 1 = 0.183798 loss)
I0818 21:26:34.104163  3083 sgd_solver.cpp:165] Iteration 32500, lr = 0.01
I0818 21:28:20.800411  3083 solver.cpp:357] Iteration 32600 (0.937204 iter/s, 106.7s/100 iters), loss = 0.2162
I0818 21:28:20.806919  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.165453 (* 1 = 0.165453 loss)
I0818 21:28:20.807018  3083 sgd_solver.cpp:165] Iteration 32600, lr = 0.01
I0818 21:29:59.747519  3083 solver.cpp:357] Iteration 32700 (1.01065 iter/s, 98.9459s/100 iters), loss = 0.17122
I0818 21:29:59.747721  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.247714 (* 1 = 0.247714 loss)
I0818 21:29:59.747750  3083 sgd_solver.cpp:165] Iteration 32700, lr = 0.01
I0818 21:31:37.454408  3083 solver.cpp:357] Iteration 32800 (1.02344 iter/s, 97.7096s/100 iters), loss = 0.149297
I0818 21:31:37.454618  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.165268 (* 1 = 0.165268 loss)
I0818 21:31:37.454656  3083 sgd_solver.cpp:165] Iteration 32800, lr = 0.01
I0818 21:31:47.832106  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:33:23.467361  3083 solver.cpp:357] Iteration 32900 (0.943275 iter/s, 106.014s/100 iters), loss = 0.119849
I0818 21:33:23.467473  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.083143 (* 1 = 0.083143 loss)
I0818 21:33:23.467484  3083 sgd_solver.cpp:165] Iteration 32900, lr = 0.01
I0818 21:35:09.361268  3083 solver.cpp:514] Iteration 33000, Testing net (#0)
I0818 21:36:09.206576  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:36:09.406623  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.885002
I0818 21:36:09.406769  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.341493 (* 1 = 0.341493 loss)
I0818 21:36:10.104962  3083 solver.cpp:357] Iteration 33000 (0.600087 iter/s, 166.643s/100 iters), loss = 0.146762
I0818 21:36:10.105130  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0972252 (* 1 = 0.0972252 loss)
I0818 21:36:10.105160  3083 sgd_solver.cpp:165] Iteration 33000, lr = 0.01
I0818 21:37:47.903801  3083 solver.cpp:357] Iteration 33100 (1.02251 iter/s, 97.7985s/100 iters), loss = 0.136281
I0818 21:37:47.906965  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.132923 (* 1 = 0.132923 loss)
I0818 21:37:47.907093  3083 sgd_solver.cpp:165] Iteration 33100, lr = 0.01
I0818 21:39:32.866413  3083 solver.cpp:357] Iteration 33200 (0.952722 iter/s, 104.962s/100 iters), loss = 0.137176
I0818 21:39:32.866572  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0840904 (* 1 = 0.0840904 loss)
I0818 21:39:32.866585  3083 sgd_solver.cpp:165] Iteration 33200, lr = 0.01
I0818 21:39:33.514708  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:41:16.932724  3083 solver.cpp:357] Iteration 33300 (0.96093 iter/s, 104.066s/100 iters), loss = 0.21464
I0818 21:41:16.932924  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.252591 (* 1 = 0.252591 loss)
I0818 21:41:16.932955  3083 sgd_solver.cpp:165] Iteration 33300, lr = 0.01
I0818 21:43:00.325855  3083 solver.cpp:357] Iteration 33400 (0.967168 iter/s, 103.395s/100 iters), loss = 0.117414
I0818 21:43:00.325971  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.113609 (* 1 = 0.113609 loss)
I0818 21:43:00.325984  3083 sgd_solver.cpp:165] Iteration 33400, lr = 0.01
I0818 21:44:40.973500  3083 solver.cpp:514] Iteration 33500, Testing net (#0)
I0818 21:45:48.902880  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:45:49.047457  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.893302
I0818 21:45:49.047523  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.314757 (* 1 = 0.314757 loss)
I0818 21:45:49.917388  3083 solver.cpp:357] Iteration 33500 (0.589639 iter/s, 169.595s/100 iters), loss = 0.124349
I0818 21:45:49.917466  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.180945 (* 1 = 0.180945 loss)
I0818 21:45:49.917479  3083 sgd_solver.cpp:165] Iteration 33500, lr = 0.01
I0818 21:47:12.026001  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:47:18.487022  3083 solver.cpp:357] Iteration 33600 (1.12907 iter/s, 88.5683s/100 iters), loss = 0.185776
I0818 21:47:18.487087  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.252378 (* 1 = 0.252378 loss)
I0818 21:47:18.487098  3083 sgd_solver.cpp:165] Iteration 33600, lr = 0.01
I0818 21:48:30.480629  3083 solver.cpp:357] Iteration 33700 (1.38901 iter/s, 71.9938s/100 iters), loss = 0.175384
I0818 21:48:30.480777  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.235228 (* 1 = 0.235228 loss)
I0818 21:48:30.480788  3083 sgd_solver.cpp:165] Iteration 33700, lr = 0.01
I0818 21:49:33.640067  3083 solver.cpp:357] Iteration 33800 (1.58325 iter/s, 63.1614s/100 iters), loss = 0.0970007
I0818 21:49:33.640185  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0876958 (* 1 = 0.0876958 loss)
I0818 21:49:33.640197  3083 sgd_solver.cpp:165] Iteration 33800, lr = 0.01
I0818 21:50:44.804844  3083 solver.cpp:357] Iteration 33900 (1.40516 iter/s, 71.1662s/100 iters), loss = 0.150969
I0818 21:50:44.805032  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.220151 (* 1 = 0.220151 loss)
I0818 21:50:44.805061  3083 sgd_solver.cpp:165] Iteration 33900, lr = 0.01
I0818 21:51:43.780750  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:51:56.425395  3083 solver.cpp:514] Iteration 34000, Testing net (#0)
I0818 21:52:42.628358  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:52:42.758587  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.883402
I0818 21:52:42.758658  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.348215 (* 1 = 0.348215 loss)
I0818 21:52:43.370059  3083 solver.cpp:357] Iteration 34000 (0.843401 iter/s, 118.568s/100 iters), loss = 0.0580495
I0818 21:52:43.370142  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0672694 (* 1 = 0.0672694 loss)
I0818 21:52:43.370153  3083 sgd_solver.cpp:165] Iteration 34000, lr = 0.01
I0818 21:53:51.626159  3083 solver.cpp:357] Iteration 34100 (1.46504 iter/s, 68.2575s/100 iters), loss = 0.177068
I0818 21:53:51.626386  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.160955 (* 1 = 0.160955 loss)
I0818 21:53:51.626411  3083 sgd_solver.cpp:165] Iteration 34100, lr = 0.01
I0818 21:54:56.716660  3083 solver.cpp:357] Iteration 34200 (1.53629 iter/s, 65.0918s/100 iters), loss = 0.0877419
I0818 21:54:56.722817  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0802972 (* 1 = 0.0802972 loss)
I0818 21:54:56.722862  3083 sgd_solver.cpp:165] Iteration 34200, lr = 0.01
I0818 21:56:05.371448  3083 solver.cpp:357] Iteration 34300 (1.45666 iter/s, 68.6501s/100 iters), loss = 0.0976806
I0818 21:56:05.374824  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0974904 (* 1 = 0.0974904 loss)
I0818 21:56:05.374863  3083 sgd_solver.cpp:165] Iteration 34300, lr = 0.01
I0818 21:56:55.101851  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:57:14.905125  3083 solver.cpp:357] Iteration 34400 (1.4382 iter/s, 69.5311s/100 iters), loss = 0.162364
I0818 21:57:14.905292  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.11185 (* 1 = 0.11185 loss)
I0818 21:57:14.905341  3083 sgd_solver.cpp:165] Iteration 34400, lr = 0.01
I0818 21:58:24.508054  3083 solver.cpp:514] Iteration 34500, Testing net (#0)
I0818 21:59:00.497722  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 21:59:00.675858  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.893102
I0818 21:59:00.675977  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.326943 (* 1 = 0.326943 loss)
I0818 21:59:01.285647  3083 solver.cpp:357] Iteration 34500 (0.940016 iter/s, 106.381s/100 iters), loss = 0.0931022
I0818 21:59:01.285917  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.057146 (* 1 = 0.057146 loss)
I0818 21:59:01.285943  3083 sgd_solver.cpp:165] Iteration 34500, lr = 0.01
I0818 22:00:10.862483  3083 solver.cpp:357] Iteration 34600 (1.43723 iter/s, 69.5783s/100 iters), loss = 0.178983
I0818 22:00:10.863046  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.254772 (* 1 = 0.254772 loss)
I0818 22:00:10.863144  3083 sgd_solver.cpp:165] Iteration 34600, lr = 0.01
I0818 22:01:22.491039  3083 solver.cpp:357] Iteration 34700 (1.3961 iter/s, 71.6283s/100 iters), loss = 0.0905661
I0818 22:01:22.494819  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.139144 (* 1 = 0.139144 loss)
I0818 22:01:22.494858  3083 sgd_solver.cpp:165] Iteration 34700, lr = 0.01
I0818 22:02:05.107229  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:02:31.163674  3083 solver.cpp:357] Iteration 34800 (1.45624 iter/s, 68.6698s/100 iters), loss = 0.104166
I0818 22:02:31.163846  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.12994 (* 1 = 0.12994 loss)
I0818 22:02:31.163879  3083 sgd_solver.cpp:165] Iteration 34800, lr = 0.01
I0818 22:03:31.932229  3083 solver.cpp:357] Iteration 34900 (1.6456 iter/s, 60.7681s/100 iters), loss = 0.0948242
I0818 22:03:31.934898  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0740451 (* 1 = 0.0740451 loss)
I0818 22:03:31.935000  3083 sgd_solver.cpp:165] Iteration 34900, lr = 0.01
I0818 22:04:39.351368  3083 solver.cpp:514] Iteration 35000, Testing net (#0)
I0818 22:05:23.124079  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:05:23.360610  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.895502
I0818 22:05:23.360747  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.325512 (* 1 = 0.325512 loss)
I0818 22:05:23.982534  3083 solver.cpp:357] Iteration 35000 (0.892452 iter/s, 112.051s/100 iters), loss = 0.0684844
I0818 22:05:23.982681  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0938933 (* 1 = 0.0938933 loss)
I0818 22:05:23.982710  3083 sgd_solver.cpp:165] Iteration 35000, lr = 0.01
I0818 22:06:35.715287  3083 solver.cpp:357] Iteration 35100 (1.39407 iter/s, 71.7326s/100 iters), loss = 0.100483
I0818 22:06:35.718848  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0740898 (* 1 = 0.0740898 loss)
I0818 22:06:35.718892  3083 sgd_solver.cpp:165] Iteration 35100, lr = 0.01
I0818 22:07:12.583425  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:07:42.511992  3083 solver.cpp:357] Iteration 35200 (1.49713 iter/s, 66.7943s/100 iters), loss = 0.133781
I0818 22:07:42.512151  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0834752 (* 1 = 0.0834752 loss)
I0818 22:07:42.512181  3083 sgd_solver.cpp:165] Iteration 35200, lr = 0.01
I0818 22:08:45.865603  3083 solver.cpp:357] Iteration 35300 (1.57845 iter/s, 63.3533s/100 iters), loss = 0.101502
I0818 22:08:45.870856  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.167648 (* 1 = 0.167648 loss)
I0818 22:08:45.870896  3083 sgd_solver.cpp:165] Iteration 35300, lr = 0.01
I0818 22:09:57.097874  3083 solver.cpp:357] Iteration 35400 (1.40393 iter/s, 71.2288s/100 iters), loss = 0.101585
I0818 22:09:57.098057  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0596855 (* 1 = 0.0596855 loss)
I0818 22:09:57.098086  3083 sgd_solver.cpp:165] Iteration 35400, lr = 0.01
I0818 22:11:05.877539  3083 solver.cpp:514] Iteration 35500, Testing net (#0)
I0818 22:11:52.823979  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:11:53.042590  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.906202
I0818 22:11:53.042742  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.299642 (* 1 = 0.299642 loss)
I0818 22:11:53.741392  3083 solver.cpp:357] Iteration 35500 (0.857293 iter/s, 116.646s/100 iters), loss = 0.0985659
I0818 22:11:53.741549  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0842936 (* 1 = 0.0842936 loss)
I0818 22:11:53.741577  3083 sgd_solver.cpp:165] Iteration 35500, lr = 0.01
I0818 22:12:21.705066  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:12:52.850267  3083 solver.cpp:357] Iteration 35600 (1.69182 iter/s, 59.1081s/100 iters), loss = 0.101037
I0818 22:12:52.850602  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0434624 (* 1 = 0.0434624 loss)
I0818 22:12:52.850641  3083 sgd_solver.cpp:165] Iteration 35600, lr = 0.01
I0818 22:14:03.409499  3083 solver.cpp:357] Iteration 35700 (1.41724 iter/s, 70.5595s/100 iters), loss = 0.101056
I0818 22:14:03.414925  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.135526 (* 1 = 0.135526 loss)
I0818 22:14:03.414986  3083 sgd_solver.cpp:165] Iteration 35700, lr = 0.01
I0818 22:15:11.953629  3083 solver.cpp:357] Iteration 35800 (1.45902 iter/s, 68.5389s/100 iters), loss = 0.0587285
I0818 22:15:11.958781  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0762459 (* 1 = 0.0762459 loss)
I0818 22:15:11.958811  3083 sgd_solver.cpp:165] Iteration 35800, lr = 0.01
I0818 22:16:24.145870  3083 solver.cpp:357] Iteration 35900 (1.38526 iter/s, 72.1887s/100 iters), loss = 0.115884
I0818 22:16:24.146126  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.1475 (* 1 = 0.1475 loss)
I0818 22:16:24.146158  3083 sgd_solver.cpp:165] Iteration 35900, lr = 0.01
I0818 22:16:49.120229  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:17:26.709672  3083 solver.cpp:514] Iteration 36000, Testing net (#0)
I0818 22:18:10.350706  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:18:10.572080  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.893203
I0818 22:18:10.572130  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.335745 (* 1 = 0.335745 loss)
I0818 22:18:11.186718  3083 solver.cpp:357] Iteration 36000 (0.934214 iter/s, 107.042s/100 iters), loss = 0.156641
I0818 22:18:11.186789  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.238602 (* 1 = 0.238602 loss)
I0818 22:18:11.186802  3083 sgd_solver.cpp:165] Iteration 36000, lr = 0.01
I0818 22:19:22.783802  3083 solver.cpp:357] Iteration 36100 (1.39671 iter/s, 71.597s/100 iters), loss = 0.0640311
I0818 22:19:22.783962  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0694717 (* 1 = 0.0694717 loss)
I0818 22:19:22.783973  3083 sgd_solver.cpp:165] Iteration 36100, lr = 0.01
I0818 22:20:34.549244  3083 solver.cpp:357] Iteration 36200 (1.39343 iter/s, 71.7654s/100 iters), loss = 0.0535173
I0818 22:20:34.549360  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0546747 (* 1 = 0.0546747 loss)
I0818 22:20:34.549371  3083 sgd_solver.cpp:165] Iteration 36200, lr = 0.01
I0818 22:21:43.752198  3083 solver.cpp:357] Iteration 36300 (1.44498 iter/s, 69.2049s/100 iters), loss = 0.140673
I0818 22:21:43.752336  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.180411 (* 1 = 0.180411 loss)
I0818 22:21:43.752348  3083 sgd_solver.cpp:165] Iteration 36300, lr = 0.01
I0818 22:21:58.549085  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:22:49.130750  3083 solver.cpp:357] Iteration 36400 (1.52955 iter/s, 65.3788s/100 iters), loss = 0.100885
I0818 22:22:49.130929  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0702263 (* 1 = 0.0702263 loss)
I0818 22:22:49.130941  3083 sgd_solver.cpp:165] Iteration 36400, lr = 0.01
I0818 22:24:00.653276  3083 solver.cpp:514] Iteration 36500, Testing net (#0)
I0818 22:24:44.790261  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:24:44.885231  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.893302
I0818 22:24:44.885298  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.353469 (* 1 = 0.353469 loss)
I0818 22:24:45.479526  3083 solver.cpp:357] Iteration 36500 (0.859482 iter/s, 116.349s/100 iters), loss = 0.0627465
I0818 22:24:45.479609  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0326837 (* 1 = 0.0326837 loss)
I0818 22:24:45.479621  3083 sgd_solver.cpp:165] Iteration 36500, lr = 0.01
I0818 22:25:57.454869  3083 solver.cpp:357] Iteration 36600 (1.38939 iter/s, 71.9742s/100 iters), loss = 0.121348
I0818 22:25:57.455077  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.139023 (* 1 = 0.139023 loss)
I0818 22:25:57.455088  3083 sgd_solver.cpp:165] Iteration 36600, lr = 0.01
I0818 22:27:00.468699  3083 solver.cpp:357] Iteration 36700 (1.58693 iter/s, 63.0146s/100 iters), loss = 0.07138
I0818 22:27:00.468874  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0572043 (* 1 = 0.0572043 loss)
I0818 22:27:00.468886  3083 sgd_solver.cpp:165] Iteration 36700, lr = 0.01
I0818 22:27:12.105739  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:28:12.295678  3083 solver.cpp:357] Iteration 36800 (1.39225 iter/s, 71.826s/100 iters), loss = 0.0716734
I0818 22:28:12.295816  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0707353 (* 1 = 0.0707353 loss)
I0818 22:28:12.295827  3083 sgd_solver.cpp:165] Iteration 36800, lr = 0.01
I0818 22:29:24.252667  3083 solver.cpp:357] Iteration 36900 (1.38971 iter/s, 71.9572s/100 iters), loss = 0.0653384
I0818 22:29:24.252787  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0914636 (* 1 = 0.0914636 loss)
I0818 22:29:24.252799  3083 sgd_solver.cpp:165] Iteration 36900, lr = 0.01
I0818 22:30:35.603657  3083 solver.cpp:514] Iteration 37000, Testing net (#0)
I0818 22:31:15.048702  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:31:15.187840  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.902902
I0818 22:31:15.187893  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.305851 (* 1 = 0.305851 loss)
I0818 22:31:15.733503  3083 solver.cpp:357] Iteration 37000 (0.897015 iter/s, 111.481s/100 iters), loss = 0.138946
I0818 22:31:15.733567  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.100349 (* 1 = 0.100349 loss)
I0818 22:31:15.733578  3083 sgd_solver.cpp:165] Iteration 37000, lr = 0.01
I0818 22:32:23.164224  3083 solver.cpp:357] Iteration 37100 (1.48297 iter/s, 67.4321s/100 iters), loss = 0.0695372
I0818 22:32:23.164543  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.096108 (* 1 = 0.096108 loss)
I0818 22:32:23.164607  3083 sgd_solver.cpp:165] Iteration 37100, lr = 0.01
I0818 22:32:27.912379  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:33:34.884387  3083 solver.cpp:357] Iteration 37200 (1.39432 iter/s, 71.7196s/100 iters), loss = 0.126851
I0818 22:33:34.884512  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.154416 (* 1 = 0.154416 loss)
I0818 22:33:34.884523  3083 sgd_solver.cpp:165] Iteration 37200, lr = 0.01
I0818 22:34:46.572341  3083 solver.cpp:357] Iteration 37300 (1.39494 iter/s, 71.6874s/100 iters), loss = 0.0589702
I0818 22:34:46.572511  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0396761 (* 1 = 0.0396761 loss)
I0818 22:34:46.572523  3083 sgd_solver.cpp:165] Iteration 37300, lr = 0.01
I0818 22:35:55.944607  3083 solver.cpp:357] Iteration 37400 (1.44151 iter/s, 69.3717s/100 iters), loss = 0.117525
I0818 22:35:55.944762  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.140526 (* 1 = 0.140526 loss)
I0818 22:35:55.944775  3083 sgd_solver.cpp:165] Iteration 37400, lr = 0.01
I0818 22:36:59.449177  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:37:00.834403  3083 solver.cpp:514] Iteration 37500, Testing net (#0)
I0818 22:37:44.733572  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:37:44.950429  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.897502
I0818 22:37:44.950477  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.34628 (* 1 = 0.34628 loss)
I0818 22:37:45.563518  3083 solver.cpp:357] Iteration 37500 (0.912247 iter/s, 109.619s/100 iters), loss = 0.0884042
I0818 22:37:45.563596  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.106236 (* 1 = 0.106236 loss)
I0818 22:37:45.563608  3083 sgd_solver.cpp:165] Iteration 37500, lr = 0.01
I0818 22:38:57.382359  3083 solver.cpp:357] Iteration 37600 (1.3924 iter/s, 71.8184s/100 iters), loss = 0.0790379
I0818 22:38:57.382612  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0359331 (* 1 = 0.0359331 loss)
I0818 22:38:57.382625  3083 sgd_solver.cpp:165] Iteration 37600, lr = 0.01
I0818 22:40:09.457108  3083 solver.cpp:357] Iteration 37700 (1.38746 iter/s, 72.0743s/100 iters), loss = 0.0787182
I0818 22:40:09.457260  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0743034 (* 1 = 0.0743034 loss)
I0818 22:40:09.457273  3083 sgd_solver.cpp:165] Iteration 37700, lr = 0.01
I0818 22:41:12.591625  3083 solver.cpp:357] Iteration 37800 (1.58393 iter/s, 63.1339s/100 iters), loss = 0.0854645
I0818 22:41:12.591791  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.096893 (* 1 = 0.096893 loss)
I0818 22:41:12.591802  3083 sgd_solver.cpp:165] Iteration 37800, lr = 0.01
I0818 22:42:15.874322  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:42:24.377835  3083 solver.cpp:357] Iteration 37900 (1.39303 iter/s, 71.7858s/100 iters), loss = 0.109195
I0818 22:42:24.377904  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0855826 (* 1 = 0.0855826 loss)
I0818 22:42:24.377916  3083 sgd_solver.cpp:165] Iteration 37900, lr = 0.01
I0818 22:43:35.837991  3083 solver.cpp:514] Iteration 38000, Testing net (#0)
I0818 22:44:20.143519  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:44:20.363231  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.874602
I0818 22:44:20.363278  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.437249 (* 1 = 0.437249 loss)
I0818 22:44:20.969970  3083 solver.cpp:357] Iteration 38000 (0.857684 iter/s, 116.593s/100 iters), loss = 0.0593017
I0818 22:44:20.970036  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0904647 (* 1 = 0.0904647 loss)
I0818 22:44:20.970046  3083 sgd_solver.cpp:165] Iteration 38000, lr = 0.01
I0818 22:45:28.305249  3083 solver.cpp:357] Iteration 38100 (1.48507 iter/s, 67.3369s/100 iters), loss = 0.0896513
I0818 22:45:28.305394  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.108127 (* 1 = 0.108127 loss)
I0818 22:45:28.305408  3083 sgd_solver.cpp:165] Iteration 38100, lr = 0.01
I0818 22:46:35.866219  3083 solver.cpp:357] Iteration 38200 (1.48015 iter/s, 67.5606s/100 iters), loss = 0.0394852
I0818 22:46:35.866386  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0584072 (* 1 = 0.0584072 loss)
I0818 22:46:35.866399  3083 sgd_solver.cpp:165] Iteration 38200, lr = 0.01
I0818 22:47:32.416350  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:47:47.679558  3083 solver.cpp:357] Iteration 38300 (1.3925 iter/s, 71.8131s/100 iters), loss = 0.127641
I0818 22:47:47.679632  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0574689 (* 1 = 0.0574689 loss)
I0818 22:47:47.679642  3083 sgd_solver.cpp:165] Iteration 38300, lr = 0.01
I0818 22:48:59.702754  3083 solver.cpp:357] Iteration 38400 (1.38841 iter/s, 72.025s/100 iters), loss = 0.110673
I0818 22:48:59.702872  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0800338 (* 1 = 0.0800338 loss)
I0818 22:48:59.702884  3083 sgd_solver.cpp:165] Iteration 38400, lr = 0.01
I0818 22:50:08.358937  3083 solver.cpp:514] Iteration 38500, Testing net (#0)
I0818 22:50:46.406330  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:50:46.547045  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.889102
I0818 22:50:46.547091  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.386244 (* 1 = 0.386244 loss)
I0818 22:50:47.151873  3083 solver.cpp:357] Iteration 38500 (0.930667 iter/s, 107.45s/100 iters), loss = 0.0569017
I0818 22:50:47.151937  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0886633 (* 1 = 0.0886633 loss)
I0818 22:50:47.151947  3083 sgd_solver.cpp:165] Iteration 38500, lr = 0.01
I0818 22:51:59.012612  3083 solver.cpp:357] Iteration 38600 (1.39155 iter/s, 71.8626s/100 iters), loss = 0.0678869
I0818 22:51:59.012797  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0580796 (* 1 = 0.0580796 loss)
I0818 22:51:59.012810  3083 sgd_solver.cpp:165] Iteration 38600, lr = 0.01
I0818 22:52:48.740856  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:53:10.700302  3083 solver.cpp:357] Iteration 38700 (1.39494 iter/s, 71.6874s/100 iters), loss = 0.0855078
I0818 22:53:10.700366  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0529523 (* 1 = 0.0529523 loss)
I0818 22:53:10.700376  3083 sgd_solver.cpp:165] Iteration 38700, lr = 0.01
I0818 22:54:22.718842  3083 solver.cpp:357] Iteration 38800 (1.3885 iter/s, 72.0204s/100 iters), loss = 0.0788085
I0818 22:54:22.718998  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0793105 (* 1 = 0.0793105 loss)
I0818 22:54:22.719012  3083 sgd_solver.cpp:165] Iteration 38800, lr = 0.01
I0818 22:55:26.194947  3083 solver.cpp:357] Iteration 38900 (1.57541 iter/s, 63.4757s/100 iters), loss = 0.0609962
I0818 22:55:26.195080  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0493818 (* 1 = 0.0493818 loss)
I0818 22:55:26.195089  3083 sgd_solver.cpp:165] Iteration 38900, lr = 0.01
I0818 22:56:37.515719  3083 solver.cpp:514] Iteration 39000, Testing net (#0)
I0818 22:57:21.535470  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:57:21.676929  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.899202
I0818 22:57:21.676990  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.342405 (* 1 = 0.342405 loss)
I0818 22:57:22.283810  3083 solver.cpp:357] Iteration 39000 (0.861387 iter/s, 116.092s/100 iters), loss = 0.041923
I0818 22:57:22.283880  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0347567 (* 1 = 0.0347567 loss)
I0818 22:57:22.283893  3083 sgd_solver.cpp:165] Iteration 39000, lr = 0.01
I0818 22:58:05.108886  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 22:58:34.209810  3083 solver.cpp:357] Iteration 39100 (1.39028 iter/s, 71.9278s/100 iters), loss = 0.0703786
I0818 22:58:34.209883  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0853814 (* 1 = 0.0853814 loss)
I0818 22:58:34.209893  3083 sgd_solver.cpp:165] Iteration 39100, lr = 0.01
I0818 22:59:40.918467  3083 solver.cpp:357] Iteration 39200 (1.49893 iter/s, 66.7143s/100 iters), loss = 0.0603079
I0818 22:59:40.918604  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.062421 (* 1 = 0.062421 loss)
I0818 22:59:40.918615  3083 sgd_solver.cpp:165] Iteration 39200, lr = 0.01
I0818 23:00:49.100134  3083 solver.cpp:357] Iteration 39300 (1.46656 iter/s, 68.187s/100 iters), loss = 0.12742
I0818 23:00:49.100255  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.158797 (* 1 = 0.158797 loss)
I0818 23:00:49.100268  3083 sgd_solver.cpp:165] Iteration 39300, lr = 0.01
I0818 23:02:00.966286  3083 solver.cpp:357] Iteration 39400 (1.39141 iter/s, 71.8694s/100 iters), loss = 0.0396774
I0818 23:02:00.966462  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0252931 (* 1 = 0.0252931 loss)
I0818 23:02:00.966477  3083 sgd_solver.cpp:165] Iteration 39400, lr = 0.01
I0818 23:02:37.395865  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:03:12.616752  3083 solver.cpp:514] Iteration 39500, Testing net (#0)
I0818 23:03:59.041816  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:03:59.171249  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.889002
I0818 23:03:59.171294  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.369245 (* 1 = 0.369245 loss)
I0818 23:03:59.705881  3083 solver.cpp:357] Iteration 39500 (0.842136 iter/s, 118.746s/100 iters), loss = 0.0933519
I0818 23:03:59.705948  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0859827 (* 1 = 0.0859827 loss)
I0818 23:03:59.705961  3083 sgd_solver.cpp:165] Iteration 39500, lr = 0.01
I0818 23:05:02.982152  3083 solver.cpp:357] Iteration 39600 (1.58032 iter/s, 63.2781s/100 iters), loss = 0.140681
I0818 23:05:02.982396  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.191102 (* 1 = 0.191102 loss)
I0818 23:05:02.982411  3083 sgd_solver.cpp:165] Iteration 39600, lr = 0.01
I0818 23:06:15.572548  3083 solver.cpp:357] Iteration 39700 (1.37755 iter/s, 72.5926s/100 iters), loss = 0.106373
I0818 23:06:15.572770  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.123041 (* 1 = 0.123041 loss)
I0818 23:06:15.572800  3083 sgd_solver.cpp:165] Iteration 39700, lr = 0.01
I0818 23:07:27.568720  3083 solver.cpp:357] Iteration 39800 (1.38892 iter/s, 71.9982s/100 iters), loss = 0.0748492
I0818 23:07:27.568861  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0631185 (* 1 = 0.0631185 loss)
I0818 23:07:27.568876  3083 sgd_solver.cpp:165] Iteration 39800, lr = 0.01
I0818 23:07:57.341543  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:08:39.747045  3083 solver.cpp:357] Iteration 39900 (1.38542 iter/s, 72.1801s/100 iters), loss = 0.0505236
I0818 23:08:39.747162  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0891875 (* 1 = 0.0891875 loss)
I0818 23:08:39.747172  3083 sgd_solver.cpp:165] Iteration 39900, lr = 0.01
I0818 23:09:41.871312  3083 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_56_iter_40000.caffemodel
I0818 23:09:41.900802  3083 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_56_iter_40000.solverstate
I0818 23:09:41.910208  3083 solver.cpp:514] Iteration 40000, Testing net (#0)
I0818 23:10:26.059046  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:10:26.194900  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.881001
I0818 23:10:26.194954  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.412692 (* 1 = 0.412692 loss)
I0818 23:10:26.797324  3083 solver.cpp:357] Iteration 40000 (0.934093 iter/s, 107.056s/100 iters), loss = 0.149092
I0818 23:10:26.797390  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0362312 (* 1 = 0.0362312 loss)
I0818 23:10:26.797401  3083 sgd_solver.cpp:165] Iteration 40000, lr = 0.01
I0818 23:11:38.821251  3083 solver.cpp:357] Iteration 40100 (1.38836 iter/s, 72.0274s/100 iters), loss = 0.0817292
I0818 23:11:38.821566  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0849697 (* 1 = 0.0849697 loss)
I0818 23:11:38.821583  3083 sgd_solver.cpp:165] Iteration 40100, lr = 0.01
I0818 23:12:50.639309  3083 solver.cpp:357] Iteration 40200 (1.39238 iter/s, 71.8194s/100 iters), loss = 0.0705232
I0818 23:12:50.639461  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0295003 (* 1 = 0.0295003 loss)
I0818 23:12:50.639472  3083 sgd_solver.cpp:165] Iteration 40200, lr = 0.01
I0818 23:13:13.563809  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:13:55.832077  3083 solver.cpp:357] Iteration 40300 (1.53389 iter/s, 65.1936s/100 iters), loss = 0.073508
I0818 23:13:55.832213  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.087108 (* 1 = 0.087108 loss)
I0818 23:13:55.832226  3083 sgd_solver.cpp:165] Iteration 40300, lr = 0.01
I0818 23:15:05.170809  3083 solver.cpp:357] Iteration 40400 (1.44213 iter/s, 69.3417s/100 iters), loss = 0.0894689
I0818 23:15:05.171041  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0654876 (* 1 = 0.0654876 loss)
I0818 23:15:05.171072  3083 sgd_solver.cpp:165] Iteration 40400, lr = 0.01
I0818 23:16:16.391657  3083 solver.cpp:514] Iteration 40500, Testing net (#0)
I0818 23:17:00.104424  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:17:00.281747  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.885002
I0818 23:17:00.281810  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.413326 (* 1 = 0.413326 loss)
I0818 23:17:00.886016  3083 solver.cpp:357] Iteration 40500 (0.864168 iter/s, 115.718s/100 iters), loss = 0.123314
I0818 23:17:00.886085  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0939318 (* 1 = 0.0939318 loss)
I0818 23:17:00.886097  3083 sgd_solver.cpp:165] Iteration 40500, lr = 0.01
I0818 23:18:12.761638  3083 solver.cpp:357] Iteration 40600 (1.39127 iter/s, 71.8766s/100 iters), loss = 0.068217
I0818 23:18:12.761886  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0660897 (* 1 = 0.0660897 loss)
I0818 23:18:12.761914  3083 sgd_solver.cpp:165] Iteration 40600, lr = 0.01
I0818 23:18:25.164722  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:19:14.231058  3083 solver.cpp:357] Iteration 40700 (1.62676 iter/s, 61.4718s/100 iters), loss = 0.0847586
I0818 23:19:14.231254  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0364783 (* 1 = 0.0364783 loss)
I0818 23:19:14.231267  3083 sgd_solver.cpp:165] Iteration 40700, lr = 0.01
I0818 23:20:26.632241  3083 solver.cpp:357] Iteration 40800 (1.38116 iter/s, 72.4031s/100 iters), loss = 0.0512521
I0818 23:20:26.632392  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0498894 (* 1 = 0.0498894 loss)
I0818 23:20:26.632405  3083 sgd_solver.cpp:165] Iteration 40800, lr = 0.01
I0818 23:21:38.753551  3083 solver.cpp:357] Iteration 40900 (1.3865 iter/s, 72.1241s/100 iters), loss = 0.0362802
I0818 23:21:38.753664  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.041624 (* 1 = 0.041624 loss)
I0818 23:21:38.753674  3083 sgd_solver.cpp:165] Iteration 40900, lr = 0.01
I0818 23:22:50.022395  3083 solver.cpp:514] Iteration 41000, Testing net (#0)
I0818 23:23:26.436717  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:23:26.557492  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.871001
I0818 23:23:26.557544  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.47551 (* 1 = 0.47551 loss)
I0818 23:23:27.088954  3083 solver.cpp:357] Iteration 41000 (0.923023 iter/s, 108.34s/100 iters), loss = 0.0427009
I0818 23:23:27.089022  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0297869 (* 1 = 0.0297869 loss)
I0818 23:23:27.089035  3083 sgd_solver.cpp:165] Iteration 41000, lr = 0.01
I0818 23:23:35.545789  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:24:37.992496  3083 solver.cpp:357] Iteration 41100 (1.41032 iter/s, 70.9061s/100 iters), loss = 0.0898046
I0818 23:24:37.992710  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0745443 (* 1 = 0.0745443 loss)
I0818 23:24:37.992735  3083 sgd_solver.cpp:165] Iteration 41100, lr = 0.01
I0818 23:25:50.220458  3083 solver.cpp:357] Iteration 41200 (1.38449 iter/s, 72.2286s/100 iters), loss = 0.0540786
I0818 23:25:50.220782  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00955382 (* 1 = 0.00955382 loss)
I0818 23:25:50.220844  3083 sgd_solver.cpp:165] Iteration 41200, lr = 0.01
I0818 23:27:02.330699  3083 solver.cpp:357] Iteration 41300 (1.38675 iter/s, 72.111s/100 iters), loss = 0.0353661
I0818 23:27:02.330797  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0580188 (* 1 = 0.0580188 loss)
I0818 23:27:02.330808  3083 sgd_solver.cpp:165] Iteration 41300, lr = 0.01
I0818 23:28:08.072897  3083 solver.cpp:357] Iteration 41400 (1.52104 iter/s, 65.7447s/100 iters), loss = 0.062463
I0818 23:28:08.073029  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0468085 (* 1 = 0.0468085 loss)
I0818 23:28:08.073043  3083 sgd_solver.cpp:165] Iteration 41400, lr = 0.01
I0818 23:28:10.125607  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:29:16.344815  3083 solver.cpp:514] Iteration 41500, Testing net (#0)
I0818 23:30:00.606957  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:30:00.829635  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.882402
I0818 23:30:00.829680  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.473822 (* 1 = 0.473822 loss)
I0818 23:30:01.438205  3083 solver.cpp:357] Iteration 41500 (0.882071 iter/s, 113.37s/100 iters), loss = 0.0914274
I0818 23:30:01.438266  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.146797 (* 1 = 0.146797 loss)
I0818 23:30:01.438277  3083 sgd_solver.cpp:165] Iteration 41500, lr = 0.01
I0818 23:31:13.409883  3083 solver.cpp:357] Iteration 41600 (1.38938 iter/s, 71.9744s/100 iters), loss = 0.140139
I0818 23:31:13.410065  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.176311 (* 1 = 0.176311 loss)
I0818 23:31:13.410081  3083 sgd_solver.cpp:165] Iteration 41600, lr = 0.01
I0818 23:32:25.081419  3083 solver.cpp:357] Iteration 41700 (1.3952 iter/s, 71.6741s/100 iters), loss = 0.0792601
I0818 23:32:25.081529  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0846675 (* 1 = 0.0846675 loss)
I0818 23:32:25.081542  3083 sgd_solver.cpp:165] Iteration 41700, lr = 0.01
I0818 23:33:23.476750  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:33:27.695979  3083 solver.cpp:357] Iteration 41800 (1.59701 iter/s, 62.6168s/100 iters), loss = 0.0769405
I0818 23:33:27.696051  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0615495 (* 1 = 0.0615495 loss)
I0818 23:33:27.696063  3083 sgd_solver.cpp:165] Iteration 41800, lr = 0.01
I0818 23:34:39.493455  3083 solver.cpp:357] Iteration 41900 (1.39279 iter/s, 71.7981s/100 iters), loss = 0.0581667
I0818 23:34:39.493641  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0316828 (* 1 = 0.0316828 loss)
I0818 23:34:39.493654  3083 sgd_solver.cpp:165] Iteration 41900, lr = 0.01
I0818 23:35:50.728651  3083 solver.cpp:514] Iteration 42000, Testing net (#0)
I0818 23:36:34.886811  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:36:35.066555  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.868202
I0818 23:36:35.066601  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.496626 (* 1 = 0.496626 loss)
I0818 23:36:35.672966  3083 solver.cpp:357] Iteration 42000 (0.86072 iter/s, 116.182s/100 iters), loss = 0.196742
I0818 23:36:35.673027  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.28585 (* 1 = 0.28585 loss)
I0818 23:36:35.673038  3083 sgd_solver.cpp:165] Iteration 42000, lr = 0.01
I0818 23:37:39.636726  3083 solver.cpp:357] Iteration 42100 (1.56333 iter/s, 63.9661s/100 iters), loss = 0.041214
I0818 23:37:39.636878  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0415826 (* 1 = 0.0415826 loss)
I0818 23:37:39.636889  3083 sgd_solver.cpp:165] Iteration 42100, lr = 0.01
I0818 23:38:39.113543  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:38:50.153527  3083 solver.cpp:357] Iteration 42200 (1.41805 iter/s, 70.5193s/100 iters), loss = 0.0631401
I0818 23:38:50.153604  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0304571 (* 1 = 0.0304571 loss)
I0818 23:38:50.153614  3083 sgd_solver.cpp:165] Iteration 42200, lr = 0.01
I0818 23:40:01.957636  3083 solver.cpp:357] Iteration 42300 (1.39267 iter/s, 71.8047s/100 iters), loss = 0.022794
I0818 23:40:01.957752  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0266842 (* 1 = 0.0266842 loss)
I0818 23:40:01.957764  3083 sgd_solver.cpp:165] Iteration 42300, lr = 0.01
I0818 23:41:13.727687  3083 solver.cpp:357] Iteration 42400 (1.39333 iter/s, 71.7706s/100 iters), loss = 0.111365
I0818 23:41:13.727782  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.102657 (* 1 = 0.102657 loss)
I0818 23:41:13.727793  3083 sgd_solver.cpp:165] Iteration 42400, lr = 0.01
I0818 23:42:19.568583  3083 solver.cpp:514] Iteration 42500, Testing net (#0)
I0818 23:43:00.133533  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:43:00.353866  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.874502
I0818 23:43:00.353920  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.472619 (* 1 = 0.472619 loss)
I0818 23:43:00.973021  3083 solver.cpp:357] Iteration 42500 (0.932407 iter/s, 107.249s/100 iters), loss = 0.0297461
I0818 23:43:00.973093  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0244325 (* 1 = 0.0244325 loss)
I0818 23:43:00.973104  3083 sgd_solver.cpp:165] Iteration 42500, lr = 0.01
I0818 23:43:55.177373  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:44:12.721911  3083 solver.cpp:357] Iteration 42600 (1.39374 iter/s, 71.7494s/100 iters), loss = 0.0456739
I0818 23:44:12.721985  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0274081 (* 1 = 0.0274081 loss)
I0818 23:44:12.721997  3083 sgd_solver.cpp:165] Iteration 42600, lr = 0.01
I0818 23:45:24.492655  3083 solver.cpp:357] Iteration 42700 (1.39331 iter/s, 71.7713s/100 iters), loss = 0.139285
I0818 23:45:24.492772  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.131418 (* 1 = 0.131418 loss)
I0818 23:45:24.492787  3083 sgd_solver.cpp:165] Iteration 42700, lr = 0.01
I0818 23:46:36.444599  3083 solver.cpp:357] Iteration 42800 (1.38981 iter/s, 71.9525s/100 iters), loss = 0.129127
I0818 23:46:36.444736  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0871257 (* 1 = 0.0871257 loss)
I0818 23:46:36.444747  3083 sgd_solver.cpp:165] Iteration 42800, lr = 0.01
I0818 23:47:39.224264  3083 solver.cpp:357] Iteration 42900 (1.59287 iter/s, 62.7799s/100 iters), loss = 0.0856171
I0818 23:47:39.224417  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.10424 (* 1 = 0.10424 loss)
I0818 23:47:39.224431  3083 sgd_solver.cpp:165] Iteration 42900, lr = 0.01
I0818 23:48:26.754088  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:48:50.452443  3083 solver.cpp:514] Iteration 43000, Testing net (#0)
I0818 23:49:34.602016  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:49:34.703611  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.870401
I0818 23:49:34.703680  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.465835 (* 1 = 0.465835 loss)
I0818 23:49:35.307269  3083 solver.cpp:357] Iteration 43000 (0.861483 iter/s, 116.079s/100 iters), loss = 0.0377185
I0818 23:49:35.307348  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0453061 (* 1 = 0.0453061 loss)
I0818 23:49:35.307361  3083 sgd_solver.cpp:165] Iteration 43000, lr = 0.01
I0818 23:50:47.369881  3083 solver.cpp:357] Iteration 43100 (1.38806 iter/s, 72.0431s/100 iters), loss = 0.0755137
I0818 23:50:47.370167  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0935569 (* 1 = 0.0935569 loss)
I0818 23:50:47.370223  3083 sgd_solver.cpp:165] Iteration 43100, lr = 0.01
I0818 23:51:51.342329  3083 solver.cpp:357] Iteration 43200 (1.56347 iter/s, 63.9603s/100 iters), loss = 0.106202
I0818 23:51:51.342473  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0395813 (* 1 = 0.0395813 loss)
I0818 23:51:51.342487  3083 sgd_solver.cpp:165] Iteration 43200, lr = 0.01
I0818 23:53:01.193061  3083 solver.cpp:357] Iteration 43300 (1.43187 iter/s, 69.8387s/100 iters), loss = 0.0404525
I0818 23:53:01.193222  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0545089 (* 1 = 0.0545089 loss)
I0818 23:53:01.193235  3083 sgd_solver.cpp:165] Iteration 43300, lr = 0.01
I0818 23:53:41.787158  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:54:13.025883  3083 solver.cpp:357] Iteration 43400 (1.39232 iter/s, 71.8227s/100 iters), loss = 0.205378
I0818 23:54:13.026011  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.212889 (* 1 = 0.212889 loss)
I0818 23:54:13.026023  3083 sgd_solver.cpp:165] Iteration 43400, lr = 0.01
I0818 23:55:24.278707  3083 solver.cpp:514] Iteration 43500, Testing net (#0)
I0818 23:56:07.267624  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:56:07.396497  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.882002
I0818 23:56:07.396586  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.43067 (* 1 = 0.43067 loss)
I0818 23:56:07.934964  3083 solver.cpp:357] Iteration 43500 (0.870338 iter/s, 114.898s/100 iters), loss = 0.128786
I0818 23:56:07.935025  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.124975 (* 1 = 0.124975 loss)
I0818 23:56:07.935037  3083 sgd_solver.cpp:165] Iteration 43500, lr = 0.01
I0818 23:57:11.645853  3083 solver.cpp:357] Iteration 43600 (1.56968 iter/s, 63.7072s/100 iters), loss = 0.09242
I0818 23:57:11.646143  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0604446 (* 1 = 0.0604446 loss)
I0818 23:57:11.646158  3083 sgd_solver.cpp:165] Iteration 43600, lr = 0.01
I0818 23:58:24.156270  3083 solver.cpp:357] Iteration 43700 (1.37921 iter/s, 72.5051s/100 iters), loss = 0.0668449
I0818 23:58:24.156630  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.052031 (* 1 = 0.052031 loss)
I0818 23:58:24.156703  3083 sgd_solver.cpp:165] Iteration 43700, lr = 0.01
I0818 23:58:58.474009  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0818 23:59:36.915899  3083 solver.cpp:357] Iteration 43800 (1.37448 iter/s, 72.7549s/100 iters), loss = 0.105188
I0818 23:59:36.916121  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.11853 (* 1 = 0.11853 loss)
I0818 23:59:36.916151  3083 sgd_solver.cpp:165] Iteration 43800, lr = 0.01
I0819 00:00:49.560068  3083 solver.cpp:357] Iteration 43900 (1.37662 iter/s, 72.6418s/100 iters), loss = 0.124562
I0819 00:00:49.560299  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.140248 (* 1 = 0.140248 loss)
I0819 00:00:49.560330  3083 sgd_solver.cpp:165] Iteration 43900, lr = 0.01
I0819 00:01:51.343811  3083 solver.cpp:514] Iteration 44000, Testing net (#0)
I0819 00:02:35.285984  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:02:35.510728  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.875001
I0819 00:02:35.510774  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.451822 (* 1 = 0.451822 loss)
I0819 00:02:36.114507  3083 solver.cpp:357] Iteration 44000 (0.938516 iter/s, 106.551s/100 iters), loss = 0.0719802
I0819 00:02:36.114572  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0960755 (* 1 = 0.0960755 loss)
I0819 00:02:36.114583  3083 sgd_solver.cpp:165] Iteration 44000, lr = 0.01
I0819 00:03:48.065337  3083 solver.cpp:357] Iteration 44100 (1.38986 iter/s, 71.9496s/100 iters), loss = 0.117243
I0819 00:03:48.065465  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0591925 (* 1 = 0.0591925 loss)
I0819 00:03:48.065476  3083 sgd_solver.cpp:165] Iteration 44100, lr = 0.01
I0819 00:04:15.447365  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:04:59.791096  3083 solver.cpp:357] Iteration 44200 (1.39426 iter/s, 71.7227s/100 iters), loss = 0.0764886
I0819 00:04:59.791275  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.104266 (* 1 = 0.104266 loss)
I0819 00:04:59.791285  3083 sgd_solver.cpp:165] Iteration 44200, lr = 0.01
I0819 00:06:04.672354  3083 solver.cpp:357] Iteration 44300 (1.54133 iter/s, 64.8789s/100 iters), loss = 0.0404694
I0819 00:06:04.672490  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.025954 (* 1 = 0.025954 loss)
I0819 00:06:04.672502  3083 sgd_solver.cpp:165] Iteration 44300, lr = 0.01
I0819 00:07:14.924916  3083 solver.cpp:357] Iteration 44400 (1.42348 iter/s, 70.2504s/100 iters), loss = 0.127292
I0819 00:07:14.925076  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.060586 (* 1 = 0.060586 loss)
I0819 00:07:14.925087  3083 sgd_solver.cpp:165] Iteration 44400, lr = 0.01
I0819 00:08:25.890067  3083 solver.cpp:514] Iteration 44500, Testing net (#0)
I0819 00:09:09.921691  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:09:10.143683  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.861501
I0819 00:09:10.143730  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.521944 (* 1 = 0.521944 loss)
I0819 00:09:10.753341  3083 solver.cpp:357] Iteration 44500 (0.863387 iter/s, 115.823s/100 iters), loss = 0.0855111
I0819 00:09:10.753404  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.11639 (* 1 = 0.11639 loss)
I0819 00:09:10.753415  3083 sgd_solver.cpp:165] Iteration 44500, lr = 0.01
I0819 00:09:31.285382  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:10:21.537055  3083 solver.cpp:357] Iteration 44600 (1.41279 iter/s, 70.7818s/100 iters), loss = 0.0979603
I0819 00:10:21.537236  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.127202 (* 1 = 0.127202 loss)
I0819 00:10:21.537248  3083 sgd_solver.cpp:165] Iteration 44600, lr = 0.01
I0819 00:11:25.969054  3083 solver.cpp:357] Iteration 44700 (1.55207 iter/s, 64.4303s/100 iters), loss = 0.0525238
I0819 00:11:25.969182  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0440433 (* 1 = 0.0440433 loss)
I0819 00:11:25.969192  3083 sgd_solver.cpp:165] Iteration 44700, lr = 0.01
I0819 00:12:38.192984  3083 solver.cpp:357] Iteration 44800 (1.38462 iter/s, 72.2222s/100 iters), loss = 0.0646809
I0819 00:12:38.193099  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0489995 (* 1 = 0.0489995 loss)
I0819 00:12:38.193110  3083 sgd_solver.cpp:165] Iteration 44800, lr = 0.01
I0819 00:13:50.096027  3083 solver.cpp:357] Iteration 44900 (1.39083 iter/s, 71.8995s/100 iters), loss = 0.123771
I0819 00:13:50.096197  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.095192 (* 1 = 0.095192 loss)
I0819 00:13:50.096210  3083 sgd_solver.cpp:165] Iteration 44900, lr = 0.01
I0819 00:14:03.862906  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:15:01.482517  3083 solver.cpp:514] Iteration 45000, Testing net (#0)
I0819 00:15:37.188592  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:15:37.367421  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.878702
I0819 00:15:37.367466  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.465092 (* 1 = 0.465092 loss)
I0819 00:15:37.972995  3083 solver.cpp:357] Iteration 45000 (0.927017 iter/s, 107.873s/100 iters), loss = 0.060796
I0819 00:15:37.973057  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0271746 (* 1 = 0.0271746 loss)
I0819 00:15:37.973067  3083 sgd_solver.cpp:165] Iteration 45000, lr = 0.01
I0819 00:16:49.789820  3083 solver.cpp:357] Iteration 45100 (1.39246 iter/s, 71.8156s/100 iters), loss = 0.0581653
I0819 00:16:49.789947  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0468265 (* 1 = 0.0468265 loss)
I0819 00:16:49.789958  3083 sgd_solver.cpp:165] Iteration 45100, lr = 0.01
I0819 00:18:01.810292  3083 solver.cpp:357] Iteration 45200 (1.38856 iter/s, 72.0172s/100 iters), loss = 0.11627
I0819 00:18:01.810392  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.133288 (* 1 = 0.133288 loss)
I0819 00:18:01.810405  3083 sgd_solver.cpp:165] Iteration 45200, lr = 0.01
I0819 00:19:13.631434  3083 solver.cpp:357] Iteration 45300 (1.39241 iter/s, 71.818s/100 iters), loss = 0.0803948
I0819 00:19:13.631620  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0931625 (* 1 = 0.0931625 loss)
I0819 00:19:13.631633  3083 sgd_solver.cpp:165] Iteration 45300, lr = 0.01
I0819 00:19:20.557539  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:20:16.955890  3083 solver.cpp:357] Iteration 45400 (1.57924 iter/s, 63.3214s/100 iters), loss = 0.0645802
I0819 00:20:16.956038  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0664502 (* 1 = 0.0664502 loss)
I0819 00:20:16.956051  3083 sgd_solver.cpp:165] Iteration 45400, lr = 0.01
I0819 00:20:54.172775  3083 solver.cpp:514] Iteration 45500, Testing net (#0)
I0819 00:21:02.990353  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:21:03.022140  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.832501
I0819 00:21:03.022199  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.708937 (* 1 = 0.708937 loss)
I0819 00:21:03.359284  3083 solver.cpp:357] Iteration 45500 (2.15505 iter/s, 46.4026s/100 iters), loss = 0.094518
I0819 00:21:03.359362  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.12478 (* 1 = 0.12478 loss)
I0819 00:21:03.359375  3083 sgd_solver.cpp:165] Iteration 45500, lr = 0.01
I0819 00:21:37.579509  3083 solver.cpp:357] Iteration 45600 (2.92229 iter/s, 34.2197s/100 iters), loss = 0.0741622
I0819 00:21:37.579746  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0293405 (* 1 = 0.0293405 loss)
I0819 00:21:37.579759  3083 sgd_solver.cpp:165] Iteration 45600, lr = 0.01
I0819 00:22:11.833634  3083 solver.cpp:357] Iteration 45700 (2.91941 iter/s, 34.2535s/100 iters), loss = 0.0747191
I0819 00:22:11.833814  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0838677 (* 1 = 0.0838677 loss)
I0819 00:22:11.833827  3083 sgd_solver.cpp:165] Iteration 45700, lr = 0.01
I0819 00:22:12.013216  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:22:46.108850  3083 solver.cpp:357] Iteration 45800 (2.91761 iter/s, 34.2746s/100 iters), loss = 0.0882807
I0819 00:22:46.109026  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.112296 (* 1 = 0.112296 loss)
I0819 00:22:46.109040  3083 sgd_solver.cpp:165] Iteration 45800, lr = 0.01
I0819 00:23:20.438766  3083 solver.cpp:357] Iteration 45900 (2.91296 iter/s, 34.3293s/100 iters), loss = 0.0617189
I0819 00:23:20.438933  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0893846 (* 1 = 0.0893846 loss)
I0819 00:23:20.438946  3083 sgd_solver.cpp:165] Iteration 45900, lr = 0.01
I0819 00:23:54.447350  3083 solver.cpp:514] Iteration 46000, Testing net (#0)
I0819 00:24:03.205854  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:24:03.268671  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.861602
I0819 00:24:03.268748  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.497631 (* 1 = 0.497631 loss)
I0819 00:24:03.606477  3083 solver.cpp:357] Iteration 46000 (2.31658 iter/s, 43.167s/100 iters), loss = 0.103809
I0819 00:24:03.606546  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.13595 (* 1 = 0.13595 loss)
I0819 00:24:03.606557  3083 sgd_solver.cpp:165] Iteration 46000, lr = 0.01
I0819 00:24:34.795967  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:24:37.889647  3083 solver.cpp:357] Iteration 46100 (2.91692 iter/s, 34.2827s/100 iters), loss = 0.0718811
I0819 00:24:37.889726  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.120469 (* 1 = 0.120469 loss)
I0819 00:24:37.889739  3083 sgd_solver.cpp:165] Iteration 46100, lr = 0.01
I0819 00:25:12.135145  3083 solver.cpp:357] Iteration 46200 (2.92013 iter/s, 34.245s/100 iters), loss = 0.073463
I0819 00:25:12.135314  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0987268 (* 1 = 0.0987268 loss)
I0819 00:25:12.135327  3083 sgd_solver.cpp:165] Iteration 46200, lr = 0.01
I0819 00:25:46.365581  3083 solver.cpp:357] Iteration 46300 (2.92142 iter/s, 34.2299s/100 iters), loss = 0.0850018
I0819 00:25:46.365730  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0769186 (* 1 = 0.0769186 loss)
I0819 00:25:46.365742  3083 sgd_solver.cpp:165] Iteration 46300, lr = 0.01
I0819 00:26:20.617090  3083 solver.cpp:357] Iteration 46400 (2.91962 iter/s, 34.251s/100 iters), loss = 0.0737002
I0819 00:26:20.617274  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.110106 (* 1 = 0.110106 loss)
I0819 00:26:20.617286  3083 sgd_solver.cpp:165] Iteration 46400, lr = 0.01
I0819 00:26:48.519599  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:26:54.508198  3083 solver.cpp:514] Iteration 46500, Testing net (#0)
I0819 00:27:03.419687  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:27:03.451788  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.858102
I0819 00:27:03.451843  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.552933 (* 1 = 0.552933 loss)
I0819 00:27:03.792327  3083 solver.cpp:357] Iteration 46500 (2.31618 iter/s, 43.1746s/100 iters), loss = 0.075709
I0819 00:27:03.792408  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0911637 (* 1 = 0.0911637 loss)
I0819 00:27:03.792420  3083 sgd_solver.cpp:165] Iteration 46500, lr = 0.01
I0819 00:27:38.010073  3083 solver.cpp:357] Iteration 46600 (2.9225 iter/s, 34.2173s/100 iters), loss = 0.118348
I0819 00:27:38.010330  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0955378 (* 1 = 0.0955378 loss)
I0819 00:27:38.010344  3083 sgd_solver.cpp:165] Iteration 46600, lr = 0.01
I0819 00:28:12.209987  3083 solver.cpp:357] Iteration 46700 (2.92403 iter/s, 34.1993s/100 iters), loss = 0.0511846
I0819 00:28:12.210158  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0612532 (* 1 = 0.0612532 loss)
I0819 00:28:12.210170  3083 sgd_solver.cpp:165] Iteration 46700, lr = 0.01
I0819 00:28:46.510390  3083 solver.cpp:357] Iteration 46800 (2.91546 iter/s, 34.2999s/100 iters), loss = 0.0832974
I0819 00:28:46.510561  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.141725 (* 1 = 0.141725 loss)
I0819 00:28:46.510574  3083 sgd_solver.cpp:165] Iteration 46800, lr = 0.01
I0819 00:29:11.193482  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:29:20.791796  3083 solver.cpp:357] Iteration 46900 (2.91708 iter/s, 34.2809s/100 iters), loss = 0.162824
I0819 00:29:20.792013  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.124681 (* 1 = 0.124681 loss)
I0819 00:29:20.792027  3083 sgd_solver.cpp:165] Iteration 46900, lr = 0.01
I0819 00:29:54.807961  3083 solver.cpp:514] Iteration 47000, Testing net (#0)
I0819 00:30:03.599300  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:30:03.640476  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.892602
I0819 00:30:03.640535  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.39303 (* 1 = 0.39303 loss)
I0819 00:30:03.980330  3083 solver.cpp:357] Iteration 47000 (2.31546 iter/s, 43.1879s/100 iters), loss = 0.0874257
I0819 00:30:03.980420  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0616973 (* 1 = 0.0616973 loss)
I0819 00:30:03.980433  3083 sgd_solver.cpp:165] Iteration 47000, lr = 0.01
I0819 00:30:38.248632  3083 solver.cpp:357] Iteration 47100 (2.91818 iter/s, 34.2679s/100 iters), loss = 0.0885819
I0819 00:30:38.248811  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.109655 (* 1 = 0.109655 loss)
I0819 00:30:38.248823  3083 sgd_solver.cpp:165] Iteration 47100, lr = 0.01
I0819 00:31:12.449337  3083 solver.cpp:357] Iteration 47200 (2.92396 iter/s, 34.2002s/100 iters), loss = 0.123903
I0819 00:31:12.449579  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.201279 (* 1 = 0.201279 loss)
I0819 00:31:12.449594  3083 sgd_solver.cpp:165] Iteration 47200, lr = 0.01
I0819 00:31:34.064699  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:31:46.702137  3083 solver.cpp:357] Iteration 47300 (2.91952 iter/s, 34.2522s/100 iters), loss = 0.0926673
I0819 00:31:46.702286  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.103826 (* 1 = 0.103826 loss)
I0819 00:31:46.702298  3083 sgd_solver.cpp:165] Iteration 47300, lr = 0.01
I0819 00:32:20.999981  3083 solver.cpp:357] Iteration 47400 (2.91568 iter/s, 34.2974s/100 iters), loss = 0.0841012
I0819 00:32:21.000190  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0884666 (* 1 = 0.0884666 loss)
I0819 00:32:21.000203  3083 sgd_solver.cpp:165] Iteration 47400, lr = 0.01
I0819 00:32:54.926448  3083 solver.cpp:514] Iteration 47500, Testing net (#0)
I0819 00:33:03.849233  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:33:03.881156  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.839601
I0819 00:33:03.881213  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.642753 (* 1 = 0.642753 loss)
I0819 00:33:04.221738  3083 solver.cpp:357] Iteration 47500 (2.31368 iter/s, 43.2212s/100 iters), loss = 0.0826129
I0819 00:33:04.221810  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0781463 (* 1 = 0.0781463 loss)
I0819 00:33:04.221822  3083 sgd_solver.cpp:165] Iteration 47500, lr = 0.01
I0819 00:33:38.622305  3083 solver.cpp:357] Iteration 47600 (2.90696 iter/s, 34.4002s/100 iters), loss = 0.089473
I0819 00:33:38.622514  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.110035 (* 1 = 0.110035 loss)
I0819 00:33:38.622529  3083 sgd_solver.cpp:165] Iteration 47600, lr = 0.01
I0819 00:33:56.952072  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:34:12.869067  3083 solver.cpp:357] Iteration 47700 (2.92003 iter/s, 34.2462s/100 iters), loss = 0.0730992
I0819 00:34:12.869241  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0617612 (* 1 = 0.0617612 loss)
I0819 00:34:12.869254  3083 sgd_solver.cpp:165] Iteration 47700, lr = 0.01
I0819 00:34:47.106001  3083 solver.cpp:357] Iteration 47800 (2.92086 iter/s, 34.2365s/100 iters), loss = 0.0763642
I0819 00:34:47.106173  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0961753 (* 1 = 0.0961753 loss)
I0819 00:34:47.106185  3083 sgd_solver.cpp:165] Iteration 47800, lr = 0.01
I0819 00:35:21.376451  3083 solver.cpp:357] Iteration 47900 (2.91801 iter/s, 34.27s/100 iters), loss = 0.075074
I0819 00:35:21.376624  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0995355 (* 1 = 0.0995355 loss)
I0819 00:35:21.376636  3083 sgd_solver.cpp:165] Iteration 47900, lr = 0.01
I0819 00:35:55.304364  3083 solver.cpp:514] Iteration 48000, Testing net (#0)
I0819 00:36:04.029199  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:36:04.061228  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.892902
I0819 00:36:04.061288  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.401162 (* 1 = 0.401162 loss)
I0819 00:36:04.397981  3083 solver.cpp:357] Iteration 48000 (2.32445 iter/s, 43.021s/100 iters), loss = 0.0643046
I0819 00:36:04.398062  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.103697 (* 1 = 0.103697 loss)
I0819 00:36:04.398072  3083 sgd_solver.cpp:64] MultiStep Status: Iteration 48000, step = 2
I0819 00:36:04.398079  3083 sgd_solver.cpp:165] Iteration 48000, lr = 0.001
I0819 00:36:19.515085  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:36:38.777113  3083 solver.cpp:357] Iteration 48100 (2.90877 iter/s, 34.3788s/100 iters), loss = 0.0992178
I0819 00:36:38.777251  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.135662 (* 1 = 0.135662 loss)
I0819 00:36:38.777261  3083 sgd_solver.cpp:165] Iteration 48100, lr = 0.001
I0819 00:37:13.207999  3083 solver.cpp:357] Iteration 48200 (2.90441 iter/s, 34.4305s/100 iters), loss = 0.0396558
I0819 00:37:13.208096  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0578086 (* 1 = 0.0578086 loss)
I0819 00:37:13.208107  3083 sgd_solver.cpp:165] Iteration 48200, lr = 0.001
I0819 00:37:47.570046  3083 solver.cpp:357] Iteration 48300 (2.91022 iter/s, 34.3616s/100 iters), loss = 0.0360155
I0819 00:37:47.570178  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0529307 (* 1 = 0.0529307 loss)
I0819 00:37:47.570190  3083 sgd_solver.cpp:165] Iteration 48300, lr = 0.001
I0819 00:38:21.935820  3083 solver.cpp:357] Iteration 48400 (2.90991 iter/s, 34.3653s/100 iters), loss = 0.0393287
I0819 00:38:21.935986  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0637417 (* 1 = 0.0637417 loss)
I0819 00:38:21.935998  3083 sgd_solver.cpp:165] Iteration 48400, lr = 0.001
I0819 00:38:33.775070  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:38:56.205343  3083 solver.cpp:514] Iteration 48500, Testing net (#0)
I0819 00:39:05.261905  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:39:05.297689  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.928502
I0819 00:39:05.297803  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.256285 (* 1 = 0.256285 loss)
I0819 00:39:05.642721  3083 solver.cpp:357] Iteration 48500 (2.288 iter/s, 43.7064s/100 iters), loss = 0.0158109
I0819 00:39:05.642913  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0135963 (* 1 = 0.0135963 loss)
I0819 00:39:05.642958  3083 sgd_solver.cpp:165] Iteration 48500, lr = 0.001
I0819 00:39:40.774719  3083 solver.cpp:357] Iteration 48600 (2.84668 iter/s, 35.1287s/100 iters), loss = 0.0234161
I0819 00:39:40.774991  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0235395 (* 1 = 0.0235395 loss)
I0819 00:39:40.775022  3083 sgd_solver.cpp:165] Iteration 48600, lr = 0.001
I0819 00:40:15.822059  3083 solver.cpp:357] Iteration 48700 (2.85333 iter/s, 35.0468s/100 iters), loss = 0.0289596
I0819 00:40:15.826805  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0117426 (* 1 = 0.0117426 loss)
I0819 00:40:15.826845  3083 sgd_solver.cpp:165] Iteration 48700, lr = 0.001
I0819 00:40:50.900774  3083 solver.cpp:357] Iteration 48800 (2.85097 iter/s, 35.0758s/100 iters), loss = 0.0553027
I0819 00:40:50.900982  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0310047 (* 1 = 0.0310047 loss)
I0819 00:40:50.901016  3083 sgd_solver.cpp:165] Iteration 48800, lr = 0.001
I0819 00:40:59.830188  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:41:25.958387  3083 solver.cpp:357] Iteration 48900 (2.85224 iter/s, 35.0602s/100 iters), loss = 0.0512371
I0819 00:41:25.962791  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0734233 (* 1 = 0.0734233 loss)
I0819 00:41:25.962828  3083 sgd_solver.cpp:165] Iteration 48900, lr = 0.001
I0819 00:42:00.578440  3083 solver.cpp:514] Iteration 49000, Testing net (#0)
I0819 00:42:09.703281  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:42:09.738193  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.930303
I0819 00:42:09.738313  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.255688 (* 1 = 0.255688 loss)
I0819 00:42:10.078172  3083 solver.cpp:357] Iteration 49000 (2.26661 iter/s, 44.1187s/100 iters), loss = 0.0316553
I0819 00:42:10.078300  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0200859 (* 1 = 0.0200859 loss)
I0819 00:42:10.078327  3083 sgd_solver.cpp:165] Iteration 49000, lr = 0.001
I0819 00:42:45.084524  3083 solver.cpp:357] Iteration 49100 (2.85644 iter/s, 35.0086s/100 iters), loss = 0.0322337
I0819 00:42:45.086812  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0540795 (* 1 = 0.0540795 loss)
I0819 00:42:45.086851  3083 sgd_solver.cpp:165] Iteration 49100, lr = 0.001
I0819 00:43:22.944629  3083 solver.cpp:357] Iteration 49200 (2.64129 iter/s, 37.8603s/100 iters), loss = 0.0167417
I0819 00:43:22.944772  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0293616 (* 1 = 0.0293616 loss)
I0819 00:43:22.944785  3083 sgd_solver.cpp:165] Iteration 49200, lr = 0.001
I0819 00:43:28.439724  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:43:57.943898  3083 solver.cpp:357] Iteration 49300 (2.85705 iter/s, 35.0012s/100 iters), loss = 0.0606586
I0819 00:43:57.946784  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0994796 (* 1 = 0.0994796 loss)
I0819 00:43:57.946817  3083 sgd_solver.cpp:165] Iteration 49300, lr = 0.001
I0819 00:44:50.851039  3083 solver.cpp:357] Iteration 49400 (1.8901 iter/s, 52.9072s/100 iters), loss = 0.0125525
I0819 00:44:50.851282  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00565764 (* 1 = 0.00565764 loss)
I0819 00:44:50.851322  3083 sgd_solver.cpp:165] Iteration 49400, lr = 0.001
I0819 00:46:03.974479  3083 solver.cpp:514] Iteration 49500, Testing net (#0)
I0819 00:46:48.849027  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:46:49.073019  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.928202
I0819 00:46:49.073139  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.264213 (* 1 = 0.264213 loss)
I0819 00:46:49.800889  3083 solver.cpp:357] Iteration 49500 (0.840653 iter/s, 118.955s/100 iters), loss = 0.0237268
I0819 00:46:49.801072  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.015313 (* 1 = 0.015313 loss)
I0819 00:46:49.801117  3083 sgd_solver.cpp:165] Iteration 49500, lr = 0.001
I0819 00:48:01.382361  3083 solver.cpp:357] Iteration 49600 (1.39696 iter/s, 71.5841s/100 iters), loss = 0.0143478
I0819 00:48:01.386044  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0155092 (* 1 = 0.0155092 loss)
I0819 00:48:01.386093  3083 sgd_solver.cpp:165] Iteration 49600, lr = 0.001
I0819 00:48:06.563786  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:49:17.346360  3083 solver.cpp:357] Iteration 49700 (1.31644 iter/s, 75.9623s/100 iters), loss = 0.0149851
I0819 00:49:17.350944  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00419365 (* 1 = 0.00419365 loss)
I0819 00:49:17.351070  3083 sgd_solver.cpp:165] Iteration 49700, lr = 0.001
I0819 00:50:28.840121  3083 solver.cpp:357] Iteration 49800 (1.3988 iter/s, 71.49s/100 iters), loss = 0.0218724
I0819 00:50:28.840423  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0217332 (* 1 = 0.0217332 loss)
I0819 00:50:28.840451  3083 sgd_solver.cpp:165] Iteration 49800, lr = 0.001
I0819 00:51:41.275032  3083 solver.cpp:357] Iteration 49900 (1.38052 iter/s, 72.4365s/100 iters), loss = 0.033211
I0819 00:51:41.278792  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0206407 (* 1 = 0.0206407 loss)
I0819 00:51:41.278828  3083 sgd_solver.cpp:165] Iteration 49900, lr = 0.001
I0819 00:52:51.925904  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:52:53.625711  3083 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_56_iter_50000.caffemodel
I0819 00:52:53.657673  3083 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_56_iter_50000.solverstate
I0819 00:52:53.667603  3083 solver.cpp:514] Iteration 50000, Testing net (#0)
I0819 00:53:40.579632  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:53:40.811033  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.929702
I0819 00:53:40.811154  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.262371 (* 1 = 0.262371 loss)
I0819 00:53:41.388577  3083 solver.cpp:357] Iteration 50000 (0.832557 iter/s, 120.112s/100 iters), loss = 0.0151748
I0819 00:53:41.388718  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0191742 (* 1 = 0.0191742 loss)
I0819 00:53:41.388746  3083 sgd_solver.cpp:165] Iteration 50000, lr = 0.001
I0819 00:54:54.032529  3083 solver.cpp:357] Iteration 50100 (1.37655 iter/s, 72.6451s/100 iters), loss = 0.0494594
I0819 00:54:54.032807  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.061588 (* 1 = 0.061588 loss)
I0819 00:54:54.032866  3083 sgd_solver.cpp:165] Iteration 50100, lr = 0.001
I0819 00:56:06.678618  3083 solver.cpp:357] Iteration 50200 (1.37652 iter/s, 72.647s/100 iters), loss = 0.0182838
I0819 00:56:06.678757  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0171498 (* 1 = 0.0171498 loss)
I0819 00:56:06.678771  3083 sgd_solver.cpp:165] Iteration 50200, lr = 0.001
I0819 00:57:19.635236  3083 solver.cpp:357] Iteration 50300 (1.3707 iter/s, 72.9555s/100 iters), loss = 0.0126412
I0819 00:57:19.635421  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0213911 (* 1 = 0.0213911 loss)
I0819 00:57:19.635450  3083 sgd_solver.cpp:165] Iteration 50300, lr = 0.001
I0819 00:58:26.298787  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 00:58:35.261606  3083 solver.cpp:357] Iteration 50400 (1.32228 iter/s, 75.6271s/100 iters), loss = 0.0101344
I0819 00:58:35.261679  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0131236 (* 1 = 0.0131236 loss)
I0819 00:58:35.261692  3083 sgd_solver.cpp:165] Iteration 50400, lr = 0.001
I0819 00:59:47.230787  3083 solver.cpp:514] Iteration 50500, Testing net (#0)
I0819 01:00:32.232003  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:00:32.461236  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.930702
I0819 01:00:32.461292  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.267561 (* 1 = 0.267561 loss)
I0819 01:00:33.198076  3083 solver.cpp:357] Iteration 50500 (0.847905 iter/s, 117.938s/100 iters), loss = 0.0140112
I0819 01:00:33.198149  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0114149 (* 1 = 0.0114149 loss)
I0819 01:00:33.198163  3083 sgd_solver.cpp:165] Iteration 50500, lr = 0.001
I0819 01:01:45.707319  3083 solver.cpp:357] Iteration 50600 (1.37916 iter/s, 72.5077s/100 iters), loss = 0.0100094
I0819 01:01:45.707535  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00933737 (* 1 = 0.00933737 loss)
I0819 01:01:45.707563  3083 sgd_solver.cpp:165] Iteration 50600, lr = 0.001
I0819 01:02:58.148960  3083 solver.cpp:357] Iteration 50700 (1.38041 iter/s, 72.442s/100 iters), loss = 0.0102483
I0819 01:02:58.149179  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00755955 (* 1 = 0.00755955 loss)
I0819 01:02:58.149195  3083 sgd_solver.cpp:165] Iteration 50700, lr = 0.001
I0819 01:03:55.138520  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:04:10.501540  3083 solver.cpp:357] Iteration 50800 (1.38215 iter/s, 72.351s/100 iters), loss = 0.0202037
I0819 01:04:10.501646  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0089822 (* 1 = 0.0089822 loss)
I0819 01:04:10.501662  3083 sgd_solver.cpp:165] Iteration 50800, lr = 0.001
I0819 01:05:22.871129  3083 solver.cpp:357] Iteration 50900 (1.38183 iter/s, 72.3679s/100 iters), loss = 0.0380612
I0819 01:05:22.871392  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0499955 (* 1 = 0.0499955 loss)
I0819 01:05:22.871425  3083 sgd_solver.cpp:165] Iteration 50900, lr = 0.001
I0819 01:06:34.800622  3083 solver.cpp:514] Iteration 51000, Testing net (#0)
I0819 01:07:22.306365  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:07:22.442909  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.931902
I0819 01:07:22.442968  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.273366 (* 1 = 0.273366 loss)
I0819 01:07:23.067210  3083 solver.cpp:357] Iteration 51000 (0.831984 iter/s, 120.195s/100 iters), loss = 0.0238357
I0819 01:07:23.067303  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0104967 (* 1 = 0.0104967 loss)
I0819 01:07:23.067317  3083 sgd_solver.cpp:165] Iteration 51000, lr = 0.001
I0819 01:08:35.898069  3083 solver.cpp:357] Iteration 51100 (1.37308 iter/s, 72.8291s/100 iters), loss = 0.00340183
I0819 01:08:35.898195  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00296605 (* 1 = 0.00296605 loss)
I0819 01:08:35.898208  3083 sgd_solver.cpp:165] Iteration 51100, lr = 0.001
I0819 01:09:25.954335  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:09:48.403628  3083 solver.cpp:357] Iteration 51200 (1.37924 iter/s, 72.5037s/100 iters), loss = 0.0246184
I0819 01:09:48.403709  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0441503 (* 1 = 0.0441503 loss)
I0819 01:09:48.403722  3083 sgd_solver.cpp:165] Iteration 51200, lr = 0.001
I0819 01:11:02.385027  3083 solver.cpp:357] Iteration 51300 (1.35172 iter/s, 73.9796s/100 iters), loss = 0.0178607
I0819 01:11:02.385177  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0181941 (* 1 = 0.0181941 loss)
I0819 01:11:02.385190  3083 sgd_solver.cpp:165] Iteration 51300, lr = 0.001
I0819 01:12:17.428741  3083 solver.cpp:357] Iteration 51400 (1.33255 iter/s, 75.0439s/100 iters), loss = 0.0293959
I0819 01:12:17.428871  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0388943 (* 1 = 0.0388943 loss)
I0819 01:12:17.428884  3083 sgd_solver.cpp:165] Iteration 51400, lr = 0.001
I0819 01:13:29.429816  3083 solver.cpp:514] Iteration 51500, Testing net (#0)
I0819 01:14:14.785545  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:14:14.992084  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.929402
I0819 01:14:14.992139  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.278331 (* 1 = 0.278331 loss)
I0819 01:14:15.511479  3083 solver.cpp:357] Iteration 51500 (0.846876 iter/s, 118.081s/100 iters), loss = 0.0191236
I0819 01:14:15.511545  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00300049 (* 1 = 0.00300049 loss)
I0819 01:14:15.511556  3083 sgd_solver.cpp:165] Iteration 51500, lr = 0.001
I0819 01:14:58.656441  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:15:27.798707  3083 solver.cpp:357] Iteration 51600 (1.38327 iter/s, 72.2926s/100 iters), loss = 0.0236841
I0819 01:15:27.798781  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0386301 (* 1 = 0.0386301 loss)
I0819 01:15:27.798794  3083 sgd_solver.cpp:165] Iteration 51600, lr = 0.001
I0819 01:16:40.543283  3083 solver.cpp:357] Iteration 51700 (1.37458 iter/s, 72.7494s/100 iters), loss = 0.0288285
I0819 01:16:40.543442  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0270868 (* 1 = 0.0270868 loss)
I0819 01:16:40.543454  3083 sgd_solver.cpp:165] Iteration 51700, lr = 0.001
I0819 01:17:53.336612  3083 solver.cpp:357] Iteration 51800 (1.37367 iter/s, 72.7974s/100 iters), loss = 0.0217739
I0819 01:17:53.336773  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0281717 (* 1 = 0.0281717 loss)
I0819 01:17:53.336784  3083 sgd_solver.cpp:165] Iteration 51800, lr = 0.001
I0819 01:19:06.139715  3083 solver.cpp:357] Iteration 51900 (1.37346 iter/s, 72.8086s/100 iters), loss = 0.0172387
I0819 01:19:06.139833  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0202884 (* 1 = 0.0202884 loss)
I0819 01:19:06.139847  3083 sgd_solver.cpp:165] Iteration 51900, lr = 0.001
I0819 01:19:42.845320  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:20:17.706312  3083 solver.cpp:514] Iteration 52000, Testing net (#0)
I0819 01:21:03.355660  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:21:03.476967  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.932302
I0819 01:21:03.477030  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.271576 (* 1 = 0.271576 loss)
I0819 01:21:04.210278  3083 solver.cpp:357] Iteration 52000 (0.846909 iter/s, 118.076s/100 iters), loss = 0.00828543
I0819 01:21:04.210356  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00754442 (* 1 = 0.00754442 loss)
I0819 01:21:04.210369  3083 sgd_solver.cpp:165] Iteration 52000, lr = 0.001
I0819 01:22:16.970197  3083 solver.cpp:357] Iteration 52100 (1.37434 iter/s, 72.7621s/100 iters), loss = 0.00611239
I0819 01:22:16.970337  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00483342 (* 1 = 0.00483342 loss)
I0819 01:22:16.970350  3083 sgd_solver.cpp:165] Iteration 52100, lr = 0.001
I0819 01:23:29.673359  3083 solver.cpp:357] Iteration 52200 (1.37542 iter/s, 72.7049s/100 iters), loss = 0.0471539
I0819 01:23:29.673508  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0684274 (* 1 = 0.0684274 loss)
I0819 01:23:29.673521  3083 sgd_solver.cpp:165] Iteration 52200, lr = 0.001
I0819 01:24:44.852836  3083 solver.cpp:357] Iteration 52300 (1.33009 iter/s, 75.183s/100 iters), loss = 0.0192744
I0819 01:24:44.853008  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0291992 (* 1 = 0.0291992 loss)
I0819 01:24:44.853021  3083 sgd_solver.cpp:165] Iteration 52300, lr = 0.001
I0819 01:25:15.993930  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:25:59.159768  3083 solver.cpp:357] Iteration 52400 (1.34575 iter/s, 74.3082s/100 iters), loss = 0.0109505
I0819 01:25:59.159924  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0166819 (* 1 = 0.0166819 loss)
I0819 01:25:59.159934  3083 sgd_solver.cpp:165] Iteration 52400, lr = 0.001
I0819 01:27:11.120769  3083 solver.cpp:514] Iteration 52500, Testing net (#0)
I0819 01:27:56.039108  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:27:56.269116  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.933002
I0819 01:27:56.269170  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.276012 (* 1 = 0.276012 loss)
I0819 01:27:56.998100  3083 solver.cpp:357] Iteration 52500 (0.848587 iter/s, 117.843s/100 iters), loss = 0.051407
I0819 01:27:56.998172  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0154697 (* 1 = 0.0154697 loss)
I0819 01:27:56.998183  3083 sgd_solver.cpp:165] Iteration 52500, lr = 0.001
I0819 01:29:09.256376  3083 solver.cpp:357] Iteration 52600 (1.38391 iter/s, 72.2588s/100 iters), loss = 0.00935321
I0819 01:29:09.256553  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0083683 (* 1 = 0.0083683 loss)
I0819 01:29:09.256567  3083 sgd_solver.cpp:165] Iteration 52600, lr = 0.001
I0819 01:30:21.738057  3083 solver.cpp:357] Iteration 52700 (1.37965 iter/s, 72.4821s/100 iters), loss = 0.0116035
I0819 01:30:21.738167  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00676121 (* 1 = 0.00676121 loss)
I0819 01:30:21.738178  3083 sgd_solver.cpp:165] Iteration 52700, lr = 0.001
I0819 01:30:44.645627  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:31:34.223016  3083 solver.cpp:357] Iteration 52800 (1.37955 iter/s, 72.4872s/100 iters), loss = 0.018062
I0819 01:31:34.223156  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0180646 (* 1 = 0.0180646 loss)
I0819 01:31:34.223168  3083 sgd_solver.cpp:165] Iteration 52800, lr = 0.001
I0819 01:32:46.616158  3083 solver.cpp:357] Iteration 52900 (1.38134 iter/s, 72.3932s/100 iters), loss = 0.0180835
I0819 01:32:46.616281  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00897841 (* 1 = 0.00897841 loss)
I0819 01:32:46.616292  3083 sgd_solver.cpp:165] Iteration 52900, lr = 0.001
I0819 01:33:58.413697  3083 solver.cpp:514] Iteration 53000, Testing net (#0)
I0819 01:34:44.153292  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:34:44.219182  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.930802
I0819 01:34:44.219226  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.285521 (* 1 = 0.285521 loss)
I0819 01:34:44.847528  3083 solver.cpp:357] Iteration 53000 (0.84579 iter/s, 118.233s/100 iters), loss = 0.00661166
I0819 01:34:44.847604  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00703435 (* 1 = 0.00703435 loss)
I0819 01:34:44.847616  3083 sgd_solver.cpp:165] Iteration 53000, lr = 0.001
I0819 01:35:57.466822  3083 solver.cpp:357] Iteration 53100 (1.37705 iter/s, 72.6191s/100 iters), loss = 0.0188916
I0819 01:35:57.466977  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00690517 (* 1 = 0.00690517 loss)
I0819 01:35:57.466990  3083 sgd_solver.cpp:165] Iteration 53100, lr = 0.001
I0819 01:36:13.570472  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:37:10.021378  3083 solver.cpp:357] Iteration 53200 (1.37828 iter/s, 72.5543s/100 iters), loss = 0.0253524
I0819 01:37:10.021538  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00582651 (* 1 = 0.00582651 loss)
I0819 01:37:10.021553  3083 sgd_solver.cpp:165] Iteration 53200, lr = 0.001
I0819 01:38:25.638540  3083 solver.cpp:357] Iteration 53300 (1.32245 iter/s, 75.6169s/100 iters), loss = 0.0189617
I0819 01:38:25.638670  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0102453 (* 1 = 0.0102453 loss)
I0819 01:38:25.638684  3083 sgd_solver.cpp:165] Iteration 53300, lr = 0.001
I0819 01:39:38.915082  3083 solver.cpp:357] Iteration 53400 (1.36466 iter/s, 73.2782s/100 iters), loss = 0.00752898
I0819 01:39:38.915379  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00501589 (* 1 = 0.00501589 loss)
I0819 01:39:38.915439  3083 sgd_solver.cpp:165] Iteration 53400, lr = 0.001
I0819 01:40:50.848306  3083 solver.cpp:514] Iteration 53500, Testing net (#0)
I0819 01:41:36.437409  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:41:36.549969  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.932103
I0819 01:41:36.550014  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.279787 (* 1 = 0.279787 loss)
I0819 01:41:37.083464  3083 solver.cpp:357] Iteration 53500 (0.846232 iter/s, 118.171s/100 iters), loss = 0.00503602
I0819 01:41:37.083537  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00544052 (* 1 = 0.00544052 loss)
I0819 01:41:37.083549  3083 sgd_solver.cpp:165] Iteration 53500, lr = 0.001
I0819 01:41:46.694941  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:42:49.503360  3083 solver.cpp:357] Iteration 53600 (1.38085 iter/s, 72.4194s/100 iters), loss = 0.0102193
I0819 01:42:49.503574  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00591375 (* 1 = 0.00591375 loss)
I0819 01:42:49.503592  3083 sgd_solver.cpp:165] Iteration 53600, lr = 0.001
I0819 01:44:01.800220  3083 solver.cpp:357] Iteration 53700 (1.3832 iter/s, 72.2963s/100 iters), loss = 0.0244584
I0819 01:44:01.800330  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0378236 (* 1 = 0.0378236 loss)
I0819 01:44:01.800349  3083 sgd_solver.cpp:165] Iteration 53700, lr = 0.001
I0819 01:45:14.260018  3083 solver.cpp:357] Iteration 53800 (1.38009 iter/s, 72.4592s/100 iters), loss = 0.015068
I0819 01:45:14.260205  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0282573 (* 1 = 0.0282573 loss)
I0819 01:45:14.260218  3083 sgd_solver.cpp:165] Iteration 53800, lr = 0.001
I0819 01:46:26.679484  3083 solver.cpp:357] Iteration 53900 (1.38086 iter/s, 72.4189s/100 iters), loss = 0.00488623
I0819 01:46:26.679613  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0046382 (* 1 = 0.0046382 loss)
I0819 01:46:26.679626  3083 sgd_solver.cpp:165] Iteration 53900, lr = 0.001
I0819 01:46:29.240046  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:47:38.155913  3083 solver.cpp:514] Iteration 54000, Testing net (#0)
I0819 01:48:23.323213  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:48:23.535737  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.933902
I0819 01:48:23.535789  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.27643 (* 1 = 0.27643 loss)
I0819 01:48:24.038514  3083 solver.cpp:357] Iteration 54000 (0.852083 iter/s, 117.359s/100 iters), loss = 0.00464838
I0819 01:48:24.038579  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00252212 (* 1 = 0.00252212 loss)
I0819 01:48:24.038591  3083 sgd_solver.cpp:165] Iteration 54000, lr = 0.001
I0819 01:49:36.295038  3083 solver.cpp:357] Iteration 54100 (1.38386 iter/s, 72.2619s/100 iters), loss = 0.0148685
I0819 01:49:36.295166  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00461058 (* 1 = 0.00461058 loss)
I0819 01:49:36.295178  3083 sgd_solver.cpp:165] Iteration 54100, lr = 0.001
I0819 01:50:49.629539  3083 solver.cpp:357] Iteration 54200 (1.36353 iter/s, 73.339s/100 iters), loss = 0.00769824
I0819 01:50:49.629658  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00837922 (* 1 = 0.00837922 loss)
I0819 01:50:49.629671  3083 sgd_solver.cpp:165] Iteration 54200, lr = 0.001
I0819 01:52:01.058554  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:52:05.284322  3083 solver.cpp:357] Iteration 54300 (1.32171 iter/s, 75.6593s/100 iters), loss = 0.012567
I0819 01:52:05.284404  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00637414 (* 1 = 0.00637414 loss)
I0819 01:52:05.284416  3083 sgd_solver.cpp:165] Iteration 54300, lr = 0.001
I0819 01:53:18.030908  3083 solver.cpp:357] Iteration 54400 (1.37457 iter/s, 72.75s/100 iters), loss = 0.00579404
I0819 01:53:18.031055  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00539077 (* 1 = 0.00539077 loss)
I0819 01:53:18.031069  3083 sgd_solver.cpp:165] Iteration 54400, lr = 0.001
I0819 01:54:30.090638  3083 solver.cpp:514] Iteration 54500, Testing net (#0)
I0819 01:55:15.330693  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:55:15.547783  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.931702
I0819 01:55:15.547840  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.289716 (* 1 = 0.289716 loss)
I0819 01:55:16.276163  3083 solver.cpp:357] Iteration 54500 (0.845657 iter/s, 118.251s/100 iters), loss = 0.00706042
I0819 01:55:16.276237  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0124123 (* 1 = 0.0124123 loss)
I0819 01:55:16.276250  3083 sgd_solver.cpp:165] Iteration 54500, lr = 0.001
I0819 01:56:28.708580  3083 solver.cpp:357] Iteration 54600 (1.38055 iter/s, 72.4348s/100 iters), loss = 0.00214428
I0819 01:56:28.708731  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.000968947 (* 1 = 0.000968947 loss)
I0819 01:56:28.708745  3083 sgd_solver.cpp:165] Iteration 54600, lr = 0.001
I0819 01:57:29.844806  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 01:57:41.076162  3083 solver.cpp:357] Iteration 54700 (1.38179 iter/s, 72.3697s/100 iters), loss = 0.00923275
I0819 01:57:41.076238  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00757937 (* 1 = 0.00757937 loss)
I0819 01:57:41.076251  3083 sgd_solver.cpp:165] Iteration 54700, lr = 0.001
I0819 01:58:53.437822  3083 solver.cpp:357] Iteration 54800 (1.38191 iter/s, 72.3635s/100 iters), loss = 0.00596696
I0819 01:58:53.437970  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00467298 (* 1 = 0.00467298 loss)
I0819 01:58:53.437984  3083 sgd_solver.cpp:165] Iteration 54800, lr = 0.001
I0819 02:00:05.983340  3083 solver.cpp:357] Iteration 54900 (1.37841 iter/s, 72.5472s/100 iters), loss = 0.0114232
I0819 02:00:05.983458  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00570788 (* 1 = 0.00570788 loss)
I0819 02:00:05.983469  3083 sgd_solver.cpp:165] Iteration 54900, lr = 0.001
I0819 02:01:17.954484  3083 solver.cpp:514] Iteration 55000, Testing net (#0)
I0819 02:02:03.285766  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:02:03.495765  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.931503
I0819 02:02:03.495821  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.287843 (* 1 = 0.287843 loss)
I0819 02:02:04.037258  3083 solver.cpp:357] Iteration 55000 (0.84703 iter/s, 118.06s/100 iters), loss = 0.00717411
I0819 02:02:04.037320  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00211297 (* 1 = 0.00211297 loss)
I0819 02:02:04.037331  3083 sgd_solver.cpp:165] Iteration 55000, lr = 0.001
I0819 02:02:58.751132  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:03:16.324442  3083 solver.cpp:357] Iteration 55100 (1.38331 iter/s, 72.2904s/100 iters), loss = 0.0118327
I0819 02:03:16.324522  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0169897 (* 1 = 0.0169897 loss)
I0819 02:03:16.324534  3083 sgd_solver.cpp:165] Iteration 55100, lr = 0.001
I0819 02:04:30.890712  3083 solver.cpp:357] Iteration 55200 (1.34107 iter/s, 74.5674s/100 iters), loss = 0.00699997
I0819 02:04:30.890842  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00658356 (* 1 = 0.00658356 loss)
I0819 02:04:30.890854  3083 sgd_solver.cpp:165] Iteration 55200, lr = 0.001
I0819 02:05:45.830970  3083 solver.cpp:357] Iteration 55300 (1.33434 iter/s, 74.9433s/100 iters), loss = 0.00824156
I0819 02:05:45.831120  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00835341 (* 1 = 0.00835341 loss)
I0819 02:05:45.831130  3083 sgd_solver.cpp:165] Iteration 55300, lr = 0.001
I0819 02:06:58.100270  3083 solver.cpp:357] Iteration 55400 (1.38366 iter/s, 72.2721s/100 iters), loss = 0.00184111
I0819 02:06:58.100453  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0022965 (* 1 = 0.0022965 loss)
I0819 02:06:58.100467  3083 sgd_solver.cpp:165] Iteration 55400, lr = 0.001
I0819 02:07:45.760740  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:08:09.705871  3083 solver.cpp:514] Iteration 55500, Testing net (#0)
I0819 02:08:54.617245  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:08:54.829668  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.932103
I0819 02:08:54.829720  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.289387 (* 1 = 0.289387 loss)
I0819 02:08:55.565680  3083 solver.cpp:357] Iteration 55500 (0.851296 iter/s, 117.468s/100 iters), loss = 0.0071942
I0819 02:08:55.565753  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0105779 (* 1 = 0.0105779 loss)
I0819 02:08:55.565766  3083 sgd_solver.cpp:165] Iteration 55500, lr = 0.001
I0819 02:10:07.695773  3083 solver.cpp:357] Iteration 55600 (1.38637 iter/s, 72.1307s/100 iters), loss = 0.00366311
I0819 02:10:07.695947  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00306569 (* 1 = 0.00306569 loss)
I0819 02:10:07.695960  3083 sgd_solver.cpp:165] Iteration 55600, lr = 0.001
I0819 02:11:20.017356  3083 solver.cpp:357] Iteration 55700 (1.3827 iter/s, 72.3222s/100 iters), loss = 0.0621789
I0819 02:11:20.017508  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00446448 (* 1 = 0.00446448 loss)
I0819 02:11:20.017520  3083 sgd_solver.cpp:165] Iteration 55700, lr = 0.001
I0819 02:12:32.135354  3083 solver.cpp:357] Iteration 55800 (1.38657 iter/s, 72.1205s/100 iters), loss = 0.00393562
I0819 02:12:32.135481  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00512551 (* 1 = 0.00512551 loss)
I0819 02:12:32.135495  3083 sgd_solver.cpp:165] Iteration 55800, lr = 0.001
I0819 02:13:13.087357  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:13:44.682559  3083 solver.cpp:357] Iteration 55900 (1.3784 iter/s, 72.5477s/100 iters), loss = 0.028821
I0819 02:13:44.682693  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0113381 (* 1 = 0.0113381 loss)
I0819 02:13:44.682705  3083 sgd_solver.cpp:165] Iteration 55900, lr = 0.001
I0819 02:14:56.453356  3083 solver.cpp:514] Iteration 56000, Testing net (#0)
I0819 02:15:41.574638  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:15:41.787690  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.930602
I0819 02:15:41.787745  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.288603 (* 1 = 0.288603 loss)
I0819 02:15:42.325934  3083 solver.cpp:357] Iteration 56000 (0.850012 iter/s, 117.645s/100 iters), loss = 0.00943854
I0819 02:15:42.325995  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00575892 (* 1 = 0.00575892 loss)
I0819 02:15:42.326006  3083 sgd_solver.cpp:165] Iteration 56000, lr = 0.001
I0819 02:16:55.135298  3083 solver.cpp:357] Iteration 56100 (1.3734 iter/s, 72.8118s/100 iters), loss = 0.00352036
I0819 02:16:55.135478  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.001596 (* 1 = 0.001596 loss)
I0819 02:16:55.135491  3083 sgd_solver.cpp:165] Iteration 56100, lr = 0.001
I0819 02:18:10.081688  3083 solver.cpp:357] Iteration 56200 (1.33428 iter/s, 74.9469s/100 iters), loss = 0.00195336
I0819 02:18:10.081851  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00222209 (* 1 = 0.00222209 loss)
I0819 02:18:10.081862  3083 sgd_solver.cpp:165] Iteration 56200, lr = 0.001
I0819 02:18:45.565806  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:19:24.251997  3083 solver.cpp:357] Iteration 56300 (1.34824 iter/s, 74.1707s/100 iters), loss = 0.00441967
I0819 02:19:24.252144  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00498047 (* 1 = 0.00498047 loss)
I0819 02:19:24.252156  3083 sgd_solver.cpp:165] Iteration 56300, lr = 0.001
I0819 02:20:36.840665  3083 solver.cpp:357] Iteration 56400 (1.37758 iter/s, 72.591s/100 iters), loss = 0.0441711
I0819 02:20:36.840811  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00767258 (* 1 = 0.00767258 loss)
I0819 02:20:36.840823  3083 sgd_solver.cpp:165] Iteration 56400, lr = 0.001
I0819 02:21:48.839059  3083 solver.cpp:514] Iteration 56500, Testing net (#0)
I0819 02:22:33.989832  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:22:34.204454  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.931803
I0819 02:22:34.204506  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.29009 (* 1 = 0.29009 loss)
I0819 02:22:34.939321  3083 solver.cpp:357] Iteration 56500 (0.846722 iter/s, 118.103s/100 iters), loss = 0.0105258
I0819 02:22:34.939395  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00400567 (* 1 = 0.00400567 loss)
I0819 02:22:34.939409  3083 sgd_solver.cpp:165] Iteration 56500, lr = 0.001
I0819 02:23:47.356071  3083 solver.cpp:357] Iteration 56600 (1.38103 iter/s, 72.4095s/100 iters), loss = 0.00834915
I0819 02:23:47.356253  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00506312 (* 1 = 0.00506312 loss)
I0819 02:23:47.356266  3083 sgd_solver.cpp:165] Iteration 56600, lr = 0.001
I0819 02:24:14.924543  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:24:59.740371  3083 solver.cpp:357] Iteration 56700 (1.38168 iter/s, 72.3754s/100 iters), loss = 0.0115438
I0819 02:24:59.740550  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00738358 (* 1 = 0.00738358 loss)
I0819 02:24:59.740561  3083 sgd_solver.cpp:165] Iteration 56700, lr = 0.001
I0819 02:26:11.990285  3083 solver.cpp:357] Iteration 56800 (1.38423 iter/s, 72.2421s/100 iters), loss = 0.00666699
I0819 02:26:11.990620  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00346386 (* 1 = 0.00346386 loss)
I0819 02:26:11.990738  3083 sgd_solver.cpp:165] Iteration 56800, lr = 0.001
I0819 02:27:24.466434  3083 solver.cpp:357] Iteration 56900 (1.3799 iter/s, 72.4692s/100 iters), loss = 0.0102796
I0819 02:27:24.466614  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0103495 (* 1 = 0.0103495 loss)
I0819 02:27:24.466626  3083 sgd_solver.cpp:165] Iteration 56900, lr = 0.001
I0819 02:28:36.393199  3083 solver.cpp:514] Iteration 57000, Testing net (#0)
I0819 02:29:22.069898  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:29:22.134315  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.931503
I0819 02:29:22.134369  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.294168 (* 1 = 0.294168 loss)
I0819 02:29:22.807828  3083 solver.cpp:357] Iteration 57000 (0.845072 iter/s, 118.333s/100 iters), loss = 0.00474498
I0819 02:29:22.807904  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00832388 (* 1 = 0.00832388 loss)
I0819 02:29:22.807915  3083 sgd_solver.cpp:165] Iteration 57000, lr = 0.001
I0819 02:29:43.685304  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:30:35.571744  3083 solver.cpp:357] Iteration 57100 (1.3744 iter/s, 72.7588s/100 iters), loss = 0.00293164
I0819 02:30:35.571921  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0022942 (* 1 = 0.0022942 loss)
I0819 02:30:35.571934  3083 sgd_solver.cpp:165] Iteration 57100, lr = 0.001
I0819 02:31:51.260903  3083 solver.cpp:357] Iteration 57200 (1.32127 iter/s, 75.6845s/100 iters), loss = 0.00256831
I0819 02:31:51.261034  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00269566 (* 1 = 0.00269566 loss)
I0819 02:31:51.261046  3083 sgd_solver.cpp:165] Iteration 57200, lr = 0.001
I0819 02:33:04.183553  3083 solver.cpp:357] Iteration 57300 (1.37139 iter/s, 72.9186s/100 iters), loss = 0.00879147
I0819 02:33:04.183684  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0141345 (* 1 = 0.0141345 loss)
I0819 02:33:04.183697  3083 sgd_solver.cpp:165] Iteration 57300, lr = 0.001
I0819 02:34:16.728858  3083 solver.cpp:357] Iteration 57400 (1.37852 iter/s, 72.5417s/100 iters), loss = 0.00700611
I0819 02:34:16.729008  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0111653 (* 1 = 0.0111653 loss)
I0819 02:34:16.729019  3083 sgd_solver.cpp:165] Iteration 57400, lr = 0.001
I0819 02:34:30.831483  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:35:28.806097  3083 solver.cpp:514] Iteration 57500, Testing net (#0)
I0819 02:36:14.465728  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:36:14.533298  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.932402
I0819 02:36:14.533351  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.293807 (* 1 = 0.293807 loss)
I0819 02:36:15.263427  3083 solver.cpp:357] Iteration 57500 (0.843649 iter/s, 118.533s/100 iters), loss = 0.00435333
I0819 02:36:15.263504  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00374425 (* 1 = 0.00374425 loss)
I0819 02:36:15.263516  3083 sgd_solver.cpp:165] Iteration 57500, lr = 0.001
I0819 02:37:27.631187  3083 solver.cpp:357] Iteration 57600 (1.38189 iter/s, 72.3649s/100 iters), loss = 0.00977747
I0819 02:37:27.631352  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0064979 (* 1 = 0.0064979 loss)
I0819 02:37:27.631366  3083 sgd_solver.cpp:165] Iteration 57600, lr = 0.001
I0819 02:38:40.085273  3083 solver.cpp:357] Iteration 57700 (1.38023 iter/s, 72.4515s/100 iters), loss = 0.00532719
I0819 02:38:40.085378  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00593979 (* 1 = 0.00593979 loss)
I0819 02:38:40.085389  3083 sgd_solver.cpp:165] Iteration 57700, lr = 0.001
I0819 02:39:52.817786  3083 solver.cpp:357] Iteration 57800 (1.37491 iter/s, 72.7322s/100 iters), loss = 0.00311473
I0819 02:39:52.817953  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00386956 (* 1 = 0.00386956 loss)
I0819 02:39:52.817966  3083 sgd_solver.cpp:165] Iteration 57800, lr = 0.001
I0819 02:39:59.698194  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:41:05.292299  3083 solver.cpp:357] Iteration 57900 (1.37984 iter/s, 72.4723s/100 iters), loss = 0.00186578
I0819 02:41:05.292418  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00165277 (* 1 = 0.00165277 loss)
I0819 02:41:05.292433  3083 sgd_solver.cpp:165] Iteration 57900, lr = 0.001
I0819 02:42:16.826711  3083 solver.cpp:514] Iteration 58000, Testing net (#0)
I0819 02:43:02.254940  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:43:02.320015  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.932002
I0819 02:43:02.320058  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.293696 (* 1 = 0.293696 loss)
I0819 02:43:02.899350  3083 solver.cpp:357] Iteration 58000 (0.850303 iter/s, 117.605s/100 iters), loss = 0.0099673
I0819 02:43:02.899425  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00148069 (* 1 = 0.00148069 loss)
I0819 02:43:02.899436  3083 sgd_solver.cpp:165] Iteration 58000, lr = 0.001
I0819 02:44:16.611878  3083 solver.cpp:357] Iteration 58100 (1.35665 iter/s, 73.7107s/100 iters), loss = 0.00951429
I0819 02:44:16.612030  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0107083 (* 1 = 0.0107083 loss)
I0819 02:44:16.612041  3083 sgd_solver.cpp:165] Iteration 58100, lr = 0.001
I0819 02:45:31.989404  3083 solver.cpp:357] Iteration 58200 (1.32665 iter/s, 75.3778s/100 iters), loss = 0.00351496
I0819 02:45:31.989720  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00358623 (* 1 = 0.00358623 loss)
I0819 02:45:31.989789  3083 sgd_solver.cpp:165] Iteration 58200, lr = 0.001
I0819 02:45:32.316741  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:46:44.285202  3083 solver.cpp:357] Iteration 58300 (1.38324 iter/s, 72.2942s/100 iters), loss = 0.0174667
I0819 02:46:44.285542  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00828495 (* 1 = 0.00828495 loss)
I0819 02:46:44.285609  3083 sgd_solver.cpp:165] Iteration 58300, lr = 0.001
I0819 02:47:56.808339  3083 solver.cpp:357] Iteration 58400 (1.3789 iter/s, 72.5216s/100 iters), loss = 0.0246797
I0819 02:47:56.808445  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0455042 (* 1 = 0.0455042 loss)
I0819 02:47:56.808457  3083 sgd_solver.cpp:165] Iteration 58400, lr = 0.001
I0819 02:49:08.881000  3083 solver.cpp:514] Iteration 58500, Testing net (#0)
I0819 02:49:53.893988  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:49:54.105316  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.930402
I0819 02:49:54.105370  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.300634 (* 1 = 0.300634 loss)
I0819 02:49:54.839632  3083 solver.cpp:357] Iteration 58500 (0.847225 iter/s, 118.032s/100 iters), loss = 0.00301878
I0819 02:49:54.839713  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00373926 (* 1 = 0.00373926 loss)
I0819 02:49:54.839725  3083 sgd_solver.cpp:165] Iteration 58500, lr = 0.001
I0819 02:51:00.437466  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:51:06.940626  3083 solver.cpp:357] Iteration 58600 (1.38697 iter/s, 72.0996s/100 iters), loss = 0.0182871
I0819 02:51:06.940706  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0343461 (* 1 = 0.0343461 loss)
I0819 02:51:06.940717  3083 sgd_solver.cpp:165] Iteration 58600, lr = 0.001
I0819 02:52:19.415293  3083 solver.cpp:357] Iteration 58700 (1.37982 iter/s, 72.4734s/100 iters), loss = 0.00680167
I0819 02:52:19.415441  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00554248 (* 1 = 0.00554248 loss)
I0819 02:52:19.415452  3083 sgd_solver.cpp:165] Iteration 58700, lr = 0.001
I0819 02:53:31.588927  3083 solver.cpp:357] Iteration 58800 (1.38553 iter/s, 72.1744s/100 iters), loss = 0.00687649
I0819 02:53:31.589110  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00696012 (* 1 = 0.00696012 loss)
I0819 02:53:31.589123  3083 sgd_solver.cpp:165] Iteration 58800, lr = 0.001
I0819 02:54:44.238344  3083 solver.cpp:357] Iteration 58900 (1.3765 iter/s, 72.6482s/100 iters), loss = 0.00536574
I0819 02:54:44.238504  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00447053 (* 1 = 0.00447053 loss)
I0819 02:54:44.238523  3083 sgd_solver.cpp:165] Iteration 58900, lr = 0.001
I0819 02:55:43.724253  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:55:56.325840  3083 solver.cpp:514] Iteration 59000, Testing net (#0)
I0819 02:56:41.495066  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 02:56:41.560547  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.930402
I0819 02:56:41.560591  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.299827 (* 1 = 0.299827 loss)
I0819 02:56:42.208984  3083 solver.cpp:357] Iteration 59000 (0.847672 iter/s, 117.97s/100 iters), loss = 0.00116023
I0819 02:56:42.209055  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00177382 (* 1 = 0.00177382 loss)
I0819 02:56:42.209067  3083 sgd_solver.cpp:165] Iteration 59000, lr = 0.001
I0819 02:57:56.793681  3083 solver.cpp:357] Iteration 59100 (1.34076 iter/s, 74.5844s/100 iters), loss = 0.00464481
I0819 02:57:56.793854  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00331241 (* 1 = 0.00331241 loss)
I0819 02:57:56.793867  3083 sgd_solver.cpp:165] Iteration 59100, lr = 0.001
I0819 02:59:11.545712  3083 solver.cpp:357] Iteration 59200 (1.33776 iter/s, 74.752s/100 iters), loss = 0.0132681
I0819 02:59:11.545864  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0152615 (* 1 = 0.0152615 loss)
I0819 02:59:11.545881  3083 sgd_solver.cpp:165] Iteration 59200, lr = 0.001
I0819 03:00:23.703330  3083 solver.cpp:357] Iteration 59300 (1.38586 iter/s, 72.1573s/100 iters), loss = 0.00553251
I0819 03:00:23.703469  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0025927 (* 1 = 0.0025927 loss)
I0819 03:00:23.703482  3083 sgd_solver.cpp:165] Iteration 59300, lr = 0.001
I0819 03:01:15.967147  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:01:36.438616  3083 solver.cpp:357] Iteration 59400 (1.37485 iter/s, 72.735s/100 iters), loss = 0.0456129
I0819 03:01:36.438704  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0386978 (* 1 = 0.0386978 loss)
I0819 03:01:36.438717  3083 sgd_solver.cpp:165] Iteration 59400, lr = 0.001
I0819 03:02:48.225461  3083 solver.cpp:514] Iteration 59500, Testing net (#0)
I0819 03:03:33.735347  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:03:33.966886  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.931402
I0819 03:03:33.966941  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.300926 (* 1 = 0.300926 loss)
I0819 03:03:34.390601  3083 solver.cpp:357] Iteration 59500 (0.847798 iter/s, 117.953s/100 iters), loss = 0.0105861
I0819 03:03:34.390693  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0181747 (* 1 = 0.0181747 loss)
I0819 03:03:34.390707  3083 sgd_solver.cpp:165] Iteration 59500, lr = 0.001
I0819 03:04:46.993067  3083 solver.cpp:357] Iteration 59600 (1.37737 iter/s, 72.6019s/100 iters), loss = 0.00294722
I0819 03:04:46.993268  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00273247 (* 1 = 0.00273247 loss)
I0819 03:04:46.993280  3083 sgd_solver.cpp:165] Iteration 59600, lr = 0.001
I0819 03:05:59.491104  3083 solver.cpp:357] Iteration 59700 (1.37936 iter/s, 72.4975s/100 iters), loss = 0.00206723
I0819 03:05:59.491314  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00175346 (* 1 = 0.00175346 loss)
I0819 03:05:59.491328  3083 sgd_solver.cpp:165] Iteration 59700, lr = 0.001
I0819 03:06:44.892191  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:07:11.816298  3083 solver.cpp:357] Iteration 59800 (1.38266 iter/s, 72.3246s/100 iters), loss = 0.00345608
I0819 03:07:11.816365  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00471181 (* 1 = 0.00471181 loss)
I0819 03:07:11.816376  3083 sgd_solver.cpp:165] Iteration 59800, lr = 0.001
I0819 03:08:24.106199  3083 solver.cpp:357] Iteration 59900 (1.38329 iter/s, 72.2913s/100 iters), loss = 0.00931486
I0819 03:08:24.106349  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00408425 (* 1 = 0.00408425 loss)
I0819 03:08:24.106361  3083 sgd_solver.cpp:165] Iteration 59900, lr = 0.001
I0819 03:09:36.085767  3083 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_56_iter_60000.caffemodel
I0819 03:09:36.115722  3083 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_56_iter_60000.solverstate
I0819 03:09:36.125316  3083 solver.cpp:514] Iteration 60000, Testing net (#0)
I0819 03:10:21.639607  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:10:21.804735  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.931802
I0819 03:10:21.804781  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.302271 (* 1 = 0.302271 loss)
I0819 03:10:22.358608  3083 solver.cpp:357] Iteration 60000 (0.845632 iter/s, 118.255s/100 iters), loss = 0.00236441
I0819 03:10:22.358692  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00177116 (* 1 = 0.00177116 loss)
I0819 03:10:22.358705  3083 sgd_solver.cpp:165] Iteration 60000, lr = 0.001
I0819 03:11:37.869022  3083 solver.cpp:357] Iteration 60100 (1.32433 iter/s, 75.5098s/100 iters), loss = 0.0104118
I0819 03:11:37.869196  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.000720113 (* 1 = 0.000720113 loss)
I0819 03:11:37.869210  3083 sgd_solver.cpp:165] Iteration 60100, lr = 0.001
I0819 03:12:17.758127  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:12:51.586413  3083 solver.cpp:357] Iteration 60200 (1.35655 iter/s, 73.7167s/100 iters), loss = 0.00288277
I0819 03:12:51.586562  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00266051 (* 1 = 0.00266051 loss)
I0819 03:12:51.586573  3083 sgd_solver.cpp:165] Iteration 60200, lr = 0.001
I0819 03:14:04.184270  3083 solver.cpp:357] Iteration 60300 (1.37743 iter/s, 72.5991s/100 iters), loss = 0.00495156
I0819 03:14:04.184391  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0078231 (* 1 = 0.0078231 loss)
I0819 03:14:04.184404  3083 sgd_solver.cpp:165] Iteration 60300, lr = 0.001
I0819 03:15:16.415448  3083 solver.cpp:357] Iteration 60400 (1.38446 iter/s, 72.2304s/100 iters), loss = 0.00643172
I0819 03:15:16.415624  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0036125 (* 1 = 0.0036125 loss)
I0819 03:15:16.415637  3083 sgd_solver.cpp:165] Iteration 60400, lr = 0.001
I0819 03:16:28.111747  3083 solver.cpp:514] Iteration 60500, Testing net (#0)
I0819 03:17:13.614687  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:17:13.843574  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.932902
I0819 03:17:13.843629  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.298696 (* 1 = 0.298696 loss)
I0819 03:17:14.257841  3083 solver.cpp:357] Iteration 60500 (0.84859 iter/s, 117.842s/100 iters), loss = 0.0059011
I0819 03:17:14.257915  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00632376 (* 1 = 0.00632376 loss)
I0819 03:17:14.257928  3083 sgd_solver.cpp:165] Iteration 60500, lr = 0.001
I0819 03:17:46.595418  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:18:26.966244  3083 solver.cpp:357] Iteration 60600 (1.37537 iter/s, 72.7076s/100 iters), loss = 0.00548816
I0819 03:18:26.966423  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00447785 (* 1 = 0.00447785 loss)
I0819 03:18:26.966435  3083 sgd_solver.cpp:165] Iteration 60600, lr = 0.001
I0819 03:19:39.251488  3083 solver.cpp:357] Iteration 60700 (1.38342 iter/s, 72.2845s/100 iters), loss = 0.0193564
I0819 03:19:39.251711  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0314858 (* 1 = 0.0314858 loss)
I0819 03:19:39.251724  3083 sgd_solver.cpp:165] Iteration 60700, lr = 0.001
I0819 03:20:51.577853  3083 solver.cpp:357] Iteration 60800 (1.38264 iter/s, 72.3256s/100 iters), loss = 0.00263442
I0819 03:20:51.578016  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00360272 (* 1 = 0.00360272 loss)
I0819 03:20:51.578028  3083 sgd_solver.cpp:165] Iteration 60800, lr = 0.001
I0819 03:22:03.982913  3083 solver.cpp:357] Iteration 60900 (1.38113 iter/s, 72.4043s/100 iters), loss = 0.0206661
I0819 03:22:03.983014  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00541841 (* 1 = 0.00541841 loss)
I0819 03:22:03.983026  3083 sgd_solver.cpp:165] Iteration 60900, lr = 0.001
I0819 03:22:29.057116  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:23:15.785329  3083 solver.cpp:514] Iteration 61000, Testing net (#0)
I0819 03:24:01.051101  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:24:01.238299  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.930402
I0819 03:24:01.238363  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.297141 (* 1 = 0.297141 loss)
I0819 03:24:01.885797  3083 solver.cpp:357] Iteration 61000 (0.848141 iter/s, 117.905s/100 iters), loss = 0.00594993
I0819 03:24:01.885870  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00531216 (* 1 = 0.00531216 loss)
I0819 03:24:01.885885  3083 sgd_solver.cpp:165] Iteration 61000, lr = 0.001
I0819 03:25:17.844688  3083 solver.cpp:357] Iteration 61100 (1.31651 iter/s, 75.9581s/100 iters), loss = 0.00353403
I0819 03:25:17.844877  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00601537 (* 1 = 0.00601537 loss)
I0819 03:25:17.844907  3083 sgd_solver.cpp:165] Iteration 61100, lr = 0.001
I0819 03:26:30.857859  3083 solver.cpp:357] Iteration 61200 (1.3696 iter/s, 73.0143s/100 iters), loss = 0.00353709
I0819 03:26:30.858022  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00399192 (* 1 = 0.00399192 loss)
I0819 03:26:30.858033  3083 sgd_solver.cpp:165] Iteration 61200, lr = 0.001
I0819 03:27:43.381748  3083 solver.cpp:357] Iteration 61300 (1.37883 iter/s, 72.525s/100 iters), loss = 0.0068181
I0819 03:27:43.381856  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00836939 (* 1 = 0.00836939 loss)
I0819 03:27:43.381867  3083 sgd_solver.cpp:165] Iteration 61300, lr = 0.001
I0819 03:28:01.990756  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:28:56.221065  3083 solver.cpp:357] Iteration 61400 (1.37286 iter/s, 72.8405s/100 iters), loss = 0.00971407
I0819 03:28:56.221314  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00470228 (* 1 = 0.00470228 loss)
I0819 03:28:56.221328  3083 sgd_solver.cpp:165] Iteration 61400, lr = 0.001
I0819 03:30:08.106310  3083 solver.cpp:514] Iteration 61500, Testing net (#0)
I0819 03:30:53.333616  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:30:53.399893  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.931202
I0819 03:30:53.399936  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.298726 (* 1 = 0.298726 loss)
I0819 03:30:53.996291  3083 solver.cpp:357] Iteration 61500 (0.849075 iter/s, 117.775s/100 iters), loss = 0.00657613
I0819 03:30:53.996361  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0092695 (* 1 = 0.0092695 loss)
I0819 03:30:53.996373  3083 sgd_solver.cpp:165] Iteration 61500, lr = 0.001
I0819 03:32:06.822227  3083 solver.cpp:357] Iteration 61600 (1.37313 iter/s, 72.8261s/100 iters), loss = 0.00881829
I0819 03:32:06.822378  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00334844 (* 1 = 0.00334844 loss)
I0819 03:32:06.822396  3083 sgd_solver.cpp:165] Iteration 61600, lr = 0.001
I0819 03:33:19.489979  3083 solver.cpp:357] Iteration 61700 (1.37612 iter/s, 72.6681s/100 iters), loss = 0.00236354
I0819 03:33:19.490130  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00267392 (* 1 = 0.00267392 loss)
I0819 03:33:19.490141  3083 sgd_solver.cpp:165] Iteration 61700, lr = 0.001
I0819 03:33:31.095787  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:34:31.961139  3083 solver.cpp:357] Iteration 61800 (1.37982 iter/s, 72.4733s/100 iters), loss = 0.0187178
I0819 03:34:31.961315  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0316217 (* 1 = 0.0316217 loss)
I0819 03:34:31.961328  3083 sgd_solver.cpp:165] Iteration 61800, lr = 0.001
I0819 03:35:44.648602  3083 solver.cpp:357] Iteration 61900 (1.37575 iter/s, 72.6876s/100 iters), loss = 0.00573474
I0819 03:35:44.648768  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00437241 (* 1 = 0.00437241 loss)
I0819 03:35:44.648782  3083 sgd_solver.cpp:165] Iteration 61900, lr = 0.001
I0819 03:36:56.279232  3083 solver.cpp:514] Iteration 62000, Testing net (#0)
I0819 03:37:42.363091  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:37:42.553071  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.931302
I0819 03:37:42.553133  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.301516 (* 1 = 0.301516 loss)
I0819 03:37:43.196588  3083 solver.cpp:357] Iteration 62000 (0.843531 iter/s, 118.549s/100 iters), loss = 0.0147344
I0819 03:37:43.196660  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00598581 (* 1 = 0.00598581 loss)
I0819 03:37:43.196672  3083 sgd_solver.cpp:165] Iteration 62000, lr = 0.001
I0819 03:38:58.502697  3083 solver.cpp:357] Iteration 62100 (1.32791 iter/s, 75.306s/100 iters), loss = 0.00446062
I0819 03:38:58.502856  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00200704 (* 1 = 0.00200704 loss)
I0819 03:38:58.502868  3083 sgd_solver.cpp:165] Iteration 62100, lr = 0.001
I0819 03:39:03.385486  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:40:10.943720  3083 solver.cpp:357] Iteration 62200 (1.38044 iter/s, 72.4408s/100 iters), loss = 0.00227158
I0819 03:40:10.943912  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00222955 (* 1 = 0.00222955 loss)
I0819 03:40:10.943927  3083 sgd_solver.cpp:165] Iteration 62200, lr = 0.001
I0819 03:41:23.491837  3083 solver.cpp:357] Iteration 62300 (1.3784 iter/s, 72.5478s/100 iters), loss = 0.00276977
I0819 03:41:23.492012  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00288103 (* 1 = 0.00288103 loss)
I0819 03:41:23.492025  3083 sgd_solver.cpp:165] Iteration 62300, lr = 0.001
I0819 03:42:36.187328  3083 solver.cpp:357] Iteration 62400 (1.37561 iter/s, 72.6951s/100 iters), loss = 0.00534081
I0819 03:42:36.187480  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00448184 (* 1 = 0.00448184 loss)
I0819 03:42:36.187494  3083 sgd_solver.cpp:165] Iteration 62400, lr = 0.001
I0819 03:43:46.572533  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:43:48.013917  3083 solver.cpp:514] Iteration 62500, Testing net (#0)
I0819 03:44:33.157703  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:44:33.368592  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.929503
I0819 03:44:33.368649  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.299779 (* 1 = 0.299779 loss)
I0819 03:44:33.984963  3083 solver.cpp:357] Iteration 62500 (0.848908 iter/s, 117.798s/100 iters), loss = 0.00496968
I0819 03:44:33.985028  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00276284 (* 1 = 0.00276284 loss)
I0819 03:44:33.985039  3083 sgd_solver.cpp:165] Iteration 62500, lr = 0.001
I0819 03:45:46.208057  3083 solver.cpp:357] Iteration 62600 (1.38457 iter/s, 72.2247s/100 iters), loss = 0.00398468
I0819 03:45:46.208210  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00538508 (* 1 = 0.00538508 loss)
I0819 03:45:46.208221  3083 sgd_solver.cpp:165] Iteration 62600, lr = 0.001
I0819 03:46:58.798779  3083 solver.cpp:357] Iteration 62700 (1.37756 iter/s, 72.5922s/100 iters), loss = 0.00409281
I0819 03:46:58.798960  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00297834 (* 1 = 0.00297834 loss)
I0819 03:46:58.798974  3083 sgd_solver.cpp:165] Iteration 62700, lr = 0.001
I0819 03:48:11.141333  3083 solver.cpp:357] Iteration 62800 (1.38232 iter/s, 72.3421s/100 iters), loss = 0.0055242
I0819 03:48:11.141508  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00914872 (* 1 = 0.00914872 loss)
I0819 03:48:11.141523  3083 sgd_solver.cpp:165] Iteration 62800, lr = 0.001
I0819 03:49:15.008062  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:49:23.535696  3083 solver.cpp:357] Iteration 62900 (1.38133 iter/s, 72.3939s/100 iters), loss = 0.015858
I0819 03:49:23.535776  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0146263 (* 1 = 0.0146263 loss)
I0819 03:49:23.535789  3083 sgd_solver.cpp:165] Iteration 62900, lr = 0.001
I0819 03:50:35.250353  3083 solver.cpp:514] Iteration 63000, Testing net (#0)
I0819 03:51:22.026489  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:51:22.215400  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.933502
I0819 03:51:22.215463  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.30096 (* 1 = 0.30096 loss)
I0819 03:51:22.862205  3083 solver.cpp:357] Iteration 63000 (0.838033 iter/s, 119.327s/100 iters), loss = 0.00350388
I0819 03:51:22.862280  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00247117 (* 1 = 0.00247117 loss)
I0819 03:51:22.862293  3083 sgd_solver.cpp:165] Iteration 63000, lr = 0.001
I0819 03:52:37.487421  3083 solver.cpp:357] Iteration 63100 (1.34004 iter/s, 74.6247s/100 iters), loss = 0.00736924
I0819 03:52:37.487566  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00307268 (* 1 = 0.00307268 loss)
I0819 03:52:37.487579  3083 sgd_solver.cpp:165] Iteration 63100, lr = 0.001
I0819 03:53:50.485906  3083 solver.cpp:357] Iteration 63200 (1.3699 iter/s, 72.9979s/100 iters), loss = 0.0020607
I0819 03:53:50.486030  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00144506 (* 1 = 0.00144506 loss)
I0819 03:53:50.486042  3083 sgd_solver.cpp:165] Iteration 63200, lr = 0.001
I0819 03:54:47.908908  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:55:03.350755  3083 solver.cpp:357] Iteration 63300 (1.37238 iter/s, 72.8663s/100 iters), loss = 0.00586911
I0819 03:55:03.350842  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00524164 (* 1 = 0.00524164 loss)
I0819 03:55:03.350855  3083 sgd_solver.cpp:165] Iteration 63300, lr = 0.001
I0819 03:56:15.932893  3083 solver.cpp:357] Iteration 63400 (1.37776 iter/s, 72.5816s/100 iters), loss = 0.00416402
I0819 03:56:15.933143  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00189797 (* 1 = 0.00189797 loss)
I0819 03:56:15.933156  3083 sgd_solver.cpp:165] Iteration 63400, lr = 0.001
I0819 03:57:27.520617  3083 solver.cpp:514] Iteration 63500, Testing net (#0)
I0819 03:58:12.568253  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 03:58:12.779134  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.931502
I0819 03:58:12.779186  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.307864 (* 1 = 0.307864 loss)
I0819 03:58:13.302354  3083 solver.cpp:357] Iteration 63500 (0.852008 iter/s, 117.37s/100 iters), loss = 0.00410352
I0819 03:58:13.302415  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0024044 (* 1 = 0.0024044 loss)
I0819 03:58:13.302426  3083 sgd_solver.cpp:165] Iteration 63500, lr = 0.001
I0819 03:59:26.157930  3083 solver.cpp:357] Iteration 63600 (1.37255 iter/s, 72.857s/100 iters), loss = 0.00146199
I0819 03:59:26.158082  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00101379 (* 1 = 0.00101379 loss)
I0819 03:59:26.158094  3083 sgd_solver.cpp:165] Iteration 63600, lr = 0.001
I0819 04:00:16.402374  3088 data_layer.cpp:73] Restarting data prefetching from start.
I0819 04:00:38.750954  3083 solver.cpp:357] Iteration 63700 (1.37756 iter/s, 72.5923s/100 iters), loss = 0.0140165
I0819 04:00:38.751029  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.0239073 (* 1 = 0.0239073 loss)
I0819 04:00:38.751041  3083 sgd_solver.cpp:165] Iteration 63700, lr = 0.001
I0819 04:01:50.959547  3083 solver.cpp:357] Iteration 63800 (1.38489 iter/s, 72.208s/100 iters), loss = 0.00166202
I0819 04:01:50.959681  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00148962 (* 1 = 0.00148962 loss)
I0819 04:01:50.959693  3083 sgd_solver.cpp:165] Iteration 63800, lr = 0.001
I0819 04:03:03.284538  3083 solver.cpp:357] Iteration 63900 (1.38266 iter/s, 72.3243s/100 iters), loss = 0.00160203
I0819 04:03:03.284659  3083 solver.cpp:376]     Train net output #0: SoftmaxWithLoss1 = 0.00201386 (* 1 = 0.00201386 loss)
I0819 04:03:03.284673  3083 sgd_solver.cpp:165] Iteration 63900, lr = 0.001
I0819 04:04:15.732342  3083 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_56_iter_64000.caffemodel
I0819 04:04:15.761454  3083 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_56_iter_64000.solverstate
I0819 04:04:15.863646  3083 solver.cpp:472] Iteration 64000, loss = 0.00392883
I0819 04:04:15.863708  3083 solver.cpp:514] Iteration 64000, Testing net (#0)
I0819 04:05:02.780431  3089 data_layer.cpp:73] Restarting data prefetching from start.
I0819 04:05:02.967427  3083 solver.cpp:580]     Test net output #0: Accuracy1 = 0.933603
I0819 04:05:02.967487  3083 solver.cpp:580]     Test net output #1: SoftmaxWithLoss1 = 0.302391 (* 1 = 0.302391 loss)
I0819 04:05:02.967499  3083 solver.cpp:479] Optimization Done.
I0819 04:05:02.967519  3083 caffe.cpp:326] Optimization Done.
