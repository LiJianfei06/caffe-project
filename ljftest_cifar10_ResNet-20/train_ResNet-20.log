WARNING: Logging before InitGoogleLogging() is written to STDERR
I0929 10:16:44.491376 22954 caffe.cpp:530] argc:5 lijianfei debug!!!!!!!!!!
I0929 10:16:44.491503 22954 caffe.cpp:533] argv[0]:../../build/tools/caffe lijianfei debug!!!!!!!!!!
I0929 10:16:44.491506 22954 caffe.cpp:533] argv[1]:train lijianfei debug!!!!!!!!!!
I0929 10:16:44.491513 22954 caffe.cpp:533] argv[2]:--solver=./solver.prototxt lijianfei debug!!!!!!!!!!
I0929 10:16:44.491515 22954 caffe.cpp:533] argv[3]:--weights= lijianfei debug!!!!!!!!!!
I0929 10:16:44.491519 22954 caffe.cpp:533] argv[4]:--gpu=0 lijianfei debug!!!!!!!!!!
I0929 10:16:44.491583 22954 caffe.cpp:548] use WITH_PYTHON_LAYER lijianfei debug!!!!!!!!!!
I0929 10:16:44.491778 22954 caffe.cpp:553] caffe::string(argv[1]):train lijianfei debug!!!!!!!!!!
I0929 10:16:44.493536 22954 caffe.cpp:238] stages: lijianfei debug!!!!!!!!!!!!
I0929 10:16:44.493577 22954 caffe.cpp:269] Using GPUs 0
I0929 10:16:44.499866 22954 caffe.cpp:274] GPU 0: GeForce GTX 1060 6GB
I0929 10:16:45.116681 22954 solver_factory.hpp:111] function Solver<Dtype>* CreateSolver()  lijianfei debug!!!!!!!!!!
I0929 10:16:45.116734 22954 solver_factory.hpp:113] type:Nesterov lijianfei debug!!!!!!!!!!
I0929 10:16:45.214824 22954 solver.cpp:97] Initializing solver from parameters: 
train_net: "./train_ResNet_20.prototxt"
test_net: "./test_ResNet_20.prototxt"
test_iter: 1000
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "./model_save/cifar10_ResNet_20"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
stepvalue: 32000
stepvalue: 48000
iter_size: 1
type: "Nesterov"
I0929 10:16:45.215195 22954 solver.cpp:167] Creating training net from train_net file: ./train_ResNet_20.prototxt
I0929 10:16:45.216150 22954 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./train_ResNet_20.prototxt
I0929 10:16:45.216188 22954 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0929 10:16:45.217165 22954 net.cpp:82] Initializing net from parameters: 
name: "ResNet-20"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: true
    crop_size: 32
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "conv2_1_1"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "conv4_Eltwise_3"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Softmax1"
  type: "SoftmaxWithLoss"
  bottom: "fc1"
  bottom: "label"
  top: "Softmax1"
}
I0929 10:16:45.217648 22954 layer_factory.hpp:77] Creating layer Data1
I0929 10:16:45.217864 22954 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/train_lmdb
I0929 10:16:45.217912 22954 net.cpp:128] Creating Layer Data1
I0929 10:16:45.217923 22954 net.cpp:522] Data1 -> data
I0929 10:16:45.217974 22954 net.cpp:522] Data1 -> label
I0929 10:16:45.219777 22954 data_layer.cpp:45] output data size: 128,3,32,32
I0929 10:16:45.236210 22954 net.cpp:172] Setting up Data1
I0929 10:16:45.236274 22954 net.cpp:186] Top shape: 128 3 32 32 (393216)
I0929 10:16:45.236280 22954 net.cpp:186] Top shape: 128 (128)
I0929 10:16:45.236284 22954 net.cpp:194] Memory required for data: 1573376
I0929 10:16:45.236300 22954 layer_factory.hpp:77] Creating layer conv1
I0929 10:16:45.236346 22954 net.cpp:128] Creating Layer conv1
I0929 10:16:45.236413 22954 net.cpp:558] conv1 <- data
I0929 10:16:45.236449 22954 net.cpp:522] conv1 -> conv1
I0929 10:16:46.231277 22954 net.cpp:172] Setting up conv1
I0929 10:16:46.231346 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.231353 22954 net.cpp:194] Memory required for data: 9961984
I0929 10:16:46.231400 22954 layer_factory.hpp:77] Creating layer conv1/bn
I0929 10:16:46.231426 22954 net.cpp:128] Creating Layer conv1/bn
I0929 10:16:46.231432 22954 net.cpp:558] conv1/bn <- conv1
I0929 10:16:46.231441 22954 net.cpp:509] conv1/bn -> conv1 (in-place)
I0929 10:16:46.231664 22954 net.cpp:172] Setting up conv1/bn
I0929 10:16:46.231721 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.231725 22954 net.cpp:194] Memory required for data: 18350592
I0929 10:16:46.231739 22954 layer_factory.hpp:77] Creating layer conv1/scale
I0929 10:16:46.231750 22954 net.cpp:128] Creating Layer conv1/scale
I0929 10:16:46.231753 22954 net.cpp:558] conv1/scale <- conv1
I0929 10:16:46.231760 22954 net.cpp:509] conv1/scale -> conv1 (in-place)
I0929 10:16:46.231807 22954 layer_factory.hpp:77] Creating layer conv1/scale
I0929 10:16:46.231930 22954 net.cpp:172] Setting up conv1/scale
I0929 10:16:46.231942 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.231946 22954 net.cpp:194] Memory required for data: 26739200
I0929 10:16:46.231954 22954 layer_factory.hpp:77] Creating layer conv1/ReLU
I0929 10:16:46.231963 22954 net.cpp:128] Creating Layer conv1/ReLU
I0929 10:16:46.231967 22954 net.cpp:558] conv1/ReLU <- conv1
I0929 10:16:46.231972 22954 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I0929 10:16:46.233042 22954 net.cpp:172] Setting up conv1/ReLU
I0929 10:16:46.233057 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.233063 22954 net.cpp:194] Memory required for data: 35127808
I0929 10:16:46.233067 22954 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I0929 10:16:46.233077 22954 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I0929 10:16:46.233081 22954 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I0929 10:16:46.233088 22954 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I0929 10:16:46.233096 22954 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I0929 10:16:46.233137 22954 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I0929 10:16:46.233145 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.233151 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.233155 22954 net.cpp:194] Memory required for data: 51905024
I0929 10:16:46.233160 22954 layer_factory.hpp:77] Creating layer conv2_1_0
I0929 10:16:46.233172 22954 net.cpp:128] Creating Layer conv2_1_0
I0929 10:16:46.233176 22954 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I0929 10:16:46.233183 22954 net.cpp:522] conv2_1_0 -> conv2_1_0
I0929 10:16:46.239794 22954 net.cpp:172] Setting up conv2_1_0
I0929 10:16:46.239821 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.239826 22954 net.cpp:194] Memory required for data: 60293632
I0929 10:16:46.239838 22954 layer_factory.hpp:77] Creating layer conv2_1_bn0
I0929 10:16:46.239852 22954 net.cpp:128] Creating Layer conv2_1_bn0
I0929 10:16:46.239856 22954 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I0929 10:16:46.239866 22954 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I0929 10:16:46.240084 22954 net.cpp:172] Setting up conv2_1_bn0
I0929 10:16:46.240092 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.240097 22954 net.cpp:194] Memory required for data: 68682240
I0929 10:16:46.240105 22954 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0929 10:16:46.240116 22954 net.cpp:128] Creating Layer conv2_1_scale0
I0929 10:16:46.240121 22954 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I0929 10:16:46.240128 22954 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I0929 10:16:46.240166 22954 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0929 10:16:46.240309 22954 net.cpp:172] Setting up conv2_1_scale0
I0929 10:16:46.240324 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.240327 22954 net.cpp:194] Memory required for data: 77070848
I0929 10:16:46.240335 22954 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I0929 10:16:46.240342 22954 net.cpp:128] Creating Layer conv2_1_ReLU0
I0929 10:16:46.240346 22954 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I0929 10:16:46.240355 22954 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I0929 10:16:46.241891 22954 net.cpp:172] Setting up conv2_1_ReLU0
I0929 10:16:46.241911 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.241915 22954 net.cpp:194] Memory required for data: 85459456
I0929 10:16:46.241945 22954 layer_factory.hpp:77] Creating layer conv2_1_1
I0929 10:16:46.241971 22954 net.cpp:128] Creating Layer conv2_1_1
I0929 10:16:46.241976 22954 net.cpp:558] conv2_1_1 <- conv2_1_0
I0929 10:16:46.241986 22954 net.cpp:522] conv2_1_1 -> conv2_1_1
I0929 10:16:46.248646 22954 net.cpp:172] Setting up conv2_1_1
I0929 10:16:46.248672 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.248675 22954 net.cpp:194] Memory required for data: 93848064
I0929 10:16:46.248685 22954 layer_factory.hpp:77] Creating layer conv2_1bn1
I0929 10:16:46.248694 22954 net.cpp:128] Creating Layer conv2_1bn1
I0929 10:16:46.248699 22954 net.cpp:558] conv2_1bn1 <- conv2_1_1
I0929 10:16:46.248708 22954 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I0929 10:16:46.248936 22954 net.cpp:172] Setting up conv2_1bn1
I0929 10:16:46.248948 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.248952 22954 net.cpp:194] Memory required for data: 102236672
I0929 10:16:46.248965 22954 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0929 10:16:46.248975 22954 net.cpp:128] Creating Layer conv2_1_scale1
I0929 10:16:46.248980 22954 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I0929 10:16:46.248986 22954 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I0929 10:16:46.249023 22954 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0929 10:16:46.249194 22954 net.cpp:172] Setting up conv2_1_scale1
I0929 10:16:46.249234 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.249243 22954 net.cpp:194] Memory required for data: 110625280
I0929 10:16:46.249253 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I0929 10:16:46.249264 22954 net.cpp:128] Creating Layer conv2_Eltwise_1
I0929 10:16:46.249267 22954 net.cpp:558] conv2_Eltwise_1 <- conv1_conv1/ReLU_0_split_1
I0929 10:16:46.249274 22954 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I0929 10:16:46.249282 22954 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I0929 10:16:46.249315 22954 net.cpp:172] Setting up conv2_Eltwise_1
I0929 10:16:46.249326 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.249331 22954 net.cpp:194] Memory required for data: 119013888
I0929 10:16:46.249336 22954 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I0929 10:16:46.249342 22954 net.cpp:128] Creating Layer conv2_1ReLU_1
I0929 10:16:46.249346 22954 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I0929 10:16:46.249354 22954 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I0929 10:16:46.250751 22954 net.cpp:172] Setting up conv2_1ReLU_1
I0929 10:16:46.250777 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.250780 22954 net.cpp:194] Memory required for data: 127402496
I0929 10:16:46.250785 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 10:16:46.250799 22954 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 10:16:46.250805 22954 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I0929 10:16:46.250814 22954 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0929 10:16:46.250828 22954 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0929 10:16:46.250877 22954 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 10:16:46.250885 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.250890 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.250895 22954 net.cpp:194] Memory required for data: 144179712
I0929 10:16:46.250900 22954 layer_factory.hpp:77] Creating layer conv2_2_0
I0929 10:16:46.250917 22954 net.cpp:128] Creating Layer conv2_2_0
I0929 10:16:46.250922 22954 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0929 10:16:46.250931 22954 net.cpp:522] conv2_2_0 -> conv2_2_0
I0929 10:16:46.257498 22954 net.cpp:172] Setting up conv2_2_0
I0929 10:16:46.257524 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.257529 22954 net.cpp:194] Memory required for data: 152568320
I0929 10:16:46.257539 22954 layer_factory.hpp:77] Creating layer conv2_2_bn0
I0929 10:16:46.257567 22954 net.cpp:128] Creating Layer conv2_2_bn0
I0929 10:16:46.257573 22954 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I0929 10:16:46.257580 22954 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I0929 10:16:46.257809 22954 net.cpp:172] Setting up conv2_2_bn0
I0929 10:16:46.257822 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.257827 22954 net.cpp:194] Memory required for data: 160956928
I0929 10:16:46.257835 22954 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0929 10:16:46.257843 22954 net.cpp:128] Creating Layer conv2_2_scale0
I0929 10:16:46.257848 22954 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I0929 10:16:46.257855 22954 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I0929 10:16:46.257892 22954 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0929 10:16:46.258069 22954 net.cpp:172] Setting up conv2_2_scale0
I0929 10:16:46.258098 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.258107 22954 net.cpp:194] Memory required for data: 169345536
I0929 10:16:46.258116 22954 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I0929 10:16:46.258123 22954 net.cpp:128] Creating Layer conv2_2_ReLU0
I0929 10:16:46.258127 22954 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I0929 10:16:46.258133 22954 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I0929 10:16:46.259593 22954 net.cpp:172] Setting up conv2_2_ReLU0
I0929 10:16:46.259614 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.259618 22954 net.cpp:194] Memory required for data: 177734144
I0929 10:16:46.259624 22954 layer_factory.hpp:77] Creating layer conv2_2_1
I0929 10:16:46.259639 22954 net.cpp:128] Creating Layer conv2_2_1
I0929 10:16:46.259644 22954 net.cpp:558] conv2_2_1 <- conv2_2_0
I0929 10:16:46.259654 22954 net.cpp:522] conv2_2_1 -> conv2_2_1
I0929 10:16:46.266358 22954 net.cpp:172] Setting up conv2_2_1
I0929 10:16:46.266386 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.266389 22954 net.cpp:194] Memory required for data: 186122752
I0929 10:16:46.266398 22954 layer_factory.hpp:77] Creating layer conv2_2bn1
I0929 10:16:46.266410 22954 net.cpp:128] Creating Layer conv2_2bn1
I0929 10:16:46.266415 22954 net.cpp:558] conv2_2bn1 <- conv2_2_1
I0929 10:16:46.266424 22954 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I0929 10:16:46.266659 22954 net.cpp:172] Setting up conv2_2bn1
I0929 10:16:46.266670 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.266676 22954 net.cpp:194] Memory required for data: 194511360
I0929 10:16:46.266690 22954 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0929 10:16:46.266698 22954 net.cpp:128] Creating Layer conv2_2_scale1
I0929 10:16:46.266703 22954 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I0929 10:16:46.266710 22954 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I0929 10:16:46.266747 22954 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0929 10:16:46.266924 22954 net.cpp:172] Setting up conv2_2_scale1
I0929 10:16:46.266950 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.266958 22954 net.cpp:194] Memory required for data: 202899968
I0929 10:16:46.266966 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I0929 10:16:46.266978 22954 net.cpp:128] Creating Layer conv2_Eltwise_2
I0929 10:16:46.266981 22954 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0929 10:16:46.266986 22954 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I0929 10:16:46.266993 22954 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I0929 10:16:46.267024 22954 net.cpp:172] Setting up conv2_Eltwise_2
I0929 10:16:46.267030 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.267035 22954 net.cpp:194] Memory required for data: 211288576
I0929 10:16:46.267040 22954 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I0929 10:16:46.267045 22954 net.cpp:128] Creating Layer conv2_2ReLU_1
I0929 10:16:46.267050 22954 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I0929 10:16:46.267057 22954 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I0929 10:16:46.268457 22954 net.cpp:172] Setting up conv2_2ReLU_1
I0929 10:16:46.268477 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.268482 22954 net.cpp:194] Memory required for data: 219677184
I0929 10:16:46.268486 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 10:16:46.268493 22954 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 10:16:46.268498 22954 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I0929 10:16:46.268508 22954 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0929 10:16:46.268517 22954 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0929 10:16:46.268568 22954 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 10:16:46.268575 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.268581 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.268586 22954 net.cpp:194] Memory required for data: 236454400
I0929 10:16:46.268590 22954 layer_factory.hpp:77] Creating layer conv2_3_0
I0929 10:16:46.268602 22954 net.cpp:128] Creating Layer conv2_3_0
I0929 10:16:46.268607 22954 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0929 10:16:46.268617 22954 net.cpp:522] conv2_3_0 -> conv2_3_0
I0929 10:16:46.275213 22954 net.cpp:172] Setting up conv2_3_0
I0929 10:16:46.275238 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.275243 22954 net.cpp:194] Memory required for data: 244843008
I0929 10:16:46.275252 22954 layer_factory.hpp:77] Creating layer conv2_3_bn0
I0929 10:16:46.275267 22954 net.cpp:128] Creating Layer conv2_3_bn0
I0929 10:16:46.275272 22954 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I0929 10:16:46.275281 22954 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I0929 10:16:46.275509 22954 net.cpp:172] Setting up conv2_3_bn0
I0929 10:16:46.275521 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.275526 22954 net.cpp:194] Memory required for data: 253231616
I0929 10:16:46.275535 22954 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0929 10:16:46.275544 22954 net.cpp:128] Creating Layer conv2_3_scale0
I0929 10:16:46.275548 22954 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I0929 10:16:46.275554 22954 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I0929 10:16:46.275593 22954 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0929 10:16:46.275728 22954 net.cpp:172] Setting up conv2_3_scale0
I0929 10:16:46.275735 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.275739 22954 net.cpp:194] Memory required for data: 261620224
I0929 10:16:46.275748 22954 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I0929 10:16:46.275753 22954 net.cpp:128] Creating Layer conv2_3_ReLU0
I0929 10:16:46.275758 22954 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I0929 10:16:46.275765 22954 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I0929 10:16:46.277309 22954 net.cpp:172] Setting up conv2_3_ReLU0
I0929 10:16:46.277335 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.277339 22954 net.cpp:194] Memory required for data: 270008832
I0929 10:16:46.277344 22954 layer_factory.hpp:77] Creating layer conv2_3_1
I0929 10:16:46.277360 22954 net.cpp:128] Creating Layer conv2_3_1
I0929 10:16:46.277365 22954 net.cpp:558] conv2_3_1 <- conv2_3_0
I0929 10:16:46.277375 22954 net.cpp:522] conv2_3_1 -> conv2_3_1
I0929 10:16:46.284040 22954 net.cpp:172] Setting up conv2_3_1
I0929 10:16:46.284066 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.284071 22954 net.cpp:194] Memory required for data: 278397440
I0929 10:16:46.284080 22954 layer_factory.hpp:77] Creating layer conv2_3bn1
I0929 10:16:46.284092 22954 net.cpp:128] Creating Layer conv2_3bn1
I0929 10:16:46.284097 22954 net.cpp:558] conv2_3bn1 <- conv2_3_1
I0929 10:16:46.284106 22954 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I0929 10:16:46.284350 22954 net.cpp:172] Setting up conv2_3bn1
I0929 10:16:46.284363 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.284384 22954 net.cpp:194] Memory required for data: 286786048
I0929 10:16:46.284395 22954 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0929 10:16:46.284415 22954 net.cpp:128] Creating Layer conv2_3_scale1
I0929 10:16:46.284418 22954 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I0929 10:16:46.284425 22954 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I0929 10:16:46.284463 22954 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0929 10:16:46.284626 22954 net.cpp:172] Setting up conv2_3_scale1
I0929 10:16:46.284633 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.284637 22954 net.cpp:194] Memory required for data: 295174656
I0929 10:16:46.284646 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I0929 10:16:46.284652 22954 net.cpp:128] Creating Layer conv2_Eltwise_3
I0929 10:16:46.284657 22954 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0929 10:16:46.284662 22954 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I0929 10:16:46.284670 22954 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I0929 10:16:46.284696 22954 net.cpp:172] Setting up conv2_Eltwise_3
I0929 10:16:46.284706 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.284710 22954 net.cpp:194] Memory required for data: 303563264
I0929 10:16:46.284714 22954 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I0929 10:16:46.284720 22954 net.cpp:128] Creating Layer conv2_3ReLU_1
I0929 10:16:46.284724 22954 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I0929 10:16:46.284730 22954 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I0929 10:16:46.286093 22954 net.cpp:172] Setting up conv2_3ReLU_1
I0929 10:16:46.286110 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.286114 22954 net.cpp:194] Memory required for data: 311951872
I0929 10:16:46.286120 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 10:16:46.286130 22954 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 10:16:46.286139 22954 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I0929 10:16:46.286145 22954 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0929 10:16:46.286156 22954 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0929 10:16:46.286204 22954 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 10:16:46.286211 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.286217 22954 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 10:16:46.286221 22954 net.cpp:194] Memory required for data: 328729088
I0929 10:16:46.286226 22954 layer_factory.hpp:77] Creating layer conv3_1_0
I0929 10:16:46.286240 22954 net.cpp:128] Creating Layer conv3_1_0
I0929 10:16:46.286245 22954 net.cpp:558] conv3_1_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0929 10:16:46.286252 22954 net.cpp:522] conv3_1_0 -> conv3_1_0
I0929 10:16:46.293057 22954 net.cpp:172] Setting up conv3_1_0
I0929 10:16:46.293085 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.293090 22954 net.cpp:194] Memory required for data: 332923392
I0929 10:16:46.293102 22954 layer_factory.hpp:77] Creating layer conv3_1_bn0
I0929 10:16:46.293113 22954 net.cpp:128] Creating Layer conv3_1_bn0
I0929 10:16:46.293118 22954 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I0929 10:16:46.293130 22954 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I0929 10:16:46.293375 22954 net.cpp:172] Setting up conv3_1_bn0
I0929 10:16:46.293388 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.293393 22954 net.cpp:194] Memory required for data: 337117696
I0929 10:16:46.293403 22954 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0929 10:16:46.293413 22954 net.cpp:128] Creating Layer conv3_1_scale0
I0929 10:16:46.293417 22954 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I0929 10:16:46.293423 22954 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I0929 10:16:46.293463 22954 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0929 10:16:46.293617 22954 net.cpp:172] Setting up conv3_1_scale0
I0929 10:16:46.293625 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.293628 22954 net.cpp:194] Memory required for data: 341312000
I0929 10:16:46.293637 22954 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I0929 10:16:46.293645 22954 net.cpp:128] Creating Layer conv3_1_ReLU0
I0929 10:16:46.293650 22954 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I0929 10:16:46.293655 22954 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I0929 10:16:46.294960 22954 net.cpp:172] Setting up conv3_1_ReLU0
I0929 10:16:46.294982 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.294986 22954 net.cpp:194] Memory required for data: 345506304
I0929 10:16:46.294991 22954 layer_factory.hpp:77] Creating layer conv3_1_1
I0929 10:16:46.295008 22954 net.cpp:128] Creating Layer conv3_1_1
I0929 10:16:46.295014 22954 net.cpp:558] conv3_1_1 <- conv3_1_0
I0929 10:16:46.295022 22954 net.cpp:522] conv3_1_1 -> conv3_1_1
I0929 10:16:46.301720 22954 net.cpp:172] Setting up conv3_1_1
I0929 10:16:46.301746 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.301750 22954 net.cpp:194] Memory required for data: 349700608
I0929 10:16:46.301760 22954 layer_factory.hpp:77] Creating layer conv3_1bn1
I0929 10:16:46.301771 22954 net.cpp:128] Creating Layer conv3_1bn1
I0929 10:16:46.301776 22954 net.cpp:558] conv3_1bn1 <- conv3_1_1
I0929 10:16:46.301785 22954 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I0929 10:16:46.302037 22954 net.cpp:172] Setting up conv3_1bn1
I0929 10:16:46.302044 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.302048 22954 net.cpp:194] Memory required for data: 353894912
I0929 10:16:46.302057 22954 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0929 10:16:46.302064 22954 net.cpp:128] Creating Layer conv3_1_scale1
I0929 10:16:46.302068 22954 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I0929 10:16:46.302075 22954 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I0929 10:16:46.302114 22954 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0929 10:16:46.302253 22954 net.cpp:172] Setting up conv3_1_scale1
I0929 10:16:46.302261 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.302265 22954 net.cpp:194] Memory required for data: 358089216
I0929 10:16:46.302273 22954 layer_factory.hpp:77] Creating layer conv3_1_down
I0929 10:16:46.302284 22954 net.cpp:128] Creating Layer conv3_1_down
I0929 10:16:46.302289 22954 net.cpp:558] conv3_1_down <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0929 10:16:46.302299 22954 net.cpp:522] conv3_1_down -> conv3_1_down
I0929 10:16:46.308385 22954 net.cpp:172] Setting up conv3_1_down
I0929 10:16:46.308411 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.308415 22954 net.cpp:194] Memory required for data: 362283520
I0929 10:16:46.308434 22954 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I0929 10:16:46.308447 22954 net.cpp:128] Creating Layer conv3_1_bn_down
I0929 10:16:46.308452 22954 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I0929 10:16:46.308465 22954 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I0929 10:16:46.308701 22954 net.cpp:172] Setting up conv3_1_bn_down
I0929 10:16:46.308714 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.308718 22954 net.cpp:194] Memory required for data: 366477824
I0929 10:16:46.308727 22954 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0929 10:16:46.308734 22954 net.cpp:128] Creating Layer conv3_1_scale_down
I0929 10:16:46.308738 22954 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I0929 10:16:46.308746 22954 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I0929 10:16:46.308784 22954 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0929 10:16:46.308924 22954 net.cpp:172] Setting up conv3_1_scale_down
I0929 10:16:46.308933 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.308936 22954 net.cpp:194] Memory required for data: 370672128
I0929 10:16:46.308943 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I0929 10:16:46.308966 22954 net.cpp:128] Creating Layer conv3_Eltwise_1
I0929 10:16:46.308971 22954 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I0929 10:16:46.308976 22954 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I0929 10:16:46.308985 22954 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I0929 10:16:46.309008 22954 net.cpp:172] Setting up conv3_Eltwise_1
I0929 10:16:46.309015 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.309020 22954 net.cpp:194] Memory required for data: 374866432
I0929 10:16:46.309023 22954 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I0929 10:16:46.309031 22954 net.cpp:128] Creating Layer conv3_1ReLU_1
I0929 10:16:46.309036 22954 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I0929 10:16:46.309041 22954 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I0929 10:16:46.310477 22954 net.cpp:172] Setting up conv3_1ReLU_1
I0929 10:16:46.310497 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.310503 22954 net.cpp:194] Memory required for data: 379060736
I0929 10:16:46.310506 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 10:16:46.310518 22954 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 10:16:46.310523 22954 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I0929 10:16:46.310530 22954 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0929 10:16:46.310544 22954 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0929 10:16:46.310595 22954 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 10:16:46.310601 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.310606 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.310611 22954 net.cpp:194] Memory required for data: 387449344
I0929 10:16:46.310614 22954 layer_factory.hpp:77] Creating layer conv3_2_0
I0929 10:16:46.310628 22954 net.cpp:128] Creating Layer conv3_2_0
I0929 10:16:46.310633 22954 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0929 10:16:46.310640 22954 net.cpp:522] conv3_2_0 -> conv3_2_0
I0929 10:16:46.317217 22954 net.cpp:172] Setting up conv3_2_0
I0929 10:16:46.317243 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.317247 22954 net.cpp:194] Memory required for data: 391643648
I0929 10:16:46.317257 22954 layer_factory.hpp:77] Creating layer conv3_2_bn0
I0929 10:16:46.317270 22954 net.cpp:128] Creating Layer conv3_2_bn0
I0929 10:16:46.317275 22954 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I0929 10:16:46.317283 22954 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I0929 10:16:46.317520 22954 net.cpp:172] Setting up conv3_2_bn0
I0929 10:16:46.317528 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.317531 22954 net.cpp:194] Memory required for data: 395837952
I0929 10:16:46.317541 22954 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0929 10:16:46.317548 22954 net.cpp:128] Creating Layer conv3_2_scale0
I0929 10:16:46.317551 22954 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I0929 10:16:46.317559 22954 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I0929 10:16:46.317596 22954 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0929 10:16:46.317736 22954 net.cpp:172] Setting up conv3_2_scale0
I0929 10:16:46.317744 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.317747 22954 net.cpp:194] Memory required for data: 400032256
I0929 10:16:46.317754 22954 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I0929 10:16:46.317796 22954 net.cpp:128] Creating Layer conv3_2_ReLU0
I0929 10:16:46.317801 22954 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I0929 10:16:46.317824 22954 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I0929 10:16:46.319304 22954 net.cpp:172] Setting up conv3_2_ReLU0
I0929 10:16:46.319330 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.319335 22954 net.cpp:194] Memory required for data: 404226560
I0929 10:16:46.319340 22954 layer_factory.hpp:77] Creating layer conv3_2_1
I0929 10:16:46.319370 22954 net.cpp:128] Creating Layer conv3_2_1
I0929 10:16:46.319376 22954 net.cpp:558] conv3_2_1 <- conv3_2_0
I0929 10:16:46.319386 22954 net.cpp:522] conv3_2_1 -> conv3_2_1
I0929 10:16:46.326087 22954 net.cpp:172] Setting up conv3_2_1
I0929 10:16:46.326113 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.326117 22954 net.cpp:194] Memory required for data: 408420864
I0929 10:16:46.326126 22954 layer_factory.hpp:77] Creating layer conv3_2bn1
I0929 10:16:46.326139 22954 net.cpp:128] Creating Layer conv3_2bn1
I0929 10:16:46.326144 22954 net.cpp:558] conv3_2bn1 <- conv3_2_1
I0929 10:16:46.326153 22954 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I0929 10:16:46.326395 22954 net.cpp:172] Setting up conv3_2bn1
I0929 10:16:46.326406 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.326411 22954 net.cpp:194] Memory required for data: 412615168
I0929 10:16:46.326421 22954 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0929 10:16:46.326429 22954 net.cpp:128] Creating Layer conv3_2_scale1
I0929 10:16:46.326434 22954 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I0929 10:16:46.326439 22954 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I0929 10:16:46.326479 22954 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0929 10:16:46.326648 22954 net.cpp:172] Setting up conv3_2_scale1
I0929 10:16:46.326661 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.326665 22954 net.cpp:194] Memory required for data: 416809472
I0929 10:16:46.326673 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I0929 10:16:46.326683 22954 net.cpp:128] Creating Layer conv3_Eltwise_2
I0929 10:16:46.326687 22954 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0929 10:16:46.326692 22954 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I0929 10:16:46.326699 22954 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I0929 10:16:46.326722 22954 net.cpp:172] Setting up conv3_Eltwise_2
I0929 10:16:46.326730 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.326733 22954 net.cpp:194] Memory required for data: 421003776
I0929 10:16:46.326737 22954 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I0929 10:16:46.326743 22954 net.cpp:128] Creating Layer conv3_2ReLU_1
I0929 10:16:46.326747 22954 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I0929 10:16:46.326753 22954 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I0929 10:16:46.328152 22954 net.cpp:172] Setting up conv3_2ReLU_1
I0929 10:16:46.328172 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.328177 22954 net.cpp:194] Memory required for data: 425198080
I0929 10:16:46.328181 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 10:16:46.328207 22954 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 10:16:46.328213 22954 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I0929 10:16:46.328224 22954 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0929 10:16:46.328233 22954 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0929 10:16:46.328281 22954 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 10:16:46.328289 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.328294 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.328299 22954 net.cpp:194] Memory required for data: 433586688
I0929 10:16:46.328302 22954 layer_factory.hpp:77] Creating layer conv3_3_0
I0929 10:16:46.328316 22954 net.cpp:128] Creating Layer conv3_3_0
I0929 10:16:46.328320 22954 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0929 10:16:46.328327 22954 net.cpp:522] conv3_3_0 -> conv3_3_0
I0929 10:16:46.334909 22954 net.cpp:172] Setting up conv3_3_0
I0929 10:16:46.334935 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.334939 22954 net.cpp:194] Memory required for data: 437780992
I0929 10:16:46.334949 22954 layer_factory.hpp:77] Creating layer conv3_3_bn0
I0929 10:16:46.334978 22954 net.cpp:128] Creating Layer conv3_3_bn0
I0929 10:16:46.334985 22954 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I0929 10:16:46.334995 22954 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I0929 10:16:46.335242 22954 net.cpp:172] Setting up conv3_3_bn0
I0929 10:16:46.335253 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.335258 22954 net.cpp:194] Memory required for data: 441975296
I0929 10:16:46.335266 22954 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0929 10:16:46.335275 22954 net.cpp:128] Creating Layer conv3_3_scale0
I0929 10:16:46.335279 22954 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I0929 10:16:46.335285 22954 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I0929 10:16:46.335326 22954 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0929 10:16:46.335469 22954 net.cpp:172] Setting up conv3_3_scale0
I0929 10:16:46.335476 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.335480 22954 net.cpp:194] Memory required for data: 446169600
I0929 10:16:46.335489 22954 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I0929 10:16:46.335494 22954 net.cpp:128] Creating Layer conv3_3_ReLU0
I0929 10:16:46.335500 22954 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I0929 10:16:46.335507 22954 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I0929 10:16:46.337005 22954 net.cpp:172] Setting up conv3_3_ReLU0
I0929 10:16:46.337025 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.337029 22954 net.cpp:194] Memory required for data: 450363904
I0929 10:16:46.337034 22954 layer_factory.hpp:77] Creating layer conv3_3_1
I0929 10:16:46.337047 22954 net.cpp:128] Creating Layer conv3_3_1
I0929 10:16:46.337052 22954 net.cpp:558] conv3_3_1 <- conv3_3_0
I0929 10:16:46.337062 22954 net.cpp:522] conv3_3_1 -> conv3_3_1
I0929 10:16:46.343735 22954 net.cpp:172] Setting up conv3_3_1
I0929 10:16:46.343765 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.343770 22954 net.cpp:194] Memory required for data: 454558208
I0929 10:16:46.343780 22954 layer_factory.hpp:77] Creating layer conv3_3bn1
I0929 10:16:46.343801 22954 net.cpp:128] Creating Layer conv3_3bn1
I0929 10:16:46.343806 22954 net.cpp:558] conv3_3bn1 <- conv3_3_1
I0929 10:16:46.343814 22954 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I0929 10:16:46.344058 22954 net.cpp:172] Setting up conv3_3bn1
I0929 10:16:46.344072 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.344076 22954 net.cpp:194] Memory required for data: 458752512
I0929 10:16:46.344086 22954 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0929 10:16:46.344094 22954 net.cpp:128] Creating Layer conv3_3_scale1
I0929 10:16:46.344097 22954 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I0929 10:16:46.344105 22954 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I0929 10:16:46.344143 22954 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0929 10:16:46.344287 22954 net.cpp:172] Setting up conv3_3_scale1
I0929 10:16:46.344295 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.344298 22954 net.cpp:194] Memory required for data: 462946816
I0929 10:16:46.344306 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I0929 10:16:46.344313 22954 net.cpp:128] Creating Layer conv3_Eltwise_3
I0929 10:16:46.344318 22954 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0929 10:16:46.344323 22954 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I0929 10:16:46.344331 22954 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I0929 10:16:46.344352 22954 net.cpp:172] Setting up conv3_Eltwise_3
I0929 10:16:46.344362 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.344365 22954 net.cpp:194] Memory required for data: 467141120
I0929 10:16:46.344369 22954 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I0929 10:16:46.344375 22954 net.cpp:128] Creating Layer conv3_3ReLU_1
I0929 10:16:46.344379 22954 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I0929 10:16:46.344385 22954 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I0929 10:16:46.345803 22954 net.cpp:172] Setting up conv3_3ReLU_1
I0929 10:16:46.345844 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.345849 22954 net.cpp:194] Memory required for data: 471335424
I0929 10:16:46.345854 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 10:16:46.345865 22954 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 10:16:46.345870 22954 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I0929 10:16:46.345877 22954 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0929 10:16:46.345892 22954 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0929 10:16:46.345959 22954 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 10:16:46.345978 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.345983 22954 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 10:16:46.345988 22954 net.cpp:194] Memory required for data: 479724032
I0929 10:16:46.345991 22954 layer_factory.hpp:77] Creating layer conv4_1_0
I0929 10:16:46.346004 22954 net.cpp:128] Creating Layer conv4_1_0
I0929 10:16:46.346009 22954 net.cpp:558] conv4_1_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0929 10:16:46.346020 22954 net.cpp:522] conv4_1_0 -> conv4_1_0
I0929 10:16:46.352728 22954 net.cpp:172] Setting up conv4_1_0
I0929 10:16:46.352758 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.352763 22954 net.cpp:194] Memory required for data: 481821184
I0929 10:16:46.352774 22954 layer_factory.hpp:77] Creating layer conv4_1_bn0
I0929 10:16:46.352784 22954 net.cpp:128] Creating Layer conv4_1_bn0
I0929 10:16:46.352789 22954 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I0929 10:16:46.352802 22954 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I0929 10:16:46.353065 22954 net.cpp:172] Setting up conv4_1_bn0
I0929 10:16:46.353076 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.353081 22954 net.cpp:194] Memory required for data: 483918336
I0929 10:16:46.353091 22954 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0929 10:16:46.353098 22954 net.cpp:128] Creating Layer conv4_1_scale0
I0929 10:16:46.353102 22954 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I0929 10:16:46.353111 22954 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I0929 10:16:46.353150 22954 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0929 10:16:46.353296 22954 net.cpp:172] Setting up conv4_1_scale0
I0929 10:16:46.353303 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.353307 22954 net.cpp:194] Memory required for data: 486015488
I0929 10:16:46.353315 22954 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I0929 10:16:46.353322 22954 net.cpp:128] Creating Layer conv4_1_ReLU0
I0929 10:16:46.353325 22954 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I0929 10:16:46.353333 22954 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I0929 10:16:46.354606 22954 net.cpp:172] Setting up conv4_1_ReLU0
I0929 10:16:46.354629 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.354632 22954 net.cpp:194] Memory required for data: 488112640
I0929 10:16:46.354637 22954 layer_factory.hpp:77] Creating layer conv4_1_1
I0929 10:16:46.354650 22954 net.cpp:128] Creating Layer conv4_1_1
I0929 10:16:46.354656 22954 net.cpp:558] conv4_1_1 <- conv4_1_0
I0929 10:16:46.354666 22954 net.cpp:522] conv4_1_1 -> conv4_1_1
I0929 10:16:46.361544 22954 net.cpp:172] Setting up conv4_1_1
I0929 10:16:46.361573 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.361578 22954 net.cpp:194] Memory required for data: 490209792
I0929 10:16:46.361588 22954 layer_factory.hpp:77] Creating layer conv4_1bn1
I0929 10:16:46.361599 22954 net.cpp:128] Creating Layer conv4_1bn1
I0929 10:16:46.361604 22954 net.cpp:558] conv4_1bn1 <- conv4_1_1
I0929 10:16:46.361611 22954 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I0929 10:16:46.361883 22954 net.cpp:172] Setting up conv4_1bn1
I0929 10:16:46.361891 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.361896 22954 net.cpp:194] Memory required for data: 492306944
I0929 10:16:46.361924 22954 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0929 10:16:46.361943 22954 net.cpp:128] Creating Layer conv4_1_scale1
I0929 10:16:46.361948 22954 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I0929 10:16:46.361953 22954 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I0929 10:16:46.361997 22954 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0929 10:16:46.362145 22954 net.cpp:172] Setting up conv4_1_scale1
I0929 10:16:46.362181 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.362186 22954 net.cpp:194] Memory required for data: 494404096
I0929 10:16:46.362195 22954 layer_factory.hpp:77] Creating layer conv4_1_down
I0929 10:16:46.362207 22954 net.cpp:128] Creating Layer conv4_1_down
I0929 10:16:46.362212 22954 net.cpp:558] conv4_1_down <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0929 10:16:46.362223 22954 net.cpp:522] conv4_1_down -> conv4_1_down
I0929 10:16:46.368014 22954 net.cpp:172] Setting up conv4_1_down
I0929 10:16:46.368039 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.368044 22954 net.cpp:194] Memory required for data: 496501248
I0929 10:16:46.368054 22954 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I0929 10:16:46.368065 22954 net.cpp:128] Creating Layer conv4_1_bn_down
I0929 10:16:46.368072 22954 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I0929 10:16:46.368079 22954 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I0929 10:16:46.368335 22954 net.cpp:172] Setting up conv4_1_bn_down
I0929 10:16:46.368347 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.368351 22954 net.cpp:194] Memory required for data: 498598400
I0929 10:16:46.368361 22954 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0929 10:16:46.368371 22954 net.cpp:128] Creating Layer conv4_1_scale_down
I0929 10:16:46.368376 22954 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I0929 10:16:46.368381 22954 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I0929 10:16:46.368422 22954 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0929 10:16:46.368569 22954 net.cpp:172] Setting up conv4_1_scale_down
I0929 10:16:46.368577 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.368582 22954 net.cpp:194] Memory required for data: 500695552
I0929 10:16:46.368588 22954 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I0929 10:16:46.368597 22954 net.cpp:128] Creating Layer conv4_Eltwise_1
I0929 10:16:46.368600 22954 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I0929 10:16:46.368605 22954 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I0929 10:16:46.368614 22954 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I0929 10:16:46.368636 22954 net.cpp:172] Setting up conv4_Eltwise_1
I0929 10:16:46.368643 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.368646 22954 net.cpp:194] Memory required for data: 502792704
I0929 10:16:46.368650 22954 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I0929 10:16:46.368685 22954 net.cpp:128] Creating Layer conv4_1ReLU_1
I0929 10:16:46.368691 22954 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I0929 10:16:46.368696 22954 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I0929 10:16:46.370090 22954 net.cpp:172] Setting up conv4_1ReLU_1
I0929 10:16:46.370110 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.370113 22954 net.cpp:194] Memory required for data: 504889856
I0929 10:16:46.370118 22954 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 10:16:46.370127 22954 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 10:16:46.370133 22954 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I0929 10:16:46.370141 22954 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0929 10:16:46.370151 22954 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0929 10:16:46.370215 22954 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 10:16:46.370223 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.370247 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.370251 22954 net.cpp:194] Memory required for data: 509084160
I0929 10:16:46.370255 22954 layer_factory.hpp:77] Creating layer conv4_2_0
I0929 10:16:46.370270 22954 net.cpp:128] Creating Layer conv4_2_0
I0929 10:16:46.370273 22954 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0929 10:16:46.370283 22954 net.cpp:522] conv4_2_0 -> conv4_2_0
I0929 10:16:46.376834 22954 net.cpp:172] Setting up conv4_2_0
I0929 10:16:46.376860 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.376865 22954 net.cpp:194] Memory required for data: 511181312
I0929 10:16:46.376879 22954 layer_factory.hpp:77] Creating layer conv4_2_bn0
I0929 10:16:46.376890 22954 net.cpp:128] Creating Layer conv4_2_bn0
I0929 10:16:46.376896 22954 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I0929 10:16:46.376905 22954 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I0929 10:16:46.377157 22954 net.cpp:172] Setting up conv4_2_bn0
I0929 10:16:46.377167 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.377171 22954 net.cpp:194] Memory required for data: 513278464
I0929 10:16:46.377180 22954 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0929 10:16:46.377187 22954 net.cpp:128] Creating Layer conv4_2_scale0
I0929 10:16:46.377192 22954 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I0929 10:16:46.377200 22954 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I0929 10:16:46.377239 22954 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0929 10:16:46.377418 22954 net.cpp:172] Setting up conv4_2_scale0
I0929 10:16:46.377429 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.377432 22954 net.cpp:194] Memory required for data: 515375616
I0929 10:16:46.377440 22954 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I0929 10:16:46.377446 22954 net.cpp:128] Creating Layer conv4_2_ReLU0
I0929 10:16:46.377450 22954 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I0929 10:16:46.377456 22954 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I0929 10:16:46.378926 22954 net.cpp:172] Setting up conv4_2_ReLU0
I0929 10:16:46.378952 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.378957 22954 net.cpp:194] Memory required for data: 517472768
I0929 10:16:46.378962 22954 layer_factory.hpp:77] Creating layer conv4_2_1
I0929 10:16:46.378985 22954 net.cpp:128] Creating Layer conv4_2_1
I0929 10:16:46.378999 22954 net.cpp:558] conv4_2_1 <- conv4_2_0
I0929 10:16:46.379007 22954 net.cpp:522] conv4_2_1 -> conv4_2_1
I0929 10:16:46.385844 22954 net.cpp:172] Setting up conv4_2_1
I0929 10:16:46.385872 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.385877 22954 net.cpp:194] Memory required for data: 519569920
I0929 10:16:46.385887 22954 layer_factory.hpp:77] Creating layer conv4_2bn1
I0929 10:16:46.385896 22954 net.cpp:128] Creating Layer conv4_2bn1
I0929 10:16:46.385901 22954 net.cpp:558] conv4_2bn1 <- conv4_2_1
I0929 10:16:46.385910 22954 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I0929 10:16:46.386196 22954 net.cpp:172] Setting up conv4_2bn1
I0929 10:16:46.386210 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.386215 22954 net.cpp:194] Memory required for data: 521667072
I0929 10:16:46.386238 22954 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0929 10:16:46.386246 22954 net.cpp:128] Creating Layer conv4_2_scale1
I0929 10:16:46.386250 22954 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I0929 10:16:46.386260 22954 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I0929 10:16:46.386301 22954 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0929 10:16:46.386446 22954 net.cpp:172] Setting up conv4_2_scale1
I0929 10:16:46.386454 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.386457 22954 net.cpp:194] Memory required for data: 523764224
I0929 10:16:46.386466 22954 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I0929 10:16:46.386471 22954 net.cpp:128] Creating Layer conv4_Eltwise_2
I0929 10:16:46.386476 22954 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0929 10:16:46.386499 22954 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I0929 10:16:46.386507 22954 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I0929 10:16:46.386528 22954 net.cpp:172] Setting up conv4_Eltwise_2
I0929 10:16:46.386535 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.386539 22954 net.cpp:194] Memory required for data: 525861376
I0929 10:16:46.386543 22954 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I0929 10:16:46.386551 22954 net.cpp:128] Creating Layer conv4_2ReLU_1
I0929 10:16:46.386556 22954 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I0929 10:16:46.386561 22954 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I0929 10:16:46.387758 22954 net.cpp:172] Setting up conv4_2ReLU_1
I0929 10:16:46.387775 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.387780 22954 net.cpp:194] Memory required for data: 527958528
I0929 10:16:46.387784 22954 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 10:16:46.387794 22954 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 10:16:46.387799 22954 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I0929 10:16:46.387809 22954 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0929 10:16:46.387817 22954 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0929 10:16:46.387867 22954 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 10:16:46.387876 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.387882 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.387887 22954 net.cpp:194] Memory required for data: 532152832
I0929 10:16:46.387890 22954 layer_factory.hpp:77] Creating layer conv4_3_0
I0929 10:16:46.387902 22954 net.cpp:128] Creating Layer conv4_3_0
I0929 10:16:46.387907 22954 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0929 10:16:46.387913 22954 net.cpp:522] conv4_3_0 -> conv4_3_0
I0929 10:16:46.395859 22954 net.cpp:172] Setting up conv4_3_0
I0929 10:16:46.395941 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.395961 22954 net.cpp:194] Memory required for data: 534249984
I0929 10:16:46.396001 22954 layer_factory.hpp:77] Creating layer conv4_3_bn0
I0929 10:16:46.396057 22954 net.cpp:128] Creating Layer conv4_3_bn0
I0929 10:16:46.396090 22954 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I0929 10:16:46.396126 22954 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I0929 10:16:46.397236 22954 net.cpp:172] Setting up conv4_3_bn0
I0929 10:16:46.397272 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.397289 22954 net.cpp:194] Memory required for data: 536347136
I0929 10:16:46.399629 22954 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0929 10:16:46.399652 22954 net.cpp:128] Creating Layer conv4_3_scale0
I0929 10:16:46.399658 22954 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I0929 10:16:46.399672 22954 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I0929 10:16:46.399750 22954 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0929 10:16:46.399951 22954 net.cpp:172] Setting up conv4_3_scale0
I0929 10:16:46.399967 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.399972 22954 net.cpp:194] Memory required for data: 538444288
I0929 10:16:46.399982 22954 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I0929 10:16:46.399991 22954 net.cpp:128] Creating Layer conv4_3_ReLU0
I0929 10:16:46.399997 22954 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I0929 10:16:46.400007 22954 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I0929 10:16:46.400312 22954 net.cpp:172] Setting up conv4_3_ReLU0
I0929 10:16:46.400329 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.400336 22954 net.cpp:194] Memory required for data: 540541440
I0929 10:16:46.400341 22954 layer_factory.hpp:77] Creating layer conv4_3_1
I0929 10:16:46.400362 22954 net.cpp:128] Creating Layer conv4_3_1
I0929 10:16:46.400367 22954 net.cpp:558] conv4_3_1 <- conv4_3_0
I0929 10:16:46.400380 22954 net.cpp:522] conv4_3_1 -> conv4_3_1
I0929 10:16:46.406484 22954 net.cpp:172] Setting up conv4_3_1
I0929 10:16:46.406517 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.406523 22954 net.cpp:194] Memory required for data: 542638592
I0929 10:16:46.406535 22954 layer_factory.hpp:77] Creating layer conv4_3bn1
I0929 10:16:46.406550 22954 net.cpp:128] Creating Layer conv4_3bn1
I0929 10:16:46.406563 22954 net.cpp:558] conv4_3bn1 <- conv4_3_1
I0929 10:16:46.406572 22954 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I0929 10:16:46.406908 22954 net.cpp:172] Setting up conv4_3bn1
I0929 10:16:46.406920 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.406925 22954 net.cpp:194] Memory required for data: 544735744
I0929 10:16:46.406937 22954 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0929 10:16:46.406949 22954 net.cpp:128] Creating Layer conv4_3_scale1
I0929 10:16:46.406955 22954 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I0929 10:16:46.406965 22954 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I0929 10:16:46.407022 22954 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0929 10:16:46.407213 22954 net.cpp:172] Setting up conv4_3_scale1
I0929 10:16:46.407225 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.407232 22954 net.cpp:194] Memory required for data: 546832896
I0929 10:16:46.407240 22954 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I0929 10:16:46.407256 22954 net.cpp:128] Creating Layer conv4_Eltwise_3
I0929 10:16:46.407266 22954 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0929 10:16:46.407274 22954 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I0929 10:16:46.407284 22954 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I0929 10:16:46.407311 22954 net.cpp:172] Setting up conv4_Eltwise_3
I0929 10:16:46.407322 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.407327 22954 net.cpp:194] Memory required for data: 548930048
I0929 10:16:46.407337 22954 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I0929 10:16:46.407348 22954 net.cpp:128] Creating Layer conv4_3ReLU_1
I0929 10:16:46.407357 22954 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I0929 10:16:46.407366 22954 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I0929 10:16:46.408304 22954 net.cpp:172] Setting up conv4_3ReLU_1
I0929 10:16:46.408325 22954 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 10:16:46.408330 22954 net.cpp:194] Memory required for data: 551027200
I0929 10:16:46.408336 22954 layer_factory.hpp:77] Creating layer Pooling1
I0929 10:16:46.408349 22954 net.cpp:128] Creating Layer Pooling1
I0929 10:16:46.408360 22954 net.cpp:558] Pooling1 <- conv4_Eltwise_3
I0929 10:16:46.408372 22954 net.cpp:522] Pooling1 -> Pooling1
I0929 10:16:46.410537 22954 net.cpp:172] Setting up Pooling1
I0929 10:16:46.410557 22954 net.cpp:186] Top shape: 128 64 1 1 (8192)
I0929 10:16:46.410562 22954 net.cpp:194] Memory required for data: 551059968
I0929 10:16:46.410567 22954 layer_factory.hpp:77] Creating layer fc1
I0929 10:16:46.410581 22954 net.cpp:128] Creating Layer fc1
I0929 10:16:46.410590 22954 net.cpp:558] fc1 <- Pooling1
I0929 10:16:46.410600 22954 net.cpp:522] fc1 -> fc1
I0929 10:16:46.410785 22954 net.cpp:172] Setting up fc1
I0929 10:16:46.410796 22954 net.cpp:186] Top shape: 128 10 (1280)
I0929 10:16:46.410800 22954 net.cpp:194] Memory required for data: 551065088
I0929 10:16:46.410810 22954 layer_factory.hpp:77] Creating layer Softmax1
I0929 10:16:46.410818 22954 net.cpp:128] Creating Layer Softmax1
I0929 10:16:46.410826 22954 net.cpp:558] Softmax1 <- fc1
I0929 10:16:46.410832 22954 net.cpp:558] Softmax1 <- label
I0929 10:16:46.410842 22954 net.cpp:522] Softmax1 -> Softmax1
I0929 10:16:46.410858 22954 layer_factory.hpp:77] Creating layer Softmax1
I0929 10:16:46.412808 22954 net.cpp:172] Setting up Softmax1
I0929 10:16:46.412828 22954 net.cpp:186] Top shape: (1)
I0929 10:16:46.412833 22954 net.cpp:189]     with loss weight 1
I0929 10:16:46.412873 22954 net.cpp:194] Memory required for data: 551065092
I0929 10:16:46.412879 22954 net.cpp:301] Softmax1 needs backward computation.
I0929 10:16:46.412909 22954 net.cpp:301] fc1 needs backward computation.
I0929 10:16:46.412914 22954 net.cpp:301] Pooling1 needs backward computation.
I0929 10:16:46.412917 22954 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I0929 10:16:46.412922 22954 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I0929 10:16:46.412930 22954 net.cpp:301] conv4_3_scale1 needs backward computation.
I0929 10:16:46.412935 22954 net.cpp:301] conv4_3bn1 needs backward computation.
I0929 10:16:46.412940 22954 net.cpp:301] conv4_3_1 needs backward computation.
I0929 10:16:46.412943 22954 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I0929 10:16:46.412951 22954 net.cpp:301] conv4_3_scale0 needs backward computation.
I0929 10:16:46.412956 22954 net.cpp:301] conv4_3_bn0 needs backward computation.
I0929 10:16:46.412961 22954 net.cpp:301] conv4_3_0 needs backward computation.
I0929 10:16:46.412966 22954 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I0929 10:16:46.412973 22954 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I0929 10:16:46.412978 22954 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I0929 10:16:46.412986 22954 net.cpp:301] conv4_2_scale1 needs backward computation.
I0929 10:16:46.412994 22954 net.cpp:301] conv4_2bn1 needs backward computation.
I0929 10:16:46.412999 22954 net.cpp:301] conv4_2_1 needs backward computation.
I0929 10:16:46.413004 22954 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I0929 10:16:46.413012 22954 net.cpp:301] conv4_2_scale0 needs backward computation.
I0929 10:16:46.413015 22954 net.cpp:301] conv4_2_bn0 needs backward computation.
I0929 10:16:46.413019 22954 net.cpp:301] conv4_2_0 needs backward computation.
I0929 10:16:46.413028 22954 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I0929 10:16:46.413034 22954 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I0929 10:16:46.413039 22954 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I0929 10:16:46.413048 22954 net.cpp:301] conv4_1_scale_down needs backward computation.
I0929 10:16:46.413053 22954 net.cpp:301] conv4_1_bn_down needs backward computation.
I0929 10:16:46.413058 22954 net.cpp:301] conv4_1_down needs backward computation.
I0929 10:16:46.413065 22954 net.cpp:301] conv4_1_scale1 needs backward computation.
I0929 10:16:46.413070 22954 net.cpp:301] conv4_1bn1 needs backward computation.
I0929 10:16:46.413079 22954 net.cpp:301] conv4_1_1 needs backward computation.
I0929 10:16:46.413084 22954 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I0929 10:16:46.413089 22954 net.cpp:301] conv4_1_scale0 needs backward computation.
I0929 10:16:46.413098 22954 net.cpp:301] conv4_1_bn0 needs backward computation.
I0929 10:16:46.413102 22954 net.cpp:301] conv4_1_0 needs backward computation.
I0929 10:16:46.413108 22954 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I0929 10:16:46.413113 22954 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I0929 10:16:46.413120 22954 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I0929 10:16:46.413125 22954 net.cpp:301] conv3_3_scale1 needs backward computation.
I0929 10:16:46.413130 22954 net.cpp:301] conv3_3bn1 needs backward computation.
I0929 10:16:46.413137 22954 net.cpp:301] conv3_3_1 needs backward computation.
I0929 10:16:46.413142 22954 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I0929 10:16:46.413152 22954 net.cpp:301] conv3_3_scale0 needs backward computation.
I0929 10:16:46.413156 22954 net.cpp:301] conv3_3_bn0 needs backward computation.
I0929 10:16:46.413161 22954 net.cpp:301] conv3_3_0 needs backward computation.
I0929 10:16:46.413166 22954 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I0929 10:16:46.413172 22954 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I0929 10:16:46.413177 22954 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I0929 10:16:46.413185 22954 net.cpp:301] conv3_2_scale1 needs backward computation.
I0929 10:16:46.413189 22954 net.cpp:301] conv3_2bn1 needs backward computation.
I0929 10:16:46.413206 22954 net.cpp:301] conv3_2_1 needs backward computation.
I0929 10:16:46.413213 22954 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I0929 10:16:46.413218 22954 net.cpp:301] conv3_2_scale0 needs backward computation.
I0929 10:16:46.413226 22954 net.cpp:301] conv3_2_bn0 needs backward computation.
I0929 10:16:46.413231 22954 net.cpp:301] conv3_2_0 needs backward computation.
I0929 10:16:46.413236 22954 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I0929 10:16:46.413241 22954 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I0929 10:16:46.413250 22954 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I0929 10:16:46.413255 22954 net.cpp:301] conv3_1_scale_down needs backward computation.
I0929 10:16:46.413260 22954 net.cpp:301] conv3_1_bn_down needs backward computation.
I0929 10:16:46.413269 22954 net.cpp:301] conv3_1_down needs backward computation.
I0929 10:16:46.413273 22954 net.cpp:301] conv3_1_scale1 needs backward computation.
I0929 10:16:46.413278 22954 net.cpp:301] conv3_1bn1 needs backward computation.
I0929 10:16:46.413286 22954 net.cpp:301] conv3_1_1 needs backward computation.
I0929 10:16:46.413293 22954 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I0929 10:16:46.413301 22954 net.cpp:301] conv3_1_scale0 needs backward computation.
I0929 10:16:46.413305 22954 net.cpp:301] conv3_1_bn0 needs backward computation.
I0929 10:16:46.413309 22954 net.cpp:301] conv3_1_0 needs backward computation.
I0929 10:16:46.413314 22954 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I0929 10:16:46.413323 22954 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I0929 10:16:46.413327 22954 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I0929 10:16:46.413333 22954 net.cpp:301] conv2_3_scale1 needs backward computation.
I0929 10:16:46.413341 22954 net.cpp:301] conv2_3bn1 needs backward computation.
I0929 10:16:46.413344 22954 net.cpp:301] conv2_3_1 needs backward computation.
I0929 10:16:46.413349 22954 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I0929 10:16:46.413358 22954 net.cpp:301] conv2_3_scale0 needs backward computation.
I0929 10:16:46.413363 22954 net.cpp:301] conv2_3_bn0 needs backward computation.
I0929 10:16:46.413367 22954 net.cpp:301] conv2_3_0 needs backward computation.
I0929 10:16:46.413373 22954 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I0929 10:16:46.413380 22954 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I0929 10:16:46.413385 22954 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I0929 10:16:46.413390 22954 net.cpp:301] conv2_2_scale1 needs backward computation.
I0929 10:16:46.413404 22954 net.cpp:301] conv2_2bn1 needs backward computation.
I0929 10:16:46.413408 22954 net.cpp:301] conv2_2_1 needs backward computation.
I0929 10:16:46.413414 22954 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I0929 10:16:46.413419 22954 net.cpp:301] conv2_2_scale0 needs backward computation.
I0929 10:16:46.413422 22954 net.cpp:301] conv2_2_bn0 needs backward computation.
I0929 10:16:46.413426 22954 net.cpp:301] conv2_2_0 needs backward computation.
I0929 10:16:46.413431 22954 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I0929 10:16:46.413437 22954 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I0929 10:16:46.413441 22954 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I0929 10:16:46.413447 22954 net.cpp:301] conv2_1_scale1 needs backward computation.
I0929 10:16:46.413452 22954 net.cpp:301] conv2_1bn1 needs backward computation.
I0929 10:16:46.413457 22954 net.cpp:301] conv2_1_1 needs backward computation.
I0929 10:16:46.413461 22954 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I0929 10:16:46.413465 22954 net.cpp:301] conv2_1_scale0 needs backward computation.
I0929 10:16:46.413470 22954 net.cpp:301] conv2_1_bn0 needs backward computation.
I0929 10:16:46.413475 22954 net.cpp:301] conv2_1_0 needs backward computation.
I0929 10:16:46.413491 22954 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I0929 10:16:46.413497 22954 net.cpp:301] conv1/ReLU needs backward computation.
I0929 10:16:46.413502 22954 net.cpp:301] conv1/scale needs backward computation.
I0929 10:16:46.413506 22954 net.cpp:301] conv1/bn needs backward computation.
I0929 10:16:46.413511 22954 net.cpp:301] conv1 needs backward computation.
I0929 10:16:46.413520 22954 net.cpp:303] Data1 does not need backward computation.
I0929 10:16:46.413527 22954 net.cpp:348] This network produces output Softmax1
I0929 10:16:46.413590 22954 net.cpp:363] Network initialization done.
I0929 10:16:46.414906 22954 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./test_ResNet_20.prototxt
I0929 10:16:46.414927 22954 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0929 10:16:46.414937 22954 solver.cpp:277] Creating test net (#0) specified by test_net file: ./test_ResNet_20.prototxt
I0929 10:16:46.415721 22954 net.cpp:82] Initializing net from parameters: 
name: "ResNet-20"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: false
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/test_lmdb"
    batch_size: 10
    backend: LMDB
  }
  image_data_param {
    shuffle: false
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "conv2_1_1"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "conv4_Eltwise_3"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Softmax1"
  type: "SoftmaxWithLoss"
  bottom: "fc1"
  bottom: "label"
  top: "Softmax1"
}
layer {
  name: "prob"
  type: "Accuracy"
  bottom: "fc1"
  bottom: "label"
  top: "prob"
}
I0929 10:16:46.416117 22954 layer_factory.hpp:77] Creating layer Data1
I0929 10:16:46.416214 22954 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/test_lmdb
I0929 10:16:46.416234 22954 net.cpp:128] Creating Layer Data1
I0929 10:16:46.416241 22954 net.cpp:522] Data1 -> data
I0929 10:16:46.416254 22954 net.cpp:522] Data1 -> label
I0929 10:16:46.416410 22954 data_layer.cpp:45] output data size: 10,3,32,32
I0929 10:16:46.423702 22954 net.cpp:172] Setting up Data1
I0929 10:16:46.423727 22954 net.cpp:186] Top shape: 10 3 32 32 (30720)
I0929 10:16:46.423732 22954 net.cpp:186] Top shape: 10 (10)
I0929 10:16:46.423737 22954 net.cpp:194] Memory required for data: 122920
I0929 10:16:46.423743 22954 layer_factory.hpp:77] Creating layer label_Data1_1_split
I0929 10:16:46.423758 22954 net.cpp:128] Creating Layer label_Data1_1_split
I0929 10:16:46.423763 22954 net.cpp:558] label_Data1_1_split <- label
I0929 10:16:46.423769 22954 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_0
I0929 10:16:46.423786 22954 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_1
I0929 10:16:46.423895 22954 net.cpp:172] Setting up label_Data1_1_split
I0929 10:16:46.423907 22954 net.cpp:186] Top shape: 10 (10)
I0929 10:16:46.423913 22954 net.cpp:186] Top shape: 10 (10)
I0929 10:16:46.423916 22954 net.cpp:194] Memory required for data: 123000
I0929 10:16:46.423924 22954 layer_factory.hpp:77] Creating layer conv1
I0929 10:16:46.423943 22954 net.cpp:128] Creating Layer conv1
I0929 10:16:46.423949 22954 net.cpp:558] conv1 <- data
I0929 10:16:46.423955 22954 net.cpp:522] conv1 -> conv1
I0929 10:16:46.430817 22954 net.cpp:172] Setting up conv1
I0929 10:16:46.430841 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.430845 22954 net.cpp:194] Memory required for data: 778360
I0929 10:16:46.430881 22954 layer_factory.hpp:77] Creating layer conv1/bn
I0929 10:16:46.430897 22954 net.cpp:128] Creating Layer conv1/bn
I0929 10:16:46.430907 22954 net.cpp:558] conv1/bn <- conv1
I0929 10:16:46.430917 22954 net.cpp:509] conv1/bn -> conv1 (in-place)
I0929 10:16:46.431193 22954 net.cpp:172] Setting up conv1/bn
I0929 10:16:46.431203 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.431207 22954 net.cpp:194] Memory required for data: 1433720
I0929 10:16:46.431221 22954 layer_factory.hpp:77] Creating layer conv1/scale
I0929 10:16:46.431236 22954 net.cpp:128] Creating Layer conv1/scale
I0929 10:16:46.431241 22954 net.cpp:558] conv1/scale <- conv1
I0929 10:16:46.431246 22954 net.cpp:509] conv1/scale -> conv1 (in-place)
I0929 10:16:46.431301 22954 layer_factory.hpp:77] Creating layer conv1/scale
I0929 10:16:46.431455 22954 net.cpp:172] Setting up conv1/scale
I0929 10:16:46.431468 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.431471 22954 net.cpp:194] Memory required for data: 2089080
I0929 10:16:46.431478 22954 layer_factory.hpp:77] Creating layer conv1/ReLU
I0929 10:16:46.431486 22954 net.cpp:128] Creating Layer conv1/ReLU
I0929 10:16:46.431490 22954 net.cpp:558] conv1/ReLU <- conv1
I0929 10:16:46.431499 22954 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I0929 10:16:46.432493 22954 net.cpp:172] Setting up conv1/ReLU
I0929 10:16:46.432559 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.432591 22954 net.cpp:194] Memory required for data: 2744440
I0929 10:16:46.432615 22954 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I0929 10:16:46.432642 22954 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I0929 10:16:46.432664 22954 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I0929 10:16:46.432693 22954 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I0929 10:16:46.432723 22954 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I0929 10:16:46.434778 22954 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I0929 10:16:46.434886 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.434952 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.435019 22954 net.cpp:194] Memory required for data: 4055160
I0929 10:16:46.435082 22954 layer_factory.hpp:77] Creating layer conv2_1_0
I0929 10:16:46.435158 22954 net.cpp:128] Creating Layer conv2_1_0
I0929 10:16:46.435226 22954 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I0929 10:16:46.435298 22954 net.cpp:522] conv2_1_0 -> conv2_1_0
I0929 10:16:46.439314 22954 net.cpp:172] Setting up conv2_1_0
I0929 10:16:46.439349 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.439355 22954 net.cpp:194] Memory required for data: 4710520
I0929 10:16:46.439476 22954 layer_factory.hpp:77] Creating layer conv2_1_bn0
I0929 10:16:46.439527 22954 net.cpp:128] Creating Layer conv2_1_bn0
I0929 10:16:46.439538 22954 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I0929 10:16:46.439589 22954 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I0929 10:16:46.439975 22954 net.cpp:172] Setting up conv2_1_bn0
I0929 10:16:46.439990 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.440078 22954 net.cpp:194] Memory required for data: 5365880
I0929 10:16:46.440126 22954 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0929 10:16:46.440171 22954 net.cpp:128] Creating Layer conv2_1_scale0
I0929 10:16:46.440182 22954 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I0929 10:16:46.440240 22954 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I0929 10:16:46.440352 22954 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0929 10:16:46.440587 22954 net.cpp:172] Setting up conv2_1_scale0
I0929 10:16:46.440600 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.440640 22954 net.cpp:194] Memory required for data: 6021240
I0929 10:16:46.440702 22954 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I0929 10:16:46.440716 22954 net.cpp:128] Creating Layer conv2_1_ReLU0
I0929 10:16:46.440753 22954 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I0929 10:16:46.440845 22954 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I0929 10:16:46.441424 22954 net.cpp:172] Setting up conv2_1_ReLU0
I0929 10:16:46.441452 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.441458 22954 net.cpp:194] Memory required for data: 6676600
I0929 10:16:46.441529 22954 layer_factory.hpp:77] Creating layer conv2_1_1
I0929 10:16:46.441581 22954 net.cpp:128] Creating Layer conv2_1_1
I0929 10:16:46.441592 22954 net.cpp:558] conv2_1_1 <- conv2_1_0
I0929 10:16:46.441643 22954 net.cpp:522] conv2_1_1 -> conv2_1_1
I0929 10:16:46.448168 22954 net.cpp:172] Setting up conv2_1_1
I0929 10:16:46.448226 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.448323 22954 net.cpp:194] Memory required for data: 7331960
I0929 10:16:46.448388 22954 layer_factory.hpp:77] Creating layer conv2_1bn1
I0929 10:16:46.448451 22954 net.cpp:128] Creating Layer conv2_1bn1
I0929 10:16:46.448474 22954 net.cpp:558] conv2_1bn1 <- conv2_1_1
I0929 10:16:46.448559 22954 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I0929 10:16:46.448959 22954 net.cpp:172] Setting up conv2_1bn1
I0929 10:16:46.448976 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.448982 22954 net.cpp:194] Memory required for data: 7987320
I0929 10:16:46.448997 22954 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0929 10:16:46.449118 22954 net.cpp:128] Creating Layer conv2_1_scale1
I0929 10:16:46.449127 22954 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I0929 10:16:46.449137 22954 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I0929 10:16:46.449277 22954 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0929 10:16:46.449470 22954 net.cpp:172] Setting up conv2_1_scale1
I0929 10:16:46.449484 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.449535 22954 net.cpp:194] Memory required for data: 8642680
I0929 10:16:46.449606 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I0929 10:16:46.449620 22954 net.cpp:128] Creating Layer conv2_Eltwise_1
I0929 10:16:46.449625 22954 net.cpp:558] conv2_Eltwise_1 <- conv1_conv1/ReLU_0_split_1
I0929 10:16:46.449681 22954 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I0929 10:16:46.449736 22954 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I0929 10:16:46.449822 22954 net.cpp:172] Setting up conv2_Eltwise_1
I0929 10:16:46.449834 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.449841 22954 net.cpp:194] Memory required for data: 9298040
I0929 10:16:46.449846 22954 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I0929 10:16:46.449856 22954 net.cpp:128] Creating Layer conv2_1ReLU_1
I0929 10:16:46.449862 22954 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I0929 10:16:46.449867 22954 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I0929 10:16:46.450378 22954 net.cpp:172] Setting up conv2_1ReLU_1
I0929 10:16:46.450397 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.450402 22954 net.cpp:194] Memory required for data: 9953400
I0929 10:16:46.450407 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 10:16:46.450451 22954 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 10:16:46.450520 22954 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I0929 10:16:46.450533 22954 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0929 10:16:46.450574 22954 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0929 10:16:46.450748 22954 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 10:16:46.450762 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.450767 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.450772 22954 net.cpp:194] Memory required for data: 11264120
I0929 10:16:46.450775 22954 layer_factory.hpp:77] Creating layer conv2_2_0
I0929 10:16:46.450827 22954 net.cpp:128] Creating Layer conv2_2_0
I0929 10:16:46.450881 22954 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0929 10:16:46.450889 22954 net.cpp:522] conv2_2_0 -> conv2_2_0
I0929 10:16:46.453271 22954 net.cpp:172] Setting up conv2_2_0
I0929 10:16:46.453299 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.453302 22954 net.cpp:194] Memory required for data: 11919480
I0929 10:16:46.453316 22954 layer_factory.hpp:77] Creating layer conv2_2_bn0
I0929 10:16:46.453331 22954 net.cpp:128] Creating Layer conv2_2_bn0
I0929 10:16:46.453337 22954 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I0929 10:16:46.453346 22954 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I0929 10:16:46.453809 22954 net.cpp:172] Setting up conv2_2_bn0
I0929 10:16:46.453824 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.453827 22954 net.cpp:194] Memory required for data: 12574840
I0929 10:16:46.453869 22954 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0929 10:16:46.453882 22954 net.cpp:128] Creating Layer conv2_2_scale0
I0929 10:16:46.453925 22954 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I0929 10:16:46.453963 22954 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I0929 10:16:46.454130 22954 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0929 10:16:46.454324 22954 net.cpp:172] Setting up conv2_2_scale0
I0929 10:16:46.454339 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.454342 22954 net.cpp:194] Memory required for data: 13230200
I0929 10:16:46.454351 22954 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I0929 10:16:46.454390 22954 net.cpp:128] Creating Layer conv2_2_ReLU0
I0929 10:16:46.454396 22954 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I0929 10:16:46.454440 22954 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I0929 10:16:46.454816 22954 net.cpp:172] Setting up conv2_2_ReLU0
I0929 10:16:46.454833 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.454838 22954 net.cpp:194] Memory required for data: 13885560
I0929 10:16:46.454843 22954 layer_factory.hpp:77] Creating layer conv2_2_1
I0929 10:16:46.454931 22954 net.cpp:128] Creating Layer conv2_2_1
I0929 10:16:46.454972 22954 net.cpp:558] conv2_2_1 <- conv2_2_0
I0929 10:16:46.455003 22954 net.cpp:522] conv2_2_1 -> conv2_2_1
I0929 10:16:46.456423 22954 net.cpp:172] Setting up conv2_2_1
I0929 10:16:46.456449 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.456454 22954 net.cpp:194] Memory required for data: 14540920
I0929 10:16:46.456465 22954 layer_factory.hpp:77] Creating layer conv2_2bn1
I0929 10:16:46.456473 22954 net.cpp:128] Creating Layer conv2_2bn1
I0929 10:16:46.456478 22954 net.cpp:558] conv2_2bn1 <- conv2_2_1
I0929 10:16:46.456487 22954 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I0929 10:16:46.456966 22954 net.cpp:172] Setting up conv2_2bn1
I0929 10:16:46.456980 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.456985 22954 net.cpp:194] Memory required for data: 15196280
I0929 10:16:46.457033 22954 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0929 10:16:46.457067 22954 net.cpp:128] Creating Layer conv2_2_scale1
I0929 10:16:46.457073 22954 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I0929 10:16:46.457079 22954 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I0929 10:16:46.457141 22954 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0929 10:16:46.457291 22954 net.cpp:172] Setting up conv2_2_scale1
I0929 10:16:46.457298 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.457303 22954 net.cpp:194] Memory required for data: 15851640
I0929 10:16:46.457310 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I0929 10:16:46.457319 22954 net.cpp:128] Creating Layer conv2_Eltwise_2
I0929 10:16:46.457325 22954 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0929 10:16:46.457330 22954 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I0929 10:16:46.457337 22954 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I0929 10:16:46.457366 22954 net.cpp:172] Setting up conv2_Eltwise_2
I0929 10:16:46.457373 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.457377 22954 net.cpp:194] Memory required for data: 16507000
I0929 10:16:46.457381 22954 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I0929 10:16:46.457404 22954 net.cpp:128] Creating Layer conv2_2ReLU_1
I0929 10:16:46.457409 22954 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I0929 10:16:46.457414 22954 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I0929 10:16:46.457860 22954 net.cpp:172] Setting up conv2_2ReLU_1
I0929 10:16:46.457877 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.457881 22954 net.cpp:194] Memory required for data: 17162360
I0929 10:16:46.457886 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 10:16:46.457895 22954 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 10:16:46.457898 22954 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I0929 10:16:46.457908 22954 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0929 10:16:46.457917 22954 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0929 10:16:46.457995 22954 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 10:16:46.458004 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.458010 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.458014 22954 net.cpp:194] Memory required for data: 18473080
I0929 10:16:46.458017 22954 layer_factory.hpp:77] Creating layer conv2_3_0
I0929 10:16:46.458029 22954 net.cpp:128] Creating Layer conv2_3_0
I0929 10:16:46.458034 22954 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0929 10:16:46.458043 22954 net.cpp:522] conv2_3_0 -> conv2_3_0
I0929 10:16:46.459857 22954 net.cpp:172] Setting up conv2_3_0
I0929 10:16:46.459879 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.459883 22954 net.cpp:194] Memory required for data: 19128440
I0929 10:16:46.459893 22954 layer_factory.hpp:77] Creating layer conv2_3_bn0
I0929 10:16:46.459905 22954 net.cpp:128] Creating Layer conv2_3_bn0
I0929 10:16:46.459911 22954 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I0929 10:16:46.459918 22954 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I0929 10:16:46.460191 22954 net.cpp:172] Setting up conv2_3_bn0
I0929 10:16:46.460198 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.460202 22954 net.cpp:194] Memory required for data: 19783800
I0929 10:16:46.460212 22954 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0929 10:16:46.460218 22954 net.cpp:128] Creating Layer conv2_3_scale0
I0929 10:16:46.460222 22954 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I0929 10:16:46.460228 22954 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I0929 10:16:46.460279 22954 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0929 10:16:46.460427 22954 net.cpp:172] Setting up conv2_3_scale0
I0929 10:16:46.460434 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.460438 22954 net.cpp:194] Memory required for data: 20439160
I0929 10:16:46.460446 22954 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I0929 10:16:46.460454 22954 net.cpp:128] Creating Layer conv2_3_ReLU0
I0929 10:16:46.460458 22954 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I0929 10:16:46.460465 22954 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I0929 10:16:46.460940 22954 net.cpp:172] Setting up conv2_3_ReLU0
I0929 10:16:46.460956 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.460996 22954 net.cpp:194] Memory required for data: 21094520
I0929 10:16:46.461005 22954 layer_factory.hpp:77] Creating layer conv2_3_1
I0929 10:16:46.461060 22954 net.cpp:128] Creating Layer conv2_3_1
I0929 10:16:46.461068 22954 net.cpp:558] conv2_3_1 <- conv2_3_0
I0929 10:16:46.461110 22954 net.cpp:522] conv2_3_1 -> conv2_3_1
I0929 10:16:46.462497 22954 net.cpp:172] Setting up conv2_3_1
I0929 10:16:46.462524 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.462528 22954 net.cpp:194] Memory required for data: 21749880
I0929 10:16:46.462538 22954 layer_factory.hpp:77] Creating layer conv2_3bn1
I0929 10:16:46.462635 22954 net.cpp:128] Creating Layer conv2_3bn1
I0929 10:16:46.462643 22954 net.cpp:558] conv2_3bn1 <- conv2_3_1
I0929 10:16:46.462692 22954 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I0929 10:16:46.463037 22954 net.cpp:172] Setting up conv2_3bn1
I0929 10:16:46.463050 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.463090 22954 net.cpp:194] Memory required for data: 22405240
I0929 10:16:46.463129 22954 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0929 10:16:46.463140 22954 net.cpp:128] Creating Layer conv2_3_scale1
I0929 10:16:46.463178 22954 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I0929 10:16:46.463187 22954 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I0929 10:16:46.463280 22954 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0929 10:16:46.463467 22954 net.cpp:172] Setting up conv2_3_scale1
I0929 10:16:46.463479 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.463515 22954 net.cpp:194] Memory required for data: 23060600
I0929 10:16:46.463529 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I0929 10:16:46.463587 22954 net.cpp:128] Creating Layer conv2_Eltwise_3
I0929 10:16:46.463596 22954 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0929 10:16:46.463635 22954 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I0929 10:16:46.463646 22954 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I0929 10:16:46.463716 22954 net.cpp:172] Setting up conv2_Eltwise_3
I0929 10:16:46.463726 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.463730 22954 net.cpp:194] Memory required for data: 23715960
I0929 10:16:46.463769 22954 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I0929 10:16:46.463809 22954 net.cpp:128] Creating Layer conv2_3ReLU_1
I0929 10:16:46.463817 22954 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I0929 10:16:46.463857 22954 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I0929 10:16:46.464136 22954 net.cpp:172] Setting up conv2_3ReLU_1
I0929 10:16:46.464150 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.464192 22954 net.cpp:194] Memory required for data: 24371320
I0929 10:16:46.464200 22954 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 10:16:46.464243 22954 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 10:16:46.464251 22954 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I0929 10:16:46.464296 22954 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0929 10:16:46.464309 22954 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0929 10:16:46.464427 22954 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 10:16:46.464437 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.464478 22954 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 10:16:46.464486 22954 net.cpp:194] Memory required for data: 25682040
I0929 10:16:46.464490 22954 layer_factory.hpp:77] Creating layer conv3_1_0
I0929 10:16:46.464560 22954 net.cpp:128] Creating Layer conv3_1_0
I0929 10:16:46.464568 22954 net.cpp:558] conv3_1_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0929 10:16:46.464612 22954 net.cpp:522] conv3_1_0 -> conv3_1_0
I0929 10:16:46.466040 22954 net.cpp:172] Setting up conv3_1_0
I0929 10:16:46.466063 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.466066 22954 net.cpp:194] Memory required for data: 26009720
I0929 10:16:46.466076 22954 layer_factory.hpp:77] Creating layer conv3_1_bn0
I0929 10:16:46.466087 22954 net.cpp:128] Creating Layer conv3_1_bn0
I0929 10:16:46.466092 22954 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I0929 10:16:46.466099 22954 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I0929 10:16:46.466472 22954 net.cpp:172] Setting up conv3_1_bn0
I0929 10:16:46.466485 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.466488 22954 net.cpp:194] Memory required for data: 26337400
I0929 10:16:46.466498 22954 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0929 10:16:46.466552 22954 net.cpp:128] Creating Layer conv3_1_scale0
I0929 10:16:46.466591 22954 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I0929 10:16:46.466624 22954 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I0929 10:16:46.466737 22954 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0929 10:16:46.466926 22954 net.cpp:172] Setting up conv3_1_scale0
I0929 10:16:46.466939 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.466943 22954 net.cpp:194] Memory required for data: 26665080
I0929 10:16:46.466953 22954 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I0929 10:16:46.467005 22954 net.cpp:128] Creating Layer conv3_1_ReLU0
I0929 10:16:46.467044 22954 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I0929 10:16:46.467057 22954 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I0929 10:16:46.467345 22954 net.cpp:172] Setting up conv3_1_ReLU0
I0929 10:16:46.467360 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.467365 22954 net.cpp:194] Memory required for data: 26992760
I0929 10:16:46.467370 22954 layer_factory.hpp:77] Creating layer conv3_1_1
I0929 10:16:46.467445 22954 net.cpp:128] Creating Layer conv3_1_1
I0929 10:16:46.467453 22954 net.cpp:558] conv3_1_1 <- conv3_1_0
I0929 10:16:46.467464 22954 net.cpp:522] conv3_1_1 -> conv3_1_1
I0929 10:16:46.469000 22954 net.cpp:172] Setting up conv3_1_1
I0929 10:16:46.469027 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.469032 22954 net.cpp:194] Memory required for data: 27320440
I0929 10:16:46.469041 22954 layer_factory.hpp:77] Creating layer conv3_1bn1
I0929 10:16:46.469123 22954 net.cpp:128] Creating Layer conv3_1bn1
I0929 10:16:46.469135 22954 net.cpp:558] conv3_1bn1 <- conv3_1_1
I0929 10:16:46.469146 22954 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I0929 10:16:46.469476 22954 net.cpp:172] Setting up conv3_1bn1
I0929 10:16:46.469489 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.469493 22954 net.cpp:194] Memory required for data: 27648120
I0929 10:16:46.469503 22954 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0929 10:16:46.469569 22954 net.cpp:128] Creating Layer conv3_1_scale1
I0929 10:16:46.469578 22954 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I0929 10:16:46.469585 22954 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I0929 10:16:46.469688 22954 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0929 10:16:46.469892 22954 net.cpp:172] Setting up conv3_1_scale1
I0929 10:16:46.469907 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.469913 22954 net.cpp:194] Memory required for data: 27975800
I0929 10:16:46.469923 22954 layer_factory.hpp:77] Creating layer conv3_1_down
I0929 10:16:46.470042 22954 net.cpp:128] Creating Layer conv3_1_down
I0929 10:16:46.470057 22954 net.cpp:558] conv3_1_down <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0929 10:16:46.470067 22954 net.cpp:522] conv3_1_down -> conv3_1_down
I0929 10:16:46.471379 22954 net.cpp:172] Setting up conv3_1_down
I0929 10:16:46.471405 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.471410 22954 net.cpp:194] Memory required for data: 28303480
I0929 10:16:46.471429 22954 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I0929 10:16:46.471441 22954 net.cpp:128] Creating Layer conv3_1_bn_down
I0929 10:16:46.471448 22954 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I0929 10:16:46.471455 22954 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I0929 10:16:46.471720 22954 net.cpp:172] Setting up conv3_1_bn_down
I0929 10:16:46.471729 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.471734 22954 net.cpp:194] Memory required for data: 28631160
I0929 10:16:46.471743 22954 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0929 10:16:46.471750 22954 net.cpp:128] Creating Layer conv3_1_scale_down
I0929 10:16:46.471755 22954 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I0929 10:16:46.471762 22954 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I0929 10:16:46.471812 22954 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0929 10:16:46.471966 22954 net.cpp:172] Setting up conv3_1_scale_down
I0929 10:16:46.471976 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.471999 22954 net.cpp:194] Memory required for data: 28958840
I0929 10:16:46.472008 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I0929 10:16:46.472016 22954 net.cpp:128] Creating Layer conv3_Eltwise_1
I0929 10:16:46.472021 22954 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I0929 10:16:46.472025 22954 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I0929 10:16:46.472034 22954 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I0929 10:16:46.472059 22954 net.cpp:172] Setting up conv3_Eltwise_1
I0929 10:16:46.472065 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.472069 22954 net.cpp:194] Memory required for data: 29286520
I0929 10:16:46.472074 22954 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I0929 10:16:46.472081 22954 net.cpp:128] Creating Layer conv3_1ReLU_1
I0929 10:16:46.472086 22954 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I0929 10:16:46.472091 22954 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I0929 10:16:46.472533 22954 net.cpp:172] Setting up conv3_1ReLU_1
I0929 10:16:46.472553 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.472558 22954 net.cpp:194] Memory required for data: 29614200
I0929 10:16:46.472563 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 10:16:46.472571 22954 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 10:16:46.472578 22954 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I0929 10:16:46.472587 22954 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0929 10:16:46.472599 22954 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0929 10:16:46.472658 22954 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 10:16:46.472668 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.472674 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.472678 22954 net.cpp:194] Memory required for data: 30269560
I0929 10:16:46.472682 22954 layer_factory.hpp:77] Creating layer conv3_2_0
I0929 10:16:46.472693 22954 net.cpp:128] Creating Layer conv3_2_0
I0929 10:16:46.472697 22954 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0929 10:16:46.472707 22954 net.cpp:522] conv3_2_0 -> conv3_2_0
I0929 10:16:46.474339 22954 net.cpp:172] Setting up conv3_2_0
I0929 10:16:46.474361 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.474365 22954 net.cpp:194] Memory required for data: 30597240
I0929 10:16:46.474378 22954 layer_factory.hpp:77] Creating layer conv3_2_bn0
I0929 10:16:46.474390 22954 net.cpp:128] Creating Layer conv3_2_bn0
I0929 10:16:46.474395 22954 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I0929 10:16:46.474402 22954 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I0929 10:16:46.474678 22954 net.cpp:172] Setting up conv3_2_bn0
I0929 10:16:46.474686 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.474690 22954 net.cpp:194] Memory required for data: 30924920
I0929 10:16:46.474700 22954 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0929 10:16:46.474709 22954 net.cpp:128] Creating Layer conv3_2_scale0
I0929 10:16:46.474714 22954 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I0929 10:16:46.474721 22954 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I0929 10:16:46.474771 22954 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0929 10:16:46.474933 22954 net.cpp:172] Setting up conv3_2_scale0
I0929 10:16:46.474943 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.474947 22954 net.cpp:194] Memory required for data: 31252600
I0929 10:16:46.474954 22954 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I0929 10:16:46.474961 22954 net.cpp:128] Creating Layer conv3_2_ReLU0
I0929 10:16:46.474968 22954 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I0929 10:16:46.474977 22954 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I0929 10:16:46.475221 22954 net.cpp:172] Setting up conv3_2_ReLU0
I0929 10:16:46.475234 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.475237 22954 net.cpp:194] Memory required for data: 31580280
I0929 10:16:46.475261 22954 layer_factory.hpp:77] Creating layer conv3_2_1
I0929 10:16:46.475275 22954 net.cpp:128] Creating Layer conv3_2_1
I0929 10:16:46.475283 22954 net.cpp:558] conv3_2_1 <- conv3_2_0
I0929 10:16:46.475293 22954 net.cpp:522] conv3_2_1 -> conv3_2_1
I0929 10:16:46.479830 22954 net.cpp:172] Setting up conv3_2_1
I0929 10:16:46.479857 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.479862 22954 net.cpp:194] Memory required for data: 31907960
I0929 10:16:46.479876 22954 layer_factory.hpp:77] Creating layer conv3_2bn1
I0929 10:16:46.479885 22954 net.cpp:128] Creating Layer conv3_2bn1
I0929 10:16:46.479890 22954 net.cpp:558] conv3_2bn1 <- conv3_2_1
I0929 10:16:46.479903 22954 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I0929 10:16:46.480186 22954 net.cpp:172] Setting up conv3_2bn1
I0929 10:16:46.480197 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.480202 22954 net.cpp:194] Memory required for data: 32235640
I0929 10:16:46.480212 22954 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0929 10:16:46.480219 22954 net.cpp:128] Creating Layer conv3_2_scale1
I0929 10:16:46.480226 22954 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I0929 10:16:46.480231 22954 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I0929 10:16:46.480283 22954 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0929 10:16:46.480440 22954 net.cpp:172] Setting up conv3_2_scale1
I0929 10:16:46.480454 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.480458 22954 net.cpp:194] Memory required for data: 32563320
I0929 10:16:46.480466 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I0929 10:16:46.480473 22954 net.cpp:128] Creating Layer conv3_Eltwise_2
I0929 10:16:46.480479 22954 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0929 10:16:46.480484 22954 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I0929 10:16:46.480489 22954 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I0929 10:16:46.480515 22954 net.cpp:172] Setting up conv3_Eltwise_2
I0929 10:16:46.480521 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.480525 22954 net.cpp:194] Memory required for data: 32891000
I0929 10:16:46.480530 22954 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I0929 10:16:46.480536 22954 net.cpp:128] Creating Layer conv3_2ReLU_1
I0929 10:16:46.480540 22954 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I0929 10:16:46.480548 22954 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I0929 10:16:46.481905 22954 net.cpp:172] Setting up conv3_2ReLU_1
I0929 10:16:46.481923 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.481927 22954 net.cpp:194] Memory required for data: 33218680
I0929 10:16:46.481950 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 10:16:46.481957 22954 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 10:16:46.481966 22954 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I0929 10:16:46.481972 22954 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0929 10:16:46.481981 22954 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0929 10:16:46.482043 22954 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 10:16:46.482050 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.482056 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.482060 22954 net.cpp:194] Memory required for data: 33874040
I0929 10:16:46.482064 22954 layer_factory.hpp:77] Creating layer conv3_3_0
I0929 10:16:46.482079 22954 net.cpp:128] Creating Layer conv3_3_0
I0929 10:16:46.482082 22954 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0929 10:16:46.482092 22954 net.cpp:522] conv3_3_0 -> conv3_3_0
I0929 10:16:46.488687 22954 net.cpp:172] Setting up conv3_3_0
I0929 10:16:46.488714 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.488718 22954 net.cpp:194] Memory required for data: 34201720
I0929 10:16:46.488747 22954 layer_factory.hpp:77] Creating layer conv3_3_bn0
I0929 10:16:46.488765 22954 net.cpp:128] Creating Layer conv3_3_bn0
I0929 10:16:46.488770 22954 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I0929 10:16:46.488777 22954 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I0929 10:16:46.489053 22954 net.cpp:172] Setting up conv3_3_bn0
I0929 10:16:46.489064 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.489068 22954 net.cpp:194] Memory required for data: 34529400
I0929 10:16:46.489078 22954 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0929 10:16:46.489090 22954 net.cpp:128] Creating Layer conv3_3_scale0
I0929 10:16:46.489096 22954 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I0929 10:16:46.489101 22954 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I0929 10:16:46.489154 22954 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0929 10:16:46.489313 22954 net.cpp:172] Setting up conv3_3_scale0
I0929 10:16:46.489326 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.489331 22954 net.cpp:194] Memory required for data: 34857080
I0929 10:16:46.489338 22954 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I0929 10:16:46.489348 22954 net.cpp:128] Creating Layer conv3_3_ReLU0
I0929 10:16:46.489352 22954 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I0929 10:16:46.489361 22954 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I0929 10:16:46.490759 22954 net.cpp:172] Setting up conv3_3_ReLU0
I0929 10:16:46.490787 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.490792 22954 net.cpp:194] Memory required for data: 35184760
I0929 10:16:46.490797 22954 layer_factory.hpp:77] Creating layer conv3_3_1
I0929 10:16:46.490820 22954 net.cpp:128] Creating Layer conv3_3_1
I0929 10:16:46.490825 22954 net.cpp:558] conv3_3_1 <- conv3_3_0
I0929 10:16:46.490839 22954 net.cpp:522] conv3_3_1 -> conv3_3_1
I0929 10:16:46.497560 22954 net.cpp:172] Setting up conv3_3_1
I0929 10:16:46.497587 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.497591 22954 net.cpp:194] Memory required for data: 35512440
I0929 10:16:46.497601 22954 layer_factory.hpp:77] Creating layer conv3_3bn1
I0929 10:16:46.497615 22954 net.cpp:128] Creating Layer conv3_3bn1
I0929 10:16:46.497620 22954 net.cpp:558] conv3_3bn1 <- conv3_3_1
I0929 10:16:46.497627 22954 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I0929 10:16:46.497907 22954 net.cpp:172] Setting up conv3_3bn1
I0929 10:16:46.497918 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.497922 22954 net.cpp:194] Memory required for data: 35840120
I0929 10:16:46.497947 22954 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0929 10:16:46.497957 22954 net.cpp:128] Creating Layer conv3_3_scale1
I0929 10:16:46.497961 22954 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I0929 10:16:46.497967 22954 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I0929 10:16:46.498021 22954 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0929 10:16:46.498188 22954 net.cpp:172] Setting up conv3_3_scale1
I0929 10:16:46.498199 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.498204 22954 net.cpp:194] Memory required for data: 36167800
I0929 10:16:46.498212 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I0929 10:16:46.498219 22954 net.cpp:128] Creating Layer conv3_Eltwise_3
I0929 10:16:46.498224 22954 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0929 10:16:46.498229 22954 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I0929 10:16:46.498239 22954 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I0929 10:16:46.498261 22954 net.cpp:172] Setting up conv3_Eltwise_3
I0929 10:16:46.498268 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.498271 22954 net.cpp:194] Memory required for data: 36495480
I0929 10:16:46.498275 22954 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I0929 10:16:46.498282 22954 net.cpp:128] Creating Layer conv3_3ReLU_1
I0929 10:16:46.498286 22954 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I0929 10:16:46.498294 22954 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I0929 10:16:46.499577 22954 net.cpp:172] Setting up conv3_3ReLU_1
I0929 10:16:46.499593 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.499598 22954 net.cpp:194] Memory required for data: 36823160
I0929 10:16:46.499603 22954 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 10:16:46.499614 22954 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 10:16:46.499619 22954 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I0929 10:16:46.499624 22954 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0929 10:16:46.499632 22954 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0929 10:16:46.499689 22954 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 10:16:46.499696 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.499702 22954 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 10:16:46.499706 22954 net.cpp:194] Memory required for data: 37478520
I0929 10:16:46.499711 22954 layer_factory.hpp:77] Creating layer conv4_1_0
I0929 10:16:46.499723 22954 net.cpp:128] Creating Layer conv4_1_0
I0929 10:16:46.499728 22954 net.cpp:558] conv4_1_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0929 10:16:46.499739 22954 net.cpp:522] conv4_1_0 -> conv4_1_0
I0929 10:16:46.506376 22954 net.cpp:172] Setting up conv4_1_0
I0929 10:16:46.506402 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.506407 22954 net.cpp:194] Memory required for data: 37642360
I0929 10:16:46.506417 22954 layer_factory.hpp:77] Creating layer conv4_1_bn0
I0929 10:16:46.506428 22954 net.cpp:128] Creating Layer conv4_1_bn0
I0929 10:16:46.506434 22954 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I0929 10:16:46.506443 22954 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I0929 10:16:46.506732 22954 net.cpp:172] Setting up conv4_1_bn0
I0929 10:16:46.506743 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.506748 22954 net.cpp:194] Memory required for data: 37806200
I0929 10:16:46.506757 22954 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0929 10:16:46.506765 22954 net.cpp:128] Creating Layer conv4_1_scale0
I0929 10:16:46.506769 22954 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I0929 10:16:46.506778 22954 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I0929 10:16:46.506827 22954 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0929 10:16:46.506990 22954 net.cpp:172] Setting up conv4_1_scale0
I0929 10:16:46.507000 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.507004 22954 net.cpp:194] Memory required for data: 37970040
I0929 10:16:46.507012 22954 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I0929 10:16:46.507019 22954 net.cpp:128] Creating Layer conv4_1_ReLU0
I0929 10:16:46.507022 22954 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I0929 10:16:46.507033 22954 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I0929 10:16:46.508432 22954 net.cpp:172] Setting up conv4_1_ReLU0
I0929 10:16:46.508450 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.508455 22954 net.cpp:194] Memory required for data: 38133880
I0929 10:16:46.508460 22954 layer_factory.hpp:77] Creating layer conv4_1_1
I0929 10:16:46.508472 22954 net.cpp:128] Creating Layer conv4_1_1
I0929 10:16:46.508477 22954 net.cpp:558] conv4_1_1 <- conv4_1_0
I0929 10:16:46.508488 22954 net.cpp:522] conv4_1_1 -> conv4_1_1
I0929 10:16:46.515143 22954 net.cpp:172] Setting up conv4_1_1
I0929 10:16:46.515169 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.515173 22954 net.cpp:194] Memory required for data: 38297720
I0929 10:16:46.515183 22954 layer_factory.hpp:77] Creating layer conv4_1bn1
I0929 10:16:46.515194 22954 net.cpp:128] Creating Layer conv4_1bn1
I0929 10:16:46.515200 22954 net.cpp:558] conv4_1bn1 <- conv4_1_1
I0929 10:16:46.515206 22954 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I0929 10:16:46.515488 22954 net.cpp:172] Setting up conv4_1bn1
I0929 10:16:46.515499 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.515519 22954 net.cpp:194] Memory required for data: 38461560
I0929 10:16:46.515529 22954 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0929 10:16:46.515539 22954 net.cpp:128] Creating Layer conv4_1_scale1
I0929 10:16:46.515544 22954 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I0929 10:16:46.515550 22954 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I0929 10:16:46.515604 22954 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0929 10:16:46.515767 22954 net.cpp:172] Setting up conv4_1_scale1
I0929 10:16:46.515779 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.515784 22954 net.cpp:194] Memory required for data: 38625400
I0929 10:16:46.515791 22954 layer_factory.hpp:77] Creating layer conv4_1_down
I0929 10:16:46.515803 22954 net.cpp:128] Creating Layer conv4_1_down
I0929 10:16:46.515808 22954 net.cpp:558] conv4_1_down <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0929 10:16:46.515820 22954 net.cpp:522] conv4_1_down -> conv4_1_down
I0929 10:16:46.521796 22954 net.cpp:172] Setting up conv4_1_down
I0929 10:16:46.521822 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.521827 22954 net.cpp:194] Memory required for data: 38789240
I0929 10:16:46.521837 22954 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I0929 10:16:46.521848 22954 net.cpp:128] Creating Layer conv4_1_bn_down
I0929 10:16:46.521853 22954 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I0929 10:16:46.521860 22954 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I0929 10:16:46.522162 22954 net.cpp:172] Setting up conv4_1_bn_down
I0929 10:16:46.522176 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.522179 22954 net.cpp:194] Memory required for data: 38953080
I0929 10:16:46.522189 22954 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0929 10:16:46.522197 22954 net.cpp:128] Creating Layer conv4_1_scale_down
I0929 10:16:46.522202 22954 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I0929 10:16:46.522207 22954 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I0929 10:16:46.522262 22954 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0929 10:16:46.522424 22954 net.cpp:172] Setting up conv4_1_scale_down
I0929 10:16:46.522436 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.522440 22954 net.cpp:194] Memory required for data: 39116920
I0929 10:16:46.522449 22954 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I0929 10:16:46.522455 22954 net.cpp:128] Creating Layer conv4_Eltwise_1
I0929 10:16:46.522459 22954 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I0929 10:16:46.522464 22954 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I0929 10:16:46.522472 22954 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I0929 10:16:46.522500 22954 net.cpp:172] Setting up conv4_Eltwise_1
I0929 10:16:46.522511 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.522514 22954 net.cpp:194] Memory required for data: 39280760
I0929 10:16:46.522518 22954 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I0929 10:16:46.522524 22954 net.cpp:128] Creating Layer conv4_1ReLU_1
I0929 10:16:46.522528 22954 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I0929 10:16:46.522534 22954 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I0929 10:16:46.523847 22954 net.cpp:172] Setting up conv4_1ReLU_1
I0929 10:16:46.523869 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.523874 22954 net.cpp:194] Memory required for data: 39444600
I0929 10:16:46.523878 22954 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 10:16:46.523888 22954 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 10:16:46.523893 22954 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I0929 10:16:46.523903 22954 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0929 10:16:46.523912 22954 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0929 10:16:46.523969 22954 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 10:16:46.523978 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.523999 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.524003 22954 net.cpp:194] Memory required for data: 39772280
I0929 10:16:46.524008 22954 layer_factory.hpp:77] Creating layer conv4_2_0
I0929 10:16:46.524020 22954 net.cpp:128] Creating Layer conv4_2_0
I0929 10:16:46.524025 22954 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0929 10:16:46.524032 22954 net.cpp:522] conv4_2_0 -> conv4_2_0
I0929 10:16:46.530860 22954 net.cpp:172] Setting up conv4_2_0
I0929 10:16:46.530889 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.530894 22954 net.cpp:194] Memory required for data: 39936120
I0929 10:16:46.530903 22954 layer_factory.hpp:77] Creating layer conv4_2_bn0
I0929 10:16:46.530912 22954 net.cpp:128] Creating Layer conv4_2_bn0
I0929 10:16:46.530917 22954 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I0929 10:16:46.530926 22954 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I0929 10:16:46.531222 22954 net.cpp:172] Setting up conv4_2_bn0
I0929 10:16:46.531234 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.531239 22954 net.cpp:194] Memory required for data: 40099960
I0929 10:16:46.531249 22954 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0929 10:16:46.531255 22954 net.cpp:128] Creating Layer conv4_2_scale0
I0929 10:16:46.531260 22954 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I0929 10:16:46.531265 22954 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I0929 10:16:46.531321 22954 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0929 10:16:46.531481 22954 net.cpp:172] Setting up conv4_2_scale0
I0929 10:16:46.531493 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.531497 22954 net.cpp:194] Memory required for data: 40263800
I0929 10:16:46.531505 22954 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I0929 10:16:46.531512 22954 net.cpp:128] Creating Layer conv4_2_ReLU0
I0929 10:16:46.531515 22954 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I0929 10:16:46.531522 22954 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I0929 10:16:46.532719 22954 net.cpp:172] Setting up conv4_2_ReLU0
I0929 10:16:46.532735 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.532740 22954 net.cpp:194] Memory required for data: 40427640
I0929 10:16:46.532744 22954 layer_factory.hpp:77] Creating layer conv4_2_1
I0929 10:16:46.532757 22954 net.cpp:128] Creating Layer conv4_2_1
I0929 10:16:46.532763 22954 net.cpp:558] conv4_2_1 <- conv4_2_0
I0929 10:16:46.532769 22954 net.cpp:522] conv4_2_1 -> conv4_2_1
I0929 10:16:46.539511 22954 net.cpp:172] Setting up conv4_2_1
I0929 10:16:46.539537 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.539541 22954 net.cpp:194] Memory required for data: 40591480
I0929 10:16:46.539551 22954 layer_factory.hpp:77] Creating layer conv4_2bn1
I0929 10:16:46.539562 22954 net.cpp:128] Creating Layer conv4_2bn1
I0929 10:16:46.539567 22954 net.cpp:558] conv4_2bn1 <- conv4_2_1
I0929 10:16:46.539577 22954 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I0929 10:16:46.539870 22954 net.cpp:172] Setting up conv4_2bn1
I0929 10:16:46.539881 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.539887 22954 net.cpp:194] Memory required for data: 40755320
I0929 10:16:46.539911 22954 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0929 10:16:46.539919 22954 net.cpp:128] Creating Layer conv4_2_scale1
I0929 10:16:46.539923 22954 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I0929 10:16:46.539932 22954 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I0929 10:16:46.539984 22954 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0929 10:16:46.540145 22954 net.cpp:172] Setting up conv4_2_scale1
I0929 10:16:46.540156 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.540161 22954 net.cpp:194] Memory required for data: 40919160
I0929 10:16:46.540169 22954 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I0929 10:16:46.540179 22954 net.cpp:128] Creating Layer conv4_Eltwise_2
I0929 10:16:46.540184 22954 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0929 10:16:46.540206 22954 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I0929 10:16:46.540213 22954 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I0929 10:16:46.540246 22954 net.cpp:172] Setting up conv4_Eltwise_2
I0929 10:16:46.540253 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.540257 22954 net.cpp:194] Memory required for data: 41083000
I0929 10:16:46.540261 22954 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I0929 10:16:46.540267 22954 net.cpp:128] Creating Layer conv4_2ReLU_1
I0929 10:16:46.540272 22954 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I0929 10:16:46.540279 22954 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I0929 10:16:46.541548 22954 net.cpp:172] Setting up conv4_2ReLU_1
I0929 10:16:46.541563 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.541568 22954 net.cpp:194] Memory required for data: 41246840
I0929 10:16:46.541574 22954 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 10:16:46.541580 22954 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 10:16:46.541584 22954 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I0929 10:16:46.541594 22954 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0929 10:16:46.541604 22954 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0929 10:16:46.541659 22954 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 10:16:46.541667 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.541673 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.541677 22954 net.cpp:194] Memory required for data: 41574520
I0929 10:16:46.541682 22954 layer_factory.hpp:77] Creating layer conv4_3_0
I0929 10:16:46.541693 22954 net.cpp:128] Creating Layer conv4_3_0
I0929 10:16:46.541698 22954 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0929 10:16:46.541708 22954 net.cpp:522] conv4_3_0 -> conv4_3_0
I0929 10:16:46.548509 22954 net.cpp:172] Setting up conv4_3_0
I0929 10:16:46.548537 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.548540 22954 net.cpp:194] Memory required for data: 41738360
I0929 10:16:46.548552 22954 layer_factory.hpp:77] Creating layer conv4_3_bn0
I0929 10:16:46.548563 22954 net.cpp:128] Creating Layer conv4_3_bn0
I0929 10:16:46.548569 22954 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I0929 10:16:46.548576 22954 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I0929 10:16:46.548878 22954 net.cpp:172] Setting up conv4_3_bn0
I0929 10:16:46.548890 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.548895 22954 net.cpp:194] Memory required for data: 41902200
I0929 10:16:46.548904 22954 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0929 10:16:46.548912 22954 net.cpp:128] Creating Layer conv4_3_scale0
I0929 10:16:46.548916 22954 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I0929 10:16:46.548921 22954 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I0929 10:16:46.548976 22954 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0929 10:16:46.549139 22954 net.cpp:172] Setting up conv4_3_scale0
I0929 10:16:46.549150 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.549155 22954 net.cpp:194] Memory required for data: 42066040
I0929 10:16:46.549163 22954 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I0929 10:16:46.549170 22954 net.cpp:128] Creating Layer conv4_3_ReLU0
I0929 10:16:46.549173 22954 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I0929 10:16:46.549181 22954 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I0929 10:16:46.550386 22954 net.cpp:172] Setting up conv4_3_ReLU0
I0929 10:16:46.550402 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.550406 22954 net.cpp:194] Memory required for data: 42229880
I0929 10:16:46.550411 22954 layer_factory.hpp:77] Creating layer conv4_3_1
I0929 10:16:46.550426 22954 net.cpp:128] Creating Layer conv4_3_1
I0929 10:16:46.550431 22954 net.cpp:558] conv4_3_1 <- conv4_3_0
I0929 10:16:46.550441 22954 net.cpp:522] conv4_3_1 -> conv4_3_1
I0929 10:16:46.557139 22954 net.cpp:172] Setting up conv4_3_1
I0929 10:16:46.557165 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.557169 22954 net.cpp:194] Memory required for data: 42393720
I0929 10:16:46.557180 22954 layer_factory.hpp:77] Creating layer conv4_3bn1
I0929 10:16:46.557193 22954 net.cpp:128] Creating Layer conv4_3bn1
I0929 10:16:46.557198 22954 net.cpp:558] conv4_3bn1 <- conv4_3_1
I0929 10:16:46.557204 22954 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I0929 10:16:46.557497 22954 net.cpp:172] Setting up conv4_3bn1
I0929 10:16:46.557508 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.557513 22954 net.cpp:194] Memory required for data: 42557560
I0929 10:16:46.557523 22954 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0929 10:16:46.557530 22954 net.cpp:128] Creating Layer conv4_3_scale1
I0929 10:16:46.557535 22954 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I0929 10:16:46.557541 22954 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I0929 10:16:46.557596 22954 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0929 10:16:46.557763 22954 net.cpp:172] Setting up conv4_3_scale1
I0929 10:16:46.557777 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.557781 22954 net.cpp:194] Memory required for data: 42721400
I0929 10:16:46.557790 22954 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I0929 10:16:46.557796 22954 net.cpp:128] Creating Layer conv4_Eltwise_3
I0929 10:16:46.557801 22954 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0929 10:16:46.557807 22954 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I0929 10:16:46.557816 22954 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I0929 10:16:46.557843 22954 net.cpp:172] Setting up conv4_Eltwise_3
I0929 10:16:46.557852 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.557857 22954 net.cpp:194] Memory required for data: 42885240
I0929 10:16:46.557860 22954 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I0929 10:16:46.557868 22954 net.cpp:128] Creating Layer conv4_3ReLU_1
I0929 10:16:46.557871 22954 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I0929 10:16:46.557876 22954 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I0929 10:16:46.559161 22954 net.cpp:172] Setting up conv4_3ReLU_1
I0929 10:16:46.559186 22954 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 10:16:46.559190 22954 net.cpp:194] Memory required for data: 43049080
I0929 10:16:46.559197 22954 layer_factory.hpp:77] Creating layer Pooling1
I0929 10:16:46.559211 22954 net.cpp:128] Creating Layer Pooling1
I0929 10:16:46.559216 22954 net.cpp:558] Pooling1 <- conv4_Eltwise_3
I0929 10:16:46.559223 22954 net.cpp:522] Pooling1 -> Pooling1
I0929 10:16:46.561393 22954 net.cpp:172] Setting up Pooling1
I0929 10:16:46.561414 22954 net.cpp:186] Top shape: 10 64 1 1 (640)
I0929 10:16:46.561419 22954 net.cpp:194] Memory required for data: 43051640
I0929 10:16:46.561424 22954 layer_factory.hpp:77] Creating layer fc1
I0929 10:16:46.561434 22954 net.cpp:128] Creating Layer fc1
I0929 10:16:46.561439 22954 net.cpp:558] fc1 <- Pooling1
I0929 10:16:46.561452 22954 net.cpp:522] fc1 -> fc1
I0929 10:16:46.561628 22954 net.cpp:172] Setting up fc1
I0929 10:16:46.561640 22954 net.cpp:186] Top shape: 10 10 (100)
I0929 10:16:46.561643 22954 net.cpp:194] Memory required for data: 43052040
I0929 10:16:46.561652 22954 layer_factory.hpp:77] Creating layer fc1_fc1_0_split
I0929 10:16:46.561661 22954 net.cpp:128] Creating Layer fc1_fc1_0_split
I0929 10:16:46.561666 22954 net.cpp:558] fc1_fc1_0_split <- fc1
I0929 10:16:46.561674 22954 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_0
I0929 10:16:46.561682 22954 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_1
I0929 10:16:46.561730 22954 net.cpp:172] Setting up fc1_fc1_0_split
I0929 10:16:46.561739 22954 net.cpp:186] Top shape: 10 10 (100)
I0929 10:16:46.561744 22954 net.cpp:186] Top shape: 10 10 (100)
I0929 10:16:46.561748 22954 net.cpp:194] Memory required for data: 43052840
I0929 10:16:46.561753 22954 layer_factory.hpp:77] Creating layer Softmax1
I0929 10:16:46.561759 22954 net.cpp:128] Creating Layer Softmax1
I0929 10:16:46.561782 22954 net.cpp:558] Softmax1 <- fc1_fc1_0_split_0
I0929 10:16:46.561789 22954 net.cpp:558] Softmax1 <- label_Data1_1_split_0
I0929 10:16:46.561794 22954 net.cpp:522] Softmax1 -> Softmax1
I0929 10:16:46.561805 22954 layer_factory.hpp:77] Creating layer Softmax1
I0929 10:16:46.563712 22954 net.cpp:172] Setting up Softmax1
I0929 10:16:46.563736 22954 net.cpp:186] Top shape: (1)
I0929 10:16:46.563741 22954 net.cpp:189]     with loss weight 1
I0929 10:16:46.563758 22954 net.cpp:194] Memory required for data: 43052844
I0929 10:16:46.563763 22954 layer_factory.hpp:77] Creating layer prob
I0929 10:16:46.563772 22954 net.cpp:128] Creating Layer prob
I0929 10:16:46.563776 22954 net.cpp:558] prob <- fc1_fc1_0_split_1
I0929 10:16:46.563782 22954 net.cpp:558] prob <- label_Data1_1_split_1
I0929 10:16:46.563788 22954 net.cpp:522] prob -> prob
I0929 10:16:46.563799 22954 net.cpp:172] Setting up prob
I0929 10:16:46.563805 22954 net.cpp:186] Top shape: (1)
I0929 10:16:46.563809 22954 net.cpp:194] Memory required for data: 43052848
I0929 10:16:46.563814 22954 net.cpp:303] prob does not need backward computation.
I0929 10:16:46.563819 22954 net.cpp:301] Softmax1 needs backward computation.
I0929 10:16:46.563823 22954 net.cpp:301] fc1_fc1_0_split needs backward computation.
I0929 10:16:46.563828 22954 net.cpp:301] fc1 needs backward computation.
I0929 10:16:46.563832 22954 net.cpp:301] Pooling1 needs backward computation.
I0929 10:16:46.563836 22954 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I0929 10:16:46.563840 22954 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I0929 10:16:46.563845 22954 net.cpp:301] conv4_3_scale1 needs backward computation.
I0929 10:16:46.563849 22954 net.cpp:301] conv4_3bn1 needs backward computation.
I0929 10:16:46.563853 22954 net.cpp:301] conv4_3_1 needs backward computation.
I0929 10:16:46.563858 22954 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I0929 10:16:46.563861 22954 net.cpp:301] conv4_3_scale0 needs backward computation.
I0929 10:16:46.563865 22954 net.cpp:301] conv4_3_bn0 needs backward computation.
I0929 10:16:46.563869 22954 net.cpp:301] conv4_3_0 needs backward computation.
I0929 10:16:46.563874 22954 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I0929 10:16:46.563879 22954 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I0929 10:16:46.563882 22954 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I0929 10:16:46.563887 22954 net.cpp:301] conv4_2_scale1 needs backward computation.
I0929 10:16:46.563891 22954 net.cpp:301] conv4_2bn1 needs backward computation.
I0929 10:16:46.563895 22954 net.cpp:301] conv4_2_1 needs backward computation.
I0929 10:16:46.563900 22954 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I0929 10:16:46.563905 22954 net.cpp:301] conv4_2_scale0 needs backward computation.
I0929 10:16:46.563908 22954 net.cpp:301] conv4_2_bn0 needs backward computation.
I0929 10:16:46.563912 22954 net.cpp:301] conv4_2_0 needs backward computation.
I0929 10:16:46.563916 22954 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I0929 10:16:46.563921 22954 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I0929 10:16:46.563928 22954 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I0929 10:16:46.563932 22954 net.cpp:301] conv4_1_scale_down needs backward computation.
I0929 10:16:46.563937 22954 net.cpp:301] conv4_1_bn_down needs backward computation.
I0929 10:16:46.563941 22954 net.cpp:301] conv4_1_down needs backward computation.
I0929 10:16:46.563946 22954 net.cpp:301] conv4_1_scale1 needs backward computation.
I0929 10:16:46.563951 22954 net.cpp:301] conv4_1bn1 needs backward computation.
I0929 10:16:46.563956 22954 net.cpp:301] conv4_1_1 needs backward computation.
I0929 10:16:46.563959 22954 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I0929 10:16:46.563963 22954 net.cpp:301] conv4_1_scale0 needs backward computation.
I0929 10:16:46.563967 22954 net.cpp:301] conv4_1_bn0 needs backward computation.
I0929 10:16:46.563985 22954 net.cpp:301] conv4_1_0 needs backward computation.
I0929 10:16:46.563992 22954 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I0929 10:16:46.563995 22954 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I0929 10:16:46.564000 22954 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I0929 10:16:46.564005 22954 net.cpp:301] conv3_3_scale1 needs backward computation.
I0929 10:16:46.564013 22954 net.cpp:301] conv3_3bn1 needs backward computation.
I0929 10:16:46.564016 22954 net.cpp:301] conv3_3_1 needs backward computation.
I0929 10:16:46.564020 22954 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I0929 10:16:46.564025 22954 net.cpp:301] conv3_3_scale0 needs backward computation.
I0929 10:16:46.564029 22954 net.cpp:301] conv3_3_bn0 needs backward computation.
I0929 10:16:46.564033 22954 net.cpp:301] conv3_3_0 needs backward computation.
I0929 10:16:46.564038 22954 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I0929 10:16:46.564043 22954 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I0929 10:16:46.564047 22954 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I0929 10:16:46.564052 22954 net.cpp:301] conv3_2_scale1 needs backward computation.
I0929 10:16:46.564056 22954 net.cpp:301] conv3_2bn1 needs backward computation.
I0929 10:16:46.564061 22954 net.cpp:301] conv3_2_1 needs backward computation.
I0929 10:16:46.564065 22954 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I0929 10:16:46.564069 22954 net.cpp:301] conv3_2_scale0 needs backward computation.
I0929 10:16:46.564074 22954 net.cpp:301] conv3_2_bn0 needs backward computation.
I0929 10:16:46.564079 22954 net.cpp:301] conv3_2_0 needs backward computation.
I0929 10:16:46.564082 22954 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I0929 10:16:46.564087 22954 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I0929 10:16:46.564091 22954 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I0929 10:16:46.564096 22954 net.cpp:301] conv3_1_scale_down needs backward computation.
I0929 10:16:46.564101 22954 net.cpp:301] conv3_1_bn_down needs backward computation.
I0929 10:16:46.564105 22954 net.cpp:301] conv3_1_down needs backward computation.
I0929 10:16:46.564110 22954 net.cpp:301] conv3_1_scale1 needs backward computation.
I0929 10:16:46.564115 22954 net.cpp:301] conv3_1bn1 needs backward computation.
I0929 10:16:46.564118 22954 net.cpp:301] conv3_1_1 needs backward computation.
I0929 10:16:46.564123 22954 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I0929 10:16:46.564127 22954 net.cpp:301] conv3_1_scale0 needs backward computation.
I0929 10:16:46.564131 22954 net.cpp:301] conv3_1_bn0 needs backward computation.
I0929 10:16:46.564136 22954 net.cpp:301] conv3_1_0 needs backward computation.
I0929 10:16:46.564141 22954 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I0929 10:16:46.564146 22954 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I0929 10:16:46.564149 22954 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I0929 10:16:46.564154 22954 net.cpp:301] conv2_3_scale1 needs backward computation.
I0929 10:16:46.564159 22954 net.cpp:301] conv2_3bn1 needs backward computation.
I0929 10:16:46.564163 22954 net.cpp:301] conv2_3_1 needs backward computation.
I0929 10:16:46.564167 22954 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I0929 10:16:46.564172 22954 net.cpp:301] conv2_3_scale0 needs backward computation.
I0929 10:16:46.564177 22954 net.cpp:301] conv2_3_bn0 needs backward computation.
I0929 10:16:46.564180 22954 net.cpp:301] conv2_3_0 needs backward computation.
I0929 10:16:46.564185 22954 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I0929 10:16:46.564190 22954 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I0929 10:16:46.564194 22954 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I0929 10:16:46.564199 22954 net.cpp:301] conv2_2_scale1 needs backward computation.
I0929 10:16:46.564203 22954 net.cpp:301] conv2_2bn1 needs backward computation.
I0929 10:16:46.564216 22954 net.cpp:301] conv2_2_1 needs backward computation.
I0929 10:16:46.564221 22954 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I0929 10:16:46.564225 22954 net.cpp:301] conv2_2_scale0 needs backward computation.
I0929 10:16:46.564229 22954 net.cpp:301] conv2_2_bn0 needs backward computation.
I0929 10:16:46.564234 22954 net.cpp:301] conv2_2_0 needs backward computation.
I0929 10:16:46.564239 22954 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I0929 10:16:46.564247 22954 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I0929 10:16:46.564252 22954 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I0929 10:16:46.564257 22954 net.cpp:301] conv2_1_scale1 needs backward computation.
I0929 10:16:46.564261 22954 net.cpp:301] conv2_1bn1 needs backward computation.
I0929 10:16:46.564266 22954 net.cpp:301] conv2_1_1 needs backward computation.
I0929 10:16:46.564270 22954 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I0929 10:16:46.564275 22954 net.cpp:301] conv2_1_scale0 needs backward computation.
I0929 10:16:46.564280 22954 net.cpp:301] conv2_1_bn0 needs backward computation.
I0929 10:16:46.564283 22954 net.cpp:301] conv2_1_0 needs backward computation.
I0929 10:16:46.564288 22954 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I0929 10:16:46.564292 22954 net.cpp:301] conv1/ReLU needs backward computation.
I0929 10:16:46.564297 22954 net.cpp:301] conv1/scale needs backward computation.
I0929 10:16:46.564301 22954 net.cpp:301] conv1/bn needs backward computation.
I0929 10:16:46.564306 22954 net.cpp:301] conv1 needs backward computation.
I0929 10:16:46.564311 22954 net.cpp:303] label_Data1_1_split does not need backward computation.
I0929 10:16:46.564316 22954 net.cpp:303] Data1 does not need backward computation.
I0929 10:16:46.564321 22954 net.cpp:348] This network produces output Softmax1
I0929 10:16:46.564324 22954 net.cpp:348] This network produces output prob
I0929 10:16:46.564388 22954 net.cpp:363] Network initialization done.
I0929 10:16:46.564805 22954 solver.cpp:110] Solver scaffolding done.
I0929 10:16:46.572744 22954 caffe.cpp:313] Starting Optimization
I0929 10:16:46.572767 22954 solver.cpp:425] Solving ResNet-20
I0929 10:16:46.572772 22954 solver.cpp:427] Learning Rate Policy: multistep
I0929 10:16:46.575914 22954 solver.cpp:514] Iteration 0, Testing net (#0)
I0929 10:17:06.441347 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:17:06.549232 22954 solver.cpp:580]     Test net output #0: Softmax1 = 87.3361 (* 1 = 87.3361 loss)
I0929 10:17:06.549259 22954 solver.cpp:580]     Test net output #1: prob = 1
I0929 10:17:06.832515 22954 solver.cpp:357] Iteration 0 (-6.60372e-17 iter/s, 20.2594s/100 iters), loss = 2.54189
I0929 10:17:06.832597 22954 solver.cpp:376]     Train net output #0: Softmax1 = 2.54189 (* 1 = 2.54189 loss)
I0929 10:17:06.832638 22954 sgd_solver.cpp:165] Iteration 0, lr = 0.1
I0929 10:17:32.391551 22954 solver.cpp:357] Iteration 100 (3.91263 iter/s, 25.5582s/100 iters), loss = 1.57901
I0929 10:17:32.391695 22954 solver.cpp:376]     Train net output #0: Softmax1 = 1.57901 (* 1 = 1.57901 loss)
I0929 10:17:32.391705 22954 sgd_solver.cpp:165] Iteration 100, lr = 0.1
I0929 10:17:57.823616 22954 solver.cpp:357] Iteration 200 (3.93186 iter/s, 25.4333s/100 iters), loss = 1.26609
I0929 10:17:57.823702 22954 solver.cpp:376]     Train net output #0: Softmax1 = 1.26609 (* 1 = 1.26609 loss)
I0929 10:17:57.823715 22954 sgd_solver.cpp:165] Iteration 200, lr = 0.1
I0929 10:18:23.221055 22954 solver.cpp:357] Iteration 300 (3.93753 iter/s, 25.3967s/100 iters), loss = 1.22793
I0929 10:18:23.221225 22954 solver.cpp:376]     Train net output #0: Softmax1 = 1.22793 (* 1 = 1.22793 loss)
I0929 10:18:23.221237 22954 sgd_solver.cpp:165] Iteration 300, lr = 0.1
I0929 10:18:45.044656 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:18:48.587219 22954 solver.cpp:357] Iteration 400 (3.94207 iter/s, 25.3674s/100 iters), loss = 1.18137
I0929 10:18:48.587309 22954 solver.cpp:376]     Train net output #0: Softmax1 = 1.18137 (* 1 = 1.18137 loss)
I0929 10:18:48.587323 22954 sgd_solver.cpp:165] Iteration 400, lr = 0.1
I0929 10:19:13.711432 22954 solver.cpp:514] Iteration 500, Testing net (#0)
I0929 10:19:33.350286 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:19:33.457695 22954 solver.cpp:580]     Test net output #0: Softmax1 = 2.901 (* 1 = 2.901 loss)
I0929 10:19:33.457758 22954 solver.cpp:580]     Test net output #1: prob = 0.1585
I0929 10:19:33.670387 22954 solver.cpp:357] Iteration 500 (2.21811 iter/s, 45.0835s/100 iters), loss = 1.04859
I0929 10:19:33.670451 22954 solver.cpp:376]     Train net output #0: Softmax1 = 1.04859 (* 1 = 1.04859 loss)
I0929 10:19:33.670464 22954 sgd_solver.cpp:165] Iteration 500, lr = 0.1
I0929 10:19:59.054054 22954 solver.cpp:357] Iteration 600 (3.93967 iter/s, 25.3829s/100 iters), loss = 0.957743
I0929 10:19:59.054208 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.957743 (* 1 = 0.957743 loss)
I0929 10:19:59.054220 22954 sgd_solver.cpp:165] Iteration 600, lr = 0.1
I0929 10:20:24.389111 22954 solver.cpp:357] Iteration 700 (3.94723 iter/s, 25.3342s/100 iters), loss = 0.781816
I0929 10:20:24.389194 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.781816 (* 1 = 0.781816 loss)
I0929 10:20:24.389206 22954 sgd_solver.cpp:165] Iteration 700, lr = 0.1
I0929 10:20:44.017019 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:20:49.814800 22954 solver.cpp:357] Iteration 800 (3.93316 iter/s, 25.4249s/100 iters), loss = 0.847836
I0929 10:20:49.814879 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.847836 (* 1 = 0.847836 loss)
I0929 10:20:49.814890 22954 sgd_solver.cpp:165] Iteration 800, lr = 0.1
I0929 10:21:15.177593 22954 solver.cpp:357] Iteration 900 (3.94291 iter/s, 25.362s/100 iters), loss = 0.861133
I0929 10:21:15.177760 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.861133 (* 1 = 0.861133 loss)
I0929 10:21:15.177772 22954 sgd_solver.cpp:165] Iteration 900, lr = 0.1
I0929 10:21:40.336875 22954 solver.cpp:514] Iteration 1000, Testing net (#0)
I0929 10:21:59.955488 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:21:59.969820 22954 solver.cpp:580]     Test net output #0: Softmax1 = 3.49538 (* 1 = 3.49538 loss)
I0929 10:21:59.969848 22954 solver.cpp:580]     Test net output #1: prob = 0.131799
I0929 10:22:00.195955 22954 solver.cpp:357] Iteration 1000 (2.2213 iter/s, 45.0186s/100 iters), loss = 0.788605
I0929 10:22:00.196005 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.788605 (* 1 = 0.788605 loss)
I0929 10:22:00.196019 22954 sgd_solver.cpp:165] Iteration 1000, lr = 0.1
I0929 10:22:25.549638 22954 solver.cpp:357] Iteration 1100 (3.94432 iter/s, 25.3529s/100 iters), loss = 0.665886
I0929 10:22:25.549717 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.665886 (* 1 = 0.665886 loss)
I0929 10:22:25.549729 22954 sgd_solver.cpp:165] Iteration 1100, lr = 0.1
I0929 10:22:42.601137 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:22:50.927296 22954 solver.cpp:357] Iteration 1200 (3.9406 iter/s, 25.3769s/100 iters), loss = 0.704612
I0929 10:22:50.927377 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.704612 (* 1 = 0.704612 loss)
I0929 10:22:50.927388 22954 sgd_solver.cpp:165] Iteration 1200, lr = 0.1
I0929 10:23:16.258819 22954 solver.cpp:357] Iteration 1300 (3.94777 iter/s, 25.3307s/100 iters), loss = 0.557055
I0929 10:23:16.259002 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.557055 (* 1 = 0.557055 loss)
I0929 10:23:16.259016 22954 sgd_solver.cpp:165] Iteration 1300, lr = 0.1
I0929 10:23:41.672968 22954 solver.cpp:357] Iteration 1400 (3.93494 iter/s, 25.4134s/100 iters), loss = 0.692657
I0929 10:23:41.673048 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.692657 (* 1 = 0.692657 loss)
I0929 10:23:41.673059 22954 sgd_solver.cpp:165] Iteration 1400, lr = 0.1
I0929 10:24:06.837306 22954 solver.cpp:514] Iteration 1500, Testing net (#0)
I0929 10:24:26.542475 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:24:26.646251 22954 solver.cpp:580]     Test net output #0: Softmax1 = 3.97657 (* 1 = 3.97657 loss)
I0929 10:24:26.646277 22954 solver.cpp:580]     Test net output #1: prob = 0.100699
I0929 10:24:26.646298 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_1500.caffemodel
I0929 10:24:26.663300 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_1500.solverstate
I0929 10:24:26.666160 22954 solver.cpp:593]     Max_acc: 0.100699  with iter: 1500
I0929 10:24:26.877477 22954 solver.cpp:357] Iteration 1500 (2.21275 iter/s, 45.1926s/100 iters), loss = 0.660542
I0929 10:24:26.877566 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.660542 (* 1 = 0.660542 loss)
I0929 10:24:26.877579 22954 sgd_solver.cpp:165] Iteration 1500, lr = 0.1
I0929 10:24:41.754168 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:24:52.355746 22954 solver.cpp:357] Iteration 1600 (3.92705 iter/s, 25.4644s/100 iters), loss = 0.62174
I0929 10:24:52.355829 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.62174 (* 1 = 0.62174 loss)
I0929 10:24:52.355839 22954 sgd_solver.cpp:165] Iteration 1600, lr = 0.1
I0929 10:25:17.740172 22954 solver.cpp:357] Iteration 1700 (3.9414 iter/s, 25.3717s/100 iters), loss = 0.822441
I0929 10:25:17.740339 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.822441 (* 1 = 0.822441 loss)
I0929 10:25:17.740350 22954 sgd_solver.cpp:165] Iteration 1700, lr = 0.1
I0929 10:25:43.135860 22954 solver.cpp:357] Iteration 1800 (3.93951 iter/s, 25.3839s/100 iters), loss = 0.719676
I0929 10:25:43.135938 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.719676 (* 1 = 0.719676 loss)
I0929 10:25:43.135949 22954 sgd_solver.cpp:165] Iteration 1800, lr = 0.1
I0929 10:26:08.520467 22954 solver.cpp:357] Iteration 1900 (3.9411 iter/s, 25.3737s/100 iters), loss = 0.559148
I0929 10:26:08.520645 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.559148 (* 1 = 0.559148 loss)
I0929 10:26:08.520658 22954 sgd_solver.cpp:165] Iteration 1900, lr = 0.1
I0929 10:26:21.013530 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:26:33.717627 22954 solver.cpp:514] Iteration 2000, Testing net (#0)
I0929 10:26:53.502102 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:26:53.560608 22954 solver.cpp:580]     Test net output #0: Softmax1 = 3.23812 (* 1 = 3.23812 loss)
I0929 10:26:53.560636 22954 solver.cpp:580]     Test net output #1: prob = 0.0999995
I0929 10:26:53.560644 22954 solver.cpp:593]     Max_acc: 0.100699  with iter: 1500
I0929 10:26:53.737522 22954 solver.cpp:357] Iteration 2000 (2.21233 iter/s, 45.2012s/100 iters), loss = 0.472509
I0929 10:26:53.737601 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.472509 (* 1 = 0.472509 loss)
I0929 10:26:53.737612 22954 sgd_solver.cpp:165] Iteration 2000, lr = 0.1
I0929 10:27:19.208214 22954 solver.cpp:357] Iteration 2100 (3.92714 iter/s, 25.4638s/100 iters), loss = 0.648217
I0929 10:27:19.208295 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.648217 (* 1 = 0.648217 loss)
I0929 10:27:19.208305 22954 sgd_solver.cpp:165] Iteration 2100, lr = 0.1
I0929 10:27:44.589691 22954 solver.cpp:357] Iteration 2200 (3.94117 iter/s, 25.3732s/100 iters), loss = 0.651032
I0929 10:27:44.589869 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.651032 (* 1 = 0.651032 loss)
I0929 10:27:44.589880 22954 sgd_solver.cpp:165] Iteration 2200, lr = 0.1
I0929 10:28:09.985342 22954 solver.cpp:357] Iteration 2300 (3.93889 iter/s, 25.3878s/100 iters), loss = 0.570261
I0929 10:28:09.985419 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.570261 (* 1 = 0.570261 loss)
I0929 10:28:09.985430 22954 sgd_solver.cpp:165] Iteration 2300, lr = 0.1
I0929 10:28:19.937124 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:28:35.326545 22954 solver.cpp:357] Iteration 2400 (3.94728 iter/s, 25.3339s/100 iters), loss = 0.571722
I0929 10:28:35.326619 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.571722 (* 1 = 0.571722 loss)
I0929 10:28:35.326632 22954 sgd_solver.cpp:165] Iteration 2400, lr = 0.1
I0929 10:29:00.549412 22954 solver.cpp:514] Iteration 2500, Testing net (#0)
I0929 10:29:20.415174 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:29:20.494488 22954 solver.cpp:580]     Test net output #0: Softmax1 = 2.64187 (* 1 = 2.64187 loss)
I0929 10:29:20.494532 22954 solver.cpp:580]     Test net output #1: prob = 0.1758
I0929 10:29:20.494549 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_2500.caffemodel
I0929 10:29:20.504247 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_2500.solverstate
I0929 10:29:20.506760 22954 solver.cpp:593]     Max_acc: 0.1758  with iter: 2500
I0929 10:29:20.733525 22954 solver.cpp:357] Iteration 2500 (2.2028 iter/s, 45.3967s/100 iters), loss = 0.606098
I0929 10:29:20.733585 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.606098 (* 1 = 0.606098 loss)
I0929 10:29:20.733597 22954 sgd_solver.cpp:165] Iteration 2500, lr = 0.1
I0929 10:29:46.087325 22954 solver.cpp:357] Iteration 2600 (3.94515 iter/s, 25.3476s/100 iters), loss = 0.71471
I0929 10:29:46.087507 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.71471 (* 1 = 0.71471 loss)
I0929 10:29:46.087519 22954 sgd_solver.cpp:165] Iteration 2600, lr = 0.1
I0929 10:30:11.405915 22954 solver.cpp:357] Iteration 2700 (3.95058 iter/s, 25.3127s/100 iters), loss = 0.690211
I0929 10:30:11.405995 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.690211 (* 1 = 0.690211 loss)
I0929 10:30:11.406008 22954 sgd_solver.cpp:165] Iteration 2700, lr = 0.1
I0929 10:30:19.060513 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:30:36.723564 22954 solver.cpp:357] Iteration 2800 (3.95068 iter/s, 25.3121s/100 iters), loss = 0.495156
I0929 10:30:36.723635 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.495156 (* 1 = 0.495156 loss)
I0929 10:30:36.723646 22954 sgd_solver.cpp:165] Iteration 2800, lr = 0.1
I0929 10:31:02.053890 22954 solver.cpp:357] Iteration 2900 (3.94866 iter/s, 25.325s/100 iters), loss = 0.679055
I0929 10:31:02.054059 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.679055 (* 1 = 0.679055 loss)
I0929 10:31:02.054070 22954 sgd_solver.cpp:165] Iteration 2900, lr = 0.1
I0929 10:31:27.153183 22954 solver.cpp:514] Iteration 3000, Testing net (#0)
I0929 10:31:46.833499 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:31:46.946182 22954 solver.cpp:580]     Test net output #0: Softmax1 = 3.02617 (* 1 = 3.02617 loss)
I0929 10:31:46.946210 22954 solver.cpp:580]     Test net output #1: prob = 0.104799
I0929 10:31:46.946218 22954 solver.cpp:593]     Max_acc: 0.1758  with iter: 2500
I0929 10:31:47.155105 22954 solver.cpp:357] Iteration 3000 (2.21758 iter/s, 45.0941s/100 iters), loss = 0.616669
I0929 10:31:47.155194 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.616669 (* 1 = 0.616669 loss)
I0929 10:31:47.155207 22954 sgd_solver.cpp:165] Iteration 3000, lr = 0.1
I0929 10:32:12.514859 22954 solver.cpp:357] Iteration 3100 (3.94398 iter/s, 25.3551s/100 iters), loss = 0.608905
I0929 10:32:12.514946 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.608905 (* 1 = 0.608905 loss)
I0929 10:32:12.514957 22954 sgd_solver.cpp:165] Iteration 3100, lr = 0.1
I0929 10:32:17.682150 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:32:37.871125 22954 solver.cpp:357] Iteration 3200 (3.94449 iter/s, 25.3518s/100 iters), loss = 0.591456
I0929 10:32:37.871207 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.591456 (* 1 = 0.591456 loss)
I0929 10:32:37.871218 22954 sgd_solver.cpp:165] Iteration 3200, lr = 0.1
I0929 10:33:03.184904 22954 solver.cpp:357] Iteration 3300 (3.95109 iter/s, 25.3095s/100 iters), loss = 0.559366
I0929 10:33:03.185103 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.559366 (* 1 = 0.559366 loss)
I0929 10:33:03.185115 22954 sgd_solver.cpp:165] Iteration 3300, lr = 0.1
I0929 10:33:28.506250 22954 solver.cpp:357] Iteration 3400 (3.94988 iter/s, 25.3172s/100 iters), loss = 0.409481
I0929 10:33:28.506326 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.409481 (* 1 = 0.409481 loss)
I0929 10:33:28.506337 22954 sgd_solver.cpp:165] Iteration 3400, lr = 0.1
I0929 10:33:53.563134 22954 solver.cpp:514] Iteration 3500, Testing net (#0)
I0929 10:34:13.503479 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:34:13.551753 22954 solver.cpp:580]     Test net output #0: Softmax1 = 2.63328 (* 1 = 2.63328 loss)
I0929 10:34:13.551784 22954 solver.cpp:580]     Test net output #1: prob = 0.236
I0929 10:34:13.551800 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_3500.caffemodel
I0929 10:34:13.561971 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_3500.solverstate
I0929 10:34:13.564653 22954 solver.cpp:593]     Max_acc: 0.236  with iter: 3500
I0929 10:34:13.803683 22954 solver.cpp:357] Iteration 3500 (2.20789 iter/s, 45.2921s/100 iters), loss = 0.59829
I0929 10:34:13.803733 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.59829 (* 1 = 0.59829 loss)
I0929 10:34:13.803745 22954 sgd_solver.cpp:165] Iteration 3500, lr = 0.1
I0929 10:34:16.727615 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:34:39.179651 22954 solver.cpp:357] Iteration 3600 (3.94133 iter/s, 25.3722s/100 iters), loss = 0.578238
I0929 10:34:39.179798 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.578238 (* 1 = 0.578238 loss)
I0929 10:34:39.179808 22954 sgd_solver.cpp:165] Iteration 3600, lr = 0.1
I0929 10:35:04.559952 22954 solver.cpp:357] Iteration 3700 (3.94032 iter/s, 25.3786s/100 iters), loss = 0.527054
I0929 10:35:04.560030 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.527054 (* 1 = 0.527054 loss)
I0929 10:35:04.560041 22954 sgd_solver.cpp:165] Iteration 3700, lr = 0.1
I0929 10:35:29.865478 22954 solver.cpp:357] Iteration 3800 (3.95193 iter/s, 25.3041s/100 iters), loss = 0.468326
I0929 10:35:29.865649 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.468326 (* 1 = 0.468326 loss)
I0929 10:35:29.865664 22954 sgd_solver.cpp:165] Iteration 3800, lr = 0.1
I0929 10:35:55.199982 22954 solver.cpp:357] Iteration 3900 (3.94774 iter/s, 25.331s/100 iters), loss = 0.62006
I0929 10:35:55.200132 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.62006 (* 1 = 0.62006 loss)
I0929 10:35:55.200150 22954 sgd_solver.cpp:165] Iteration 3900, lr = 0.1
I0929 10:35:55.710589 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:36:20.272626 22954 solver.cpp:514] Iteration 4000, Testing net (#0)
I0929 10:36:40.071040 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:36:40.177245 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.45298 (* 1 = 1.45298 loss)
I0929 10:36:40.177273 22954 solver.cpp:580]     Test net output #1: prob = 0.4994
I0929 10:36:40.177287 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_4000.caffemodel
I0929 10:36:40.186403 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_4000.solverstate
I0929 10:36:40.188722 22954 solver.cpp:593]     Max_acc: 0.4994  with iter: 4000
I0929 10:36:40.410143 22954 solver.cpp:357] Iteration 4000 (2.212 iter/s, 45.2079s/100 iters), loss = 0.505255
I0929 10:36:40.410210 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.505255 (* 1 = 0.505255 loss)
I0929 10:36:40.410221 22954 sgd_solver.cpp:165] Iteration 4000, lr = 0.1
I0929 10:37:05.718093 22954 solver.cpp:357] Iteration 4100 (3.95151 iter/s, 25.3068s/100 iters), loss = 0.561381
I0929 10:37:05.718350 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.561381 (* 1 = 0.561381 loss)
I0929 10:37:05.718364 22954 sgd_solver.cpp:165] Iteration 4100, lr = 0.1
I0929 10:37:30.982218 22954 solver.cpp:357] Iteration 4200 (3.95843 iter/s, 25.2625s/100 iters), loss = 0.520231
I0929 10:37:30.982291 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.520231 (* 1 = 0.520231 loss)
I0929 10:37:30.982301 22954 sgd_solver.cpp:165] Iteration 4200, lr = 0.1
I0929 10:37:54.346917 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:37:56.351198 22954 solver.cpp:357] Iteration 4300 (3.94231 iter/s, 25.3658s/100 iters), loss = 0.562127
I0929 10:37:56.351286 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.562127 (* 1 = 0.562127 loss)
I0929 10:37:56.351300 22954 sgd_solver.cpp:165] Iteration 4300, lr = 0.1
I0929 10:38:21.688190 22954 solver.cpp:357] Iteration 4400 (3.94729 iter/s, 25.3339s/100 iters), loss = 0.473406
I0929 10:38:21.688274 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.473406 (* 1 = 0.473406 loss)
I0929 10:38:21.688287 22954 sgd_solver.cpp:165] Iteration 4400, lr = 0.1
I0929 10:38:46.749696 22954 solver.cpp:514] Iteration 4500, Testing net (#0)
I0929 10:39:06.404736 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:39:06.479126 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.77562 (* 1 = 1.77562 loss)
I0929 10:39:06.479167 22954 solver.cpp:580]     Test net output #1: prob = 0.378799
I0929 10:39:06.479174 22954 solver.cpp:593]     Max_acc: 0.4994  with iter: 4000
I0929 10:39:06.693068 22954 solver.cpp:357] Iteration 4500 (2.22209 iter/s, 45.0028s/100 iters), loss = 0.494607
I0929 10:39:06.693130 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.494607 (* 1 = 0.494607 loss)
I0929 10:39:06.693141 22954 sgd_solver.cpp:165] Iteration 4500, lr = 0.1
I0929 10:39:31.997323 22954 solver.cpp:357] Iteration 4600 (3.95238 iter/s, 25.3012s/100 iters), loss = 0.426927
I0929 10:39:31.997447 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.426927 (* 1 = 0.426927 loss)
I0929 10:39:31.997458 22954 sgd_solver.cpp:165] Iteration 4600, lr = 0.1
I0929 10:39:53.065390 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:39:57.316910 22954 solver.cpp:357] Iteration 4700 (3.94998 iter/s, 25.3166s/100 iters), loss = 0.328454
I0929 10:39:57.316987 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.328454 (* 1 = 0.328454 loss)
I0929 10:39:57.316998 22954 sgd_solver.cpp:165] Iteration 4700, lr = 0.1
I0929 10:40:22.627455 22954 solver.cpp:357] Iteration 4800 (3.95138 iter/s, 25.3076s/100 iters), loss = 0.470969
I0929 10:40:22.627629 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.470969 (* 1 = 0.470969 loss)
I0929 10:40:22.627641 22954 sgd_solver.cpp:165] Iteration 4800, lr = 0.1
I0929 10:40:47.950865 22954 solver.cpp:357] Iteration 4900 (3.94937 iter/s, 25.3205s/100 iters), loss = 0.465251
I0929 10:40:47.950944 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.465251 (* 1 = 0.465251 loss)
I0929 10:40:47.950955 22954 sgd_solver.cpp:165] Iteration 4900, lr = 0.1
I0929 10:41:13.060084 22954 solver.cpp:514] Iteration 5000, Testing net (#0)
I0929 10:41:32.607450 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:41:32.713098 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.1939 (* 1 = 1.1939 loss)
I0929 10:41:32.713126 22954 solver.cpp:580]     Test net output #1: prob = 0.609
I0929 10:41:32.713142 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_5000.caffemodel
I0929 10:41:32.722749 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_5000.solverstate
I0929 10:41:32.725380 22954 solver.cpp:593]     Max_acc: 0.609  with iter: 5000
I0929 10:41:32.957438 22954 solver.cpp:357] Iteration 5000 (2.22198 iter/s, 45.0049s/100 iters), loss = 0.379123
I0929 10:41:32.957494 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.379123 (* 1 = 0.379123 loss)
I0929 10:41:32.957505 22954 sgd_solver.cpp:165] Iteration 5000, lr = 0.1
I0929 10:41:51.744083 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:41:58.318259 22954 solver.cpp:357] Iteration 5100 (3.94327 iter/s, 25.3597s/100 iters), loss = 0.47386
I0929 10:41:58.318348 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.47386 (* 1 = 0.47386 loss)
I0929 10:41:58.318361 22954 sgd_solver.cpp:165] Iteration 5100, lr = 0.1
I0929 10:42:23.630183 22954 solver.cpp:357] Iteration 5200 (3.95089 iter/s, 25.3107s/100 iters), loss = 0.700914
I0929 10:42:23.630376 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.700914 (* 1 = 0.700914 loss)
I0929 10:42:23.630390 22954 sgd_solver.cpp:165] Iteration 5200, lr = 0.1
I0929 10:42:48.903403 22954 solver.cpp:357] Iteration 5300 (3.95696 iter/s, 25.2719s/100 iters), loss = 0.542419
I0929 10:42:48.903466 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.542419 (* 1 = 0.542419 loss)
I0929 10:42:48.903475 22954 sgd_solver.cpp:165] Iteration 5300, lr = 0.1
I0929 10:43:14.289949 22954 solver.cpp:357] Iteration 5400 (3.93899 iter/s, 25.3872s/100 iters), loss = 0.355027
I0929 10:43:14.290143 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.355027 (* 1 = 0.355027 loss)
I0929 10:43:14.290156 22954 sgd_solver.cpp:165] Iteration 5400, lr = 0.1
I0929 10:43:30.504811 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:43:39.358276 22954 solver.cpp:514] Iteration 5500, Testing net (#0)
I0929 10:43:59.002202 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:43:59.047338 22954 solver.cpp:580]     Test net output #0: Softmax1 = 2.42785 (* 1 = 2.42785 loss)
I0929 10:43:59.047379 22954 solver.cpp:580]     Test net output #1: prob = 0.4311
I0929 10:43:59.047387 22954 solver.cpp:593]     Max_acc: 0.609  with iter: 5000
I0929 10:43:59.264529 22954 solver.cpp:357] Iteration 5500 (2.22344 iter/s, 44.9754s/100 iters), loss = 0.340565
I0929 10:43:59.264591 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.340565 (* 1 = 0.340565 loss)
I0929 10:43:59.264603 22954 sgd_solver.cpp:165] Iteration 5500, lr = 0.1
I0929 10:44:24.565424 22954 solver.cpp:357] Iteration 5600 (3.95266 iter/s, 25.2994s/100 iters), loss = 0.522336
I0929 10:44:24.565495 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.522336 (* 1 = 0.522336 loss)
I0929 10:44:24.565506 22954 sgd_solver.cpp:165] Iteration 5600, lr = 0.1
I0929 10:44:49.882702 22954 solver.cpp:357] Iteration 5700 (3.95011 iter/s, 25.3158s/100 iters), loss = 0.420135
I0929 10:44:49.882879 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.420135 (* 1 = 0.420135 loss)
I0929 10:44:49.882890 22954 sgd_solver.cpp:165] Iteration 5700, lr = 0.1
I0929 10:45:15.183773 22954 solver.cpp:357] Iteration 5800 (3.95264 iter/s, 25.2995s/100 iters), loss = 0.364941
I0929 10:45:15.183848 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.364941 (* 1 = 0.364941 loss)
I0929 10:45:15.183858 22954 sgd_solver.cpp:165] Iteration 5800, lr = 0.1
I0929 10:45:29.164129 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:45:40.457501 22954 solver.cpp:357] Iteration 5900 (3.95693 iter/s, 25.2721s/100 iters), loss = 0.645121
I0929 10:45:40.457588 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.645121 (* 1 = 0.645121 loss)
I0929 10:45:40.457602 22954 sgd_solver.cpp:165] Iteration 5900, lr = 0.1
I0929 10:46:05.597663 22954 solver.cpp:514] Iteration 6000, Testing net (#0)
I0929 10:46:25.454843 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:46:25.503460 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.32911 (* 1 = 1.32911 loss)
I0929 10:46:25.503490 22954 solver.cpp:580]     Test net output #1: prob = 0.5834
I0929 10:46:25.503497 22954 solver.cpp:593]     Max_acc: 0.609  with iter: 5000
I0929 10:46:25.740169 22954 solver.cpp:357] Iteration 6000 (2.20841 iter/s, 45.2814s/100 iters), loss = 0.441312
I0929 10:46:25.740211 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.441312 (* 1 = 0.441312 loss)
I0929 10:46:25.740221 22954 sgd_solver.cpp:165] Iteration 6000, lr = 0.1
I0929 10:46:50.989598 22954 solver.cpp:357] Iteration 6100 (3.96076 iter/s, 25.2477s/100 iters), loss = 0.448093
I0929 10:46:50.989856 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.448093 (* 1 = 0.448093 loss)
I0929 10:46:50.989868 22954 sgd_solver.cpp:165] Iteration 6100, lr = 0.1
I0929 10:47:16.298882 22954 solver.cpp:357] Iteration 6200 (3.9514 iter/s, 25.3075s/100 iters), loss = 0.446592
I0929 10:47:16.298964 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.446592 (* 1 = 0.446592 loss)
I0929 10:47:16.298975 22954 sgd_solver.cpp:165] Iteration 6200, lr = 0.1
I0929 10:47:27.466343 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:47:41.339783 22954 solver.cpp:357] Iteration 6300 (3.99376 iter/s, 25.0391s/100 iters), loss = 0.391376
I0929 10:47:41.339864 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.391376 (* 1 = 0.391376 loss)
I0929 10:47:41.339874 22954 sgd_solver.cpp:165] Iteration 6300, lr = 0.1
I0929 10:48:06.658689 22954 solver.cpp:357] Iteration 6400 (3.9499 iter/s, 25.3171s/100 iters), loss = 0.64338
I0929 10:48:06.658864 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.64338 (* 1 = 0.64338 loss)
I0929 10:48:06.658874 22954 sgd_solver.cpp:165] Iteration 6400, lr = 0.1
I0929 10:48:31.705402 22954 solver.cpp:514] Iteration 6500, Testing net (#0)
I0929 10:48:51.312582 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:48:51.325479 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.29354 (* 1 = 1.29354 loss)
I0929 10:48:51.325511 22954 solver.cpp:580]     Test net output #1: prob = 0.599
I0929 10:48:51.325518 22954 solver.cpp:593]     Max_acc: 0.609  with iter: 5000
I0929 10:48:51.546458 22954 solver.cpp:357] Iteration 6500 (2.22786 iter/s, 44.8861s/100 iters), loss = 0.408682
I0929 10:48:51.546530 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.408682 (* 1 = 0.408682 loss)
I0929 10:48:51.546541 22954 sgd_solver.cpp:165] Iteration 6500, lr = 0.1
I0929 10:49:16.860330 22954 solver.cpp:357] Iteration 6600 (3.9507 iter/s, 25.312s/100 iters), loss = 0.46142
I0929 10:49:16.860411 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.46142 (* 1 = 0.46142 loss)
I0929 10:49:16.860422 22954 sgd_solver.cpp:165] Iteration 6600, lr = 0.1
I0929 10:49:25.993006 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:49:42.145326 22954 solver.cpp:357] Iteration 6700 (3.95522 iter/s, 25.2831s/100 iters), loss = 0.509872
I0929 10:49:42.145411 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.509872 (* 1 = 0.509872 loss)
I0929 10:49:42.145422 22954 sgd_solver.cpp:165] Iteration 6700, lr = 0.1
I0929 10:50:07.513389 22954 solver.cpp:357] Iteration 6800 (3.94227 iter/s, 25.3661s/100 iters), loss = 0.447431
I0929 10:50:07.513571 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.447431 (* 1 = 0.447431 loss)
I0929 10:50:07.513582 22954 sgd_solver.cpp:165] Iteration 6800, lr = 0.1
I0929 10:50:32.819209 22954 solver.cpp:357] Iteration 6900 (3.95197 iter/s, 25.3038s/100 iters), loss = 0.462913
I0929 10:50:32.819288 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.462913 (* 1 = 0.462913 loss)
I0929 10:50:32.819298 22954 sgd_solver.cpp:165] Iteration 6900, lr = 0.1
I0929 10:50:57.910562 22954 solver.cpp:514] Iteration 7000, Testing net (#0)
I0929 10:51:17.761778 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:51:17.816983 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.989868 (* 1 = 0.989868 loss)
I0929 10:51:17.817023 22954 solver.cpp:580]     Test net output #1: prob = 0.6883
I0929 10:51:17.817035 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_7000.caffemodel
I0929 10:51:17.826109 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_7000.solverstate
I0929 10:51:17.828517 22954 solver.cpp:593]     Max_acc: 0.6883  with iter: 7000
I0929 10:51:18.060775 22954 solver.cpp:357] Iteration 7000 (2.21045 iter/s, 45.2397s/100 iters), loss = 0.465119
I0929 10:51:18.060827 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.465119 (* 1 = 0.465119 loss)
I0929 10:51:18.060838 22954 sgd_solver.cpp:165] Iteration 7000, lr = 0.1
I0929 10:51:25.078742 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:51:43.530056 22954 solver.cpp:357] Iteration 7100 (3.92662 iter/s, 25.4672s/100 iters), loss = 0.534428
I0929 10:51:43.530318 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.534428 (* 1 = 0.534428 loss)
I0929 10:51:43.530330 22954 sgd_solver.cpp:165] Iteration 7100, lr = 0.1
I0929 10:52:08.789849 22954 solver.cpp:357] Iteration 7200 (3.95918 iter/s, 25.2578s/100 iters), loss = 0.674294
I0929 10:52:08.789911 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.674294 (* 1 = 0.674294 loss)
I0929 10:52:08.789921 22954 sgd_solver.cpp:165] Iteration 7200, lr = 0.1
I0929 10:52:34.153527 22954 solver.cpp:357] Iteration 7300 (3.94265 iter/s, 25.3637s/100 iters), loss = 0.396297
I0929 10:52:34.153678 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.396297 (* 1 = 0.396297 loss)
I0929 10:52:34.153692 22954 sgd_solver.cpp:165] Iteration 7300, lr = 0.1
I0929 10:52:59.479085 22954 solver.cpp:357] Iteration 7400 (3.94866 iter/s, 25.325s/100 iters), loss = 0.461126
I0929 10:52:59.479159 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.461126 (* 1 = 0.461126 loss)
I0929 10:52:59.479171 22954 sgd_solver.cpp:165] Iteration 7400, lr = 0.1
I0929 10:53:03.804219 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:53:24.541128 22954 solver.cpp:514] Iteration 7500, Testing net (#0)
I0929 10:53:44.370223 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:53:44.478426 22954 solver.cpp:580]     Test net output #0: Softmax1 = 2.80707 (* 1 = 2.80707 loss)
I0929 10:53:44.478456 22954 solver.cpp:580]     Test net output #1: prob = 0.390899
I0929 10:53:44.478463 22954 solver.cpp:593]     Max_acc: 0.6883  with iter: 7000
I0929 10:53:44.708950 22954 solver.cpp:357] Iteration 7500 (2.21093 iter/s, 45.2299s/100 iters), loss = 0.42854
I0929 10:53:44.709022 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.42854 (* 1 = 0.42854 loss)
I0929 10:53:44.709033 22954 sgd_solver.cpp:165] Iteration 7500, lr = 0.1
I0929 10:54:10.035605 22954 solver.cpp:357] Iteration 7600 (3.94842 iter/s, 25.3266s/100 iters), loss = 0.454863
I0929 10:54:10.035899 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.454863 (* 1 = 0.454863 loss)
I0929 10:54:10.035917 22954 sgd_solver.cpp:165] Iteration 7600, lr = 0.1
I0929 10:54:35.362246 22954 solver.cpp:357] Iteration 7700 (3.94846 iter/s, 25.3264s/100 iters), loss = 0.451966
I0929 10:54:35.362331 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.451966 (* 1 = 0.451966 loss)
I0929 10:54:35.362344 22954 sgd_solver.cpp:165] Iteration 7700, lr = 0.1
I0929 10:55:00.616376 22954 solver.cpp:357] Iteration 7800 (3.95984 iter/s, 25.2536s/100 iters), loss = 0.411449
I0929 10:55:00.616494 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.411449 (* 1 = 0.411449 loss)
I0929 10:55:00.616504 22954 sgd_solver.cpp:165] Iteration 7800, lr = 0.1
I0929 10:55:02.712600 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:55:25.997370 22954 solver.cpp:357] Iteration 7900 (3.9403 iter/s, 25.3787s/100 iters), loss = 0.484226
I0929 10:55:25.997457 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.484226 (* 1 = 0.484226 loss)
I0929 10:55:25.997468 22954 sgd_solver.cpp:165] Iteration 7900, lr = 0.1
I0929 10:55:51.060896 22954 solver.cpp:514] Iteration 8000, Testing net (#0)
I0929 10:56:10.782670 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:56:10.833381 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.01735 (* 1 = 1.01735 loss)
I0929 10:56:10.833412 22954 solver.cpp:580]     Test net output #1: prob = 0.684001
I0929 10:56:10.833420 22954 solver.cpp:593]     Max_acc: 0.6883  with iter: 7000
I0929 10:56:11.072383 22954 solver.cpp:357] Iteration 8000 (2.21855 iter/s, 45.0745s/100 iters), loss = 0.341054
I0929 10:56:11.072430 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.341054 (* 1 = 0.341054 loss)
I0929 10:56:11.072441 22954 sgd_solver.cpp:165] Iteration 8000, lr = 0.1
I0929 10:56:36.508074 22954 solver.cpp:357] Iteration 8100 (3.93183 iter/s, 25.4334s/100 iters), loss = 0.403789
I0929 10:56:36.508374 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.403789 (* 1 = 0.403789 loss)
I0929 10:56:36.508393 22954 sgd_solver.cpp:165] Iteration 8100, lr = 0.1
I0929 10:57:01.583302 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:57:01.811167 22954 solver.cpp:357] Iteration 8200 (3.95215 iter/s, 25.3027s/100 iters), loss = 0.522777
I0929 10:57:01.811256 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.522777 (* 1 = 0.522777 loss)
I0929 10:57:01.811275 22954 sgd_solver.cpp:165] Iteration 8200, lr = 0.1
I0929 10:57:27.053580 22954 solver.cpp:357] Iteration 8300 (3.96161 iter/s, 25.2423s/100 iters), loss = 0.635882
I0929 10:57:27.053733 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.635882 (* 1 = 0.635882 loss)
I0929 10:57:27.053742 22954 sgd_solver.cpp:165] Iteration 8300, lr = 0.1
I0929 10:57:52.432792 22954 solver.cpp:357] Iteration 8400 (3.94028 iter/s, 25.3789s/100 iters), loss = 0.384003
I0929 10:57:52.432881 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.384003 (* 1 = 0.384003 loss)
I0929 10:57:52.432894 22954 sgd_solver.cpp:165] Iteration 8400, lr = 0.1
I0929 10:58:17.486296 22954 solver.cpp:514] Iteration 8500, Testing net (#0)
I0929 10:58:37.209810 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:58:37.304668 22954 solver.cpp:580]     Test net output #0: Softmax1 = 2.78696 (* 1 = 2.78696 loss)
I0929 10:58:37.304698 22954 solver.cpp:580]     Test net output #1: prob = 0.385299
I0929 10:58:37.304706 22954 solver.cpp:593]     Max_acc: 0.6883  with iter: 7000
I0929 10:58:37.543229 22954 solver.cpp:357] Iteration 8500 (2.2169 iter/s, 45.1081s/100 iters), loss = 0.448525
I0929 10:58:37.543275 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.448525 (* 1 = 0.448525 loss)
I0929 10:58:37.543289 22954 sgd_solver.cpp:165] Iteration 8500, lr = 0.1
I0929 10:59:00.184718 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 10:59:02.950254 22954 solver.cpp:357] Iteration 8600 (3.93628 iter/s, 25.4047s/100 iters), loss = 0.413992
I0929 10:59:02.950345 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.413992 (* 1 = 0.413992 loss)
I0929 10:59:02.950357 22954 sgd_solver.cpp:165] Iteration 8600, lr = 0.1
I0929 10:59:28.270361 22954 solver.cpp:357] Iteration 8700 (3.94956 iter/s, 25.3193s/100 iters), loss = 0.449253
I0929 10:59:28.270452 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.449253 (* 1 = 0.449253 loss)
I0929 10:59:28.270465 22954 sgd_solver.cpp:165] Iteration 8700, lr = 0.1
I0929 10:59:53.580492 22954 solver.cpp:357] Iteration 8800 (3.9511 iter/s, 25.3094s/100 iters), loss = 0.509959
I0929 10:59:53.580679 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.509959 (* 1 = 0.509959 loss)
I0929 10:59:53.580693 22954 sgd_solver.cpp:165] Iteration 8800, lr = 0.1
I0929 11:00:18.882050 22954 solver.cpp:357] Iteration 8900 (3.95269 iter/s, 25.2992s/100 iters), loss = 0.43248
I0929 11:00:18.882289 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.43248 (* 1 = 0.43248 loss)
I0929 11:00:18.882303 22954 sgd_solver.cpp:165] Iteration 8900, lr = 0.1
I0929 11:00:39.186240 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:00:43.997339 22954 solver.cpp:514] Iteration 9000, Testing net (#0)
I0929 11:01:03.819275 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:01:03.931465 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.38293 (* 1 = 1.38293 loss)
I0929 11:01:03.931491 22954 solver.cpp:580]     Test net output #1: prob = 0.566701
I0929 11:01:03.931499 22954 solver.cpp:593]     Max_acc: 0.6883  with iter: 7000
I0929 11:01:04.079891 22954 solver.cpp:357] Iteration 9000 (2.21261 iter/s, 45.1954s/100 iters), loss = 0.255479
I0929 11:01:04.079934 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.255479 (* 1 = 0.255479 loss)
I0929 11:01:04.079944 22954 sgd_solver.cpp:165] Iteration 9000, lr = 0.1
I0929 11:01:29.469936 22954 solver.cpp:357] Iteration 9100 (3.93859 iter/s, 25.3898s/100 iters), loss = 0.484926
I0929 11:01:29.470202 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.484926 (* 1 = 0.484926 loss)
I0929 11:01:29.470216 22954 sgd_solver.cpp:165] Iteration 9100, lr = 0.1
I0929 11:01:54.781733 22954 solver.cpp:357] Iteration 9200 (3.9508 iter/s, 25.3113s/100 iters), loss = 0.403016
I0929 11:01:54.781828 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.403016 (* 1 = 0.403016 loss)
I0929 11:01:54.781841 22954 sgd_solver.cpp:165] Iteration 9200, lr = 0.1
I0929 11:02:20.094418 22954 solver.cpp:357] Iteration 9300 (3.95095 iter/s, 25.3104s/100 iters), loss = 0.39474
I0929 11:02:20.094566 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.39474 (* 1 = 0.39474 loss)
I0929 11:02:20.094583 22954 sgd_solver.cpp:165] Iteration 9300, lr = 0.1
I0929 11:02:37.844242 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:02:45.361258 22954 solver.cpp:357] Iteration 9400 (3.95781 iter/s, 25.2665s/100 iters), loss = 0.557722
I0929 11:02:45.361321 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.557722 (* 1 = 0.557722 loss)
I0929 11:02:45.361330 22954 sgd_solver.cpp:165] Iteration 9400, lr = 0.1
I0929 11:03:10.488883 22954 solver.cpp:514] Iteration 9500, Testing net (#0)
I0929 11:03:30.318279 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:03:30.423902 22954 solver.cpp:580]     Test net output #0: Softmax1 = 3.05064 (* 1 = 3.05064 loss)
I0929 11:03:30.423928 22954 solver.cpp:580]     Test net output #1: prob = 0.392299
I0929 11:03:30.423936 22954 solver.cpp:593]     Max_acc: 0.6883  with iter: 7000
I0929 11:03:30.648375 22954 solver.cpp:357] Iteration 9500 (2.20816 iter/s, 45.2867s/100 iters), loss = 0.482826
I0929 11:03:30.648445 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.482826 (* 1 = 0.482826 loss)
I0929 11:03:30.648456 22954 sgd_solver.cpp:165] Iteration 9500, lr = 0.1
I0929 11:03:55.932592 22954 solver.cpp:357] Iteration 9600 (3.95508 iter/s, 25.284s/100 iters), loss = 0.563688
I0929 11:03:55.932785 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.563688 (* 1 = 0.563688 loss)
I0929 11:03:55.932799 22954 sgd_solver.cpp:165] Iteration 9600, lr = 0.1
I0929 11:04:21.273488 22954 solver.cpp:357] Iteration 9700 (3.94656 iter/s, 25.3385s/100 iters), loss = 0.511484
I0929 11:04:21.273579 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.511484 (* 1 = 0.511484 loss)
I0929 11:04:21.273592 22954 sgd_solver.cpp:165] Iteration 9700, lr = 0.1
I0929 11:04:36.755483 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:04:46.585222 22954 solver.cpp:357] Iteration 9800 (3.95111 iter/s, 25.3093s/100 iters), loss = 0.45285
I0929 11:04:46.585314 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.45285 (* 1 = 0.45285 loss)
I0929 11:04:46.585326 22954 sgd_solver.cpp:165] Iteration 9800, lr = 0.1
I0929 11:05:11.912137 22954 solver.cpp:357] Iteration 9900 (3.94875 iter/s, 25.3245s/100 iters), loss = 0.388801
I0929 11:05:11.912367 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.388801 (* 1 = 0.388801 loss)
I0929 11:05:11.912385 22954 sgd_solver.cpp:165] Iteration 9900, lr = 0.1
I0929 11:05:36.931191 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_10000.caffemodel
I0929 11:05:36.942620 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_10000.solverstate
I0929 11:05:36.945806 22954 solver.cpp:514] Iteration 10000, Testing net (#0)
I0929 11:05:56.854223 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:05:56.964395 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.973508 (* 1 = 0.973508 loss)
I0929 11:05:56.964426 22954 solver.cpp:580]     Test net output #1: prob = 0.6811
I0929 11:05:56.964432 22954 solver.cpp:593]     Max_acc: 0.6883  with iter: 7000
I0929 11:05:57.175027 22954 solver.cpp:357] Iteration 10000 (2.20934 iter/s, 45.2623s/100 iters), loss = 0.394618
I0929 11:05:57.175110 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.394618 (* 1 = 0.394618 loss)
I0929 11:05:57.175122 22954 sgd_solver.cpp:165] Iteration 10000, lr = 0.1
I0929 11:06:22.500095 22954 solver.cpp:357] Iteration 10100 (3.94903 iter/s, 25.3226s/100 iters), loss = 0.470786
I0929 11:06:22.500180 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.470786 (* 1 = 0.470786 loss)
I0929 11:06:22.500191 22954 sgd_solver.cpp:165] Iteration 10100, lr = 0.1
I0929 11:06:35.746574 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:06:47.847898 22954 solver.cpp:357] Iteration 10200 (3.94549 iter/s, 25.3454s/100 iters), loss = 0.42549
I0929 11:06:47.847975 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.42549 (* 1 = 0.42549 loss)
I0929 11:06:47.847986 22954 sgd_solver.cpp:165] Iteration 10200, lr = 0.1
I0929 11:07:13.150265 22954 solver.cpp:357] Iteration 10300 (3.95258 iter/s, 25.3s/100 iters), loss = 0.424837
I0929 11:07:13.150452 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.424837 (* 1 = 0.424837 loss)
I0929 11:07:13.150463 22954 sgd_solver.cpp:165] Iteration 10300, lr = 0.1
I0929 11:07:38.467658 22954 solver.cpp:357] Iteration 10400 (3.95023 iter/s, 25.315s/100 iters), loss = 0.516567
I0929 11:07:38.467737 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.516567 (* 1 = 0.516567 loss)
I0929 11:07:38.467749 22954 sgd_solver.cpp:165] Iteration 10400, lr = 0.1
I0929 11:08:03.524722 22954 solver.cpp:514] Iteration 10500, Testing net (#0)
I0929 11:08:23.225970 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:08:23.333809 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.88062 (* 1 = 1.88062 loss)
I0929 11:08:23.333837 22954 solver.cpp:580]     Test net output #1: prob = 0.4673
I0929 11:08:23.333844 22954 solver.cpp:593]     Max_acc: 0.6883  with iter: 7000
I0929 11:08:23.566587 22954 solver.cpp:357] Iteration 10500 (2.21748 iter/s, 45.0963s/100 iters), loss = 0.467323
I0929 11:08:23.566676 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.467323 (* 1 = 0.467323 loss)
I0929 11:08:23.566689 22954 sgd_solver.cpp:165] Iteration 10500, lr = 0.1
I0929 11:08:34.219643 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:08:48.871917 22954 solver.cpp:357] Iteration 10600 (3.95212 iter/s, 25.3029s/100 iters), loss = 0.512801
I0929 11:08:48.872020 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.512801 (* 1 = 0.512801 loss)
I0929 11:08:48.872033 22954 sgd_solver.cpp:165] Iteration 10600, lr = 0.1
I0929 11:09:14.157985 22954 solver.cpp:357] Iteration 10700 (3.95513 iter/s, 25.2836s/100 iters), loss = 0.434557
I0929 11:09:14.158152 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.434557 (* 1 = 0.434557 loss)
I0929 11:09:14.158164 22954 sgd_solver.cpp:165] Iteration 10700, lr = 0.1
I0929 11:09:39.520339 22954 solver.cpp:357] Iteration 10800 (3.94323 iter/s, 25.3599s/100 iters), loss = 0.400592
I0929 11:09:39.520432 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.400592 (* 1 = 0.400592 loss)
I0929 11:09:39.520445 22954 sgd_solver.cpp:165] Iteration 10800, lr = 0.1
I0929 11:10:04.837250 22954 solver.cpp:357] Iteration 10900 (3.9503 iter/s, 25.3145s/100 iters), loss = 0.455882
I0929 11:10:04.837389 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.455882 (* 1 = 0.455882 loss)
I0929 11:10:04.837400 22954 sgd_solver.cpp:165] Iteration 10900, lr = 0.1
I0929 11:10:13.227049 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:10:29.915979 22954 solver.cpp:514] Iteration 11000, Testing net (#0)
I0929 11:10:49.846508 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:10:49.935014 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.955776 (* 1 = 0.955776 loss)
I0929 11:10:49.935053 22954 solver.cpp:580]     Test net output #1: prob = 0.6774
I0929 11:10:49.935060 22954 solver.cpp:593]     Max_acc: 0.6883  with iter: 7000
I0929 11:10:50.147449 22954 solver.cpp:357] Iteration 11000 (2.20714 iter/s, 45.3076s/100 iters), loss = 0.439185
I0929 11:10:50.147511 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.439185 (* 1 = 0.439185 loss)
I0929 11:10:50.147522 22954 sgd_solver.cpp:165] Iteration 11000, lr = 0.1
I0929 11:11:15.463425 22954 solver.cpp:357] Iteration 11100 (3.95046 iter/s, 25.3135s/100 iters), loss = 0.467024
I0929 11:11:15.463506 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.467024 (* 1 = 0.467024 loss)
I0929 11:11:15.463517 22954 sgd_solver.cpp:165] Iteration 11100, lr = 0.1
I0929 11:11:40.739410 22954 solver.cpp:357] Iteration 11200 (3.95671 iter/s, 25.2735s/100 iters), loss = 0.370253
I0929 11:11:40.739626 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.370253 (* 1 = 0.370253 loss)
I0929 11:11:40.739639 22954 sgd_solver.cpp:165] Iteration 11200, lr = 0.1
I0929 11:12:06.092766 22954 solver.cpp:357] Iteration 11300 (3.94463 iter/s, 25.3509s/100 iters), loss = 0.427873
I0929 11:12:06.092844 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.427873 (* 1 = 0.427873 loss)
I0929 11:12:06.092854 22954 sgd_solver.cpp:165] Iteration 11300, lr = 0.1
I0929 11:12:12.240743 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:12:31.415208 22954 solver.cpp:357] Iteration 11400 (3.94945 iter/s, 25.32s/100 iters), loss = 0.429381
I0929 11:12:31.415290 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.429381 (* 1 = 0.429381 loss)
I0929 11:12:31.415302 22954 sgd_solver.cpp:165] Iteration 11400, lr = 0.1
I0929 11:12:56.531893 22954 solver.cpp:514] Iteration 11500, Testing net (#0)
I0929 11:13:16.175747 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:13:16.281455 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.52448 (* 1 = 1.52448 loss)
I0929 11:13:16.281482 22954 solver.cpp:580]     Test net output #1: prob = 0.607
I0929 11:13:16.281489 22954 solver.cpp:593]     Max_acc: 0.6883  with iter: 7000
I0929 11:13:16.504036 22954 solver.cpp:357] Iteration 11500 (2.21797 iter/s, 45.0862s/100 iters), loss = 0.539991
I0929 11:13:16.504108 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.539991 (* 1 = 0.539991 loss)
I0929 11:13:16.504120 22954 sgd_solver.cpp:165] Iteration 11500, lr = 0.1
I0929 11:13:41.821161 22954 solver.cpp:357] Iteration 11600 (3.94995 iter/s, 25.3168s/100 iters), loss = 0.39208
I0929 11:13:41.821316 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.39208 (* 1 = 0.39208 loss)
I0929 11:13:41.821327 22954 sgd_solver.cpp:165] Iteration 11600, lr = 0.1
I0929 11:14:07.160547 22954 solver.cpp:357] Iteration 11700 (3.94649 iter/s, 25.339s/100 iters), loss = 0.532412
I0929 11:14:07.160634 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.532412 (* 1 = 0.532412 loss)
I0929 11:14:07.160646 22954 sgd_solver.cpp:165] Iteration 11700, lr = 0.1
I0929 11:14:10.719885 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:14:32.426646 22954 solver.cpp:357] Iteration 11800 (3.958 iter/s, 25.2653s/100 iters), loss = 0.666775
I0929 11:14:32.426787 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.666775 (* 1 = 0.666775 loss)
I0929 11:14:32.426797 22954 sgd_solver.cpp:165] Iteration 11800, lr = 0.1
I0929 11:14:57.804044 22954 solver.cpp:357] Iteration 11900 (3.94059 iter/s, 25.3769s/100 iters), loss = 0.526235
I0929 11:14:57.804127 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.526235 (* 1 = 0.526235 loss)
I0929 11:14:57.804141 22954 sgd_solver.cpp:165] Iteration 11900, lr = 0.1
I0929 11:15:22.867645 22954 solver.cpp:514] Iteration 12000, Testing net (#0)
I0929 11:15:42.596278 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:15:42.644305 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.14207 (* 1 = 1.14207 loss)
I0929 11:15:42.644356 22954 solver.cpp:580]     Test net output #1: prob = 0.630701
I0929 11:15:42.644366 22954 solver.cpp:593]     Max_acc: 0.6883  with iter: 7000
I0929 11:15:42.882786 22954 solver.cpp:357] Iteration 12000 (2.21847 iter/s, 45.0761s/100 iters), loss = 0.496525
I0929 11:15:42.882863 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.496525 (* 1 = 0.496525 loss)
I0929 11:15:42.882875 22954 sgd_solver.cpp:165] Iteration 12000, lr = 0.1
I0929 11:16:08.313352 22954 solver.cpp:357] Iteration 12100 (3.93211 iter/s, 25.4316s/100 iters), loss = 0.399979
I0929 11:16:08.313560 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.399979 (* 1 = 0.399979 loss)
I0929 11:16:08.313572 22954 sgd_solver.cpp:165] Iteration 12100, lr = 0.1
I0929 11:16:09.607957 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:16:33.622017 22954 solver.cpp:357] Iteration 12200 (3.95055 iter/s, 25.3129s/100 iters), loss = 0.390692
I0929 11:16:33.622108 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.390692 (* 1 = 0.390692 loss)
I0929 11:16:33.622122 22954 sgd_solver.cpp:165] Iteration 12200, lr = 0.1
I0929 11:16:58.886551 22954 solver.cpp:357] Iteration 12300 (3.95755 iter/s, 25.2681s/100 iters), loss = 0.44731
I0929 11:16:58.886706 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.44731 (* 1 = 0.44731 loss)
I0929 11:16:58.886716 22954 sgd_solver.cpp:165] Iteration 12300, lr = 0.1
I0929 11:17:24.245283 22954 solver.cpp:357] Iteration 12400 (3.94282 iter/s, 25.3626s/100 iters), loss = 0.562733
I0929 11:17:24.245370 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.562733 (* 1 = 0.562733 loss)
I0929 11:17:24.245383 22954 sgd_solver.cpp:165] Iteration 12400, lr = 0.1
I0929 11:17:48.318610 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:17:49.314177 22954 solver.cpp:514] Iteration 12500, Testing net (#0)
I0929 11:18:09.009656 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:18:09.115219 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.827176 (* 1 = 0.827176 loss)
I0929 11:18:09.115248 22954 solver.cpp:580]     Test net output #1: prob = 0.706399
I0929 11:18:09.115262 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_12500.caffemodel
I0929 11:18:09.124299 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_12500.solverstate
I0929 11:18:09.126809 22954 solver.cpp:593]     Max_acc: 0.706399  with iter: 12500
I0929 11:18:09.362426 22954 solver.cpp:357] Iteration 12500 (2.21613 iter/s, 45.1236s/100 iters), loss = 0.423164
I0929 11:18:09.362502 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.423164 (* 1 = 0.423164 loss)
I0929 11:18:09.362516 22954 sgd_solver.cpp:165] Iteration 12500, lr = 0.1
I0929 11:18:34.719032 22954 solver.cpp:357] Iteration 12600 (3.94352 iter/s, 25.358s/100 iters), loss = 0.344654
I0929 11:18:34.719171 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.344654 (* 1 = 0.344654 loss)
I0929 11:18:34.719182 22954 sgd_solver.cpp:165] Iteration 12600, lr = 0.1
I0929 11:19:00.006673 22954 solver.cpp:357] Iteration 12700 (3.95403 iter/s, 25.2907s/100 iters), loss = 0.653658
I0929 11:19:00.006765 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.653658 (* 1 = 0.653658 loss)
I0929 11:19:00.006778 22954 sgd_solver.cpp:165] Iteration 12700, lr = 0.1
I0929 11:19:25.331336 22954 solver.cpp:357] Iteration 12800 (3.94854 iter/s, 25.3258s/100 iters), loss = 0.441366
I0929 11:19:25.331513 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.441366 (* 1 = 0.441366 loss)
I0929 11:19:25.331527 22954 sgd_solver.cpp:165] Iteration 12800, lr = 0.1
I0929 11:19:47.111650 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:19:50.606616 22954 solver.cpp:357] Iteration 12900 (3.95602 iter/s, 25.2779s/100 iters), loss = 0.454942
I0929 11:19:50.606766 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.454942 (* 1 = 0.454942 loss)
I0929 11:19:50.606796 22954 sgd_solver.cpp:165] Iteration 12900, lr = 0.1
I0929 11:20:15.717437 22954 solver.cpp:514] Iteration 13000, Testing net (#0)
I0929 11:20:35.401190 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:20:35.415498 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.63877 (* 1 = 1.63877 loss)
I0929 11:20:35.415527 22954 solver.cpp:580]     Test net output #1: prob = 0.5612
I0929 11:20:35.415534 22954 solver.cpp:593]     Max_acc: 0.706399  with iter: 12500
I0929 11:20:35.626534 22954 solver.cpp:357] Iteration 13000 (2.22108 iter/s, 45.0231s/100 iters), loss = 0.362717
I0929 11:20:35.626586 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.362717 (* 1 = 0.362717 loss)
I0929 11:20:35.626597 22954 sgd_solver.cpp:165] Iteration 13000, lr = 0.1
I0929 11:21:00.942579 22954 solver.cpp:357] Iteration 13100 (3.94997 iter/s, 25.3167s/100 iters), loss = 0.409908
I0929 11:21:00.942768 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.409908 (* 1 = 0.409908 loss)
I0929 11:21:00.942780 22954 sgd_solver.cpp:165] Iteration 13100, lr = 0.1
I0929 11:21:26.259156 22954 solver.cpp:357] Iteration 13200 (3.9499 iter/s, 25.3171s/100 iters), loss = 0.36571
I0929 11:21:26.259234 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.36571 (* 1 = 0.36571 loss)
I0929 11:21:26.259245 22954 sgd_solver.cpp:165] Iteration 13200, lr = 0.1
I0929 11:21:45.794039 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:21:51.564232 22954 solver.cpp:357] Iteration 13300 (3.95171 iter/s, 25.3055s/100 iters), loss = 0.450877
I0929 11:21:51.564314 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.450877 (* 1 = 0.450877 loss)
I0929 11:21:51.564326 22954 sgd_solver.cpp:165] Iteration 13300, lr = 0.1
I0929 11:22:16.877655 22954 solver.cpp:357] Iteration 13400 (3.95042 iter/s, 25.3138s/100 iters), loss = 0.539639
I0929 11:22:16.877785 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.539639 (* 1 = 0.539639 loss)
I0929 11:22:16.877796 22954 sgd_solver.cpp:165] Iteration 13400, lr = 0.1
I0929 11:22:41.978991 22954 solver.cpp:514] Iteration 13500, Testing net (#0)
I0929 11:23:01.873469 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:23:01.885763 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.992264 (* 1 = 0.992264 loss)
I0929 11:23:01.885788 22954 solver.cpp:580]     Test net output #1: prob = 0.6871
I0929 11:23:01.885794 22954 solver.cpp:593]     Max_acc: 0.706399  with iter: 12500
I0929 11:23:02.112102 22954 solver.cpp:357] Iteration 13500 (2.2106 iter/s, 45.2366s/100 iters), loss = 0.380115
I0929 11:23:02.112155 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.380115 (* 1 = 0.380115 loss)
I0929 11:23:02.112169 22954 sgd_solver.cpp:165] Iteration 13500, lr = 0.1
I0929 11:23:27.372637 22954 solver.cpp:357] Iteration 13600 (3.95874 iter/s, 25.2606s/100 iters), loss = 0.320067
I0929 11:23:27.372725 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.320067 (* 1 = 0.320067 loss)
I0929 11:23:27.372737 22954 sgd_solver.cpp:165] Iteration 13600, lr = 0.1
I0929 11:23:44.434247 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:23:52.738175 22954 solver.cpp:357] Iteration 13700 (3.94236 iter/s, 25.3655s/100 iters), loss = 0.349609
I0929 11:23:52.738257 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.349609 (* 1 = 0.349609 loss)
I0929 11:23:52.738268 22954 sgd_solver.cpp:165] Iteration 13700, lr = 0.1
I0929 11:24:18.061477 22954 solver.cpp:357] Iteration 13800 (3.94895 iter/s, 25.3232s/100 iters), loss = 0.326061
I0929 11:24:18.061602 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.326061 (* 1 = 0.326061 loss)
I0929 11:24:18.061614 22954 sgd_solver.cpp:165] Iteration 13800, lr = 0.1
I0929 11:24:43.382447 22954 solver.cpp:357] Iteration 13900 (3.94933 iter/s, 25.3208s/100 iters), loss = 0.393549
I0929 11:24:43.382527 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.393549 (* 1 = 0.393549 loss)
I0929 11:24:43.382539 22954 sgd_solver.cpp:165] Iteration 13900, lr = 0.1
I0929 11:25:08.429590 22954 solver.cpp:514] Iteration 14000, Testing net (#0)
I0929 11:25:28.056043 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:25:28.128126 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.2258 (* 1 = 1.2258 loss)
I0929 11:25:28.128155 22954 solver.cpp:580]     Test net output #1: prob = 0.6413
I0929 11:25:28.128163 22954 solver.cpp:593]     Max_acc: 0.706399  with iter: 12500
I0929 11:25:28.368157 22954 solver.cpp:357] Iteration 14000 (2.22287 iter/s, 44.9869s/100 iters), loss = 0.389179
I0929 11:25:28.368201 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.389179 (* 1 = 0.389179 loss)
I0929 11:25:28.368214 22954 sgd_solver.cpp:165] Iteration 14000, lr = 0.1
I0929 11:25:43.160522 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:25:53.777987 22954 solver.cpp:357] Iteration 14100 (3.93554 iter/s, 25.4095s/100 iters), loss = 0.416546
I0929 11:25:53.778079 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.416546 (* 1 = 0.416546 loss)
I0929 11:25:53.778091 22954 sgd_solver.cpp:165] Iteration 14100, lr = 0.1
I0929 11:26:19.047389 22954 solver.cpp:357] Iteration 14200 (3.95742 iter/s, 25.269s/100 iters), loss = 0.533441
I0929 11:26:19.048910 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.533441 (* 1 = 0.533441 loss)
I0929 11:26:19.048928 22954 sgd_solver.cpp:165] Iteration 14200, lr = 0.1
I0929 11:26:44.404747 22954 solver.cpp:357] Iteration 14300 (3.94371 iter/s, 25.3568s/100 iters), loss = 0.555876
I0929 11:26:44.405020 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.555876 (* 1 = 0.555876 loss)
I0929 11:26:44.405063 22954 sgd_solver.cpp:165] Iteration 14300, lr = 0.1
I0929 11:27:09.714458 22954 solver.cpp:357] Iteration 14400 (3.95085 iter/s, 25.311s/100 iters), loss = 0.374379
I0929 11:27:09.714749 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.374379 (* 1 = 0.374379 loss)
I0929 11:27:09.714767 22954 sgd_solver.cpp:165] Iteration 14400, lr = 0.1
I0929 11:27:22.146364 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:27:34.775260 22954 solver.cpp:514] Iteration 14500, Testing net (#0)
I0929 11:27:54.347174 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:27:54.456003 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.25292 (* 1 = 1.25292 loss)
I0929 11:27:54.456054 22954 solver.cpp:580]     Test net output #1: prob = 0.588001
I0929 11:27:54.456063 22954 solver.cpp:593]     Max_acc: 0.706399  with iter: 12500
I0929 11:27:54.651259 22954 solver.cpp:357] Iteration 14500 (2.22522 iter/s, 44.9393s/100 iters), loss = 0.43636
I0929 11:27:54.651340 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.43636 (* 1 = 0.43636 loss)
I0929 11:27:54.651351 22954 sgd_solver.cpp:165] Iteration 14500, lr = 0.1
I0929 11:28:19.983135 22954 solver.cpp:357] Iteration 14600 (3.94771 iter/s, 25.3312s/100 iters), loss = 0.600423
I0929 11:28:19.983214 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.600423 (* 1 = 0.600423 loss)
I0929 11:28:19.983225 22954 sgd_solver.cpp:165] Iteration 14600, lr = 0.1
I0929 11:28:45.302414 22954 solver.cpp:357] Iteration 14700 (3.94968 iter/s, 25.3185s/100 iters), loss = 0.497434
I0929 11:28:45.302554 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.497434 (* 1 = 0.497434 loss)
I0929 11:28:45.302567 22954 sgd_solver.cpp:165] Iteration 14700, lr = 0.1
I0929 11:29:10.622700 22954 solver.cpp:357] Iteration 14800 (3.94953 iter/s, 25.3195s/100 iters), loss = 0.299803
I0929 11:29:10.622779 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.299803 (* 1 = 0.299803 loss)
I0929 11:29:10.622792 22954 sgd_solver.cpp:165] Iteration 14800, lr = 0.1
I0929 11:29:20.558452 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:29:35.938417 22954 solver.cpp:357] Iteration 14900 (3.95025 iter/s, 25.3149s/100 iters), loss = 0.394215
I0929 11:29:35.938494 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.394215 (* 1 = 0.394215 loss)
I0929 11:29:35.938505 22954 sgd_solver.cpp:165] Iteration 14900, lr = 0.1
I0929 11:30:01.065858 22954 solver.cpp:514] Iteration 15000, Testing net (#0)
I0929 11:30:20.585402 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:30:20.686105 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.09057 (* 1 = 1.09057 loss)
I0929 11:30:20.686136 22954 solver.cpp:580]     Test net output #1: prob = 0.669501
I0929 11:30:20.686143 22954 solver.cpp:593]     Max_acc: 0.706399  with iter: 12500
I0929 11:30:20.922066 22954 solver.cpp:357] Iteration 15000 (2.22302 iter/s, 44.9838s/100 iters), loss = 0.445752
I0929 11:30:20.922109 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.445752 (* 1 = 0.445752 loss)
I0929 11:30:20.922122 22954 sgd_solver.cpp:165] Iteration 15000, lr = 0.1
I0929 11:30:46.310104 22954 solver.cpp:357] Iteration 15100 (3.93902 iter/s, 25.387s/100 iters), loss = 0.58518
I0929 11:30:46.310390 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.58518 (* 1 = 0.58518 loss)
I0929 11:30:46.310410 22954 sgd_solver.cpp:165] Iteration 15100, lr = 0.1
I0929 11:31:11.621493 22954 solver.cpp:357] Iteration 15200 (3.95065 iter/s, 25.3123s/100 iters), loss = 0.583943
I0929 11:31:11.621583 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.583943 (* 1 = 0.583943 loss)
I0929 11:31:11.621596 22954 sgd_solver.cpp:165] Iteration 15200, lr = 0.1
I0929 11:31:19.227419 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:31:36.857012 22954 solver.cpp:357] Iteration 15300 (3.96257 iter/s, 25.2362s/100 iters), loss = 0.400842
I0929 11:31:36.857076 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.400842 (* 1 = 0.400842 loss)
I0929 11:31:36.857085 22954 sgd_solver.cpp:165] Iteration 15300, lr = 0.1
I0929 11:32:02.230011 22954 solver.cpp:357] Iteration 15400 (3.94104 iter/s, 25.374s/100 iters), loss = 0.465968
I0929 11:32:02.230154 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.465968 (* 1 = 0.465968 loss)
I0929 11:32:02.230167 22954 sgd_solver.cpp:165] Iteration 15400, lr = 0.1
I0929 11:32:27.292264 22954 solver.cpp:514] Iteration 15500, Testing net (#0)
I0929 11:32:46.977452 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:32:46.991235 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.19972 (* 1 = 1.19972 loss)
I0929 11:32:46.991263 22954 solver.cpp:580]     Test net output #1: prob = 0.6339
I0929 11:32:46.991271 22954 solver.cpp:593]     Max_acc: 0.706399  with iter: 12500
I0929 11:32:47.221242 22954 solver.cpp:357] Iteration 15500 (2.22267 iter/s, 44.991s/100 iters), loss = 0.509431
I0929 11:32:47.221294 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.509431 (* 1 = 0.509431 loss)
I0929 11:32:47.221308 22954 sgd_solver.cpp:165] Iteration 15500, lr = 0.1
I0929 11:33:12.697391 22954 solver.cpp:357] Iteration 15600 (3.92542 iter/s, 25.475s/100 iters), loss = 0.423303
I0929 11:33:12.697480 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.423303 (* 1 = 0.423303 loss)
I0929 11:33:12.697492 22954 sgd_solver.cpp:165] Iteration 15600, lr = 0.1
I0929 11:33:17.778645 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:33:38.017000 22954 solver.cpp:357] Iteration 15700 (3.94969 iter/s, 25.3184s/100 iters), loss = 0.399383
I0929 11:33:38.017094 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.399383 (* 1 = 0.399383 loss)
I0929 11:33:38.017107 22954 sgd_solver.cpp:165] Iteration 15700, lr = 0.1
I0929 11:34:03.348987 22954 solver.cpp:357] Iteration 15800 (3.94776 iter/s, 25.3308s/100 iters), loss = 0.452457
I0929 11:34:03.349154 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.452457 (* 1 = 0.452457 loss)
I0929 11:34:03.349167 22954 sgd_solver.cpp:165] Iteration 15800, lr = 0.1
I0929 11:34:28.644492 22954 solver.cpp:357] Iteration 15900 (3.95323 iter/s, 25.2958s/100 iters), loss = 0.395604
I0929 11:34:28.644641 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.395604 (* 1 = 0.395604 loss)
I0929 11:34:28.644670 22954 sgd_solver.cpp:165] Iteration 15900, lr = 0.1
I0929 11:34:53.740213 22954 solver.cpp:514] Iteration 16000, Testing net (#0)
I0929 11:35:13.409013 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:35:13.499568 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.869127 (* 1 = 0.869127 loss)
I0929 11:35:13.499596 22954 solver.cpp:580]     Test net output #1: prob = 0.7114
I0929 11:35:13.499611 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_16000.caffemodel
I0929 11:35:13.509189 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_16000.solverstate
I0929 11:35:13.511723 22954 solver.cpp:593]     Max_acc: 0.7114  with iter: 16000
I0929 11:35:13.748931 22954 solver.cpp:357] Iteration 16000 (2.2171 iter/s, 45.1039s/100 iters), loss = 0.51636
I0929 11:35:13.748980 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.51636 (* 1 = 0.51636 loss)
I0929 11:35:13.748993 22954 sgd_solver.cpp:165] Iteration 16000, lr = 0.1
I0929 11:35:16.472586 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:35:38.960793 22954 solver.cpp:357] Iteration 16100 (3.96659 iter/s, 25.2106s/100 iters), loss = 0.514338
I0929 11:35:38.960960 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.514338 (* 1 = 0.514338 loss)
I0929 11:35:38.960973 22954 sgd_solver.cpp:165] Iteration 16100, lr = 0.1
I0929 11:36:04.292371 22954 solver.cpp:357] Iteration 16200 (3.94785 iter/s, 25.3303s/100 iters), loss = 0.344817
I0929 11:36:04.292452 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.344817 (* 1 = 0.344817 loss)
I0929 11:36:04.292464 22954 sgd_solver.cpp:165] Iteration 16200, lr = 0.1
I0929 11:36:29.611646 22954 solver.cpp:357] Iteration 16300 (3.94977 iter/s, 25.3179s/100 iters), loss = 0.312015
I0929 11:36:29.611822 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.312015 (* 1 = 0.312015 loss)
I0929 11:36:29.611834 22954 sgd_solver.cpp:165] Iteration 16300, lr = 0.1
I0929 11:36:54.924616 22954 solver.cpp:357] Iteration 16400 (3.95075 iter/s, 25.3116s/100 iters), loss = 0.503678
I0929 11:36:54.924697 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.503678 (* 1 = 0.503678 loss)
I0929 11:36:54.924710 22954 sgd_solver.cpp:165] Iteration 16400, lr = 0.1
I0929 11:36:55.455705 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:37:20.039984 22954 solver.cpp:514] Iteration 16500, Testing net (#0)
I0929 11:37:39.811192 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:37:39.916896 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.36413 (* 1 = 1.36413 loss)
I0929 11:37:39.916929 22954 solver.cpp:580]     Test net output #1: prob = 0.6495
I0929 11:37:39.916936 22954 solver.cpp:593]     Max_acc: 0.7114  with iter: 16000
I0929 11:37:40.124330 22954 solver.cpp:357] Iteration 16500 (2.21244 iter/s, 45.199s/100 iters), loss = 0.436482
I0929 11:37:40.124418 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.436482 (* 1 = 0.436482 loss)
I0929 11:37:40.124431 22954 sgd_solver.cpp:165] Iteration 16500, lr = 0.1
I0929 11:38:05.443845 22954 solver.cpp:357] Iteration 16600 (3.94974 iter/s, 25.3181s/100 iters), loss = 0.394043
I0929 11:38:05.443977 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.394043 (* 1 = 0.394043 loss)
I0929 11:38:05.443990 22954 sgd_solver.cpp:165] Iteration 16600, lr = 0.1
I0929 11:38:30.803156 22954 solver.cpp:357] Iteration 16700 (3.94354 iter/s, 25.3579s/100 iters), loss = 0.423054
I0929 11:38:30.803237 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.423054 (* 1 = 0.423054 loss)
I0929 11:38:30.803248 22954 sgd_solver.cpp:165] Iteration 16700, lr = 0.1
I0929 11:38:54.107951 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:38:56.101855 22954 solver.cpp:357] Iteration 16800 (3.95299 iter/s, 25.2973s/100 iters), loss = 0.438354
I0929 11:38:56.101939 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.438354 (* 1 = 0.438354 loss)
I0929 11:38:56.101950 22954 sgd_solver.cpp:165] Iteration 16800, lr = 0.1
I0929 11:39:21.426395 22954 solver.cpp:357] Iteration 16900 (3.94896 iter/s, 25.3231s/100 iters), loss = 0.376793
I0929 11:39:21.426477 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.376793 (* 1 = 0.376793 loss)
I0929 11:39:21.426488 22954 sgd_solver.cpp:165] Iteration 16900, lr = 0.1
I0929 11:39:46.475010 22954 solver.cpp:514] Iteration 17000, Testing net (#0)
I0929 11:40:06.154611 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:40:06.261971 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.77752 (* 1 = 0.77752 loss)
I0929 11:40:06.261998 22954 solver.cpp:580]     Test net output #1: prob = 0.7241
I0929 11:40:06.262012 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_17000.caffemodel
I0929 11:40:06.271261 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_17000.solverstate
I0929 11:40:06.273589 22954 solver.cpp:593]     Max_acc: 0.7241  with iter: 17000
I0929 11:40:06.508409 22954 solver.cpp:357] Iteration 17000 (2.21822 iter/s, 45.0812s/100 iters), loss = 0.506698
I0929 11:40:06.508499 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.506698 (* 1 = 0.506698 loss)
I0929 11:40:06.508512 22954 sgd_solver.cpp:165] Iteration 17000, lr = 0.1
I0929 11:40:31.841260 22954 solver.cpp:357] Iteration 17100 (3.94767 iter/s, 25.3314s/100 iters), loss = 0.334226
I0929 11:40:31.841399 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.334226 (* 1 = 0.334226 loss)
I0929 11:40:31.841413 22954 sgd_solver.cpp:165] Iteration 17100, lr = 0.1
I0929 11:40:52.850466 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:40:57.136831 22954 solver.cpp:357] Iteration 17200 (3.95322 iter/s, 25.2959s/100 iters), loss = 0.365108
I0929 11:40:57.136970 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.365108 (* 1 = 0.365108 loss)
I0929 11:40:57.137002 22954 sgd_solver.cpp:165] Iteration 17200, lr = 0.1
I0929 11:41:22.497987 22954 solver.cpp:357] Iteration 17300 (3.94327 iter/s, 25.3597s/100 iters), loss = 0.400186
I0929 11:41:22.498116 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.400186 (* 1 = 0.400186 loss)
I0929 11:41:22.498127 22954 sgd_solver.cpp:165] Iteration 17300, lr = 0.1
I0929 11:41:47.812402 22954 solver.cpp:357] Iteration 17400 (3.95027 iter/s, 25.3147s/100 iters), loss = 0.407046
I0929 11:41:47.812494 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.407046 (* 1 = 0.407046 loss)
I0929 11:41:47.812505 22954 sgd_solver.cpp:165] Iteration 17400, lr = 0.1
I0929 11:42:12.869702 22954 solver.cpp:514] Iteration 17500, Testing net (#0)
I0929 11:42:32.570721 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:42:32.597573 22954 solver.cpp:580]     Test net output #0: Softmax1 = 2.24642 (* 1 = 2.24642 loss)
I0929 11:42:32.597615 22954 solver.cpp:580]     Test net output #1: prob = 0.4574
I0929 11:42:32.597623 22954 solver.cpp:593]     Max_acc: 0.7241  with iter: 17000
I0929 11:42:32.812769 22954 solver.cpp:357] Iteration 17500 (2.22217 iter/s, 45.001s/100 iters), loss = 0.308529
I0929 11:42:32.812836 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.308529 (* 1 = 0.308529 loss)
I0929 11:42:32.812847 22954 sgd_solver.cpp:165] Iteration 17500, lr = 0.1
I0929 11:42:51.555739 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:42:58.119626 22954 solver.cpp:357] Iteration 17600 (3.95174 iter/s, 25.3053s/100 iters), loss = 0.476775
I0929 11:42:58.119702 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.476775 (* 1 = 0.476775 loss)
I0929 11:42:58.119714 22954 sgd_solver.cpp:165] Iteration 17600, lr = 0.1
I0929 11:43:23.423583 22954 solver.cpp:357] Iteration 17700 (3.95219 iter/s, 25.3024s/100 iters), loss = 0.586037
I0929 11:43:23.423753 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.586037 (* 1 = 0.586037 loss)
I0929 11:43:23.423764 22954 sgd_solver.cpp:165] Iteration 17700, lr = 0.1
I0929 11:43:48.738453 22954 solver.cpp:357] Iteration 17800 (3.95049 iter/s, 25.3133s/100 iters), loss = 0.420697
I0929 11:43:48.738541 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.420697 (* 1 = 0.420697 loss)
I0929 11:43:48.738551 22954 sgd_solver.cpp:165] Iteration 17800, lr = 0.1
I0929 11:44:14.057706 22954 solver.cpp:357] Iteration 17900 (3.9498 iter/s, 25.3177s/100 iters), loss = 0.239996
I0929 11:44:14.057965 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.239996 (* 1 = 0.239996 loss)
I0929 11:44:14.057977 22954 sgd_solver.cpp:165] Iteration 17900, lr = 0.1
I0929 11:44:30.306747 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:44:39.152761 22954 solver.cpp:514] Iteration 18000, Testing net (#0)
I0929 11:44:58.727529 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:44:58.832918 22954 solver.cpp:580]     Test net output #0: Softmax1 = 2.1427 (* 1 = 2.1427 loss)
I0929 11:44:58.832947 22954 solver.cpp:580]     Test net output #1: prob = 0.4592
I0929 11:44:58.832953 22954 solver.cpp:593]     Max_acc: 0.7241  with iter: 17000
I0929 11:44:59.067610 22954 solver.cpp:357] Iteration 18000 (2.22179 iter/s, 45.0088s/100 iters), loss = 0.352943
I0929 11:44:59.067692 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.352943 (* 1 = 0.352943 loss)
I0929 11:44:59.067704 22954 sgd_solver.cpp:165] Iteration 18000, lr = 0.1
I0929 11:45:24.425295 22954 solver.cpp:357] Iteration 18100 (3.94382 iter/s, 25.3561s/100 iters), loss = 0.400508
I0929 11:45:24.425374 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.400508 (* 1 = 0.400508 loss)
I0929 11:45:24.425385 22954 sgd_solver.cpp:165] Iteration 18100, lr = 0.1
I0929 11:45:49.719956 22954 solver.cpp:357] Iteration 18200 (3.95334 iter/s, 25.2951s/100 iters), loss = 0.387424
I0929 11:45:49.720158 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.387424 (* 1 = 0.387424 loss)
I0929 11:45:49.720172 22954 sgd_solver.cpp:165] Iteration 18200, lr = 0.1
I0929 11:46:14.999114 22954 solver.cpp:357] Iteration 18300 (3.95608 iter/s, 25.2776s/100 iters), loss = 0.308976
I0929 11:46:14.999177 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.308976 (* 1 = 0.308976 loss)
I0929 11:46:14.999186 22954 sgd_solver.cpp:165] Iteration 18300, lr = 0.1
I0929 11:46:29.021816 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:46:40.393556 22954 solver.cpp:357] Iteration 18400 (3.9378 iter/s, 25.3949s/100 iters), loss = 0.667902
I0929 11:46:40.393649 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.667902 (* 1 = 0.667902 loss)
I0929 11:46:40.393662 22954 sgd_solver.cpp:165] Iteration 18400, lr = 0.1
I0929 11:47:05.461925 22954 solver.cpp:514] Iteration 18500, Testing net (#0)
I0929 11:47:25.155999 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:47:25.167665 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.788621 (* 1 = 0.788621 loss)
I0929 11:47:25.167693 22954 solver.cpp:580]     Test net output #1: prob = 0.7271
I0929 11:47:25.167706 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_18500.caffemodel
I0929 11:47:25.177165 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_18500.solverstate
I0929 11:47:25.179762 22954 solver.cpp:593]     Max_acc: 0.7271  with iter: 18500
I0929 11:47:25.416602 22954 solver.cpp:357] Iteration 18500 (2.22106 iter/s, 45.0235s/100 iters), loss = 0.429957
I0929 11:47:25.416649 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.429957 (* 1 = 0.429957 loss)
I0929 11:47:25.416663 22954 sgd_solver.cpp:165] Iteration 18500, lr = 0.1
I0929 11:47:50.877125 22954 solver.cpp:357] Iteration 18600 (3.9279 iter/s, 25.4589s/100 iters), loss = 0.336559
I0929 11:47:50.877310 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.336559 (* 1 = 0.336559 loss)
I0929 11:47:50.877326 22954 sgd_solver.cpp:165] Iteration 18600, lr = 0.1
I0929 11:48:16.187613 22954 solver.cpp:357] Iteration 18700 (3.95087 iter/s, 25.3109s/100 iters), loss = 0.293384
I0929 11:48:16.187693 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.293384 (* 1 = 0.293384 loss)
I0929 11:48:16.187706 22954 sgd_solver.cpp:165] Iteration 18700, lr = 0.1
I0929 11:48:27.607671 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:48:41.515228 22954 solver.cpp:357] Iteration 18800 (3.94822 iter/s, 25.3278s/100 iters), loss = 0.382654
I0929 11:48:41.515305 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.382654 (* 1 = 0.382654 loss)
I0929 11:48:41.515316 22954 sgd_solver.cpp:165] Iteration 18800, lr = 0.1
I0929 11:49:06.789544 22954 solver.cpp:357] Iteration 18900 (3.95651 iter/s, 25.2748s/100 iters), loss = 0.428268
I0929 11:49:06.789717 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.428268 (* 1 = 0.428268 loss)
I0929 11:49:06.789728 22954 sgd_solver.cpp:165] Iteration 18900, lr = 0.1
I0929 11:49:31.896432 22954 solver.cpp:514] Iteration 19000, Testing net (#0)
I0929 11:49:51.587949 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:49:51.670526 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.34509 (* 1 = 1.34509 loss)
I0929 11:49:51.670557 22954 solver.cpp:580]     Test net output #1: prob = 0.6351
I0929 11:49:51.670564 22954 solver.cpp:593]     Max_acc: 0.7271  with iter: 18500
I0929 11:49:51.908932 22954 solver.cpp:357] Iteration 19000 (2.2164 iter/s, 45.1182s/100 iters), loss = 0.451827
I0929 11:49:51.908980 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.451827 (* 1 = 0.451827 loss)
I0929 11:49:51.908991 22954 sgd_solver.cpp:165] Iteration 19000, lr = 0.1
I0929 11:50:17.138730 22954 solver.cpp:357] Iteration 19100 (3.96399 iter/s, 25.2271s/100 iters), loss = 0.369061
I0929 11:50:17.138810 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.369061 (* 1 = 0.369061 loss)
I0929 11:50:17.138821 22954 sgd_solver.cpp:165] Iteration 19100, lr = 0.1
I0929 11:50:26.321785 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:50:42.463266 22954 solver.cpp:357] Iteration 19200 (3.94922 iter/s, 25.3215s/100 iters), loss = 0.467855
I0929 11:50:42.463340 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.467855 (* 1 = 0.467855 loss)
I0929 11:50:42.463351 22954 sgd_solver.cpp:165] Iteration 19200, lr = 0.1
I0929 11:51:07.790753 22954 solver.cpp:357] Iteration 19300 (3.94874 iter/s, 25.3245s/100 iters), loss = 0.357351
I0929 11:51:07.790937 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.357351 (* 1 = 0.357351 loss)
I0929 11:51:07.790949 22954 sgd_solver.cpp:165] Iteration 19300, lr = 0.1
I0929 11:51:33.102733 22954 solver.cpp:357] Iteration 19400 (3.95115 iter/s, 25.3091s/100 iters), loss = 0.42624
I0929 11:51:33.102813 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.42624 (* 1 = 0.42624 loss)
I0929 11:51:33.102825 22954 sgd_solver.cpp:165] Iteration 19400, lr = 0.1
I0929 11:51:57.880722 22954 solver.cpp:514] Iteration 19500, Testing net (#0)
I0929 11:52:17.475281 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:52:17.532114 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.910571 (* 1 = 0.910571 loss)
I0929 11:52:17.532145 22954 solver.cpp:580]     Test net output #1: prob = 0.7122
I0929 11:52:17.532150 22954 solver.cpp:593]     Max_acc: 0.7271  with iter: 18500
I0929 11:52:17.768441 22954 solver.cpp:357] Iteration 19500 (2.23902 iter/s, 44.6623s/100 iters), loss = 0.39383
I0929 11:52:17.768486 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.39383 (* 1 = 0.39383 loss)
I0929 11:52:17.768496 22954 sgd_solver.cpp:165] Iteration 19500, lr = 0.1
I0929 11:52:24.739051 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:52:43.190359 22954 solver.cpp:357] Iteration 19600 (3.93405 iter/s, 25.4191s/100 iters), loss = 0.45816
I0929 11:52:43.190541 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.45816 (* 1 = 0.45816 loss)
I0929 11:52:43.190554 22954 sgd_solver.cpp:165] Iteration 19600, lr = 0.1
I0929 11:53:08.481087 22954 solver.cpp:357] Iteration 19700 (3.95444 iter/s, 25.288s/100 iters), loss = 0.636901
I0929 11:53:08.481170 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.636901 (* 1 = 0.636901 loss)
I0929 11:53:08.481184 22954 sgd_solver.cpp:165] Iteration 19700, lr = 0.1
I0929 11:53:33.838939 22954 solver.cpp:357] Iteration 19800 (3.94398 iter/s, 25.3551s/100 iters), loss = 0.342027
I0929 11:53:33.839195 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.342027 (* 1 = 0.342027 loss)
I0929 11:53:33.839210 22954 sgd_solver.cpp:165] Iteration 19800, lr = 0.1
I0929 11:53:59.161963 22954 solver.cpp:357] Iteration 19900 (3.94939 iter/s, 25.3204s/100 iters), loss = 0.498896
I0929 11:53:59.162051 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.498896 (* 1 = 0.498896 loss)
I0929 11:53:59.162065 22954 sgd_solver.cpp:165] Iteration 19900, lr = 0.1
I0929 11:54:03.489888 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:54:24.235229 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_20000.caffemodel
I0929 11:54:24.246949 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_20000.solverstate
I0929 11:54:24.250041 22954 solver.cpp:514] Iteration 20000, Testing net (#0)
I0929 11:54:44.016387 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:54:44.124590 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.616409 (* 1 = 0.616409 loss)
I0929 11:54:44.124619 22954 solver.cpp:580]     Test net output #1: prob = 0.788
I0929 11:54:44.124634 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_20000.caffemodel
I0929 11:54:44.130578 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_20000.solverstate
I0929 11:54:44.133175 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 11:54:44.367269 22954 solver.cpp:357] Iteration 20000 (2.21227 iter/s, 45.2023s/100 iters), loss = 0.363732
I0929 11:54:44.367359 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.363732 (* 1 = 0.363732 loss)
I0929 11:54:44.367372 22954 sgd_solver.cpp:165] Iteration 20000, lr = 0.1
I0929 11:55:09.663470 22954 solver.cpp:357] Iteration 20100 (3.95331 iter/s, 25.2952s/100 iters), loss = 0.494716
I0929 11:55:09.663812 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.494716 (* 1 = 0.494716 loss)
I0929 11:55:09.663872 22954 sgd_solver.cpp:165] Iteration 20100, lr = 0.1
I0929 11:55:34.909760 22954 solver.cpp:357] Iteration 20200 (3.9611 iter/s, 25.2455s/100 iters), loss = 0.407262
I0929 11:55:34.909822 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.407262 (* 1 = 0.407262 loss)
I0929 11:55:34.909832 22954 sgd_solver.cpp:165] Iteration 20200, lr = 0.1
I0929 11:56:00.278522 22954 solver.cpp:357] Iteration 20300 (3.94192 iter/s, 25.3683s/100 iters), loss = 0.349199
I0929 11:56:00.278681 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.349199 (* 1 = 0.349199 loss)
I0929 11:56:00.278699 22954 sgd_solver.cpp:165] Iteration 20300, lr = 0.1
I0929 11:56:02.310117 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:56:25.589087 22954 solver.cpp:357] Iteration 20400 (3.95104 iter/s, 25.3098s/100 iters), loss = 0.322992
I0929 11:56:25.589177 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.322992 (* 1 = 0.322992 loss)
I0929 11:56:25.589190 22954 sgd_solver.cpp:165] Iteration 20400, lr = 0.1
I0929 11:56:50.664098 22954 solver.cpp:514] Iteration 20500, Testing net (#0)
I0929 11:57:10.338667 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:57:10.390133 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.921981 (* 1 = 0.921981 loss)
I0929 11:57:10.390159 22954 solver.cpp:580]     Test net output #1: prob = 0.7041
I0929 11:57:10.390166 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 11:57:10.628538 22954 solver.cpp:357] Iteration 20500 (2.22041 iter/s, 45.0368s/100 iters), loss = 0.331392
I0929 11:57:10.628585 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.331392 (* 1 = 0.331392 loss)
I0929 11:57:10.628599 22954 sgd_solver.cpp:165] Iteration 20500, lr = 0.1
I0929 11:57:36.056264 22954 solver.cpp:357] Iteration 20600 (3.93309 iter/s, 25.4253s/100 iters), loss = 0.349601
I0929 11:57:36.056490 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.349601 (* 1 = 0.349601 loss)
I0929 11:57:36.056504 22954 sgd_solver.cpp:165] Iteration 20600, lr = 0.1
I0929 11:58:01.167858 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:58:01.396028 22954 solver.cpp:357] Iteration 20700 (3.94674 iter/s, 25.3373s/100 iters), loss = 0.36115
I0929 11:58:01.396178 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.36115 (* 1 = 0.36115 loss)
I0929 11:58:01.396195 22954 sgd_solver.cpp:165] Iteration 20700, lr = 0.1
I0929 11:58:26.678418 22954 solver.cpp:357] Iteration 20800 (3.95537 iter/s, 25.2821s/100 iters), loss = 0.450404
I0929 11:58:26.678601 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.450404 (* 1 = 0.450404 loss)
I0929 11:58:26.678613 22954 sgd_solver.cpp:165] Iteration 20800, lr = 0.1
I0929 11:58:52.025075 22954 solver.cpp:357] Iteration 20900 (3.94566 iter/s, 25.3443s/100 iters), loss = 0.406446
I0929 11:58:52.025167 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.406446 (* 1 = 0.406446 loss)
I0929 11:58:52.025179 22954 sgd_solver.cpp:165] Iteration 20900, lr = 0.1
I0929 11:59:17.109618 22954 solver.cpp:514] Iteration 21000, Testing net (#0)
I0929 11:59:36.814321 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 11:59:36.912467 22954 solver.cpp:580]     Test net output #0: Softmax1 = 2.30471 (* 1 = 2.30471 loss)
I0929 11:59:36.912495 22954 solver.cpp:580]     Test net output #1: prob = 0.3981
I0929 11:59:36.912503 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 11:59:37.149235 22954 solver.cpp:357] Iteration 21000 (2.21623 iter/s, 45.1218s/100 iters), loss = 0.394935
I0929 11:59:37.149278 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.394935 (* 1 = 0.394935 loss)
I0929 11:59:37.149292 22954 sgd_solver.cpp:165] Iteration 21000, lr = 0.1
I0929 11:59:59.766731 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:00:02.527842 22954 solver.cpp:357] Iteration 21100 (3.94069 iter/s, 25.3763s/100 iters), loss = 0.401949
I0929 12:00:02.527930 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.401949 (* 1 = 0.401949 loss)
I0929 12:00:02.527942 22954 sgd_solver.cpp:165] Iteration 21100, lr = 0.1
I0929 12:00:27.846297 22954 solver.cpp:357] Iteration 21200 (3.94979 iter/s, 25.3178s/100 iters), loss = 0.371917
I0929 12:00:27.846384 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.371917 (* 1 = 0.371917 loss)
I0929 12:00:27.846395 22954 sgd_solver.cpp:165] Iteration 21200, lr = 0.1
I0929 12:00:53.122655 22954 solver.cpp:357] Iteration 21300 (3.95634 iter/s, 25.2759s/100 iters), loss = 0.452416
I0929 12:00:53.122761 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.452416 (* 1 = 0.452416 loss)
I0929 12:00:53.122771 22954 sgd_solver.cpp:165] Iteration 21300, lr = 0.1
I0929 12:01:18.491809 22954 solver.cpp:357] Iteration 21400 (3.94182 iter/s, 25.369s/100 iters), loss = 0.455827
I0929 12:01:18.491899 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.455827 (* 1 = 0.455827 loss)
I0929 12:01:18.491912 22954 sgd_solver.cpp:165] Iteration 21400, lr = 0.1
I0929 12:01:38.758591 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:01:43.567252 22954 solver.cpp:514] Iteration 21500, Testing net (#0)
I0929 12:02:03.275455 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:02:03.288712 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.972657 (* 1 = 0.972657 loss)
I0929 12:02:03.288745 22954 solver.cpp:580]     Test net output #1: prob = 0.671
I0929 12:02:03.288751 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:02:03.521693 22954 solver.cpp:357] Iteration 21500 (2.22078 iter/s, 45.0293s/100 iters), loss = 0.224237
I0929 12:02:03.521747 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.224237 (* 1 = 0.224237 loss)
I0929 12:02:03.521762 22954 sgd_solver.cpp:165] Iteration 21500, lr = 0.1
I0929 12:02:28.815747 22954 solver.cpp:357] Iteration 21600 (3.95384 iter/s, 25.2918s/100 iters), loss = 0.406201
I0929 12:02:28.815996 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.406201 (* 1 = 0.406201 loss)
I0929 12:02:28.816009 22954 sgd_solver.cpp:165] Iteration 21600, lr = 0.1
I0929 12:02:54.112318 22954 solver.cpp:357] Iteration 21700 (3.95345 iter/s, 25.2944s/100 iters), loss = 0.400898
I0929 12:02:54.112392 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.400898 (* 1 = 0.400898 loss)
I0929 12:02:54.112402 22954 sgd_solver.cpp:165] Iteration 21700, lr = 0.1
I0929 12:03:19.430959 22954 solver.cpp:357] Iteration 21800 (3.94999 iter/s, 25.3165s/100 iters), loss = 0.423448
I0929 12:03:19.431092 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.423448 (* 1 = 0.423448 loss)
I0929 12:03:19.431103 22954 sgd_solver.cpp:165] Iteration 21800, lr = 0.1
I0929 12:03:37.222126 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:03:44.708822 22954 solver.cpp:357] Iteration 21900 (3.95637 iter/s, 25.2757s/100 iters), loss = 0.482888
I0929 12:03:44.708902 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.482888 (* 1 = 0.482888 loss)
I0929 12:03:44.708914 22954 sgd_solver.cpp:165] Iteration 21900, lr = 0.1
I0929 12:04:09.871327 22954 solver.cpp:514] Iteration 22000, Testing net (#0)
I0929 12:04:29.623491 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:04:29.729918 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.685989 (* 1 = 0.685989 loss)
I0929 12:04:29.730021 22954 solver.cpp:580]     Test net output #1: prob = 0.7607
I0929 12:04:29.730043 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:04:29.940059 22954 solver.cpp:357] Iteration 22000 (2.21096 iter/s, 45.2291s/100 iters), loss = 0.367922
I0929 12:04:29.940143 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.367922 (* 1 = 0.367922 loss)
I0929 12:04:29.940155 22954 sgd_solver.cpp:165] Iteration 22000, lr = 0.1
I0929 12:04:55.283655 22954 solver.cpp:357] Iteration 22100 (3.9461 iter/s, 25.3415s/100 iters), loss = 0.460309
I0929 12:04:55.283834 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.460309 (* 1 = 0.460309 loss)
I0929 12:04:55.283846 22954 sgd_solver.cpp:165] Iteration 22100, lr = 0.1
I0929 12:05:20.591951 22954 solver.cpp:357] Iteration 22200 (3.95161 iter/s, 25.3062s/100 iters), loss = 0.313704
I0929 12:05:20.592031 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.313704 (* 1 = 0.313704 loss)
I0929 12:05:20.592043 22954 sgd_solver.cpp:165] Iteration 22200, lr = 0.1
I0929 12:05:36.078145 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:05:45.899874 22954 solver.cpp:357] Iteration 22300 (3.95166 iter/s, 25.3058s/100 iters), loss = 0.482822
I0929 12:05:45.899953 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.482822 (* 1 = 0.482822 loss)
I0929 12:05:45.899963 22954 sgd_solver.cpp:165] Iteration 22300, lr = 0.1
I0929 12:06:11.209975 22954 solver.cpp:357] Iteration 22400 (3.95132 iter/s, 25.308s/100 iters), loss = 0.337069
I0929 12:06:11.210103 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.337069 (* 1 = 0.337069 loss)
I0929 12:06:11.210114 22954 sgd_solver.cpp:165] Iteration 22400, lr = 0.1
I0929 12:06:36.339886 22954 solver.cpp:514] Iteration 22500, Testing net (#0)
I0929 12:06:56.189766 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:06:56.204038 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.15674 (* 1 = 1.15674 loss)
I0929 12:06:56.204069 22954 solver.cpp:580]     Test net output #1: prob = 0.62
I0929 12:06:56.204078 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:06:56.427604 22954 solver.cpp:357] Iteration 22500 (2.21162 iter/s, 45.2156s/100 iters), loss = 0.426988
I0929 12:06:56.427655 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.426988 (* 1 = 0.426988 loss)
I0929 12:06:56.427669 22954 sgd_solver.cpp:165] Iteration 22500, lr = 0.1
I0929 12:07:21.695076 22954 solver.cpp:357] Iteration 22600 (3.95798 iter/s, 25.2654s/100 iters), loss = 0.494372
I0929 12:07:21.695163 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.494372 (* 1 = 0.494372 loss)
I0929 12:07:21.695176 22954 sgd_solver.cpp:165] Iteration 22600, lr = 0.1
I0929 12:07:34.948935 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:07:47.055341 22954 solver.cpp:357] Iteration 22700 (3.9435 iter/s, 25.3582s/100 iters), loss = 0.479439
I0929 12:07:47.055419 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.479439 (* 1 = 0.479439 loss)
I0929 12:07:47.055430 22954 sgd_solver.cpp:165] Iteration 22700, lr = 0.1
I0929 12:08:12.362049 22954 solver.cpp:357] Iteration 22800 (3.95184 iter/s, 25.3046s/100 iters), loss = 0.384603
I0929 12:08:12.362222 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.384603 (* 1 = 0.384603 loss)
I0929 12:08:12.362234 22954 sgd_solver.cpp:165] Iteration 22800, lr = 0.1
I0929 12:08:37.683853 22954 solver.cpp:357] Iteration 22900 (3.94949 iter/s, 25.3197s/100 iters), loss = 0.446236
I0929 12:08:37.683936 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.446236 (* 1 = 0.446236 loss)
I0929 12:08:37.683948 22954 sgd_solver.cpp:165] Iteration 22900, lr = 0.1
I0929 12:09:02.732058 22954 solver.cpp:514] Iteration 23000, Testing net (#0)
I0929 12:09:22.571755 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:09:22.653645 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.2421 (* 1 = 1.2421 loss)
I0929 12:09:22.653687 22954 solver.cpp:580]     Test net output #1: prob = 0.645401
I0929 12:09:22.653694 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:09:22.867616 22954 solver.cpp:357] Iteration 23000 (2.21328 iter/s, 45.1818s/100 iters), loss = 0.444431
I0929 12:09:22.867692 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.444431 (* 1 = 0.444431 loss)
I0929 12:09:22.867704 22954 sgd_solver.cpp:165] Iteration 23000, lr = 0.1
I0929 12:09:33.571949 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:09:48.183297 22954 solver.cpp:357] Iteration 23100 (3.95044 iter/s, 25.3136s/100 iters), loss = 0.426847
I0929 12:09:48.183378 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.426847 (* 1 = 0.426847 loss)
I0929 12:09:48.183389 22954 sgd_solver.cpp:165] Iteration 23100, lr = 0.1
I0929 12:10:13.501798 22954 solver.cpp:357] Iteration 23200 (3.95 iter/s, 25.3165s/100 iters), loss = 0.443188
I0929 12:10:13.501997 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.443188 (* 1 = 0.443188 loss)
I0929 12:10:13.502008 22954 sgd_solver.cpp:165] Iteration 23200, lr = 0.1
I0929 12:10:38.815444 22954 solver.cpp:357] Iteration 23300 (3.95075 iter/s, 25.3116s/100 iters), loss = 0.334628
I0929 12:10:38.815524 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.334628 (* 1 = 0.334628 loss)
I0929 12:10:38.815536 22954 sgd_solver.cpp:165] Iteration 23300, lr = 0.1
I0929 12:11:04.128684 22954 solver.cpp:357] Iteration 23400 (3.95082 iter/s, 25.3112s/100 iters), loss = 0.388855
I0929 12:11:04.128809 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.388855 (* 1 = 0.388855 loss)
I0929 12:11:04.128820 22954 sgd_solver.cpp:165] Iteration 23400, lr = 0.1
I0929 12:11:12.532927 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:11:29.226348 22954 solver.cpp:514] Iteration 23500, Testing net (#0)
I0929 12:11:48.748790 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:11:48.828119 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.913067 (* 1 = 0.913067 loss)
I0929 12:11:48.828148 22954 solver.cpp:580]     Test net output #1: prob = 0.7046
I0929 12:11:48.828155 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:11:49.063911 22954 solver.cpp:357] Iteration 23500 (2.22552 iter/s, 44.9334s/100 iters), loss = 0.346611
I0929 12:11:49.063956 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.346611 (* 1 = 0.346611 loss)
I0929 12:11:49.063971 22954 sgd_solver.cpp:165] Iteration 23500, lr = 0.1
I0929 12:12:14.465509 22954 solver.cpp:357] Iteration 23600 (3.93708 iter/s, 25.3996s/100 iters), loss = 0.47143
I0929 12:12:14.465593 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.47143 (* 1 = 0.47143 loss)
I0929 12:12:14.465606 22954 sgd_solver.cpp:165] Iteration 23600, lr = 0.1
I0929 12:12:39.704583 22954 solver.cpp:357] Iteration 23700 (3.96215 iter/s, 25.2388s/100 iters), loss = 0.333067
I0929 12:12:39.704747 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.333067 (* 1 = 0.333067 loss)
I0929 12:12:39.704757 22954 sgd_solver.cpp:165] Iteration 23700, lr = 0.1
I0929 12:13:05.087299 22954 solver.cpp:357] Iteration 23800 (3.93969 iter/s, 25.3827s/100 iters), loss = 0.420717
I0929 12:13:05.087386 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.420717 (* 1 = 0.420717 loss)
I0929 12:13:05.087399 22954 sgd_solver.cpp:165] Iteration 23800, lr = 0.1
I0929 12:13:11.166133 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:13:30.386263 22954 solver.cpp:357] Iteration 23900 (3.95304 iter/s, 25.297s/100 iters), loss = 0.413989
I0929 12:13:30.386355 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.413989 (* 1 = 0.413989 loss)
I0929 12:13:30.386368 22954 sgd_solver.cpp:165] Iteration 23900, lr = 0.1
I0929 12:13:55.478098 22954 solver.cpp:514] Iteration 24000, Testing net (#0)
I0929 12:14:15.268954 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:14:15.377327 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.920959 (* 1 = 0.920959 loss)
I0929 12:14:15.377352 22954 solver.cpp:580]     Test net output #1: prob = 0.6939
I0929 12:14:15.377358 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:14:15.612260 22954 solver.cpp:357] Iteration 24000 (2.21121 iter/s, 45.2242s/100 iters), loss = 0.492709
I0929 12:14:15.612346 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.492709 (* 1 = 0.492709 loss)
I0929 12:14:15.612360 22954 sgd_solver.cpp:165] Iteration 24000, lr = 0.1
I0929 12:14:40.927390 22954 solver.cpp:357] Iteration 24100 (3.95051 iter/s, 25.3132s/100 iters), loss = 0.358751
I0929 12:14:40.927592 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.358751 (* 1 = 0.358751 loss)
I0929 12:14:40.927605 22954 sgd_solver.cpp:165] Iteration 24100, lr = 0.1
I0929 12:15:06.234419 22954 solver.cpp:357] Iteration 24200 (3.95179 iter/s, 25.305s/100 iters), loss = 0.45164
I0929 12:15:06.234571 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.45164 (* 1 = 0.45164 loss)
I0929 12:15:06.234591 22954 sgd_solver.cpp:165] Iteration 24200, lr = 0.1
I0929 12:15:09.793468 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:15:31.518857 22954 solver.cpp:357] Iteration 24300 (3.95499 iter/s, 25.2845s/100 iters), loss = 0.606359
I0929 12:15:31.519013 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.606359 (* 1 = 0.606359 loss)
I0929 12:15:31.519027 22954 sgd_solver.cpp:165] Iteration 24300, lr = 0.1
I0929 12:15:56.878175 22954 solver.cpp:357] Iteration 24400 (3.94364 iter/s, 25.3573s/100 iters), loss = 0.3782
I0929 12:15:56.878317 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.3782 (* 1 = 0.3782 loss)
I0929 12:15:56.878336 22954 sgd_solver.cpp:165] Iteration 24400, lr = 0.1
I0929 12:16:21.947248 22954 solver.cpp:514] Iteration 24500, Testing net (#0)
I0929 12:16:41.576900 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:16:41.661361 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.28263 (* 1 = 1.28263 loss)
I0929 12:16:41.661407 22954 solver.cpp:580]     Test net output #1: prob = 0.6318
I0929 12:16:41.661414 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:16:41.869925 22954 solver.cpp:357] Iteration 24500 (2.22262 iter/s, 44.992s/100 iters), loss = 0.458226
I0929 12:16:41.870012 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.458226 (* 1 = 0.458226 loss)
I0929 12:16:41.870023 22954 sgd_solver.cpp:165] Iteration 24500, lr = 0.1
I0929 12:17:07.196389 22954 solver.cpp:357] Iteration 24600 (3.94874 iter/s, 25.3245s/100 iters), loss = 0.385388
I0929 12:17:07.196604 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.385388 (* 1 = 0.385388 loss)
I0929 12:17:07.196615 22954 sgd_solver.cpp:165] Iteration 24600, lr = 0.1
I0929 12:17:08.506378 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:17:32.520185 22954 solver.cpp:357] Iteration 24700 (3.94916 iter/s, 25.3218s/100 iters), loss = 0.35789
I0929 12:17:32.520264 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.35789 (* 1 = 0.35789 loss)
I0929 12:17:32.520277 22954 sgd_solver.cpp:165] Iteration 24700, lr = 0.1
I0929 12:17:57.998813 22954 solver.cpp:357] Iteration 24800 (3.92516 iter/s, 25.4767s/100 iters), loss = 0.394992
I0929 12:17:57.998996 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.394992 (* 1 = 0.394992 loss)
I0929 12:17:57.999008 22954 sgd_solver.cpp:165] Iteration 24800, lr = 0.1
I0929 12:18:23.306241 22954 solver.cpp:357] Iteration 24900 (3.95172 iter/s, 25.3055s/100 iters), loss = 0.472282
I0929 12:18:23.306322 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.472282 (* 1 = 0.472282 loss)
I0929 12:18:23.306334 22954 sgd_solver.cpp:165] Iteration 24900, lr = 0.1
I0929 12:18:47.548602 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:18:48.557067 22954 solver.cpp:514] Iteration 25000, Testing net (#0)
I0929 12:19:08.379108 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:19:08.465029 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.50837 (* 1 = 1.50837 loss)
I0929 12:19:08.465165 22954 solver.cpp:580]     Test net output #1: prob = 0.5473
I0929 12:19:08.465189 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:19:08.689849 22954 solver.cpp:357] Iteration 25000 (2.20352 iter/s, 45.3818s/100 iters), loss = 0.387905
I0929 12:19:08.689960 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.387905 (* 1 = 0.387905 loss)
I0929 12:19:08.689972 22954 sgd_solver.cpp:165] Iteration 25000, lr = 0.1
I0929 12:19:34.122927 22954 solver.cpp:357] Iteration 25100 (3.93219 iter/s, 25.4311s/100 iters), loss = 0.454067
I0929 12:19:34.123073 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.454067 (* 1 = 0.454067 loss)
I0929 12:19:34.123087 22954 sgd_solver.cpp:165] Iteration 25100, lr = 0.1
I0929 12:19:59.450992 22954 solver.cpp:357] Iteration 25200 (3.94849 iter/s, 25.3261s/100 iters), loss = 0.509416
I0929 12:19:59.451071 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.509416 (* 1 = 0.509416 loss)
I0929 12:19:59.451083 22954 sgd_solver.cpp:165] Iteration 25200, lr = 0.1
I0929 12:20:26.277951 22954 solver.cpp:357] Iteration 25300 (3.72787 iter/s, 26.825s/100 iters), loss = 0.442975
I0929 12:20:26.278192 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.442975 (* 1 = 0.442975 loss)
I0929 12:20:26.278223 22954 sgd_solver.cpp:165] Iteration 25300, lr = 0.1
I0929 12:20:52.721735 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:20:56.834514 22954 solver.cpp:357] Iteration 25400 (3.27305 iter/s, 30.5525s/100 iters), loss = 0.407682
I0929 12:20:56.834736 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.407682 (* 1 = 0.407682 loss)
I0929 12:20:56.834764 22954 sgd_solver.cpp:165] Iteration 25400, lr = 0.1
I0929 12:21:27.137257 22954 solver.cpp:514] Iteration 25500, Testing net (#0)
I0929 12:21:48.812700 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:21:48.890542 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.31368 (* 1 = 1.31368 loss)
I0929 12:21:48.890678 22954 solver.cpp:580]     Test net output #1: prob = 0.6511
I0929 12:21:48.890733 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:21:49.186110 22954 solver.cpp:357] Iteration 25500 (1.91015 iter/s, 52.3519s/100 iters), loss = 0.269792
I0929 12:21:49.186280 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.269792 (* 1 = 0.269792 loss)
I0929 12:21:49.186308 22954 sgd_solver.cpp:165] Iteration 25500, lr = 0.1
I0929 12:22:19.800086 22954 solver.cpp:357] Iteration 25600 (3.26672 iter/s, 30.6117s/100 iters), loss = 0.408975
I0929 12:22:19.800333 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.408975 (* 1 = 0.408975 loss)
I0929 12:22:19.800361 22954 sgd_solver.cpp:165] Iteration 25600, lr = 0.1
I0929 12:22:50.376935 22954 solver.cpp:357] Iteration 25700 (3.27044 iter/s, 30.5769s/100 iters), loss = 0.378615
I0929 12:22:50.382081 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.378615 (* 1 = 0.378615 loss)
I0929 12:22:50.382113 22954 sgd_solver.cpp:165] Iteration 25700, lr = 0.1
I0929 12:23:14.379609 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:23:21.308239 22954 solver.cpp:357] Iteration 25800 (3.23385 iter/s, 30.9229s/100 iters), loss = 0.432731
I0929 12:23:21.308490 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.432731 (* 1 = 0.432731 loss)
I0929 12:23:21.308519 22954 sgd_solver.cpp:165] Iteration 25800, lr = 0.1
I0929 12:23:52.037385 22954 solver.cpp:357] Iteration 25900 (3.25467 iter/s, 30.7251s/100 iters), loss = 0.481703
I0929 12:23:52.037609 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.481703 (* 1 = 0.481703 loss)
I0929 12:23:52.037638 22954 sgd_solver.cpp:165] Iteration 25900, lr = 0.1
I0929 12:24:22.186517 22954 solver.cpp:514] Iteration 26000, Testing net (#0)
I0929 12:24:44.525416 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:24:44.646100 22954 solver.cpp:580]     Test net output #0: Softmax1 = 2.00509 (* 1 = 2.00509 loss)
I0929 12:24:44.646266 22954 solver.cpp:580]     Test net output #1: prob = 0.5092
I0929 12:24:44.646292 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:24:44.821547 22954 solver.cpp:357] Iteration 26000 (1.89463 iter/s, 52.7806s/100 iters), loss = 0.448112
I0929 12:24:44.821704 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.448112 (* 1 = 0.448112 loss)
I0929 12:24:44.821732 22954 sgd_solver.cpp:165] Iteration 26000, lr = 0.1
I0929 12:25:15.556936 22954 solver.cpp:357] Iteration 26100 (3.25393 iter/s, 30.7321s/100 iters), loss = 0.352547
I0929 12:25:15.557186 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.352547 (* 1 = 0.352547 loss)
I0929 12:25:15.557219 22954 sgd_solver.cpp:165] Iteration 26100, lr = 0.1
I0929 12:25:36.260484 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:25:46.434278 22954 solver.cpp:357] Iteration 26200 (3.23919 iter/s, 30.8719s/100 iters), loss = 0.453689
I0929 12:25:46.434615 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.453689 (* 1 = 0.453689 loss)
I0929 12:25:46.434645 22954 sgd_solver.cpp:165] Iteration 26200, lr = 0.1
I0929 12:26:17.290009 22954 solver.cpp:357] Iteration 26300 (3.24145 iter/s, 30.8504s/100 iters), loss = 0.290255
I0929 12:26:17.290257 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.290255 (* 1 = 0.290255 loss)
I0929 12:26:17.290287 22954 sgd_solver.cpp:165] Iteration 26300, lr = 0.1
I0929 12:26:48.116183 22954 solver.cpp:357] Iteration 26400 (3.24432 iter/s, 30.8231s/100 iters), loss = 0.334748
I0929 12:26:48.116400 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.334748 (* 1 = 0.334748 loss)
I0929 12:26:48.116428 22954 sgd_solver.cpp:165] Iteration 26400, lr = 0.1
I0929 12:27:18.481943 22954 solver.cpp:514] Iteration 26500, Testing net (#0)
I0929 12:27:40.623664 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:27:40.662237 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.19619 (* 1 = 1.19619 loss)
I0929 12:27:40.662356 22954 solver.cpp:580]     Test net output #1: prob = 0.6402
I0929 12:27:40.662380 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:27:40.909008 22954 solver.cpp:357] Iteration 26500 (1.89433 iter/s, 52.7892s/100 iters), loss = 0.365387
I0929 12:27:40.909191 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.365387 (* 1 = 0.365387 loss)
I0929 12:27:40.909224 22954 sgd_solver.cpp:165] Iteration 26500, lr = 0.1
I0929 12:27:58.571077 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:28:11.277477 22954 solver.cpp:357] Iteration 26600 (3.29344 iter/s, 30.3633s/100 iters), loss = 0.304916
I0929 12:28:11.277617 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.304916 (* 1 = 0.304916 loss)
I0929 12:28:11.277647 22954 sgd_solver.cpp:165] Iteration 26600, lr = 0.1
I0929 12:28:41.982923 22954 solver.cpp:357] Iteration 26700 (3.25684 iter/s, 30.7046s/100 iters), loss = 0.48163
I0929 12:28:41.983222 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.48163 (* 1 = 0.48163 loss)
I0929 12:28:41.983250 22954 sgd_solver.cpp:165] Iteration 26700, lr = 0.1
I0929 12:29:12.379361 22954 solver.cpp:357] Iteration 26800 (3.29016 iter/s, 30.3936s/100 iters), loss = 0.426709
I0929 12:29:12.379601 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.426709 (* 1 = 0.426709 loss)
I0929 12:29:12.379631 22954 sgd_solver.cpp:165] Iteration 26800, lr = 0.1
I0929 12:29:42.692107 22954 solver.cpp:357] Iteration 26900 (3.29924 iter/s, 30.31s/100 iters), loss = 0.314776
I0929 12:29:42.692340 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.314776 (* 1 = 0.314776 loss)
I0929 12:29:42.692370 22954 sgd_solver.cpp:165] Iteration 26900, lr = 0.1
I0929 12:29:57.728298 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:30:12.735641 22954 solver.cpp:514] Iteration 27000, Testing net (#0)
I0929 12:30:34.025686 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:30:34.039146 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.16486 (* 1 = 1.16486 loss)
I0929 12:30:34.039175 22954 solver.cpp:580]     Test net output #1: prob = 0.6188
I0929 12:30:34.039181 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:30:34.269222 22954 solver.cpp:357] Iteration 27000 (1.93896 iter/s, 51.574s/100 iters), loss = 0.314669
I0929 12:30:34.269273 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.314669 (* 1 = 0.314669 loss)
I0929 12:30:34.269284 22954 sgd_solver.cpp:165] Iteration 27000, lr = 0.1
I0929 12:30:59.738467 22954 solver.cpp:357] Iteration 27100 (3.92671 iter/s, 25.4666s/100 iters), loss = 0.476477
I0929 12:30:59.738656 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.476477 (* 1 = 0.476477 loss)
I0929 12:30:59.738668 22954 sgd_solver.cpp:165] Iteration 27100, lr = 0.1
I0929 12:31:25.101706 22954 solver.cpp:357] Iteration 27200 (3.94311 iter/s, 25.3607s/100 iters), loss = 0.468145
I0929 12:31:25.101779 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.468145 (* 1 = 0.468145 loss)
I0929 12:31:25.101791 22954 sgd_solver.cpp:165] Iteration 27200, lr = 0.1
I0929 12:31:50.350253 22954 solver.cpp:357] Iteration 27300 (3.96069 iter/s, 25.2481s/100 iters), loss = 0.449955
I0929 12:31:50.350409 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.449955 (* 1 = 0.449955 loss)
I0929 12:31:50.350419 22954 sgd_solver.cpp:165] Iteration 27300, lr = 0.1
I0929 12:32:00.314803 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:32:15.710554 22954 solver.cpp:357] Iteration 27400 (3.94326 iter/s, 25.3598s/100 iters), loss = 0.348932
I0929 12:32:15.710645 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.348932 (* 1 = 0.348932 loss)
I0929 12:32:15.710657 22954 sgd_solver.cpp:165] Iteration 27400, lr = 0.1
I0929 12:32:40.788591 22954 solver.cpp:514] Iteration 27500, Testing net (#0)
I0929 12:33:00.547178 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:33:00.652962 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.24195 (* 1 = 1.24195 loss)
I0929 12:33:00.652989 22954 solver.cpp:580]     Test net output #1: prob = 0.6336
I0929 12:33:00.652997 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:33:00.888788 22954 solver.cpp:357] Iteration 27500 (2.21359 iter/s, 45.1755s/100 iters), loss = 0.436218
I0929 12:33:00.888871 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.436218 (* 1 = 0.436218 loss)
I0929 12:33:00.888885 22954 sgd_solver.cpp:165] Iteration 27500, lr = 0.1
I0929 12:33:26.201203 22954 solver.cpp:357] Iteration 27600 (3.95101 iter/s, 25.31s/100 iters), loss = 0.387406
I0929 12:33:26.201457 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.387406 (* 1 = 0.387406 loss)
I0929 12:33:26.201469 22954 sgd_solver.cpp:165] Iteration 27600, lr = 0.1
I0929 12:33:51.508666 22954 solver.cpp:357] Iteration 27700 (3.95179 iter/s, 25.305s/100 iters), loss = 0.563621
I0929 12:33:51.508749 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.563621 (* 1 = 0.563621 loss)
I0929 12:33:51.508762 22954 sgd_solver.cpp:165] Iteration 27700, lr = 0.1
I0929 12:33:59.129214 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:34:16.841428 22954 solver.cpp:357] Iteration 27800 (3.94784 iter/s, 25.3303s/100 iters), loss = 0.314896
I0929 12:34:16.841519 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.314896 (* 1 = 0.314896 loss)
I0929 12:34:16.841531 22954 sgd_solver.cpp:165] Iteration 27800, lr = 0.1
I0929 12:34:42.113181 22954 solver.cpp:357] Iteration 27900 (3.95712 iter/s, 25.2709s/100 iters), loss = 0.413228
I0929 12:34:42.113334 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.413228 (* 1 = 0.413228 loss)
I0929 12:34:42.113348 22954 sgd_solver.cpp:165] Iteration 27900, lr = 0.1
I0929 12:35:07.231003 22954 solver.cpp:514] Iteration 28000, Testing net (#0)
I0929 12:35:26.918306 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:35:26.967479 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.49856 (* 1 = 1.49856 loss)
I0929 12:35:26.967510 22954 solver.cpp:580]     Test net output #1: prob = 0.5832
I0929 12:35:26.967519 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:35:27.206166 22954 solver.cpp:357] Iteration 28000 (2.21776 iter/s, 45.0905s/100 iters), loss = 0.45203
I0929 12:35:27.206210 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.45203 (* 1 = 0.45203 loss)
I0929 12:35:27.206223 22954 sgd_solver.cpp:165] Iteration 28000, lr = 0.1
I0929 12:35:52.454764 22954 solver.cpp:357] Iteration 28100 (3.96099 iter/s, 25.2462s/100 iters), loss = 0.373583
I0929 12:35:52.454843 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.373583 (* 1 = 0.373583 loss)
I0929 12:35:52.454855 22954 sgd_solver.cpp:165] Iteration 28100, lr = 0.1
I0929 12:35:57.590925 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:36:17.773247 22954 solver.cpp:357] Iteration 28200 (3.95005 iter/s, 25.3161s/100 iters), loss = 0.518199
I0929 12:36:17.773326 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.518199 (* 1 = 0.518199 loss)
I0929 12:36:17.773339 22954 sgd_solver.cpp:165] Iteration 28200, lr = 0.1
I0929 12:36:43.085494 22954 solver.cpp:357] Iteration 28300 (3.95102 iter/s, 25.3099s/100 iters), loss = 0.408556
I0929 12:36:43.085667 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.408556 (* 1 = 0.408556 loss)
I0929 12:36:43.085680 22954 sgd_solver.cpp:165] Iteration 28300, lr = 0.1
I0929 12:37:08.380211 22954 solver.cpp:357] Iteration 28400 (3.95376 iter/s, 25.2924s/100 iters), loss = 0.384145
I0929 12:37:08.380275 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.384145 (* 1 = 0.384145 loss)
I0929 12:37:08.380286 22954 sgd_solver.cpp:165] Iteration 28400, lr = 0.1
I0929 12:37:33.475244 22954 solver.cpp:514] Iteration 28500, Testing net (#0)
I0929 12:37:53.238131 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:37:53.343819 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.78683 (* 1 = 1.78683 loss)
I0929 12:37:53.343922 22954 solver.cpp:580]     Test net output #1: prob = 0.567601
I0929 12:37:53.343948 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:37:53.543244 22954 solver.cpp:357] Iteration 28500 (2.21432 iter/s, 45.1606s/100 iters), loss = 0.431539
I0929 12:37:53.543326 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.431539 (* 1 = 0.431539 loss)
I0929 12:37:53.543339 22954 sgd_solver.cpp:165] Iteration 28500, lr = 0.1
I0929 12:37:56.407330 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:38:18.846218 22954 solver.cpp:357] Iteration 28600 (3.95246 iter/s, 25.3007s/100 iters), loss = 0.419079
I0929 12:38:18.846441 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.419079 (* 1 = 0.419079 loss)
I0929 12:38:18.846457 22954 sgd_solver.cpp:165] Iteration 28600, lr = 0.1
I0929 12:38:44.207319 22954 solver.cpp:357] Iteration 28700 (3.9434 iter/s, 25.3588s/100 iters), loss = 0.421182
I0929 12:38:44.207401 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.421182 (* 1 = 0.421182 loss)
I0929 12:38:44.207412 22954 sgd_solver.cpp:165] Iteration 28700, lr = 0.1
I0929 12:39:09.523181 22954 solver.cpp:357] Iteration 28800 (3.95045 iter/s, 25.3136s/100 iters), loss = 0.276961
I0929 12:39:09.523314 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.276961 (* 1 = 0.276961 loss)
I0929 12:39:09.523327 22954 sgd_solver.cpp:165] Iteration 28800, lr = 0.1
I0929 12:39:34.826881 22954 solver.cpp:357] Iteration 28900 (3.95235 iter/s, 25.3014s/100 iters), loss = 0.443199
I0929 12:39:34.826966 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.443199 (* 1 = 0.443199 loss)
I0929 12:39:34.826977 22954 sgd_solver.cpp:165] Iteration 28900, lr = 0.1
I0929 12:39:35.404776 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:39:59.876158 22954 solver.cpp:514] Iteration 29000, Testing net (#0)
I0929 12:40:19.786228 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:40:19.847705 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.34774 (* 1 = 1.34774 loss)
I0929 12:40:19.847745 22954 solver.cpp:580]     Test net output #1: prob = 0.6147
I0929 12:40:19.847753 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:40:20.062480 22954 solver.cpp:357] Iteration 29000 (2.21076 iter/s, 45.2333s/100 iters), loss = 0.457467
I0929 12:40:20.062544 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.457467 (* 1 = 0.457467 loss)
I0929 12:40:20.062556 22954 sgd_solver.cpp:165] Iteration 29000, lr = 0.1
I0929 12:40:45.376262 22954 solver.cpp:357] Iteration 29100 (3.95077 iter/s, 25.3115s/100 iters), loss = 0.340452
I0929 12:40:45.376386 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.340452 (* 1 = 0.340452 loss)
I0929 12:40:45.376399 22954 sgd_solver.cpp:165] Iteration 29100, lr = 0.1
I0929 12:41:10.692987 22954 solver.cpp:357] Iteration 29200 (3.95031 iter/s, 25.3145s/100 iters), loss = 0.404212
I0929 12:41:10.693068 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.404212 (* 1 = 0.404212 loss)
I0929 12:41:10.693078 22954 sgd_solver.cpp:165] Iteration 29200, lr = 0.1
I0929 12:41:34.055924 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:41:36.016957 22954 solver.cpp:357] Iteration 29300 (3.94918 iter/s, 25.3217s/100 iters), loss = 0.406206
I0929 12:41:36.017027 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.406206 (* 1 = 0.406206 loss)
I0929 12:41:36.017038 22954 sgd_solver.cpp:165] Iteration 29300, lr = 0.1
I0929 12:42:01.328964 22954 solver.cpp:357] Iteration 29400 (3.95104 iter/s, 25.3098s/100 iters), loss = 0.385442
I0929 12:42:01.329046 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.385442 (* 1 = 0.385442 loss)
I0929 12:42:01.329056 22954 sgd_solver.cpp:165] Iteration 29400, lr = 0.1
I0929 12:42:26.440057 22954 solver.cpp:514] Iteration 29500, Testing net (#0)
I0929 12:42:46.194567 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:42:46.299363 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.31382 (* 1 = 1.31382 loss)
I0929 12:42:46.299412 22954 solver.cpp:580]     Test net output #1: prob = 0.6078
I0929 12:42:46.299419 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:42:46.497146 22954 solver.cpp:357] Iteration 29500 (2.21406 iter/s, 45.166s/100 iters), loss = 0.324765
I0929 12:42:46.497231 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.324765 (* 1 = 0.324765 loss)
I0929 12:42:46.497243 22954 sgd_solver.cpp:165] Iteration 29500, lr = 0.1
I0929 12:43:11.838143 22954 solver.cpp:357] Iteration 29600 (3.94652 iter/s, 25.3388s/100 iters), loss = 0.330891
I0929 12:43:11.838263 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.330891 (* 1 = 0.330891 loss)
I0929 12:43:11.838274 22954 sgd_solver.cpp:165] Iteration 29600, lr = 0.1
I0929 12:43:32.858340 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:43:37.127452 22954 solver.cpp:357] Iteration 29700 (3.95458 iter/s, 25.2871s/100 iters), loss = 0.366657
I0929 12:43:37.127537 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.366657 (* 1 = 0.366657 loss)
I0929 12:43:37.127548 22954 sgd_solver.cpp:165] Iteration 29700, lr = 0.1
I0929 12:44:02.496103 22954 solver.cpp:357] Iteration 29800 (3.94221 iter/s, 25.3665s/100 iters), loss = 0.432991
I0929 12:44:02.496301 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.432991 (* 1 = 0.432991 loss)
I0929 12:44:02.496314 22954 sgd_solver.cpp:165] Iteration 29800, lr = 0.1
I0929 12:44:27.814220 22954 solver.cpp:357] Iteration 29900 (3.95007 iter/s, 25.316s/100 iters), loss = 0.431581
I0929 12:44:27.814301 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.431581 (* 1 = 0.431581 loss)
I0929 12:44:27.814312 22954 sgd_solver.cpp:165] Iteration 29900, lr = 0.1
I0929 12:44:52.922016 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_30000.caffemodel
I0929 12:44:52.930932 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_30000.solverstate
I0929 12:44:52.933823 22954 solver.cpp:514] Iteration 30000, Testing net (#0)
I0929 12:45:12.780380 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:45:12.836614 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.12568 (* 1 = 1.12568 loss)
I0929 12:45:12.836658 22954 solver.cpp:580]     Test net output #1: prob = 0.6555
I0929 12:45:12.836668 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:45:13.053748 22954 solver.cpp:357] Iteration 30000 (2.21056 iter/s, 45.2374s/100 iters), loss = 0.311454
I0929 12:45:13.053809 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.311454 (* 1 = 0.311454 loss)
I0929 12:45:13.053822 22954 sgd_solver.cpp:165] Iteration 30000, lr = 0.1
I0929 12:45:31.803412 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:45:38.359424 22954 solver.cpp:357] Iteration 30100 (3.95202 iter/s, 25.3035s/100 iters), loss = 0.395326
I0929 12:45:38.359503 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.395326 (* 1 = 0.395326 loss)
I0929 12:45:38.359514 22954 sgd_solver.cpp:165] Iteration 30100, lr = 0.1
I0929 12:46:03.666498 22954 solver.cpp:357] Iteration 30200 (3.9518 iter/s, 25.3049s/100 iters), loss = 0.538956
I0929 12:46:03.666622 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.538956 (* 1 = 0.538956 loss)
I0929 12:46:03.666633 22954 sgd_solver.cpp:165] Iteration 30200, lr = 0.1
I0929 12:46:28.954754 22954 solver.cpp:357] Iteration 30300 (3.95474 iter/s, 25.2861s/100 iters), loss = 0.432027
I0929 12:46:28.954835 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.432027 (* 1 = 0.432027 loss)
I0929 12:46:28.954846 22954 sgd_solver.cpp:165] Iteration 30300, lr = 0.1
I0929 12:46:54.273147 22954 solver.cpp:357] Iteration 30400 (3.95003 iter/s, 25.3162s/100 iters), loss = 0.265757
I0929 12:46:54.273330 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.265757 (* 1 = 0.265757 loss)
I0929 12:46:54.273344 22954 sgd_solver.cpp:165] Iteration 30400, lr = 0.1
I0929 12:47:10.543439 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:47:19.381388 22954 solver.cpp:514] Iteration 30500, Testing net (#0)
I0929 12:47:39.048904 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:47:39.156734 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.49134 (* 1 = 1.49134 loss)
I0929 12:47:39.156761 22954 solver.cpp:580]     Test net output #1: prob = 0.6406
I0929 12:47:39.156769 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:47:39.367400 22954 solver.cpp:357] Iteration 30500 (2.21768 iter/s, 45.0921s/100 iters), loss = 0.292846
I0929 12:47:39.367487 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.292846 (* 1 = 0.292846 loss)
I0929 12:47:39.367501 22954 sgd_solver.cpp:165] Iteration 30500, lr = 0.1
I0929 12:48:04.769140 22954 solver.cpp:357] Iteration 30600 (3.93707 iter/s, 25.3996s/100 iters), loss = 0.353978
I0929 12:48:04.769222 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.353978 (* 1 = 0.353978 loss)
I0929 12:48:04.769232 22954 sgd_solver.cpp:165] Iteration 30600, lr = 0.1
I0929 12:48:30.091197 22954 solver.cpp:357] Iteration 30700 (3.94946 iter/s, 25.3199s/100 iters), loss = 0.392849
I0929 12:48:30.091467 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.392849 (* 1 = 0.392849 loss)
I0929 12:48:30.091480 22954 sgd_solver.cpp:165] Iteration 30700, lr = 0.1
I0929 12:48:55.373451 22954 solver.cpp:357] Iteration 30800 (3.95568 iter/s, 25.2801s/100 iters), loss = 0.35753
I0929 12:48:55.373536 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.35753 (* 1 = 0.35753 loss)
I0929 12:48:55.373548 22954 sgd_solver.cpp:165] Iteration 30800, lr = 0.1
I0929 12:49:09.389080 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:49:20.739212 22954 solver.cpp:357] Iteration 30900 (3.94265 iter/s, 25.3636s/100 iters), loss = 0.528353
I0929 12:49:20.739292 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.528353 (* 1 = 0.528353 loss)
I0929 12:49:20.739305 22954 sgd_solver.cpp:165] Iteration 30900, lr = 0.1
I0929 12:49:45.840000 22954 solver.cpp:514] Iteration 31000, Testing net (#0)
I0929 12:50:05.494472 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:50:05.599777 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.05241 (* 1 = 1.05241 loss)
I0929 12:50:05.599807 22954 solver.cpp:580]     Test net output #1: prob = 0.6653
I0929 12:50:05.599815 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:50:05.803920 22954 solver.cpp:357] Iteration 31000 (2.21913 iter/s, 45.0626s/100 iters), loss = 0.365532
I0929 12:50:05.803998 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.365532 (* 1 = 0.365532 loss)
I0929 12:50:05.804009 22954 sgd_solver.cpp:165] Iteration 31000, lr = 0.1
I0929 12:50:31.207924 22954 solver.cpp:357] Iteration 31100 (3.93672 iter/s, 25.4019s/100 iters), loss = 0.344695
I0929 12:50:31.208097 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.344695 (* 1 = 0.344695 loss)
I0929 12:50:31.208109 22954 sgd_solver.cpp:165] Iteration 31100, lr = 0.1
I0929 12:50:56.523903 22954 solver.cpp:357] Iteration 31200 (3.95041 iter/s, 25.3139s/100 iters), loss = 0.354746
I0929 12:50:56.523982 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.354746 (* 1 = 0.354746 loss)
I0929 12:50:56.523993 22954 sgd_solver.cpp:165] Iteration 31200, lr = 0.1
I0929 12:51:07.967886 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:51:21.829157 22954 solver.cpp:357] Iteration 31300 (3.95208 iter/s, 25.3031s/100 iters), loss = 0.266189
I0929 12:51:21.829237 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.266189 (* 1 = 0.266189 loss)
I0929 12:51:21.829248 22954 sgd_solver.cpp:165] Iteration 31300, lr = 0.1
I0929 12:51:47.154568 22954 solver.cpp:357] Iteration 31400 (3.94894 iter/s, 25.3233s/100 iters), loss = 0.553068
I0929 12:51:47.154742 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.553068 (* 1 = 0.553068 loss)
I0929 12:51:47.154753 22954 sgd_solver.cpp:165] Iteration 31400, lr = 0.1
I0929 12:52:12.251215 22954 solver.cpp:514] Iteration 31500, Testing net (#0)
I0929 12:52:31.787912 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:52:31.823166 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.1086 (* 1 = 1.1086 loss)
I0929 12:52:31.823196 22954 solver.cpp:580]     Test net output #1: prob = 0.6533
I0929 12:52:31.823204 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:52:32.061529 22954 solver.cpp:357] Iteration 31500 (2.22693 iter/s, 44.9049s/100 iters), loss = 0.318652
I0929 12:52:32.061573 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.318652 (* 1 = 0.318652 loss)
I0929 12:52:32.061588 22954 sgd_solver.cpp:165] Iteration 31500, lr = 0.1
I0929 12:52:57.316473 22954 solver.cpp:357] Iteration 31600 (3.95995 iter/s, 25.2528s/100 iters), loss = 0.408574
I0929 12:52:57.316555 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.408574 (* 1 = 0.408574 loss)
I0929 12:52:57.316566 22954 sgd_solver.cpp:165] Iteration 31600, lr = 0.1
I0929 12:53:06.486207 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:53:22.625855 22954 solver.cpp:357] Iteration 31700 (3.95143 iter/s, 25.3073s/100 iters), loss = 0.468407
I0929 12:53:22.625941 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.468407 (* 1 = 0.468407 loss)
I0929 12:53:22.625952 22954 sgd_solver.cpp:165] Iteration 31700, lr = 0.1
I0929 12:53:47.921710 22954 solver.cpp:357] Iteration 31800 (3.95354 iter/s, 25.2938s/100 iters), loss = 0.339821
I0929 12:53:47.921902 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.339821 (* 1 = 0.339821 loss)
I0929 12:53:47.921914 22954 sgd_solver.cpp:165] Iteration 31800, lr = 0.1
I0929 12:54:13.247193 22954 solver.cpp:357] Iteration 31900 (3.94892 iter/s, 25.3234s/100 iters), loss = 0.415363
I0929 12:54:13.247273 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.415363 (* 1 = 0.415363 loss)
I0929 12:54:13.247284 22954 sgd_solver.cpp:165] Iteration 31900, lr = 0.1
I0929 12:54:38.355859 22954 solver.cpp:514] Iteration 32000, Testing net (#0)
I0929 12:54:58.105986 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:54:58.210907 22954 solver.cpp:580]     Test net output #0: Softmax1 = 1.33924 (* 1 = 1.33924 loss)
I0929 12:54:58.210958 22954 solver.cpp:580]     Test net output #1: prob = 0.6142
I0929 12:54:58.210968 22954 solver.cpp:593]     Max_acc: 0.788  with iter: 20000
I0929 12:54:58.405252 22954 solver.cpp:357] Iteration 32000 (2.21454 iter/s, 45.156s/100 iters), loss = 0.455511
I0929 12:54:58.405313 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.455511 (* 1 = 0.455511 loss)
I0929 12:54:58.405324 22954 sgd_solver.cpp:64] MultiStep Status: Iteration 32000, step = 1
I0929 12:54:58.405330 22954 sgd_solver.cpp:165] Iteration 32000, lr = 0.01
I0929 12:55:05.306394 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:55:23.684651 22954 solver.cpp:357] Iteration 32100 (3.95612 iter/s, 25.2773s/100 iters), loss = 0.276797
I0929 12:55:23.684792 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.276797 (* 1 = 0.276797 loss)
I0929 12:55:23.684805 22954 sgd_solver.cpp:165] Iteration 32100, lr = 0.01
I0929 12:55:49.051959 22954 solver.cpp:357] Iteration 32200 (3.94241 iter/s, 25.3652s/100 iters), loss = 0.366161
I0929 12:55:49.052057 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.366161 (* 1 = 0.366161 loss)
I0929 12:55:49.052070 22954 sgd_solver.cpp:165] Iteration 32200, lr = 0.01
I0929 12:56:14.357116 22954 solver.cpp:357] Iteration 32300 (3.95209 iter/s, 25.3031s/100 iters), loss = 0.273655
I0929 12:56:14.357285 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.273655 (* 1 = 0.273655 loss)
I0929 12:56:14.357295 22954 sgd_solver.cpp:165] Iteration 32300, lr = 0.01
I0929 12:56:39.672135 22954 solver.cpp:357] Iteration 32400 (3.95055 iter/s, 25.3129s/100 iters), loss = 0.267676
I0929 12:56:39.672216 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.267676 (* 1 = 0.267676 loss)
I0929 12:56:39.672227 22954 sgd_solver.cpp:165] Iteration 32400, lr = 0.01
I0929 12:56:44.025660 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:57:04.710166 22954 solver.cpp:514] Iteration 32500, Testing net (#0)
I0929 12:57:24.474932 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:57:24.581343 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.415389 (* 1 = 0.415389 loss)
I0929 12:57:24.581372 22954 solver.cpp:580]     Test net output #1: prob = 0.858601
I0929 12:57:24.581384 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_32500.caffemodel
I0929 12:57:24.590745 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_32500.solverstate
I0929 12:57:24.593421 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 12:57:24.806569 22954 solver.cpp:357] Iteration 32500 (2.2157 iter/s, 45.1324s/100 iters), loss = 0.163671
I0929 12:57:24.806655 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.163671 (* 1 = 0.163671 loss)
I0929 12:57:24.806668 22954 sgd_solver.cpp:165] Iteration 32500, lr = 0.01
I0929 12:57:49.900571 22954 solver.cpp:357] Iteration 32600 (3.98535 iter/s, 25.0919s/100 iters), loss = 0.202898
I0929 12:57:49.900820 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.202898 (* 1 = 0.202898 loss)
I0929 12:57:49.900833 22954 sgd_solver.cpp:165] Iteration 32600, lr = 0.01
I0929 12:58:15.174968 22954 solver.cpp:357] Iteration 32700 (3.9569 iter/s, 25.2723s/100 iters), loss = 0.21824
I0929 12:58:15.175055 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.21824 (* 1 = 0.21824 loss)
I0929 12:58:15.175066 22954 sgd_solver.cpp:165] Iteration 32700, lr = 0.01
I0929 12:58:40.532635 22954 solver.cpp:357] Iteration 32800 (3.94329 iter/s, 25.3595s/100 iters), loss = 0.190327
I0929 12:58:40.532819 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.190327 (* 1 = 0.190327 loss)
I0929 12:58:40.532831 22954 sgd_solver.cpp:165] Iteration 32800, lr = 0.01
I0929 12:58:42.621464 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:59:05.838973 22954 solver.cpp:357] Iteration 32900 (3.9513 iter/s, 25.3082s/100 iters), loss = 0.128109
I0929 12:59:05.839051 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.128108 (* 1 = 0.128108 loss)
I0929 12:59:05.839062 22954 sgd_solver.cpp:165] Iteration 32900, lr = 0.01
I0929 12:59:30.938814 22954 solver.cpp:514] Iteration 33000, Testing net (#0)
I0929 12:59:50.661401 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 12:59:50.765513 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.459811 (* 1 = 0.459811 loss)
I0929 12:59:50.765561 22954 solver.cpp:580]     Test net output #1: prob = 0.839101
I0929 12:59:50.765571 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 12:59:50.979141 22954 solver.cpp:357] Iteration 33000 (2.2151 iter/s, 45.1448s/100 iters), loss = 0.200602
I0929 12:59:50.979224 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.200602 (* 1 = 0.200602 loss)
I0929 12:59:50.979236 22954 sgd_solver.cpp:165] Iteration 33000, lr = 0.01
I0929 13:00:16.329875 22954 solver.cpp:357] Iteration 33100 (3.94444 iter/s, 25.3521s/100 iters), loss = 0.171634
I0929 13:00:16.330065 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.171634 (* 1 = 0.171634 loss)
I0929 13:00:16.330076 22954 sgd_solver.cpp:165] Iteration 33100, lr = 0.01
I0929 13:00:41.442852 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:00:41.651105 22954 solver.cpp:357] Iteration 33200 (3.94905 iter/s, 25.3225s/100 iters), loss = 0.227952
I0929 13:00:41.651170 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.227952 (* 1 = 0.227952 loss)
I0929 13:00:41.651183 22954 sgd_solver.cpp:165] Iteration 33200, lr = 0.01
I0929 13:01:06.968890 22954 solver.cpp:357] Iteration 33300 (3.94961 iter/s, 25.3189s/100 iters), loss = 0.224437
I0929 13:01:06.969039 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.224437 (* 1 = 0.224437 loss)
I0929 13:01:06.969053 22954 sgd_solver.cpp:165] Iteration 33300, lr = 0.01
I0929 13:01:32.287971 22954 solver.cpp:357] Iteration 33400 (3.94943 iter/s, 25.3201s/100 iters), loss = 0.169943
I0929 13:01:32.288053 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.169943 (* 1 = 0.169943 loss)
I0929 13:01:32.288064 22954 sgd_solver.cpp:165] Iteration 33400, lr = 0.01
I0929 13:01:57.401510 22954 solver.cpp:514] Iteration 33500, Testing net (#0)
I0929 13:02:17.247763 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:02:17.345717 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.4762 (* 1 = 0.4762 loss)
I0929 13:02:17.345746 22954 solver.cpp:580]     Test net output #1: prob = 0.838101
I0929 13:02:17.345752 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:02:17.582509 22954 solver.cpp:357] Iteration 33500 (2.20761 iter/s, 45.2979s/100 iters), loss = 0.199403
I0929 13:02:17.582556 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.199403 (* 1 = 0.199403 loss)
I0929 13:02:17.582566 22954 sgd_solver.cpp:165] Iteration 33500, lr = 0.01
I0929 13:02:40.217066 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:02:42.957625 22954 solver.cpp:357] Iteration 33600 (3.94076 iter/s, 25.3758s/100 iters), loss = 0.336342
I0929 13:02:42.957713 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.336342 (* 1 = 0.336342 loss)
I0929 13:02:42.957726 22954 sgd_solver.cpp:165] Iteration 33600, lr = 0.01
I0929 13:03:08.294664 22954 solver.cpp:357] Iteration 33700 (3.94669 iter/s, 25.3377s/100 iters), loss = 0.235102
I0929 13:03:08.294756 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.235102 (* 1 = 0.235102 loss)
I0929 13:03:08.294770 22954 sgd_solver.cpp:165] Iteration 33700, lr = 0.01
I0929 13:03:33.565219 22954 solver.cpp:357] Iteration 33800 (3.95709 iter/s, 25.2711s/100 iters), loss = 0.150135
I0929 13:03:33.565362 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.150135 (* 1 = 0.150135 loss)
I0929 13:03:33.565376 22954 sgd_solver.cpp:165] Iteration 33800, lr = 0.01
I0929 13:03:58.915298 22954 solver.cpp:357] Iteration 33900 (3.9447 iter/s, 25.3505s/100 iters), loss = 0.173605
I0929 13:03:58.915388 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.173605 (* 1 = 0.173605 loss)
I0929 13:03:58.915401 22954 sgd_solver.cpp:165] Iteration 33900, lr = 0.01
I0929 13:04:19.185503 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:04:23.992656 22954 solver.cpp:514] Iteration 34000, Testing net (#0)
I0929 13:04:43.791038 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:04:43.896739 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.682528 (* 1 = 0.682528 loss)
I0929 13:04:43.896766 22954 solver.cpp:580]     Test net output #1: prob = 0.777501
I0929 13:04:43.896772 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:04:44.119838 22954 solver.cpp:357] Iteration 34000 (2.21198 iter/s, 45.2083s/100 iters), loss = 0.140211
I0929 13:04:44.119909 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.140211 (* 1 = 0.140211 loss)
I0929 13:04:44.119920 22954 sgd_solver.cpp:165] Iteration 34000, lr = 0.01
I0929 13:05:09.428347 22954 solver.cpp:357] Iteration 34100 (3.95088 iter/s, 25.3108s/100 iters), loss = 0.166821
I0929 13:05:09.428537 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.166821 (* 1 = 0.166821 loss)
I0929 13:05:09.428551 22954 sgd_solver.cpp:165] Iteration 34100, lr = 0.01
I0929 13:05:34.740846 22954 solver.cpp:357] Iteration 34200 (3.95038 iter/s, 25.314s/100 iters), loss = 0.0920191
I0929 13:05:34.740936 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0920191 (* 1 = 0.0920191 loss)
I0929 13:05:34.740948 22954 sgd_solver.cpp:165] Iteration 34200, lr = 0.01
I0929 13:06:00.012146 22954 solver.cpp:357] Iteration 34300 (3.95705 iter/s, 25.2714s/100 iters), loss = 0.0986921
I0929 13:06:00.012300 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0986921 (* 1 = 0.0986921 loss)
I0929 13:06:00.012310 22954 sgd_solver.cpp:165] Iteration 34300, lr = 0.01
I0929 13:06:17.807080 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:06:25.382463 22954 solver.cpp:357] Iteration 34400 (3.94131 iter/s, 25.3723s/100 iters), loss = 0.281753
I0929 13:06:25.382560 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.281753 (* 1 = 0.281753 loss)
I0929 13:06:25.382571 22954 sgd_solver.cpp:165] Iteration 34400, lr = 0.01
I0929 13:06:50.432412 22954 solver.cpp:514] Iteration 34500, Testing net (#0)
I0929 13:07:10.061833 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:07:10.091035 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.651427 (* 1 = 0.651427 loss)
I0929 13:07:10.091063 22954 solver.cpp:580]     Test net output #1: prob = 0.7846
I0929 13:07:10.091070 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:07:10.299949 22954 solver.cpp:357] Iteration 34500 (2.22615 iter/s, 44.9205s/100 iters), loss = 0.0698799
I0929 13:07:10.300034 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0698799 (* 1 = 0.0698799 loss)
I0929 13:07:10.300046 22954 sgd_solver.cpp:165] Iteration 34500, lr = 0.01
I0929 13:07:35.657948 22954 solver.cpp:357] Iteration 34600 (3.94356 iter/s, 25.3578s/100 iters), loss = 0.173338
I0929 13:07:35.658150 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.173338 (* 1 = 0.173338 loss)
I0929 13:07:35.658161 22954 sgd_solver.cpp:165] Iteration 34600, lr = 0.01
I0929 13:08:00.968080 22954 solver.cpp:357] Iteration 34700 (3.95103 iter/s, 25.3099s/100 iters), loss = 0.109633
I0929 13:08:00.968160 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.109633 (* 1 = 0.109633 loss)
I0929 13:08:00.968170 22954 sgd_solver.cpp:165] Iteration 34700, lr = 0.01
I0929 13:08:16.466944 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:08:26.291885 22954 solver.cpp:357] Iteration 34800 (3.94891 iter/s, 25.3235s/100 iters), loss = 0.141995
I0929 13:08:26.291966 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.141995 (* 1 = 0.141995 loss)
I0929 13:08:26.291977 22954 sgd_solver.cpp:165] Iteration 34800, lr = 0.01
I0929 13:08:51.576769 22954 solver.cpp:357] Iteration 34900 (3.95499 iter/s, 25.2845s/100 iters), loss = 0.13973
I0929 13:08:51.576910 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.13973 (* 1 = 0.13973 loss)
I0929 13:08:51.576922 22954 sgd_solver.cpp:165] Iteration 34900, lr = 0.01
I0929 13:09:16.731252 22954 solver.cpp:514] Iteration 35000, Testing net (#0)
I0929 13:09:36.246443 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:09:36.295871 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.597033 (* 1 = 0.597033 loss)
I0929 13:09:36.295902 22954 solver.cpp:580]     Test net output #1: prob = 0.803501
I0929 13:09:36.295907 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:09:36.535249 22954 solver.cpp:357] Iteration 35000 (2.22423 iter/s, 44.9594s/100 iters), loss = 0.151383
I0929 13:09:36.535296 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.151383 (* 1 = 0.151383 loss)
I0929 13:09:36.535310 22954 sgd_solver.cpp:165] Iteration 35000, lr = 0.01
I0929 13:10:01.925418 22954 solver.cpp:357] Iteration 35100 (3.93862 iter/s, 25.3896s/100 iters), loss = 0.155212
I0929 13:10:01.925509 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.155212 (* 1 = 0.155212 loss)
I0929 13:10:01.925523 22954 sgd_solver.cpp:165] Iteration 35100, lr = 0.01
I0929 13:10:15.131359 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:10:27.276190 22954 solver.cpp:357] Iteration 35200 (3.94474 iter/s, 25.3502s/100 iters), loss = 0.181214
I0929 13:10:27.276286 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.181214 (* 1 = 0.181214 loss)
I0929 13:10:27.276299 22954 sgd_solver.cpp:165] Iteration 35200, lr = 0.01
I0929 13:10:52.579746 22954 solver.cpp:357] Iteration 35300 (3.95187 iter/s, 25.3045s/100 iters), loss = 0.137807
I0929 13:10:52.579881 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.137807 (* 1 = 0.137807 loss)
I0929 13:10:52.579893 22954 sgd_solver.cpp:165] Iteration 35300, lr = 0.01
I0929 13:11:17.893692 22954 solver.cpp:357] Iteration 35400 (3.95021 iter/s, 25.3151s/100 iters), loss = 0.0937903
I0929 13:11:17.893780 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0937903 (* 1 = 0.0937903 loss)
I0929 13:11:17.893792 22954 sgd_solver.cpp:165] Iteration 35400, lr = 0.01
I0929 13:11:42.912493 22954 solver.cpp:514] Iteration 35500, Testing net (#0)
I0929 13:12:02.679630 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:12:02.751857 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.706839 (* 1 = 0.706839 loss)
I0929 13:12:02.751888 22954 solver.cpp:580]     Test net output #1: prob = 0.7738
I0929 13:12:02.751894 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:12:02.990833 22954 solver.cpp:357] Iteration 35500 (2.21741 iter/s, 45.0976s/100 iters), loss = 0.160377
I0929 13:12:02.990876 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.160377 (* 1 = 0.160377 loss)
I0929 13:12:02.990888 22954 sgd_solver.cpp:165] Iteration 35500, lr = 0.01
I0929 13:12:13.729800 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:12:28.343485 22954 solver.cpp:357] Iteration 35600 (3.94447 iter/s, 25.3519s/100 iters), loss = 0.157603
I0929 13:12:28.343549 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.157603 (* 1 = 0.157603 loss)
I0929 13:12:28.343560 22954 sgd_solver.cpp:165] Iteration 35600, lr = 0.01
I0929 13:12:53.719748 22954 solver.cpp:357] Iteration 35700 (3.94048 iter/s, 25.3776s/100 iters), loss = 0.212863
I0929 13:12:53.719944 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.212863 (* 1 = 0.212863 loss)
I0929 13:12:53.719956 22954 sgd_solver.cpp:165] Iteration 35700, lr = 0.01
I0929 13:13:19.042065 22954 solver.cpp:357] Iteration 35800 (3.94921 iter/s, 25.3215s/100 iters), loss = 0.144968
I0929 13:13:19.042153 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.144968 (* 1 = 0.144968 loss)
I0929 13:13:19.042166 22954 sgd_solver.cpp:165] Iteration 35800, lr = 0.01
I0929 13:13:44.362215 22954 solver.cpp:357] Iteration 35900 (3.94956 iter/s, 25.3193s/100 iters), loss = 0.149875
I0929 13:13:44.362395 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.149875 (* 1 = 0.149875 loss)
I0929 13:13:44.362406 22954 sgd_solver.cpp:165] Iteration 35900, lr = 0.01
I0929 13:13:52.726024 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:14:09.434903 22954 solver.cpp:514] Iteration 36000, Testing net (#0)
I0929 13:14:29.138391 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:14:29.234917 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.580662 (* 1 = 0.580662 loss)
I0929 13:14:29.234946 22954 solver.cpp:580]     Test net output #1: prob = 0.8074
I0929 13:14:29.234951 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:14:29.471772 22954 solver.cpp:357] Iteration 36000 (2.21673 iter/s, 45.1115s/100 iters), loss = 0.208132
I0929 13:14:29.471817 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.208132 (* 1 = 0.208132 loss)
I0929 13:14:29.471828 22954 sgd_solver.cpp:165] Iteration 36000, lr = 0.01
I0929 13:14:54.849814 22954 solver.cpp:357] Iteration 36100 (3.94056 iter/s, 25.3771s/100 iters), loss = 0.212773
I0929 13:14:54.849903 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.212773 (* 1 = 0.212773 loss)
I0929 13:14:54.849916 22954 sgd_solver.cpp:165] Iteration 36100, lr = 0.01
I0929 13:15:20.130753 22954 solver.cpp:357] Iteration 36200 (3.95569 iter/s, 25.28s/100 iters), loss = 0.061818
I0929 13:15:20.130909 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.061818 (* 1 = 0.061818 loss)
I0929 13:15:20.130921 22954 sgd_solver.cpp:165] Iteration 36200, lr = 0.01
I0929 13:15:45.493021 22954 solver.cpp:357] Iteration 36300 (3.94301 iter/s, 25.3613s/100 iters), loss = 0.225804
I0929 13:15:45.493111 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.225804 (* 1 = 0.225804 loss)
I0929 13:15:45.493124 22954 sgd_solver.cpp:165] Iteration 36300, lr = 0.01
I0929 13:15:51.576735 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:16:10.803472 22954 solver.cpp:357] Iteration 36400 (3.95109 iter/s, 25.3095s/100 iters), loss = 0.11322
I0929 13:16:10.803558 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.11322 (* 1 = 0.11322 loss)
I0929 13:16:10.803571 22954 sgd_solver.cpp:165] Iteration 36400, lr = 0.01
I0929 13:16:35.886415 22954 solver.cpp:514] Iteration 36500, Testing net (#0)
I0929 13:16:55.586670 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:16:55.636111 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.515095 (* 1 = 0.515095 loss)
I0929 13:16:55.636140 22954 solver.cpp:580]     Test net output #1: prob = 0.826001
I0929 13:16:55.636147 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:16:55.874990 22954 solver.cpp:357] Iteration 36500 (2.2187 iter/s, 45.0714s/100 iters), loss = 0.118424
I0929 13:16:55.875039 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.118424 (* 1 = 0.118424 loss)
I0929 13:16:55.875054 22954 sgd_solver.cpp:165] Iteration 36500, lr = 0.01
I0929 13:17:21.300446 22954 solver.cpp:357] Iteration 36600 (3.93323 iter/s, 25.4244s/100 iters), loss = 0.114763
I0929 13:17:21.300700 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.114763 (* 1 = 0.114763 loss)
I0929 13:17:21.300719 22954 sgd_solver.cpp:165] Iteration 36600, lr = 0.01
I0929 13:17:46.554287 22954 solver.cpp:357] Iteration 36700 (3.95996 iter/s, 25.2528s/100 iters), loss = 0.0983412
I0929 13:17:46.554354 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0983412 (* 1 = 0.0983412 loss)
I0929 13:17:46.554363 22954 sgd_solver.cpp:165] Iteration 36700, lr = 0.01
I0929 13:17:50.164494 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:18:11.925170 22954 solver.cpp:357] Iteration 36800 (3.94137 iter/s, 25.3719s/100 iters), loss = 0.19621
I0929 13:18:11.925314 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.19621 (* 1 = 0.19621 loss)
I0929 13:18:11.925328 22954 sgd_solver.cpp:165] Iteration 36800, lr = 0.01
I0929 13:18:37.231734 22954 solver.cpp:357] Iteration 36900 (3.95144 iter/s, 25.3072s/100 iters), loss = 0.182327
I0929 13:18:37.231824 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.182327 (* 1 = 0.182327 loss)
I0929 13:18:37.231837 22954 sgd_solver.cpp:165] Iteration 36900, lr = 0.01
I0929 13:19:02.287819 22954 solver.cpp:514] Iteration 37000, Testing net (#0)
I0929 13:19:21.982161 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:19:22.031916 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.580795 (* 1 = 0.580795 loss)
I0929 13:19:22.031945 22954 solver.cpp:580]     Test net output #1: prob = 0.8086
I0929 13:19:22.031951 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:19:22.270855 22954 solver.cpp:357] Iteration 37000 (2.22022 iter/s, 45.0405s/100 iters), loss = 0.147735
I0929 13:19:22.270898 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.147734 (* 1 = 0.147734 loss)
I0929 13:19:22.270911 22954 sgd_solver.cpp:165] Iteration 37000, lr = 0.01
I0929 13:19:47.679925 22954 solver.cpp:357] Iteration 37100 (3.93578 iter/s, 25.4079s/100 iters), loss = 0.101461
I0929 13:19:47.680112 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.101461 (* 1 = 0.101461 loss)
I0929 13:19:47.680126 22954 sgd_solver.cpp:165] Iteration 37100, lr = 0.01
I0929 13:19:48.970793 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:20:12.991858 22954 solver.cpp:357] Iteration 37200 (3.95063 iter/s, 25.3124s/100 iters), loss = 0.144737
I0929 13:20:12.991946 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.144737 (* 1 = 0.144737 loss)
I0929 13:20:12.991960 22954 sgd_solver.cpp:165] Iteration 37200, lr = 0.01
I0929 13:20:38.266198 22954 solver.cpp:357] Iteration 37300 (3.95651 iter/s, 25.2748s/100 iters), loss = 0.17248
I0929 13:20:38.266382 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.17248 (* 1 = 0.17248 loss)
I0929 13:20:38.266410 22954 sgd_solver.cpp:165] Iteration 37300, lr = 0.01
I0929 13:21:03.620163 22954 solver.cpp:357] Iteration 37400 (3.94434 iter/s, 25.3528s/100 iters), loss = 0.182915
I0929 13:21:03.620254 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.182915 (* 1 = 0.182915 loss)
I0929 13:21:03.620266 22954 sgd_solver.cpp:165] Iteration 37400, lr = 0.01
I0929 13:21:27.710238 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:21:28.696497 22954 solver.cpp:514] Iteration 37500, Testing net (#0)
I0929 13:21:48.434156 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:21:48.542238 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.617214 (* 1 = 0.617214 loss)
I0929 13:21:48.542268 22954 solver.cpp:580]     Test net output #1: prob = 0.8024
I0929 13:21:48.542273 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:21:48.777165 22954 solver.cpp:357] Iteration 37500 (2.21451 iter/s, 45.1566s/100 iters), loss = 0.130303
I0929 13:21:48.777278 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.130303 (* 1 = 0.130303 loss)
I0929 13:21:48.777305 22954 sgd_solver.cpp:165] Iteration 37500, lr = 0.01
I0929 13:22:14.151140 22954 solver.cpp:357] Iteration 37600 (3.94123 iter/s, 25.3728s/100 iters), loss = 0.125316
I0929 13:22:14.151448 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.125316 (* 1 = 0.125316 loss)
I0929 13:22:14.151474 22954 sgd_solver.cpp:165] Iteration 37600, lr = 0.01
I0929 13:22:39.477895 22954 solver.cpp:357] Iteration 37700 (3.9483 iter/s, 25.3274s/100 iters), loss = 0.239767
I0929 13:22:39.477990 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.239767 (* 1 = 0.239767 loss)
I0929 13:22:39.478003 22954 sgd_solver.cpp:165] Iteration 37700, lr = 0.01
I0929 13:23:04.711982 22954 solver.cpp:357] Iteration 37800 (3.96284 iter/s, 25.2344s/100 iters), loss = 0.153722
I0929 13:23:04.712092 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.153722 (* 1 = 0.153722 loss)
I0929 13:23:04.712101 22954 sgd_solver.cpp:165] Iteration 37800, lr = 0.01
I0929 13:23:26.555990 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:23:30.079716 22954 solver.cpp:357] Iteration 37900 (3.9419 iter/s, 25.3685s/100 iters), loss = 0.159601
I0929 13:23:30.079810 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.159601 (* 1 = 0.159601 loss)
I0929 13:23:30.079823 22954 sgd_solver.cpp:165] Iteration 37900, lr = 0.01
I0929 13:23:55.168352 22954 solver.cpp:514] Iteration 38000, Testing net (#0)
I0929 13:24:14.889236 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:24:14.995365 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.606597 (* 1 = 0.606597 loss)
I0929 13:24:14.995393 22954 solver.cpp:580]     Test net output #1: prob = 0.804601
I0929 13:24:14.995399 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:24:15.230306 22954 solver.cpp:357] Iteration 38000 (2.21483 iter/s, 45.1501s/100 iters), loss = 0.0866497
I0929 13:24:15.230352 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0866496 (* 1 = 0.0866496 loss)
I0929 13:24:15.230363 22954 sgd_solver.cpp:165] Iteration 38000, lr = 0.01
I0929 13:24:40.603873 22954 solver.cpp:357] Iteration 38100 (3.94131 iter/s, 25.3723s/100 iters), loss = 0.135722
I0929 13:24:40.604018 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.135722 (* 1 = 0.135722 loss)
I0929 13:24:40.604032 22954 sgd_solver.cpp:165] Iteration 38100, lr = 0.01
I0929 13:25:05.919391 22954 solver.cpp:357] Iteration 38200 (3.95009 iter/s, 25.3159s/100 iters), loss = 0.0805234
I0929 13:25:05.919531 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0805233 (* 1 = 0.0805233 loss)
I0929 13:25:05.919548 22954 sgd_solver.cpp:165] Iteration 38200, lr = 0.01
I0929 13:25:25.426193 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:25:31.226166 22954 solver.cpp:357] Iteration 38300 (3.95139 iter/s, 25.3076s/100 iters), loss = 0.147557
I0929 13:25:31.226258 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.147557 (* 1 = 0.147557 loss)
I0929 13:25:31.226270 22954 sgd_solver.cpp:165] Iteration 38300, lr = 0.01
I0929 13:25:56.492729 22954 solver.cpp:357] Iteration 38400 (3.95799 iter/s, 25.2653s/100 iters), loss = 0.101415
I0929 13:25:56.492849 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.101415 (* 1 = 0.101415 loss)
I0929 13:25:56.492861 22954 sgd_solver.cpp:165] Iteration 38400, lr = 0.01
I0929 13:26:21.602262 22954 solver.cpp:514] Iteration 38500, Testing net (#0)
I0929 13:26:41.302844 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:26:41.350899 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.531241 (* 1 = 0.531241 loss)
I0929 13:26:41.350930 22954 solver.cpp:580]     Test net output #1: prob = 0.8282
I0929 13:26:41.350937 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:26:41.589974 22954 solver.cpp:357] Iteration 38500 (2.21746 iter/s, 45.0967s/100 iters), loss = 0.120567
I0929 13:26:41.590018 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.120567 (* 1 = 0.120567 loss)
I0929 13:26:41.590029 22954 sgd_solver.cpp:165] Iteration 38500, lr = 0.01
I0929 13:27:06.845322 22954 solver.cpp:357] Iteration 38600 (3.95976 iter/s, 25.254s/100 iters), loss = 0.0786229
I0929 13:27:06.845405 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0786229 (* 1 = 0.0786229 loss)
I0929 13:27:06.845417 22954 sgd_solver.cpp:165] Iteration 38600, lr = 0.01
I0929 13:27:23.858417 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:27:32.157665 22954 solver.cpp:357] Iteration 38700 (3.95084 iter/s, 25.311s/100 iters), loss = 0.127189
I0929 13:27:32.157742 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.127189 (* 1 = 0.127189 loss)
I0929 13:27:32.157752 22954 sgd_solver.cpp:165] Iteration 38700, lr = 0.01
I0929 13:27:57.484756 22954 solver.cpp:357] Iteration 38800 (3.94855 iter/s, 25.3258s/100 iters), loss = 0.0968638
I0929 13:27:57.484935 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0968637 (* 1 = 0.0968637 loss)
I0929 13:27:57.484946 22954 sgd_solver.cpp:165] Iteration 38800, lr = 0.01
I0929 13:28:22.796818 22954 solver.cpp:357] Iteration 38900 (3.95089 iter/s, 25.3107s/100 iters), loss = 0.11147
I0929 13:28:22.796900 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.11147 (* 1 = 0.11147 loss)
I0929 13:28:22.796911 22954 sgd_solver.cpp:165] Iteration 38900, lr = 0.01
I0929 13:28:47.899859 22954 solver.cpp:514] Iteration 39000, Testing net (#0)
I0929 13:29:07.473623 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:29:07.579519 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.508815 (* 1 = 0.508815 loss)
I0929 13:29:07.579548 22954 solver.cpp:580]     Test net output #1: prob = 0.835401
I0929 13:29:07.579555 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:29:07.818305 22954 solver.cpp:357] Iteration 39000 (2.22119 iter/s, 45.0209s/100 iters), loss = 0.0805816
I0929 13:29:07.818351 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0805816 (* 1 = 0.0805816 loss)
I0929 13:29:07.818365 22954 sgd_solver.cpp:165] Iteration 39000, lr = 0.01
I0929 13:29:22.579627 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:29:33.139616 22954 solver.cpp:357] Iteration 39100 (3.94945 iter/s, 25.32s/100 iters), loss = 0.126433
I0929 13:29:33.139680 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.126433 (* 1 = 0.126433 loss)
I0929 13:29:33.139690 22954 sgd_solver.cpp:165] Iteration 39100, lr = 0.01
I0929 13:29:58.502331 22954 solver.cpp:357] Iteration 39200 (3.94268 iter/s, 25.3635s/100 iters), loss = 0.177815
I0929 13:29:58.502506 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.177815 (* 1 = 0.177815 loss)
I0929 13:29:58.502519 22954 sgd_solver.cpp:165] Iteration 39200, lr = 0.01
I0929 13:30:23.836796 22954 solver.cpp:357] Iteration 39300 (3.9474 iter/s, 25.3331s/100 iters), loss = 0.109843
I0929 13:30:23.836874 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.109843 (* 1 = 0.109843 loss)
I0929 13:30:23.836885 22954 sgd_solver.cpp:165] Iteration 39300, lr = 0.01
I0929 13:30:49.136245 22954 solver.cpp:357] Iteration 39400 (3.95253 iter/s, 25.3002s/100 iters), loss = 0.096152
I0929 13:30:49.136407 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0961519 (* 1 = 0.0961519 loss)
I0929 13:30:49.136420 22954 sgd_solver.cpp:165] Iteration 39400, lr = 0.01
I0929 13:31:01.568228 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:31:14.208323 22954 solver.cpp:514] Iteration 39500, Testing net (#0)
I0929 13:31:33.882869 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:31:33.940646 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.512826 (* 1 = 0.512826 loss)
I0929 13:31:33.940690 22954 solver.cpp:580]     Test net output #1: prob = 0.837701
I0929 13:31:33.940696 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:31:34.156939 22954 solver.cpp:357] Iteration 39500 (2.22123 iter/s, 45.02s/100 iters), loss = 0.0862334
I0929 13:31:34.157002 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0862334 (* 1 = 0.0862334 loss)
I0929 13:31:34.157014 22954 sgd_solver.cpp:165] Iteration 39500, lr = 0.01
I0929 13:31:59.444360 22954 solver.cpp:357] Iteration 39600 (3.95475 iter/s, 25.2861s/100 iters), loss = 0.148368
I0929 13:31:59.444442 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.148368 (* 1 = 0.148368 loss)
I0929 13:31:59.444453 22954 sgd_solver.cpp:165] Iteration 39600, lr = 0.01
I0929 13:32:24.714857 22954 solver.cpp:357] Iteration 39700 (3.95741 iter/s, 25.2691s/100 iters), loss = 0.0813973
I0929 13:32:24.715044 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0813973 (* 1 = 0.0813973 loss)
I0929 13:32:24.715056 22954 sgd_solver.cpp:165] Iteration 39700, lr = 0.01
I0929 13:32:50.074506 22954 solver.cpp:357] Iteration 39800 (3.9438 iter/s, 25.3563s/100 iters), loss = 0.109916
I0929 13:32:50.074584 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.109916 (* 1 = 0.109916 loss)
I0929 13:32:50.074595 22954 sgd_solver.cpp:165] Iteration 39800, lr = 0.01
I0929 13:32:59.992146 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:33:15.387374 22954 solver.cpp:357] Iteration 39900 (3.95107 iter/s, 25.3096s/100 iters), loss = 0.0893406
I0929 13:33:15.387456 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0893406 (* 1 = 0.0893406 loss)
I0929 13:33:15.387466 22954 sgd_solver.cpp:165] Iteration 39900, lr = 0.01
I0929 13:33:40.499222 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_40000.caffemodel
I0929 13:33:40.507618 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_40000.solverstate
I0929 13:33:40.510596 22954 solver.cpp:514] Iteration 40000, Testing net (#0)
I0929 13:34:00.258980 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:34:00.377882 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.477149 (* 1 = 0.477149 loss)
I0929 13:34:00.377997 22954 solver.cpp:580]     Test net output #1: prob = 0.849801
I0929 13:34:00.378026 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:34:00.570454 22954 solver.cpp:357] Iteration 40000 (2.21341 iter/s, 45.1791s/100 iters), loss = 0.154533
I0929 13:34:00.570538 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.154533 (* 1 = 0.154533 loss)
I0929 13:34:00.570549 22954 sgd_solver.cpp:165] Iteration 40000, lr = 0.01
I0929 13:34:25.916321 22954 solver.cpp:357] Iteration 40100 (3.9459 iter/s, 25.3428s/100 iters), loss = 0.121793
I0929 13:34:25.916496 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.121793 (* 1 = 0.121793 loss)
I0929 13:34:25.916507 22954 sgd_solver.cpp:165] Iteration 40100, lr = 0.01
I0929 13:34:51.228943 22954 solver.cpp:357] Iteration 40200 (3.95107 iter/s, 25.3096s/100 iters), loss = 0.205535
I0929 13:34:51.229022 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.205535 (* 1 = 0.205535 loss)
I0929 13:34:51.229033 22954 sgd_solver.cpp:165] Iteration 40200, lr = 0.01
I0929 13:34:58.900885 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:35:16.553552 22954 solver.cpp:357] Iteration 40300 (3.94919 iter/s, 25.3217s/100 iters), loss = 0.12645
I0929 13:35:16.553632 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.12645 (* 1 = 0.12645 loss)
I0929 13:35:16.553643 22954 sgd_solver.cpp:165] Iteration 40300, lr = 0.01
I0929 13:35:41.868995 22954 solver.cpp:357] Iteration 40400 (3.95061 iter/s, 25.3125s/100 iters), loss = 0.184849
I0929 13:35:41.869125 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.184849 (* 1 = 0.184849 loss)
I0929 13:35:41.869137 22954 sgd_solver.cpp:165] Iteration 40400, lr = 0.01
I0929 13:36:06.971082 22954 solver.cpp:514] Iteration 40500, Testing net (#0)
I0929 13:36:26.550963 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:36:26.658669 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.566619 (* 1 = 0.566619 loss)
I0929 13:36:26.658696 22954 solver.cpp:580]     Test net output #1: prob = 0.820101
I0929 13:36:26.658702 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:36:26.894090 22954 solver.cpp:357] Iteration 40500 (2.22115 iter/s, 45.0218s/100 iters), loss = 0.126786
I0929 13:36:26.894207 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.126786 (* 1 = 0.126786 loss)
I0929 13:36:26.894222 22954 sgd_solver.cpp:165] Iteration 40500, lr = 0.01
I0929 13:36:52.220660 22954 solver.cpp:357] Iteration 40600 (3.94885 iter/s, 25.3238s/100 iters), loss = 0.0871093
I0929 13:36:52.220746 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0871093 (* 1 = 0.0871093 loss)
I0929 13:36:52.220758 22954 sgd_solver.cpp:165] Iteration 40600, lr = 0.01
I0929 13:36:57.308423 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:37:17.550786 22954 solver.cpp:357] Iteration 40700 (3.94828 iter/s, 25.3275s/100 iters), loss = 0.124183
I0929 13:37:17.550870 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.124183 (* 1 = 0.124183 loss)
I0929 13:37:17.550884 22954 sgd_solver.cpp:165] Iteration 40700, lr = 0.01
I0929 13:37:42.809280 22954 solver.cpp:357] Iteration 40800 (3.95921 iter/s, 25.2576s/100 iters), loss = 0.103334
I0929 13:37:42.809360 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.103334 (* 1 = 0.103334 loss)
I0929 13:37:42.809368 22954 sgd_solver.cpp:165] Iteration 40800, lr = 0.01
I0929 13:38:08.188920 22954 solver.cpp:357] Iteration 40900 (3.94024 iter/s, 25.3791s/100 iters), loss = 0.0856026
I0929 13:38:08.189013 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0856025 (* 1 = 0.0856025 loss)
I0929 13:38:08.189025 22954 sgd_solver.cpp:165] Iteration 40900, lr = 0.01
I0929 13:38:33.251972 22954 solver.cpp:514] Iteration 41000, Testing net (#0)
I0929 13:38:53.105573 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:38:53.213312 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.482844 (* 1 = 0.482844 loss)
I0929 13:38:53.213344 22954 solver.cpp:580]     Test net output #1: prob = 0.844301
I0929 13:38:53.213351 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:38:53.429467 22954 solver.cpp:357] Iteration 41000 (2.21047 iter/s, 45.2393s/100 iters), loss = 0.107294
I0929 13:38:53.429553 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.107294 (* 1 = 0.107294 loss)
I0929 13:38:53.429564 22954 sgd_solver.cpp:165] Iteration 41000, lr = 0.01
I0929 13:38:56.319125 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:39:18.796550 22954 solver.cpp:357] Iteration 41100 (3.9425 iter/s, 25.3646s/100 iters), loss = 0.0895716
I0929 13:39:18.796680 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0895715 (* 1 = 0.0895715 loss)
I0929 13:39:18.796691 22954 sgd_solver.cpp:165] Iteration 41100, lr = 0.01
I0929 13:39:44.107350 22954 solver.cpp:357] Iteration 41200 (3.95126 iter/s, 25.3084s/100 iters), loss = 0.086268
I0929 13:39:44.107425 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.086268 (* 1 = 0.086268 loss)
I0929 13:39:44.107436 22954 sgd_solver.cpp:165] Iteration 41200, lr = 0.01
I0929 13:40:09.425190 22954 solver.cpp:357] Iteration 41300 (3.95016 iter/s, 25.3155s/100 iters), loss = 0.129326
I0929 13:40:09.425355 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.129326 (* 1 = 0.129326 loss)
I0929 13:40:09.425369 22954 sgd_solver.cpp:165] Iteration 41300, lr = 0.01
I0929 13:40:34.747987 22954 solver.cpp:357] Iteration 41400 (3.94938 iter/s, 25.3204s/100 iters), loss = 0.0940811
I0929 13:40:34.748071 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0940811 (* 1 = 0.0940811 loss)
I0929 13:40:34.748083 22954 sgd_solver.cpp:165] Iteration 41400, lr = 0.01
I0929 13:40:35.317648 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:40:59.833429 22954 solver.cpp:514] Iteration 41500, Testing net (#0)
I0929 13:41:19.643656 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:41:19.706159 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.646885 (* 1 = 0.646885 loss)
I0929 13:41:19.706204 22954 solver.cpp:580]     Test net output #1: prob = 0.7968
I0929 13:41:19.706212 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:41:19.901065 22954 solver.cpp:357] Iteration 41500 (2.2148 iter/s, 45.1507s/100 iters), loss = 0.0846315
I0929 13:41:19.901146 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0846314 (* 1 = 0.0846314 loss)
I0929 13:41:19.901157 22954 sgd_solver.cpp:165] Iteration 41500, lr = 0.01
I0929 13:41:45.244670 22954 solver.cpp:357] Iteration 41600 (3.94612 iter/s, 25.3414s/100 iters), loss = 0.176395
I0929 13:41:45.244856 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.176395 (* 1 = 0.176395 loss)
I0929 13:41:45.244868 22954 sgd_solver.cpp:165] Iteration 41600, lr = 0.01
I0929 13:42:10.542944 22954 solver.cpp:357] Iteration 41700 (3.95319 iter/s, 25.2961s/100 iters), loss = 0.0958866
I0929 13:42:10.543032 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0958866 (* 1 = 0.0958866 loss)
I0929 13:42:10.543045 22954 sgd_solver.cpp:165] Iteration 41700, lr = 0.01
I0929 13:42:33.889514 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:42:35.842717 22954 solver.cpp:357] Iteration 41800 (3.95295 iter/s, 25.2976s/100 iters), loss = 0.158338
I0929 13:42:35.842795 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.158338 (* 1 = 0.158338 loss)
I0929 13:42:35.842806 22954 sgd_solver.cpp:165] Iteration 41800, lr = 0.01
I0929 13:43:01.111421 22954 solver.cpp:357] Iteration 41900 (3.95781 iter/s, 25.2665s/100 iters), loss = 0.167395
I0929 13:43:01.111506 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.167395 (* 1 = 0.167395 loss)
I0929 13:43:01.111518 22954 sgd_solver.cpp:165] Iteration 41900, lr = 0.01
I0929 13:43:26.252336 22954 solver.cpp:514] Iteration 42000, Testing net (#0)
I0929 13:43:46.045548 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:43:46.103976 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.51219 (* 1 = 0.51219 loss)
I0929 13:43:46.104015 22954 solver.cpp:580]     Test net output #1: prob = 0.841801
I0929 13:43:46.104022 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:43:46.313925 22954 solver.cpp:357] Iteration 42000 (2.21237 iter/s, 45.2004s/100 iters), loss = 0.168309
I0929 13:43:46.313990 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.168309 (* 1 = 0.168309 loss)
I0929 13:43:46.314003 22954 sgd_solver.cpp:165] Iteration 42000, lr = 0.01
I0929 13:44:11.637068 22954 solver.cpp:357] Iteration 42100 (3.94928 iter/s, 25.321s/100 iters), loss = 0.0962311
I0929 13:44:11.637346 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0962311 (* 1 = 0.0962311 loss)
I0929 13:44:11.637358 22954 sgd_solver.cpp:165] Iteration 42100, lr = 0.01
I0929 13:44:32.696796 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:44:36.948640 22954 solver.cpp:357] Iteration 42200 (3.95109 iter/s, 25.3095s/100 iters), loss = 0.181772
I0929 13:44:36.948719 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.181772 (* 1 = 0.181772 loss)
I0929 13:44:36.948730 22954 sgd_solver.cpp:165] Iteration 42200, lr = 0.01
I0929 13:45:02.251729 22954 solver.cpp:357] Iteration 42300 (3.95241 iter/s, 25.301s/100 iters), loss = 0.077859
I0929 13:45:02.251857 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.077859 (* 1 = 0.077859 loss)
I0929 13:45:02.251868 22954 sgd_solver.cpp:165] Iteration 42300, lr = 0.01
I0929 13:45:27.590538 22954 solver.cpp:357] Iteration 42400 (3.94684 iter/s, 25.3368s/100 iters), loss = 0.0773785
I0929 13:45:27.590601 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0773785 (* 1 = 0.0773785 loss)
I0929 13:45:27.590613 22954 sgd_solver.cpp:165] Iteration 42400, lr = 0.01
I0929 13:45:52.681907 22954 solver.cpp:514] Iteration 42500, Testing net (#0)
I0929 13:46:12.406643 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:46:12.512853 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.689633 (* 1 = 0.689633 loss)
I0929 13:46:12.512879 22954 solver.cpp:580]     Test net output #1: prob = 0.7962
I0929 13:46:12.512886 22954 solver.cpp:593]     Max_acc: 0.858601  with iter: 32500
I0929 13:46:12.724907 22954 solver.cpp:357] Iteration 42500 (2.2157 iter/s, 45.1325s/100 iters), loss = 0.0898825
I0929 13:46:12.724997 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0898825 (* 1 = 0.0898825 loss)
I0929 13:46:12.725010 22954 sgd_solver.cpp:165] Iteration 42500, lr = 0.01
I0929 13:46:31.583556 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:46:38.042069 22954 solver.cpp:357] Iteration 42600 (3.9502 iter/s, 25.3152s/100 iters), loss = 0.148513
I0929 13:46:38.042161 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.148513 (* 1 = 0.148513 loss)
I0929 13:46:38.042173 22954 sgd_solver.cpp:165] Iteration 42600, lr = 0.01
I0929 13:47:03.399173 22954 solver.cpp:357] Iteration 42700 (3.94397 iter/s, 25.3551s/100 iters), loss = 0.10231
I0929 13:47:03.399296 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.10231 (* 1 = 0.10231 loss)
I0929 13:47:03.399307 22954 sgd_solver.cpp:165] Iteration 42700, lr = 0.01
I0929 13:47:28.730427 22954 solver.cpp:357] Iteration 42800 (3.948 iter/s, 25.3293s/100 iters), loss = 0.16494
I0929 13:47:28.730510 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.16494 (* 1 = 0.16494 loss)
I0929 13:47:28.730521 22954 sgd_solver.cpp:165] Iteration 42800, lr = 0.01
I0929 13:47:54.049680 22954 solver.cpp:357] Iteration 42900 (3.94987 iter/s, 25.3173s/100 iters), loss = 0.0943395
I0929 13:47:54.049813 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0943395 (* 1 = 0.0943395 loss)
I0929 13:47:54.049823 22954 sgd_solver.cpp:165] Iteration 42900, lr = 0.01
I0929 13:48:10.316015 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:48:19.114634 22954 solver.cpp:514] Iteration 43000, Testing net (#0)
I0929 13:48:38.990170 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:48:39.029562 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.396494 (* 1 = 0.396494 loss)
I0929 13:48:39.029611 22954 solver.cpp:580]     Test net output #1: prob = 0.872402
I0929 13:48:39.029628 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_43000.caffemodel
I0929 13:48:39.038244 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_43000.solverstate
I0929 13:48:39.040531 22954 solver.cpp:593]     Max_acc: 0.872402  with iter: 43000
I0929 13:48:39.278534 22954 solver.cpp:357] Iteration 43000 (2.21106 iter/s, 45.2272s/100 iters), loss = 0.106225
I0929 13:48:39.278586 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.106225 (* 1 = 0.106225 loss)
I0929 13:48:39.278597 22954 sgd_solver.cpp:165] Iteration 43000, lr = 0.01
I0929 13:49:04.675865 22954 solver.cpp:357] Iteration 43100 (3.93772 iter/s, 25.3954s/100 iters), loss = 0.134166
I0929 13:49:04.675931 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.134166 (* 1 = 0.134166 loss)
I0929 13:49:04.675941 22954 sgd_solver.cpp:165] Iteration 43100, lr = 0.01
I0929 13:49:30.039216 22954 solver.cpp:357] Iteration 43200 (3.94267 iter/s, 25.3636s/100 iters), loss = 0.16188
I0929 13:49:30.039372 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.16188 (* 1 = 0.16188 loss)
I0929 13:49:30.039384 22954 sgd_solver.cpp:165] Iteration 43200, lr = 0.01
I0929 13:49:55.362886 22954 solver.cpp:357] Iteration 43300 (3.94885 iter/s, 25.3238s/100 iters), loss = 0.0628747
I0929 13:49:55.362959 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0628747 (* 1 = 0.0628747 loss)
I0929 13:49:55.362970 22954 sgd_solver.cpp:165] Iteration 43300, lr = 0.01
I0929 13:50:09.299255 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:50:20.672039 22954 solver.cpp:357] Iteration 43400 (3.9511 iter/s, 25.3094s/100 iters), loss = 0.190307
I0929 13:50:20.672127 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.190307 (* 1 = 0.190307 loss)
I0929 13:50:20.672139 22954 sgd_solver.cpp:165] Iteration 43400, lr = 0.01
I0929 13:50:45.742847 22954 solver.cpp:514] Iteration 43500, Testing net (#0)
I0929 13:51:05.544000 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:51:05.653717 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.453756 (* 1 = 0.453756 loss)
I0929 13:51:05.653744 22954 solver.cpp:580]     Test net output #1: prob = 0.862801
I0929 13:51:05.653750 22954 solver.cpp:593]     Max_acc: 0.872402  with iter: 43000
I0929 13:51:05.875748 22954 solver.cpp:357] Iteration 43500 (2.2122 iter/s, 45.2038s/100 iters), loss = 0.119346
I0929 13:51:05.875821 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.119346 (* 1 = 0.119346 loss)
I0929 13:51:05.875833 22954 sgd_solver.cpp:165] Iteration 43500, lr = 0.01
I0929 13:51:31.177052 22954 solver.cpp:357] Iteration 43600 (3.95232 iter/s, 25.3016s/100 iters), loss = 0.128434
I0929 13:51:31.177283 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.128434 (* 1 = 0.128434 loss)
I0929 13:51:31.177301 22954 sgd_solver.cpp:165] Iteration 43600, lr = 0.01
I0929 13:51:56.435917 22954 solver.cpp:357] Iteration 43700 (3.95899 iter/s, 25.259s/100 iters), loss = 0.0991611
I0929 13:51:56.435997 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0991611 (* 1 = 0.0991611 loss)
I0929 13:51:56.436007 22954 sgd_solver.cpp:165] Iteration 43700, lr = 0.01
I0929 13:52:07.901860 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:52:21.791044 22954 solver.cpp:357] Iteration 43800 (3.94425 iter/s, 25.3533s/100 iters), loss = 0.0898309
I0929 13:52:21.791138 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0898309 (* 1 = 0.0898309 loss)
I0929 13:52:21.791152 22954 sgd_solver.cpp:165] Iteration 43800, lr = 0.01
I0929 13:52:47.103605 22954 solver.cpp:357] Iteration 43900 (3.95089 iter/s, 25.3108s/100 iters), loss = 0.172683
I0929 13:52:47.103747 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.172683 (* 1 = 0.172683 loss)
I0929 13:52:47.103760 22954 sgd_solver.cpp:165] Iteration 43900, lr = 0.01
I0929 13:53:12.170717 22954 solver.cpp:514] Iteration 44000, Testing net (#0)
I0929 13:53:31.861456 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:53:31.910308 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.370265 (* 1 = 0.370265 loss)
I0929 13:53:31.910338 22954 solver.cpp:580]     Test net output #1: prob = 0.879802
I0929 13:53:31.910352 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_44000.caffemodel
I0929 13:53:31.920166 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_44000.solverstate
I0929 13:53:31.922580 22954 solver.cpp:593]     Max_acc: 0.879802  with iter: 44000
I0929 13:53:32.158962 22954 solver.cpp:357] Iteration 44000 (2.21956 iter/s, 45.0539s/100 iters), loss = 0.114971
I0929 13:53:32.159009 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.114971 (* 1 = 0.114971 loss)
I0929 13:53:32.159023 22954 sgd_solver.cpp:165] Iteration 44000, lr = 0.01
I0929 13:53:57.577112 22954 solver.cpp:357] Iteration 44100 (3.93448 iter/s, 25.4163s/100 iters), loss = 0.167438
I0929 13:53:57.577205 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.167438 (* 1 = 0.167438 loss)
I0929 13:53:57.577217 22954 sgd_solver.cpp:165] Iteration 44100, lr = 0.01
I0929 13:54:06.662840 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:54:22.832614 22954 solver.cpp:357] Iteration 44200 (3.95981 iter/s, 25.2537s/100 iters), loss = 0.147066
I0929 13:54:22.832679 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.147066 (* 1 = 0.147066 loss)
I0929 13:54:22.832687 22954 sgd_solver.cpp:165] Iteration 44200, lr = 0.01
I0929 13:54:48.216660 22954 solver.cpp:357] Iteration 44300 (3.93943 iter/s, 25.3844s/100 iters), loss = 0.0777283
I0929 13:54:48.216904 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0777283 (* 1 = 0.0777283 loss)
I0929 13:54:48.216919 22954 sgd_solver.cpp:165] Iteration 44300, lr = 0.01
I0929 13:55:13.531256 22954 solver.cpp:357] Iteration 44400 (3.95029 iter/s, 25.3146s/100 iters), loss = 0.130273
I0929 13:55:13.531329 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.130273 (* 1 = 0.130273 loss)
I0929 13:55:13.531340 22954 sgd_solver.cpp:165] Iteration 44400, lr = 0.01
I0929 13:55:38.606808 22954 solver.cpp:514] Iteration 44500, Testing net (#0)
I0929 13:55:58.229737 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:55:58.313309 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.503293 (* 1 = 0.503293 loss)
I0929 13:55:58.313350 22954 solver.cpp:580]     Test net output #1: prob = 0.845201
I0929 13:55:58.313356 22954 solver.cpp:593]     Max_acc: 0.879802  with iter: 44000
I0929 13:55:58.521453 22954 solver.cpp:357] Iteration 44500 (2.22267 iter/s, 44.9909s/100 iters), loss = 0.126192
I0929 13:55:58.521513 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.126192 (* 1 = 0.126192 loss)
I0929 13:55:58.521524 22954 sgd_solver.cpp:165] Iteration 44500, lr = 0.01
I0929 13:56:05.367122 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:56:23.808255 22954 solver.cpp:357] Iteration 44600 (3.9549 iter/s, 25.2851s/100 iters), loss = 0.146722
I0929 13:56:23.808431 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.146722 (* 1 = 0.146722 loss)
I0929 13:56:23.808444 22954 sgd_solver.cpp:165] Iteration 44600, lr = 0.01
I0929 13:56:49.133496 22954 solver.cpp:357] Iteration 44700 (3.9489 iter/s, 25.3235s/100 iters), loss = 0.142986
I0929 13:56:49.133575 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.142986 (* 1 = 0.142986 loss)
I0929 13:56:49.133585 22954 sgd_solver.cpp:165] Iteration 44700, lr = 0.01
I0929 13:57:14.411690 22954 solver.cpp:357] Iteration 44800 (3.95625 iter/s, 25.2764s/100 iters), loss = 0.0630488
I0929 13:57:14.411880 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0630488 (* 1 = 0.0630488 loss)
I0929 13:57:14.411891 22954 sgd_solver.cpp:165] Iteration 44800, lr = 0.01
I0929 13:57:39.775216 22954 solver.cpp:357] Iteration 44900 (3.94294 iter/s, 25.3618s/100 iters), loss = 0.160071
I0929 13:57:39.775300 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.160071 (* 1 = 0.160071 loss)
I0929 13:57:39.775311 22954 sgd_solver.cpp:165] Iteration 44900, lr = 0.01
I0929 13:57:44.132896 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:58:04.878515 22954 solver.cpp:514] Iteration 45000, Testing net (#0)
I0929 13:58:24.568419 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 13:58:24.674001 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.57831 (* 1 = 0.57831 loss)
I0929 13:58:24.674027 22954 solver.cpp:580]     Test net output #1: prob = 0.825801
I0929 13:58:24.674034 22954 solver.cpp:593]     Max_acc: 0.879802  with iter: 44000
I0929 13:58:24.882555 22954 solver.cpp:357] Iteration 45000 (2.217 iter/s, 45.106s/100 iters), loss = 0.153172
I0929 13:58:24.882644 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.153172 (* 1 = 0.153172 loss)
I0929 13:58:24.882656 22954 sgd_solver.cpp:165] Iteration 45000, lr = 0.01
I0929 13:58:50.286602 22954 solver.cpp:357] Iteration 45100 (3.93665 iter/s, 25.4023s/100 iters), loss = 0.112172
I0929 13:58:50.286787 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.112172 (* 1 = 0.112172 loss)
I0929 13:58:50.286799 22954 sgd_solver.cpp:165] Iteration 45100, lr = 0.01
I0929 13:59:15.595074 22954 solver.cpp:357] Iteration 45200 (3.95151 iter/s, 25.3068s/100 iters), loss = 0.114435
I0929 13:59:15.595155 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.114435 (* 1 = 0.114435 loss)
I0929 13:59:15.595167 22954 sgd_solver.cpp:165] Iteration 45200, lr = 0.01
I0929 13:59:40.895545 22954 solver.cpp:357] Iteration 45300 (3.95276 iter/s, 25.2988s/100 iters), loss = 0.0863075
I0929 13:59:40.895789 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0863075 (* 1 = 0.0863075 loss)
I0929 13:59:40.895802 22954 sgd_solver.cpp:165] Iteration 45300, lr = 0.01
I0929 13:59:43.002533 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:00:06.207515 22954 solver.cpp:357] Iteration 45400 (3.95097 iter/s, 25.3103s/100 iters), loss = 0.134386
I0929 14:00:06.207598 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.134386 (* 1 = 0.134386 loss)
I0929 14:00:06.207610 22954 sgd_solver.cpp:165] Iteration 45400, lr = 0.01
I0929 14:00:31.315778 22954 solver.cpp:514] Iteration 45500, Testing net (#0)
I0929 14:00:51.156165 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:00:51.204648 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.531152 (* 1 = 0.531152 loss)
I0929 14:00:51.204689 22954 solver.cpp:580]     Test net output #1: prob = 0.839801
I0929 14:00:51.204694 22954 solver.cpp:593]     Max_acc: 0.879802  with iter: 44000
I0929 14:00:51.420755 22954 solver.cpp:357] Iteration 45500 (2.21181 iter/s, 45.2119s/100 iters), loss = 0.0586904
I0929 14:00:51.420814 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0586903 (* 1 = 0.0586903 loss)
I0929 14:00:51.420825 22954 sgd_solver.cpp:165] Iteration 45500, lr = 0.01
I0929 14:01:16.743835 22954 solver.cpp:357] Iteration 45600 (3.94923 iter/s, 25.3214s/100 iters), loss = 0.101862
I0929 14:01:16.744022 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.101862 (* 1 = 0.101862 loss)
I0929 14:01:16.744033 22954 sgd_solver.cpp:165] Iteration 45600, lr = 0.01
I0929 14:01:41.863927 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:01:42.069010 22954 solver.cpp:357] Iteration 45700 (3.9489 iter/s, 25.3235s/100 iters), loss = 0.125988
I0929 14:01:42.069075 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.125988 (* 1 = 0.125988 loss)
I0929 14:01:42.069087 22954 sgd_solver.cpp:165] Iteration 45700, lr = 0.01
I0929 14:02:07.374953 22954 solver.cpp:357] Iteration 45800 (3.95191 iter/s, 25.3042s/100 iters), loss = 0.160684
I0929 14:02:07.375119 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.160684 (* 1 = 0.160684 loss)
I0929 14:02:07.375130 22954 sgd_solver.cpp:165] Iteration 45800, lr = 0.01
I0929 14:02:32.394253 22954 solver.cpp:357] Iteration 45900 (3.99719 iter/s, 25.0176s/100 iters), loss = 0.102347
I0929 14:02:32.394330 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.102347 (* 1 = 0.102347 loss)
I0929 14:02:32.394342 22954 sgd_solver.cpp:165] Iteration 45900, lr = 0.01
I0929 14:02:57.519326 22954 solver.cpp:514] Iteration 46000, Testing net (#0)
I0929 14:03:17.161490 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:03:17.267477 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.464594 (* 1 = 0.464594 loss)
I0929 14:03:17.267503 22954 solver.cpp:580]     Test net output #1: prob = 0.859201
I0929 14:03:17.267509 22954 solver.cpp:593]     Max_acc: 0.879802  with iter: 44000
I0929 14:03:17.499874 22954 solver.cpp:357] Iteration 46000 (2.21708 iter/s, 45.1044s/100 iters), loss = 0.114517
I0929 14:03:17.499964 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.114517 (* 1 = 0.114517 loss)
I0929 14:03:17.499976 22954 sgd_solver.cpp:165] Iteration 46000, lr = 0.01
I0929 14:03:40.064649 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:03:42.763384 22954 solver.cpp:357] Iteration 46100 (3.95854 iter/s, 25.2618s/100 iters), loss = 0.144835
I0929 14:03:42.763443 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.144835 (* 1 = 0.144835 loss)
I0929 14:03:42.763453 22954 sgd_solver.cpp:165] Iteration 46100, lr = 0.01
I0929 14:04:08.121703 22954 solver.cpp:357] Iteration 46200 (3.94343 iter/s, 25.3587s/100 iters), loss = 0.109264
I0929 14:04:08.121798 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.109264 (* 1 = 0.109264 loss)
I0929 14:04:08.121812 22954 sgd_solver.cpp:165] Iteration 46200, lr = 0.01
I0929 14:04:33.454182 22954 solver.cpp:357] Iteration 46300 (3.94776 iter/s, 25.3308s/100 iters), loss = 0.144772
I0929 14:04:33.454396 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.144772 (* 1 = 0.144772 loss)
I0929 14:04:33.454409 22954 sgd_solver.cpp:165] Iteration 46300, lr = 0.01
I0929 14:04:58.757084 22954 solver.cpp:357] Iteration 46400 (3.95212 iter/s, 25.3029s/100 iters), loss = 0.179183
I0929 14:04:58.757177 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.179183 (* 1 = 0.179183 loss)
I0929 14:04:58.757189 22954 sgd_solver.cpp:165] Iteration 46400, lr = 0.01
I0929 14:05:19.029053 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:05:23.827100 22954 solver.cpp:514] Iteration 46500, Testing net (#0)
I0929 14:05:43.402019 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:05:43.512898 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.456794 (* 1 = 0.456794 loss)
I0929 14:05:43.513006 22954 solver.cpp:580]     Test net output #1: prob = 0.863101
I0929 14:05:43.513028 22954 solver.cpp:593]     Max_acc: 0.879802  with iter: 44000
I0929 14:05:43.710659 22954 solver.cpp:357] Iteration 46500 (2.22458 iter/s, 44.9523s/100 iters), loss = 0.108884
I0929 14:05:43.710738 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.108884 (* 1 = 0.108884 loss)
I0929 14:05:43.710750 22954 sgd_solver.cpp:165] Iteration 46500, lr = 0.01
I0929 14:06:09.059337 22954 solver.cpp:357] Iteration 46600 (3.94524 iter/s, 25.347s/100 iters), loss = 0.132128
I0929 14:06:09.059466 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.132128 (* 1 = 0.132128 loss)
I0929 14:06:09.059478 22954 sgd_solver.cpp:165] Iteration 46600, lr = 0.01
I0929 14:06:34.346590 22954 solver.cpp:357] Iteration 46700 (3.95484 iter/s, 25.2855s/100 iters), loss = 0.122546
I0929 14:06:34.346673 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.122546 (* 1 = 0.122546 loss)
I0929 14:06:34.346685 22954 sgd_solver.cpp:165] Iteration 46700, lr = 0.01
I0929 14:06:59.709318 22954 solver.cpp:357] Iteration 46800 (3.94329 iter/s, 25.3595s/100 iters), loss = 0.0594106
I0929 14:06:59.709437 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0594105 (* 1 = 0.0594105 loss)
I0929 14:06:59.709450 22954 sgd_solver.cpp:165] Iteration 46800, lr = 0.01
I0929 14:07:17.494331 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:07:25.024402 22954 solver.cpp:357] Iteration 46900 (3.9507 iter/s, 25.312s/100 iters), loss = 0.194021
I0929 14:07:25.024483 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.194021 (* 1 = 0.194021 loss)
I0929 14:07:25.024493 22954 sgd_solver.cpp:165] Iteration 46900, lr = 0.01
I0929 14:07:50.133919 22954 solver.cpp:514] Iteration 47000, Testing net (#0)
I0929 14:08:09.874102 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:08:09.983752 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.443326 (* 1 = 0.443326 loss)
I0929 14:08:09.983798 22954 solver.cpp:580]     Test net output #1: prob = 0.869701
I0929 14:08:09.983804 22954 solver.cpp:593]     Max_acc: 0.879802  with iter: 44000
I0929 14:08:10.192706 22954 solver.cpp:357] Iteration 47000 (2.21412 iter/s, 45.1646s/100 iters), loss = 0.0833744
I0929 14:08:10.192786 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0833744 (* 1 = 0.0833744 loss)
I0929 14:08:10.192797 22954 sgd_solver.cpp:165] Iteration 47000, lr = 0.01
I0929 14:08:35.534169 22954 solver.cpp:357] Iteration 47100 (3.94656 iter/s, 25.3385s/100 iters), loss = 0.11421
I0929 14:08:35.534299 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.11421 (* 1 = 0.11421 loss)
I0929 14:08:35.534310 22954 sgd_solver.cpp:165] Iteration 47100, lr = 0.01
I0929 14:09:00.819725 22954 solver.cpp:357] Iteration 47200 (3.95528 iter/s, 25.2826s/100 iters), loss = 0.175168
I0929 14:09:00.819804 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.175168 (* 1 = 0.175168 loss)
I0929 14:09:00.819815 22954 sgd_solver.cpp:165] Iteration 47200, lr = 0.01
I0929 14:09:16.322211 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:09:26.132508 22954 solver.cpp:357] Iteration 47300 (3.95102 iter/s, 25.3099s/100 iters), loss = 0.102984
I0929 14:09:26.132586 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.102984 (* 1 = 0.102984 loss)
I0929 14:09:26.132597 22954 sgd_solver.cpp:165] Iteration 47300, lr = 0.01
I0929 14:09:51.450242 22954 solver.cpp:357] Iteration 47400 (3.95024 iter/s, 25.3149s/100 iters), loss = 0.168535
I0929 14:09:51.450381 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.168535 (* 1 = 0.168535 loss)
I0929 14:09:51.450392 22954 sgd_solver.cpp:165] Iteration 47400, lr = 0.01
I0929 14:10:16.549125 22954 solver.cpp:514] Iteration 47500, Testing net (#0)
I0929 14:10:36.135979 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:10:36.241613 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.640643 (* 1 = 0.640643 loss)
I0929 14:10:36.241641 22954 solver.cpp:580]     Test net output #1: prob = 0.812301
I0929 14:10:36.241647 22954 solver.cpp:593]     Max_acc: 0.879802  with iter: 44000
I0929 14:10:36.475334 22954 solver.cpp:357] Iteration 47500 (2.22114 iter/s, 45.0219s/100 iters), loss = 0.0772336
I0929 14:10:36.475416 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0772336 (* 1 = 0.0772336 loss)
I0929 14:10:36.475430 22954 sgd_solver.cpp:165] Iteration 47500, lr = 0.01
I0929 14:11:01.836704 22954 solver.cpp:357] Iteration 47600 (3.94343 iter/s, 25.3587s/100 iters), loss = 0.135272
I0929 14:11:01.836786 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.135272 (* 1 = 0.135272 loss)
I0929 14:11:01.836798 22954 sgd_solver.cpp:165] Iteration 47600, lr = 0.01
I0929 14:11:15.012526 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:11:27.164507 22954 solver.cpp:357] Iteration 47700 (3.94834 iter/s, 25.3271s/100 iters), loss = 0.124296
I0929 14:11:27.164582 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.124296 (* 1 = 0.124296 loss)
I0929 14:11:27.164593 22954 sgd_solver.cpp:165] Iteration 47700, lr = 0.01
I0929 14:11:52.418359 22954 solver.cpp:357] Iteration 47800 (3.95987 iter/s, 25.2533s/100 iters), loss = 0.0991094
I0929 14:11:52.418460 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0991094 (* 1 = 0.0991094 loss)
I0929 14:11:52.418470 22954 sgd_solver.cpp:165] Iteration 47800, lr = 0.01
I0929 14:12:17.788684 22954 solver.cpp:357] Iteration 47900 (3.9417 iter/s, 25.3698s/100 iters), loss = 0.113404
I0929 14:12:17.788775 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.113404 (* 1 = 0.113404 loss)
I0929 14:12:17.788789 22954 sgd_solver.cpp:165] Iteration 47900, lr = 0.01
I0929 14:12:42.852222 22954 solver.cpp:514] Iteration 48000, Testing net (#0)
I0929 14:13:02.674085 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:13:02.781641 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.475541 (* 1 = 0.475541 loss)
I0929 14:13:02.781667 22954 solver.cpp:580]     Test net output #1: prob = 0.861402
I0929 14:13:02.781673 22954 solver.cpp:593]     Max_acc: 0.879802  with iter: 44000
I0929 14:13:02.987872 22954 solver.cpp:357] Iteration 48000 (2.21256 iter/s, 45.1964s/100 iters), loss = 0.141342
I0929 14:13:02.987967 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.141342 (* 1 = 0.141342 loss)
I0929 14:13:02.987977 22954 sgd_solver.cpp:64] MultiStep Status: Iteration 48000, step = 2
I0929 14:13:02.987984 22954 sgd_solver.cpp:165] Iteration 48000, lr = 0.001
I0929 14:13:13.780387 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:13:28.392241 22954 solver.cpp:357] Iteration 48100 (3.93672 iter/s, 25.4019s/100 iters), loss = 0.0927112
I0929 14:13:28.392320 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0927111 (* 1 = 0.0927111 loss)
I0929 14:13:28.392331 22954 sgd_solver.cpp:165] Iteration 48100, lr = 0.001
I0929 14:13:53.703090 22954 solver.cpp:357] Iteration 48200 (3.95126 iter/s, 25.3084s/100 iters), loss = 0.0722625
I0929 14:13:53.703341 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0722625 (* 1 = 0.0722625 loss)
I0929 14:13:53.703354 22954 sgd_solver.cpp:165] Iteration 48200, lr = 0.001
I0929 14:14:19.011513 22954 solver.cpp:357] Iteration 48300 (3.95164 iter/s, 25.306s/100 iters), loss = 0.0454751
I0929 14:14:19.011595 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0454751 (* 1 = 0.0454751 loss)
I0929 14:14:19.011607 22954 sgd_solver.cpp:165] Iteration 48300, lr = 0.001
I0929 14:14:44.320468 22954 solver.cpp:357] Iteration 48400 (3.95155 iter/s, 25.3065s/100 iters), loss = 0.0828824
I0929 14:14:44.320662 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0828824 (* 1 = 0.0828824 loss)
I0929 14:14:44.320675 22954 sgd_solver.cpp:165] Iteration 48400, lr = 0.001
I0929 14:14:52.754350 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:15:09.456665 22954 solver.cpp:514] Iteration 48500, Testing net (#0)
I0929 14:15:29.150501 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:15:29.251288 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.289709 (* 1 = 0.289709 loss)
I0929 14:15:29.251320 22954 solver.cpp:580]     Test net output #1: prob = 0.908202
I0929 14:15:29.251336 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_48500.caffemodel
I0929 14:15:29.261546 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_48500.solverstate
I0929 14:15:29.264217 22954 solver.cpp:593]     Max_acc: 0.908202  with iter: 48500
I0929 14:15:29.478664 22954 solver.cpp:357] Iteration 48500 (2.21456 iter/s, 45.1557s/100 iters), loss = 0.0648573
I0929 14:15:29.478754 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0648573 (* 1 = 0.0648573 loss)
I0929 14:15:29.478766 22954 sgd_solver.cpp:165] Iteration 48500, lr = 0.001
I0929 14:15:54.834486 22954 solver.cpp:357] Iteration 48600 (3.94423 iter/s, 25.3535s/100 iters), loss = 0.138101
I0929 14:15:54.834568 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.138101 (* 1 = 0.138101 loss)
I0929 14:15:54.834578 22954 sgd_solver.cpp:165] Iteration 48600, lr = 0.001
I0929 14:16:20.156651 22954 solver.cpp:357] Iteration 48700 (3.94947 iter/s, 25.3198s/100 iters), loss = 0.0210383
I0929 14:16:20.156775 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0210383 (* 1 = 0.0210383 loss)
I0929 14:16:20.156786 22954 sgd_solver.cpp:165] Iteration 48700, lr = 0.001
I0929 14:16:45.467664 22954 solver.cpp:357] Iteration 48800 (3.9512 iter/s, 25.3087s/100 iters), loss = 0.0988833
I0929 14:16:45.467744 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0988833 (* 1 = 0.0988833 loss)
I0929 14:16:45.467756 22954 sgd_solver.cpp:165] Iteration 48800, lr = 0.001
I0929 14:16:51.613337 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:17:10.741384 22954 solver.cpp:357] Iteration 48900 (3.95704 iter/s, 25.2714s/100 iters), loss = 0.0912254
I0929 14:17:10.741469 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0912254 (* 1 = 0.0912254 loss)
I0929 14:17:10.741482 22954 sgd_solver.cpp:165] Iteration 48900, lr = 0.001
I0929 14:17:35.894706 22954 solver.cpp:514] Iteration 49000, Testing net (#0)
I0929 14:17:55.667170 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:17:55.763903 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.27871 (* 1 = 0.27871 loss)
I0929 14:17:55.763969 22954 solver.cpp:580]     Test net output #1: prob = 0.912802
I0929 14:17:55.763989 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_49000.caffemodel
I0929 14:17:55.773996 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_49000.solverstate
I0929 14:17:55.776480 22954 solver.cpp:593]     Max_acc: 0.912802  with iter: 49000
I0929 14:17:55.993314 22954 solver.cpp:357] Iteration 49000 (2.20996 iter/s, 45.2496s/100 iters), loss = 0.0892702
I0929 14:17:55.993376 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0892702 (* 1 = 0.0892702 loss)
I0929 14:17:55.993387 22954 sgd_solver.cpp:165] Iteration 49000, lr = 0.001
I0929 14:18:21.274183 22954 solver.cpp:357] Iteration 49100 (3.95591 iter/s, 25.2786s/100 iters), loss = 0.0489757
I0929 14:18:21.274446 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0489757 (* 1 = 0.0489757 loss)
I0929 14:18:21.274458 22954 sgd_solver.cpp:165] Iteration 49100, lr = 0.001
I0929 14:18:46.606001 22954 solver.cpp:357] Iteration 49200 (3.94795 iter/s, 25.3296s/100 iters), loss = 0.0312629
I0929 14:18:46.606081 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0312629 (* 1 = 0.0312629 loss)
I0929 14:18:46.606092 22954 sgd_solver.cpp:165] Iteration 49200, lr = 0.001
I0929 14:18:50.228862 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:19:11.922768 22954 solver.cpp:357] Iteration 49300 (3.9503 iter/s, 25.3145s/100 iters), loss = 0.0719498
I0929 14:19:11.922956 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0719498 (* 1 = 0.0719498 loss)
I0929 14:19:11.922968 22954 sgd_solver.cpp:165] Iteration 49300, lr = 0.001
I0929 14:19:37.215843 22954 solver.cpp:357] Iteration 49400 (3.95399 iter/s, 25.2909s/100 iters), loss = 0.0528497
I0929 14:19:37.215924 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0528497 (* 1 = 0.0528497 loss)
I0929 14:19:37.215934 22954 sgd_solver.cpp:165] Iteration 49400, lr = 0.001
I0929 14:20:02.298379 22954 solver.cpp:514] Iteration 49500, Testing net (#0)
I0929 14:20:22.147358 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:20:22.231209 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.262746 (* 1 = 0.262746 loss)
I0929 14:20:22.231295 22954 solver.cpp:580]     Test net output #1: prob = 0.914402
I0929 14:20:22.231324 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_49500.caffemodel
I0929 14:20:22.239796 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_49500.solverstate
I0929 14:20:22.242362 22954 solver.cpp:593]     Max_acc: 0.914402  with iter: 49500
I0929 14:20:22.464042 22954 solver.cpp:357] Iteration 49500 (2.21014 iter/s, 45.2461s/100 iters), loss = 0.0669112
I0929 14:20:22.464107 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0669112 (* 1 = 0.0669112 loss)
I0929 14:20:22.464118 22954 sgd_solver.cpp:165] Iteration 49500, lr = 0.001
I0929 14:20:47.730655 22954 solver.cpp:357] Iteration 49600 (3.95813 iter/s, 25.2645s/100 iters), loss = 0.0392153
I0929 14:20:47.730794 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0392153 (* 1 = 0.0392153 loss)
I0929 14:20:47.730806 22954 sgd_solver.cpp:165] Iteration 49600, lr = 0.001
I0929 14:20:49.085767 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:21:13.084434 22954 solver.cpp:357] Iteration 49700 (3.94452 iter/s, 25.3516s/100 iters), loss = 0.059912
I0929 14:21:13.084516 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.059912 (* 1 = 0.059912 loss)
I0929 14:21:13.084527 22954 sgd_solver.cpp:165] Iteration 49700, lr = 0.001
I0929 14:21:38.400183 22954 solver.cpp:357] Iteration 49800 (3.95044 iter/s, 25.3136s/100 iters), loss = 0.0454327
I0929 14:21:38.400311 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0454327 (* 1 = 0.0454327 loss)
I0929 14:21:38.400323 22954 sgd_solver.cpp:165] Iteration 49800, lr = 0.001
I0929 14:22:03.721493 22954 solver.cpp:357] Iteration 49900 (3.94957 iter/s, 25.3192s/100 iters), loss = 0.0607657
I0929 14:22:03.721575 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0607657 (* 1 = 0.0607657 loss)
I0929 14:22:03.721585 22954 sgd_solver.cpp:165] Iteration 49900, lr = 0.001
I0929 14:22:27.835000 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:22:28.785435 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_50000.caffemodel
I0929 14:22:28.797986 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_50000.solverstate
I0929 14:22:28.801209 22954 solver.cpp:514] Iteration 50000, Testing net (#0)
I0929 14:22:48.586282 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:22:48.697648 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.262622 (* 1 = 0.262622 loss)
I0929 14:22:48.697698 22954 solver.cpp:580]     Test net output #1: prob = 0.917502
I0929 14:22:48.697712 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_50000.caffemodel
I0929 14:22:48.703927 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_50000.solverstate
I0929 14:22:48.706665 22954 solver.cpp:593]     Max_acc: 0.917502  with iter: 50000
I0929 14:22:48.895917 22954 solver.cpp:357] Iteration 50000 (2.21374 iter/s, 45.1724s/100 iters), loss = 0.0626809
I0929 14:22:48.895999 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0626808 (* 1 = 0.0626808 loss)
I0929 14:22:48.896013 22954 sgd_solver.cpp:165] Iteration 50000, lr = 0.001
I0929 14:23:14.243516 22954 solver.cpp:357] Iteration 50100 (3.94547 iter/s, 25.3455s/100 iters), loss = 0.0383645
I0929 14:23:14.243726 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0383645 (* 1 = 0.0383645 loss)
I0929 14:23:14.243737 22954 sgd_solver.cpp:165] Iteration 50100, lr = 0.001
I0929 14:23:39.564301 22954 solver.cpp:357] Iteration 50200 (3.94965 iter/s, 25.3187s/100 iters), loss = 0.0737641
I0929 14:23:39.564383 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0737641 (* 1 = 0.0737641 loss)
I0929 14:23:39.564393 22954 sgd_solver.cpp:165] Iteration 50200, lr = 0.001
I0929 14:24:04.887262 22954 solver.cpp:357] Iteration 50300 (3.94931 iter/s, 25.3209s/100 iters), loss = 0.0793959
I0929 14:24:04.887394 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0793959 (* 1 = 0.0793959 loss)
I0929 14:24:04.887408 22954 sgd_solver.cpp:165] Iteration 50300, lr = 0.001
I0929 14:24:26.712524 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:24:30.203960 22954 solver.cpp:357] Iteration 50400 (3.95028 iter/s, 25.3146s/100 iters), loss = 0.0653875
I0929 14:24:30.204039 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0653875 (* 1 = 0.0653875 loss)
I0929 14:24:30.204051 22954 sgd_solver.cpp:165] Iteration 50400, lr = 0.001
I0929 14:24:55.307148 22954 solver.cpp:514] Iteration 50500, Testing net (#0)
I0929 14:25:14.888545 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:25:14.993569 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.248142 (* 1 = 0.248142 loss)
I0929 14:25:14.993595 22954 solver.cpp:580]     Test net output #1: prob = 0.920602
I0929 14:25:14.993609 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_50500.caffemodel
I0929 14:25:15.003070 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_50500.solverstate
I0929 14:25:15.005681 22954 solver.cpp:593]     Max_acc: 0.920602  with iter: 50500
I0929 14:25:15.237354 22954 solver.cpp:357] Iteration 50500 (2.22067 iter/s, 45.0315s/100 iters), loss = 0.0442991
I0929 14:25:15.237437 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0442991 (* 1 = 0.0442991 loss)
I0929 14:25:15.237452 22954 sgd_solver.cpp:165] Iteration 50500, lr = 0.001
I0929 14:25:40.573057 22954 solver.cpp:357] Iteration 50600 (3.94732 iter/s, 25.3337s/100 iters), loss = 0.0295061
I0929 14:25:40.573230 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0295061 (* 1 = 0.0295061 loss)
I0929 14:25:40.573243 22954 sgd_solver.cpp:165] Iteration 50600, lr = 0.001
I0929 14:26:05.826150 22954 solver.cpp:357] Iteration 50700 (3.95999 iter/s, 25.2526s/100 iters), loss = 0.0347424
I0929 14:26:05.826216 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0347424 (* 1 = 0.0347424 loss)
I0929 14:26:05.826225 22954 sgd_solver.cpp:165] Iteration 50700, lr = 0.001
I0929 14:26:25.407192 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:26:31.196007 22954 solver.cpp:357] Iteration 50800 (3.94169 iter/s, 25.3699s/100 iters), loss = 0.0697139
I0929 14:26:31.196100 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0697139 (* 1 = 0.0697139 loss)
I0929 14:26:31.196112 22954 sgd_solver.cpp:165] Iteration 50800, lr = 0.001
I0929 14:26:56.508273 22954 solver.cpp:357] Iteration 50900 (3.95096 iter/s, 25.3103s/100 iters), loss = 0.0651604
I0929 14:26:56.508412 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0651604 (* 1 = 0.0651604 loss)
I0929 14:26:56.508430 22954 sgd_solver.cpp:165] Iteration 50900, lr = 0.001
I0929 14:27:21.582804 22954 solver.cpp:514] Iteration 51000, Testing net (#0)
I0929 14:27:41.193581 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:27:41.294392 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.260357 (* 1 = 0.260357 loss)
I0929 14:27:41.294430 22954 solver.cpp:580]     Test net output #1: prob = 0.919402
I0929 14:27:41.294435 22954 solver.cpp:593]     Max_acc: 0.920602  with iter: 50500
I0929 14:27:41.502394 22954 solver.cpp:357] Iteration 51000 (2.2225 iter/s, 44.9943s/100 iters), loss = 0.0424506
I0929 14:27:41.502463 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0424506 (* 1 = 0.0424506 loss)
I0929 14:27:41.502475 22954 sgd_solver.cpp:165] Iteration 51000, lr = 0.001
I0929 14:28:06.819509 22954 solver.cpp:357] Iteration 51100 (3.95021 iter/s, 25.3151s/100 iters), loss = 0.0286497
I0929 14:28:06.819586 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0286497 (* 1 = 0.0286497 loss)
I0929 14:28:06.819597 22954 sgd_solver.cpp:165] Iteration 51100, lr = 0.001
I0929 14:28:23.838220 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:28:32.138028 22954 solver.cpp:357] Iteration 51200 (3.94999 iter/s, 25.3165s/100 iters), loss = 0.0527878
I0929 14:28:32.138108 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0527878 (* 1 = 0.0527878 loss)
I0929 14:28:32.138118 22954 sgd_solver.cpp:165] Iteration 51200, lr = 0.001
I0929 14:28:57.409901 22954 solver.cpp:357] Iteration 51300 (3.95728 iter/s, 25.2699s/100 iters), loss = 0.0299667
I0929 14:28:57.410089 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0299667 (* 1 = 0.0299667 loss)
I0929 14:28:57.410101 22954 sgd_solver.cpp:165] Iteration 51300, lr = 0.001
I0929 14:29:22.760344 22954 solver.cpp:357] Iteration 51400 (3.94502 iter/s, 25.3484s/100 iters), loss = 0.0243479
I0929 14:29:22.760426 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0243479 (* 1 = 0.0243479 loss)
I0929 14:29:22.760438 22954 sgd_solver.cpp:165] Iteration 51400, lr = 0.001
I0929 14:29:47.864161 22954 solver.cpp:514] Iteration 51500, Testing net (#0)
I0929 14:30:07.447142 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:30:07.553645 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.265144 (* 1 = 0.265144 loss)
I0929 14:30:07.553673 22954 solver.cpp:580]     Test net output #1: prob = 0.916102
I0929 14:30:07.553678 22954 solver.cpp:593]     Max_acc: 0.920602  with iter: 50500
I0929 14:30:07.789531 22954 solver.cpp:357] Iteration 51500 (2.22087 iter/s, 45.0274s/100 iters), loss = 0.0276405
I0929 14:30:07.789582 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0276405 (* 1 = 0.0276405 loss)
I0929 14:30:07.789593 22954 sgd_solver.cpp:165] Iteration 51500, lr = 0.001
I0929 14:30:22.543104 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:30:33.170476 22954 solver.cpp:357] Iteration 51600 (3.94027 iter/s, 25.379s/100 iters), loss = 0.0255957
I0929 14:30:33.170569 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0255956 (* 1 = 0.0255956 loss)
I0929 14:30:33.170583 22954 sgd_solver.cpp:165] Iteration 51600, lr = 0.001
I0929 14:30:58.483860 22954 solver.cpp:357] Iteration 51700 (3.95079 iter/s, 25.3114s/100 iters), loss = 0.0906423
I0929 14:30:58.484052 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0906423 (* 1 = 0.0906423 loss)
I0929 14:30:58.484066 22954 sgd_solver.cpp:165] Iteration 51700, lr = 0.001
I0929 14:31:23.789338 22954 solver.cpp:357] Iteration 51800 (3.95202 iter/s, 25.3035s/100 iters), loss = 0.0301375
I0929 14:31:23.789430 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0301375 (* 1 = 0.0301375 loss)
I0929 14:31:23.789443 22954 sgd_solver.cpp:165] Iteration 51800, lr = 0.001
I0929 14:31:49.059800 22954 solver.cpp:357] Iteration 51900 (3.9575 iter/s, 25.2685s/100 iters), loss = 0.0510371
I0929 14:31:49.060003 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0510371 (* 1 = 0.0510371 loss)
I0929 14:31:49.060014 22954 sgd_solver.cpp:165] Iteration 51900, lr = 0.001
I0929 14:32:01.546631 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:32:14.174319 22954 solver.cpp:514] Iteration 52000, Testing net (#0)
I0929 14:32:33.883785 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:32:33.895846 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.260175 (* 1 = 0.260175 loss)
I0929 14:32:33.895874 22954 solver.cpp:580]     Test net output #1: prob = 0.919102
I0929 14:32:33.895880 22954 solver.cpp:593]     Max_acc: 0.920602  with iter: 50500
I0929 14:32:34.117734 22954 solver.cpp:357] Iteration 52000 (2.21946 iter/s, 45.0561s/100 iters), loss = 0.0442692
I0929 14:32:34.117787 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0442691 (* 1 = 0.0442691 loss)
I0929 14:32:34.117799 22954 sgd_solver.cpp:165] Iteration 52000, lr = 0.001
I0929 14:32:59.410961 22954 solver.cpp:357] Iteration 52100 (3.95393 iter/s, 25.2913s/100 iters), loss = 0.0522796
I0929 14:32:59.411041 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0522796 (* 1 = 0.0522796 loss)
I0929 14:32:59.411053 22954 sgd_solver.cpp:165] Iteration 52100, lr = 0.001
I0929 14:33:24.731304 22954 solver.cpp:357] Iteration 52200 (3.9497 iter/s, 25.3184s/100 iters), loss = 0.0413911
I0929 14:33:24.731485 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.041391 (* 1 = 0.041391 loss)
I0929 14:33:24.731497 22954 sgd_solver.cpp:165] Iteration 52200, lr = 0.001
I0929 14:33:50.046779 22954 solver.cpp:357] Iteration 52300 (3.95046 iter/s, 25.3135s/100 iters), loss = 0.0390831
I0929 14:33:50.046864 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.039083 (* 1 = 0.039083 loss)
I0929 14:33:50.046875 22954 sgd_solver.cpp:165] Iteration 52300, lr = 0.001
I0929 14:33:59.962354 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:34:15.358014 22954 solver.cpp:357] Iteration 52400 (3.95112 iter/s, 25.3093s/100 iters), loss = 0.0331475
I0929 14:34:15.358098 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0331475 (* 1 = 0.0331475 loss)
I0929 14:34:15.358108 22954 sgd_solver.cpp:165] Iteration 52400, lr = 0.001
I0929 14:34:40.470299 22954 solver.cpp:514] Iteration 52500, Testing net (#0)
I0929 14:35:00.249214 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:35:00.354418 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.266692 (* 1 = 0.266692 loss)
I0929 14:35:00.354465 22954 solver.cpp:580]     Test net output #1: prob = 0.917002
I0929 14:35:00.354470 22954 solver.cpp:593]     Max_acc: 0.920602  with iter: 50500
I0929 14:35:00.565781 22954 solver.cpp:357] Iteration 52500 (2.21209 iter/s, 45.206s/100 iters), loss = 0.0662175
I0929 14:35:00.565860 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0662175 (* 1 = 0.0662175 loss)
I0929 14:35:00.565872 22954 sgd_solver.cpp:165] Iteration 52500, lr = 0.001
I0929 14:35:25.843209 22954 solver.cpp:357] Iteration 52600 (3.9564 iter/s, 25.2755s/100 iters), loss = 0.0323393
I0929 14:35:25.843392 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0323393 (* 1 = 0.0323393 loss)
I0929 14:35:25.843406 22954 sgd_solver.cpp:165] Iteration 52600, lr = 0.001
I0929 14:35:51.169193 22954 solver.cpp:357] Iteration 52700 (3.94882 iter/s, 25.324s/100 iters), loss = 0.063803
I0929 14:35:51.169276 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.063803 (* 1 = 0.063803 loss)
I0929 14:35:51.169287 22954 sgd_solver.cpp:165] Iteration 52700, lr = 0.001
I0929 14:35:58.831076 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:36:16.494738 22954 solver.cpp:357] Iteration 52800 (3.94889 iter/s, 25.3236s/100 iters), loss = 0.0158129
I0929 14:36:16.494820 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0158129 (* 1 = 0.0158129 loss)
I0929 14:36:16.494832 22954 sgd_solver.cpp:165] Iteration 52800, lr = 0.001
I0929 14:36:41.806381 22954 solver.cpp:357] Iteration 52900 (3.95105 iter/s, 25.3097s/100 iters), loss = 0.0490962
I0929 14:36:41.806535 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0490961 (* 1 = 0.0490961 loss)
I0929 14:36:41.806546 22954 sgd_solver.cpp:165] Iteration 52900, lr = 0.001
I0929 14:37:06.872704 22954 solver.cpp:514] Iteration 53000, Testing net (#0)
I0929 14:37:26.589781 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:37:26.697392 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.261183 (* 1 = 0.261183 loss)
I0929 14:37:26.697418 22954 solver.cpp:580]     Test net output #1: prob = 0.921002
I0929 14:37:26.697432 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_53000.caffemodel
I0929 14:37:26.706516 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_53000.solverstate
I0929 14:37:26.709015 22954 solver.cpp:593]     Max_acc: 0.921002  with iter: 53000
I0929 14:37:26.918517 22954 solver.cpp:357] Iteration 53000 (2.21678 iter/s, 45.1105s/100 iters), loss = 0.0300733
I0929 14:37:26.918591 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0300733 (* 1 = 0.0300733 loss)
I0929 14:37:26.918602 22954 sgd_solver.cpp:165] Iteration 53000, lr = 0.001
I0929 14:37:52.342036 22954 solver.cpp:357] Iteration 53100 (3.93334 iter/s, 25.4237s/100 iters), loss = 0.0458239
I0929 14:37:52.342118 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0458238 (* 1 = 0.0458238 loss)
I0929 14:37:52.342129 22954 sgd_solver.cpp:165] Iteration 53100, lr = 0.001
I0929 14:37:57.464484 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:38:17.655680 22954 solver.cpp:357] Iteration 53200 (3.95074 iter/s, 25.3117s/100 iters), loss = 0.102491
I0929 14:38:17.655762 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.10249 (* 1 = 0.10249 loss)
I0929 14:38:17.655776 22954 sgd_solver.cpp:165] Iteration 53200, lr = 0.001
I0929 14:38:42.960139 22954 solver.cpp:357] Iteration 53300 (3.95218 iter/s, 25.3025s/100 iters), loss = 0.0191802
I0929 14:38:42.960302 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0191802 (* 1 = 0.0191802 loss)
I0929 14:38:42.960314 22954 sgd_solver.cpp:165] Iteration 53300, lr = 0.001
I0929 14:39:08.260383 22954 solver.cpp:357] Iteration 53400 (3.95283 iter/s, 25.2983s/100 iters), loss = 0.0286508
I0929 14:39:08.260468 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0286508 (* 1 = 0.0286508 loss)
I0929 14:39:08.260483 22954 sgd_solver.cpp:165] Iteration 53400, lr = 0.001
I0929 14:39:33.370654 22954 solver.cpp:514] Iteration 53500, Testing net (#0)
I0929 14:39:53.159526 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:39:53.264670 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.256168 (* 1 = 0.256168 loss)
I0929 14:39:53.264724 22954 solver.cpp:580]     Test net output #1: prob = 0.922302
I0929 14:39:53.264739 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_53500.caffemodel
I0929 14:39:53.275317 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_53500.solverstate
I0929 14:39:53.278080 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 14:39:53.478050 22954 solver.cpp:357] Iteration 53500 (2.21161 iter/s, 45.216s/100 iters), loss = 0.036171
I0929 14:39:53.478129 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.036171 (* 1 = 0.036171 loss)
I0929 14:39:53.478140 22954 sgd_solver.cpp:165] Iteration 53500, lr = 0.001
I0929 14:39:56.330305 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:40:18.822284 22954 solver.cpp:357] Iteration 53600 (3.94597 iter/s, 25.3423s/100 iters), loss = 0.0300937
I0929 14:40:18.822553 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0300937 (* 1 = 0.0300937 loss)
I0929 14:40:18.822566 22954 sgd_solver.cpp:165] Iteration 53600, lr = 0.001
I0929 14:40:44.100605 22954 solver.cpp:357] Iteration 53700 (3.95623 iter/s, 25.2766s/100 iters), loss = 0.014876
I0929 14:40:44.100687 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0148759 (* 1 = 0.0148759 loss)
I0929 14:40:44.100697 22954 sgd_solver.cpp:165] Iteration 53700, lr = 0.001
I0929 14:41:09.447969 22954 solver.cpp:357] Iteration 53800 (3.94525 iter/s, 25.347s/100 iters), loss = 0.0296039
I0929 14:41:09.448151 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0296039 (* 1 = 0.0296039 loss)
I0929 14:41:09.448163 22954 sgd_solver.cpp:165] Iteration 53800, lr = 0.001
I0929 14:41:34.755847 22954 solver.cpp:357] Iteration 53900 (3.95142 iter/s, 25.3074s/100 iters), loss = 0.0377324
I0929 14:41:34.755929 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0377324 (* 1 = 0.0377324 loss)
I0929 14:41:34.755939 22954 sgd_solver.cpp:165] Iteration 53900, lr = 0.001
I0929 14:41:35.331537 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:41:59.857652 22954 solver.cpp:514] Iteration 54000, Testing net (#0)
I0929 14:42:19.399507 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:42:19.413172 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.264894 (* 1 = 0.264894 loss)
I0929 14:42:19.413203 22954 solver.cpp:580]     Test net output #1: prob = 0.921602
I0929 14:42:19.413211 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 14:42:19.634183 22954 solver.cpp:357] Iteration 54000 (2.22821 iter/s, 44.8791s/100 iters), loss = 0.0463494
I0929 14:42:19.634234 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0463494 (* 1 = 0.0463494 loss)
I0929 14:42:19.634246 22954 sgd_solver.cpp:165] Iteration 54000, lr = 0.001
I0929 14:42:44.917943 22954 solver.cpp:357] Iteration 54100 (3.95521 iter/s, 25.2831s/100 iters), loss = 0.0305893
I0929 14:42:44.918072 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0305893 (* 1 = 0.0305893 loss)
I0929 14:42:44.918083 22954 sgd_solver.cpp:165] Iteration 54100, lr = 0.001
I0929 14:43:10.228333 22954 solver.cpp:357] Iteration 54200 (3.95105 iter/s, 25.3097s/100 iters), loss = 0.030069
I0929 14:43:10.228415 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.030069 (* 1 = 0.030069 loss)
I0929 14:43:10.228427 22954 sgd_solver.cpp:165] Iteration 54200, lr = 0.001
I0929 14:43:33.568500 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:43:35.502504 22954 solver.cpp:357] Iteration 54300 (3.95672 iter/s, 25.2735s/100 iters), loss = 0.0312292
I0929 14:43:35.502585 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0312291 (* 1 = 0.0312291 loss)
I0929 14:43:35.502598 22954 sgd_solver.cpp:165] Iteration 54300, lr = 0.001
I0929 14:44:00.852537 22954 solver.cpp:357] Iteration 54400 (3.94489 iter/s, 25.3493s/100 iters), loss = 0.0720476
I0929 14:44:00.852619 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0720476 (* 1 = 0.0720476 loss)
I0929 14:44:00.852632 22954 sgd_solver.cpp:165] Iteration 54400, lr = 0.001
I0929 14:44:25.948220 22954 solver.cpp:514] Iteration 54500, Testing net (#0)
I0929 14:44:45.513015 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:44:45.572846 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.27099 (* 1 = 0.27099 loss)
I0929 14:44:45.572876 22954 solver.cpp:580]     Test net output #1: prob = 0.918102
I0929 14:44:45.572882 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 14:44:45.811357 22954 solver.cpp:357] Iteration 54500 (2.22425 iter/s, 44.959s/100 iters), loss = 0.0363562
I0929 14:44:45.811404 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0363562 (* 1 = 0.0363562 loss)
I0929 14:44:45.811417 22954 sgd_solver.cpp:165] Iteration 54500, lr = 0.001
I0929 14:45:11.237474 22954 solver.cpp:357] Iteration 54600 (3.9331 iter/s, 25.4252s/100 iters), loss = 0.0244498
I0929 14:45:11.237776 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0244498 (* 1 = 0.0244498 loss)
I0929 14:45:11.237794 22954 sgd_solver.cpp:165] Iteration 54600, lr = 0.001
I0929 14:45:32.267277 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:45:36.546396 22954 solver.cpp:357] Iteration 54700 (3.95103 iter/s, 25.3099s/100 iters), loss = 0.0375735
I0929 14:45:36.546499 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0375735 (* 1 = 0.0375735 loss)
I0929 14:45:36.546512 22954 sgd_solver.cpp:165] Iteration 54700, lr = 0.001
I0929 14:46:01.850963 22954 solver.cpp:357] Iteration 54800 (3.95175 iter/s, 25.3052s/100 iters), loss = 0.0244579
I0929 14:46:01.853277 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0244579 (* 1 = 0.0244579 loss)
I0929 14:46:01.853291 22954 sgd_solver.cpp:165] Iteration 54800, lr = 0.001
I0929 14:46:27.106221 22954 solver.cpp:357] Iteration 54900 (3.95975 iter/s, 25.2541s/100 iters), loss = 0.0495997
I0929 14:46:27.106295 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0495997 (* 1 = 0.0495997 loss)
I0929 14:46:27.106307 22954 sgd_solver.cpp:165] Iteration 54900, lr = 0.001
I0929 14:46:52.213459 22954 solver.cpp:514] Iteration 55000, Testing net (#0)
I0929 14:47:11.680868 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:47:11.789438 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.268622 (* 1 = 0.268622 loss)
I0929 14:47:11.789464 22954 solver.cpp:580]     Test net output #1: prob = 0.917402
I0929 14:47:11.789471 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 14:47:12.002252 22954 solver.cpp:357] Iteration 55000 (2.22727 iter/s, 44.8979s/100 iters), loss = 0.0221642
I0929 14:47:12.002324 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0221642 (* 1 = 0.0221642 loss)
I0929 14:47:12.002336 22954 sgd_solver.cpp:165] Iteration 55000, lr = 0.001
I0929 14:47:30.733062 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:47:37.244889 22954 solver.cpp:357] Iteration 55100 (3.96139 iter/s, 25.2437s/100 iters), loss = 0.032437
I0929 14:47:37.244963 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.032437 (* 1 = 0.032437 loss)
I0929 14:47:37.244974 22954 sgd_solver.cpp:165] Iteration 55100, lr = 0.001
I0929 14:48:02.621170 22954 solver.cpp:357] Iteration 55200 (3.94054 iter/s, 25.3772s/100 iters), loss = 0.0459998
I0929 14:48:02.621337 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0459997 (* 1 = 0.0459997 loss)
I0929 14:48:02.621351 22954 sgd_solver.cpp:165] Iteration 55200, lr = 0.001
I0929 14:48:27.934824 22954 solver.cpp:357] Iteration 55300 (3.95061 iter/s, 25.3125s/100 iters), loss = 0.033414
I0929 14:48:27.934916 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.033414 (* 1 = 0.033414 loss)
I0929 14:48:27.934927 22954 sgd_solver.cpp:165] Iteration 55300, lr = 0.001
I0929 14:48:53.268594 22954 solver.cpp:357] Iteration 55400 (3.94749 iter/s, 25.3326s/100 iters), loss = 0.013254
I0929 14:48:53.268786 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.013254 (* 1 = 0.013254 loss)
I0929 14:48:53.268800 22954 sgd_solver.cpp:165] Iteration 55400, lr = 0.001
I0929 14:49:09.468245 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:49:18.282788 22954 solver.cpp:514] Iteration 55500, Testing net (#0)
I0929 14:49:38.104507 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:49:38.212332 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.264049 (* 1 = 0.264049 loss)
I0929 14:49:38.212358 22954 solver.cpp:580]     Test net output #1: prob = 0.919602
I0929 14:49:38.212364 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 14:49:38.446991 22954 solver.cpp:357] Iteration 55500 (2.21339 iter/s, 45.1796s/100 iters), loss = 0.0497841
I0929 14:49:38.447087 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0497841 (* 1 = 0.0497841 loss)
I0929 14:49:38.447100 22954 sgd_solver.cpp:165] Iteration 55500, lr = 0.001
I0929 14:50:03.727669 22954 solver.cpp:357] Iteration 55600 (3.95579 iter/s, 25.2794s/100 iters), loss = 0.0483611
I0929 14:50:03.727735 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0483611 (* 1 = 0.0483611 loss)
I0929 14:50:03.727743 22954 sgd_solver.cpp:165] Iteration 55600, lr = 0.001
I0929 14:50:29.096451 22954 solver.cpp:357] Iteration 55700 (3.94174 iter/s, 25.3695s/100 iters), loss = 0.050242
I0929 14:50:29.096680 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.050242 (* 1 = 0.050242 loss)
I0929 14:50:29.096693 22954 sgd_solver.cpp:165] Iteration 55700, lr = 0.001
I0929 14:50:54.419708 22954 solver.cpp:357] Iteration 55800 (3.94914 iter/s, 25.322s/100 iters), loss = 0.021284
I0929 14:50:54.419798 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.021284 (* 1 = 0.021284 loss)
I0929 14:50:54.419811 22954 sgd_solver.cpp:165] Iteration 55800, lr = 0.001
I0929 14:51:08.357468 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:51:19.730116 22954 solver.cpp:357] Iteration 55900 (3.95089 iter/s, 25.3107s/100 iters), loss = 0.061517
I0929 14:51:19.730206 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.061517 (* 1 = 0.061517 loss)
I0929 14:51:19.730217 22954 sgd_solver.cpp:165] Iteration 55900, lr = 0.001
I0929 14:51:44.810226 22954 solver.cpp:514] Iteration 56000, Testing net (#0)
I0929 14:52:04.550599 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:52:04.623663 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.266575 (* 1 = 0.266575 loss)
I0929 14:52:04.623693 22954 solver.cpp:580]     Test net output #1: prob = 0.919602
I0929 14:52:04.623699 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 14:52:04.859338 22954 solver.cpp:357] Iteration 56000 (2.21581 iter/s, 45.1303s/100 iters), loss = 0.0270416
I0929 14:52:04.859385 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0270416 (* 1 = 0.0270416 loss)
I0929 14:52:04.859396 22954 sgd_solver.cpp:165] Iteration 56000, lr = 0.001
I0929 14:52:30.269857 22954 solver.cpp:357] Iteration 56100 (3.93559 iter/s, 25.4092s/100 iters), loss = 0.0370333
I0929 14:52:30.270016 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0370333 (* 1 = 0.0370333 loss)
I0929 14:52:30.270030 22954 sgd_solver.cpp:165] Iteration 56100, lr = 0.001
I0929 14:52:55.547263 22954 solver.cpp:357] Iteration 56200 (3.95632 iter/s, 25.276s/100 iters), loss = 0.0192779
I0929 14:52:55.547343 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0192779 (* 1 = 0.0192779 loss)
I0929 14:52:55.547355 22954 sgd_solver.cpp:165] Iteration 56200, lr = 0.001
I0929 14:53:07.009426 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:53:20.894438 22954 solver.cpp:357] Iteration 56300 (3.94543 iter/s, 25.3458s/100 iters), loss = 0.027222
I0929 14:53:20.894531 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.027222 (* 1 = 0.027222 loss)
I0929 14:53:20.894546 22954 sgd_solver.cpp:165] Iteration 56300, lr = 0.001
I0929 14:53:46.220324 22954 solver.cpp:357] Iteration 56400 (3.94875 iter/s, 25.3245s/100 iters), loss = 0.0294549
I0929 14:53:46.220484 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0294549 (* 1 = 0.0294549 loss)
I0929 14:53:46.220496 22954 sgd_solver.cpp:165] Iteration 56400, lr = 0.001
I0929 14:54:11.292520 22954 solver.cpp:514] Iteration 56500, Testing net (#0)
I0929 14:54:31.133301 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:54:31.240916 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.260652 (* 1 = 0.260652 loss)
I0929 14:54:31.240942 22954 solver.cpp:580]     Test net output #1: prob = 0.922102
I0929 14:54:31.240948 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 14:54:31.450337 22954 solver.cpp:357] Iteration 56500 (2.21086 iter/s, 45.2312s/100 iters), loss = 0.0674321
I0929 14:54:31.450417 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0674321 (* 1 = 0.0674321 loss)
I0929 14:54:31.450430 22954 sgd_solver.cpp:165] Iteration 56500, lr = 0.001
I0929 14:54:56.851028 22954 solver.cpp:357] Iteration 56600 (3.93713 iter/s, 25.3992s/100 iters), loss = 0.0535952
I0929 14:54:56.851109 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0535952 (* 1 = 0.0535952 loss)
I0929 14:54:56.851119 22954 sgd_solver.cpp:165] Iteration 56600, lr = 0.001
I0929 14:55:05.985441 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:55:22.122432 22954 solver.cpp:357] Iteration 56700 (3.95727 iter/s, 25.2699s/100 iters), loss = 0.0315388
I0929 14:55:22.122524 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0315388 (* 1 = 0.0315388 loss)
I0929 14:55:22.122536 22954 sgd_solver.cpp:165] Iteration 56700, lr = 0.001
I0929 14:55:47.473264 22954 solver.cpp:357] Iteration 56800 (3.94488 iter/s, 25.3493s/100 iters), loss = 0.0274074
I0929 14:55:47.473453 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0274074 (* 1 = 0.0274074 loss)
I0929 14:55:47.473464 22954 sgd_solver.cpp:165] Iteration 56800, lr = 0.001
I0929 14:56:12.788648 22954 solver.cpp:357] Iteration 56900 (3.9504 iter/s, 25.3139s/100 iters), loss = 0.0159779
I0929 14:56:12.788730 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0159778 (* 1 = 0.0159778 loss)
I0929 14:56:12.788740 22954 sgd_solver.cpp:165] Iteration 56900, lr = 0.001
I0929 14:56:37.898666 22954 solver.cpp:514] Iteration 57000, Testing net (#0)
I0929 14:56:57.549285 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:56:57.657162 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.267201 (* 1 = 0.267201 loss)
I0929 14:56:57.657187 22954 solver.cpp:580]     Test net output #1: prob = 0.918502
I0929 14:56:57.657193 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 14:56:57.871953 22954 solver.cpp:357] Iteration 57000 (2.21816 iter/s, 45.0823s/100 iters), loss = 0.0203513
I0929 14:56:57.872035 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0203513 (* 1 = 0.0203513 loss)
I0929 14:56:57.872048 22954 sgd_solver.cpp:165] Iteration 57000, lr = 0.001
I0929 14:57:04.819926 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:57:23.258361 22954 solver.cpp:357] Iteration 57100 (3.93935 iter/s, 25.3849s/100 iters), loss = 0.036287
I0929 14:57:23.258539 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.036287 (* 1 = 0.036287 loss)
I0929 14:57:23.258550 22954 sgd_solver.cpp:165] Iteration 57100, lr = 0.001
I0929 14:57:48.573858 22954 solver.cpp:357] Iteration 57200 (3.95039 iter/s, 25.314s/100 iters), loss = 0.0214705
I0929 14:57:48.573943 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0214704 (* 1 = 0.0214704 loss)
I0929 14:57:48.573954 22954 sgd_solver.cpp:165] Iteration 57200, lr = 0.001
I0929 14:58:13.890656 22954 solver.cpp:357] Iteration 57300 (3.95019 iter/s, 25.3153s/100 iters), loss = 0.0155809
I0929 14:58:13.890838 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0155809 (* 1 = 0.0155809 loss)
I0929 14:58:13.890849 22954 sgd_solver.cpp:165] Iteration 57300, lr = 0.001
I0929 14:58:39.206315 22954 solver.cpp:357] Iteration 57400 (3.95037 iter/s, 25.3141s/100 iters), loss = 0.0420337
I0929 14:58:39.206396 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0420337 (* 1 = 0.0420337 loss)
I0929 14:58:39.206409 22954 sgd_solver.cpp:165] Iteration 57400, lr = 0.001
I0929 14:58:43.562062 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:59:04.319933 22954 solver.cpp:514] Iteration 57500, Testing net (#0)
I0929 14:59:23.891257 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 14:59:23.905195 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.273574 (* 1 = 0.273574 loss)
I0929 14:59:23.905223 22954 solver.cpp:580]     Test net output #1: prob = 0.918702
I0929 14:59:23.905230 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 14:59:24.134209 22954 solver.cpp:357] Iteration 57500 (2.22584 iter/s, 44.9268s/100 iters), loss = 0.0220536
I0929 14:59:24.134260 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0220536 (* 1 = 0.0220536 loss)
I0929 14:59:24.134274 22954 sgd_solver.cpp:165] Iteration 57500, lr = 0.001
I0929 14:59:49.426043 22954 solver.cpp:357] Iteration 57600 (3.95409 iter/s, 25.2902s/100 iters), loss = 0.0262186
I0929 14:59:49.426297 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0262186 (* 1 = 0.0262186 loss)
I0929 14:59:49.426308 22954 sgd_solver.cpp:165] Iteration 57600, lr = 0.001
I0929 15:00:14.745448 22954 solver.cpp:357] Iteration 57700 (3.94979 iter/s, 25.3178s/100 iters), loss = 0.0579804
I0929 15:00:14.745529 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0579804 (* 1 = 0.0579804 loss)
I0929 15:00:14.745542 22954 sgd_solver.cpp:165] Iteration 57700, lr = 0.001
I0929 15:00:40.067879 22954 solver.cpp:357] Iteration 57800 (3.94931 iter/s, 25.3208s/100 iters), loss = 0.0384787
I0929 15:00:40.068018 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0384787 (* 1 = 0.0384787 loss)
I0929 15:00:40.068029 22954 sgd_solver.cpp:165] Iteration 57800, lr = 0.001
I0929 15:00:42.160131 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:01:05.387320 22954 solver.cpp:357] Iteration 57900 (3.94978 iter/s, 25.3179s/100 iters), loss = 0.0130429
I0929 15:01:05.387403 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0130429 (* 1 = 0.0130429 loss)
I0929 15:01:05.387414 22954 sgd_solver.cpp:165] Iteration 57900, lr = 0.001
I0929 15:01:30.492486 22954 solver.cpp:514] Iteration 58000, Testing net (#0)
I0929 15:01:50.278074 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:01:50.313177 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.277966 (* 1 = 0.277966 loss)
I0929 15:01:50.313210 22954 solver.cpp:580]     Test net output #1: prob = 0.918502
I0929 15:01:50.313215 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:01:50.529820 22954 solver.cpp:357] Iteration 58000 (2.21526 iter/s, 45.1414s/100 iters), loss = 0.0208138
I0929 15:01:50.529904 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0208138 (* 1 = 0.0208138 loss)
I0929 15:01:50.529917 22954 sgd_solver.cpp:165] Iteration 58000, lr = 0.001
I0929 15:02:15.885270 22954 solver.cpp:357] Iteration 58100 (3.94418 iter/s, 25.3538s/100 iters), loss = 0.0247566
I0929 15:02:15.885452 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0247566 (* 1 = 0.0247566 loss)
I0929 15:02:15.885463 22954 sgd_solver.cpp:165] Iteration 58100, lr = 0.001
I0929 15:02:40.996810 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:02:41.200018 22954 solver.cpp:357] Iteration 58200 (3.95052 iter/s, 25.3131s/100 iters), loss = 0.0308926
I0929 15:02:41.200083 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0308926 (* 1 = 0.0308926 loss)
I0929 15:02:41.200094 22954 sgd_solver.cpp:165] Iteration 58200, lr = 0.001
I0929 15:03:06.509925 22954 solver.cpp:357] Iteration 58300 (3.95128 iter/s, 25.3083s/100 iters), loss = 0.0237149
I0929 15:03:06.510103 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0237148 (* 1 = 0.0237148 loss)
I0929 15:03:06.510115 22954 sgd_solver.cpp:165] Iteration 58300, lr = 0.001
I0929 15:03:31.782764 22954 solver.cpp:357] Iteration 58400 (3.95707 iter/s, 25.2712s/100 iters), loss = 0.0523527
I0929 15:03:31.782851 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0523527 (* 1 = 0.0523527 loss)
I0929 15:03:31.782865 22954 sgd_solver.cpp:165] Iteration 58400, lr = 0.001
I0929 15:03:56.924367 22954 solver.cpp:514] Iteration 58500, Testing net (#0)
I0929 15:04:16.716766 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:04:16.782691 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.269655 (* 1 = 0.269655 loss)
I0929 15:04:16.782733 22954 solver.cpp:580]     Test net output #1: prob = 0.919502
I0929 15:04:16.782742 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:04:17.000519 22954 solver.cpp:357] Iteration 58500 (2.21158 iter/s, 45.2166s/100 iters), loss = 0.0127225
I0929 15:04:17.000581 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0127225 (* 1 = 0.0127225 loss)
I0929 15:04:17.000591 22954 sgd_solver.cpp:165] Iteration 58500, lr = 0.001
I0929 15:04:39.587091 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:04:42.305532 22954 solver.cpp:357] Iteration 58600 (3.95204 iter/s, 25.3034s/100 iters), loss = 0.0610084
I0929 15:04:42.305613 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0610084 (* 1 = 0.0610084 loss)
I0929 15:04:42.305624 22954 sgd_solver.cpp:165] Iteration 58600, lr = 0.001
I0929 15:05:07.641854 22954 solver.cpp:357] Iteration 58700 (3.94716 iter/s, 25.3347s/100 iters), loss = 0.0449618
I0929 15:05:07.641945 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0449618 (* 1 = 0.0449618 loss)
I0929 15:05:07.641957 22954 sgd_solver.cpp:165] Iteration 58700, lr = 0.001
I0929 15:05:32.947557 22954 solver.cpp:357] Iteration 58800 (3.95194 iter/s, 25.304s/100 iters), loss = 0.0186318
I0929 15:05:32.947737 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0186317 (* 1 = 0.0186317 loss)
I0929 15:05:32.947748 22954 sgd_solver.cpp:165] Iteration 58800, lr = 0.001
I0929 15:05:58.250054 22954 solver.cpp:357] Iteration 58900 (3.95244 iter/s, 25.3008s/100 iters), loss = 0.0439013
I0929 15:05:58.250136 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0439013 (* 1 = 0.0439013 loss)
I0929 15:05:58.250149 22954 sgd_solver.cpp:165] Iteration 58900, lr = 0.001
I0929 15:06:18.575139 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:06:23.342315 22954 solver.cpp:514] Iteration 59000, Testing net (#0)
I0929 15:06:42.553581 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:06:42.661640 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.273312 (* 1 = 0.273312 loss)
I0929 15:06:42.661695 22954 solver.cpp:580]     Test net output #1: prob = 0.920103
I0929 15:06:42.661701 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:06:42.858352 22954 solver.cpp:357] Iteration 59000 (2.2418 iter/s, 44.6071s/100 iters), loss = 0.00952894
I0929 15:06:42.858412 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.00952893 (* 1 = 0.00952893 loss)
I0929 15:06:42.858427 22954 sgd_solver.cpp:165] Iteration 59000, lr = 0.001
I0929 15:07:08.183576 22954 solver.cpp:357] Iteration 59100 (3.94889 iter/s, 25.3236s/100 iters), loss = 0.0210159
I0929 15:07:08.183755 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0210159 (* 1 = 0.0210159 loss)
I0929 15:07:08.183768 22954 sgd_solver.cpp:165] Iteration 59100, lr = 0.001
I0929 15:07:33.460417 22954 solver.cpp:357] Iteration 59200 (3.95645 iter/s, 25.2752s/100 iters), loss = 0.016519
I0929 15:07:33.460506 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.016519 (* 1 = 0.016519 loss)
I0929 15:07:33.460520 22954 sgd_solver.cpp:165] Iteration 59200, lr = 0.001
I0929 15:07:58.818917 22954 solver.cpp:357] Iteration 59300 (3.94371 iter/s, 25.3568s/100 iters), loss = 0.0204051
I0929 15:07:58.819044 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0204051 (* 1 = 0.0204051 loss)
I0929 15:07:58.819057 22954 sgd_solver.cpp:165] Iteration 59300, lr = 0.001
I0929 15:08:16.590364 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:08:24.132625 22954 solver.cpp:357] Iteration 59400 (3.95069 iter/s, 25.312s/100 iters), loss = 0.037206
I0929 15:08:24.132700 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0372059 (* 1 = 0.0372059 loss)
I0929 15:08:24.132710 22954 sgd_solver.cpp:165] Iteration 59400, lr = 0.001
I0929 15:08:49.257287 22954 solver.cpp:514] Iteration 59500, Testing net (#0)
I0929 15:09:09.054495 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:09:09.164775 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.269765 (* 1 = 0.269765 loss)
I0929 15:09:09.164824 22954 solver.cpp:580]     Test net output #1: prob = 0.920402
I0929 15:09:09.164830 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:09:09.368409 22954 solver.cpp:357] Iteration 59500 (2.2107 iter/s, 45.2346s/100 iters), loss = 0.0196224
I0929 15:09:09.368480 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0196224 (* 1 = 0.0196224 loss)
I0929 15:09:09.368491 22954 sgd_solver.cpp:165] Iteration 59500, lr = 0.001
I0929 15:09:34.688125 22954 solver.cpp:357] Iteration 59600 (3.94975 iter/s, 25.318s/100 iters), loss = 0.0567475
I0929 15:09:34.688369 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0567475 (* 1 = 0.0567475 loss)
I0929 15:09:34.688381 22954 sgd_solver.cpp:165] Iteration 59600, lr = 0.001
I0929 15:10:00.021452 22954 solver.cpp:357] Iteration 59700 (3.94763 iter/s, 25.3316s/100 iters), loss = 0.0354607
I0929 15:10:00.021533 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0354607 (* 1 = 0.0354607 loss)
I0929 15:10:00.021543 22954 sgd_solver.cpp:165] Iteration 59700, lr = 0.001
I0929 15:10:15.516305 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:10:25.332024 22954 solver.cpp:357] Iteration 59800 (3.95118 iter/s, 25.3089s/100 iters), loss = 0.0338445
I0929 15:10:25.332104 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0338445 (* 1 = 0.0338445 loss)
I0929 15:10:25.332118 22954 sgd_solver.cpp:165] Iteration 59800, lr = 0.001
I0929 15:10:50.650985 22954 solver.cpp:357] Iteration 59900 (3.94987 iter/s, 25.3173s/100 iters), loss = 0.037029
I0929 15:10:50.651113 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.037029 (* 1 = 0.037029 loss)
I0929 15:10:50.651124 22954 sgd_solver.cpp:165] Iteration 59900, lr = 0.001
I0929 15:11:15.745016 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_60000.caffemodel
I0929 15:11:15.753729 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_60000.solverstate
I0929 15:11:15.756649 22954 solver.cpp:514] Iteration 60000, Testing net (#0)
I0929 15:11:35.621170 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:11:35.649340 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.29037 (* 1 = 0.29037 loss)
I0929 15:11:35.649384 22954 solver.cpp:580]     Test net output #1: prob = 0.916403
I0929 15:11:35.649390 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:11:35.868930 22954 solver.cpp:357] Iteration 60000 (2.21157 iter/s, 45.2167s/100 iters), loss = 0.0122419
I0929 15:11:35.868988 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0122419 (* 1 = 0.0122419 loss)
I0929 15:11:35.869004 22954 sgd_solver.cpp:165] Iteration 60000, lr = 0.001
I0929 15:12:01.176017 22954 solver.cpp:357] Iteration 60100 (3.95173 iter/s, 25.3054s/100 iters), loss = 0.0271304
I0929 15:12:01.176090 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0271304 (* 1 = 0.0271304 loss)
I0929 15:12:01.176101 22954 sgd_solver.cpp:165] Iteration 60100, lr = 0.001
I0929 15:12:14.395256 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:12:26.488281 22954 solver.cpp:357] Iteration 60200 (3.95092 iter/s, 25.3106s/100 iters), loss = 0.0251204
I0929 15:12:26.488359 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0251204 (* 1 = 0.0251204 loss)
I0929 15:12:26.488371 22954 sgd_solver.cpp:165] Iteration 60200, lr = 0.001
I0929 15:12:51.763499 22954 solver.cpp:357] Iteration 60300 (3.9567 iter/s, 25.2736s/100 iters), loss = 0.0210133
I0929 15:12:51.763643 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0210133 (* 1 = 0.0210133 loss)
I0929 15:12:51.763655 22954 sgd_solver.cpp:165] Iteration 60300, lr = 0.001
I0929 15:13:17.131980 22954 solver.cpp:357] Iteration 60400 (3.94216 iter/s, 25.3668s/100 iters), loss = 0.0339023
I0929 15:13:17.132064 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0339023 (* 1 = 0.0339023 loss)
I0929 15:13:17.132076 22954 sgd_solver.cpp:165] Iteration 60400, lr = 0.001
I0929 15:13:42.240449 22954 solver.cpp:514] Iteration 60500, Testing net (#0)
I0929 15:14:01.799957 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:14:01.829679 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.284629 (* 1 = 0.284629 loss)
I0929 15:14:01.829710 22954 solver.cpp:580]     Test net output #1: prob = 0.917902
I0929 15:14:01.829715 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:14:02.068075 22954 solver.cpp:357] Iteration 60500 (2.22545 iter/s, 44.9348s/100 iters), loss = 0.0466771
I0929 15:14:02.068123 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0466771 (* 1 = 0.0466771 loss)
I0929 15:14:02.068137 22954 sgd_solver.cpp:165] Iteration 60500, lr = 0.001
I0929 15:14:12.839445 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:14:27.513204 22954 solver.cpp:357] Iteration 60600 (3.93029 iter/s, 25.4434s/100 iters), loss = 0.0330648
I0929 15:14:27.513296 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0330648 (* 1 = 0.0330648 loss)
I0929 15:14:27.513309 22954 sgd_solver.cpp:165] Iteration 60600, lr = 0.001
I0929 15:14:52.829799 22954 solver.cpp:357] Iteration 60700 (3.94993 iter/s, 25.3169s/100 iters), loss = 0.0292103
I0929 15:14:52.829960 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0292103 (* 1 = 0.0292103 loss)
I0929 15:14:52.829973 22954 sgd_solver.cpp:165] Iteration 60700, lr = 0.001
I0929 15:15:18.145984 22954 solver.cpp:357] Iteration 60800 (3.94948 iter/s, 25.3198s/100 iters), loss = 0.0160922
I0929 15:15:18.146076 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0160922 (* 1 = 0.0160922 loss)
I0929 15:15:18.146090 22954 sgd_solver.cpp:165] Iteration 60800, lr = 0.001
I0929 15:15:43.428038 22954 solver.cpp:357] Iteration 60900 (3.95489 iter/s, 25.2851s/100 iters), loss = 0.0232085
I0929 15:15:43.428216 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0232085 (* 1 = 0.0232085 loss)
I0929 15:15:43.428246 22954 sgd_solver.cpp:165] Iteration 60900, lr = 0.001
I0929 15:15:51.842228 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:16:08.522989 22954 solver.cpp:514] Iteration 61000, Testing net (#0)
I0929 15:16:28.095434 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:16:28.199712 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.274998 (* 1 = 0.274998 loss)
I0929 15:16:28.199781 22954 solver.cpp:580]     Test net output #1: prob = 0.918102
I0929 15:16:28.199789 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:16:28.410184 22954 solver.cpp:357] Iteration 61000 (2.22291 iter/s, 44.9861s/100 iters), loss = 0.0203156
I0929 15:16:28.410248 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0203156 (* 1 = 0.0203156 loss)
I0929 15:16:28.410261 22954 sgd_solver.cpp:165] Iteration 61000, lr = 0.001
I0929 15:16:53.710857 22954 solver.cpp:357] Iteration 61100 (3.95228 iter/s, 25.3018s/100 iters), loss = 0.0400154
I0929 15:16:53.710938 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0400154 (* 1 = 0.0400154 loss)
I0929 15:16:53.710949 22954 sgd_solver.cpp:165] Iteration 61100, lr = 0.001
I0929 15:17:19.032058 22954 solver.cpp:357] Iteration 61200 (3.9491 iter/s, 25.3222s/100 iters), loss = 0.0159659
I0929 15:17:19.032239 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0159659 (* 1 = 0.0159659 loss)
I0929 15:17:19.032250 22954 sgd_solver.cpp:165] Iteration 61200, lr = 0.001
I0929 15:17:44.341679 22954 solver.cpp:357] Iteration 61300 (3.95092 iter/s, 25.3106s/100 iters), loss = 0.0335326
I0929 15:17:44.341760 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0335326 (* 1 = 0.0335326 loss)
I0929 15:17:44.341771 22954 sgd_solver.cpp:165] Iteration 61300, lr = 0.001
I0929 15:17:50.492033 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:18:09.669126 22954 solver.cpp:357] Iteration 61400 (3.94816 iter/s, 25.3283s/100 iters), loss = 0.0351778
I0929 15:18:09.669198 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0351778 (* 1 = 0.0351778 loss)
I0929 15:18:09.669209 22954 sgd_solver.cpp:165] Iteration 61400, lr = 0.001
I0929 15:18:34.766388 22954 solver.cpp:514] Iteration 61500, Testing net (#0)
I0929 15:18:54.363972 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:18:54.472445 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.286504 (* 1 = 0.286504 loss)
I0929 15:18:54.472472 22954 solver.cpp:580]     Test net output #1: prob = 0.919902
I0929 15:18:54.472478 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:18:54.706552 22954 solver.cpp:357] Iteration 61500 (2.22023 iter/s, 45.0403s/100 iters), loss = 0.0382471
I0929 15:18:54.706641 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0382471 (* 1 = 0.0382471 loss)
I0929 15:18:54.706655 22954 sgd_solver.cpp:165] Iteration 61500, lr = 0.001
I0929 15:19:19.964485 22954 solver.cpp:357] Iteration 61600 (3.95907 iter/s, 25.2585s/100 iters), loss = 0.0251337
I0929 15:19:19.964597 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0251337 (* 1 = 0.0251337 loss)
I0929 15:19:19.964608 22954 sgd_solver.cpp:165] Iteration 61600, lr = 0.001
I0929 15:19:45.326279 22954 solver.cpp:357] Iteration 61700 (3.94255 iter/s, 25.3643s/100 iters), loss = 0.0366066
I0929 15:19:45.326372 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0366066 (* 1 = 0.0366066 loss)
I0929 15:19:45.326386 22954 sgd_solver.cpp:165] Iteration 61700, lr = 0.001
I0929 15:19:48.886349 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:20:10.642199 22954 solver.cpp:357] Iteration 61800 (3.95003 iter/s, 25.3163s/100 iters), loss = 0.0340063
I0929 15:20:10.642387 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0340063 (* 1 = 0.0340063 loss)
I0929 15:20:10.642401 22954 sgd_solver.cpp:165] Iteration 61800, lr = 0.001
I0929 15:20:35.933838 22954 solver.cpp:357] Iteration 61900 (3.95355 iter/s, 25.2937s/100 iters), loss = 0.0254106
I0929 15:20:35.933939 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0254107 (* 1 = 0.0254107 loss)
I0929 15:20:35.933954 22954 sgd_solver.cpp:165] Iteration 61900, lr = 0.001
I0929 15:21:01.026706 22954 solver.cpp:514] Iteration 62000, Testing net (#0)
I0929 15:21:20.750274 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:21:20.856159 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.275064 (* 1 = 0.275064 loss)
I0929 15:21:20.856187 22954 solver.cpp:580]     Test net output #1: prob = 0.919802
I0929 15:21:20.856194 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:21:21.090967 22954 solver.cpp:357] Iteration 62000 (2.21438 iter/s, 45.1593s/100 iters), loss = 0.0402592
I0929 15:21:21.091056 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0402592 (* 1 = 0.0402592 loss)
I0929 15:21:21.091069 22954 sgd_solver.cpp:165] Iteration 62000, lr = 0.001
I0929 15:21:46.439231 22954 solver.cpp:357] Iteration 62100 (3.94502 iter/s, 25.3484s/100 iters), loss = 0.0388047
I0929 15:21:46.439375 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0388047 (* 1 = 0.0388047 loss)
I0929 15:21:46.439389 22954 sgd_solver.cpp:165] Iteration 62100, lr = 0.001
I0929 15:21:47.735725 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:22:11.697515 22954 solver.cpp:357] Iteration 62200 (3.95909 iter/s, 25.2583s/100 iters), loss = 0.0329859
I0929 15:22:11.697597 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0329859 (* 1 = 0.0329859 loss)
I0929 15:22:11.697607 22954 sgd_solver.cpp:165] Iteration 62200, lr = 0.001
I0929 15:22:37.077080 22954 solver.cpp:357] Iteration 62300 (3.94018 iter/s, 25.3796s/100 iters), loss = 0.026799
I0929 15:22:37.077245 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0267991 (* 1 = 0.0267991 loss)
I0929 15:22:37.077258 22954 sgd_solver.cpp:165] Iteration 62300, lr = 0.001
I0929 15:23:02.389830 22954 solver.cpp:357] Iteration 62400 (3.95059 iter/s, 25.3127s/100 iters), loss = 0.0301043
I0929 15:23:02.389917 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0301043 (* 1 = 0.0301043 loss)
I0929 15:23:02.389938 22954 sgd_solver.cpp:165] Iteration 62400, lr = 0.001
I0929 15:23:26.459278 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:23:27.450044 22954 solver.cpp:514] Iteration 62500, Testing net (#0)
I0929 15:23:47.130623 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:23:47.142457 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.27714 (* 1 = 0.27714 loss)
I0929 15:23:47.142485 22954 solver.cpp:580]     Test net output #1: prob = 0.919402
I0929 15:23:47.142491 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:23:47.365414 22954 solver.cpp:357] Iteration 62500 (2.22327 iter/s, 44.9788s/100 iters), loss = 0.0308575
I0929 15:23:47.365465 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0308575 (* 1 = 0.0308575 loss)
I0929 15:23:47.365478 22954 sgd_solver.cpp:165] Iteration 62500, lr = 0.001
I0929 15:24:12.658038 22954 solver.cpp:357] Iteration 62600 (3.95375 iter/s, 25.2924s/100 iters), loss = 0.0310364
I0929 15:24:12.658229 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0310365 (* 1 = 0.0310365 loss)
I0929 15:24:12.658242 22954 sgd_solver.cpp:165] Iteration 62600, lr = 0.001
I0929 15:24:37.961792 22954 solver.cpp:357] Iteration 62700 (3.95202 iter/s, 25.3035s/100 iters), loss = 0.0361601
I0929 15:24:37.961874 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0361601 (* 1 = 0.0361601 loss)
I0929 15:24:37.961885 22954 sgd_solver.cpp:165] Iteration 62700, lr = 0.001
I0929 15:25:03.268060 22954 solver.cpp:357] Iteration 62800 (3.95163 iter/s, 25.306s/100 iters), loss = 0.0499641
I0929 15:25:03.268185 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0499642 (* 1 = 0.0499642 loss)
I0929 15:25:03.268198 22954 sgd_solver.cpp:165] Iteration 62800, lr = 0.001
I0929 15:25:25.099977 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:25:28.576088 22954 solver.cpp:357] Iteration 62900 (3.95137 iter/s, 25.3077s/100 iters), loss = 0.0271182
I0929 15:25:28.576169 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0271182 (* 1 = 0.0271182 loss)
I0929 15:25:28.576181 22954 sgd_solver.cpp:165] Iteration 62900, lr = 0.001
I0929 15:25:53.676532 22954 solver.cpp:514] Iteration 63000, Testing net (#0)
I0929 15:26:13.369870 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:26:13.476099 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.279152 (* 1 = 0.279152 loss)
I0929 15:26:13.476127 22954 solver.cpp:580]     Test net output #1: prob = 0.920002
I0929 15:26:13.476135 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:26:13.693059 22954 solver.cpp:357] Iteration 63000 (2.21641 iter/s, 45.118s/100 iters), loss = 0.012951
I0929 15:26:13.693143 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.012951 (* 1 = 0.012951 loss)
I0929 15:26:13.693156 22954 sgd_solver.cpp:165] Iteration 63000, lr = 0.001
I0929 15:26:39.050125 22954 solver.cpp:357] Iteration 63100 (3.94374 iter/s, 25.3566s/100 iters), loss = 0.0274316
I0929 15:26:39.050284 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0274316 (* 1 = 0.0274316 loss)
I0929 15:26:39.050297 22954 sgd_solver.cpp:165] Iteration 63100, lr = 0.001
I0929 15:27:04.370978 22954 solver.cpp:357] Iteration 63200 (3.94939 iter/s, 25.3204s/100 iters), loss = 0.0140469
I0929 15:27:04.371060 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0140469 (* 1 = 0.0140469 loss)
I0929 15:27:04.371070 22954 sgd_solver.cpp:165] Iteration 63200, lr = 0.001
I0929 15:27:23.908778 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:27:29.629434 22954 solver.cpp:357] Iteration 63300 (3.95915 iter/s, 25.258s/100 iters), loss = 0.0509418
I0929 15:27:29.629528 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0509418 (* 1 = 0.0509418 loss)
I0929 15:27:29.629540 22954 sgd_solver.cpp:165] Iteration 63300, lr = 0.001
I0929 15:27:55.001451 22954 solver.cpp:357] Iteration 63400 (3.94143 iter/s, 25.3715s/100 iters), loss = 0.0428211
I0929 15:27:55.001628 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0428211 (* 1 = 0.0428211 loss)
I0929 15:27:55.001641 22954 sgd_solver.cpp:165] Iteration 63400, lr = 0.001
I0929 15:28:20.120276 22954 solver.cpp:514] Iteration 63500, Testing net (#0)
I0929 15:28:40.019608 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:28:40.033489 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.286445 (* 1 = 0.286445 loss)
I0929 15:28:40.033517 22954 solver.cpp:580]     Test net output #1: prob = 0.919102
I0929 15:28:40.033524 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:28:40.265738 22954 solver.cpp:357] Iteration 63500 (2.20921 iter/s, 45.265s/100 iters), loss = 0.0444313
I0929 15:28:40.265789 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0444313 (* 1 = 0.0444313 loss)
I0929 15:28:40.265801 22954 sgd_solver.cpp:165] Iteration 63500, lr = 0.001
I0929 15:29:05.705052 22954 solver.cpp:357] Iteration 63600 (3.93102 iter/s, 25.4387s/100 iters), loss = 0.0163462
I0929 15:29:05.705148 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0163462 (* 1 = 0.0163462 loss)
I0929 15:29:05.705162 22954 sgd_solver.cpp:165] Iteration 63600, lr = 0.001
I0929 15:29:22.707525 22959 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:29:31.028221 22954 solver.cpp:357] Iteration 63700 (3.94906 iter/s, 25.3225s/100 iters), loss = 0.0185919
I0929 15:29:31.028313 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0185919 (* 1 = 0.0185919 loss)
I0929 15:29:31.028326 22954 sgd_solver.cpp:165] Iteration 63700, lr = 0.001
I0929 15:29:56.273098 22954 solver.cpp:357] Iteration 63800 (3.96105 iter/s, 25.2458s/100 iters), loss = 0.0223457
I0929 15:29:56.273372 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0223457 (* 1 = 0.0223457 loss)
I0929 15:29:56.273429 22954 sgd_solver.cpp:165] Iteration 63800, lr = 0.001
I0929 15:30:21.641362 22954 solver.cpp:357] Iteration 63900 (3.94175 iter/s, 25.3695s/100 iters), loss = 0.0413277
I0929 15:30:21.641506 22954 solver.cpp:376]     Train net output #0: Softmax1 = 0.0413277 (* 1 = 0.0413277 loss)
I0929 15:30:21.641525 22954 sgd_solver.cpp:165] Iteration 63900, lr = 0.001
I0929 15:30:46.705118 22954 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_64000.caffemodel
I0929 15:30:46.716840 22954 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_64000.solverstate
I0929 15:30:46.784247 22954 solver.cpp:472] Iteration 64000, loss = 0.0220242
I0929 15:30:46.784298 22954 solver.cpp:514] Iteration 64000, Testing net (#0)
I0929 15:31:06.418010 22960 data_layer.cpp:73] Restarting data prefetching from start.
I0929 15:31:06.523227 22954 solver.cpp:580]     Test net output #0: Softmax1 = 0.281132 (* 1 = 0.281132 loss)
I0929 15:31:06.523253 22954 solver.cpp:580]     Test net output #1: prob = 0.918702
I0929 15:31:06.523259 22954 solver.cpp:593]     Max_acc: 0.922302  with iter: 53500
I0929 15:31:06.523270 22954 solver.cpp:479] Optimization Done.
I0929 15:31:06.523275 22954 caffe.cpp:326] Optimization Done.
