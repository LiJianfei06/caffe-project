WARNING: Logging before InitGoogleLogging() is written to STDERR
I0925 21:35:42.491786 19975 caffe.cpp:530] argc:5 lijianfei debug!!!!!!!!!!
I0925 21:35:42.491905 19975 caffe.cpp:533] argv[0]:../../build/tools/caffe lijianfei debug!!!!!!!!!!
I0925 21:35:42.491910 19975 caffe.cpp:533] argv[1]:train lijianfei debug!!!!!!!!!!
I0925 21:35:42.491914 19975 caffe.cpp:533] argv[2]:--solver=./solver.prototxt lijianfei debug!!!!!!!!!!
I0925 21:35:42.491917 19975 caffe.cpp:533] argv[3]:--weights= lijianfei debug!!!!!!!!!!
I0925 21:35:42.491920 19975 caffe.cpp:533] argv[4]:--gpu=0 lijianfei debug!!!!!!!!!!
I0925 21:35:42.491976 19975 caffe.cpp:548] use WITH_PYTHON_LAYER lijianfei debug!!!!!!!!!!
I0925 21:35:42.492154 19975 caffe.cpp:553] caffe::string(argv[1]):train lijianfei debug!!!!!!!!!!
I0925 21:35:42.493880 19975 caffe.cpp:238] stages: lijianfei debug!!!!!!!!!!!!
I0925 21:35:42.493917 19975 caffe.cpp:269] Using GPUs 0
I0925 21:35:42.519913 19975 caffe.cpp:274] GPU 0: GeForce GTX 1060 6GB
I0925 21:35:42.910763 19975 solver_factory.hpp:111] function Solver<Dtype>* CreateSolver()  lijianfei debug!!!!!!!!!!
I0925 21:35:42.910804 19975 solver_factory.hpp:113] type:Nesterov lijianfei debug!!!!!!!!!!
I0925 21:35:42.930907 19975 solver.cpp:97] Initializing solver from parameters: 
train_net: "./train_ResNet_20.prototxt"
test_net: "./test_ResNet_20.prototxt"
test_iter: 1000
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "./model_save/cifar10_ResNet_20"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
stepvalue: 32000
stepvalue: 48000
iter_size: 1
type: "Nesterov"
I0925 21:35:42.931171 19975 solver.cpp:167] Creating training net from train_net file: ./train_ResNet_20.prototxt
I0925 21:35:42.932068 19975 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./train_ResNet_20.prototxt
I0925 21:35:42.932087 19975 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0925 21:35:42.932996 19975 net.cpp:82] Initializing net from parameters: 
name: "ResNet-20"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: true
    crop_size: 32
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "conv2_1_1"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "conv4_Eltwise_3"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Softmax1"
  type: "SoftmaxWithLoss"
  bottom: "fc1"
  bottom: "label"
  top: "Softmax1"
}
I0925 21:35:42.933481 19975 layer_factory.hpp:77] Creating layer Data1
I0925 21:35:42.933678 19975 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/train_lmdb
I0925 21:35:42.933722 19975 net.cpp:128] Creating Layer Data1
I0925 21:35:42.933733 19975 net.cpp:522] Data1 -> data
I0925 21:35:42.933760 19975 net.cpp:522] Data1 -> label
I0925 21:35:42.935451 19975 data_layer.cpp:45] output data size: 128,3,32,32
I0925 21:35:42.943966 19975 net.cpp:172] Setting up Data1
I0925 21:35:42.944054 19975 net.cpp:186] Top shape: 128 3 32 32 (393216)
I0925 21:35:42.944077 19975 net.cpp:186] Top shape: 128 (128)
I0925 21:35:42.944094 19975 net.cpp:194] Memory required for data: 1573376
I0925 21:35:42.944121 19975 layer_factory.hpp:77] Creating layer conv1
I0925 21:35:42.944177 19975 net.cpp:128] Creating Layer conv1
I0925 21:35:42.944198 19975 net.cpp:558] conv1 <- data
I0925 21:35:42.944238 19975 net.cpp:522] conv1 -> conv1
I0925 21:35:43.700392 19975 net.cpp:172] Setting up conv1
I0925 21:35:43.700454 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.700459 19975 net.cpp:194] Memory required for data: 9961984
I0925 21:35:43.700496 19975 layer_factory.hpp:77] Creating layer conv1/bn
I0925 21:35:43.700515 19975 net.cpp:128] Creating Layer conv1/bn
I0925 21:35:43.700525 19975 net.cpp:558] conv1/bn <- conv1
I0925 21:35:43.700534 19975 net.cpp:509] conv1/bn -> conv1 (in-place)
I0925 21:35:43.700764 19975 net.cpp:172] Setting up conv1/bn
I0925 21:35:43.700814 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.700819 19975 net.cpp:194] Memory required for data: 18350592
I0925 21:35:43.700831 19975 layer_factory.hpp:77] Creating layer conv1/scale
I0925 21:35:43.700841 19975 net.cpp:128] Creating Layer conv1/scale
I0925 21:35:43.700845 19975 net.cpp:558] conv1/scale <- conv1
I0925 21:35:43.700851 19975 net.cpp:509] conv1/scale -> conv1 (in-place)
I0925 21:35:43.700898 19975 layer_factory.hpp:77] Creating layer conv1/scale
I0925 21:35:43.701023 19975 net.cpp:172] Setting up conv1/scale
I0925 21:35:43.701036 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.701040 19975 net.cpp:194] Memory required for data: 26739200
I0925 21:35:43.701048 19975 layer_factory.hpp:77] Creating layer conv1/ReLU
I0925 21:35:43.701056 19975 net.cpp:128] Creating Layer conv1/ReLU
I0925 21:35:43.701061 19975 net.cpp:558] conv1/ReLU <- conv1
I0925 21:35:43.701067 19975 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I0925 21:35:43.701290 19975 net.cpp:172] Setting up conv1/ReLU
I0925 21:35:43.701365 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.701386 19975 net.cpp:194] Memory required for data: 35127808
I0925 21:35:43.701406 19975 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I0925 21:35:43.701419 19975 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I0925 21:35:43.701423 19975 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I0925 21:35:43.701431 19975 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I0925 21:35:43.701439 19975 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I0925 21:35:43.701488 19975 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I0925 21:35:43.701498 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.701504 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.701508 19975 net.cpp:194] Memory required for data: 51905024
I0925 21:35:43.701512 19975 layer_factory.hpp:77] Creating layer conv2_1_0
I0925 21:35:43.701525 19975 net.cpp:128] Creating Layer conv2_1_0
I0925 21:35:43.701529 19975 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I0925 21:35:43.701536 19975 net.cpp:522] conv2_1_0 -> conv2_1_0
I0925 21:35:43.704063 19975 net.cpp:172] Setting up conv2_1_0
I0925 21:35:43.704092 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.704097 19975 net.cpp:194] Memory required for data: 60293632
I0925 21:35:43.704110 19975 layer_factory.hpp:77] Creating layer conv2_1_bn0
I0925 21:35:43.704120 19975 net.cpp:128] Creating Layer conv2_1_bn0
I0925 21:35:43.704125 19975 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I0925 21:35:43.704133 19975 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I0925 21:35:43.704347 19975 net.cpp:172] Setting up conv2_1_bn0
I0925 21:35:43.704358 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.704363 19975 net.cpp:194] Memory required for data: 68682240
I0925 21:35:43.704373 19975 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0925 21:35:43.704381 19975 net.cpp:128] Creating Layer conv2_1_scale0
I0925 21:35:43.704386 19975 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I0925 21:35:43.704392 19975 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I0925 21:35:43.704428 19975 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0925 21:35:43.704548 19975 net.cpp:172] Setting up conv2_1_scale0
I0925 21:35:43.704558 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.704563 19975 net.cpp:194] Memory required for data: 77070848
I0925 21:35:43.704571 19975 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I0925 21:35:43.704577 19975 net.cpp:128] Creating Layer conv2_1_ReLU0
I0925 21:35:43.704581 19975 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I0925 21:35:43.704587 19975 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I0925 21:35:43.704794 19975 net.cpp:172] Setting up conv2_1_ReLU0
I0925 21:35:43.704835 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.704844 19975 net.cpp:194] Memory required for data: 85459456
I0925 21:35:43.704864 19975 layer_factory.hpp:77] Creating layer conv2_1_1
I0925 21:35:43.704875 19975 net.cpp:128] Creating Layer conv2_1_1
I0925 21:35:43.704880 19975 net.cpp:558] conv2_1_1 <- conv2_1_0
I0925 21:35:43.704887 19975 net.cpp:522] conv2_1_1 -> conv2_1_1
I0925 21:35:43.706009 19975 net.cpp:172] Setting up conv2_1_1
I0925 21:35:43.706033 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.706037 19975 net.cpp:194] Memory required for data: 93848064
I0925 21:35:43.706048 19975 layer_factory.hpp:77] Creating layer conv2_1bn1
I0925 21:35:43.706056 19975 net.cpp:128] Creating Layer conv2_1bn1
I0925 21:35:43.706061 19975 net.cpp:558] conv2_1bn1 <- conv2_1_1
I0925 21:35:43.706068 19975 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I0925 21:35:43.706280 19975 net.cpp:172] Setting up conv2_1bn1
I0925 21:35:43.706291 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.706296 19975 net.cpp:194] Memory required for data: 102236672
I0925 21:35:43.706308 19975 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0925 21:35:43.706315 19975 net.cpp:128] Creating Layer conv2_1_scale1
I0925 21:35:43.706320 19975 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I0925 21:35:43.706326 19975 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I0925 21:35:43.706362 19975 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0925 21:35:43.706483 19975 net.cpp:172] Setting up conv2_1_scale1
I0925 21:35:43.706495 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.706498 19975 net.cpp:194] Memory required for data: 110625280
I0925 21:35:43.706506 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I0925 21:35:43.706514 19975 net.cpp:128] Creating Layer conv2_Eltwise_1
I0925 21:35:43.706518 19975 net.cpp:558] conv2_Eltwise_1 <- conv1_conv1/ReLU_0_split_1
I0925 21:35:43.706523 19975 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I0925 21:35:43.706532 19975 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I0925 21:35:43.706559 19975 net.cpp:172] Setting up conv2_Eltwise_1
I0925 21:35:43.706567 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.706570 19975 net.cpp:194] Memory required for data: 119013888
I0925 21:35:43.706574 19975 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I0925 21:35:43.706580 19975 net.cpp:128] Creating Layer conv2_1ReLU_1
I0925 21:35:43.706585 19975 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I0925 21:35:43.706590 19975 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I0925 21:35:43.706998 19975 net.cpp:172] Setting up conv2_1ReLU_1
I0925 21:35:43.707046 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.707062 19975 net.cpp:194] Memory required for data: 127402496
I0925 21:35:43.707082 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0925 21:35:43.707100 19975 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0925 21:35:43.707115 19975 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I0925 21:35:43.707139 19975 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0925 21:35:43.707154 19975 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0925 21:35:43.707203 19975 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0925 21:35:43.707212 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.707218 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.707222 19975 net.cpp:194] Memory required for data: 144179712
I0925 21:35:43.707226 19975 layer_factory.hpp:77] Creating layer conv2_2_0
I0925 21:35:43.707238 19975 net.cpp:128] Creating Layer conv2_2_0
I0925 21:35:43.707243 19975 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0925 21:35:43.707250 19975 net.cpp:522] conv2_2_0 -> conv2_2_0
I0925 21:35:43.708379 19975 net.cpp:172] Setting up conv2_2_0
I0925 21:35:43.708403 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.708408 19975 net.cpp:194] Memory required for data: 152568320
I0925 21:35:43.708417 19975 layer_factory.hpp:77] Creating layer conv2_2_bn0
I0925 21:35:43.708446 19975 net.cpp:128] Creating Layer conv2_2_bn0
I0925 21:35:43.708451 19975 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I0925 21:35:43.708457 19975 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I0925 21:35:43.708670 19975 net.cpp:172] Setting up conv2_2_bn0
I0925 21:35:43.708681 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.708685 19975 net.cpp:194] Memory required for data: 160956928
I0925 21:35:43.708695 19975 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0925 21:35:43.708703 19975 net.cpp:128] Creating Layer conv2_2_scale0
I0925 21:35:43.708706 19975 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I0925 21:35:43.708714 19975 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I0925 21:35:43.708750 19975 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0925 21:35:43.708866 19975 net.cpp:172] Setting up conv2_2_scale0
I0925 21:35:43.708878 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.708881 19975 net.cpp:194] Memory required for data: 169345536
I0925 21:35:43.708889 19975 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I0925 21:35:43.708895 19975 net.cpp:128] Creating Layer conv2_2_ReLU0
I0925 21:35:43.708899 19975 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I0925 21:35:43.708905 19975 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I0925 21:35:43.709115 19975 net.cpp:172] Setting up conv2_2_ReLU0
I0925 21:35:43.709125 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.709130 19975 net.cpp:194] Memory required for data: 177734144
I0925 21:35:43.709133 19975 layer_factory.hpp:77] Creating layer conv2_2_1
I0925 21:35:43.709144 19975 net.cpp:128] Creating Layer conv2_2_1
I0925 21:35:43.709148 19975 net.cpp:558] conv2_2_1 <- conv2_2_0
I0925 21:35:43.709156 19975 net.cpp:522] conv2_2_1 -> conv2_2_1
I0925 21:35:43.710278 19975 net.cpp:172] Setting up conv2_2_1
I0925 21:35:43.710301 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.710305 19975 net.cpp:194] Memory required for data: 186122752
I0925 21:35:43.710315 19975 layer_factory.hpp:77] Creating layer conv2_2bn1
I0925 21:35:43.710325 19975 net.cpp:128] Creating Layer conv2_2bn1
I0925 21:35:43.710330 19975 net.cpp:558] conv2_2bn1 <- conv2_2_1
I0925 21:35:43.710336 19975 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I0925 21:35:43.710553 19975 net.cpp:172] Setting up conv2_2bn1
I0925 21:35:43.710563 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.710567 19975 net.cpp:194] Memory required for data: 194511360
I0925 21:35:43.710580 19975 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0925 21:35:43.710589 19975 net.cpp:128] Creating Layer conv2_2_scale1
I0925 21:35:43.710594 19975 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I0925 21:35:43.710600 19975 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I0925 21:35:43.710636 19975 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0925 21:35:43.710758 19975 net.cpp:172] Setting up conv2_2_scale1
I0925 21:35:43.710772 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.710775 19975 net.cpp:194] Memory required for data: 202899968
I0925 21:35:43.710783 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I0925 21:35:43.710790 19975 net.cpp:128] Creating Layer conv2_Eltwise_2
I0925 21:35:43.710794 19975 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0925 21:35:43.710799 19975 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I0925 21:35:43.710805 19975 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I0925 21:35:43.710851 19975 net.cpp:172] Setting up conv2_Eltwise_2
I0925 21:35:43.710860 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.710865 19975 net.cpp:194] Memory required for data: 211288576
I0925 21:35:43.710868 19975 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I0925 21:35:43.710875 19975 net.cpp:128] Creating Layer conv2_2ReLU_1
I0925 21:35:43.710880 19975 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I0925 21:35:43.710886 19975 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I0925 21:35:43.711122 19975 net.cpp:172] Setting up conv2_2ReLU_1
I0925 21:35:43.711136 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.711141 19975 net.cpp:194] Memory required for data: 219677184
I0925 21:35:43.711146 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0925 21:35:43.711208 19975 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0925 21:35:43.711230 19975 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I0925 21:35:43.711241 19975 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0925 21:35:43.711256 19975 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0925 21:35:43.711365 19975 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0925 21:35:43.711383 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.711395 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.711405 19975 net.cpp:194] Memory required for data: 236454400
I0925 21:35:43.711411 19975 layer_factory.hpp:77] Creating layer conv2_3_0
I0925 21:35:43.711428 19975 net.cpp:128] Creating Layer conv2_3_0
I0925 21:35:43.711437 19975 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0925 21:35:43.711448 19975 net.cpp:522] conv2_3_0 -> conv2_3_0
I0925 21:35:43.713150 19975 net.cpp:172] Setting up conv2_3_0
I0925 21:35:43.713184 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.713191 19975 net.cpp:194] Memory required for data: 244843008
I0925 21:35:43.713207 19975 layer_factory.hpp:77] Creating layer conv2_3_bn0
I0925 21:35:43.713222 19975 net.cpp:128] Creating Layer conv2_3_bn0
I0925 21:35:43.713228 19975 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I0925 21:35:43.713238 19975 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I0925 21:35:43.713572 19975 net.cpp:172] Setting up conv2_3_bn0
I0925 21:35:43.713587 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.713596 19975 net.cpp:194] Memory required for data: 253231616
I0925 21:35:43.713613 19975 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0925 21:35:43.713625 19975 net.cpp:128] Creating Layer conv2_3_scale0
I0925 21:35:43.713634 19975 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I0925 21:35:43.713644 19975 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I0925 21:35:43.713701 19975 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0925 21:35:43.713886 19975 net.cpp:172] Setting up conv2_3_scale0
I0925 21:35:43.713901 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.713908 19975 net.cpp:194] Memory required for data: 261620224
I0925 21:35:43.713922 19975 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I0925 21:35:43.713933 19975 net.cpp:128] Creating Layer conv2_3_ReLU0
I0925 21:35:43.713941 19975 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I0925 21:35:43.713950 19975 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I0925 21:35:43.714512 19975 net.cpp:172] Setting up conv2_3_ReLU0
I0925 21:35:43.714542 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.714550 19975 net.cpp:194] Memory required for data: 270008832
I0925 21:35:43.714558 19975 layer_factory.hpp:77] Creating layer conv2_3_1
I0925 21:35:43.714578 19975 net.cpp:128] Creating Layer conv2_3_1
I0925 21:35:43.714586 19975 net.cpp:558] conv2_3_1 <- conv2_3_0
I0925 21:35:43.714598 19975 net.cpp:522] conv2_3_1 -> conv2_3_1
I0925 21:35:43.716331 19975 net.cpp:172] Setting up conv2_3_1
I0925 21:35:43.716367 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.716373 19975 net.cpp:194] Memory required for data: 278397440
I0925 21:35:43.716392 19975 layer_factory.hpp:77] Creating layer conv2_3bn1
I0925 21:35:43.716404 19975 net.cpp:128] Creating Layer conv2_3bn1
I0925 21:35:43.716414 19975 net.cpp:558] conv2_3bn1 <- conv2_3_1
I0925 21:35:43.716424 19975 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I0925 21:35:43.716770 19975 net.cpp:172] Setting up conv2_3bn1
I0925 21:35:43.716785 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.716816 19975 net.cpp:194] Memory required for data: 286786048
I0925 21:35:43.716833 19975 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0925 21:35:43.716850 19975 net.cpp:128] Creating Layer conv2_3_scale1
I0925 21:35:43.716857 19975 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I0925 21:35:43.716866 19975 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I0925 21:35:43.716926 19975 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0925 21:35:43.717120 19975 net.cpp:172] Setting up conv2_3_scale1
I0925 21:35:43.717134 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.717144 19975 net.cpp:194] Memory required for data: 295174656
I0925 21:35:43.717155 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I0925 21:35:43.717169 19975 net.cpp:128] Creating Layer conv2_Eltwise_3
I0925 21:35:43.717175 19975 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0925 21:35:43.717183 19975 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I0925 21:35:43.717192 19975 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I0925 21:35:43.717232 19975 net.cpp:172] Setting up conv2_Eltwise_3
I0925 21:35:43.717243 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.717249 19975 net.cpp:194] Memory required for data: 303563264
I0925 21:35:43.717255 19975 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I0925 21:35:43.717265 19975 net.cpp:128] Creating Layer conv2_3ReLU_1
I0925 21:35:43.717274 19975 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I0925 21:35:43.717283 19975 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I0925 21:35:43.717605 19975 net.cpp:172] Setting up conv2_3ReLU_1
I0925 21:35:43.717623 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.717633 19975 net.cpp:194] Memory required for data: 311951872
I0925 21:35:43.717639 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0925 21:35:43.717649 19975 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0925 21:35:43.717658 19975 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I0925 21:35:43.717669 19975 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0925 21:35:43.717680 19975 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0925 21:35:43.717746 19975 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0925 21:35:43.717767 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.717777 19975 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0925 21:35:43.717782 19975 net.cpp:194] Memory required for data: 328729088
I0925 21:35:43.717788 19975 layer_factory.hpp:77] Creating layer conv3_1_0
I0925 21:35:43.717803 19975 net.cpp:128] Creating Layer conv3_1_0
I0925 21:35:43.717810 19975 net.cpp:558] conv3_1_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0925 21:35:43.717820 19975 net.cpp:522] conv3_1_0 -> conv3_1_0
I0925 21:35:43.720877 19975 net.cpp:172] Setting up conv3_1_0
I0925 21:35:43.720904 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.720909 19975 net.cpp:194] Memory required for data: 332923392
I0925 21:35:43.720922 19975 layer_factory.hpp:77] Creating layer conv3_1_bn0
I0925 21:35:43.720932 19975 net.cpp:128] Creating Layer conv3_1_bn0
I0925 21:35:43.720939 19975 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I0925 21:35:43.720954 19975 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I0925 21:35:43.721186 19975 net.cpp:172] Setting up conv3_1_bn0
I0925 21:35:43.721197 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.721202 19975 net.cpp:194] Memory required for data: 337117696
I0925 21:35:43.721212 19975 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0925 21:35:43.721218 19975 net.cpp:128] Creating Layer conv3_1_scale0
I0925 21:35:43.721223 19975 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I0925 21:35:43.721230 19975 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I0925 21:35:43.721267 19975 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0925 21:35:43.721417 19975 net.cpp:172] Setting up conv3_1_scale0
I0925 21:35:43.721428 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.721433 19975 net.cpp:194] Memory required for data: 341312000
I0925 21:35:43.721441 19975 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I0925 21:35:43.721448 19975 net.cpp:128] Creating Layer conv3_1_ReLU0
I0925 21:35:43.721453 19975 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I0925 21:35:43.721459 19975 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I0925 21:35:43.721683 19975 net.cpp:172] Setting up conv3_1_ReLU0
I0925 21:35:43.721698 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.721701 19975 net.cpp:194] Memory required for data: 345506304
I0925 21:35:43.721706 19975 layer_factory.hpp:77] Creating layer conv3_1_1
I0925 21:35:43.721717 19975 net.cpp:128] Creating Layer conv3_1_1
I0925 21:35:43.721721 19975 net.cpp:558] conv3_1_1 <- conv3_1_0
I0925 21:35:43.721729 19975 net.cpp:522] conv3_1_1 -> conv3_1_1
I0925 21:35:43.723040 19975 net.cpp:172] Setting up conv3_1_1
I0925 21:35:43.723063 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.723068 19975 net.cpp:194] Memory required for data: 349700608
I0925 21:35:43.723078 19975 layer_factory.hpp:77] Creating layer conv3_1bn1
I0925 21:35:43.723088 19975 net.cpp:128] Creating Layer conv3_1bn1
I0925 21:35:43.723093 19975 net.cpp:558] conv3_1bn1 <- conv3_1_1
I0925 21:35:43.723098 19975 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I0925 21:35:43.723325 19975 net.cpp:172] Setting up conv3_1bn1
I0925 21:35:43.723335 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.723340 19975 net.cpp:194] Memory required for data: 353894912
I0925 21:35:43.723350 19975 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0925 21:35:43.723356 19975 net.cpp:128] Creating Layer conv3_1_scale1
I0925 21:35:43.723361 19975 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I0925 21:35:43.723367 19975 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I0925 21:35:43.723405 19975 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0925 21:35:43.723532 19975 net.cpp:172] Setting up conv3_1_scale1
I0925 21:35:43.723544 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.723549 19975 net.cpp:194] Memory required for data: 358089216
I0925 21:35:43.723556 19975 layer_factory.hpp:77] Creating layer conv3_1_down
I0925 21:35:43.723567 19975 net.cpp:128] Creating Layer conv3_1_down
I0925 21:35:43.723572 19975 net.cpp:558] conv3_1_down <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0925 21:35:43.723578 19975 net.cpp:522] conv3_1_down -> conv3_1_down
I0925 21:35:43.724738 19975 net.cpp:172] Setting up conv3_1_down
I0925 21:35:43.724762 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.724766 19975 net.cpp:194] Memory required for data: 362283520
I0925 21:35:43.724782 19975 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I0925 21:35:43.724792 19975 net.cpp:128] Creating Layer conv3_1_bn_down
I0925 21:35:43.724797 19975 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I0925 21:35:43.724803 19975 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I0925 21:35:43.725033 19975 net.cpp:172] Setting up conv3_1_bn_down
I0925 21:35:43.725042 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.725047 19975 net.cpp:194] Memory required for data: 366477824
I0925 21:35:43.725057 19975 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0925 21:35:43.725065 19975 net.cpp:128] Creating Layer conv3_1_scale_down
I0925 21:35:43.725069 19975 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I0925 21:35:43.725076 19975 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I0925 21:35:43.725114 19975 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0925 21:35:43.725244 19975 net.cpp:172] Setting up conv3_1_scale_down
I0925 21:35:43.725251 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.725255 19975 net.cpp:194] Memory required for data: 370672128
I0925 21:35:43.725262 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I0925 21:35:43.725286 19975 net.cpp:128] Creating Layer conv3_Eltwise_1
I0925 21:35:43.725291 19975 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I0925 21:35:43.725296 19975 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I0925 21:35:43.725302 19975 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I0925 21:35:43.725324 19975 net.cpp:172] Setting up conv3_Eltwise_1
I0925 21:35:43.725332 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.725337 19975 net.cpp:194] Memory required for data: 374866432
I0925 21:35:43.725340 19975 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I0925 21:35:43.725347 19975 net.cpp:128] Creating Layer conv3_1ReLU_1
I0925 21:35:43.725352 19975 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I0925 21:35:43.725358 19975 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I0925 21:35:43.725577 19975 net.cpp:172] Setting up conv3_1ReLU_1
I0925 21:35:43.725587 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.725591 19975 net.cpp:194] Memory required for data: 379060736
I0925 21:35:43.725596 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0925 21:35:43.725603 19975 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0925 21:35:43.725607 19975 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I0925 21:35:43.725615 19975 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0925 21:35:43.725622 19975 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0925 21:35:43.725667 19975 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0925 21:35:43.725675 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.725680 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.725684 19975 net.cpp:194] Memory required for data: 387449344
I0925 21:35:43.725688 19975 layer_factory.hpp:77] Creating layer conv3_2_0
I0925 21:35:43.725699 19975 net.cpp:128] Creating Layer conv3_2_0
I0925 21:35:43.725704 19975 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0925 21:35:43.725711 19975 net.cpp:522] conv3_2_0 -> conv3_2_0
I0925 21:35:43.727020 19975 net.cpp:172] Setting up conv3_2_0
I0925 21:35:43.727042 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.727047 19975 net.cpp:194] Memory required for data: 391643648
I0925 21:35:43.727057 19975 layer_factory.hpp:77] Creating layer conv3_2_bn0
I0925 21:35:43.727066 19975 net.cpp:128] Creating Layer conv3_2_bn0
I0925 21:35:43.727072 19975 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I0925 21:35:43.727078 19975 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I0925 21:35:43.727308 19975 net.cpp:172] Setting up conv3_2_bn0
I0925 21:35:43.727314 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.727319 19975 net.cpp:194] Memory required for data: 395837952
I0925 21:35:43.727329 19975 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0925 21:35:43.727335 19975 net.cpp:128] Creating Layer conv3_2_scale0
I0925 21:35:43.727339 19975 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I0925 21:35:43.727345 19975 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I0925 21:35:43.727383 19975 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0925 21:35:43.727515 19975 net.cpp:172] Setting up conv3_2_scale0
I0925 21:35:43.727526 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.727530 19975 net.cpp:194] Memory required for data: 400032256
I0925 21:35:43.727537 19975 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I0925 21:35:43.727545 19975 net.cpp:128] Creating Layer conv3_2_ReLU0
I0925 21:35:43.727548 19975 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I0925 21:35:43.727555 19975 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I0925 21:35:43.727963 19975 net.cpp:172] Setting up conv3_2_ReLU0
I0925 21:35:43.727985 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.727990 19975 net.cpp:194] Memory required for data: 404226560
I0925 21:35:43.727995 19975 layer_factory.hpp:77] Creating layer conv3_2_1
I0925 21:35:43.728026 19975 net.cpp:128] Creating Layer conv3_2_1
I0925 21:35:43.728034 19975 net.cpp:558] conv3_2_1 <- conv3_2_0
I0925 21:35:43.728044 19975 net.cpp:522] conv3_2_1 -> conv3_2_1
I0925 21:35:43.729353 19975 net.cpp:172] Setting up conv3_2_1
I0925 21:35:43.729380 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.729384 19975 net.cpp:194] Memory required for data: 408420864
I0925 21:35:43.729398 19975 layer_factory.hpp:77] Creating layer conv3_2bn1
I0925 21:35:43.729411 19975 net.cpp:128] Creating Layer conv3_2bn1
I0925 21:35:43.729419 19975 net.cpp:558] conv3_2bn1 <- conv3_2_1
I0925 21:35:43.729427 19975 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I0925 21:35:43.729658 19975 net.cpp:172] Setting up conv3_2bn1
I0925 21:35:43.729668 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.729672 19975 net.cpp:194] Memory required for data: 412615168
I0925 21:35:43.729682 19975 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0925 21:35:43.729692 19975 net.cpp:128] Creating Layer conv3_2_scale1
I0925 21:35:43.729696 19975 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I0925 21:35:43.729702 19975 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I0925 21:35:43.729741 19975 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0925 21:35:43.729876 19975 net.cpp:172] Setting up conv3_2_scale1
I0925 21:35:43.729887 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.729890 19975 net.cpp:194] Memory required for data: 416809472
I0925 21:35:43.729898 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I0925 21:35:43.729907 19975 net.cpp:128] Creating Layer conv3_Eltwise_2
I0925 21:35:43.729910 19975 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0925 21:35:43.729917 19975 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I0925 21:35:43.729923 19975 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I0925 21:35:43.729943 19975 net.cpp:172] Setting up conv3_Eltwise_2
I0925 21:35:43.729952 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.729956 19975 net.cpp:194] Memory required for data: 421003776
I0925 21:35:43.729961 19975 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I0925 21:35:43.729967 19975 net.cpp:128] Creating Layer conv3_2ReLU_1
I0925 21:35:43.729972 19975 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I0925 21:35:43.729977 19975 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I0925 21:35:43.730198 19975 net.cpp:172] Setting up conv3_2ReLU_1
I0925 21:35:43.730214 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.730221 19975 net.cpp:194] Memory required for data: 425198080
I0925 21:35:43.730224 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0925 21:35:43.730232 19975 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0925 21:35:43.730237 19975 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I0925 21:35:43.730243 19975 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0925 21:35:43.730252 19975 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0925 21:35:43.730296 19975 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0925 21:35:43.730304 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.730309 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.730314 19975 net.cpp:194] Memory required for data: 433586688
I0925 21:35:43.730317 19975 layer_factory.hpp:77] Creating layer conv3_3_0
I0925 21:35:43.730329 19975 net.cpp:128] Creating Layer conv3_3_0
I0925 21:35:43.730332 19975 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0925 21:35:43.730340 19975 net.cpp:522] conv3_3_0 -> conv3_3_0
I0925 21:35:43.731655 19975 net.cpp:172] Setting up conv3_3_0
I0925 21:35:43.731683 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.731688 19975 net.cpp:194] Memory required for data: 437780992
I0925 21:35:43.731698 19975 layer_factory.hpp:77] Creating layer conv3_3_bn0
I0925 21:35:43.731727 19975 net.cpp:128] Creating Layer conv3_3_bn0
I0925 21:35:43.731734 19975 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I0925 21:35:43.731745 19975 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I0925 21:35:43.731974 19975 net.cpp:172] Setting up conv3_3_bn0
I0925 21:35:43.731986 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.731990 19975 net.cpp:194] Memory required for data: 441975296
I0925 21:35:43.732000 19975 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0925 21:35:43.732007 19975 net.cpp:128] Creating Layer conv3_3_scale0
I0925 21:35:43.732012 19975 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I0925 21:35:43.732017 19975 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I0925 21:35:43.732056 19975 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0925 21:35:43.732189 19975 net.cpp:172] Setting up conv3_3_scale0
I0925 21:35:43.732199 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.732204 19975 net.cpp:194] Memory required for data: 446169600
I0925 21:35:43.732213 19975 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I0925 21:35:43.732218 19975 net.cpp:128] Creating Layer conv3_3_ReLU0
I0925 21:35:43.732223 19975 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I0925 21:35:43.732228 19975 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I0925 21:35:43.732450 19975 net.cpp:172] Setting up conv3_3_ReLU0
I0925 21:35:43.732463 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.732467 19975 net.cpp:194] Memory required for data: 450363904
I0925 21:35:43.732472 19975 layer_factory.hpp:77] Creating layer conv3_3_1
I0925 21:35:43.732482 19975 net.cpp:128] Creating Layer conv3_3_1
I0925 21:35:43.732487 19975 net.cpp:558] conv3_3_1 <- conv3_3_0
I0925 21:35:43.732494 19975 net.cpp:522] conv3_3_1 -> conv3_3_1
I0925 21:35:43.733814 19975 net.cpp:172] Setting up conv3_3_1
I0925 21:35:43.733840 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.733845 19975 net.cpp:194] Memory required for data: 454558208
I0925 21:35:43.733855 19975 layer_factory.hpp:77] Creating layer conv3_3bn1
I0925 21:35:43.733867 19975 net.cpp:128] Creating Layer conv3_3bn1
I0925 21:35:43.733872 19975 net.cpp:558] conv3_3bn1 <- conv3_3_1
I0925 21:35:43.733883 19975 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I0925 21:35:43.734115 19975 net.cpp:172] Setting up conv3_3bn1
I0925 21:35:43.734127 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.734131 19975 net.cpp:194] Memory required for data: 458752512
I0925 21:35:43.734141 19975 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0925 21:35:43.734149 19975 net.cpp:128] Creating Layer conv3_3_scale1
I0925 21:35:43.734154 19975 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I0925 21:35:43.734160 19975 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I0925 21:35:43.734200 19975 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0925 21:35:43.734329 19975 net.cpp:172] Setting up conv3_3_scale1
I0925 21:35:43.734339 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.734344 19975 net.cpp:194] Memory required for data: 462946816
I0925 21:35:43.734351 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I0925 21:35:43.734359 19975 net.cpp:128] Creating Layer conv3_Eltwise_3
I0925 21:35:43.734364 19975 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0925 21:35:43.734369 19975 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I0925 21:35:43.734375 19975 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I0925 21:35:43.734395 19975 net.cpp:172] Setting up conv3_Eltwise_3
I0925 21:35:43.734402 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.734406 19975 net.cpp:194] Memory required for data: 467141120
I0925 21:35:43.734411 19975 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I0925 21:35:43.734416 19975 net.cpp:128] Creating Layer conv3_3ReLU_1
I0925 21:35:43.734421 19975 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I0925 21:35:43.734426 19975 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I0925 21:35:43.734853 19975 net.cpp:172] Setting up conv3_3ReLU_1
I0925 21:35:43.734890 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.734895 19975 net.cpp:194] Memory required for data: 471335424
I0925 21:35:43.734900 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0925 21:35:43.734908 19975 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0925 21:35:43.734913 19975 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I0925 21:35:43.734921 19975 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0925 21:35:43.734930 19975 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0925 21:35:43.734980 19975 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0925 21:35:43.734990 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.734997 19975 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0925 21:35:43.735000 19975 net.cpp:194] Memory required for data: 479724032
I0925 21:35:43.735004 19975 layer_factory.hpp:77] Creating layer conv4_1_0
I0925 21:35:43.735015 19975 net.cpp:128] Creating Layer conv4_1_0
I0925 21:35:43.735020 19975 net.cpp:558] conv4_1_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0925 21:35:43.735028 19975 net.cpp:522] conv4_1_0 -> conv4_1_0
I0925 21:35:43.738014 19975 net.cpp:172] Setting up conv4_1_0
I0925 21:35:43.738041 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.738046 19975 net.cpp:194] Memory required for data: 481821184
I0925 21:35:43.738061 19975 layer_factory.hpp:77] Creating layer conv4_1_bn0
I0925 21:35:43.738070 19975 net.cpp:128] Creating Layer conv4_1_bn0
I0925 21:35:43.738077 19975 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I0925 21:35:43.738085 19975 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I0925 21:35:43.738332 19975 net.cpp:172] Setting up conv4_1_bn0
I0925 21:35:43.738343 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.738346 19975 net.cpp:194] Memory required for data: 483918336
I0925 21:35:43.738356 19975 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0925 21:35:43.738363 19975 net.cpp:128] Creating Layer conv4_1_scale0
I0925 21:35:43.738370 19975 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I0925 21:35:43.738376 19975 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I0925 21:35:43.738415 19975 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0925 21:35:43.738554 19975 net.cpp:172] Setting up conv4_1_scale0
I0925 21:35:43.738564 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.738569 19975 net.cpp:194] Memory required for data: 486015488
I0925 21:35:43.738576 19975 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I0925 21:35:43.738584 19975 net.cpp:128] Creating Layer conv4_1_ReLU0
I0925 21:35:43.738587 19975 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I0925 21:35:43.738593 19975 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I0925 21:35:43.738832 19975 net.cpp:172] Setting up conv4_1_ReLU0
I0925 21:35:43.738849 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.738853 19975 net.cpp:194] Memory required for data: 488112640
I0925 21:35:43.738858 19975 layer_factory.hpp:77] Creating layer conv4_1_1
I0925 21:35:43.738870 19975 net.cpp:128] Creating Layer conv4_1_1
I0925 21:35:43.738875 19975 net.cpp:558] conv4_1_1 <- conv4_1_0
I0925 21:35:43.738883 19975 net.cpp:522] conv4_1_1 -> conv4_1_1
I0925 21:35:43.740806 19975 net.cpp:172] Setting up conv4_1_1
I0925 21:35:43.740833 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.740839 19975 net.cpp:194] Memory required for data: 490209792
I0925 21:35:43.740850 19975 layer_factory.hpp:77] Creating layer conv4_1bn1
I0925 21:35:43.740859 19975 net.cpp:128] Creating Layer conv4_1bn1
I0925 21:35:43.740869 19975 net.cpp:558] conv4_1bn1 <- conv4_1_1
I0925 21:35:43.740876 19975 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I0925 21:35:43.741129 19975 net.cpp:172] Setting up conv4_1bn1
I0925 21:35:43.741142 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.741145 19975 net.cpp:194] Memory required for data: 492306944
I0925 21:35:43.741175 19975 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0925 21:35:43.741185 19975 net.cpp:128] Creating Layer conv4_1_scale1
I0925 21:35:43.741190 19975 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I0925 21:35:43.741196 19975 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I0925 21:35:43.741237 19975 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0925 21:35:43.741379 19975 net.cpp:172] Setting up conv4_1_scale1
I0925 21:35:43.741390 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.741395 19975 net.cpp:194] Memory required for data: 494404096
I0925 21:35:43.741403 19975 layer_factory.hpp:77] Creating layer conv4_1_down
I0925 21:35:43.741415 19975 net.cpp:128] Creating Layer conv4_1_down
I0925 21:35:43.741422 19975 net.cpp:558] conv4_1_down <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0925 21:35:43.741430 19975 net.cpp:522] conv4_1_down -> conv4_1_down
I0925 21:35:43.742805 19975 net.cpp:172] Setting up conv4_1_down
I0925 21:35:43.742848 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.742852 19975 net.cpp:194] Memory required for data: 496501248
I0925 21:35:43.742864 19975 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I0925 21:35:43.742873 19975 net.cpp:128] Creating Layer conv4_1_bn_down
I0925 21:35:43.742882 19975 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I0925 21:35:43.742888 19975 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I0925 21:35:43.743139 19975 net.cpp:172] Setting up conv4_1_bn_down
I0925 21:35:43.743147 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.743152 19975 net.cpp:194] Memory required for data: 498598400
I0925 21:35:43.743162 19975 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0925 21:35:43.743171 19975 net.cpp:128] Creating Layer conv4_1_scale_down
I0925 21:35:43.743176 19975 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I0925 21:35:43.743181 19975 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I0925 21:35:43.743221 19975 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0925 21:35:43.743360 19975 net.cpp:172] Setting up conv4_1_scale_down
I0925 21:35:43.743369 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.743373 19975 net.cpp:194] Memory required for data: 500695552
I0925 21:35:43.743382 19975 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I0925 21:35:43.743389 19975 net.cpp:128] Creating Layer conv4_Eltwise_1
I0925 21:35:43.743393 19975 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I0925 21:35:43.743398 19975 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I0925 21:35:43.743404 19975 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I0925 21:35:43.743425 19975 net.cpp:172] Setting up conv4_Eltwise_1
I0925 21:35:43.743434 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.743438 19975 net.cpp:194] Memory required for data: 502792704
I0925 21:35:43.743443 19975 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I0925 21:35:43.743450 19975 net.cpp:128] Creating Layer conv4_1ReLU_1
I0925 21:35:43.743454 19975 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I0925 21:35:43.743460 19975 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I0925 21:35:43.743680 19975 net.cpp:172] Setting up conv4_1ReLU_1
I0925 21:35:43.743692 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.743697 19975 net.cpp:194] Memory required for data: 504889856
I0925 21:35:43.743701 19975 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0925 21:35:43.743708 19975 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0925 21:35:43.743713 19975 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I0925 21:35:43.743719 19975 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0925 21:35:43.743728 19975 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0925 21:35:43.743773 19975 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0925 21:35:43.743783 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.743808 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.743813 19975 net.cpp:194] Memory required for data: 509084160
I0925 21:35:43.743816 19975 layer_factory.hpp:77] Creating layer conv4_2_0
I0925 21:35:43.743827 19975 net.cpp:128] Creating Layer conv4_2_0
I0925 21:35:43.743832 19975 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0925 21:35:43.743839 19975 net.cpp:522] conv4_2_0 -> conv4_2_0
I0925 21:35:43.745586 19975 net.cpp:172] Setting up conv4_2_0
I0925 21:35:43.745613 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.745618 19975 net.cpp:194] Memory required for data: 511181312
I0925 21:35:43.745632 19975 layer_factory.hpp:77] Creating layer conv4_2_bn0
I0925 21:35:43.745647 19975 net.cpp:128] Creating Layer conv4_2_bn0
I0925 21:35:43.745651 19975 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I0925 21:35:43.745661 19975 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I0925 21:35:43.745909 19975 net.cpp:172] Setting up conv4_2_bn0
I0925 21:35:43.745919 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.745923 19975 net.cpp:194] Memory required for data: 513278464
I0925 21:35:43.745934 19975 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0925 21:35:43.745941 19975 net.cpp:128] Creating Layer conv4_2_scale0
I0925 21:35:43.745946 19975 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I0925 21:35:43.745952 19975 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I0925 21:35:43.745992 19975 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0925 21:35:43.746135 19975 net.cpp:172] Setting up conv4_2_scale0
I0925 21:35:43.746146 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.746150 19975 net.cpp:194] Memory required for data: 515375616
I0925 21:35:43.746158 19975 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I0925 21:35:43.746165 19975 net.cpp:128] Creating Layer conv4_2_ReLU0
I0925 21:35:43.746170 19975 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I0925 21:35:43.746176 19975 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I0925 21:35:43.746592 19975 net.cpp:172] Setting up conv4_2_ReLU0
I0925 21:35:43.746614 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.746619 19975 net.cpp:194] Memory required for data: 517472768
I0925 21:35:43.746624 19975 layer_factory.hpp:77] Creating layer conv4_2_1
I0925 21:35:43.746637 19975 net.cpp:128] Creating Layer conv4_2_1
I0925 21:35:43.746642 19975 net.cpp:558] conv4_2_1 <- conv4_2_0
I0925 21:35:43.746650 19975 net.cpp:522] conv4_2_1 -> conv4_2_1
I0925 21:35:43.748590 19975 net.cpp:172] Setting up conv4_2_1
I0925 21:35:43.748617 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.748621 19975 net.cpp:194] Memory required for data: 519569920
I0925 21:35:43.748632 19975 layer_factory.hpp:77] Creating layer conv4_2bn1
I0925 21:35:43.748641 19975 net.cpp:128] Creating Layer conv4_2bn1
I0925 21:35:43.748646 19975 net.cpp:558] conv4_2bn1 <- conv4_2_1
I0925 21:35:43.748657 19975 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I0925 21:35:43.748919 19975 net.cpp:172] Setting up conv4_2bn1
I0925 21:35:43.748930 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.748935 19975 net.cpp:194] Memory required for data: 521667072
I0925 21:35:43.748952 19975 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0925 21:35:43.748960 19975 net.cpp:128] Creating Layer conv4_2_scale1
I0925 21:35:43.748965 19975 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I0925 21:35:43.748970 19975 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I0925 21:35:43.749011 19975 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0925 21:35:43.749150 19975 net.cpp:172] Setting up conv4_2_scale1
I0925 21:35:43.749156 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.749161 19975 net.cpp:194] Memory required for data: 523764224
I0925 21:35:43.749168 19975 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I0925 21:35:43.749176 19975 net.cpp:128] Creating Layer conv4_Eltwise_2
I0925 21:35:43.749181 19975 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0925 21:35:43.749202 19975 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I0925 21:35:43.749208 19975 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I0925 21:35:43.749231 19975 net.cpp:172] Setting up conv4_Eltwise_2
I0925 21:35:43.749239 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.749243 19975 net.cpp:194] Memory required for data: 525861376
I0925 21:35:43.749248 19975 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I0925 21:35:43.749253 19975 net.cpp:128] Creating Layer conv4_2ReLU_1
I0925 21:35:43.749259 19975 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I0925 21:35:43.749265 19975 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I0925 21:35:43.749490 19975 net.cpp:172] Setting up conv4_2ReLU_1
I0925 21:35:43.749507 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.749512 19975 net.cpp:194] Memory required for data: 527958528
I0925 21:35:43.749516 19975 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0925 21:35:43.749524 19975 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0925 21:35:43.749528 19975 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I0925 21:35:43.749536 19975 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0925 21:35:43.749543 19975 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0925 21:35:43.749591 19975 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0925 21:35:43.749601 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.749608 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.749611 19975 net.cpp:194] Memory required for data: 532152832
I0925 21:35:43.749615 19975 layer_factory.hpp:77] Creating layer conv4_3_0
I0925 21:35:43.749626 19975 net.cpp:128] Creating Layer conv4_3_0
I0925 21:35:43.749632 19975 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0925 21:35:43.749639 19975 net.cpp:522] conv4_3_0 -> conv4_3_0
I0925 21:35:43.751427 19975 net.cpp:172] Setting up conv4_3_0
I0925 21:35:43.751451 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.751456 19975 net.cpp:194] Memory required for data: 534249984
I0925 21:35:43.751466 19975 layer_factory.hpp:77] Creating layer conv4_3_bn0
I0925 21:35:43.751476 19975 net.cpp:128] Creating Layer conv4_3_bn0
I0925 21:35:43.751480 19975 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I0925 21:35:43.751487 19975 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I0925 21:35:43.751740 19975 net.cpp:172] Setting up conv4_3_bn0
I0925 21:35:43.751752 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.751756 19975 net.cpp:194] Memory required for data: 536347136
I0925 21:35:43.751767 19975 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0925 21:35:43.751775 19975 net.cpp:128] Creating Layer conv4_3_scale0
I0925 21:35:43.751778 19975 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I0925 21:35:43.751785 19975 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I0925 21:35:43.751826 19975 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0925 21:35:43.751969 19975 net.cpp:172] Setting up conv4_3_scale0
I0925 21:35:43.751981 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.751984 19975 net.cpp:194] Memory required for data: 538444288
I0925 21:35:43.751993 19975 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I0925 21:35:43.752001 19975 net.cpp:128] Creating Layer conv4_3_ReLU0
I0925 21:35:43.752004 19975 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I0925 21:35:43.752010 19975 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I0925 21:35:43.752236 19975 net.cpp:172] Setting up conv4_3_ReLU0
I0925 21:35:43.752249 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.752254 19975 net.cpp:194] Memory required for data: 540541440
I0925 21:35:43.752259 19975 layer_factory.hpp:77] Creating layer conv4_3_1
I0925 21:35:43.752269 19975 net.cpp:128] Creating Layer conv4_3_1
I0925 21:35:43.752274 19975 net.cpp:558] conv4_3_1 <- conv4_3_0
I0925 21:35:43.752280 19975 net.cpp:522] conv4_3_1 -> conv4_3_1
I0925 21:35:43.754252 19975 net.cpp:172] Setting up conv4_3_1
I0925 21:35:43.754278 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.754283 19975 net.cpp:194] Memory required for data: 542638592
I0925 21:35:43.754293 19975 layer_factory.hpp:77] Creating layer conv4_3bn1
I0925 21:35:43.754302 19975 net.cpp:128] Creating Layer conv4_3bn1
I0925 21:35:43.754307 19975 net.cpp:558] conv4_3bn1 <- conv4_3_1
I0925 21:35:43.754318 19975 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I0925 21:35:43.754581 19975 net.cpp:172] Setting up conv4_3bn1
I0925 21:35:43.754591 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.754595 19975 net.cpp:194] Memory required for data: 544735744
I0925 21:35:43.754606 19975 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0925 21:35:43.754614 19975 net.cpp:128] Creating Layer conv4_3_scale1
I0925 21:35:43.754619 19975 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I0925 21:35:43.754624 19975 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I0925 21:35:43.754664 19975 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0925 21:35:43.754807 19975 net.cpp:172] Setting up conv4_3_scale1
I0925 21:35:43.754837 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.754840 19975 net.cpp:194] Memory required for data: 546832896
I0925 21:35:43.754848 19975 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I0925 21:35:43.754855 19975 net.cpp:128] Creating Layer conv4_Eltwise_3
I0925 21:35:43.754860 19975 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0925 21:35:43.754865 19975 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I0925 21:35:43.754873 19975 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I0925 21:35:43.754895 19975 net.cpp:172] Setting up conv4_Eltwise_3
I0925 21:35:43.754902 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.754906 19975 net.cpp:194] Memory required for data: 548930048
I0925 21:35:43.754910 19975 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I0925 21:35:43.754917 19975 net.cpp:128] Creating Layer conv4_3ReLU_1
I0925 21:35:43.754921 19975 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I0925 21:35:43.754927 19975 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I0925 21:35:43.755157 19975 net.cpp:172] Setting up conv4_3ReLU_1
I0925 21:35:43.755172 19975 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0925 21:35:43.755175 19975 net.cpp:194] Memory required for data: 551027200
I0925 21:35:43.755180 19975 layer_factory.hpp:77] Creating layer Pooling1
I0925 21:35:43.755188 19975 net.cpp:128] Creating Layer Pooling1
I0925 21:35:43.755193 19975 net.cpp:558] Pooling1 <- conv4_Eltwise_3
I0925 21:35:43.755200 19975 net.cpp:522] Pooling1 -> Pooling1
I0925 21:35:43.755681 19975 net.cpp:172] Setting up Pooling1
I0925 21:35:43.755704 19975 net.cpp:186] Top shape: 128 64 1 1 (8192)
I0925 21:35:43.755710 19975 net.cpp:194] Memory required for data: 551059968
I0925 21:35:43.755715 19975 layer_factory.hpp:77] Creating layer fc1
I0925 21:35:43.755726 19975 net.cpp:128] Creating Layer fc1
I0925 21:35:43.755734 19975 net.cpp:558] fc1 <- Pooling1
I0925 21:35:43.755743 19975 net.cpp:522] fc1 -> fc1
I0925 21:35:43.755897 19975 net.cpp:172] Setting up fc1
I0925 21:35:43.755909 19975 net.cpp:186] Top shape: 128 10 (1280)
I0925 21:35:43.755913 19975 net.cpp:194] Memory required for data: 551065088
I0925 21:35:43.755923 19975 layer_factory.hpp:77] Creating layer Softmax1
I0925 21:35:43.755930 19975 net.cpp:128] Creating Layer Softmax1
I0925 21:35:43.755934 19975 net.cpp:558] Softmax1 <- fc1
I0925 21:35:43.755939 19975 net.cpp:558] Softmax1 <- label
I0925 21:35:43.755946 19975 net.cpp:522] Softmax1 -> Softmax1
I0925 21:35:43.755956 19975 layer_factory.hpp:77] Creating layer Softmax1
I0925 21:35:43.756302 19975 net.cpp:172] Setting up Softmax1
I0925 21:35:43.756317 19975 net.cpp:186] Top shape: (1)
I0925 21:35:43.756321 19975 net.cpp:189]     with loss weight 1
I0925 21:35:43.756351 19975 net.cpp:194] Memory required for data: 551065092
I0925 21:35:43.756356 19975 net.cpp:301] Softmax1 needs backward computation.
I0925 21:35:43.756381 19975 net.cpp:301] fc1 needs backward computation.
I0925 21:35:43.756386 19975 net.cpp:301] Pooling1 needs backward computation.
I0925 21:35:43.756389 19975 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I0925 21:35:43.756394 19975 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I0925 21:35:43.756398 19975 net.cpp:301] conv4_3_scale1 needs backward computation.
I0925 21:35:43.756403 19975 net.cpp:301] conv4_3bn1 needs backward computation.
I0925 21:35:43.756407 19975 net.cpp:301] conv4_3_1 needs backward computation.
I0925 21:35:43.756412 19975 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I0925 21:35:43.756415 19975 net.cpp:301] conv4_3_scale0 needs backward computation.
I0925 21:35:43.756419 19975 net.cpp:301] conv4_3_bn0 needs backward computation.
I0925 21:35:43.756423 19975 net.cpp:301] conv4_3_0 needs backward computation.
I0925 21:35:43.756428 19975 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I0925 21:35:43.756433 19975 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I0925 21:35:43.756436 19975 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I0925 21:35:43.756441 19975 net.cpp:301] conv4_2_scale1 needs backward computation.
I0925 21:35:43.756445 19975 net.cpp:301] conv4_2bn1 needs backward computation.
I0925 21:35:43.756449 19975 net.cpp:301] conv4_2_1 needs backward computation.
I0925 21:35:43.756454 19975 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I0925 21:35:43.756458 19975 net.cpp:301] conv4_2_scale0 needs backward computation.
I0925 21:35:43.756462 19975 net.cpp:301] conv4_2_bn0 needs backward computation.
I0925 21:35:43.756466 19975 net.cpp:301] conv4_2_0 needs backward computation.
I0925 21:35:43.756470 19975 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I0925 21:35:43.756475 19975 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I0925 21:35:43.756479 19975 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I0925 21:35:43.756484 19975 net.cpp:301] conv4_1_scale_down needs backward computation.
I0925 21:35:43.756489 19975 net.cpp:301] conv4_1_bn_down needs backward computation.
I0925 21:35:43.756492 19975 net.cpp:301] conv4_1_down needs backward computation.
I0925 21:35:43.756497 19975 net.cpp:301] conv4_1_scale1 needs backward computation.
I0925 21:35:43.756501 19975 net.cpp:301] conv4_1bn1 needs backward computation.
I0925 21:35:43.756505 19975 net.cpp:301] conv4_1_1 needs backward computation.
I0925 21:35:43.756510 19975 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I0925 21:35:43.756515 19975 net.cpp:301] conv4_1_scale0 needs backward computation.
I0925 21:35:43.756518 19975 net.cpp:301] conv4_1_bn0 needs backward computation.
I0925 21:35:43.756522 19975 net.cpp:301] conv4_1_0 needs backward computation.
I0925 21:35:43.756527 19975 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I0925 21:35:43.756532 19975 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I0925 21:35:43.756536 19975 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I0925 21:35:43.756542 19975 net.cpp:301] conv3_3_scale1 needs backward computation.
I0925 21:35:43.756546 19975 net.cpp:301] conv3_3bn1 needs backward computation.
I0925 21:35:43.756551 19975 net.cpp:301] conv3_3_1 needs backward computation.
I0925 21:35:43.756556 19975 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I0925 21:35:43.756561 19975 net.cpp:301] conv3_3_scale0 needs backward computation.
I0925 21:35:43.756564 19975 net.cpp:301] conv3_3_bn0 needs backward computation.
I0925 21:35:43.756568 19975 net.cpp:301] conv3_3_0 needs backward computation.
I0925 21:35:43.756573 19975 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I0925 21:35:43.756578 19975 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I0925 21:35:43.756582 19975 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I0925 21:35:43.756588 19975 net.cpp:301] conv3_2_scale1 needs backward computation.
I0925 21:35:43.756592 19975 net.cpp:301] conv3_2bn1 needs backward computation.
I0925 21:35:43.756604 19975 net.cpp:301] conv3_2_1 needs backward computation.
I0925 21:35:43.756609 19975 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I0925 21:35:43.756613 19975 net.cpp:301] conv3_2_scale0 needs backward computation.
I0925 21:35:43.756618 19975 net.cpp:301] conv3_2_bn0 needs backward computation.
I0925 21:35:43.756623 19975 net.cpp:301] conv3_2_0 needs backward computation.
I0925 21:35:43.756628 19975 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I0925 21:35:43.756633 19975 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I0925 21:35:43.756636 19975 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I0925 21:35:43.756642 19975 net.cpp:301] conv3_1_scale_down needs backward computation.
I0925 21:35:43.756646 19975 net.cpp:301] conv3_1_bn_down needs backward computation.
I0925 21:35:43.756651 19975 net.cpp:301] conv3_1_down needs backward computation.
I0925 21:35:43.756655 19975 net.cpp:301] conv3_1_scale1 needs backward computation.
I0925 21:35:43.756660 19975 net.cpp:301] conv3_1bn1 needs backward computation.
I0925 21:35:43.756665 19975 net.cpp:301] conv3_1_1 needs backward computation.
I0925 21:35:43.756669 19975 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I0925 21:35:43.756673 19975 net.cpp:301] conv3_1_scale0 needs backward computation.
I0925 21:35:43.756677 19975 net.cpp:301] conv3_1_bn0 needs backward computation.
I0925 21:35:43.756681 19975 net.cpp:301] conv3_1_0 needs backward computation.
I0925 21:35:43.756686 19975 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I0925 21:35:43.756691 19975 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I0925 21:35:43.756696 19975 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I0925 21:35:43.756701 19975 net.cpp:301] conv2_3_scale1 needs backward computation.
I0925 21:35:43.756705 19975 net.cpp:301] conv2_3bn1 needs backward computation.
I0925 21:35:43.756711 19975 net.cpp:301] conv2_3_1 needs backward computation.
I0925 21:35:43.756714 19975 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I0925 21:35:43.756718 19975 net.cpp:301] conv2_3_scale0 needs backward computation.
I0925 21:35:43.756722 19975 net.cpp:301] conv2_3_bn0 needs backward computation.
I0925 21:35:43.756727 19975 net.cpp:301] conv2_3_0 needs backward computation.
I0925 21:35:43.756732 19975 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I0925 21:35:43.756736 19975 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I0925 21:35:43.756742 19975 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I0925 21:35:43.756747 19975 net.cpp:301] conv2_2_scale1 needs backward computation.
I0925 21:35:43.756750 19975 net.cpp:301] conv2_2bn1 needs backward computation.
I0925 21:35:43.756755 19975 net.cpp:301] conv2_2_1 needs backward computation.
I0925 21:35:43.756759 19975 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I0925 21:35:43.756764 19975 net.cpp:301] conv2_2_scale0 needs backward computation.
I0925 21:35:43.756768 19975 net.cpp:301] conv2_2_bn0 needs backward computation.
I0925 21:35:43.756772 19975 net.cpp:301] conv2_2_0 needs backward computation.
I0925 21:35:43.756778 19975 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I0925 21:35:43.756783 19975 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I0925 21:35:43.756786 19975 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I0925 21:35:43.756793 19975 net.cpp:301] conv2_1_scale1 needs backward computation.
I0925 21:35:43.756796 19975 net.cpp:301] conv2_1bn1 needs backward computation.
I0925 21:35:43.756801 19975 net.cpp:301] conv2_1_1 needs backward computation.
I0925 21:35:43.756805 19975 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I0925 21:35:43.756810 19975 net.cpp:301] conv2_1_scale0 needs backward computation.
I0925 21:35:43.756814 19975 net.cpp:301] conv2_1_bn0 needs backward computation.
I0925 21:35:43.756819 19975 net.cpp:301] conv2_1_0 needs backward computation.
I0925 21:35:43.756830 19975 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I0925 21:35:43.756835 19975 net.cpp:301] conv1/ReLU needs backward computation.
I0925 21:35:43.756839 19975 net.cpp:301] conv1/scale needs backward computation.
I0925 21:35:43.756844 19975 net.cpp:301] conv1/bn needs backward computation.
I0925 21:35:43.756848 19975 net.cpp:301] conv1 needs backward computation.
I0925 21:35:43.756853 19975 net.cpp:303] Data1 does not need backward computation.
I0925 21:35:43.756857 19975 net.cpp:348] This network produces output Softmax1
I0925 21:35:43.756908 19975 net.cpp:363] Network initialization done.
I0925 21:35:43.757994 19975 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./test_ResNet_20.prototxt
I0925 21:35:43.758013 19975 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0925 21:35:43.758020 19975 solver.cpp:277] Creating test net (#0) specified by test_net file: ./test_ResNet_20.prototxt
I0925 21:35:43.758781 19975 net.cpp:82] Initializing net from parameters: 
name: "ResNet-20"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: false
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/test_lmdb"
    batch_size: 10
    backend: LMDB
  }
  image_data_param {
    shuffle: false
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "conv2_1_1"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "conv4_Eltwise_3"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "Softmax1"
  type: "SoftmaxWithLoss"
  bottom: "fc1"
  bottom: "label"
  top: "Softmax1"
}
layer {
  name: "prob"
  type: "Accuracy"
  bottom: "fc1"
  bottom: "label"
  top: "prob"
}
I0925 21:35:43.759168 19975 layer_factory.hpp:77] Creating layer Data1
I0925 21:35:43.759258 19975 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/test_lmdb
I0925 21:35:43.759276 19975 net.cpp:128] Creating Layer Data1
I0925 21:35:43.759284 19975 net.cpp:522] Data1 -> data
I0925 21:35:43.759294 19975 net.cpp:522] Data1 -> label
I0925 21:35:43.759439 19975 data_layer.cpp:45] output data size: 10,3,32,32
I0925 21:35:43.760314 19975 net.cpp:172] Setting up Data1
I0925 21:35:43.760331 19975 net.cpp:186] Top shape: 10 3 32 32 (30720)
I0925 21:35:43.760337 19975 net.cpp:186] Top shape: 10 (10)
I0925 21:35:43.760341 19975 net.cpp:194] Memory required for data: 122920
I0925 21:35:43.760346 19975 layer_factory.hpp:77] Creating layer label_Data1_1_split
I0925 21:35:43.760354 19975 net.cpp:128] Creating Layer label_Data1_1_split
I0925 21:35:43.760360 19975 net.cpp:558] label_Data1_1_split <- label
I0925 21:35:43.760366 19975 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_0
I0925 21:35:43.760375 19975 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_1
I0925 21:35:43.760430 19975 net.cpp:172] Setting up label_Data1_1_split
I0925 21:35:43.760438 19975 net.cpp:186] Top shape: 10 (10)
I0925 21:35:43.760443 19975 net.cpp:186] Top shape: 10 (10)
I0925 21:35:43.760447 19975 net.cpp:194] Memory required for data: 123000
I0925 21:35:43.760452 19975 layer_factory.hpp:77] Creating layer conv1
I0925 21:35:43.760462 19975 net.cpp:128] Creating Layer conv1
I0925 21:35:43.760466 19975 net.cpp:558] conv1 <- data
I0925 21:35:43.760473 19975 net.cpp:522] conv1 -> conv1
I0925 21:35:43.761950 19975 net.cpp:172] Setting up conv1
I0925 21:35:43.761973 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.761978 19975 net.cpp:194] Memory required for data: 778360
I0925 21:35:43.762006 19975 layer_factory.hpp:77] Creating layer conv1/bn
I0925 21:35:43.762019 19975 net.cpp:128] Creating Layer conv1/bn
I0925 21:35:43.762025 19975 net.cpp:558] conv1/bn <- conv1
I0925 21:35:43.762032 19975 net.cpp:509] conv1/bn -> conv1 (in-place)
I0925 21:35:43.762392 19975 net.cpp:172] Setting up conv1/bn
I0925 21:35:43.762403 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.762408 19975 net.cpp:194] Memory required for data: 1433720
I0925 21:35:43.762420 19975 layer_factory.hpp:77] Creating layer conv1/scale
I0925 21:35:43.762431 19975 net.cpp:128] Creating Layer conv1/scale
I0925 21:35:43.762439 19975 net.cpp:558] conv1/scale <- conv1
I0925 21:35:43.762444 19975 net.cpp:509] conv1/scale -> conv1 (in-place)
I0925 21:35:43.762502 19975 layer_factory.hpp:77] Creating layer conv1/scale
I0925 21:35:43.762707 19975 net.cpp:172] Setting up conv1/scale
I0925 21:35:43.762717 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.762722 19975 net.cpp:194] Memory required for data: 2089080
I0925 21:35:43.762729 19975 layer_factory.hpp:77] Creating layer conv1/ReLU
I0925 21:35:43.762738 19975 net.cpp:128] Creating Layer conv1/ReLU
I0925 21:35:43.762747 19975 net.cpp:558] conv1/ReLU <- conv1
I0925 21:35:43.762753 19975 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I0925 21:35:43.763031 19975 net.cpp:172] Setting up conv1/ReLU
I0925 21:35:43.763047 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.763053 19975 net.cpp:194] Memory required for data: 2744440
I0925 21:35:43.763057 19975 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I0925 21:35:43.763067 19975 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I0925 21:35:43.763072 19975 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I0925 21:35:43.763078 19975 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I0925 21:35:43.763087 19975 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I0925 21:35:43.763147 19975 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I0925 21:35:43.763157 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.763164 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.763167 19975 net.cpp:194] Memory required for data: 4055160
I0925 21:35:43.763171 19975 layer_factory.hpp:77] Creating layer conv2_1_0
I0925 21:35:43.763181 19975 net.cpp:128] Creating Layer conv2_1_0
I0925 21:35:43.763185 19975 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I0925 21:35:43.763193 19975 net.cpp:522] conv2_1_0 -> conv2_1_0
I0925 21:35:43.764801 19975 net.cpp:172] Setting up conv2_1_0
I0925 21:35:43.764824 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.764829 19975 net.cpp:194] Memory required for data: 4710520
I0925 21:35:43.764842 19975 layer_factory.hpp:77] Creating layer conv2_1_bn0
I0925 21:35:43.764852 19975 net.cpp:128] Creating Layer conv2_1_bn0
I0925 21:35:43.764859 19975 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I0925 21:35:43.764866 19975 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I0925 21:35:43.765143 19975 net.cpp:172] Setting up conv2_1_bn0
I0925 21:35:43.765153 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.765157 19975 net.cpp:194] Memory required for data: 5365880
I0925 21:35:43.765167 19975 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0925 21:35:43.765177 19975 net.cpp:128] Creating Layer conv2_1_scale0
I0925 21:35:43.765182 19975 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I0925 21:35:43.765187 19975 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I0925 21:35:43.765259 19975 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0925 21:35:43.765400 19975 net.cpp:172] Setting up conv2_1_scale0
I0925 21:35:43.765410 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.765414 19975 net.cpp:194] Memory required for data: 6021240
I0925 21:35:43.765422 19975 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I0925 21:35:43.765429 19975 net.cpp:128] Creating Layer conv2_1_ReLU0
I0925 21:35:43.765434 19975 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I0925 21:35:43.765460 19975 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I0925 21:35:43.765887 19975 net.cpp:172] Setting up conv2_1_ReLU0
I0925 21:35:43.765908 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.765913 19975 net.cpp:194] Memory required for data: 6676600
I0925 21:35:43.765918 19975 layer_factory.hpp:77] Creating layer conv2_1_1
I0925 21:35:43.765929 19975 net.cpp:128] Creating Layer conv2_1_1
I0925 21:35:43.765934 19975 net.cpp:558] conv2_1_1 <- conv2_1_0
I0925 21:35:43.765942 19975 net.cpp:522] conv2_1_1 -> conv2_1_1
I0925 21:35:43.767205 19975 net.cpp:172] Setting up conv2_1_1
I0925 21:35:43.767230 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.767235 19975 net.cpp:194] Memory required for data: 7331960
I0925 21:35:43.767244 19975 layer_factory.hpp:77] Creating layer conv2_1bn1
I0925 21:35:43.767256 19975 net.cpp:128] Creating Layer conv2_1bn1
I0925 21:35:43.767261 19975 net.cpp:558] conv2_1bn1 <- conv2_1_1
I0925 21:35:43.767267 19975 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I0925 21:35:43.767527 19975 net.cpp:172] Setting up conv2_1bn1
I0925 21:35:43.767536 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.767540 19975 net.cpp:194] Memory required for data: 7987320
I0925 21:35:43.767554 19975 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0925 21:35:43.767563 19975 net.cpp:128] Creating Layer conv2_1_scale1
I0925 21:35:43.767568 19975 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I0925 21:35:43.767575 19975 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I0925 21:35:43.767621 19975 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0925 21:35:43.767762 19975 net.cpp:172] Setting up conv2_1_scale1
I0925 21:35:43.767773 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.767777 19975 net.cpp:194] Memory required for data: 8642680
I0925 21:35:43.767784 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I0925 21:35:43.767792 19975 net.cpp:128] Creating Layer conv2_Eltwise_1
I0925 21:35:43.767796 19975 net.cpp:558] conv2_Eltwise_1 <- conv1_conv1/ReLU_0_split_1
I0925 21:35:43.767802 19975 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I0925 21:35:43.767807 19975 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I0925 21:35:43.767834 19975 net.cpp:172] Setting up conv2_Eltwise_1
I0925 21:35:43.767845 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.767849 19975 net.cpp:194] Memory required for data: 9298040
I0925 21:35:43.767853 19975 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I0925 21:35:43.767859 19975 net.cpp:128] Creating Layer conv2_1ReLU_1
I0925 21:35:43.767864 19975 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I0925 21:35:43.767869 19975 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I0925 21:35:43.768102 19975 net.cpp:172] Setting up conv2_1ReLU_1
I0925 21:35:43.768116 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.768121 19975 net.cpp:194] Memory required for data: 9953400
I0925 21:35:43.768124 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0925 21:35:43.768133 19975 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0925 21:35:43.768141 19975 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I0925 21:35:43.768147 19975 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0925 21:35:43.768157 19975 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0925 21:35:43.768204 19975 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0925 21:35:43.768214 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.768219 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.768224 19975 net.cpp:194] Memory required for data: 11264120
I0925 21:35:43.768229 19975 layer_factory.hpp:77] Creating layer conv2_2_0
I0925 21:35:43.768239 19975 net.cpp:128] Creating Layer conv2_2_0
I0925 21:35:43.768244 19975 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0925 21:35:43.768252 19975 net.cpp:522] conv2_2_0 -> conv2_2_0
I0925 21:35:43.769574 19975 net.cpp:172] Setting up conv2_2_0
I0925 21:35:43.769601 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.769605 19975 net.cpp:194] Memory required for data: 11919480
I0925 21:35:43.769618 19975 layer_factory.hpp:77] Creating layer conv2_2_bn0
I0925 21:35:43.769631 19975 net.cpp:128] Creating Layer conv2_2_bn0
I0925 21:35:43.769640 19975 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I0925 21:35:43.769649 19975 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I0925 21:35:43.769907 19975 net.cpp:172] Setting up conv2_2_bn0
I0925 21:35:43.769917 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.769922 19975 net.cpp:194] Memory required for data: 12574840
I0925 21:35:43.769930 19975 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0925 21:35:43.769938 19975 net.cpp:128] Creating Layer conv2_2_scale0
I0925 21:35:43.769944 19975 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I0925 21:35:43.769950 19975 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I0925 21:35:43.769997 19975 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0925 21:35:43.770136 19975 net.cpp:172] Setting up conv2_2_scale0
I0925 21:35:43.770146 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.770150 19975 net.cpp:194] Memory required for data: 13230200
I0925 21:35:43.770159 19975 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I0925 21:35:43.770164 19975 net.cpp:128] Creating Layer conv2_2_ReLU0
I0925 21:35:43.770169 19975 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I0925 21:35:43.770174 19975 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I0925 21:35:43.770402 19975 net.cpp:172] Setting up conv2_2_ReLU0
I0925 21:35:43.770416 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.770422 19975 net.cpp:194] Memory required for data: 13885560
I0925 21:35:43.770427 19975 layer_factory.hpp:77] Creating layer conv2_2_1
I0925 21:35:43.770437 19975 net.cpp:128] Creating Layer conv2_2_1
I0925 21:35:43.770443 19975 net.cpp:558] conv2_2_1 <- conv2_2_0
I0925 21:35:43.770452 19975 net.cpp:522] conv2_2_1 -> conv2_2_1
I0925 21:35:43.771692 19975 net.cpp:172] Setting up conv2_2_1
I0925 21:35:43.771720 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.771724 19975 net.cpp:194] Memory required for data: 14540920
I0925 21:35:43.771739 19975 layer_factory.hpp:77] Creating layer conv2_2bn1
I0925 21:35:43.771751 19975 net.cpp:128] Creating Layer conv2_2bn1
I0925 21:35:43.771756 19975 net.cpp:558] conv2_2bn1 <- conv2_2_1
I0925 21:35:43.771764 19975 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I0925 21:35:43.772024 19975 net.cpp:172] Setting up conv2_2bn1
I0925 21:35:43.772034 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.772038 19975 net.cpp:194] Memory required for data: 15196280
I0925 21:35:43.772050 19975 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0925 21:35:43.772060 19975 net.cpp:128] Creating Layer conv2_2_scale1
I0925 21:35:43.772064 19975 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I0925 21:35:43.772070 19975 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I0925 21:35:43.772117 19975 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0925 21:35:43.772260 19975 net.cpp:172] Setting up conv2_2_scale1
I0925 21:35:43.772270 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.772274 19975 net.cpp:194] Memory required for data: 15851640
I0925 21:35:43.772282 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I0925 21:35:43.772289 19975 net.cpp:128] Creating Layer conv2_Eltwise_2
I0925 21:35:43.772294 19975 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0925 21:35:43.772300 19975 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I0925 21:35:43.772305 19975 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I0925 21:35:43.772331 19975 net.cpp:172] Setting up conv2_Eltwise_2
I0925 21:35:43.772341 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.772346 19975 net.cpp:194] Memory required for data: 16507000
I0925 21:35:43.772349 19975 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I0925 21:35:43.772377 19975 net.cpp:128] Creating Layer conv2_2ReLU_1
I0925 21:35:43.772382 19975 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I0925 21:35:43.772387 19975 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I0925 21:35:43.772809 19975 net.cpp:172] Setting up conv2_2ReLU_1
I0925 21:35:43.772830 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.772835 19975 net.cpp:194] Memory required for data: 17162360
I0925 21:35:43.772840 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0925 21:35:43.772848 19975 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0925 21:35:43.772853 19975 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I0925 21:35:43.772861 19975 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0925 21:35:43.772869 19975 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0925 21:35:43.772924 19975 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0925 21:35:43.772933 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.772940 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.772944 19975 net.cpp:194] Memory required for data: 18473080
I0925 21:35:43.772948 19975 layer_factory.hpp:77] Creating layer conv2_3_0
I0925 21:35:43.772959 19975 net.cpp:128] Creating Layer conv2_3_0
I0925 21:35:43.772964 19975 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0925 21:35:43.772971 19975 net.cpp:522] conv2_3_0 -> conv2_3_0
I0925 21:35:43.774260 19975 net.cpp:172] Setting up conv2_3_0
I0925 21:35:43.774286 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.774291 19975 net.cpp:194] Memory required for data: 19128440
I0925 21:35:43.774300 19975 layer_factory.hpp:77] Creating layer conv2_3_bn0
I0925 21:35:43.774309 19975 net.cpp:128] Creating Layer conv2_3_bn0
I0925 21:35:43.774318 19975 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I0925 21:35:43.774325 19975 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I0925 21:35:43.774582 19975 net.cpp:172] Setting up conv2_3_bn0
I0925 21:35:43.774592 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.774596 19975 net.cpp:194] Memory required for data: 19783800
I0925 21:35:43.774606 19975 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0925 21:35:43.774613 19975 net.cpp:128] Creating Layer conv2_3_scale0
I0925 21:35:43.774618 19975 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I0925 21:35:43.774623 19975 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I0925 21:35:43.774669 19975 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0925 21:35:43.774828 19975 net.cpp:172] Setting up conv2_3_scale0
I0925 21:35:43.774840 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.774844 19975 net.cpp:194] Memory required for data: 20439160
I0925 21:35:43.774852 19975 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I0925 21:35:43.774858 19975 net.cpp:128] Creating Layer conv2_3_ReLU0
I0925 21:35:43.774863 19975 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I0925 21:35:43.774869 19975 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I0925 21:35:43.775099 19975 net.cpp:172] Setting up conv2_3_ReLU0
I0925 21:35:43.775112 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.775116 19975 net.cpp:194] Memory required for data: 21094520
I0925 21:35:43.775121 19975 layer_factory.hpp:77] Creating layer conv2_3_1
I0925 21:35:43.775131 19975 net.cpp:128] Creating Layer conv2_3_1
I0925 21:35:43.775136 19975 net.cpp:558] conv2_3_1 <- conv2_3_0
I0925 21:35:43.775143 19975 net.cpp:522] conv2_3_1 -> conv2_3_1
I0925 21:35:43.776396 19975 net.cpp:172] Setting up conv2_3_1
I0925 21:35:43.776423 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.776427 19975 net.cpp:194] Memory required for data: 21749880
I0925 21:35:43.776439 19975 layer_factory.hpp:77] Creating layer conv2_3bn1
I0925 21:35:43.776450 19975 net.cpp:128] Creating Layer conv2_3bn1
I0925 21:35:43.776455 19975 net.cpp:558] conv2_3bn1 <- conv2_3_1
I0925 21:35:43.776481 19975 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I0925 21:35:43.776746 19975 net.cpp:172] Setting up conv2_3bn1
I0925 21:35:43.776756 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.776759 19975 net.cpp:194] Memory required for data: 22405240
I0925 21:35:43.776770 19975 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0925 21:35:43.776777 19975 net.cpp:128] Creating Layer conv2_3_scale1
I0925 21:35:43.776782 19975 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I0925 21:35:43.776788 19975 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I0925 21:35:43.776835 19975 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0925 21:35:43.776976 19975 net.cpp:172] Setting up conv2_3_scale1
I0925 21:35:43.776986 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.776990 19975 net.cpp:194] Memory required for data: 23060600
I0925 21:35:43.776998 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I0925 21:35:43.777004 19975 net.cpp:128] Creating Layer conv2_Eltwise_3
I0925 21:35:43.777009 19975 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0925 21:35:43.777014 19975 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I0925 21:35:43.777021 19975 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I0925 21:35:43.777047 19975 net.cpp:172] Setting up conv2_Eltwise_3
I0925 21:35:43.777057 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.777061 19975 net.cpp:194] Memory required for data: 23715960
I0925 21:35:43.777065 19975 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I0925 21:35:43.777071 19975 net.cpp:128] Creating Layer conv2_3ReLU_1
I0925 21:35:43.777076 19975 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I0925 21:35:43.777082 19975 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I0925 21:35:43.777315 19975 net.cpp:172] Setting up conv2_3ReLU_1
I0925 21:35:43.777328 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.777333 19975 net.cpp:194] Memory required for data: 24371320
I0925 21:35:43.777338 19975 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0925 21:35:43.777344 19975 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0925 21:35:43.777349 19975 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I0925 21:35:43.777355 19975 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0925 21:35:43.777364 19975 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0925 21:35:43.777412 19975 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0925 21:35:43.777422 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.777428 19975 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0925 21:35:43.777432 19975 net.cpp:194] Memory required for data: 25682040
I0925 21:35:43.777436 19975 layer_factory.hpp:77] Creating layer conv3_1_0
I0925 21:35:43.777446 19975 net.cpp:128] Creating Layer conv3_1_0
I0925 21:35:43.777451 19975 net.cpp:558] conv3_1_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0925 21:35:43.777458 19975 net.cpp:522] conv3_1_0 -> conv3_1_0
I0925 21:35:43.778766 19975 net.cpp:172] Setting up conv3_1_0
I0925 21:35:43.778792 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.778796 19975 net.cpp:194] Memory required for data: 26009720
I0925 21:35:43.778823 19975 layer_factory.hpp:77] Creating layer conv3_1_bn0
I0925 21:35:43.778833 19975 net.cpp:128] Creating Layer conv3_1_bn0
I0925 21:35:43.778838 19975 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I0925 21:35:43.778846 19975 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I0925 21:35:43.779100 19975 net.cpp:172] Setting up conv3_1_bn0
I0925 21:35:43.779110 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.779114 19975 net.cpp:194] Memory required for data: 26337400
I0925 21:35:43.779124 19975 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0925 21:35:43.779131 19975 net.cpp:128] Creating Layer conv3_1_scale0
I0925 21:35:43.779136 19975 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I0925 21:35:43.779160 19975 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I0925 21:35:43.779211 19975 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0925 21:35:43.779356 19975 net.cpp:172] Setting up conv3_1_scale0
I0925 21:35:43.779366 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.779369 19975 net.cpp:194] Memory required for data: 26665080
I0925 21:35:43.779377 19975 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I0925 21:35:43.779383 19975 net.cpp:128] Creating Layer conv3_1_ReLU0
I0925 21:35:43.779388 19975 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I0925 21:35:43.779394 19975 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I0925 21:35:43.779628 19975 net.cpp:172] Setting up conv3_1_ReLU0
I0925 21:35:43.779642 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.779647 19975 net.cpp:194] Memory required for data: 26992760
I0925 21:35:43.779651 19975 layer_factory.hpp:77] Creating layer conv3_1_1
I0925 21:35:43.779664 19975 net.cpp:128] Creating Layer conv3_1_1
I0925 21:35:43.779669 19975 net.cpp:558] conv3_1_1 <- conv3_1_0
I0925 21:35:43.779675 19975 net.cpp:522] conv3_1_1 -> conv3_1_1
I0925 21:35:43.781035 19975 net.cpp:172] Setting up conv3_1_1
I0925 21:35:43.781062 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.781066 19975 net.cpp:194] Memory required for data: 27320440
I0925 21:35:43.781080 19975 layer_factory.hpp:77] Creating layer conv3_1bn1
I0925 21:35:43.781093 19975 net.cpp:128] Creating Layer conv3_1bn1
I0925 21:35:43.781098 19975 net.cpp:558] conv3_1bn1 <- conv3_1_1
I0925 21:35:43.781110 19975 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I0925 21:35:43.781361 19975 net.cpp:172] Setting up conv3_1bn1
I0925 21:35:43.781371 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.781375 19975 net.cpp:194] Memory required for data: 27648120
I0925 21:35:43.781385 19975 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0925 21:35:43.781392 19975 net.cpp:128] Creating Layer conv3_1_scale1
I0925 21:35:43.781397 19975 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I0925 21:35:43.781404 19975 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I0925 21:35:43.781451 19975 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0925 21:35:43.781596 19975 net.cpp:172] Setting up conv3_1_scale1
I0925 21:35:43.781606 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.781611 19975 net.cpp:194] Memory required for data: 27975800
I0925 21:35:43.781618 19975 layer_factory.hpp:77] Creating layer conv3_1_down
I0925 21:35:43.781628 19975 net.cpp:128] Creating Layer conv3_1_down
I0925 21:35:43.781633 19975 net.cpp:558] conv3_1_down <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0925 21:35:43.781641 19975 net.cpp:522] conv3_1_down -> conv3_1_down
I0925 21:35:43.782883 19975 net.cpp:172] Setting up conv3_1_down
I0925 21:35:43.782909 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.782913 19975 net.cpp:194] Memory required for data: 28303480
I0925 21:35:43.782928 19975 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I0925 21:35:43.782938 19975 net.cpp:128] Creating Layer conv3_1_bn_down
I0925 21:35:43.782943 19975 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I0925 21:35:43.782953 19975 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I0925 21:35:43.783210 19975 net.cpp:172] Setting up conv3_1_bn_down
I0925 21:35:43.783221 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.783224 19975 net.cpp:194] Memory required for data: 28631160
I0925 21:35:43.783234 19975 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0925 21:35:43.783242 19975 net.cpp:128] Creating Layer conv3_1_scale_down
I0925 21:35:43.783246 19975 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I0925 21:35:43.783252 19975 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I0925 21:35:43.783300 19975 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0925 21:35:43.783443 19975 net.cpp:172] Setting up conv3_1_scale_down
I0925 21:35:43.783453 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.783479 19975 net.cpp:194] Memory required for data: 28958840
I0925 21:35:43.783489 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I0925 21:35:43.783495 19975 net.cpp:128] Creating Layer conv3_Eltwise_1
I0925 21:35:43.783500 19975 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I0925 21:35:43.783505 19975 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I0925 21:35:43.783511 19975 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I0925 21:35:43.783535 19975 net.cpp:172] Setting up conv3_Eltwise_1
I0925 21:35:43.783542 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.783546 19975 net.cpp:194] Memory required for data: 29286520
I0925 21:35:43.783550 19975 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I0925 21:35:43.783558 19975 net.cpp:128] Creating Layer conv3_1ReLU_1
I0925 21:35:43.783562 19975 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I0925 21:35:43.783568 19975 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I0925 21:35:43.783995 19975 net.cpp:172] Setting up conv3_1ReLU_1
I0925 21:35:43.784018 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.784023 19975 net.cpp:194] Memory required for data: 29614200
I0925 21:35:43.784027 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0925 21:35:43.784035 19975 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0925 21:35:43.784040 19975 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I0925 21:35:43.784047 19975 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0925 21:35:43.784056 19975 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0925 21:35:43.784111 19975 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0925 21:35:43.784122 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.784127 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.784132 19975 net.cpp:194] Memory required for data: 30269560
I0925 21:35:43.784137 19975 layer_factory.hpp:77] Creating layer conv3_2_0
I0925 21:35:43.784147 19975 net.cpp:128] Creating Layer conv3_2_0
I0925 21:35:43.784152 19975 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0925 21:35:43.784158 19975 net.cpp:522] conv3_2_0 -> conv3_2_0
I0925 21:35:43.785686 19975 net.cpp:172] Setting up conv3_2_0
I0925 21:35:43.785712 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.785717 19975 net.cpp:194] Memory required for data: 30597240
I0925 21:35:43.785727 19975 layer_factory.hpp:77] Creating layer conv3_2_bn0
I0925 21:35:43.785737 19975 net.cpp:128] Creating Layer conv3_2_bn0
I0925 21:35:43.785742 19975 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I0925 21:35:43.785753 19975 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I0925 21:35:43.786010 19975 net.cpp:172] Setting up conv3_2_bn0
I0925 21:35:43.786022 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.786026 19975 net.cpp:194] Memory required for data: 30924920
I0925 21:35:43.786036 19975 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0925 21:35:43.786043 19975 net.cpp:128] Creating Layer conv3_2_scale0
I0925 21:35:43.786048 19975 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I0925 21:35:43.786053 19975 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I0925 21:35:43.786103 19975 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0925 21:35:43.786249 19975 net.cpp:172] Setting up conv3_2_scale0
I0925 21:35:43.786260 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.786264 19975 net.cpp:194] Memory required for data: 31252600
I0925 21:35:43.786272 19975 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I0925 21:35:43.786278 19975 net.cpp:128] Creating Layer conv3_2_ReLU0
I0925 21:35:43.786283 19975 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I0925 21:35:43.786288 19975 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I0925 21:35:43.786520 19975 net.cpp:172] Setting up conv3_2_ReLU0
I0925 21:35:43.786535 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.786538 19975 net.cpp:194] Memory required for data: 31580280
I0925 21:35:43.786561 19975 layer_factory.hpp:77] Creating layer conv3_2_1
I0925 21:35:43.786571 19975 net.cpp:128] Creating Layer conv3_2_1
I0925 21:35:43.786576 19975 net.cpp:558] conv3_2_1 <- conv3_2_0
I0925 21:35:43.786583 19975 net.cpp:522] conv3_2_1 -> conv3_2_1
I0925 21:35:43.787986 19975 net.cpp:172] Setting up conv3_2_1
I0925 21:35:43.788012 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.788017 19975 net.cpp:194] Memory required for data: 31907960
I0925 21:35:43.788027 19975 layer_factory.hpp:77] Creating layer conv3_2bn1
I0925 21:35:43.788035 19975 net.cpp:128] Creating Layer conv3_2bn1
I0925 21:35:43.788040 19975 net.cpp:558] conv3_2bn1 <- conv3_2_1
I0925 21:35:43.788048 19975 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I0925 21:35:43.788322 19975 net.cpp:172] Setting up conv3_2bn1
I0925 21:35:43.788333 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.788337 19975 net.cpp:194] Memory required for data: 32235640
I0925 21:35:43.788347 19975 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0925 21:35:43.788357 19975 net.cpp:128] Creating Layer conv3_2_scale1
I0925 21:35:43.788362 19975 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I0925 21:35:43.788367 19975 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I0925 21:35:43.788419 19975 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0925 21:35:43.788574 19975 net.cpp:172] Setting up conv3_2_scale1
I0925 21:35:43.788585 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.788589 19975 net.cpp:194] Memory required for data: 32563320
I0925 21:35:43.788596 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I0925 21:35:43.788607 19975 net.cpp:128] Creating Layer conv3_Eltwise_2
I0925 21:35:43.788612 19975 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0925 21:35:43.788617 19975 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I0925 21:35:43.788624 19975 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I0925 21:35:43.788648 19975 net.cpp:172] Setting up conv3_Eltwise_2
I0925 21:35:43.788656 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.788661 19975 net.cpp:194] Memory required for data: 32891000
I0925 21:35:43.788664 19975 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I0925 21:35:43.788671 19975 net.cpp:128] Creating Layer conv3_2ReLU_1
I0925 21:35:43.788676 19975 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I0925 21:35:43.788683 19975 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I0925 21:35:43.788918 19975 net.cpp:172] Setting up conv3_2ReLU_1
I0925 21:35:43.788933 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.788938 19975 net.cpp:194] Memory required for data: 33218680
I0925 21:35:43.788941 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0925 21:35:43.788949 19975 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0925 21:35:43.788952 19975 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I0925 21:35:43.788961 19975 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0925 21:35:43.788969 19975 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0925 21:35:43.789032 19975 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0925 21:35:43.789043 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.789049 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.789053 19975 net.cpp:194] Memory required for data: 33874040
I0925 21:35:43.789057 19975 layer_factory.hpp:77] Creating layer conv3_3_0
I0925 21:35:43.789069 19975 net.cpp:128] Creating Layer conv3_3_0
I0925 21:35:43.789074 19975 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0925 21:35:43.789086 19975 net.cpp:522] conv3_3_0 -> conv3_3_0
I0925 21:35:43.790513 19975 net.cpp:172] Setting up conv3_3_0
I0925 21:35:43.790540 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.790545 19975 net.cpp:194] Memory required for data: 34201720
I0925 21:35:43.790571 19975 layer_factory.hpp:77] Creating layer conv3_3_bn0
I0925 21:35:43.790583 19975 net.cpp:128] Creating Layer conv3_3_bn0
I0925 21:35:43.790588 19975 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I0925 21:35:43.790597 19975 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I0925 21:35:43.790887 19975 net.cpp:172] Setting up conv3_3_bn0
I0925 21:35:43.790900 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.790905 19975 net.cpp:194] Memory required for data: 34529400
I0925 21:35:43.790915 19975 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0925 21:35:43.790922 19975 net.cpp:128] Creating Layer conv3_3_scale0
I0925 21:35:43.790926 19975 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I0925 21:35:43.790932 19975 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I0925 21:35:43.790984 19975 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0925 21:35:43.791142 19975 net.cpp:172] Setting up conv3_3_scale0
I0925 21:35:43.791155 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.791159 19975 net.cpp:194] Memory required for data: 34857080
I0925 21:35:43.791167 19975 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I0925 21:35:43.791173 19975 net.cpp:128] Creating Layer conv3_3_ReLU0
I0925 21:35:43.791178 19975 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I0925 21:35:43.791183 19975 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I0925 21:35:43.791627 19975 net.cpp:172] Setting up conv3_3_ReLU0
I0925 21:35:43.791649 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.791654 19975 net.cpp:194] Memory required for data: 35184760
I0925 21:35:43.791659 19975 layer_factory.hpp:77] Creating layer conv3_3_1
I0925 21:35:43.791684 19975 net.cpp:128] Creating Layer conv3_3_1
I0925 21:35:43.791690 19975 net.cpp:558] conv3_3_1 <- conv3_3_0
I0925 21:35:43.791698 19975 net.cpp:522] conv3_3_1 -> conv3_3_1
I0925 21:35:43.793162 19975 net.cpp:172] Setting up conv3_3_1
I0925 21:35:43.793189 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.793192 19975 net.cpp:194] Memory required for data: 35512440
I0925 21:35:43.793202 19975 layer_factory.hpp:77] Creating layer conv3_3bn1
I0925 21:35:43.793211 19975 net.cpp:128] Creating Layer conv3_3bn1
I0925 21:35:43.793216 19975 net.cpp:558] conv3_3bn1 <- conv3_3_1
I0925 21:35:43.793229 19975 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I0925 21:35:43.793505 19975 net.cpp:172] Setting up conv3_3bn1
I0925 21:35:43.793516 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.793521 19975 net.cpp:194] Memory required for data: 35840120
I0925 21:35:43.793530 19975 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0925 21:35:43.793537 19975 net.cpp:128] Creating Layer conv3_3_scale1
I0925 21:35:43.793541 19975 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I0925 21:35:43.793547 19975 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I0925 21:35:43.793601 19975 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0925 21:35:43.793756 19975 net.cpp:172] Setting up conv3_3_scale1
I0925 21:35:43.793768 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.793772 19975 net.cpp:194] Memory required for data: 36167800
I0925 21:35:43.793781 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I0925 21:35:43.793787 19975 net.cpp:128] Creating Layer conv3_Eltwise_3
I0925 21:35:43.793792 19975 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0925 21:35:43.793797 19975 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I0925 21:35:43.793804 19975 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I0925 21:35:43.793829 19975 net.cpp:172] Setting up conv3_Eltwise_3
I0925 21:35:43.793836 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.793840 19975 net.cpp:194] Memory required for data: 36495480
I0925 21:35:43.793844 19975 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I0925 21:35:43.793850 19975 net.cpp:128] Creating Layer conv3_3ReLU_1
I0925 21:35:43.793854 19975 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I0925 21:35:43.793864 19975 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I0925 21:35:43.794124 19975 net.cpp:172] Setting up conv3_3ReLU_1
I0925 21:35:43.794139 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.794143 19975 net.cpp:194] Memory required for data: 36823160
I0925 21:35:43.794148 19975 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0925 21:35:43.794155 19975 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0925 21:35:43.794162 19975 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I0925 21:35:43.794168 19975 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0925 21:35:43.794176 19975 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0925 21:35:43.794234 19975 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0925 21:35:43.794243 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.794250 19975 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0925 21:35:43.794252 19975 net.cpp:194] Memory required for data: 37478520
I0925 21:35:43.794257 19975 layer_factory.hpp:77] Creating layer conv4_1_0
I0925 21:35:43.794268 19975 net.cpp:128] Creating Layer conv4_1_0
I0925 21:35:43.794273 19975 net.cpp:558] conv4_1_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0925 21:35:43.794282 19975 net.cpp:522] conv4_1_0 -> conv4_1_0
I0925 21:35:43.795917 19975 net.cpp:172] Setting up conv4_1_0
I0925 21:35:43.795943 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.795948 19975 net.cpp:194] Memory required for data: 37642360
I0925 21:35:43.795958 19975 layer_factory.hpp:77] Creating layer conv4_1_bn0
I0925 21:35:43.795971 19975 net.cpp:128] Creating Layer conv4_1_bn0
I0925 21:35:43.795977 19975 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I0925 21:35:43.795990 19975 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I0925 21:35:43.796270 19975 net.cpp:172] Setting up conv4_1_bn0
I0925 21:35:43.796280 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.796285 19975 net.cpp:194] Memory required for data: 37806200
I0925 21:35:43.796294 19975 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0925 21:35:43.796303 19975 net.cpp:128] Creating Layer conv4_1_scale0
I0925 21:35:43.796308 19975 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I0925 21:35:43.796314 19975 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I0925 21:35:43.796365 19975 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0925 21:35:43.796526 19975 net.cpp:172] Setting up conv4_1_scale0
I0925 21:35:43.796537 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.796541 19975 net.cpp:194] Memory required for data: 37970040
I0925 21:35:43.796550 19975 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I0925 21:35:43.796555 19975 net.cpp:128] Creating Layer conv4_1_ReLU0
I0925 21:35:43.796560 19975 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I0925 21:35:43.796567 19975 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I0925 21:35:43.796813 19975 net.cpp:172] Setting up conv4_1_ReLU0
I0925 21:35:43.796828 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.796831 19975 net.cpp:194] Memory required for data: 38133880
I0925 21:35:43.796836 19975 layer_factory.hpp:77] Creating layer conv4_1_1
I0925 21:35:43.796849 19975 net.cpp:128] Creating Layer conv4_1_1
I0925 21:35:43.796854 19975 net.cpp:558] conv4_1_1 <- conv4_1_0
I0925 21:35:43.796862 19975 net.cpp:522] conv4_1_1 -> conv4_1_1
I0925 21:35:43.798764 19975 net.cpp:172] Setting up conv4_1_1
I0925 21:35:43.798790 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.798794 19975 net.cpp:194] Memory required for data: 38297720
I0925 21:35:43.798804 19975 layer_factory.hpp:77] Creating layer conv4_1bn1
I0925 21:35:43.798828 19975 net.cpp:128] Creating Layer conv4_1bn1
I0925 21:35:43.798835 19975 net.cpp:558] conv4_1bn1 <- conv4_1_1
I0925 21:35:43.798841 19975 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I0925 21:35:43.799125 19975 net.cpp:172] Setting up conv4_1bn1
I0925 21:35:43.799136 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.799165 19975 net.cpp:194] Memory required for data: 38461560
I0925 21:35:43.799175 19975 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0925 21:35:43.799181 19975 net.cpp:128] Creating Layer conv4_1_scale1
I0925 21:35:43.799186 19975 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I0925 21:35:43.799192 19975 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I0925 21:35:43.799249 19975 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0925 21:35:43.799413 19975 net.cpp:172] Setting up conv4_1_scale1
I0925 21:35:43.799424 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.799428 19975 net.cpp:194] Memory required for data: 38625400
I0925 21:35:43.799435 19975 layer_factory.hpp:77] Creating layer conv4_1_down
I0925 21:35:43.799450 19975 net.cpp:128] Creating Layer conv4_1_down
I0925 21:35:43.799455 19975 net.cpp:558] conv4_1_down <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0925 21:35:43.799464 19975 net.cpp:522] conv4_1_down -> conv4_1_down
I0925 21:35:43.800801 19975 net.cpp:172] Setting up conv4_1_down
I0925 21:35:43.800827 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.800832 19975 net.cpp:194] Memory required for data: 38789240
I0925 21:35:43.800840 19975 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I0925 21:35:43.800851 19975 net.cpp:128] Creating Layer conv4_1_bn_down
I0925 21:35:43.800856 19975 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I0925 21:35:43.800868 19975 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I0925 21:35:43.801147 19975 net.cpp:172] Setting up conv4_1_bn_down
I0925 21:35:43.801158 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.801162 19975 net.cpp:194] Memory required for data: 38953080
I0925 21:35:43.801172 19975 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0925 21:35:43.801182 19975 net.cpp:128] Creating Layer conv4_1_scale_down
I0925 21:35:43.801185 19975 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I0925 21:35:43.801192 19975 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I0925 21:35:43.801245 19975 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0925 21:35:43.801410 19975 net.cpp:172] Setting up conv4_1_scale_down
I0925 21:35:43.801421 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.801425 19975 net.cpp:194] Memory required for data: 39116920
I0925 21:35:43.801432 19975 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I0925 21:35:43.801441 19975 net.cpp:128] Creating Layer conv4_Eltwise_1
I0925 21:35:43.801446 19975 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I0925 21:35:43.801451 19975 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I0925 21:35:43.801458 19975 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I0925 21:35:43.801487 19975 net.cpp:172] Setting up conv4_Eltwise_1
I0925 21:35:43.801494 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.801498 19975 net.cpp:194] Memory required for data: 39280760
I0925 21:35:43.801502 19975 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I0925 21:35:43.801511 19975 net.cpp:128] Creating Layer conv4_1ReLU_1
I0925 21:35:43.801515 19975 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I0925 21:35:43.801522 19975 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I0925 21:35:43.801971 19975 net.cpp:172] Setting up conv4_1ReLU_1
I0925 21:35:43.801995 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.802000 19975 net.cpp:194] Memory required for data: 39444600
I0925 21:35:43.802004 19975 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0925 21:35:43.802018 19975 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0925 21:35:43.802023 19975 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I0925 21:35:43.802031 19975 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0925 21:35:43.802042 19975 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0925 21:35:43.802101 19975 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0925 21:35:43.802109 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.802130 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.802134 19975 net.cpp:194] Memory required for data: 39772280
I0925 21:35:43.802139 19975 layer_factory.hpp:77] Creating layer conv4_2_0
I0925 21:35:43.802151 19975 net.cpp:128] Creating Layer conv4_2_0
I0925 21:35:43.802156 19975 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0925 21:35:43.802163 19975 net.cpp:522] conv4_2_0 -> conv4_2_0
I0925 21:35:43.804255 19975 net.cpp:172] Setting up conv4_2_0
I0925 21:35:43.804275 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.804280 19975 net.cpp:194] Memory required for data: 39936120
I0925 21:35:43.804291 19975 layer_factory.hpp:77] Creating layer conv4_2_bn0
I0925 21:35:43.804298 19975 net.cpp:128] Creating Layer conv4_2_bn0
I0925 21:35:43.804303 19975 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I0925 21:35:43.804312 19975 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I0925 21:35:43.804606 19975 net.cpp:172] Setting up conv4_2_bn0
I0925 21:35:43.804613 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.804617 19975 net.cpp:194] Memory required for data: 40099960
I0925 21:35:43.804627 19975 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0925 21:35:43.804633 19975 net.cpp:128] Creating Layer conv4_2_scale0
I0925 21:35:43.804638 19975 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I0925 21:35:43.804646 19975 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I0925 21:35:43.804693 19975 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0925 21:35:43.804854 19975 net.cpp:172] Setting up conv4_2_scale0
I0925 21:35:43.804862 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.804865 19975 net.cpp:194] Memory required for data: 40263800
I0925 21:35:43.804873 19975 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I0925 21:35:43.804882 19975 net.cpp:128] Creating Layer conv4_2_ReLU0
I0925 21:35:43.804885 19975 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I0925 21:35:43.804891 19975 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I0925 21:35:43.805133 19975 net.cpp:172] Setting up conv4_2_ReLU0
I0925 21:35:43.805143 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.805147 19975 net.cpp:194] Memory required for data: 40427640
I0925 21:35:43.805152 19975 layer_factory.hpp:77] Creating layer conv4_2_1
I0925 21:35:43.805166 19975 net.cpp:128] Creating Layer conv4_2_1
I0925 21:35:43.805171 19975 net.cpp:558] conv4_2_1 <- conv4_2_0
I0925 21:35:43.805178 19975 net.cpp:522] conv4_2_1 -> conv4_2_1
I0925 21:35:43.807111 19975 net.cpp:172] Setting up conv4_2_1
I0925 21:35:43.807128 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.807132 19975 net.cpp:194] Memory required for data: 40591480
I0925 21:35:43.807142 19975 layer_factory.hpp:77] Creating layer conv4_2bn1
I0925 21:35:43.807152 19975 net.cpp:128] Creating Layer conv4_2bn1
I0925 21:35:43.807157 19975 net.cpp:558] conv4_2bn1 <- conv4_2_1
I0925 21:35:43.807165 19975 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I0925 21:35:43.807449 19975 net.cpp:172] Setting up conv4_2bn1
I0925 21:35:43.807456 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.807461 19975 net.cpp:194] Memory required for data: 40755320
I0925 21:35:43.807482 19975 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0925 21:35:43.807490 19975 net.cpp:128] Creating Layer conv4_2_scale1
I0925 21:35:43.807494 19975 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I0925 21:35:43.807502 19975 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I0925 21:35:43.807552 19975 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0925 21:35:43.807710 19975 net.cpp:172] Setting up conv4_2_scale1
I0925 21:35:43.807718 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.807721 19975 net.cpp:194] Memory required for data: 40919160
I0925 21:35:43.807729 19975 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I0925 21:35:43.807735 19975 net.cpp:128] Creating Layer conv4_Eltwise_2
I0925 21:35:43.807741 19975 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0925 21:35:43.807763 19975 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I0925 21:35:43.807771 19975 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I0925 21:35:43.807803 19975 net.cpp:172] Setting up conv4_Eltwise_2
I0925 21:35:43.807811 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.807814 19975 net.cpp:194] Memory required for data: 41083000
I0925 21:35:43.807818 19975 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I0925 21:35:43.807824 19975 net.cpp:128] Creating Layer conv4_2ReLU_1
I0925 21:35:43.807828 19975 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I0925 21:35:43.807835 19975 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I0925 21:35:43.808076 19975 net.cpp:172] Setting up conv4_2ReLU_1
I0925 21:35:43.808086 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.808090 19975 net.cpp:194] Memory required for data: 41246840
I0925 21:35:43.808094 19975 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0925 21:35:43.808101 19975 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0925 21:35:43.808105 19975 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I0925 21:35:43.808115 19975 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0925 21:35:43.808122 19975 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0925 21:35:43.808176 19975 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0925 21:35:43.808184 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.808189 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.808193 19975 net.cpp:194] Memory required for data: 41574520
I0925 21:35:43.808197 19975 layer_factory.hpp:77] Creating layer conv4_3_0
I0925 21:35:43.808210 19975 net.cpp:128] Creating Layer conv4_3_0
I0925 21:35:43.808215 19975 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0925 21:35:43.808224 19975 net.cpp:522] conv4_3_0 -> conv4_3_0
I0925 21:35:43.810292 19975 net.cpp:172] Setting up conv4_3_0
I0925 21:35:43.810310 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.810314 19975 net.cpp:194] Memory required for data: 41738360
I0925 21:35:43.810324 19975 layer_factory.hpp:77] Creating layer conv4_3_bn0
I0925 21:35:43.810334 19975 net.cpp:128] Creating Layer conv4_3_bn0
I0925 21:35:43.810339 19975 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I0925 21:35:43.810346 19975 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I0925 21:35:43.810642 19975 net.cpp:172] Setting up conv4_3_bn0
I0925 21:35:43.810649 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.810653 19975 net.cpp:194] Memory required for data: 41902200
I0925 21:35:43.810662 19975 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0925 21:35:43.810672 19975 net.cpp:128] Creating Layer conv4_3_scale0
I0925 21:35:43.810675 19975 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I0925 21:35:43.810681 19975 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I0925 21:35:43.810734 19975 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0925 21:35:43.810907 19975 net.cpp:172] Setting up conv4_3_scale0
I0925 21:35:43.810915 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.810920 19975 net.cpp:194] Memory required for data: 42066040
I0925 21:35:43.810927 19975 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I0925 21:35:43.810935 19975 net.cpp:128] Creating Layer conv4_3_ReLU0
I0925 21:35:43.810940 19975 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I0925 21:35:43.810946 19975 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I0925 21:35:43.811187 19975 net.cpp:172] Setting up conv4_3_ReLU0
I0925 21:35:43.811197 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.811202 19975 net.cpp:194] Memory required for data: 42229880
I0925 21:35:43.811206 19975 layer_factory.hpp:77] Creating layer conv4_3_1
I0925 21:35:43.811219 19975 net.cpp:128] Creating Layer conv4_3_1
I0925 21:35:43.811224 19975 net.cpp:558] conv4_3_1 <- conv4_3_0
I0925 21:35:43.811231 19975 net.cpp:522] conv4_3_1 -> conv4_3_1
I0925 21:35:43.814487 19975 net.cpp:172] Setting up conv4_3_1
I0925 21:35:43.814505 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.814509 19975 net.cpp:194] Memory required for data: 42393720
I0925 21:35:43.814518 19975 layer_factory.hpp:77] Creating layer conv4_3bn1
I0925 21:35:43.814529 19975 net.cpp:128] Creating Layer conv4_3bn1
I0925 21:35:43.814534 19975 net.cpp:558] conv4_3bn1 <- conv4_3_1
I0925 21:35:43.814541 19975 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I0925 21:35:43.814884 19975 net.cpp:172] Setting up conv4_3bn1
I0925 21:35:43.814894 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.814898 19975 net.cpp:194] Memory required for data: 42557560
I0925 21:35:43.814909 19975 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0925 21:35:43.814918 19975 net.cpp:128] Creating Layer conv4_3_scale1
I0925 21:35:43.814924 19975 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I0925 21:35:43.814929 19975 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I0925 21:35:43.814983 19975 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0925 21:35:43.815166 19975 net.cpp:172] Setting up conv4_3_scale1
I0925 21:35:43.815174 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.815177 19975 net.cpp:194] Memory required for data: 42721400
I0925 21:35:43.815186 19975 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I0925 21:35:43.815194 19975 net.cpp:128] Creating Layer conv4_Eltwise_3
I0925 21:35:43.815199 19975 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0925 21:35:43.815204 19975 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I0925 21:35:43.815212 19975 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I0925 21:35:43.815240 19975 net.cpp:172] Setting up conv4_Eltwise_3
I0925 21:35:43.815248 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.815250 19975 net.cpp:194] Memory required for data: 42885240
I0925 21:35:43.815254 19975 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I0925 21:35:43.815263 19975 net.cpp:128] Creating Layer conv4_3ReLU_1
I0925 21:35:43.815268 19975 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I0925 21:35:43.815273 19975 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I0925 21:35:43.815711 19975 net.cpp:172] Setting up conv4_3ReLU_1
I0925 21:35:43.815728 19975 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0925 21:35:43.815732 19975 net.cpp:194] Memory required for data: 43049080
I0925 21:35:43.815737 19975 layer_factory.hpp:77] Creating layer Pooling1
I0925 21:35:43.815748 19975 net.cpp:128] Creating Layer Pooling1
I0925 21:35:43.815753 19975 net.cpp:558] Pooling1 <- conv4_Eltwise_3
I0925 21:35:43.815760 19975 net.cpp:522] Pooling1 -> Pooling1
I0925 21:35:43.816027 19975 net.cpp:172] Setting up Pooling1
I0925 21:35:43.816037 19975 net.cpp:186] Top shape: 10 64 1 1 (640)
I0925 21:35:43.816041 19975 net.cpp:194] Memory required for data: 43051640
I0925 21:35:43.816045 19975 layer_factory.hpp:77] Creating layer fc1
I0925 21:35:43.816056 19975 net.cpp:128] Creating Layer fc1
I0925 21:35:43.816061 19975 net.cpp:558] fc1 <- Pooling1
I0925 21:35:43.816069 19975 net.cpp:522] fc1 -> fc1
I0925 21:35:43.816237 19975 net.cpp:172] Setting up fc1
I0925 21:35:43.816247 19975 net.cpp:186] Top shape: 10 10 (100)
I0925 21:35:43.816251 19975 net.cpp:194] Memory required for data: 43052040
I0925 21:35:43.816259 19975 layer_factory.hpp:77] Creating layer fc1_fc1_0_split
I0925 21:35:43.816267 19975 net.cpp:128] Creating Layer fc1_fc1_0_split
I0925 21:35:43.816270 19975 net.cpp:558] fc1_fc1_0_split <- fc1
I0925 21:35:43.816277 19975 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_0
I0925 21:35:43.816285 19975 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_1
I0925 21:35:43.816334 19975 net.cpp:172] Setting up fc1_fc1_0_split
I0925 21:35:43.816341 19975 net.cpp:186] Top shape: 10 10 (100)
I0925 21:35:43.816346 19975 net.cpp:186] Top shape: 10 10 (100)
I0925 21:35:43.816350 19975 net.cpp:194] Memory required for data: 43052840
I0925 21:35:43.816354 19975 layer_factory.hpp:77] Creating layer Softmax1
I0925 21:35:43.816367 19975 net.cpp:128] Creating Layer Softmax1
I0925 21:35:43.816386 19975 net.cpp:558] Softmax1 <- fc1_fc1_0_split_0
I0925 21:35:43.816391 19975 net.cpp:558] Softmax1 <- label_Data1_1_split_0
I0925 21:35:43.816398 19975 net.cpp:522] Softmax1 -> Softmax1
I0925 21:35:43.816407 19975 layer_factory.hpp:77] Creating layer Softmax1
I0925 21:35:43.816789 19975 net.cpp:172] Setting up Softmax1
I0925 21:35:43.816802 19975 net.cpp:186] Top shape: (1)
I0925 21:35:43.816805 19975 net.cpp:189]     with loss weight 1
I0925 21:35:43.816818 19975 net.cpp:194] Memory required for data: 43052844
I0925 21:35:43.816823 19975 layer_factory.hpp:77] Creating layer prob
I0925 21:35:43.816833 19975 net.cpp:128] Creating Layer prob
I0925 21:35:43.816838 19975 net.cpp:558] prob <- fc1_fc1_0_split_1
I0925 21:35:43.816843 19975 net.cpp:558] prob <- label_Data1_1_split_1
I0925 21:35:43.816849 19975 net.cpp:522] prob -> prob
I0925 21:35:43.816860 19975 net.cpp:172] Setting up prob
I0925 21:35:43.816865 19975 net.cpp:186] Top shape: (1)
I0925 21:35:43.816869 19975 net.cpp:194] Memory required for data: 43052848
I0925 21:35:43.816874 19975 net.cpp:303] prob does not need backward computation.
I0925 21:35:43.816879 19975 net.cpp:301] Softmax1 needs backward computation.
I0925 21:35:43.816884 19975 net.cpp:301] fc1_fc1_0_split needs backward computation.
I0925 21:35:43.816887 19975 net.cpp:301] fc1 needs backward computation.
I0925 21:35:43.816891 19975 net.cpp:301] Pooling1 needs backward computation.
I0925 21:35:43.816896 19975 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I0925 21:35:43.816900 19975 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I0925 21:35:43.816905 19975 net.cpp:301] conv4_3_scale1 needs backward computation.
I0925 21:35:43.816908 19975 net.cpp:301] conv4_3bn1 needs backward computation.
I0925 21:35:43.816912 19975 net.cpp:301] conv4_3_1 needs backward computation.
I0925 21:35:43.816917 19975 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I0925 21:35:43.816921 19975 net.cpp:301] conv4_3_scale0 needs backward computation.
I0925 21:35:43.816926 19975 net.cpp:301] conv4_3_bn0 needs backward computation.
I0925 21:35:43.816928 19975 net.cpp:301] conv4_3_0 needs backward computation.
I0925 21:35:43.816933 19975 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I0925 21:35:43.816937 19975 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I0925 21:35:43.816942 19975 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I0925 21:35:43.816946 19975 net.cpp:301] conv4_2_scale1 needs backward computation.
I0925 21:35:43.816951 19975 net.cpp:301] conv4_2bn1 needs backward computation.
I0925 21:35:43.816954 19975 net.cpp:301] conv4_2_1 needs backward computation.
I0925 21:35:43.816959 19975 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I0925 21:35:43.816963 19975 net.cpp:301] conv4_2_scale0 needs backward computation.
I0925 21:35:43.816967 19975 net.cpp:301] conv4_2_bn0 needs backward computation.
I0925 21:35:43.816972 19975 net.cpp:301] conv4_2_0 needs backward computation.
I0925 21:35:43.816975 19975 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I0925 21:35:43.816980 19975 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I0925 21:35:43.816984 19975 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I0925 21:35:43.816989 19975 net.cpp:301] conv4_1_scale_down needs backward computation.
I0925 21:35:43.816993 19975 net.cpp:301] conv4_1_bn_down needs backward computation.
I0925 21:35:43.816998 19975 net.cpp:301] conv4_1_down needs backward computation.
I0925 21:35:43.817001 19975 net.cpp:301] conv4_1_scale1 needs backward computation.
I0925 21:35:43.817006 19975 net.cpp:301] conv4_1bn1 needs backward computation.
I0925 21:35:43.817010 19975 net.cpp:301] conv4_1_1 needs backward computation.
I0925 21:35:43.817014 19975 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I0925 21:35:43.817019 19975 net.cpp:301] conv4_1_scale0 needs backward computation.
I0925 21:35:43.817023 19975 net.cpp:301] conv4_1_bn0 needs backward computation.
I0925 21:35:43.817039 19975 net.cpp:301] conv4_1_0 needs backward computation.
I0925 21:35:43.817045 19975 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I0925 21:35:43.817049 19975 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I0925 21:35:43.817054 19975 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I0925 21:35:43.817059 19975 net.cpp:301] conv3_3_scale1 needs backward computation.
I0925 21:35:43.817064 19975 net.cpp:301] conv3_3bn1 needs backward computation.
I0925 21:35:43.817067 19975 net.cpp:301] conv3_3_1 needs backward computation.
I0925 21:35:43.817071 19975 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I0925 21:35:43.817075 19975 net.cpp:301] conv3_3_scale0 needs backward computation.
I0925 21:35:43.817080 19975 net.cpp:301] conv3_3_bn0 needs backward computation.
I0925 21:35:43.817085 19975 net.cpp:301] conv3_3_0 needs backward computation.
I0925 21:35:43.817088 19975 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I0925 21:35:43.817093 19975 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I0925 21:35:43.817097 19975 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I0925 21:35:43.817104 19975 net.cpp:301] conv3_2_scale1 needs backward computation.
I0925 21:35:43.817109 19975 net.cpp:301] conv3_2bn1 needs backward computation.
I0925 21:35:43.817113 19975 net.cpp:301] conv3_2_1 needs backward computation.
I0925 21:35:43.817117 19975 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I0925 21:35:43.817122 19975 net.cpp:301] conv3_2_scale0 needs backward computation.
I0925 21:35:43.817126 19975 net.cpp:301] conv3_2_bn0 needs backward computation.
I0925 21:35:43.817131 19975 net.cpp:301] conv3_2_0 needs backward computation.
I0925 21:35:43.817136 19975 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I0925 21:35:43.817140 19975 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I0925 21:35:43.817144 19975 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I0925 21:35:43.817149 19975 net.cpp:301] conv3_1_scale_down needs backward computation.
I0925 21:35:43.817153 19975 net.cpp:301] conv3_1_bn_down needs backward computation.
I0925 21:35:43.817157 19975 net.cpp:301] conv3_1_down needs backward computation.
I0925 21:35:43.817162 19975 net.cpp:301] conv3_1_scale1 needs backward computation.
I0925 21:35:43.817167 19975 net.cpp:301] conv3_1bn1 needs backward computation.
I0925 21:35:43.817170 19975 net.cpp:301] conv3_1_1 needs backward computation.
I0925 21:35:43.817175 19975 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I0925 21:35:43.817179 19975 net.cpp:301] conv3_1_scale0 needs backward computation.
I0925 21:35:43.817183 19975 net.cpp:301] conv3_1_bn0 needs backward computation.
I0925 21:35:43.817188 19975 net.cpp:301] conv3_1_0 needs backward computation.
I0925 21:35:43.817193 19975 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I0925 21:35:43.817196 19975 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I0925 21:35:43.817201 19975 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I0925 21:35:43.817206 19975 net.cpp:301] conv2_3_scale1 needs backward computation.
I0925 21:35:43.817210 19975 net.cpp:301] conv2_3bn1 needs backward computation.
I0925 21:35:43.817214 19975 net.cpp:301] conv2_3_1 needs backward computation.
I0925 21:35:43.817219 19975 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I0925 21:35:43.817224 19975 net.cpp:301] conv2_3_scale0 needs backward computation.
I0925 21:35:43.817227 19975 net.cpp:301] conv2_3_bn0 needs backward computation.
I0925 21:35:43.817231 19975 net.cpp:301] conv2_3_0 needs backward computation.
I0925 21:35:43.817236 19975 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I0925 21:35:43.817241 19975 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I0925 21:35:43.817245 19975 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I0925 21:35:43.817250 19975 net.cpp:301] conv2_2_scale1 needs backward computation.
I0925 21:35:43.817255 19975 net.cpp:301] conv2_2bn1 needs backward computation.
I0925 21:35:43.817265 19975 net.cpp:301] conv2_2_1 needs backward computation.
I0925 21:35:43.817270 19975 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I0925 21:35:43.817277 19975 net.cpp:301] conv2_2_scale0 needs backward computation.
I0925 21:35:43.817281 19975 net.cpp:301] conv2_2_bn0 needs backward computation.
I0925 21:35:43.817286 19975 net.cpp:301] conv2_2_0 needs backward computation.
I0925 21:35:43.817291 19975 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I0925 21:35:43.817294 19975 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I0925 21:35:43.817299 19975 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I0925 21:35:43.817304 19975 net.cpp:301] conv2_1_scale1 needs backward computation.
I0925 21:35:43.817308 19975 net.cpp:301] conv2_1bn1 needs backward computation.
I0925 21:35:43.817312 19975 net.cpp:301] conv2_1_1 needs backward computation.
I0925 21:35:43.817317 19975 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I0925 21:35:43.817320 19975 net.cpp:301] conv2_1_scale0 needs backward computation.
I0925 21:35:43.817324 19975 net.cpp:301] conv2_1_bn0 needs backward computation.
I0925 21:35:43.817328 19975 net.cpp:301] conv2_1_0 needs backward computation.
I0925 21:35:43.817333 19975 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I0925 21:35:43.817338 19975 net.cpp:301] conv1/ReLU needs backward computation.
I0925 21:35:43.817342 19975 net.cpp:301] conv1/scale needs backward computation.
I0925 21:35:43.817346 19975 net.cpp:301] conv1/bn needs backward computation.
I0925 21:35:43.817350 19975 net.cpp:301] conv1 needs backward computation.
I0925 21:35:43.817355 19975 net.cpp:303] label_Data1_1_split does not need backward computation.
I0925 21:35:43.817360 19975 net.cpp:303] Data1 does not need backward computation.
I0925 21:35:43.817364 19975 net.cpp:348] This network produces output Softmax1
I0925 21:35:43.817369 19975 net.cpp:348] This network produces output prob
I0925 21:35:43.817430 19975 net.cpp:363] Network initialization done.
I0925 21:35:43.817764 19975 solver.cpp:110] Solver scaffolding done.
I0925 21:35:43.825706 19975 caffe.cpp:313] Starting Optimization
I0925 21:35:43.825721 19975 solver.cpp:425] Solving ResNet-20
I0925 21:35:43.825726 19975 solver.cpp:427] Learning Rate Policy: multistep
I0925 21:35:43.828810 19975 solver.cpp:514] Iteration 0, Testing net (#0)
I0925 21:35:44.312604 19975 blocking_queue.cpp:49] Waiting for data
I0925 21:35:47.196293 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:35:47.208309 19975 solver.cpp:580]     Test net output #0: Softmax1 = 87.3361 (* 1 = 87.3361 loss)
I0925 21:35:47.208336 19975 solver.cpp:580]     Test net output #1: prob = 1
I0925 21:35:47.307868 19975 solver.cpp:357] Iteration 0 (1.56536e+37 iter/s, 3.48218s/100 iters), loss = 2.71678
I0925 21:35:47.307919 19975 solver.cpp:376]     Train net output #0: Softmax1 = 2.71678 (* 1 = 2.71678 loss)
I0925 21:35:47.307946 19975 sgd_solver.cpp:165] Iteration 0, lr = 0.1
I0925 21:35:57.937214 19975 solver.cpp:357] Iteration 100 (9.40779 iter/s, 10.6295s/100 iters), loss = 1.55696
I0925 21:35:57.937276 19975 solver.cpp:376]     Train net output #0: Softmax1 = 1.55696 (* 1 = 1.55696 loss)
I0925 21:35:57.937288 19975 sgd_solver.cpp:165] Iteration 100, lr = 0.1
I0925 21:36:08.564450 19975 solver.cpp:357] Iteration 200 (9.40966 iter/s, 10.6274s/100 iters), loss = 1.20354
I0925 21:36:08.564519 19975 solver.cpp:376]     Train net output #0: Softmax1 = 1.20354 (* 1 = 1.20354 loss)
I0925 21:36:08.564528 19975 sgd_solver.cpp:165] Iteration 200, lr = 0.1
I0925 21:36:19.192667 19975 solver.cpp:357] Iteration 300 (9.4088 iter/s, 10.6284s/100 iters), loss = 1.25383
I0925 21:36:19.192811 19975 solver.cpp:376]     Train net output #0: Softmax1 = 1.25383 (* 1 = 1.25383 loss)
I0925 21:36:19.192821 19975 sgd_solver.cpp:165] Iteration 300, lr = 0.1
I0925 21:36:28.359372 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:36:29.837311 19975 solver.cpp:357] Iteration 400 (9.39433 iter/s, 10.6447s/100 iters), loss = 1.00269
I0925 21:36:29.837373 19975 solver.cpp:376]     Train net output #0: Softmax1 = 1.00269 (* 1 = 1.00269 loss)
I0925 21:36:29.837381 19975 sgd_solver.cpp:165] Iteration 400, lr = 0.1
I0925 21:36:40.367684 19975 solver.cpp:514] Iteration 500, Testing net (#0)
I0925 21:36:43.675716 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:36:43.687651 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.77118 (* 1 = 2.77118 loss)
I0925 21:36:43.687678 19975 solver.cpp:580]     Test net output #1: prob = 0.2326
I0925 21:36:43.792640 19975 solver.cpp:357] Iteration 500 (7.1656 iter/s, 13.9556s/100 iters), loss = 1.01806
I0925 21:36:43.792682 19975 solver.cpp:376]     Train net output #0: Softmax1 = 1.01806 (* 1 = 1.01806 loss)
I0925 21:36:43.792695 19975 sgd_solver.cpp:165] Iteration 500, lr = 0.1
I0925 21:36:54.420410 19975 solver.cpp:357] Iteration 600 (9.40915 iter/s, 10.628s/100 iters), loss = 0.904904
I0925 21:36:54.420706 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.904904 (* 1 = 0.904904 loss)
I0925 21:36:54.420717 19975 sgd_solver.cpp:165] Iteration 600, lr = 0.1
I0925 21:37:05.046850 19975 solver.cpp:357] Iteration 700 (9.41055 iter/s, 10.6264s/100 iters), loss = 0.767038
I0925 21:37:05.046914 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.767038 (* 1 = 0.767038 loss)
I0925 21:37:05.046926 19975 sgd_solver.cpp:165] Iteration 700, lr = 0.1
I0925 21:37:13.244642 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:37:15.687855 19975 solver.cpp:357] Iteration 800 (9.39746 iter/s, 10.6412s/100 iters), loss = 0.886787
I0925 21:37:15.687918 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.886787 (* 1 = 0.886787 loss)
I0925 21:37:15.687927 19975 sgd_solver.cpp:165] Iteration 800, lr = 0.1
I0925 21:37:26.335790 19975 solver.cpp:357] Iteration 900 (9.39136 iter/s, 10.6481s/100 iters), loss = 0.953446
I0925 21:37:26.336062 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.953446 (* 1 = 0.953446 loss)
I0925 21:37:26.336072 19975 sgd_solver.cpp:165] Iteration 900, lr = 0.1
I0925 21:37:36.891047 19975 solver.cpp:514] Iteration 1000, Testing net (#0)
I0925 21:37:40.147686 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:37:40.166448 19975 solver.cpp:580]     Test net output #0: Softmax1 = 4.71899 (* 1 = 4.71899 loss)
I0925 21:37:40.166476 19975 solver.cpp:580]     Test net output #1: prob = 0.1458
I0925 21:37:40.274248 19975 solver.cpp:357] Iteration 1000 (7.1744 iter/s, 13.9384s/100 iters), loss = 0.751302
I0925 21:37:40.274292 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.751302 (* 1 = 0.751302 loss)
I0925 21:37:40.274305 19975 sgd_solver.cpp:165] Iteration 1000, lr = 0.1
I0925 21:37:50.927409 19975 solver.cpp:357] Iteration 1100 (9.38676 iter/s, 10.6533s/100 iters), loss = 0.700734
I0925 21:37:50.927474 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.700734 (* 1 = 0.700734 loss)
I0925 21:37:50.927485 19975 sgd_solver.cpp:165] Iteration 1100, lr = 0.1
I0925 21:37:58.077881 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:38:01.587132 19975 solver.cpp:357] Iteration 1200 (9.381 iter/s, 10.6598s/100 iters), loss = 0.797029
I0925 21:38:01.587195 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.797029 (* 1 = 0.797029 loss)
I0925 21:38:01.587206 19975 sgd_solver.cpp:165] Iteration 1200, lr = 0.1
I0925 21:38:12.239900 19975 solver.cpp:357] Iteration 1300 (9.38712 iter/s, 10.6529s/100 iters), loss = 0.647383
I0925 21:38:12.239964 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.647383 (* 1 = 0.647383 loss)
I0925 21:38:12.239974 19975 sgd_solver.cpp:165] Iteration 1300, lr = 0.1
I0925 21:38:22.907789 19975 solver.cpp:357] Iteration 1400 (9.37382 iter/s, 10.668s/100 iters), loss = 0.714358
I0925 21:38:22.907853 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.714358 (* 1 = 0.714358 loss)
I0925 21:38:22.907865 19975 sgd_solver.cpp:165] Iteration 1400, lr = 0.1
I0925 21:38:33.465252 19975 solver.cpp:514] Iteration 1500, Testing net (#0)
I0925 21:38:36.726804 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:38:36.738766 19975 solver.cpp:580]     Test net output #0: Softmax1 = 3.7109 (* 1 = 3.7109 loss)
I0925 21:38:36.738793 19975 solver.cpp:580]     Test net output #1: prob = 0.119299
I0925 21:38:36.843993 19975 solver.cpp:357] Iteration 1500 (7.17546 iter/s, 13.9364s/100 iters), loss = 0.653136
I0925 21:38:36.844034 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.653136 (* 1 = 0.653136 loss)
I0925 21:38:36.844044 19975 sgd_solver.cpp:165] Iteration 1500, lr = 0.1
I0925 21:38:43.021203 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:38:47.495179 19975 solver.cpp:357] Iteration 1600 (9.38849 iter/s, 10.6513s/100 iters), loss = 0.638684
I0925 21:38:47.495244 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.638684 (* 1 = 0.638684 loss)
I0925 21:38:47.495255 19975 sgd_solver.cpp:165] Iteration 1600, lr = 0.1
I0925 21:38:58.128619 19975 solver.cpp:357] Iteration 1700 (9.40418 iter/s, 10.6336s/100 iters), loss = 0.779144
I0925 21:38:58.128684 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.779144 (* 1 = 0.779144 loss)
I0925 21:38:58.128695 19975 sgd_solver.cpp:165] Iteration 1700, lr = 0.1
I0925 21:39:08.778242 19975 solver.cpp:357] Iteration 1800 (9.38989 iter/s, 10.6498s/100 iters), loss = 0.776419
I0925 21:39:08.778400 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.776419 (* 1 = 0.776419 loss)
I0925 21:39:08.778410 19975 sgd_solver.cpp:165] Iteration 1800, lr = 0.1
I0925 21:39:19.427116 19975 solver.cpp:357] Iteration 1900 (9.39063 iter/s, 10.6489s/100 iters), loss = 0.624316
I0925 21:39:19.427181 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.624316 (* 1 = 0.624316 loss)
I0925 21:39:19.427191 19975 sgd_solver.cpp:165] Iteration 1900, lr = 0.1
I0925 21:39:24.653631 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:39:29.975992 19975 solver.cpp:514] Iteration 2000, Testing net (#0)
I0925 21:39:33.186483 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:39:33.198863 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.6714 (* 1 = 2.6714 loss)
I0925 21:39:33.198889 19975 solver.cpp:580]     Test net output #1: prob = 0.175
I0925 21:39:33.302925 19975 solver.cpp:357] Iteration 2000 (7.20668 iter/s, 13.876s/100 iters), loss = 0.598879
I0925 21:39:33.302970 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.598879 (* 1 = 0.598879 loss)
I0925 21:39:33.302983 19975 sgd_solver.cpp:165] Iteration 2000, lr = 0.1
I0925 21:39:43.957011 19975 solver.cpp:357] Iteration 2100 (9.38594 iter/s, 10.6542s/100 iters), loss = 0.700031
I0925 21:39:43.957165 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.700031 (* 1 = 0.700031 loss)
I0925 21:39:43.957175 19975 sgd_solver.cpp:165] Iteration 2100, lr = 0.1
I0925 21:39:54.604877 19975 solver.cpp:357] Iteration 2200 (9.39151 iter/s, 10.6479s/100 iters), loss = 0.628693
I0925 21:39:54.604940 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.628693 (* 1 = 0.628693 loss)
I0925 21:39:54.604950 19975 sgd_solver.cpp:165] Iteration 2200, lr = 0.1
I0925 21:40:05.239400 19975 solver.cpp:357] Iteration 2300 (9.40322 iter/s, 10.6347s/100 iters), loss = 0.534908
I0925 21:40:05.239466 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.534908 (* 1 = 0.534908 loss)
I0925 21:40:05.239476 19975 sgd_solver.cpp:165] Iteration 2300, lr = 0.1
I0925 21:40:09.394979 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:40:15.887560 19975 solver.cpp:357] Iteration 2400 (9.39118 iter/s, 10.6483s/100 iters), loss = 0.548588
I0925 21:40:15.887719 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.548588 (* 1 = 0.548588 loss)
I0925 21:40:15.887728 19975 sgd_solver.cpp:165] Iteration 2400, lr = 0.1
I0925 21:40:26.427209 19975 solver.cpp:514] Iteration 2500, Testing net (#0)
I0925 21:40:29.690846 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:40:29.702836 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.24238 (* 1 = 2.24238 loss)
I0925 21:40:29.702860 19975 solver.cpp:580]     Test net output #1: prob = 0.2383
I0925 21:40:29.808163 19975 solver.cpp:357] Iteration 2500 (7.18354 iter/s, 13.9207s/100 iters), loss = 0.608564
I0925 21:40:29.808207 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.608564 (* 1 = 0.608564 loss)
I0925 21:40:29.808220 19975 sgd_solver.cpp:165] Iteration 2500, lr = 0.1
I0925 21:40:40.459580 19975 solver.cpp:357] Iteration 2600 (9.38829 iter/s, 10.6516s/100 iters), loss = 0.852656
I0925 21:40:40.459647 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.852656 (* 1 = 0.852656 loss)
I0925 21:40:40.459656 19975 sgd_solver.cpp:165] Iteration 2600, lr = 0.1
I0925 21:40:51.116477 19975 solver.cpp:357] Iteration 2700 (9.38348 iter/s, 10.657s/100 iters), loss = 0.750302
I0925 21:40:51.116686 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.750302 (* 1 = 0.750302 loss)
I0925 21:40:51.116696 19975 sgd_solver.cpp:165] Iteration 2700, lr = 0.1
I0925 21:40:54.311651 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:41:01.750784 19975 solver.cpp:357] Iteration 2800 (9.40353 iter/s, 10.6343s/100 iters), loss = 0.556297
I0925 21:41:01.750849 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.556297 (* 1 = 0.556297 loss)
I0925 21:41:01.750861 19975 sgd_solver.cpp:165] Iteration 2800, lr = 0.1
I0925 21:41:12.403595 19975 solver.cpp:357] Iteration 2900 (9.38707 iter/s, 10.6529s/100 iters), loss = 0.648041
I0925 21:41:12.403661 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.648041 (* 1 = 0.648041 loss)
I0925 21:41:12.403671 19975 sgd_solver.cpp:165] Iteration 2900, lr = 0.1
I0925 21:41:22.962628 19975 solver.cpp:514] Iteration 3000, Testing net (#0)
I0925 21:41:26.228238 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:41:26.240156 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.09457 (* 1 = 2.09457 loss)
I0925 21:41:26.240183 19975 solver.cpp:580]     Test net output #1: prob = 0.242
I0925 21:41:26.345266 19975 solver.cpp:357] Iteration 3000 (7.17263 iter/s, 13.9419s/100 iters), loss = 0.562108
I0925 21:41:26.345310 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.562108 (* 1 = 0.562108 loss)
I0925 21:41:26.345320 19975 sgd_solver.cpp:165] Iteration 3000, lr = 0.1
I0925 21:41:37.008222 19975 solver.cpp:357] Iteration 3100 (9.37812 iter/s, 10.6631s/100 iters), loss = 0.590756
I0925 21:41:37.008287 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.590756 (* 1 = 0.590756 loss)
I0925 21:41:37.008297 19975 sgd_solver.cpp:165] Iteration 3100, lr = 0.1
I0925 21:41:39.154865 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:41:47.666666 19975 solver.cpp:357] Iteration 3200 (9.38211 iter/s, 10.6586s/100 iters), loss = 0.609079
I0925 21:41:47.666733 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.609079 (* 1 = 0.609079 loss)
I0925 21:41:47.666743 19975 sgd_solver.cpp:165] Iteration 3200, lr = 0.1
I0925 21:41:58.306354 19975 solver.cpp:357] Iteration 3300 (9.39865 iter/s, 10.6398s/100 iters), loss = 0.504521
I0925 21:41:58.306511 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.504521 (* 1 = 0.504521 loss)
I0925 21:41:58.306521 19975 sgd_solver.cpp:165] Iteration 3300, lr = 0.1
I0925 21:42:08.958726 19975 solver.cpp:357] Iteration 3400 (9.38754 iter/s, 10.6524s/100 iters), loss = 0.37929
I0925 21:42:08.958791 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.37929 (* 1 = 0.37929 loss)
I0925 21:42:08.958801 19975 sgd_solver.cpp:165] Iteration 3400, lr = 0.1
I0925 21:42:19.512667 19975 solver.cpp:514] Iteration 3500, Testing net (#0)
I0925 21:42:22.799024 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:42:22.811072 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.65257 (* 1 = 1.65257 loss)
I0925 21:42:22.811098 19975 solver.cpp:580]     Test net output #1: prob = 0.4404
I0925 21:42:22.916002 19975 solver.cpp:357] Iteration 3500 (7.16461 iter/s, 13.9575s/100 iters), loss = 0.665489
I0925 21:42:22.916044 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.665489 (* 1 = 0.665489 loss)
I0925 21:42:22.916055 19975 sgd_solver.cpp:165] Iteration 3500, lr = 0.1
I0925 21:42:24.099963 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:42:33.585765 19975 solver.cpp:357] Iteration 3600 (9.37214 iter/s, 10.6699s/100 iters), loss = 0.685469
I0925 21:42:33.585974 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.685469 (* 1 = 0.685469 loss)
I0925 21:42:33.585984 19975 sgd_solver.cpp:165] Iteration 3600, lr = 0.1
I0925 21:42:44.243326 19975 solver.cpp:357] Iteration 3700 (9.38301 iter/s, 10.6576s/100 iters), loss = 0.429336
I0925 21:42:44.243391 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.429336 (* 1 = 0.429336 loss)
I0925 21:42:44.243400 19975 sgd_solver.cpp:165] Iteration 3700, lr = 0.1
I0925 21:42:54.902263 19975 solver.cpp:357] Iteration 3800 (9.38167 iter/s, 10.6591s/100 iters), loss = 0.403477
I0925 21:42:54.902329 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.403477 (* 1 = 0.403477 loss)
I0925 21:42:54.902338 19975 sgd_solver.cpp:165] Iteration 3800, lr = 0.1
I0925 21:43:05.565459 19975 solver.cpp:357] Iteration 3900 (9.37792 iter/s, 10.6633s/100 iters), loss = 0.634051
I0925 21:43:05.565606 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.634051 (* 1 = 0.634051 loss)
I0925 21:43:05.565616 19975 sgd_solver.cpp:165] Iteration 3900, lr = 0.1
I0925 21:43:05.785037 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:43:16.132046 19975 solver.cpp:514] Iteration 4000, Testing net (#0)
I0925 21:43:19.344630 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:43:19.357090 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.93297 (* 1 = 1.93297 loss)
I0925 21:43:19.357117 19975 solver.cpp:580]     Test net output #1: prob = 0.367199
I0925 21:43:19.462641 19975 solver.cpp:357] Iteration 4000 (7.19563 iter/s, 13.8973s/100 iters), loss = 0.486178
I0925 21:43:19.462684 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.486178 (* 1 = 0.486178 loss)
I0925 21:43:19.462694 19975 sgd_solver.cpp:165] Iteration 4000, lr = 0.1
I0925 21:43:30.116057 19975 solver.cpp:357] Iteration 4100 (9.38651 iter/s, 10.6536s/100 iters), loss = 0.457166
I0925 21:43:30.116122 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.457166 (* 1 = 0.457166 loss)
I0925 21:43:30.116132 19975 sgd_solver.cpp:165] Iteration 4100, lr = 0.1
I0925 21:43:40.775424 19975 solver.cpp:357] Iteration 4200 (9.38129 iter/s, 10.6595s/100 iters), loss = 0.53307
I0925 21:43:40.775575 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.53307 (* 1 = 0.53307 loss)
I0925 21:43:40.775585 19975 sgd_solver.cpp:165] Iteration 4200, lr = 0.1
I0925 21:43:50.585291 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:43:51.433851 19975 solver.cpp:357] Iteration 4300 (9.38219 iter/s, 10.6585s/100 iters), loss = 0.492437
I0925 21:43:51.433914 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.492437 (* 1 = 0.492437 loss)
I0925 21:43:51.433923 19975 sgd_solver.cpp:165] Iteration 4300, lr = 0.1
I0925 21:44:02.100558 19975 solver.cpp:357] Iteration 4400 (9.37483 iter/s, 10.6669s/100 iters), loss = 0.542153
I0925 21:44:02.100615 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.542153 (* 1 = 0.542153 loss)
I0925 21:44:02.100627 19975 sgd_solver.cpp:165] Iteration 4400, lr = 0.1
I0925 21:44:12.657888 19975 solver.cpp:514] Iteration 4500, Testing net (#0)
I0925 21:44:15.935703 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:44:15.947574 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.46976 (* 1 = 1.46976 loss)
I0925 21:44:15.947600 19975 solver.cpp:580]     Test net output #1: prob = 0.523
I0925 21:44:16.052527 19975 solver.cpp:357] Iteration 4500 (7.16733 iter/s, 13.9522s/100 iters), loss = 0.59647
I0925 21:44:16.052572 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.59647 (* 1 = 0.59647 loss)
I0925 21:44:16.052582 19975 sgd_solver.cpp:165] Iteration 4500, lr = 0.1
I0925 21:44:26.703089 19975 solver.cpp:357] Iteration 4600 (9.38903 iter/s, 10.6507s/100 iters), loss = 0.430891
I0925 21:44:26.703155 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.430891 (* 1 = 0.430891 loss)
I0925 21:44:26.703164 19975 sgd_solver.cpp:165] Iteration 4600, lr = 0.1
I0925 21:44:35.554137 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:44:37.362784 19975 solver.cpp:357] Iteration 4700 (9.381 iter/s, 10.6598s/100 iters), loss = 0.37754
I0925 21:44:37.362851 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.37754 (* 1 = 0.37754 loss)
I0925 21:44:37.362861 19975 sgd_solver.cpp:165] Iteration 4700, lr = 0.1
I0925 21:44:48.015908 19975 solver.cpp:357] Iteration 4800 (9.38679 iter/s, 10.6533s/100 iters), loss = 0.431462
I0925 21:44:48.016103 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.431462 (* 1 = 0.431462 loss)
I0925 21:44:48.016113 19975 sgd_solver.cpp:165] Iteration 4800, lr = 0.1
I0925 21:44:58.670680 19975 solver.cpp:357] Iteration 4900 (9.38545 iter/s, 10.6548s/100 iters), loss = 0.505012
I0925 21:44:58.670743 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.505012 (* 1 = 0.505012 loss)
I0925 21:44:58.670754 19975 sgd_solver.cpp:165] Iteration 4900, lr = 0.1
I0925 21:45:09.231940 19975 solver.cpp:514] Iteration 5000, Testing net (#0)
I0925 21:45:12.516299 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:45:12.528946 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.72432 (* 1 = 1.72432 loss)
I0925 21:45:12.528973 19975 solver.cpp:580]     Test net output #1: prob = 0.4818
I0925 21:45:12.634081 19975 solver.cpp:357] Iteration 5000 (7.16146 iter/s, 13.9636s/100 iters), loss = 0.428892
I0925 21:45:12.634124 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.428892 (* 1 = 0.428892 loss)
I0925 21:45:12.634135 19975 sgd_solver.cpp:165] Iteration 5000, lr = 0.1
I0925 21:45:20.528475 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:45:23.299592 19975 solver.cpp:357] Iteration 5100 (9.37586 iter/s, 10.6657s/100 iters), loss = 0.515666
I0925 21:45:23.299656 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.515666 (* 1 = 0.515666 loss)
I0925 21:45:23.299667 19975 sgd_solver.cpp:165] Iteration 5100, lr = 0.1
I0925 21:45:33.964059 19975 solver.cpp:357] Iteration 5200 (9.3768 iter/s, 10.6646s/100 iters), loss = 0.744747
I0925 21:45:33.964124 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.744747 (* 1 = 0.744747 loss)
I0925 21:45:33.964135 19975 sgd_solver.cpp:165] Iteration 5200, lr = 0.1
I0925 21:45:44.618713 19975 solver.cpp:357] Iteration 5300 (9.38544 iter/s, 10.6548s/100 iters), loss = 0.575559
I0925 21:45:44.618777 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.575559 (* 1 = 0.575559 loss)
I0925 21:45:44.618788 19975 sgd_solver.cpp:165] Iteration 5300, lr = 0.1
I0925 21:45:55.280017 19975 solver.cpp:357] Iteration 5400 (9.37958 iter/s, 10.6615s/100 iters), loss = 0.380392
I0925 21:45:55.280122 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.380392 (* 1 = 0.380392 loss)
I0925 21:45:55.280133 19975 sgd_solver.cpp:165] Iteration 5400, lr = 0.1
I0925 21:46:02.110294 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:46:05.822125 19975 solver.cpp:514] Iteration 5500, Testing net (#0)
I0925 21:46:09.038503 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:46:09.051100 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.25471 (* 1 = 1.25471 loss)
I0925 21:46:09.051126 19975 solver.cpp:580]     Test net output #1: prob = 0.5939
I0925 21:46:09.156654 19975 solver.cpp:357] Iteration 5500 (7.20626 iter/s, 13.8768s/100 iters), loss = 0.400109
I0925 21:46:09.156697 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.400109 (* 1 = 0.400109 loss)
I0925 21:46:09.156708 19975 sgd_solver.cpp:165] Iteration 5500, lr = 0.1
I0925 21:46:19.824384 19975 solver.cpp:357] Iteration 5600 (9.37391 iter/s, 10.6679s/100 iters), loss = 0.465697
I0925 21:46:19.824450 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.465697 (* 1 = 0.465697 loss)
I0925 21:46:19.824458 19975 sgd_solver.cpp:165] Iteration 5600, lr = 0.1
I0925 21:46:30.492449 19975 solver.cpp:357] Iteration 5700 (9.37363 iter/s, 10.6682s/100 iters), loss = 0.481506
I0925 21:46:30.492655 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.481506 (* 1 = 0.481506 loss)
I0925 21:46:30.492666 19975 sgd_solver.cpp:165] Iteration 5700, lr = 0.1
I0925 21:46:41.150168 19975 solver.cpp:357] Iteration 5800 (9.38286 iter/s, 10.6577s/100 iters), loss = 0.369022
I0925 21:46:41.150233 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.369022 (* 1 = 0.369022 loss)
I0925 21:46:41.150241 19975 sgd_solver.cpp:165] Iteration 5800, lr = 0.1
I0925 21:46:47.021956 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:46:51.797389 19975 solver.cpp:357] Iteration 5900 (9.39198 iter/s, 10.6474s/100 iters), loss = 0.626044
I0925 21:46:51.797452 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.626044 (* 1 = 0.626044 loss)
I0925 21:46:51.797463 19975 sgd_solver.cpp:165] Iteration 5900, lr = 0.1
I0925 21:47:02.352150 19975 solver.cpp:514] Iteration 6000, Testing net (#0)
I0925 21:47:05.626039 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:47:05.638139 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.26726 (* 1 = 2.26726 loss)
I0925 21:47:05.638165 19975 solver.cpp:580]     Test net output #1: prob = 0.4503
I0925 21:47:05.743021 19975 solver.cpp:357] Iteration 6000 (7.17058 iter/s, 13.9459s/100 iters), loss = 0.511902
I0925 21:47:05.743065 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.511902 (* 1 = 0.511902 loss)
I0925 21:47:05.743077 19975 sgd_solver.cpp:165] Iteration 6000, lr = 0.1
I0925 21:47:16.393858 19975 solver.cpp:357] Iteration 6100 (9.38878 iter/s, 10.651s/100 iters), loss = 0.472751
I0925 21:47:16.393923 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.472751 (* 1 = 0.472751 loss)
I0925 21:47:16.393931 19975 sgd_solver.cpp:165] Iteration 6100, lr = 0.1
I0925 21:47:27.048933 19975 solver.cpp:357] Iteration 6200 (9.38506 iter/s, 10.6552s/100 iters), loss = 0.407953
I0925 21:47:27.049000 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.407953 (* 1 = 0.407953 loss)
I0925 21:47:27.049010 19975 sgd_solver.cpp:165] Iteration 6200, lr = 0.1
I0925 21:47:31.848258 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:47:37.706243 19975 solver.cpp:357] Iteration 6300 (9.38309 iter/s, 10.6575s/100 iters), loss = 0.475256
I0925 21:47:37.706387 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.475256 (* 1 = 0.475256 loss)
I0925 21:47:37.706398 19975 sgd_solver.cpp:165] Iteration 6300, lr = 0.1
I0925 21:47:48.351351 19975 solver.cpp:357] Iteration 6400 (9.39392 iter/s, 10.6452s/100 iters), loss = 0.6248
I0925 21:47:48.351413 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.6248 (* 1 = 0.6248 loss)
I0925 21:47:48.351423 19975 sgd_solver.cpp:165] Iteration 6400, lr = 0.1
I0925 21:47:58.900804 19975 solver.cpp:514] Iteration 6500, Testing net (#0)
I0925 21:48:02.169726 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:48:02.182212 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.76709 (* 1 = 0.76709 loss)
I0925 21:48:02.182240 19975 solver.cpp:580]     Test net output #1: prob = 0.7343
I0925 21:48:02.288410 19975 solver.cpp:357] Iteration 6500 (7.17499 iter/s, 13.9373s/100 iters), loss = 0.45632
I0925 21:48:02.288457 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.45632 (* 1 = 0.45632 loss)
I0925 21:48:02.288467 19975 sgd_solver.cpp:165] Iteration 6500, lr = 0.1
I0925 21:48:12.948844 19975 solver.cpp:357] Iteration 6600 (9.38033 iter/s, 10.6606s/100 iters), loss = 0.405299
I0925 21:48:12.949002 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.405299 (* 1 = 0.405299 loss)
I0925 21:48:12.949012 19975 sgd_solver.cpp:165] Iteration 6600, lr = 0.1
I0925 21:48:16.794539 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:48:23.605162 19975 solver.cpp:357] Iteration 6700 (9.38404 iter/s, 10.6564s/100 iters), loss = 0.469553
I0925 21:48:23.605226 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.469553 (* 1 = 0.469553 loss)
I0925 21:48:23.605235 19975 sgd_solver.cpp:165] Iteration 6700, lr = 0.1
I0925 21:48:34.276160 19975 solver.cpp:357] Iteration 6800 (9.37105 iter/s, 10.6712s/100 iters), loss = 0.428481
I0925 21:48:34.276222 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.428481 (* 1 = 0.428481 loss)
I0925 21:48:34.276232 19975 sgd_solver.cpp:165] Iteration 6800, lr = 0.1
I0925 21:48:44.927155 19975 solver.cpp:357] Iteration 6900 (9.38865 iter/s, 10.6512s/100 iters), loss = 0.511065
I0925 21:48:44.927314 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.511065 (* 1 = 0.511065 loss)
I0925 21:48:44.927323 19975 sgd_solver.cpp:165] Iteration 6900, lr = 0.1
I0925 21:48:55.478744 19975 solver.cpp:514] Iteration 7000, Testing net (#0)
I0925 21:48:58.737771 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:48:58.757371 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.08769 (* 1 = 2.08769 loss)
I0925 21:48:58.757397 19975 solver.cpp:580]     Test net output #1: prob = 0.4915
I0925 21:48:58.862576 19975 solver.cpp:357] Iteration 7000 (7.17589 iter/s, 13.9356s/100 iters), loss = 0.476574
I0925 21:48:58.862622 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.476574 (* 1 = 0.476574 loss)
I0925 21:48:58.862632 19975 sgd_solver.cpp:165] Iteration 7000, lr = 0.1
I0925 21:49:01.746769 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:49:09.517405 19975 solver.cpp:357] Iteration 7100 (9.38526 iter/s, 10.655s/100 iters), loss = 0.484109
I0925 21:49:09.517469 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.484109 (* 1 = 0.484109 loss)
I0925 21:49:09.517478 19975 sgd_solver.cpp:165] Iteration 7100, lr = 0.1
I0925 21:49:20.181193 19975 solver.cpp:357] Iteration 7200 (9.37739 iter/s, 10.6639s/100 iters), loss = 0.556386
I0925 21:49:20.181354 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.556386 (* 1 = 0.556386 loss)
I0925 21:49:20.181362 19975 sgd_solver.cpp:165] Iteration 7200, lr = 0.1
I0925 21:49:30.838812 19975 solver.cpp:357] Iteration 7300 (9.3829 iter/s, 10.6577s/100 iters), loss = 0.419356
I0925 21:49:30.838876 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.419356 (* 1 = 0.419356 loss)
I0925 21:49:30.838886 19975 sgd_solver.cpp:165] Iteration 7300, lr = 0.1
I0925 21:49:41.498216 19975 solver.cpp:357] Iteration 7400 (9.38124 iter/s, 10.6596s/100 iters), loss = 0.528677
I0925 21:49:41.498281 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.528677 (* 1 = 0.528677 loss)
I0925 21:49:41.498291 19975 sgd_solver.cpp:165] Iteration 7400, lr = 0.1
I0925 21:49:43.325175 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:49:52.053031 19975 solver.cpp:514] Iteration 7500, Testing net (#0)
I0925 21:49:55.282140 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:49:55.294745 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.17111 (* 1 = 2.17111 loss)
I0925 21:49:55.294772 19975 solver.cpp:580]     Test net output #1: prob = 0.444
I0925 21:49:55.399710 19975 solver.cpp:357] Iteration 7500 (7.19335 iter/s, 13.9017s/100 iters), loss = 0.389626
I0925 21:49:55.399754 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.389626 (* 1 = 0.389626 loss)
I0925 21:49:55.399763 19975 sgd_solver.cpp:165] Iteration 7500, lr = 0.1
I0925 21:50:06.063488 19975 solver.cpp:357] Iteration 7600 (9.37738 iter/s, 10.664s/100 iters), loss = 0.476957
I0925 21:50:06.063551 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.476957 (* 1 = 0.476957 loss)
I0925 21:50:06.063562 19975 sgd_solver.cpp:165] Iteration 7600, lr = 0.1
I0925 21:50:16.731516 19975 solver.cpp:357] Iteration 7700 (9.37366 iter/s, 10.6682s/100 iters), loss = 0.412816
I0925 21:50:16.731580 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.412816 (* 1 = 0.412816 loss)
I0925 21:50:16.731590 19975 sgd_solver.cpp:165] Iteration 7700, lr = 0.1
I0925 21:50:27.386596 19975 solver.cpp:357] Iteration 7800 (9.38505 iter/s, 10.6552s/100 iters), loss = 0.486325
I0925 21:50:27.386797 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.486325 (* 1 = 0.486325 loss)
I0925 21:50:27.386807 19975 sgd_solver.cpp:165] Iteration 7800, lr = 0.1
I0925 21:50:28.242894 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:50:38.039420 19975 solver.cpp:357] Iteration 7900 (9.38716 iter/s, 10.6529s/100 iters), loss = 0.481162
I0925 21:50:38.039484 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.481162 (* 1 = 0.481162 loss)
I0925 21:50:38.039494 19975 sgd_solver.cpp:165] Iteration 7900, lr = 0.1
I0925 21:50:48.587699 19975 solver.cpp:514] Iteration 8000, Testing net (#0)
I0925 21:50:51.788347 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:50:51.800402 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.676737 (* 1 = 0.676737 loss)
I0925 21:50:51.800428 19975 solver.cpp:580]     Test net output #1: prob = 0.770001
I0925 21:50:51.904969 19975 solver.cpp:357] Iteration 8000 (7.21199 iter/s, 13.8658s/100 iters), loss = 0.380514
I0925 21:50:51.905012 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.380514 (* 1 = 0.380514 loss)
I0925 21:50:51.905025 19975 sgd_solver.cpp:165] Iteration 8000, lr = 0.1
I0925 21:51:02.578538 19975 solver.cpp:357] Iteration 8100 (9.36878 iter/s, 10.6738s/100 iters), loss = 0.411712
I0925 21:51:02.578642 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.411712 (* 1 = 0.411712 loss)
I0925 21:51:02.578652 19975 sgd_solver.cpp:165] Iteration 8100, lr = 0.1
I0925 21:51:13.134354 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:51:13.237903 19975 solver.cpp:357] Iteration 8200 (9.38131 iter/s, 10.6595s/100 iters), loss = 0.448357
I0925 21:51:13.237956 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.448357 (* 1 = 0.448357 loss)
I0925 21:51:13.237964 19975 sgd_solver.cpp:165] Iteration 8200, lr = 0.1
I0925 21:51:23.907513 19975 solver.cpp:357] Iteration 8300 (9.37226 iter/s, 10.6698s/100 iters), loss = 0.540072
I0925 21:51:23.907577 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.540072 (* 1 = 0.540072 loss)
I0925 21:51:23.907589 19975 sgd_solver.cpp:165] Iteration 8300, lr = 0.1
I0925 21:51:34.559005 19975 solver.cpp:357] Iteration 8400 (9.38821 iter/s, 10.6517s/100 iters), loss = 0.473153
I0925 21:51:34.559151 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.473153 (* 1 = 0.473153 loss)
I0925 21:51:34.559160 19975 sgd_solver.cpp:165] Iteration 8400, lr = 0.1
I0925 21:51:45.116571 19975 solver.cpp:514] Iteration 8500, Testing net (#0)
I0925 21:51:48.396411 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:51:48.408365 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.2645 (* 1 = 1.2645 loss)
I0925 21:51:48.408392 19975 solver.cpp:580]     Test net output #1: prob = 0.6173
I0925 21:51:48.513576 19975 solver.cpp:357] Iteration 8500 (7.16603 iter/s, 13.9547s/100 iters), loss = 0.438758
I0925 21:51:48.513620 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.438758 (* 1 = 0.438758 loss)
I0925 21:51:48.513630 19975 sgd_solver.cpp:165] Iteration 8500, lr = 0.1
I0925 21:51:58.020594 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:51:59.188170 19975 solver.cpp:357] Iteration 8600 (9.36788 iter/s, 10.6748s/100 iters), loss = 0.480529
I0925 21:51:59.188233 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.480529 (* 1 = 0.480529 loss)
I0925 21:51:59.188242 19975 sgd_solver.cpp:165] Iteration 8600, lr = 0.1
I0925 21:52:09.851423 19975 solver.cpp:357] Iteration 8700 (9.37785 iter/s, 10.6634s/100 iters), loss = 0.527059
I0925 21:52:09.851574 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.527059 (* 1 = 0.527059 loss)
I0925 21:52:09.851586 19975 sgd_solver.cpp:165] Iteration 8700, lr = 0.1
I0925 21:52:20.517802 19975 solver.cpp:357] Iteration 8800 (9.37518 iter/s, 10.6665s/100 iters), loss = 0.523326
I0925 21:52:20.517865 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.523326 (* 1 = 0.523326 loss)
I0925 21:52:20.517874 19975 sgd_solver.cpp:165] Iteration 8800, lr = 0.1
I0925 21:52:31.186882 19975 solver.cpp:357] Iteration 8900 (9.37274 iter/s, 10.6692s/100 iters), loss = 0.484352
I0925 21:52:31.186947 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.484352 (* 1 = 0.484352 loss)
I0925 21:52:31.186959 19975 sgd_solver.cpp:165] Iteration 8900, lr = 0.1
I0925 21:52:39.718677 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:52:41.738739 19975 solver.cpp:514] Iteration 9000, Testing net (#0)
I0925 21:52:45.007588 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:52:45.020169 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.44281 (* 1 = 1.44281 loss)
I0925 21:52:45.020195 19975 solver.cpp:580]     Test net output #1: prob = 0.6091
I0925 21:52:45.125018 19975 solver.cpp:357] Iteration 9000 (7.17443 iter/s, 13.9384s/100 iters), loss = 0.326804
I0925 21:52:45.125062 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.326804 (* 1 = 0.326804 loss)
I0925 21:52:45.125074 19975 sgd_solver.cpp:165] Iteration 9000, lr = 0.1
I0925 21:52:55.799700 19975 solver.cpp:357] Iteration 9100 (9.3678 iter/s, 10.6749s/100 iters), loss = 0.536545
I0925 21:52:55.799763 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.536545 (* 1 = 0.536545 loss)
I0925 21:52:55.799773 19975 sgd_solver.cpp:165] Iteration 9100, lr = 0.1
I0925 21:53:06.467254 19975 solver.cpp:357] Iteration 9200 (9.37407 iter/s, 10.6677s/100 iters), loss = 0.359799
I0925 21:53:06.467320 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.359799 (* 1 = 0.359799 loss)
I0925 21:53:06.467329 19975 sgd_solver.cpp:165] Iteration 9200, lr = 0.1
I0925 21:53:17.130360 19975 solver.cpp:357] Iteration 9300 (9.37799 iter/s, 10.6633s/100 iters), loss = 0.391137
I0925 21:53:17.130488 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.391137 (* 1 = 0.391137 loss)
I0925 21:53:17.130502 19975 sgd_solver.cpp:165] Iteration 9300, lr = 0.1
I0925 21:53:24.607735 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:53:27.794005 19975 solver.cpp:357] Iteration 9400 (9.37757 iter/s, 10.6637s/100 iters), loss = 0.531964
I0925 21:53:27.794070 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.531964 (* 1 = 0.531964 loss)
I0925 21:53:27.794078 19975 sgd_solver.cpp:165] Iteration 9400, lr = 0.1
I0925 21:53:38.340726 19975 solver.cpp:514] Iteration 9500, Testing net (#0)
I0925 21:53:41.541661 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:53:41.562996 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.24448 (* 1 = 1.24448 loss)
I0925 21:53:41.563067 19975 solver.cpp:580]     Test net output #1: prob = 0.602601
I0925 21:53:41.668016 19975 solver.cpp:357] Iteration 9500 (7.20759 iter/s, 13.8743s/100 iters), loss = 0.50458
I0925 21:53:41.668059 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.50458 (* 1 = 0.50458 loss)
I0925 21:53:41.668072 19975 sgd_solver.cpp:165] Iteration 9500, lr = 0.1
I0925 21:53:52.319466 19975 solver.cpp:357] Iteration 9600 (9.38823 iter/s, 10.6516s/100 iters), loss = 0.518035
I0925 21:53:52.319620 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.518035 (* 1 = 0.518035 loss)
I0925 21:53:52.319629 19975 sgd_solver.cpp:165] Iteration 9600, lr = 0.1
I0925 21:54:02.972306 19975 solver.cpp:357] Iteration 9700 (9.3871 iter/s, 10.6529s/100 iters), loss = 0.353641
I0925 21:54:02.972370 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.353641 (* 1 = 0.353641 loss)
I0925 21:54:02.972380 19975 sgd_solver.cpp:165] Iteration 9700, lr = 0.1
I0925 21:54:09.501415 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:54:13.656155 19975 solver.cpp:357] Iteration 9800 (9.35978 iter/s, 10.684s/100 iters), loss = 0.423057
I0925 21:54:13.656219 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.423057 (* 1 = 0.423057 loss)
I0925 21:54:13.656227 19975 sgd_solver.cpp:165] Iteration 9800, lr = 0.1
I0925 21:54:24.319645 19975 solver.cpp:357] Iteration 9900 (9.37764 iter/s, 10.6637s/100 iters), loss = 0.366949
I0925 21:54:24.319803 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.366949 (* 1 = 0.366949 loss)
I0925 21:54:24.319813 19975 sgd_solver.cpp:165] Iteration 9900, lr = 0.1
I0925 21:54:34.873035 19975 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_10000.caffemodel
I0925 21:54:34.887996 19975 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_10000.solverstate
I0925 21:54:34.890996 19975 solver.cpp:514] Iteration 10000, Testing net (#0)
I0925 21:54:38.107744 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:54:38.119462 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.12131 (* 1 = 2.12131 loss)
I0925 21:54:38.119488 19975 solver.cpp:580]     Test net output #1: prob = 0.4916
I0925 21:54:38.223549 19975 solver.cpp:357] Iteration 10000 (7.19214 iter/s, 13.9041s/100 iters), loss = 0.519148
I0925 21:54:38.223593 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.519148 (* 1 = 0.519148 loss)
I0925 21:54:38.223603 19975 sgd_solver.cpp:165] Iteration 10000, lr = 0.1
I0925 21:54:48.883888 19975 solver.cpp:357] Iteration 10100 (9.3804 iter/s, 10.6605s/100 iters), loss = 0.424196
I0925 21:54:48.883951 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.424196 (* 1 = 0.424196 loss)
I0925 21:54:48.883962 19975 sgd_solver.cpp:165] Iteration 10100, lr = 0.1
I0925 21:54:54.432379 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:54:59.542552 19975 solver.cpp:357] Iteration 10200 (9.38189 iter/s, 10.6588s/100 iters), loss = 0.387897
I0925 21:54:59.542616 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.387897 (* 1 = 0.387897 loss)
I0925 21:54:59.542625 19975 sgd_solver.cpp:165] Iteration 10200, lr = 0.1
I0925 21:55:10.193037 19975 solver.cpp:357] Iteration 10300 (9.3891 iter/s, 10.6507s/100 iters), loss = 0.386434
I0925 21:55:10.193102 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.386434 (* 1 = 0.386434 loss)
I0925 21:55:10.193114 19975 sgd_solver.cpp:165] Iteration 10300, lr = 0.1
I0925 21:55:20.846629 19975 solver.cpp:357] Iteration 10400 (9.38636 iter/s, 10.6538s/100 iters), loss = 0.512897
I0925 21:55:20.846693 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.512897 (* 1 = 0.512897 loss)
I0925 21:55:20.846704 19975 sgd_solver.cpp:165] Iteration 10400, lr = 0.1
I0925 21:55:31.408571 19975 solver.cpp:514] Iteration 10500, Testing net (#0)
I0925 21:55:34.576421 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:55:34.588201 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.939599 (* 1 = 0.939599 loss)
I0925 21:55:34.588227 19975 solver.cpp:580]     Test net output #1: prob = 0.6867
I0925 21:55:34.694113 19975 solver.cpp:357] Iteration 10500 (7.2214 iter/s, 13.8477s/100 iters), loss = 0.510258
I0925 21:55:34.694156 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.510258 (* 1 = 0.510258 loss)
I0925 21:55:34.694166 19975 sgd_solver.cpp:165] Iteration 10500, lr = 0.1
I0925 21:55:39.181735 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:55:45.347971 19975 solver.cpp:357] Iteration 10600 (9.38611 iter/s, 10.654s/100 iters), loss = 0.479766
I0925 21:55:45.348034 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.479766 (* 1 = 0.479766 loss)
I0925 21:55:45.348045 19975 sgd_solver.cpp:165] Iteration 10600, lr = 0.1
I0925 21:55:56.012892 19975 solver.cpp:357] Iteration 10700 (9.37639 iter/s, 10.6651s/100 iters), loss = 0.405533
I0925 21:55:56.012957 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.405533 (* 1 = 0.405533 loss)
I0925 21:55:56.012966 19975 sgd_solver.cpp:165] Iteration 10700, lr = 0.1
I0925 21:56:06.669677 19975 solver.cpp:357] Iteration 10800 (9.38355 iter/s, 10.657s/100 iters), loss = 0.397024
I0925 21:56:06.669891 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.397024 (* 1 = 0.397024 loss)
I0925 21:56:06.669903 19975 sgd_solver.cpp:165] Iteration 10800, lr = 0.1
I0925 21:56:17.336000 19975 solver.cpp:357] Iteration 10900 (9.37526 iter/s, 10.6664s/100 iters), loss = 0.412175
I0925 21:56:17.336063 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.412175 (* 1 = 0.412175 loss)
I0925 21:56:17.336074 19975 sgd_solver.cpp:165] Iteration 10900, lr = 0.1
I0925 21:56:20.857046 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:56:27.886099 19975 solver.cpp:514] Iteration 11000, Testing net (#0)
I0925 21:56:31.091619 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:56:31.103596 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.884853 (* 1 = 0.884853 loss)
I0925 21:56:31.103623 19975 solver.cpp:580]     Test net output #1: prob = 0.7163
I0925 21:56:31.208680 19975 solver.cpp:357] Iteration 11000 (7.20828 iter/s, 13.8729s/100 iters), loss = 0.335011
I0925 21:56:31.208724 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.335011 (* 1 = 0.335011 loss)
I0925 21:56:31.208736 19975 sgd_solver.cpp:165] Iteration 11000, lr = 0.1
I0925 21:56:41.859040 19975 solver.cpp:357] Iteration 11100 (9.38919 iter/s, 10.6505s/100 iters), loss = 0.399172
I0925 21:56:41.859196 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.399172 (* 1 = 0.399172 loss)
I0925 21:56:41.859205 19975 sgd_solver.cpp:165] Iteration 11100, lr = 0.1
I0925 21:56:52.524170 19975 solver.cpp:357] Iteration 11200 (9.37628 iter/s, 10.6652s/100 iters), loss = 0.35979
I0925 21:56:52.524237 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.35979 (* 1 = 0.35979 loss)
I0925 21:56:52.524247 19975 sgd_solver.cpp:165] Iteration 11200, lr = 0.1
I0925 21:57:03.190806 19975 solver.cpp:357] Iteration 11300 (9.37488 iter/s, 10.6668s/100 iters), loss = 0.436266
I0925 21:57:03.190874 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.436266 (* 1 = 0.436266 loss)
I0925 21:57:03.190886 19975 sgd_solver.cpp:165] Iteration 11300, lr = 0.1
I0925 21:57:05.750566 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:57:13.842757 19975 solver.cpp:357] Iteration 11400 (9.3878 iter/s, 10.6521s/100 iters), loss = 0.472044
I0925 21:57:13.842864 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.472044 (* 1 = 0.472044 loss)
I0925 21:57:13.842875 19975 sgd_solver.cpp:165] Iteration 11400, lr = 0.1
I0925 21:57:24.397373 19975 solver.cpp:514] Iteration 11500, Testing net (#0)
I0925 21:57:27.580235 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:57:27.592182 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.15255 (* 1 = 1.15255 loss)
I0925 21:57:27.592209 19975 solver.cpp:580]     Test net output #1: prob = 0.6512
I0925 21:57:27.697679 19975 solver.cpp:357] Iteration 11500 (7.21754 iter/s, 13.8551s/100 iters), loss = 0.610044
I0925 21:57:27.697722 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.610044 (* 1 = 0.610044 loss)
I0925 21:57:27.697732 19975 sgd_solver.cpp:165] Iteration 11500, lr = 0.1
I0925 21:57:38.353691 19975 solver.cpp:357] Iteration 11600 (9.38421 iter/s, 10.6562s/100 iters), loss = 0.411007
I0925 21:57:38.353755 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.411007 (* 1 = 0.411007 loss)
I0925 21:57:38.353765 19975 sgd_solver.cpp:165] Iteration 11600, lr = 0.1
I0925 21:57:48.995393 19975 solver.cpp:357] Iteration 11700 (9.39684 iter/s, 10.6419s/100 iters), loss = 0.372985
I0925 21:57:48.995548 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.372985 (* 1 = 0.372985 loss)
I0925 21:57:48.995558 19975 sgd_solver.cpp:165] Iteration 11700, lr = 0.1
I0925 21:57:50.497668 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:57:59.638905 19975 solver.cpp:357] Iteration 11800 (9.39532 iter/s, 10.6436s/100 iters), loss = 0.596937
I0925 21:57:59.638972 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.596937 (* 1 = 0.596937 loss)
I0925 21:57:59.638980 19975 sgd_solver.cpp:165] Iteration 11800, lr = 0.1
I0925 21:58:10.298354 19975 solver.cpp:357] Iteration 11900 (9.3812 iter/s, 10.6596s/100 iters), loss = 0.435469
I0925 21:58:10.298420 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.435469 (* 1 = 0.435469 loss)
I0925 21:58:10.298431 19975 sgd_solver.cpp:165] Iteration 11900, lr = 0.1
I0925 21:58:20.858860 19975 solver.cpp:514] Iteration 12000, Testing net (#0)
I0925 21:58:24.077109 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:58:24.089061 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.915904 (* 1 = 0.915904 loss)
I0925 21:58:24.089087 19975 solver.cpp:580]     Test net output #1: prob = 0.7194
I0925 21:58:24.195715 19975 solver.cpp:357] Iteration 12000 (7.19548 iter/s, 13.8976s/100 iters), loss = 0.519622
I0925 21:58:24.195758 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.519622 (* 1 = 0.519622 loss)
I0925 21:58:24.195771 19975 sgd_solver.cpp:165] Iteration 12000, lr = 0.1
I0925 21:58:34.861421 19975 solver.cpp:357] Iteration 12100 (9.37568 iter/s, 10.6659s/100 iters), loss = 0.444657
I0925 21:58:34.861486 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.444657 (* 1 = 0.444657 loss)
I0925 21:58:34.861496 19975 sgd_solver.cpp:165] Iteration 12100, lr = 0.1
I0925 21:58:35.401819 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:58:45.526491 19975 solver.cpp:357] Iteration 12200 (9.37625 iter/s, 10.6652s/100 iters), loss = 0.460573
I0925 21:58:45.526556 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.460573 (* 1 = 0.460573 loss)
I0925 21:58:45.526566 19975 sgd_solver.cpp:165] Iteration 12200, lr = 0.1
I0925 21:58:56.186400 19975 solver.cpp:357] Iteration 12300 (9.38079 iter/s, 10.6601s/100 iters), loss = 0.339581
I0925 21:58:56.186568 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.339581 (* 1 = 0.339581 loss)
I0925 21:58:56.186578 19975 sgd_solver.cpp:165] Iteration 12300, lr = 0.1
I0925 21:59:06.843623 19975 solver.cpp:357] Iteration 12400 (9.38325 iter/s, 10.6573s/100 iters), loss = 0.496228
I0925 21:59:06.843688 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.496228 (* 1 = 0.496228 loss)
I0925 21:59:06.843699 19975 sgd_solver.cpp:165] Iteration 12400, lr = 0.1
I0925 21:59:16.979501 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:59:17.394495 19975 solver.cpp:514] Iteration 12500, Testing net (#0)
I0925 21:59:20.606410 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 21:59:20.618420 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.30938 (* 1 = 1.30938 loss)
I0925 21:59:20.618448 19975 solver.cpp:580]     Test net output #1: prob = 0.6172
I0925 21:59:20.723690 19975 solver.cpp:357] Iteration 12500 (7.20444 iter/s, 13.8803s/100 iters), loss = 0.425723
I0925 21:59:20.723733 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.425723 (* 1 = 0.425723 loss)
I0925 21:59:20.723745 19975 sgd_solver.cpp:165] Iteration 12500, lr = 0.1
I0925 21:59:31.385433 19975 solver.cpp:357] Iteration 12600 (9.37916 iter/s, 10.6619s/100 iters), loss = 0.505566
I0925 21:59:31.385589 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.505566 (* 1 = 0.505566 loss)
I0925 21:59:31.385598 19975 sgd_solver.cpp:165] Iteration 12600, lr = 0.1
I0925 21:59:42.036581 19975 solver.cpp:357] Iteration 12700 (9.38859 iter/s, 10.6512s/100 iters), loss = 0.595479
I0925 21:59:42.036648 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.595479 (* 1 = 0.595479 loss)
I0925 21:59:42.036658 19975 sgd_solver.cpp:165] Iteration 12700, lr = 0.1
I0925 21:59:52.693050 19975 solver.cpp:357] Iteration 12800 (9.38382 iter/s, 10.6566s/100 iters), loss = 0.467848
I0925 21:59:52.693114 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.467848 (* 1 = 0.467848 loss)
I0925 21:59:52.693123 19975 sgd_solver.cpp:165] Iteration 12800, lr = 0.1
I0925 22:00:01.864315 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:00:03.345171 19975 solver.cpp:357] Iteration 12900 (9.38765 iter/s, 10.6523s/100 iters), loss = 0.455052
I0925 22:00:03.345237 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.455052 (* 1 = 0.455052 loss)
I0925 22:00:03.345247 19975 sgd_solver.cpp:165] Iteration 12900, lr = 0.1
I0925 22:00:13.892834 19975 solver.cpp:514] Iteration 13000, Testing net (#0)
I0925 22:00:17.122962 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:00:17.135779 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.26182 (* 1 = 1.26182 loss)
I0925 22:00:17.135807 19975 solver.cpp:580]     Test net output #1: prob = 0.6152
I0925 22:00:17.240576 19975 solver.cpp:357] Iteration 13000 (7.19649 iter/s, 13.8957s/100 iters), loss = 0.337179
I0925 22:00:17.240622 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.337179 (* 1 = 0.337179 loss)
I0925 22:00:17.240633 19975 sgd_solver.cpp:165] Iteration 13000, lr = 0.1
I0925 22:00:27.904458 19975 solver.cpp:357] Iteration 13100 (9.37728 iter/s, 10.6641s/100 iters), loss = 0.331755
I0925 22:00:27.904522 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.331755 (* 1 = 0.331755 loss)
I0925 22:00:27.904532 19975 sgd_solver.cpp:165] Iteration 13100, lr = 0.1
I0925 22:00:38.559108 19975 solver.cpp:357] Iteration 13200 (9.38542 iter/s, 10.6548s/100 iters), loss = 0.346064
I0925 22:00:38.559370 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.346064 (* 1 = 0.346064 loss)
I0925 22:00:38.559379 19975 sgd_solver.cpp:165] Iteration 13200, lr = 0.1
I0925 22:00:46.771113 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:00:49.220927 19975 solver.cpp:357] Iteration 13300 (9.37928 iter/s, 10.6618s/100 iters), loss = 0.48899
I0925 22:00:49.220993 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.48899 (* 1 = 0.48899 loss)
I0925 22:00:49.221001 19975 sgd_solver.cpp:165] Iteration 13300, lr = 0.1
I0925 22:00:59.889561 19975 solver.cpp:357] Iteration 13400 (9.37312 iter/s, 10.6688s/100 iters), loss = 0.591528
I0925 22:00:59.889626 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.591528 (* 1 = 0.591528 loss)
I0925 22:00:59.889637 19975 sgd_solver.cpp:165] Iteration 13400, lr = 0.1
I0925 22:01:10.450376 19975 solver.cpp:514] Iteration 13500, Testing net (#0)
I0925 22:01:13.642722 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:01:13.655392 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.15609 (* 1 = 1.15609 loss)
I0925 22:01:13.655418 19975 solver.cpp:580]     Test net output #1: prob = 0.6456
I0925 22:01:13.759891 19975 solver.cpp:357] Iteration 13500 (7.2095 iter/s, 13.8706s/100 iters), loss = 0.449859
I0925 22:01:13.759935 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.449859 (* 1 = 0.449859 loss)
I0925 22:01:13.759948 19975 sgd_solver.cpp:165] Iteration 13500, lr = 0.1
I0925 22:01:24.421718 19975 solver.cpp:357] Iteration 13600 (9.37909 iter/s, 10.662s/100 iters), loss = 0.315436
I0925 22:01:24.421778 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.315436 (* 1 = 0.315436 loss)
I0925 22:01:24.421787 19975 sgd_solver.cpp:165] Iteration 13600, lr = 0.1
I0925 22:01:31.583279 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:01:35.094240 19975 solver.cpp:357] Iteration 13700 (9.3697 iter/s, 10.6727s/100 iters), loss = 0.465169
I0925 22:01:35.094306 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.465169 (* 1 = 0.465169 loss)
I0925 22:01:35.094316 19975 sgd_solver.cpp:165] Iteration 13700, lr = 0.1
I0925 22:01:45.757751 19975 solver.cpp:357] Iteration 13800 (9.37762 iter/s, 10.6637s/100 iters), loss = 0.391185
I0925 22:01:45.757894 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.391185 (* 1 = 0.391185 loss)
I0925 22:01:45.757903 19975 sgd_solver.cpp:165] Iteration 13800, lr = 0.1
I0925 22:01:56.424980 19975 solver.cpp:357] Iteration 13900 (9.37442 iter/s, 10.6673s/100 iters), loss = 0.404623
I0925 22:01:56.425046 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.404623 (* 1 = 0.404623 loss)
I0925 22:01:56.425056 19975 sgd_solver.cpp:165] Iteration 13900, lr = 0.1
I0925 22:02:06.979782 19975 solver.cpp:514] Iteration 14000, Testing net (#0)
I0925 22:02:10.157457 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:02:10.176470 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.20911 (* 1 = 1.20911 loss)
I0925 22:02:10.176497 19975 solver.cpp:580]     Test net output #1: prob = 0.6495
I0925 22:02:10.281373 19975 solver.cpp:357] Iteration 14000 (7.21676 iter/s, 13.8566s/100 iters), loss = 0.487652
I0925 22:02:10.281415 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.487652 (* 1 = 0.487652 loss)
I0925 22:02:10.281425 19975 sgd_solver.cpp:165] Iteration 14000, lr = 0.1
I0925 22:02:16.464630 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:02:20.939805 19975 solver.cpp:357] Iteration 14100 (9.38208 iter/s, 10.6586s/100 iters), loss = 0.38063
I0925 22:02:20.939869 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.38063 (* 1 = 0.38063 loss)
I0925 22:02:20.939878 19975 sgd_solver.cpp:165] Iteration 14100, lr = 0.1
I0925 22:02:31.605813 19975 solver.cpp:357] Iteration 14200 (9.37543 iter/s, 10.6662s/100 iters), loss = 0.541462
I0925 22:02:31.605878 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.541462 (* 1 = 0.541462 loss)
I0925 22:02:31.605887 19975 sgd_solver.cpp:165] Iteration 14200, lr = 0.1
I0925 22:02:42.273923 19975 solver.cpp:357] Iteration 14300 (9.37358 iter/s, 10.6683s/100 iters), loss = 0.505617
I0925 22:02:42.273990 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.505617 (* 1 = 0.505617 loss)
I0925 22:02:42.274001 19975 sgd_solver.cpp:165] Iteration 14300, lr = 0.1
I0925 22:02:52.930471 19975 solver.cpp:357] Iteration 14400 (9.38375 iter/s, 10.6567s/100 iters), loss = 0.357346
I0925 22:02:52.930634 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.357346 (* 1 = 0.357346 loss)
I0925 22:02:52.930642 19975 sgd_solver.cpp:165] Iteration 14400, lr = 0.1
I0925 22:02:58.160395 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:03:03.490556 19975 solver.cpp:514] Iteration 14500, Testing net (#0)
I0925 22:03:06.728667 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:03:06.740722 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.09271 (* 1 = 1.09271 loss)
I0925 22:03:06.740751 19975 solver.cpp:580]     Test net output #1: prob = 0.6289
I0925 22:03:06.845723 19975 solver.cpp:357] Iteration 14500 (7.18628 iter/s, 13.9154s/100 iters), loss = 0.470666
I0925 22:03:06.845767 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.470666 (* 1 = 0.470666 loss)
I0925 22:03:06.845777 19975 sgd_solver.cpp:165] Iteration 14500, lr = 0.1
I0925 22:03:17.499824 19975 solver.cpp:357] Iteration 14600 (9.38589 iter/s, 10.6543s/100 iters), loss = 0.487633
I0925 22:03:17.499888 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.487633 (* 1 = 0.487633 loss)
I0925 22:03:17.499897 19975 sgd_solver.cpp:165] Iteration 14600, lr = 0.1
I0925 22:03:28.170020 19975 solver.cpp:357] Iteration 14700 (9.37175 iter/s, 10.6704s/100 iters), loss = 0.389783
I0925 22:03:28.170172 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.389783 (* 1 = 0.389783 loss)
I0925 22:03:28.170181 19975 sgd_solver.cpp:165] Iteration 14700, lr = 0.1
I0925 22:03:38.822382 19975 solver.cpp:357] Iteration 14800 (9.38751 iter/s, 10.6524s/100 iters), loss = 0.330072
I0925 22:03:38.822446 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.330072 (* 1 = 0.330072 loss)
I0925 22:03:38.822456 19975 sgd_solver.cpp:165] Iteration 14800, lr = 0.1
I0925 22:03:42.990969 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:03:49.479737 19975 solver.cpp:357] Iteration 14900 (9.38304 iter/s, 10.6575s/100 iters), loss = 0.429484
I0925 22:03:49.479800 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.429484 (* 1 = 0.429484 loss)
I0925 22:03:49.479810 19975 sgd_solver.cpp:165] Iteration 14900, lr = 0.1
I0925 22:04:00.039557 19975 solver.cpp:514] Iteration 15000, Testing net (#0)
I0925 22:04:03.264488 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:04:03.276650 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.38381 (* 1 = 1.38381 loss)
I0925 22:04:03.276677 19975 solver.cpp:580]     Test net output #1: prob = 0.6077
I0925 22:04:03.380825 19975 solver.cpp:357] Iteration 15000 (7.19355 iter/s, 13.9013s/100 iters), loss = 0.512686
I0925 22:04:03.380870 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.512686 (* 1 = 0.512686 loss)
I0925 22:04:03.380882 19975 sgd_solver.cpp:165] Iteration 15000, lr = 0.1
I0925 22:04:14.039643 19975 solver.cpp:357] Iteration 15100 (9.38174 iter/s, 10.659s/100 iters), loss = 0.39785
I0925 22:04:14.039706 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.39785 (* 1 = 0.39785 loss)
I0925 22:04:14.039717 19975 sgd_solver.cpp:165] Iteration 15100, lr = 0.1
I0925 22:04:24.690588 19975 solver.cpp:357] Iteration 15200 (9.38869 iter/s, 10.6511s/100 iters), loss = 0.605482
I0925 22:04:24.690654 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.605482 (* 1 = 0.605482 loss)
I0925 22:04:24.690665 19975 sgd_solver.cpp:165] Iteration 15200, lr = 0.1
I0925 22:04:27.890446 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:04:35.353956 19975 solver.cpp:357] Iteration 15300 (9.37775 iter/s, 10.6635s/100 iters), loss = 0.438286
I0925 22:04:35.354109 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.438286 (* 1 = 0.438286 loss)
I0925 22:04:35.354118 19975 sgd_solver.cpp:165] Iteration 15300, lr = 0.1
I0925 22:04:46.011145 19975 solver.cpp:357] Iteration 15400 (9.38326 iter/s, 10.6573s/100 iters), loss = 0.416315
I0925 22:04:46.011207 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.416315 (* 1 = 0.416315 loss)
I0925 22:04:46.011217 19975 sgd_solver.cpp:165] Iteration 15400, lr = 0.1
I0925 22:04:56.551292 19975 solver.cpp:514] Iteration 15500, Testing net (#0)
I0925 22:04:59.766284 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:04:59.785492 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.52361 (* 1 = 1.52361 loss)
I0925 22:04:59.785519 19975 solver.cpp:580]     Test net output #1: prob = 0.5048
I0925 22:04:59.890753 19975 solver.cpp:357] Iteration 15500 (7.20468 iter/s, 13.8799s/100 iters), loss = 0.421311
I0925 22:04:59.890796 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.421311 (* 1 = 0.421311 loss)
I0925 22:04:59.890820 19975 sgd_solver.cpp:165] Iteration 15500, lr = 0.1
I0925 22:05:10.554932 19975 solver.cpp:357] Iteration 15600 (9.37702 iter/s, 10.6644s/100 iters), loss = 0.366061
I0925 22:05:10.555193 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.366061 (* 1 = 0.366061 loss)
I0925 22:05:10.555202 19975 sgd_solver.cpp:165] Iteration 15600, lr = 0.1
I0925 22:05:12.701054 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:05:21.214475 19975 solver.cpp:357] Iteration 15700 (9.38129 iter/s, 10.6595s/100 iters), loss = 0.458771
I0925 22:05:21.214540 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.458771 (* 1 = 0.458771 loss)
I0925 22:05:21.214550 19975 sgd_solver.cpp:165] Iteration 15700, lr = 0.1
I0925 22:05:31.872128 19975 solver.cpp:357] Iteration 15800 (9.38278 iter/s, 10.6578s/100 iters), loss = 0.517326
I0925 22:05:31.872189 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.517326 (* 1 = 0.517326 loss)
I0925 22:05:31.872198 19975 sgd_solver.cpp:165] Iteration 15800, lr = 0.1
I0925 22:05:42.526593 19975 solver.cpp:357] Iteration 15900 (9.38558 iter/s, 10.6546s/100 iters), loss = 0.289631
I0925 22:05:42.526697 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.289631 (* 1 = 0.289631 loss)
I0925 22:05:42.526710 19975 sgd_solver.cpp:165] Iteration 15900, lr = 0.1
I0925 22:05:53.066727 19975 solver.cpp:514] Iteration 16000, Testing net (#0)
I0925 22:05:56.262353 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:05:56.274339 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.50451 (* 1 = 1.50451 loss)
I0925 22:05:56.274365 19975 solver.cpp:580]     Test net output #1: prob = 0.568
I0925 22:05:56.379087 19975 solver.cpp:357] Iteration 16000 (7.2188 iter/s, 13.8527s/100 iters), loss = 0.435863
I0925 22:05:56.379132 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.435863 (* 1 = 0.435863 loss)
I0925 22:05:56.379145 19975 sgd_solver.cpp:165] Iteration 16000, lr = 0.1
I0925 22:05:57.565129 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:06:07.050639 19975 solver.cpp:357] Iteration 16100 (9.37054 iter/s, 10.6717s/100 iters), loss = 0.434435
I0925 22:06:07.050703 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.434435 (* 1 = 0.434435 loss)
I0925 22:06:07.050714 19975 sgd_solver.cpp:165] Iteration 16100, lr = 0.1
I0925 22:06:17.711936 19975 solver.cpp:357] Iteration 16200 (9.37957 iter/s, 10.6615s/100 iters), loss = 0.369215
I0925 22:06:17.712141 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.369215 (* 1 = 0.369215 loss)
I0925 22:06:17.712150 19975 sgd_solver.cpp:165] Iteration 16200, lr = 0.1
I0925 22:06:28.368788 19975 solver.cpp:357] Iteration 16300 (9.3836 iter/s, 10.6569s/100 iters), loss = 0.340605
I0925 22:06:28.368849 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.340605 (* 1 = 0.340605 loss)
I0925 22:06:28.368860 19975 sgd_solver.cpp:165] Iteration 16300, lr = 0.1
I0925 22:06:39.020552 19975 solver.cpp:357] Iteration 16400 (9.38796 iter/s, 10.6519s/100 iters), loss = 0.38389
I0925 22:06:39.020615 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.38389 (* 1 = 0.38389 loss)
I0925 22:06:39.020625 19975 sgd_solver.cpp:165] Iteration 16400, lr = 0.1
I0925 22:06:39.240475 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:06:49.581102 19975 solver.cpp:514] Iteration 16500, Testing net (#0)
I0925 22:06:52.798025 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:06:52.810041 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.45576 (* 1 = 2.45576 loss)
I0925 22:06:52.810068 19975 solver.cpp:580]     Test net output #1: prob = 0.4621
I0925 22:06:52.915350 19975 solver.cpp:357] Iteration 16500 (7.1968 iter/s, 13.8951s/100 iters), loss = 0.445012
I0925 22:06:52.915395 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.445012 (* 1 = 0.445012 loss)
I0925 22:06:52.915408 19975 sgd_solver.cpp:165] Iteration 16500, lr = 0.1
I0925 22:07:03.587347 19975 solver.cpp:357] Iteration 16600 (9.37015 iter/s, 10.6722s/100 iters), loss = 0.438449
I0925 22:07:03.587410 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.438449 (* 1 = 0.438449 loss)
I0925 22:07:03.587421 19975 sgd_solver.cpp:165] Iteration 16600, lr = 0.1
I0925 22:07:14.245801 19975 solver.cpp:357] Iteration 16700 (9.38207 iter/s, 10.6586s/100 iters), loss = 0.419087
I0925 22:07:14.245867 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.419087 (* 1 = 0.419087 loss)
I0925 22:07:14.245877 19975 sgd_solver.cpp:165] Iteration 16700, lr = 0.1
I0925 22:07:24.061038 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:07:24.901518 19975 solver.cpp:357] Iteration 16800 (9.38448 iter/s, 10.6559s/100 iters), loss = 0.401232
I0925 22:07:24.901584 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.401232 (* 1 = 0.401232 loss)
I0925 22:07:24.901593 19975 sgd_solver.cpp:165] Iteration 16800, lr = 0.1
I0925 22:07:35.566619 19975 solver.cpp:357] Iteration 16900 (9.37623 iter/s, 10.6653s/100 iters), loss = 0.398656
I0925 22:07:35.566684 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.398656 (* 1 = 0.398656 loss)
I0925 22:07:35.566695 19975 sgd_solver.cpp:165] Iteration 16900, lr = 0.1
I0925 22:07:46.119781 19975 solver.cpp:514] Iteration 17000, Testing net (#0)
I0925 22:07:49.446066 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:07:49.458562 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.45747 (* 1 = 2.45747 loss)
I0925 22:07:49.458590 19975 solver.cpp:580]     Test net output #1: prob = 0.4643
I0925 22:07:49.563992 19975 solver.cpp:357] Iteration 17000 (7.14407 iter/s, 13.9976s/100 iters), loss = 0.466211
I0925 22:07:49.564035 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.466211 (* 1 = 0.466211 loss)
I0925 22:07:49.564045 19975 sgd_solver.cpp:165] Iteration 17000, lr = 0.1
I0925 22:08:00.228062 19975 solver.cpp:357] Iteration 17100 (9.37711 iter/s, 10.6643s/100 iters), loss = 0.290932
I0925 22:08:00.228268 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.290932 (* 1 = 0.290932 loss)
I0925 22:08:00.228278 19975 sgd_solver.cpp:165] Iteration 17100, lr = 0.1
I0925 22:08:09.087558 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:08:10.892787 19975 solver.cpp:357] Iteration 17200 (9.37668 iter/s, 10.6648s/100 iters), loss = 0.335822
I0925 22:08:10.892853 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.335822 (* 1 = 0.335822 loss)
I0925 22:08:10.892861 19975 sgd_solver.cpp:165] Iteration 17200, lr = 0.1
I0925 22:08:21.548691 19975 solver.cpp:357] Iteration 17300 (9.38432 iter/s, 10.6561s/100 iters), loss = 0.376186
I0925 22:08:21.548754 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.376186 (* 1 = 0.376186 loss)
I0925 22:08:21.548765 19975 sgd_solver.cpp:165] Iteration 17300, lr = 0.1
I0925 22:08:32.202827 19975 solver.cpp:357] Iteration 17400 (9.38588 iter/s, 10.6543s/100 iters), loss = 0.401846
I0925 22:08:32.202982 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.401846 (* 1 = 0.401846 loss)
I0925 22:08:32.202991 19975 sgd_solver.cpp:165] Iteration 17400, lr = 0.1
I0925 22:08:42.768003 19975 solver.cpp:514] Iteration 17500, Testing net (#0)
I0925 22:08:46.031625 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:08:46.043591 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.22618 (* 1 = 1.22618 loss)
I0925 22:08:46.043618 19975 solver.cpp:580]     Test net output #1: prob = 0.644201
I0925 22:08:46.149752 19975 solver.cpp:357] Iteration 17500 (7.16995 iter/s, 13.9471s/100 iters), loss = 0.303422
I0925 22:08:46.149796 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.303422 (* 1 = 0.303422 loss)
I0925 22:08:46.149807 19975 sgd_solver.cpp:165] Iteration 17500, lr = 0.1
I0925 22:08:54.035903 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:08:56.809329 19975 solver.cpp:357] Iteration 17600 (9.38107 iter/s, 10.6598s/100 iters), loss = 0.34703
I0925 22:08:56.809393 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.34703 (* 1 = 0.34703 loss)
I0925 22:08:56.809403 19975 sgd_solver.cpp:165] Iteration 17600, lr = 0.1
I0925 22:09:07.465255 19975 solver.cpp:357] Iteration 17700 (9.3843 iter/s, 10.6561s/100 iters), loss = 0.666668
I0925 22:09:07.465404 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.666668 (* 1 = 0.666668 loss)
I0925 22:09:07.465416 19975 sgd_solver.cpp:165] Iteration 17700, lr = 0.1
I0925 22:09:18.134326 19975 solver.cpp:357] Iteration 17800 (9.37281 iter/s, 10.6692s/100 iters), loss = 0.426192
I0925 22:09:18.134389 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.426192 (* 1 = 0.426192 loss)
I0925 22:09:18.134400 19975 sgd_solver.cpp:165] Iteration 17800, lr = 0.1
I0925 22:09:28.781498 19975 solver.cpp:357] Iteration 17900 (9.39201 iter/s, 10.6473s/100 iters), loss = 0.321738
I0925 22:09:28.781563 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.321738 (* 1 = 0.321738 loss)
I0925 22:09:28.781574 19975 sgd_solver.cpp:165] Iteration 17900, lr = 0.1
I0925 22:09:35.609869 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:09:39.334189 19975 solver.cpp:514] Iteration 18000, Testing net (#0)
I0925 22:09:42.547060 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:09:42.559823 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.67083 (* 1 = 2.67083 loss)
I0925 22:09:42.559849 19975 solver.cpp:580]     Test net output #1: prob = 0.4734
I0925 22:09:42.664250 19975 solver.cpp:357] Iteration 18000 (7.20305 iter/s, 13.883s/100 iters), loss = 0.383821
I0925 22:09:42.664292 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.383821 (* 1 = 0.383821 loss)
I0925 22:09:42.664304 19975 sgd_solver.cpp:165] Iteration 18000, lr = 0.1
I0925 22:09:53.315224 19975 solver.cpp:357] Iteration 18100 (9.38864 iter/s, 10.6512s/100 iters), loss = 0.331502
I0925 22:09:53.315289 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.331502 (* 1 = 0.331502 loss)
I0925 22:09:53.315299 19975 sgd_solver.cpp:165] Iteration 18100, lr = 0.1
I0925 22:10:03.970330 19975 solver.cpp:357] Iteration 18200 (9.38502 iter/s, 10.6553s/100 iters), loss = 0.346895
I0925 22:10:03.970393 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.346895 (* 1 = 0.346895 loss)
I0925 22:10:03.970405 19975 sgd_solver.cpp:165] Iteration 18200, lr = 0.1
I0925 22:10:14.628132 19975 solver.cpp:357] Iteration 18300 (9.38264 iter/s, 10.658s/100 iters), loss = 0.264205
I0925 22:10:14.628288 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.264205 (* 1 = 0.264205 loss)
I0925 22:10:14.628296 19975 sgd_solver.cpp:165] Iteration 18300, lr = 0.1
I0925 22:10:20.497558 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:10:25.283629 19975 solver.cpp:357] Iteration 18400 (9.38475 iter/s, 10.6556s/100 iters), loss = 0.573519
I0925 22:10:25.283694 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.573519 (* 1 = 0.573519 loss)
I0925 22:10:25.283704 19975 sgd_solver.cpp:165] Iteration 18400, lr = 0.1
I0925 22:10:35.840962 19975 solver.cpp:514] Iteration 18500, Testing net (#0)
I0925 22:10:39.027511 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:10:39.039584 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.7072 (* 1 = 1.7072 loss)
I0925 22:10:39.039611 19975 solver.cpp:580]     Test net output #1: prob = 0.551501
I0925 22:10:39.144439 19975 solver.cpp:357] Iteration 18500 (7.21445 iter/s, 13.8611s/100 iters), loss = 0.303312
I0925 22:10:39.144484 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.303312 (* 1 = 0.303312 loss)
I0925 22:10:39.144493 19975 sgd_solver.cpp:165] Iteration 18500, lr = 0.1
I0925 22:10:49.818059 19975 solver.cpp:357] Iteration 18600 (9.36872 iter/s, 10.6738s/100 iters), loss = 0.516684
I0925 22:10:49.818209 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.516684 (* 1 = 0.516684 loss)
I0925 22:10:49.818218 19975 sgd_solver.cpp:165] Iteration 18600, lr = 0.1
I0925 22:11:00.474786 19975 solver.cpp:357] Iteration 18700 (9.38367 iter/s, 10.6568s/100 iters), loss = 0.377182
I0925 22:11:00.474853 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.377182 (* 1 = 0.377182 loss)
I0925 22:11:00.474862 19975 sgd_solver.cpp:165] Iteration 18700, lr = 0.1
I0925 22:11:05.286582 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:11:11.136946 19975 solver.cpp:357] Iteration 18800 (9.37881 iter/s, 10.6623s/100 iters), loss = 0.381767
I0925 22:11:11.137010 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.381767 (* 1 = 0.381767 loss)
I0925 22:11:11.137020 19975 sgd_solver.cpp:165] Iteration 18800, lr = 0.1
I0925 22:11:21.798668 19975 solver.cpp:357] Iteration 18900 (9.3792 iter/s, 10.6619s/100 iters), loss = 0.507084
I0925 22:11:21.798818 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.507084 (* 1 = 0.507084 loss)
I0925 22:11:21.798828 19975 sgd_solver.cpp:165] Iteration 18900, lr = 0.1
I0925 22:11:32.347787 19975 solver.cpp:514] Iteration 19000, Testing net (#0)
I0925 22:11:35.583547 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:11:35.595504 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.04148 (* 1 = 1.04148 loss)
I0925 22:11:35.595531 19975 solver.cpp:580]     Test net output #1: prob = 0.6842
I0925 22:11:35.700361 19975 solver.cpp:357] Iteration 19000 (7.19352 iter/s, 13.9014s/100 iters), loss = 0.391527
I0925 22:11:35.700405 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.391527 (* 1 = 0.391527 loss)
I0925 22:11:35.700419 19975 sgd_solver.cpp:165] Iteration 19000, lr = 0.1
I0925 22:11:46.365449 19975 solver.cpp:357] Iteration 19100 (9.37697 iter/s, 10.6644s/100 iters), loss = 0.35315
I0925 22:11:46.365515 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.35315 (* 1 = 0.35315 loss)
I0925 22:11:46.365525 19975 sgd_solver.cpp:165] Iteration 19100, lr = 0.1
I0925 22:11:50.205973 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:11:57.009160 19975 solver.cpp:357] Iteration 19200 (9.39581 iter/s, 10.643s/100 iters), loss = 0.482349
I0925 22:11:57.009369 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.482349 (* 1 = 0.482349 loss)
I0925 22:11:57.009419 19975 sgd_solver.cpp:165] Iteration 19200, lr = 0.1
I0925 22:12:07.664039 19975 solver.cpp:357] Iteration 19300 (9.38607 iter/s, 10.6541s/100 iters), loss = 0.402453
I0925 22:12:07.664103 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.402453 (* 1 = 0.402453 loss)
I0925 22:12:07.664115 19975 sgd_solver.cpp:165] Iteration 19300, lr = 0.1
I0925 22:12:18.318383 19975 solver.cpp:357] Iteration 19400 (9.3864 iter/s, 10.6537s/100 iters), loss = 0.410321
I0925 22:12:18.318446 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.410321 (* 1 = 0.410321 loss)
I0925 22:12:18.318457 19975 sgd_solver.cpp:165] Iteration 19400, lr = 0.1
I0925 22:12:28.872308 19975 solver.cpp:514] Iteration 19500, Testing net (#0)
I0925 22:12:32.049829 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:12:32.061815 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.896949 (* 1 = 0.896949 loss)
I0925 22:12:32.061842 19975 solver.cpp:580]     Test net output #1: prob = 0.7218
I0925 22:12:32.166535 19975 solver.cpp:357] Iteration 19500 (7.22158 iter/s, 13.8474s/100 iters), loss = 0.332052
I0925 22:12:32.166579 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.332052 (* 1 = 0.332052 loss)
I0925 22:12:32.166589 19975 sgd_solver.cpp:165] Iteration 19500, lr = 0.1
I0925 22:12:35.046149 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:12:42.821964 19975 solver.cpp:357] Iteration 19600 (9.3854 iter/s, 10.6548s/100 iters), loss = 0.475267
I0925 22:12:42.822026 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.475267 (* 1 = 0.475267 loss)
I0925 22:12:42.822037 19975 sgd_solver.cpp:165] Iteration 19600, lr = 0.1
I0925 22:12:53.486392 19975 solver.cpp:357] Iteration 19700 (9.37749 iter/s, 10.6638s/100 iters), loss = 0.522154
I0925 22:12:53.486459 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.522154 (* 1 = 0.522154 loss)
I0925 22:12:53.486466 19975 sgd_solver.cpp:165] Iteration 19700, lr = 0.1
I0925 22:13:04.153774 19975 solver.cpp:357] Iteration 19800 (9.37488 iter/s, 10.6668s/100 iters), loss = 0.378725
I0925 22:13:04.153914 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.378725 (* 1 = 0.378725 loss)
I0925 22:13:04.153928 19975 sgd_solver.cpp:165] Iteration 19800, lr = 0.1
I0925 22:13:14.824044 19975 solver.cpp:357] Iteration 19900 (9.3724 iter/s, 10.6696s/100 iters), loss = 0.395812
I0925 22:13:14.824110 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.395812 (* 1 = 0.395812 loss)
I0925 22:13:14.824120 19975 sgd_solver.cpp:165] Iteration 19900, lr = 0.1
I0925 22:13:16.653198 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:13:25.391481 19975 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_20000.caffemodel
I0925 22:13:25.399729 19975 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_20000.solverstate
I0925 22:13:25.402609 19975 solver.cpp:514] Iteration 20000, Testing net (#0)
I0925 22:13:28.652495 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:13:28.665199 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.891012 (* 1 = 0.891012 loss)
I0925 22:13:28.665225 19975 solver.cpp:580]     Test net output #1: prob = 0.7066
I0925 22:13:28.770524 19975 solver.cpp:357] Iteration 20000 (7.17062 iter/s, 13.9458s/100 iters), loss = 0.439791
I0925 22:13:28.770568 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.439791 (* 1 = 0.439791 loss)
I0925 22:13:28.770581 19975 sgd_solver.cpp:165] Iteration 20000, lr = 0.1
I0925 22:13:39.421299 19975 solver.cpp:357] Iteration 20100 (9.38944 iter/s, 10.6503s/100 iters), loss = 0.337784
I0925 22:13:39.421507 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.337784 (* 1 = 0.337784 loss)
I0925 22:13:39.421517 19975 sgd_solver.cpp:165] Iteration 20100, lr = 0.1
I0925 22:13:50.085561 19975 solver.cpp:357] Iteration 20200 (9.3777 iter/s, 10.6636s/100 iters), loss = 0.422534
I0925 22:13:50.085623 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.422534 (* 1 = 0.422534 loss)
I0925 22:13:50.085633 19975 sgd_solver.cpp:165] Iteration 20200, lr = 0.1
I0925 22:14:00.751490 19975 solver.cpp:357] Iteration 20300 (9.3761 iter/s, 10.6654s/100 iters), loss = 0.360855
I0925 22:14:00.751554 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.360855 (* 1 = 0.360855 loss)
I0925 22:14:00.751565 19975 sgd_solver.cpp:165] Iteration 20300, lr = 0.1
I0925 22:14:01.613353 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:14:11.400928 19975 solver.cpp:357] Iteration 20400 (9.39061 iter/s, 10.6489s/100 iters), loss = 0.36621
I0925 22:14:11.401087 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.36621 (* 1 = 0.36621 loss)
I0925 22:14:11.401096 19975 sgd_solver.cpp:165] Iteration 20400, lr = 0.1
I0925 22:14:21.961374 19975 solver.cpp:514] Iteration 20500, Testing net (#0)
I0925 22:14:25.162156 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:14:25.174304 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.03072 (* 1 = 1.03072 loss)
I0925 22:14:25.174331 19975 solver.cpp:580]     Test net output #1: prob = 0.6941
I0925 22:14:25.280302 19975 solver.cpp:357] Iteration 20500 (7.2053 iter/s, 13.8787s/100 iters), loss = 0.327962
I0925 22:14:25.280345 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.327962 (* 1 = 0.327962 loss)
I0925 22:14:25.280355 19975 sgd_solver.cpp:165] Iteration 20500, lr = 0.1
I0925 22:14:35.945173 19975 solver.cpp:357] Iteration 20600 (9.37698 iter/s, 10.6644s/100 iters), loss = 0.430566
I0925 22:14:35.945236 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.430566 (* 1 = 0.430566 loss)
I0925 22:14:35.945246 19975 sgd_solver.cpp:165] Iteration 20600, lr = 0.1
I0925 22:14:46.512431 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:14:46.614425 19975 solver.cpp:357] Iteration 20700 (9.37313 iter/s, 10.6688s/100 iters), loss = 0.42337
I0925 22:14:46.614476 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.42337 (* 1 = 0.42337 loss)
I0925 22:14:46.614485 19975 sgd_solver.cpp:165] Iteration 20700, lr = 0.1
I0925 22:14:57.280207 19975 solver.cpp:357] Iteration 20800 (9.37617 iter/s, 10.6653s/100 iters), loss = 0.489059
I0925 22:14:57.280272 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.489059 (* 1 = 0.489059 loss)
I0925 22:14:57.280280 19975 sgd_solver.cpp:165] Iteration 20800, lr = 0.1
I0925 22:15:07.945593 19975 solver.cpp:357] Iteration 20900 (9.37652 iter/s, 10.6649s/100 iters), loss = 0.389349
I0925 22:15:07.945658 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.389349 (* 1 = 0.389349 loss)
I0925 22:15:07.945668 19975 sgd_solver.cpp:165] Iteration 20900, lr = 0.1
I0925 22:15:18.493726 19975 solver.cpp:514] Iteration 21000, Testing net (#0)
I0925 22:15:21.731703 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:15:21.743685 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.06704 (* 1 = 1.06704 loss)
I0925 22:15:21.743710 19975 solver.cpp:580]     Test net output #1: prob = 0.6726
I0925 22:15:21.848945 19975 solver.cpp:357] Iteration 21000 (7.19279 iter/s, 13.9028s/100 iters), loss = 0.377144
I0925 22:15:21.848989 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.377144 (* 1 = 0.377144 loss)
I0925 22:15:21.848999 19975 sgd_solver.cpp:165] Iteration 21000, lr = 0.1
I0925 22:15:31.341284 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:15:32.504438 19975 solver.cpp:357] Iteration 21100 (9.38518 iter/s, 10.6551s/100 iters), loss = 0.394264
I0925 22:15:32.504500 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.394264 (* 1 = 0.394264 loss)
I0925 22:15:32.504511 19975 sgd_solver.cpp:165] Iteration 21100, lr = 0.1
I0925 22:15:43.164911 19975 solver.cpp:357] Iteration 21200 (9.38081 iter/s, 10.6601s/100 iters), loss = 0.405366
I0925 22:15:43.164974 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.405366 (* 1 = 0.405366 loss)
I0925 22:15:43.164985 19975 sgd_solver.cpp:165] Iteration 21200, lr = 0.1
I0925 22:15:53.815470 19975 solver.cpp:357] Iteration 21300 (9.38953 iter/s, 10.6502s/100 iters), loss = 0.514447
I0925 22:15:53.815623 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.514447 (* 1 = 0.514447 loss)
I0925 22:15:53.815634 19975 sgd_solver.cpp:165] Iteration 21300, lr = 0.1
I0925 22:16:04.478720 19975 solver.cpp:357] Iteration 21400 (9.37843 iter/s, 10.6628s/100 iters), loss = 0.410305
I0925 22:16:04.478786 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.410305 (* 1 = 0.410305 loss)
I0925 22:16:04.478797 19975 sgd_solver.cpp:165] Iteration 21400, lr = 0.1
I0925 22:16:13.015041 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:16:15.036653 19975 solver.cpp:514] Iteration 21500, Testing net (#0)
I0925 22:16:18.251931 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:16:18.264478 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.27593 (* 1 = 1.27593 loss)
I0925 22:16:18.264505 19975 solver.cpp:580]     Test net output #1: prob = 0.6255
I0925 22:16:18.369446 19975 solver.cpp:357] Iteration 21500 (7.19929 iter/s, 13.8903s/100 iters), loss = 0.202554
I0925 22:16:18.369489 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.202554 (* 1 = 0.202554 loss)
I0925 22:16:18.369499 19975 sgd_solver.cpp:165] Iteration 21500, lr = 0.1
I0925 22:16:29.020591 19975 solver.cpp:357] Iteration 21600 (9.38898 iter/s, 10.6508s/100 iters), loss = 0.423983
I0925 22:16:29.020750 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.423983 (* 1 = 0.423983 loss)
I0925 22:16:29.020759 19975 sgd_solver.cpp:165] Iteration 21600, lr = 0.1
I0925 22:16:39.666441 19975 solver.cpp:357] Iteration 21700 (9.39374 iter/s, 10.6454s/100 iters), loss = 0.290415
I0925 22:16:39.666507 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.290414 (* 1 = 0.290414 loss)
I0925 22:16:39.666517 19975 sgd_solver.cpp:165] Iteration 21700, lr = 0.1
I0925 22:16:50.332918 19975 solver.cpp:357] Iteration 21800 (9.37548 iter/s, 10.6661s/100 iters), loss = 0.334212
I0925 22:16:50.332983 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.334212 (* 1 = 0.334212 loss)
I0925 22:16:50.332993 19975 sgd_solver.cpp:165] Iteration 21800, lr = 0.1
I0925 22:16:57.805655 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:17:00.991152 19975 solver.cpp:357] Iteration 21900 (9.38273 iter/s, 10.6579s/100 iters), loss = 0.461747
I0925 22:17:00.991297 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.461747 (* 1 = 0.461747 loss)
I0925 22:17:00.991305 19975 sgd_solver.cpp:165] Iteration 21900, lr = 0.1
I0925 22:17:11.546651 19975 solver.cpp:514] Iteration 22000, Testing net (#0)
I0925 22:17:14.771275 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:17:14.783254 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.14924 (* 1 = 1.14924 loss)
I0925 22:17:14.783280 19975 solver.cpp:580]     Test net output #1: prob = 0.6537
I0925 22:17:14.888204 19975 solver.cpp:357] Iteration 22000 (7.19603 iter/s, 13.8966s/100 iters), loss = 0.414593
I0925 22:17:14.888247 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.414593 (* 1 = 0.414593 loss)
I0925 22:17:14.888257 19975 sgd_solver.cpp:165] Iteration 22000, lr = 0.1
I0925 22:17:25.542011 19975 solver.cpp:357] Iteration 22100 (9.38659 iter/s, 10.6535s/100 iters), loss = 0.503068
I0925 22:17:25.542078 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.503068 (* 1 = 0.503068 loss)
I0925 22:17:25.542088 19975 sgd_solver.cpp:165] Iteration 22100, lr = 0.1
I0925 22:17:36.206753 19975 solver.cpp:357] Iteration 22200 (9.37698 iter/s, 10.6644s/100 iters), loss = 0.404245
I0925 22:17:36.206959 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.404245 (* 1 = 0.404245 loss)
I0925 22:17:36.206969 19975 sgd_solver.cpp:165] Iteration 22200, lr = 0.1
I0925 22:17:42.718360 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:17:46.872073 19975 solver.cpp:357] Iteration 22300 (9.37658 iter/s, 10.6649s/100 iters), loss = 0.437909
I0925 22:17:46.872138 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.437909 (* 1 = 0.437909 loss)
I0925 22:17:46.872146 19975 sgd_solver.cpp:165] Iteration 22300, lr = 0.1
I0925 22:17:57.523075 19975 solver.cpp:357] Iteration 22400 (9.38906 iter/s, 10.6507s/100 iters), loss = 0.354215
I0925 22:17:57.523138 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.354215 (* 1 = 0.354215 loss)
I0925 22:17:57.523149 19975 sgd_solver.cpp:165] Iteration 22400, lr = 0.1
I0925 22:18:08.083386 19975 solver.cpp:514] Iteration 22500, Testing net (#0)
I0925 22:18:11.309953 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:18:11.330703 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.927218 (* 1 = 0.927218 loss)
I0925 22:18:11.330736 19975 solver.cpp:580]     Test net output #1: prob = 0.7302
I0925 22:18:11.435775 19975 solver.cpp:357] Iteration 22500 (7.18787 iter/s, 13.9123s/100 iters), loss = 0.381227
I0925 22:18:11.435817 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.381227 (* 1 = 0.381227 loss)
I0925 22:18:11.435829 19975 sgd_solver.cpp:165] Iteration 22500, lr = 0.1
I0925 22:18:22.098062 19975 solver.cpp:357] Iteration 22600 (9.37909 iter/s, 10.662s/100 iters), loss = 0.457837
I0925 22:18:22.098126 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.457837 (* 1 = 0.457837 loss)
I0925 22:18:22.098135 19975 sgd_solver.cpp:165] Iteration 22600, lr = 0.1
I0925 22:18:27.644165 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:18:32.754703 19975 solver.cpp:357] Iteration 22700 (9.38407 iter/s, 10.6564s/100 iters), loss = 0.363785
I0925 22:18:32.754768 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.363785 (* 1 = 0.363785 loss)
I0925 22:18:32.754777 19975 sgd_solver.cpp:165] Iteration 22700, lr = 0.1
I0925 22:18:43.411818 19975 solver.cpp:357] Iteration 22800 (9.38365 iter/s, 10.6568s/100 iters), loss = 0.35843
I0925 22:18:43.411967 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.35843 (* 1 = 0.35843 loss)
I0925 22:18:43.411976 19975 sgd_solver.cpp:165] Iteration 22800, lr = 0.1
I0925 22:18:54.068336 19975 solver.cpp:357] Iteration 22900 (9.38424 iter/s, 10.6562s/100 iters), loss = 0.44287
I0925 22:18:54.068398 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.44287 (* 1 = 0.44287 loss)
I0925 22:18:54.068409 19975 sgd_solver.cpp:165] Iteration 22900, lr = 0.1
I0925 22:19:04.629467 19975 solver.cpp:514] Iteration 23000, Testing net (#0)
I0925 22:19:07.870175 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:19:07.882304 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.19978 (* 1 = 1.19978 loss)
I0925 22:19:07.882333 19975 solver.cpp:580]     Test net output #1: prob = 0.6435
I0925 22:19:07.987606 19975 solver.cpp:357] Iteration 23000 (7.18445 iter/s, 13.919s/100 iters), loss = 0.360484
I0925 22:19:07.987649 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.360484 (* 1 = 0.360484 loss)
I0925 22:19:07.987660 19975 sgd_solver.cpp:165] Iteration 23000, lr = 0.1
I0925 22:19:12.476007 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:19:18.646279 19975 solver.cpp:357] Iteration 23100 (9.38224 iter/s, 10.6584s/100 iters), loss = 0.499468
I0925 22:19:18.646400 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.499468 (* 1 = 0.499468 loss)
I0925 22:19:18.646414 19975 sgd_solver.cpp:165] Iteration 23100, lr = 0.1
I0925 22:19:29.297417 19975 solver.cpp:357] Iteration 23200 (9.38894 iter/s, 10.6508s/100 iters), loss = 0.384845
I0925 22:19:29.297479 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.384844 (* 1 = 0.384844 loss)
I0925 22:19:29.297492 19975 sgd_solver.cpp:165] Iteration 23200, lr = 0.1
I0925 22:19:39.969347 19975 solver.cpp:357] Iteration 23300 (9.37059 iter/s, 10.6717s/100 iters), loss = 0.361411
I0925 22:19:39.969411 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.361411 (* 1 = 0.361411 loss)
I0925 22:19:39.969422 19975 sgd_solver.cpp:165] Iteration 23300, lr = 0.1
I0925 22:19:50.640369 19975 solver.cpp:357] Iteration 23400 (9.37139 iter/s, 10.6708s/100 iters), loss = 0.389592
I0925 22:19:50.640529 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.389592 (* 1 = 0.389592 loss)
I0925 22:19:50.640542 19975 sgd_solver.cpp:165] Iteration 23400, lr = 0.1
I0925 22:19:54.163223 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:20:01.194346 19975 solver.cpp:514] Iteration 23500, Testing net (#0)
I0925 22:20:04.420984 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:20:04.432898 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.71984 (* 1 = 1.71984 loss)
I0925 22:20:04.432926 19975 solver.cpp:580]     Test net output #1: prob = 0.584
I0925 22:20:04.537437 19975 solver.cpp:357] Iteration 23500 (7.19595 iter/s, 13.8967s/100 iters), loss = 0.355882
I0925 22:20:04.537482 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.355882 (* 1 = 0.355882 loss)
I0925 22:20:04.537497 19975 sgd_solver.cpp:165] Iteration 23500, lr = 0.1
I0925 22:20:15.202436 19975 solver.cpp:357] Iteration 23600 (9.37665 iter/s, 10.6648s/100 iters), loss = 0.386526
I0925 22:20:15.202502 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.386526 (* 1 = 0.386526 loss)
I0925 22:20:15.202512 19975 sgd_solver.cpp:165] Iteration 23600, lr = 0.1
I0925 22:20:25.863584 19975 solver.cpp:357] Iteration 23700 (9.38005 iter/s, 10.6609s/100 iters), loss = 0.31463
I0925 22:20:25.863739 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.31463 (* 1 = 0.31463 loss)
I0925 22:20:25.863752 19975 sgd_solver.cpp:165] Iteration 23700, lr = 0.1
I0925 22:20:36.516167 19975 solver.cpp:357] Iteration 23800 (9.38766 iter/s, 10.6523s/100 iters), loss = 0.440804
I0925 22:20:36.516232 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.440804 (* 1 = 0.440804 loss)
I0925 22:20:36.516240 19975 sgd_solver.cpp:165] Iteration 23800, lr = 0.1
I0925 22:20:39.079612 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:20:47.179154 19975 solver.cpp:357] Iteration 23900 (9.37842 iter/s, 10.6628s/100 iters), loss = 0.37769
I0925 22:20:47.179219 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.37769 (* 1 = 0.37769 loss)
I0925 22:20:47.179227 19975 sgd_solver.cpp:165] Iteration 23900, lr = 0.1
I0925 22:20:57.734230 19975 solver.cpp:514] Iteration 24000, Testing net (#0)
I0925 22:21:00.975354 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:21:00.987290 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.06072 (* 1 = 1.06072 loss)
I0925 22:21:00.987318 19975 solver.cpp:580]     Test net output #1: prob = 0.6725
I0925 22:21:01.091837 19975 solver.cpp:357] Iteration 24000 (7.18781 iter/s, 13.9124s/100 iters), loss = 0.400681
I0925 22:21:01.091881 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.400681 (* 1 = 0.400681 loss)
I0925 22:21:01.091892 19975 sgd_solver.cpp:165] Iteration 24000, lr = 0.1
I0925 22:21:11.744386 19975 solver.cpp:357] Iteration 24100 (9.38758 iter/s, 10.6524s/100 iters), loss = 0.392465
I0925 22:21:11.744451 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.392465 (* 1 = 0.392465 loss)
I0925 22:21:11.744459 19975 sgd_solver.cpp:165] Iteration 24100, lr = 0.1
I0925 22:21:22.401800 19975 solver.cpp:357] Iteration 24200 (9.38331 iter/s, 10.6572s/100 iters), loss = 0.413251
I0925 22:21:22.401862 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.413251 (* 1 = 0.413251 loss)
I0925 22:21:22.401873 19975 sgd_solver.cpp:165] Iteration 24200, lr = 0.1
I0925 22:21:23.904765 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:21:33.049623 19975 solver.cpp:357] Iteration 24300 (9.39176 iter/s, 10.6476s/100 iters), loss = 0.606301
I0925 22:21:33.049859 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.606301 (* 1 = 0.606301 loss)
I0925 22:21:33.049873 19975 sgd_solver.cpp:165] Iteration 24300, lr = 0.1
I0925 22:21:43.709679 19975 solver.cpp:357] Iteration 24400 (9.38113 iter/s, 10.6597s/100 iters), loss = 0.369387
I0925 22:21:43.709743 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.369387 (* 1 = 0.369387 loss)
I0925 22:21:43.709754 19975 sgd_solver.cpp:165] Iteration 24400, lr = 0.1
I0925 22:21:54.258163 19975 solver.cpp:514] Iteration 24500, Testing net (#0)
I0925 22:21:57.454619 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:21:57.466238 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.652515 (* 1 = 0.652515 loss)
I0925 22:21:57.466265 19975 solver.cpp:580]     Test net output #1: prob = 0.7714
I0925 22:21:57.571480 19975 solver.cpp:357] Iteration 24500 (7.21418 iter/s, 13.8616s/100 iters), loss = 0.457123
I0925 22:21:57.571523 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.457123 (* 1 = 0.457123 loss)
I0925 22:21:57.571534 19975 sgd_solver.cpp:165] Iteration 24500, lr = 0.1
I0925 22:22:08.224561 19975 solver.cpp:357] Iteration 24600 (9.38709 iter/s, 10.6529s/100 iters), loss = 0.447686
I0925 22:22:08.224666 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.447685 (* 1 = 0.447685 loss)
I0925 22:22:08.224678 19975 sgd_solver.cpp:165] Iteration 24600, lr = 0.1
I0925 22:22:08.762506 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:22:18.880036 19975 solver.cpp:357] Iteration 24700 (9.38503 iter/s, 10.6553s/100 iters), loss = 0.370562
I0925 22:22:18.880100 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.370562 (* 1 = 0.370562 loss)
I0925 22:22:18.880110 19975 sgd_solver.cpp:165] Iteration 24700, lr = 0.1
I0925 22:22:29.533681 19975 solver.cpp:357] Iteration 24800 (9.3866 iter/s, 10.6535s/100 iters), loss = 0.334551
I0925 22:22:29.533749 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.334551 (* 1 = 0.334551 loss)
I0925 22:22:29.533759 19975 sgd_solver.cpp:165] Iteration 24800, lr = 0.1
I0925 22:22:40.208158 19975 solver.cpp:357] Iteration 24900 (9.36829 iter/s, 10.6743s/100 iters), loss = 0.490308
I0925 22:22:40.208310 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.490308 (* 1 = 0.490308 loss)
I0925 22:22:40.208319 19975 sgd_solver.cpp:165] Iteration 24900, lr = 0.1
I0925 22:22:50.351681 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:22:50.765652 19975 solver.cpp:514] Iteration 25000, Testing net (#0)
I0925 22:22:53.984879 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:22:53.996753 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.24149 (* 1 = 1.24149 loss)
I0925 22:22:53.996780 19975 solver.cpp:580]     Test net output #1: prob = 0.6107
I0925 22:22:54.101649 19975 solver.cpp:357] Iteration 25000 (7.19775 iter/s, 13.8932s/100 iters), loss = 0.384259
I0925 22:22:54.101693 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.384259 (* 1 = 0.384259 loss)
I0925 22:22:54.101708 19975 sgd_solver.cpp:165] Iteration 25000, lr = 0.1
I0925 22:23:04.768502 19975 solver.cpp:357] Iteration 25100 (9.37495 iter/s, 10.6667s/100 iters), loss = 0.47313
I0925 22:23:04.768566 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.47313 (* 1 = 0.47313 loss)
I0925 22:23:04.768577 19975 sgd_solver.cpp:165] Iteration 25100, lr = 0.1
I0925 22:23:15.440310 19975 solver.cpp:357] Iteration 25200 (9.37061 iter/s, 10.6717s/100 iters), loss = 0.472879
I0925 22:23:15.440414 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.472879 (* 1 = 0.472879 loss)
I0925 22:23:15.440426 19975 sgd_solver.cpp:165] Iteration 25200, lr = 0.1
I0925 22:23:26.108707 19975 solver.cpp:357] Iteration 25300 (9.37364 iter/s, 10.6682s/100 iters), loss = 0.383943
I0925 22:23:26.108772 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.383943 (* 1 = 0.383943 loss)
I0925 22:23:26.108783 19975 sgd_solver.cpp:165] Iteration 25300, lr = 0.1
I0925 22:23:35.293408 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:23:36.775385 19975 solver.cpp:357] Iteration 25400 (9.37511 iter/s, 10.6665s/100 iters), loss = 0.519174
I0925 22:23:36.775450 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.519174 (* 1 = 0.519174 loss)
I0925 22:23:36.775460 19975 sgd_solver.cpp:165] Iteration 25400, lr = 0.1
I0925 22:23:47.323240 19975 solver.cpp:514] Iteration 25500, Testing net (#0)
I0925 22:23:50.505527 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:23:50.516882 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.43236 (* 1 = 1.43236 loss)
I0925 22:23:50.516909 19975 solver.cpp:580]     Test net output #1: prob = 0.5786
I0925 22:23:50.621996 19975 solver.cpp:357] Iteration 25500 (7.22206 iter/s, 13.8465s/100 iters), loss = 0.349752
I0925 22:23:50.622037 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.349752 (* 1 = 0.349752 loss)
I0925 22:23:50.622048 19975 sgd_solver.cpp:165] Iteration 25500, lr = 0.1
I0925 22:24:01.277726 19975 solver.cpp:357] Iteration 25600 (9.38472 iter/s, 10.6556s/100 iters), loss = 0.357573
I0925 22:24:01.277791 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.357573 (* 1 = 0.357573 loss)
I0925 22:24:01.277799 19975 sgd_solver.cpp:165] Iteration 25600, lr = 0.1
I0925 22:24:11.938527 19975 solver.cpp:357] Iteration 25700 (9.38027 iter/s, 10.6607s/100 iters), loss = 0.325921
I0925 22:24:11.938592 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.325921 (* 1 = 0.325921 loss)
I0925 22:24:11.938601 19975 sgd_solver.cpp:165] Iteration 25700, lr = 0.1
I0925 22:24:20.161643 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:24:22.606657 19975 solver.cpp:357] Iteration 25800 (9.37383 iter/s, 10.668s/100 iters), loss = 0.481019
I0925 22:24:22.606719 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.481019 (* 1 = 0.481019 loss)
I0925 22:24:22.606730 19975 sgd_solver.cpp:165] Iteration 25800, lr = 0.1
I0925 22:24:33.275898 19975 solver.cpp:357] Iteration 25900 (9.37284 iter/s, 10.6691s/100 iters), loss = 0.498569
I0925 22:24:33.275962 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.498569 (* 1 = 0.498569 loss)
I0925 22:24:33.275972 19975 sgd_solver.cpp:165] Iteration 25900, lr = 0.1
I0925 22:24:43.843886 19975 solver.cpp:514] Iteration 26000, Testing net (#0)
I0925 22:24:47.047894 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:24:47.060137 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.156 (* 1 = 1.156 loss)
I0925 22:24:47.060164 19975 solver.cpp:580]     Test net output #1: prob = 0.6706
I0925 22:24:47.165297 19975 solver.cpp:357] Iteration 26000 (7.1998 iter/s, 13.8893s/100 iters), loss = 0.339187
I0925 22:24:47.165343 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.339187 (* 1 = 0.339187 loss)
I0925 22:24:47.165354 19975 sgd_solver.cpp:165] Iteration 26000, lr = 0.1
I0925 22:24:57.844539 19975 solver.cpp:357] Iteration 26100 (9.36405 iter/s, 10.6791s/100 iters), loss = 0.383656
I0925 22:24:57.844689 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.383656 (* 1 = 0.383656 loss)
I0925 22:24:57.844699 19975 sgd_solver.cpp:165] Iteration 26100, lr = 0.1
I0925 22:25:04.990501 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:25:08.504829 19975 solver.cpp:357] Iteration 26200 (9.38078 iter/s, 10.6601s/100 iters), loss = 0.47328
I0925 22:25:08.504892 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.473279 (* 1 = 0.473279 loss)
I0925 22:25:08.504904 19975 sgd_solver.cpp:165] Iteration 26200, lr = 0.1
I0925 22:25:19.167363 19975 solver.cpp:357] Iteration 26300 (9.37873 iter/s, 10.6624s/100 iters), loss = 0.376227
I0925 22:25:19.167429 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.376227 (* 1 = 0.376227 loss)
I0925 22:25:19.167440 19975 sgd_solver.cpp:165] Iteration 26300, lr = 0.1
I0925 22:25:29.822943 19975 solver.cpp:357] Iteration 26400 (9.38485 iter/s, 10.6555s/100 iters), loss = 0.33374
I0925 22:25:29.823153 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.33374 (* 1 = 0.33374 loss)
I0925 22:25:29.823161 19975 sgd_solver.cpp:165] Iteration 26400, lr = 0.1
I0925 22:25:40.384795 19975 solver.cpp:514] Iteration 26500, Testing net (#0)
I0925 22:25:43.563354 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:25:43.575915 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.58 (* 1 = 1.58 loss)
I0925 22:25:43.575942 19975 solver.cpp:580]     Test net output #1: prob = 0.5656
I0925 22:25:43.681452 19975 solver.cpp:357] Iteration 26500 (7.21591 iter/s, 13.8583s/100 iters), loss = 0.381143
I0925 22:25:43.681494 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.381143 (* 1 = 0.381143 loss)
I0925 22:25:43.681505 19975 sgd_solver.cpp:165] Iteration 26500, lr = 0.1
I0925 22:25:49.858136 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:25:54.317353 19975 solver.cpp:357] Iteration 26600 (9.40219 iter/s, 10.6358s/100 iters), loss = 0.346456
I0925 22:25:54.317416 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.346456 (* 1 = 0.346456 loss)
I0925 22:25:54.317425 19975 sgd_solver.cpp:165] Iteration 26600, lr = 0.1
I0925 22:26:04.979161 19975 solver.cpp:357] Iteration 26700 (9.37936 iter/s, 10.6617s/100 iters), loss = 0.417376
I0925 22:26:04.979270 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.417376 (* 1 = 0.417376 loss)
I0925 22:26:04.979279 19975 sgd_solver.cpp:165] Iteration 26700, lr = 0.1
I0925 22:26:15.647960 19975 solver.cpp:357] Iteration 26800 (9.37325 iter/s, 10.6687s/100 iters), loss = 0.400999
I0925 22:26:15.648025 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.400999 (* 1 = 0.400999 loss)
I0925 22:26:15.648036 19975 sgd_solver.cpp:165] Iteration 26800, lr = 0.1
I0925 22:26:26.317364 19975 solver.cpp:357] Iteration 26900 (9.37267 iter/s, 10.6693s/100 iters), loss = 0.412132
I0925 22:26:26.317430 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.412132 (* 1 = 0.412132 loss)
I0925 22:26:26.317440 19975 sgd_solver.cpp:165] Iteration 26900, lr = 0.1
I0925 22:26:31.544056 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:26:36.874665 19975 solver.cpp:514] Iteration 27000, Testing net (#0)
I0925 22:26:40.119901 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:26:40.132699 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.819161 (* 1 = 0.819161 loss)
I0925 22:26:40.132726 19975 solver.cpp:580]     Test net output #1: prob = 0.7443
I0925 22:26:40.237299 19975 solver.cpp:357] Iteration 27000 (7.18399 iter/s, 13.9198s/100 iters), loss = 0.367434
I0925 22:26:40.237344 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.367434 (* 1 = 0.367434 loss)
I0925 22:26:40.237354 19975 sgd_solver.cpp:165] Iteration 27000, lr = 0.1
I0925 22:26:50.890902 19975 solver.cpp:357] Iteration 27100 (9.38655 iter/s, 10.6535s/100 iters), loss = 0.454409
I0925 22:26:50.890965 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.454409 (* 1 = 0.454409 loss)
I0925 22:26:50.890974 19975 sgd_solver.cpp:165] Iteration 27100, lr = 0.1
I0925 22:27:01.544904 19975 solver.cpp:357] Iteration 27200 (9.38622 iter/s, 10.6539s/100 iters), loss = 0.376612
I0925 22:27:01.544968 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.376612 (* 1 = 0.376612 loss)
I0925 22:27:01.544977 19975 sgd_solver.cpp:165] Iteration 27200, lr = 0.1
I0925 22:27:12.202653 19975 solver.cpp:357] Iteration 27300 (9.38291 iter/s, 10.6577s/100 iters), loss = 0.337255
I0925 22:27:12.202818 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.337255 (* 1 = 0.337255 loss)
I0925 22:27:12.202827 19975 sgd_solver.cpp:165] Iteration 27300, lr = 0.1
I0925 22:27:16.361585 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:27:22.856052 19975 solver.cpp:357] Iteration 27400 (9.38683 iter/s, 10.6532s/100 iters), loss = 0.310116
I0925 22:27:22.856117 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.310116 (* 1 = 0.310116 loss)
I0925 22:27:22.856127 19975 sgd_solver.cpp:165] Iteration 27400, lr = 0.1
I0925 22:27:33.415472 19975 solver.cpp:514] Iteration 27500, Testing net (#0)
I0925 22:27:36.622705 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:27:36.634804 19975 solver.cpp:580]     Test net output #0: Softmax1 = 5.27869 (* 1 = 5.27869 loss)
I0925 22:27:36.634847 19975 solver.cpp:580]     Test net output #1: prob = 0.3036
I0925 22:27:36.739939 19975 solver.cpp:357] Iteration 27500 (7.20263 iter/s, 13.8838s/100 iters), loss = 0.482098
I0925 22:27:36.739984 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.482098 (* 1 = 0.482098 loss)
I0925 22:27:36.739994 19975 sgd_solver.cpp:165] Iteration 27500, lr = 0.1
I0925 22:27:47.413233 19975 solver.cpp:357] Iteration 27600 (9.36922 iter/s, 10.6732s/100 iters), loss = 0.471364
I0925 22:27:47.413393 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.471364 (* 1 = 0.471364 loss)
I0925 22:27:47.413403 19975 sgd_solver.cpp:165] Iteration 27600, lr = 0.1
I0925 22:27:58.068178 19975 solver.cpp:357] Iteration 27700 (9.38546 iter/s, 10.6548s/100 iters), loss = 0.56443
I0925 22:27:58.068241 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.56443 (* 1 = 0.56443 loss)
I0925 22:27:58.068251 19975 sgd_solver.cpp:165] Iteration 27700, lr = 0.1
I0925 22:28:01.270251 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:28:08.721731 19975 solver.cpp:357] Iteration 27800 (9.3866 iter/s, 10.6535s/100 iters), loss = 0.372278
I0925 22:28:08.721796 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.372278 (* 1 = 0.372278 loss)
I0925 22:28:08.721807 19975 sgd_solver.cpp:165] Iteration 27800, lr = 0.1
I0925 22:28:19.377547 19975 solver.cpp:357] Iteration 27900 (9.38461 iter/s, 10.6557s/100 iters), loss = 0.458964
I0925 22:28:19.377691 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.458964 (* 1 = 0.458964 loss)
I0925 22:28:19.377701 19975 sgd_solver.cpp:165] Iteration 27900, lr = 0.1
I0925 22:28:29.937332 19975 solver.cpp:514] Iteration 28000, Testing net (#0)
I0925 22:28:33.124430 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:28:33.136456 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.758384 (* 1 = 0.758384 loss)
I0925 22:28:33.136482 19975 solver.cpp:580]     Test net output #1: prob = 0.75
I0925 22:28:33.241196 19975 solver.cpp:357] Iteration 28000 (7.21318 iter/s, 13.8635s/100 iters), loss = 0.39634
I0925 22:28:33.241238 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.39634 (* 1 = 0.39634 loss)
I0925 22:28:33.241250 19975 sgd_solver.cpp:165] Iteration 28000, lr = 0.1
I0925 22:28:43.903905 19975 solver.cpp:357] Iteration 28100 (9.37852 iter/s, 10.6627s/100 iters), loss = 0.361609
I0925 22:28:43.903970 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.361609 (* 1 = 0.361609 loss)
I0925 22:28:43.903980 19975 sgd_solver.cpp:165] Iteration 28100, lr = 0.1
I0925 22:28:46.046977 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:28:54.551407 19975 solver.cpp:357] Iteration 28200 (9.39192 iter/s, 10.6474s/100 iters), loss = 0.392131
I0925 22:28:54.551554 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.392131 (* 1 = 0.392131 loss)
I0925 22:28:54.551564 19975 sgd_solver.cpp:165] Iteration 28200, lr = 0.1
I0925 22:29:05.209434 19975 solver.cpp:357] Iteration 28300 (9.38272 iter/s, 10.6579s/100 iters), loss = 0.428046
I0925 22:29:05.209498 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.428046 (* 1 = 0.428046 loss)
I0925 22:29:05.209508 19975 sgd_solver.cpp:165] Iteration 28300, lr = 0.1
I0925 22:29:15.885157 19975 solver.cpp:357] Iteration 28400 (9.3671 iter/s, 10.6757s/100 iters), loss = 0.289365
I0925 22:29:15.885221 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.289365 (* 1 = 0.289365 loss)
I0925 22:29:15.885231 19975 sgd_solver.cpp:165] Iteration 28400, lr = 0.1
I0925 22:29:26.449154 19975 solver.cpp:514] Iteration 28500, Testing net (#0)
I0925 22:29:29.704771 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:29:29.716778 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.904116 (* 1 = 0.904116 loss)
I0925 22:29:29.716805 19975 solver.cpp:580]     Test net output #1: prob = 0.7165
I0925 22:29:29.821444 19975 solver.cpp:357] Iteration 28500 (7.17553 iter/s, 13.9362s/100 iters), loss = 0.547059
I0925 22:29:29.821486 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.547058 (* 1 = 0.547058 loss)
I0925 22:29:29.821497 19975 sgd_solver.cpp:165] Iteration 28500, lr = 0.1
I0925 22:29:31.003057 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:29:40.491580 19975 solver.cpp:357] Iteration 28600 (9.37198 iter/s, 10.6701s/100 iters), loss = 0.44141
I0925 22:29:40.491642 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.44141 (* 1 = 0.44141 loss)
I0925 22:29:40.491652 19975 sgd_solver.cpp:165] Iteration 28600, lr = 0.1
I0925 22:29:51.171298 19975 solver.cpp:357] Iteration 28700 (9.36358 iter/s, 10.6797s/100 iters), loss = 0.320968
I0925 22:29:51.171362 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.320968 (* 1 = 0.320968 loss)
I0925 22:29:51.171371 19975 sgd_solver.cpp:165] Iteration 28700, lr = 0.1
I0925 22:30:01.836462 19975 solver.cpp:357] Iteration 28800 (9.37636 iter/s, 10.6651s/100 iters), loss = 0.309917
I0925 22:30:01.836606 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.309917 (* 1 = 0.309917 loss)
I0925 22:30:01.836616 19975 sgd_solver.cpp:165] Iteration 28800, lr = 0.1
I0925 22:30:12.489832 19975 solver.cpp:357] Iteration 28900 (9.38681 iter/s, 10.6532s/100 iters), loss = 0.432354
I0925 22:30:12.489897 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.432354 (* 1 = 0.432354 loss)
I0925 22:30:12.489908 19975 sgd_solver.cpp:165] Iteration 28900, lr = 0.1
I0925 22:30:12.709319 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:30:23.037597 19975 solver.cpp:514] Iteration 29000, Testing net (#0)
I0925 22:30:26.230111 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:30:26.242120 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.982619 (* 1 = 0.982619 loss)
I0925 22:30:26.242147 19975 solver.cpp:580]     Test net output #1: prob = 0.7014
I0925 22:30:26.347121 19975 solver.cpp:357] Iteration 29000 (7.21643 iter/s, 13.8573s/100 iters), loss = 0.40691
I0925 22:30:26.347163 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.40691 (* 1 = 0.40691 loss)
I0925 22:30:26.347173 19975 sgd_solver.cpp:165] Iteration 29000, lr = 0.1
I0925 22:30:37.014997 19975 solver.cpp:357] Iteration 29100 (9.37396 iter/s, 10.6679s/100 iters), loss = 0.456466
I0925 22:30:37.015149 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.456466 (* 1 = 0.456466 loss)
I0925 22:30:37.015161 19975 sgd_solver.cpp:165] Iteration 29100, lr = 0.1
I0925 22:30:47.655838 19975 solver.cpp:357] Iteration 29200 (9.39787 iter/s, 10.6407s/100 iters), loss = 0.395964
I0925 22:30:47.655900 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.395963 (* 1 = 0.395963 loss)
I0925 22:30:47.655912 19975 sgd_solver.cpp:165] Iteration 29200, lr = 0.1
I0925 22:30:57.485723 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:30:58.323977 19975 solver.cpp:357] Iteration 29300 (9.37374 iter/s, 10.6681s/100 iters), loss = 0.406347
I0925 22:30:58.324040 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.406347 (* 1 = 0.406347 loss)
I0925 22:30:58.324049 19975 sgd_solver.cpp:165] Iteration 29300, lr = 0.1
I0925 22:31:08.987857 19975 solver.cpp:357] Iteration 29400 (9.37748 iter/s, 10.6638s/100 iters), loss = 0.384766
I0925 22:31:08.988008 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.384766 (* 1 = 0.384766 loss)
I0925 22:31:08.988016 19975 sgd_solver.cpp:165] Iteration 29400, lr = 0.1
I0925 22:31:19.537156 19975 solver.cpp:514] Iteration 29500, Testing net (#0)
I0925 22:31:22.715113 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:31:22.727175 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.0933 (* 1 = 1.0933 loss)
I0925 22:31:22.727202 19975 solver.cpp:580]     Test net output #1: prob = 0.6456
I0925 22:31:22.831665 19975 solver.cpp:357] Iteration 29500 (7.2235 iter/s, 13.8437s/100 iters), loss = 0.318146
I0925 22:31:22.831708 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.318146 (* 1 = 0.318146 loss)
I0925 22:31:22.831718 19975 sgd_solver.cpp:165] Iteration 29500, lr = 0.1
I0925 22:31:33.493424 19975 solver.cpp:357] Iteration 29600 (9.37933 iter/s, 10.6617s/100 iters), loss = 0.326907
I0925 22:31:33.493489 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.326907 (* 1 = 0.326907 loss)
I0925 22:31:33.493499 19975 sgd_solver.cpp:165] Iteration 29600, lr = 0.1
I0925 22:31:42.345856 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:31:44.149228 19975 solver.cpp:357] Iteration 29700 (9.38458 iter/s, 10.6558s/100 iters), loss = 0.321043
I0925 22:31:44.149292 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.321043 (* 1 = 0.321043 loss)
I0925 22:31:44.149302 19975 sgd_solver.cpp:165] Iteration 29700, lr = 0.1
I0925 22:31:54.815253 19975 solver.cpp:357] Iteration 29800 (9.37559 iter/s, 10.666s/100 iters), loss = 0.298738
I0925 22:31:54.815316 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.298738 (* 1 = 0.298738 loss)
I0925 22:31:54.815326 19975 sgd_solver.cpp:165] Iteration 29800, lr = 0.1
I0925 22:32:05.481060 19975 solver.cpp:357] Iteration 29900 (9.37578 iter/s, 10.6658s/100 iters), loss = 0.444131
I0925 22:32:05.481124 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.444131 (* 1 = 0.444131 loss)
I0925 22:32:05.481134 19975 sgd_solver.cpp:165] Iteration 29900, lr = 0.1
I0925 22:32:16.020243 19975 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_30000.caffemodel
I0925 22:32:16.028416 19975 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_30000.solverstate
I0925 22:32:16.031308 19975 solver.cpp:514] Iteration 30000, Testing net (#0)
I0925 22:32:19.260124 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:32:19.272332 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.14766 (* 1 = 1.14766 loss)
I0925 22:32:19.272358 19975 solver.cpp:580]     Test net output #1: prob = 0.662
I0925 22:32:19.377378 19975 solver.cpp:357] Iteration 30000 (7.19615 iter/s, 13.8963s/100 iters), loss = 0.255319
I0925 22:32:19.377420 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.255319 (* 1 = 0.255319 loss)
I0925 22:32:19.377431 19975 sgd_solver.cpp:165] Iteration 30000, lr = 0.1
I0925 22:32:27.270323 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:32:30.042011 19975 solver.cpp:357] Iteration 30100 (9.37679 iter/s, 10.6646s/100 iters), loss = 0.527659
I0925 22:32:30.042076 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.527659 (* 1 = 0.527659 loss)
I0925 22:32:30.042086 19975 sgd_solver.cpp:165] Iteration 30100, lr = 0.1
I0925 22:32:40.698395 19975 solver.cpp:357] Iteration 30200 (9.38407 iter/s, 10.6564s/100 iters), loss = 0.518166
I0925 22:32:40.698459 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.518165 (* 1 = 0.518165 loss)
I0925 22:32:40.698468 19975 sgd_solver.cpp:165] Iteration 30200, lr = 0.1
I0925 22:32:51.373173 19975 solver.cpp:357] Iteration 30300 (9.3679 iter/s, 10.6748s/100 iters), loss = 0.426792
I0925 22:32:51.373328 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.426792 (* 1 = 0.426792 loss)
I0925 22:32:51.373337 19975 sgd_solver.cpp:165] Iteration 30300, lr = 0.1
I0925 22:33:02.048692 19975 solver.cpp:357] Iteration 30400 (9.36732 iter/s, 10.6754s/100 iters), loss = 0.274122
I0925 22:33:02.048756 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.274122 (* 1 = 0.274122 loss)
I0925 22:33:02.048764 19975 sgd_solver.cpp:165] Iteration 30400, lr = 0.1
I0925 22:33:08.886895 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:33:12.603878 19975 solver.cpp:514] Iteration 30500, Testing net (#0)
I0925 22:33:15.801893 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:33:15.814407 19975 solver.cpp:580]     Test net output #0: Softmax1 = 1.09049 (* 1 = 1.09049 loss)
I0925 22:33:15.814435 19975 solver.cpp:580]     Test net output #1: prob = 0.6855
I0925 22:33:15.918933 19975 solver.cpp:357] Iteration 30500 (7.20968 iter/s, 13.8702s/100 iters), loss = 0.313517
I0925 22:33:15.918977 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.313517 (* 1 = 0.313517 loss)
I0925 22:33:15.918987 19975 sgd_solver.cpp:165] Iteration 30500, lr = 0.1
I0925 22:33:26.584194 19975 solver.cpp:357] Iteration 30600 (9.37624 iter/s, 10.6653s/100 iters), loss = 0.389374
I0925 22:33:26.584411 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.389374 (* 1 = 0.389374 loss)
I0925 22:33:26.584421 19975 sgd_solver.cpp:165] Iteration 30600, lr = 0.1
I0925 22:33:37.243538 19975 solver.cpp:357] Iteration 30700 (9.38159 iter/s, 10.6592s/100 iters), loss = 0.458165
I0925 22:33:37.243602 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.458165 (* 1 = 0.458165 loss)
I0925 22:33:37.243613 19975 sgd_solver.cpp:165] Iteration 30700, lr = 0.1
I0925 22:33:47.908457 19975 solver.cpp:357] Iteration 30800 (9.37655 iter/s, 10.6649s/100 iters), loss = 0.388051
I0925 22:33:47.908521 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.38805 (* 1 = 0.38805 loss)
I0925 22:33:47.908532 19975 sgd_solver.cpp:165] Iteration 30800, lr = 0.1
I0925 22:33:53.781347 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:33:58.574818 19975 solver.cpp:357] Iteration 30900 (9.37528 iter/s, 10.6663s/100 iters), loss = 0.517503
I0925 22:33:58.574970 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.517503 (* 1 = 0.517503 loss)
I0925 22:33:58.574980 19975 sgd_solver.cpp:165] Iteration 30900, lr = 0.1
I0925 22:34:09.119426 19975 solver.cpp:514] Iteration 31000, Testing net (#0)
I0925 22:34:12.346626 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:34:12.358584 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.841806 (* 1 = 0.841806 loss)
I0925 22:34:12.358611 19975 solver.cpp:580]     Test net output #1: prob = 0.7248
I0925 22:34:12.463724 19975 solver.cpp:357] Iteration 31000 (7.20003 iter/s, 13.8888s/100 iters), loss = 0.36924
I0925 22:34:12.463768 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.369239 (* 1 = 0.369239 loss)
I0925 22:34:12.463780 19975 sgd_solver.cpp:165] Iteration 31000, lr = 0.1
I0925 22:34:23.124966 19975 solver.cpp:357] Iteration 31100 (9.37977 iter/s, 10.6612s/100 iters), loss = 0.323611
I0925 22:34:23.125030 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.323611 (* 1 = 0.323611 loss)
I0925 22:34:23.125041 19975 sgd_solver.cpp:165] Iteration 31100, lr = 0.1
I0925 22:34:33.791471 19975 solver.cpp:357] Iteration 31200 (9.37515 iter/s, 10.6665s/100 iters), loss = 0.33407
I0925 22:34:33.791615 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.33407 (* 1 = 0.33407 loss)
I0925 22:34:33.791626 19975 sgd_solver.cpp:165] Iteration 31200, lr = 0.1
I0925 22:34:38.607306 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:34:44.463740 19975 solver.cpp:357] Iteration 31300 (9.37016 iter/s, 10.6722s/100 iters), loss = 0.302805
I0925 22:34:44.463805 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.302805 (* 1 = 0.302805 loss)
I0925 22:34:44.463815 19975 sgd_solver.cpp:165] Iteration 31300, lr = 0.1
I0925 22:34:55.115355 19975 solver.cpp:357] Iteration 31400 (9.38826 iter/s, 10.6516s/100 iters), loss = 0.408245
I0925 22:34:55.115419 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.408244 (* 1 = 0.408244 loss)
I0925 22:34:55.115428 19975 sgd_solver.cpp:165] Iteration 31400, lr = 0.1
I0925 22:35:05.677618 19975 solver.cpp:514] Iteration 31500, Testing net (#0)
I0925 22:35:08.860189 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:35:08.883496 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.872861 (* 1 = 0.872861 loss)
I0925 22:35:08.883523 19975 solver.cpp:580]     Test net output #1: prob = 0.717299
I0925 22:35:08.988641 19975 solver.cpp:357] Iteration 31500 (7.20809 iter/s, 13.8733s/100 iters), loss = 0.34004
I0925 22:35:08.988685 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.34004 (* 1 = 0.34004 loss)
I0925 22:35:08.988698 19975 sgd_solver.cpp:165] Iteration 31500, lr = 0.1
I0925 22:35:19.646988 19975 solver.cpp:357] Iteration 31600 (9.38231 iter/s, 10.6584s/100 iters), loss = 0.333061
I0925 22:35:19.647051 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.333061 (* 1 = 0.333061 loss)
I0925 22:35:19.647061 19975 sgd_solver.cpp:165] Iteration 31600, lr = 0.1
I0925 22:35:23.496341 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:35:30.306831 19975 solver.cpp:357] Iteration 31700 (9.38101 iter/s, 10.6598s/100 iters), loss = 0.45611
I0925 22:35:30.306895 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.45611 (* 1 = 0.45611 loss)
I0925 22:35:30.306906 19975 sgd_solver.cpp:165] Iteration 31700, lr = 0.1
I0925 22:35:40.975248 19975 solver.cpp:357] Iteration 31800 (9.37347 iter/s, 10.6684s/100 iters), loss = 0.311957
I0925 22:35:40.975461 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.311957 (* 1 = 0.311957 loss)
I0925 22:35:40.975471 19975 sgd_solver.cpp:165] Iteration 31800, lr = 0.1
I0925 22:35:51.629514 19975 solver.cpp:357] Iteration 31900 (9.38604 iter/s, 10.6541s/100 iters), loss = 0.362811
I0925 22:35:51.629578 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.362811 (* 1 = 0.362811 loss)
I0925 22:35:51.629587 19975 sgd_solver.cpp:165] Iteration 31900, lr = 0.1
I0925 22:36:02.183708 19975 solver.cpp:514] Iteration 32000, Testing net (#0)
I0925 22:36:05.391212 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:36:05.403803 19975 solver.cpp:580]     Test net output #0: Softmax1 = 2.72843 (* 1 = 2.72843 loss)
I0925 22:36:05.403831 19975 solver.cpp:580]     Test net output #1: prob = 0.4322
I0925 22:36:05.509166 19975 solver.cpp:357] Iteration 32000 (7.20478 iter/s, 13.8797s/100 iters), loss = 0.421654
I0925 22:36:05.509210 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.421654 (* 1 = 0.421654 loss)
I0925 22:36:05.509222 19975 sgd_solver.cpp:64] MultiStep Status: Iteration 32000, step = 1
I0925 22:36:05.509227 19975 sgd_solver.cpp:165] Iteration 32000, lr = 0.01
I0925 22:36:08.396672 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:36:16.172839 19975 solver.cpp:357] Iteration 32100 (9.37762 iter/s, 10.6637s/100 iters), loss = 0.259323
I0925 22:36:16.172951 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.259323 (* 1 = 0.259323 loss)
I0925 22:36:16.172962 19975 sgd_solver.cpp:165] Iteration 32100, lr = 0.01
I0925 22:36:26.843814 19975 solver.cpp:357] Iteration 32200 (9.37126 iter/s, 10.6709s/100 iters), loss = 0.326587
I0925 22:36:26.843878 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.326586 (* 1 = 0.326586 loss)
I0925 22:36:26.843888 19975 sgd_solver.cpp:165] Iteration 32200, lr = 0.01
I0925 22:36:37.505172 19975 solver.cpp:357] Iteration 32300 (9.37967 iter/s, 10.6614s/100 iters), loss = 0.188291
I0925 22:36:37.505236 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.188291 (* 1 = 0.188291 loss)
I0925 22:36:37.505245 19975 sgd_solver.cpp:165] Iteration 32300, lr = 0.01
I0925 22:36:48.167397 19975 solver.cpp:357] Iteration 32400 (9.3789 iter/s, 10.6622s/100 iters), loss = 0.229052
I0925 22:36:48.167500 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.229052 (* 1 = 0.229052 loss)
I0925 22:36:48.167507 19975 sgd_solver.cpp:165] Iteration 32400, lr = 0.01
I0925 22:36:49.982497 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:36:58.715574 19975 solver.cpp:514] Iteration 32500, Testing net (#0)
I0925 22:37:01.946003 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:37:01.957751 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.377423 (* 1 = 0.377423 loss)
I0925 22:37:01.957778 19975 solver.cpp:580]     Test net output #1: prob = 0.873001
I0925 22:37:02.062518 19975 solver.cpp:357] Iteration 32500 (7.19677 iter/s, 13.8951s/100 iters), loss = 0.17925
I0925 22:37:02.062561 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.17925 (* 1 = 0.17925 loss)
I0925 22:37:02.062571 19975 sgd_solver.cpp:165] Iteration 32500, lr = 0.01
I0925 22:37:12.719475 19975 solver.cpp:357] Iteration 32600 (9.38352 iter/s, 10.657s/100 iters), loss = 0.175727
I0925 22:37:12.719540 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.175727 (* 1 = 0.175727 loss)
I0925 22:37:12.719552 19975 sgd_solver.cpp:165] Iteration 32600, lr = 0.01
I0925 22:37:23.370313 19975 solver.cpp:357] Iteration 32700 (9.38893 iter/s, 10.6508s/100 iters), loss = 0.220601
I0925 22:37:23.370471 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.220601 (* 1 = 0.220601 loss)
I0925 22:37:23.370481 19975 sgd_solver.cpp:165] Iteration 32700, lr = 0.01
I0925 22:37:34.033972 19975 solver.cpp:357] Iteration 32800 (9.37772 iter/s, 10.6636s/100 iters), loss = 0.197436
I0925 22:37:34.034039 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.197436 (* 1 = 0.197436 loss)
I0925 22:37:34.034047 19975 sgd_solver.cpp:165] Iteration 32800, lr = 0.01
I0925 22:37:34.895787 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:37:44.694725 19975 solver.cpp:357] Iteration 32900 (9.3802 iter/s, 10.6608s/100 iters), loss = 0.142082
I0925 22:37:44.694788 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.142082 (* 1 = 0.142082 loss)
I0925 22:37:44.694797 19975 sgd_solver.cpp:165] Iteration 32900, lr = 0.01
I0925 22:37:55.247356 19975 solver.cpp:514] Iteration 33000, Testing net (#0)
I0925 22:37:58.498541 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:37:58.510632 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.357145 (* 1 = 0.357145 loss)
I0925 22:37:58.510658 19975 solver.cpp:580]     Test net output #1: prob = 0.876501
I0925 22:37:58.615617 19975 solver.cpp:357] Iteration 33000 (7.18343 iter/s, 13.9209s/100 iters), loss = 0.162254
I0925 22:37:58.615661 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.162253 (* 1 = 0.162253 loss)
I0925 22:37:58.615672 19975 sgd_solver.cpp:165] Iteration 33000, lr = 0.01
I0925 22:38:09.284289 19975 solver.cpp:357] Iteration 33100 (9.37322 iter/s, 10.6687s/100 iters), loss = 0.181234
I0925 22:38:09.284353 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.181234 (* 1 = 0.181234 loss)
I0925 22:38:09.284364 19975 sgd_solver.cpp:165] Iteration 33100, lr = 0.01
I0925 22:38:19.856012 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:38:19.958348 19975 solver.cpp:357] Iteration 33200 (9.3685 iter/s, 10.6741s/100 iters), loss = 0.18663
I0925 22:38:19.958398 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.18663 (* 1 = 0.18663 loss)
I0925 22:38:19.958407 19975 sgd_solver.cpp:165] Iteration 33200, lr = 0.01
I0925 22:38:30.618284 19975 solver.cpp:357] Iteration 33300 (9.3809 iter/s, 10.66s/100 iters), loss = 0.228461
I0925 22:38:30.618389 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.228461 (* 1 = 0.228461 loss)
I0925 22:38:30.618399 19975 sgd_solver.cpp:165] Iteration 33300, lr = 0.01
I0925 22:38:41.273705 19975 solver.cpp:357] Iteration 33400 (9.38492 iter/s, 10.6554s/100 iters), loss = 0.178883
I0925 22:38:41.273772 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.178883 (* 1 = 0.178883 loss)
I0925 22:38:41.273782 19975 sgd_solver.cpp:165] Iteration 33400, lr = 0.01
I0925 22:38:51.833686 19975 solver.cpp:514] Iteration 33500, Testing net (#0)
I0925 22:38:55.063587 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:38:55.075649 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.451058 (* 1 = 0.451058 loss)
I0925 22:38:55.075675 19975 solver.cpp:580]     Test net output #1: prob = 0.844901
I0925 22:38:55.179970 19975 solver.cpp:357] Iteration 33500 (7.19098 iter/s, 13.9063s/100 iters), loss = 0.1541
I0925 22:38:55.180012 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.1541 (* 1 = 0.1541 loss)
I0925 22:38:55.180022 19975 sgd_solver.cpp:165] Iteration 33500, lr = 0.01
I0925 22:39:04.677650 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:39:05.840148 19975 solver.cpp:357] Iteration 33600 (9.38068 iter/s, 10.6602s/100 iters), loss = 0.234472
I0925 22:39:05.840212 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.234472 (* 1 = 0.234472 loss)
I0925 22:39:05.840221 19975 sgd_solver.cpp:165] Iteration 33600, lr = 0.01
I0925 22:39:16.491744 19975 solver.cpp:357] Iteration 33700 (9.38826 iter/s, 10.6516s/100 iters), loss = 0.176412
I0925 22:39:16.491809 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.176411 (* 1 = 0.176411 loss)
I0925 22:39:16.491818 19975 sgd_solver.cpp:165] Iteration 33700, lr = 0.01
I0925 22:39:27.150378 19975 solver.cpp:357] Iteration 33800 (9.38206 iter/s, 10.6586s/100 iters), loss = 0.155459
I0925 22:39:27.150444 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.155459 (* 1 = 0.155459 loss)
I0925 22:39:27.150454 19975 sgd_solver.cpp:165] Iteration 33800, lr = 0.01
I0925 22:39:37.812448 19975 solver.cpp:357] Iteration 33900 (9.37903 iter/s, 10.6621s/100 iters), loss = 0.1815
I0925 22:39:37.812603 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.1815 (* 1 = 0.1815 loss)
I0925 22:39:37.812613 19975 sgd_solver.cpp:165] Iteration 33900, lr = 0.01
I0925 22:39:46.346186 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:39:48.365837 19975 solver.cpp:514] Iteration 34000, Testing net (#0)
I0925 22:39:51.593593 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:39:51.606297 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.636163 (* 1 = 0.636163 loss)
I0925 22:39:51.606323 19975 solver.cpp:580]     Test net output #1: prob = 0.7859
I0925 22:39:51.710952 19975 solver.cpp:357] Iteration 34000 (7.19504 iter/s, 13.8985s/100 iters), loss = 0.0979073
I0925 22:39:51.710992 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0979072 (* 1 = 0.0979072 loss)
I0925 22:39:51.711004 19975 sgd_solver.cpp:165] Iteration 34000, lr = 0.01
I0925 22:40:02.372006 19975 solver.cpp:357] Iteration 34100 (9.3799 iter/s, 10.6611s/100 iters), loss = 0.250207
I0925 22:40:02.372071 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.250207 (* 1 = 0.250207 loss)
I0925 22:40:02.372083 19975 sgd_solver.cpp:165] Iteration 34100, lr = 0.01
I0925 22:40:13.021945 19975 solver.cpp:357] Iteration 34200 (9.38971 iter/s, 10.65s/100 iters), loss = 0.129354
I0925 22:40:13.022094 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.129353 (* 1 = 0.129353 loss)
I0925 22:40:13.022105 19975 sgd_solver.cpp:165] Iteration 34200, lr = 0.01
I0925 22:40:23.687649 19975 solver.cpp:357] Iteration 34300 (9.37591 iter/s, 10.6656s/100 iters), loss = 0.119421
I0925 22:40:23.687718 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.119421 (* 1 = 0.119421 loss)
I0925 22:40:23.687727 19975 sgd_solver.cpp:165] Iteration 34300, lr = 0.01
I0925 22:40:31.159191 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:40:34.338004 19975 solver.cpp:357] Iteration 34400 (9.38935 iter/s, 10.6504s/100 iters), loss = 0.258373
I0925 22:40:34.338068 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.258373 (* 1 = 0.258373 loss)
I0925 22:40:34.338079 19975 sgd_solver.cpp:165] Iteration 34400, lr = 0.01
I0925 22:40:44.888741 19975 solver.cpp:514] Iteration 34500, Testing net (#0)
I0925 22:40:48.086203 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:40:48.098295 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.551026 (* 1 = 0.551026 loss)
I0925 22:40:48.098322 19975 solver.cpp:580]     Test net output #1: prob = 0.816701
I0925 22:40:48.205086 19975 solver.cpp:357] Iteration 34500 (7.2113 iter/s, 13.8671s/100 iters), loss = 0.102972
I0925 22:40:48.205132 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.102972 (* 1 = 0.102972 loss)
I0925 22:40:48.205144 19975 sgd_solver.cpp:165] Iteration 34500, lr = 0.01
I0925 22:40:58.870362 19975 solver.cpp:357] Iteration 34600 (9.37619 iter/s, 10.6653s/100 iters), loss = 0.234781
I0925 22:40:58.870427 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.234781 (* 1 = 0.234781 loss)
I0925 22:40:58.870437 19975 sgd_solver.cpp:165] Iteration 34600, lr = 0.01
I0925 22:41:09.522588 19975 solver.cpp:357] Iteration 34700 (9.3877 iter/s, 10.6522s/100 iters), loss = 0.127645
I0925 22:41:09.522655 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.127644 (* 1 = 0.127644 loss)
I0925 22:41:09.522663 19975 sgd_solver.cpp:165] Iteration 34700, lr = 0.01
I0925 22:41:16.019556 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:41:20.166693 19975 solver.cpp:357] Iteration 34800 (9.39486 iter/s, 10.6441s/100 iters), loss = 0.147704
I0925 22:41:20.166760 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.147704 (* 1 = 0.147704 loss)
I0925 22:41:20.166774 19975 sgd_solver.cpp:165] Iteration 34800, lr = 0.01
I0925 22:41:30.830387 19975 solver.cpp:357] Iteration 34900 (9.3776 iter/s, 10.6637s/100 iters), loss = 0.148597
I0925 22:41:30.830449 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.148597 (* 1 = 0.148597 loss)
I0925 22:41:30.830461 19975 sgd_solver.cpp:165] Iteration 34900, lr = 0.01
I0925 22:41:41.386842 19975 solver.cpp:514] Iteration 35000, Testing net (#0)
I0925 22:41:44.590894 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:41:44.602710 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.576768 (* 1 = 0.576768 loss)
I0925 22:41:44.602737 19975 solver.cpp:580]     Test net output #1: prob = 0.808601
I0925 22:41:44.707607 19975 solver.cpp:357] Iteration 35000 (7.20603 iter/s, 13.8773s/100 iters), loss = 0.123586
I0925 22:41:44.707651 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.123586 (* 1 = 0.123586 loss)
I0925 22:41:44.707662 19975 sgd_solver.cpp:165] Iteration 35000, lr = 0.01
I0925 22:41:55.369835 19975 solver.cpp:357] Iteration 35100 (9.37887 iter/s, 10.6623s/100 iters), loss = 0.154527
I0925 22:41:55.369969 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.154527 (* 1 = 0.154527 loss)
I0925 22:41:55.369978 19975 sgd_solver.cpp:165] Iteration 35100, lr = 0.01
I0925 22:42:00.921394 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:42:06.034801 19975 solver.cpp:357] Iteration 35200 (9.37654 iter/s, 10.6649s/100 iters), loss = 0.121542
I0925 22:42:06.034868 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.121542 (* 1 = 0.121542 loss)
I0925 22:42:06.034876 19975 sgd_solver.cpp:165] Iteration 35200, lr = 0.01
I0925 22:42:16.688554 19975 solver.cpp:357] Iteration 35300 (9.38635 iter/s, 10.6538s/100 iters), loss = 0.163921
I0925 22:42:16.688617 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.163921 (* 1 = 0.163921 loss)
I0925 22:42:16.688627 19975 sgd_solver.cpp:165] Iteration 35300, lr = 0.01
I0925 22:42:27.354670 19975 solver.cpp:357] Iteration 35400 (9.37547 iter/s, 10.6661s/100 iters), loss = 0.125524
I0925 22:42:27.354822 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.125524 (* 1 = 0.125524 loss)
I0925 22:42:27.354831 19975 sgd_solver.cpp:165] Iteration 35400, lr = 0.01
I0925 22:42:37.917320 19975 solver.cpp:514] Iteration 35500, Testing net (#0)
I0925 22:42:41.149592 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:42:41.161545 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.758442 (* 1 = 0.758442 loss)
I0925 22:42:41.161571 19975 solver.cpp:580]     Test net output #1: prob = 0.752999
I0925 22:42:41.266057 19975 solver.cpp:357] Iteration 35500 (7.18837 iter/s, 13.9114s/100 iters), loss = 0.186832
I0925 22:42:41.266100 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.186832 (* 1 = 0.186832 loss)
I0925 22:42:41.266110 19975 sgd_solver.cpp:165] Iteration 35500, lr = 0.01
I0925 22:42:45.757113 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:42:51.930686 19975 solver.cpp:357] Iteration 35600 (9.37676 iter/s, 10.6647s/100 iters), loss = 0.194898
I0925 22:42:51.930750 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.194898 (* 1 = 0.194898 loss)
I0925 22:42:51.930761 19975 sgd_solver.cpp:165] Iteration 35600, lr = 0.01
I0925 22:43:02.586474 19975 solver.cpp:357] Iteration 35700 (9.38455 iter/s, 10.6558s/100 iters), loss = 0.128149
I0925 22:43:02.586627 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.128148 (* 1 = 0.128148 loss)
I0925 22:43:02.586637 19975 sgd_solver.cpp:165] Iteration 35700, lr = 0.01
I0925 22:43:13.249027 19975 solver.cpp:357] Iteration 35800 (9.37868 iter/s, 10.6625s/100 iters), loss = 0.124538
I0925 22:43:13.249091 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.124537 (* 1 = 0.124537 loss)
I0925 22:43:13.249102 19975 sgd_solver.cpp:165] Iteration 35800, lr = 0.01
I0925 22:43:23.910012 19975 solver.cpp:357] Iteration 35900 (9.37998 iter/s, 10.661s/100 iters), loss = 0.153946
I0925 22:43:23.910073 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.153946 (* 1 = 0.153946 loss)
I0925 22:43:23.910084 19975 sgd_solver.cpp:165] Iteration 35900, lr = 0.01
I0925 22:43:27.430394 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:43:34.454314 19975 solver.cpp:514] Iteration 36000, Testing net (#0)
I0925 22:43:37.693197 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:43:37.705231 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.524227 (* 1 = 0.524227 loss)
I0925 22:43:37.705260 19975 solver.cpp:580]     Test net output #1: prob = 0.821701
I0925 22:43:37.810359 19975 solver.cpp:357] Iteration 36000 (7.19404 iter/s, 13.9004s/100 iters), loss = 0.180229
I0925 22:43:37.810403 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.180229 (* 1 = 0.180229 loss)
I0925 22:43:37.810415 19975 sgd_solver.cpp:165] Iteration 36000, lr = 0.01
I0925 22:43:48.466675 19975 solver.cpp:357] Iteration 36100 (9.38407 iter/s, 10.6564s/100 iters), loss = 0.166269
I0925 22:43:48.466740 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.166269 (* 1 = 0.166269 loss)
I0925 22:43:48.466753 19975 sgd_solver.cpp:165] Iteration 36100, lr = 0.01
I0925 22:43:59.141808 19975 solver.cpp:357] Iteration 36200 (9.36755 iter/s, 10.6752s/100 iters), loss = 0.10623
I0925 22:43:59.141870 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.10623 (* 1 = 0.10623 loss)
I0925 22:43:59.141880 19975 sgd_solver.cpp:165] Iteration 36200, lr = 0.01
I0925 22:44:09.802482 19975 solver.cpp:357] Iteration 36300 (9.38025 iter/s, 10.6607s/100 iters), loss = 0.172659
I0925 22:44:09.802629 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.172659 (* 1 = 0.172659 loss)
I0925 22:44:09.802639 19975 sgd_solver.cpp:165] Iteration 36300, lr = 0.01
I0925 22:44:12.364789 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:44:20.472319 19975 solver.cpp:357] Iteration 36400 (9.37227 iter/s, 10.6698s/100 iters), loss = 0.175541
I0925 22:44:20.472384 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.175541 (* 1 = 0.175541 loss)
I0925 22:44:20.472394 19975 sgd_solver.cpp:165] Iteration 36400, lr = 0.01
I0925 22:44:31.023850 19975 solver.cpp:514] Iteration 36500, Testing net (#0)
I0925 22:44:34.271504 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:44:34.283008 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.623385 (* 1 = 0.623385 loss)
I0925 22:44:34.283035 19975 solver.cpp:580]     Test net output #1: prob = 0.8053
I0925 22:44:34.387828 19975 solver.cpp:357] Iteration 36500 (7.1862 iter/s, 13.9156s/100 iters), loss = 0.115504
I0925 22:44:34.387873 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.115504 (* 1 = 0.115504 loss)
I0925 22:44:34.387887 19975 sgd_solver.cpp:165] Iteration 36500, lr = 0.01
I0925 22:44:45.038820 19975 solver.cpp:357] Iteration 36600 (9.38876 iter/s, 10.651s/100 iters), loss = 0.129073
I0925 22:44:45.038966 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.129073 (* 1 = 0.129073 loss)
I0925 22:44:45.038978 19975 sgd_solver.cpp:165] Iteration 36600, lr = 0.01
I0925 22:44:55.712435 19975 solver.cpp:357] Iteration 36700 (9.36895 iter/s, 10.6736s/100 iters), loss = 0.133575
I0925 22:44:55.712498 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.133575 (* 1 = 0.133575 loss)
I0925 22:44:55.712509 19975 sgd_solver.cpp:165] Iteration 36700, lr = 0.01
I0925 22:44:57.210772 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:45:06.386248 19975 solver.cpp:357] Iteration 36800 (9.3687 iter/s, 10.6738s/100 iters), loss = 0.164267
I0925 22:45:06.386313 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.164267 (* 1 = 0.164267 loss)
I0925 22:45:06.386325 19975 sgd_solver.cpp:165] Iteration 36800, lr = 0.01
I0925 22:45:17.045382 19975 solver.cpp:357] Iteration 36900 (9.38161 iter/s, 10.6592s/100 iters), loss = 0.185701
I0925 22:45:17.045580 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.185701 (* 1 = 0.185701 loss)
I0925 22:45:17.045590 19975 sgd_solver.cpp:165] Iteration 36900, lr = 0.01
I0925 22:45:27.593211 19975 solver.cpp:514] Iteration 37000, Testing net (#0)
I0925 22:45:30.857321 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:45:30.869426 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.399427 (* 1 = 0.399427 loss)
I0925 22:45:30.869452 19975 solver.cpp:580]     Test net output #1: prob = 0.861601
I0925 22:45:30.974016 19975 solver.cpp:357] Iteration 37000 (7.17949 iter/s, 13.9286s/100 iters), loss = 0.17978
I0925 22:45:30.974059 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.17978 (* 1 = 0.17978 loss)
I0925 22:45:30.974071 19975 sgd_solver.cpp:165] Iteration 37000, lr = 0.01
I0925 22:45:41.647406 19975 solver.cpp:357] Iteration 37100 (9.3688 iter/s, 10.6737s/100 iters), loss = 0.104899
I0925 22:45:41.647469 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.104898 (* 1 = 0.104898 loss)
I0925 22:45:41.647477 19975 sgd_solver.cpp:165] Iteration 37100, lr = 0.01
I0925 22:45:42.188796 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:45:52.292937 19975 solver.cpp:357] Iteration 37200 (9.39286 iter/s, 10.6464s/100 iters), loss = 0.142249
I0925 22:45:52.293081 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.142248 (* 1 = 0.142248 loss)
I0925 22:45:52.293090 19975 sgd_solver.cpp:165] Iteration 37200, lr = 0.01
I0925 22:46:02.942903 19975 solver.cpp:357] Iteration 37300 (9.38903 iter/s, 10.6507s/100 iters), loss = 0.16233
I0925 22:46:02.942961 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.162329 (* 1 = 0.162329 loss)
I0925 22:46:02.942970 19975 sgd_solver.cpp:165] Iteration 37300, lr = 0.01
I0925 22:46:13.611920 19975 solver.cpp:357] Iteration 37400 (9.3722 iter/s, 10.6699s/100 iters), loss = 0.168187
I0925 22:46:13.611986 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.168187 (* 1 = 0.168187 loss)
I0925 22:46:13.611996 19975 sgd_solver.cpp:165] Iteration 37400, lr = 0.01
I0925 22:46:23.759435 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:46:24.175151 19975 solver.cpp:514] Iteration 37500, Testing net (#0)
I0925 22:46:27.398512 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:46:27.411151 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.693149 (* 1 = 0.693149 loss)
I0925 22:46:27.411178 19975 solver.cpp:580]     Test net output #1: prob = 0.772301
I0925 22:46:27.515734 19975 solver.cpp:357] Iteration 37500 (7.19171 iter/s, 13.9049s/100 iters), loss = 0.111143
I0925 22:46:27.515779 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.111143 (* 1 = 0.111143 loss)
I0925 22:46:27.515792 19975 sgd_solver.cpp:165] Iteration 37500, lr = 0.01
I0925 22:46:38.177750 19975 solver.cpp:357] Iteration 37600 (9.37837 iter/s, 10.6628s/100 iters), loss = 0.158127
I0925 22:46:38.177812 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.158127 (* 1 = 0.158127 loss)
I0925 22:46:38.177822 19975 sgd_solver.cpp:165] Iteration 37600, lr = 0.01
I0925 22:46:48.834959 19975 solver.cpp:357] Iteration 37700 (9.38263 iter/s, 10.658s/100 iters), loss = 0.208796
I0925 22:46:48.835024 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.208795 (* 1 = 0.208795 loss)
I0925 22:46:48.835036 19975 sgd_solver.cpp:165] Iteration 37700, lr = 0.01
I0925 22:46:59.496915 19975 solver.cpp:357] Iteration 37800 (9.37847 iter/s, 10.6627s/100 iters), loss = 0.203307
I0925 22:46:59.497226 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.203307 (* 1 = 0.203307 loss)
I0925 22:46:59.497236 19975 sgd_solver.cpp:165] Iteration 37800, lr = 0.01
I0925 22:47:08.682266 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:47:10.168447 19975 solver.cpp:357] Iteration 37900 (9.37028 iter/s, 10.672s/100 iters), loss = 0.184479
I0925 22:47:10.168511 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.184478 (* 1 = 0.184478 loss)
I0925 22:47:10.168519 19975 sgd_solver.cpp:165] Iteration 37900, lr = 0.01
I0925 22:47:20.734982 19975 solver.cpp:514] Iteration 38000, Testing net (#0)
I0925 22:47:23.914088 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:47:23.926170 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.746712 (* 1 = 0.746712 loss)
I0925 22:47:23.926198 19975 solver.cpp:580]     Test net output #1: prob = 0.7623
I0925 22:47:24.031491 19975 solver.cpp:357] Iteration 38000 (7.21291 iter/s, 13.864s/100 iters), loss = 0.114515
I0925 22:47:24.031533 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.114515 (* 1 = 0.114515 loss)
I0925 22:47:24.031543 19975 sgd_solver.cpp:165] Iteration 38000, lr = 0.01
I0925 22:47:34.697316 19975 solver.cpp:357] Iteration 38100 (9.37508 iter/s, 10.6666s/100 iters), loss = 0.103616
I0925 22:47:34.697427 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.103616 (* 1 = 0.103616 loss)
I0925 22:47:34.697439 19975 sgd_solver.cpp:165] Iteration 38100, lr = 0.01
I0925 22:47:45.359835 19975 solver.cpp:357] Iteration 38200 (9.37806 iter/s, 10.6632s/100 iters), loss = 0.0880601
I0925 22:47:45.359899 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0880599 (* 1 = 0.0880599 loss)
I0925 22:47:45.359910 19975 sgd_solver.cpp:165] Iteration 38200, lr = 0.01
I0925 22:47:53.569286 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:47:56.013762 19975 solver.cpp:357] Iteration 38300 (9.38559 iter/s, 10.6546s/100 iters), loss = 0.169782
I0925 22:47:56.013828 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.169782 (* 1 = 0.169782 loss)
I0925 22:47:56.013836 19975 sgd_solver.cpp:165] Iteration 38300, lr = 0.01
I0925 22:48:06.675251 19975 solver.cpp:357] Iteration 38400 (9.37895 iter/s, 10.6622s/100 iters), loss = 0.133604
I0925 22:48:06.675396 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.133603 (* 1 = 0.133603 loss)
I0925 22:48:06.675407 19975 sgd_solver.cpp:165] Iteration 38400, lr = 0.01
I0925 22:48:17.230975 19975 solver.cpp:514] Iteration 38500, Testing net (#0)
I0925 22:48:20.424027 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:48:20.436071 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.543796 (* 1 = 0.543796 loss)
I0925 22:48:20.436098 19975 solver.cpp:580]     Test net output #1: prob = 0.825001
I0925 22:48:20.541281 19975 solver.cpp:357] Iteration 38500 (7.21144 iter/s, 13.8669s/100 iters), loss = 0.137605
I0925 22:48:20.541324 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.137605 (* 1 = 0.137605 loss)
I0925 22:48:20.541337 19975 sgd_solver.cpp:165] Iteration 38500, lr = 0.01
I0925 22:48:31.198683 19975 solver.cpp:357] Iteration 38600 (9.38255 iter/s, 10.6581s/100 iters), loss = 0.0997055
I0925 22:48:31.198747 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0997053 (* 1 = 0.0997053 loss)
I0925 22:48:31.198758 19975 sgd_solver.cpp:165] Iteration 38600, lr = 0.01
I0925 22:48:38.337627 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:48:41.845672 19975 solver.cpp:357] Iteration 38700 (9.39175 iter/s, 10.6476s/100 iters), loss = 0.129227
I0925 22:48:41.845736 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.129227 (* 1 = 0.129227 loss)
I0925 22:48:41.845746 19975 sgd_solver.cpp:165] Iteration 38700, lr = 0.01
I0925 22:48:52.506690 19975 solver.cpp:357] Iteration 38800 (9.3794 iter/s, 10.6617s/100 iters), loss = 0.136126
I0925 22:48:52.506753 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.136126 (* 1 = 0.136126 loss)
I0925 22:48:52.506764 19975 sgd_solver.cpp:165] Iteration 38800, lr = 0.01
I0925 22:49:03.171968 19975 solver.cpp:357] Iteration 38900 (9.37567 iter/s, 10.6659s/100 iters), loss = 0.146646
I0925 22:49:03.172034 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.146646 (* 1 = 0.146646 loss)
I0925 22:49:03.172044 19975 sgd_solver.cpp:165] Iteration 38900, lr = 0.01
I0925 22:49:13.724745 19975 solver.cpp:514] Iteration 39000, Testing net (#0)
I0925 22:49:16.988118 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:49:16.999826 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.833337 (* 1 = 0.833337 loss)
I0925 22:49:16.999853 19975 solver.cpp:580]     Test net output #1: prob = 0.7629
I0925 22:49:17.104517 19975 solver.cpp:357] Iteration 39000 (7.17701 iter/s, 13.9334s/100 iters), loss = 0.0732174
I0925 22:49:17.104560 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0732172 (* 1 = 0.0732172 loss)
I0925 22:49:17.104571 19975 sgd_solver.cpp:165] Iteration 39000, lr = 0.01
I0925 22:49:23.294700 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:49:27.768923 19975 solver.cpp:357] Iteration 39100 (9.37644 iter/s, 10.665s/100 iters), loss = 0.0829734
I0925 22:49:27.768990 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0829733 (* 1 = 0.0829733 loss)
I0925 22:49:27.768998 19975 sgd_solver.cpp:165] Iteration 39100, lr = 0.01
I0925 22:49:38.438979 19975 solver.cpp:357] Iteration 39200 (9.3715 iter/s, 10.6707s/100 iters), loss = 0.203161
I0925 22:49:38.439044 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.203161 (* 1 = 0.203161 loss)
I0925 22:49:38.439054 19975 sgd_solver.cpp:165] Iteration 39200, lr = 0.01
I0925 22:49:49.110057 19975 solver.cpp:357] Iteration 39300 (9.37061 iter/s, 10.6717s/100 iters), loss = 0.0769331
I0925 22:49:49.110215 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.076933 (* 1 = 0.076933 loss)
I0925 22:49:49.110226 19975 sgd_solver.cpp:165] Iteration 39300, lr = 0.01
I0925 22:49:59.774617 19975 solver.cpp:357] Iteration 39400 (9.37642 iter/s, 10.665s/100 iters), loss = 0.17661
I0925 22:49:59.774684 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.17661 (* 1 = 0.17661 loss)
I0925 22:49:59.774694 19975 sgd_solver.cpp:165] Iteration 39400, lr = 0.01
I0925 22:50:05.006870 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:50:10.331964 19975 solver.cpp:514] Iteration 39500, Testing net (#0)
I0925 22:50:13.571569 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:50:13.584059 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.66287 (* 1 = 0.66287 loss)
I0925 22:50:13.584085 19975 solver.cpp:580]     Test net output #1: prob = 0.7858
I0925 22:50:13.688742 19975 solver.cpp:357] Iteration 39500 (7.18654 iter/s, 13.9149s/100 iters), loss = 0.130417
I0925 22:50:13.688784 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.130417 (* 1 = 0.130417 loss)
I0925 22:50:13.688797 19975 sgd_solver.cpp:165] Iteration 39500, lr = 0.01
I0925 22:50:24.354807 19975 solver.cpp:357] Iteration 39600 (9.37502 iter/s, 10.6666s/100 iters), loss = 0.158235
I0925 22:50:24.354960 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.158235 (* 1 = 0.158235 loss)
I0925 22:50:24.354970 19975 sgd_solver.cpp:165] Iteration 39600, lr = 0.01
I0925 22:50:35.010912 19975 solver.cpp:357] Iteration 39700 (9.38389 iter/s, 10.6566s/100 iters), loss = 0.147363
I0925 22:50:35.010978 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.147363 (* 1 = 0.147363 loss)
I0925 22:50:35.010987 19975 sgd_solver.cpp:165] Iteration 39700, lr = 0.01
I0925 22:50:45.681071 19975 solver.cpp:357] Iteration 39800 (9.37146 iter/s, 10.6707s/100 iters), loss = 0.117516
I0925 22:50:45.681135 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.117516 (* 1 = 0.117516 loss)
I0925 22:50:45.681144 19975 sgd_solver.cpp:165] Iteration 39800, lr = 0.01
I0925 22:50:49.843920 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:50:56.344082 19975 solver.cpp:357] Iteration 39900 (9.37775 iter/s, 10.6635s/100 iters), loss = 0.146237
I0925 22:50:56.344286 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.146237 (* 1 = 0.146237 loss)
I0925 22:50:56.344297 19975 sgd_solver.cpp:165] Iteration 39900, lr = 0.01
I0925 22:51:06.888028 19975 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_40000.caffemodel
I0925 22:51:06.896143 19975 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_40000.solverstate
I0925 22:51:06.899013 19975 solver.cpp:514] Iteration 40000, Testing net (#0)
I0925 22:51:10.131259 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:51:10.143517 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.526718 (* 1 = 0.526718 loss)
I0925 22:51:10.143543 19975 solver.cpp:580]     Test net output #1: prob = 0.833501
I0925 22:51:10.247918 19975 solver.cpp:357] Iteration 40000 (7.19196 iter/s, 13.9044s/100 iters), loss = 0.146216
I0925 22:51:10.247961 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.146216 (* 1 = 0.146216 loss)
I0925 22:51:10.247972 19975 sgd_solver.cpp:165] Iteration 40000, lr = 0.01
I0925 22:51:20.907166 19975 solver.cpp:357] Iteration 40100 (9.38106 iter/s, 10.6598s/100 iters), loss = 0.204093
I0925 22:51:20.907230 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.204093 (* 1 = 0.204093 loss)
I0925 22:51:20.907240 19975 sgd_solver.cpp:165] Iteration 40100, lr = 0.01
I0925 22:51:31.580278 19975 solver.cpp:357] Iteration 40200 (9.36889 iter/s, 10.6736s/100 iters), loss = 0.189258
I0925 22:51:31.580406 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.189257 (* 1 = 0.189257 loss)
I0925 22:51:31.580416 19975 sgd_solver.cpp:165] Iteration 40200, lr = 0.01
I0925 22:51:34.786582 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:51:42.229707 19975 solver.cpp:357] Iteration 40300 (9.38979 iter/s, 10.6499s/100 iters), loss = 0.10267
I0925 22:51:42.229773 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.102669 (* 1 = 0.102669 loss)
I0925 22:51:42.229784 19975 sgd_solver.cpp:165] Iteration 40300, lr = 0.01
I0925 22:51:52.893605 19975 solver.cpp:357] Iteration 40400 (9.37701 iter/s, 10.6644s/100 iters), loss = 0.177345
I0925 22:51:52.893668 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.177345 (* 1 = 0.177345 loss)
I0925 22:51:52.893681 19975 sgd_solver.cpp:165] Iteration 40400, lr = 0.01
I0925 22:52:03.446177 19975 solver.cpp:514] Iteration 40500, Testing net (#0)
I0925 22:52:06.644251 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:52:06.656358 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.401682 (* 1 = 0.401682 loss)
I0925 22:52:06.656384 19975 solver.cpp:580]     Test net output #1: prob = 0.868101
I0925 22:52:06.761122 19975 solver.cpp:357] Iteration 40500 (7.21076 iter/s, 13.8682s/100 iters), loss = 0.139883
I0925 22:52:06.761168 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.139883 (* 1 = 0.139883 loss)
I0925 22:52:06.761180 19975 sgd_solver.cpp:165] Iteration 40500, lr = 0.01
I0925 22:52:17.404495 19975 solver.cpp:357] Iteration 40600 (9.39509 iter/s, 10.6439s/100 iters), loss = 0.134999
I0925 22:52:17.404558 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.134999 (* 1 = 0.134999 loss)
I0925 22:52:17.404568 19975 sgd_solver.cpp:165] Iteration 40600, lr = 0.01
I0925 22:52:19.551765 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:52:28.062080 19975 solver.cpp:357] Iteration 40700 (9.38258 iter/s, 10.6581s/100 iters), loss = 0.127208
I0925 22:52:28.062144 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.127208 (* 1 = 0.127208 loss)
I0925 22:52:28.062155 19975 sgd_solver.cpp:165] Iteration 40700, lr = 0.01
I0925 22:52:38.715052 19975 solver.cpp:357] Iteration 40800 (9.38665 iter/s, 10.6534s/100 iters), loss = 0.0869955
I0925 22:52:38.715287 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0869955 (* 1 = 0.0869955 loss)
I0925 22:52:38.715297 19975 sgd_solver.cpp:165] Iteration 40800, lr = 0.01
I0925 22:52:49.371942 19975 solver.cpp:357] Iteration 40900 (9.38335 iter/s, 10.6572s/100 iters), loss = 0.124592
I0925 22:52:49.372009 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.124592 (* 1 = 0.124592 loss)
I0925 22:52:49.372018 19975 sgd_solver.cpp:165] Iteration 40900, lr = 0.01
I0925 22:52:59.924123 19975 solver.cpp:514] Iteration 41000, Testing net (#0)
I0925 22:53:03.181622 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:53:03.193703 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.488967 (* 1 = 0.488967 loss)
I0925 22:53:03.193730 19975 solver.cpp:580]     Test net output #1: prob = 0.842901
I0925 22:53:03.298910 19975 solver.cpp:357] Iteration 41000 (7.18 iter/s, 13.9276s/100 iters), loss = 0.079511
I0925 22:53:03.298954 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0795109 (* 1 = 0.0795109 loss)
I0925 22:53:03.298966 19975 sgd_solver.cpp:165] Iteration 41000, lr = 0.01
I0925 22:53:04.478665 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:53:13.962009 19975 solver.cpp:357] Iteration 41100 (9.37774 iter/s, 10.6636s/100 iters), loss = 0.0955435
I0925 22:53:13.962163 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0955434 (* 1 = 0.0955434 loss)
I0925 22:53:13.962173 19975 sgd_solver.cpp:165] Iteration 41100, lr = 0.01
I0925 22:53:24.623083 19975 solver.cpp:357] Iteration 41200 (9.37962 iter/s, 10.6614s/100 iters), loss = 0.0823843
I0925 22:53:24.623150 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0823843 (* 1 = 0.0823843 loss)
I0925 22:53:24.623160 19975 sgd_solver.cpp:165] Iteration 41200, lr = 0.01
I0925 22:53:35.280623 19975 solver.cpp:357] Iteration 41300 (9.38266 iter/s, 10.658s/100 iters), loss = 0.0537296
I0925 22:53:35.280688 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0537295 (* 1 = 0.0537295 loss)
I0925 22:53:35.280697 19975 sgd_solver.cpp:165] Iteration 41300, lr = 0.01
I0925 22:53:45.941138 19975 solver.cpp:357] Iteration 41400 (9.38004 iter/s, 10.6609s/100 iters), loss = 0.154483
I0925 22:53:45.941287 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.154483 (* 1 = 0.154483 loss)
I0925 22:53:45.941295 19975 sgd_solver.cpp:165] Iteration 41400, lr = 0.01
I0925 22:53:46.161247 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:53:56.497416 19975 solver.cpp:514] Iteration 41500, Testing net (#0)
I0925 22:53:59.704970 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:53:59.717111 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.651851 (* 1 = 0.651851 loss)
I0925 22:53:59.717139 19975 solver.cpp:580]     Test net output #1: prob = 0.8023
I0925 22:53:59.822676 19975 solver.cpp:357] Iteration 41500 (7.20356 iter/s, 13.882s/100 iters), loss = 0.0922298
I0925 22:53:59.822721 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0922297 (* 1 = 0.0922297 loss)
I0925 22:53:59.822734 19975 sgd_solver.cpp:165] Iteration 41500, lr = 0.01
I0925 22:54:10.473990 19975 solver.cpp:357] Iteration 41600 (9.38814 iter/s, 10.6517s/100 iters), loss = 0.173044
I0925 22:54:10.474054 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.173044 (* 1 = 0.173044 loss)
I0925 22:54:10.474063 19975 sgd_solver.cpp:165] Iteration 41600, lr = 0.01
I0925 22:54:21.132146 19975 solver.cpp:357] Iteration 41700 (9.38213 iter/s, 10.6586s/100 iters), loss = 0.129931
I0925 22:54:21.132249 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.129931 (* 1 = 0.129931 loss)
I0925 22:54:21.132261 19975 sgd_solver.cpp:165] Iteration 41700, lr = 0.01
I0925 22:54:30.953387 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:54:31.791425 19975 solver.cpp:357] Iteration 41800 (9.38119 iter/s, 10.6596s/100 iters), loss = 0.155279
I0925 22:54:31.791491 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.155279 (* 1 = 0.155279 loss)
I0925 22:54:31.791499 19975 sgd_solver.cpp:165] Iteration 41800, lr = 0.01
I0925 22:54:42.456737 19975 solver.cpp:357] Iteration 41900 (9.37585 iter/s, 10.6657s/100 iters), loss = 0.104722
I0925 22:54:42.456804 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.104722 (* 1 = 0.104722 loss)
I0925 22:54:42.456812 19975 sgd_solver.cpp:165] Iteration 41900, lr = 0.01
I0925 22:54:53.009747 19975 solver.cpp:514] Iteration 42000, Testing net (#0)
I0925 22:54:56.238574 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:54:56.251194 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.436817 (* 1 = 0.436817 loss)
I0925 22:54:56.251221 19975 solver.cpp:580]     Test net output #1: prob = 0.855502
I0925 22:54:56.355715 19975 solver.cpp:357] Iteration 42000 (7.1945 iter/s, 13.8995s/100 iters), loss = 0.0608235
I0925 22:54:56.355758 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0608235 (* 1 = 0.0608235 loss)
I0925 22:54:56.355772 19975 sgd_solver.cpp:165] Iteration 42000, lr = 0.01
I0925 22:55:07.024466 19975 solver.cpp:357] Iteration 42100 (9.37282 iter/s, 10.6691s/100 iters), loss = 0.0713798
I0925 22:55:07.024531 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0713797 (* 1 = 0.0713797 loss)
I0925 22:55:07.024543 19975 sgd_solver.cpp:165] Iteration 42100, lr = 0.01
I0925 22:55:15.879429 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:55:17.686805 19975 solver.cpp:357] Iteration 42200 (9.37848 iter/s, 10.6627s/100 iters), loss = 0.125169
I0925 22:55:17.686870 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.125169 (* 1 = 0.125169 loss)
I0925 22:55:17.686879 19975 sgd_solver.cpp:165] Iteration 42200, lr = 0.01
I0925 22:55:28.339936 19975 solver.cpp:357] Iteration 42300 (9.38659 iter/s, 10.6535s/100 iters), loss = 0.0868345
I0925 22:55:28.340092 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0868345 (* 1 = 0.0868345 loss)
I0925 22:55:28.340103 19975 sgd_solver.cpp:165] Iteration 42300, lr = 0.01
I0925 22:55:39.001888 19975 solver.cpp:357] Iteration 42400 (9.37891 iter/s, 10.6622s/100 iters), loss = 0.122633
I0925 22:55:39.001951 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.122633 (* 1 = 0.122633 loss)
I0925 22:55:39.001961 19975 sgd_solver.cpp:165] Iteration 42400, lr = 0.01
I0925 22:55:49.543926 19975 solver.cpp:514] Iteration 42500, Testing net (#0)
I0925 22:55:52.775223 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:55:52.787263 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.479576 (* 1 = 0.479576 loss)
I0925 22:55:52.787289 19975 solver.cpp:580]     Test net output #1: prob = 0.842201
I0925 22:55:52.892786 19975 solver.cpp:357] Iteration 42500 (7.1987 iter/s, 13.8914s/100 iters), loss = 0.0751799
I0925 22:55:52.892830 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0751798 (* 1 = 0.0751798 loss)
I0925 22:55:52.892840 19975 sgd_solver.cpp:165] Iteration 42500, lr = 0.01
I0925 22:56:00.779526 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:56:03.545214 19975 solver.cpp:357] Iteration 42600 (9.38721 iter/s, 10.6528s/100 iters), loss = 0.123289
I0925 22:56:03.545279 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.123289 (* 1 = 0.123289 loss)
I0925 22:56:03.545290 19975 sgd_solver.cpp:165] Iteration 42600, lr = 0.01
I0925 22:56:14.217993 19975 solver.cpp:357] Iteration 42700 (9.36933 iter/s, 10.6731s/100 iters), loss = 0.133383
I0925 22:56:14.218057 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.133383 (* 1 = 0.133383 loss)
I0925 22:56:14.218068 19975 sgd_solver.cpp:165] Iteration 42700, lr = 0.01
I0925 22:56:24.876955 19975 solver.cpp:357] Iteration 42800 (9.38148 iter/s, 10.6593s/100 iters), loss = 0.114776
I0925 22:56:24.877022 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.114776 (* 1 = 0.114776 loss)
I0925 22:56:24.877029 19975 sgd_solver.cpp:165] Iteration 42800, lr = 0.01
I0925 22:56:35.554833 19975 solver.cpp:357] Iteration 42900 (9.36486 iter/s, 10.6782s/100 iters), loss = 0.0654811
I0925 22:56:35.555033 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0654811 (* 1 = 0.0654811 loss)
I0925 22:56:35.555043 19975 sgd_solver.cpp:165] Iteration 42900, lr = 0.01
I0925 22:56:42.382647 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:56:46.109692 19975 solver.cpp:514] Iteration 43000, Testing net (#0)
I0925 22:56:49.336817 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:56:49.349459 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.558492 (* 1 = 0.558492 loss)
I0925 22:56:49.349488 19975 solver.cpp:580]     Test net output #1: prob = 0.834501
I0925 22:56:49.455741 19975 solver.cpp:357] Iteration 43000 (7.1936 iter/s, 13.9012s/100 iters), loss = 0.130506
I0925 22:56:49.455785 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.130506 (* 1 = 0.130506 loss)
I0925 22:56:49.455801 19975 sgd_solver.cpp:165] Iteration 43000, lr = 0.01
I0925 22:57:00.125581 19975 solver.cpp:357] Iteration 43100 (9.37191 iter/s, 10.6702s/100 iters), loss = 0.0657876
I0925 22:57:00.125645 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0657876 (* 1 = 0.0657876 loss)
I0925 22:57:00.125656 19975 sgd_solver.cpp:165] Iteration 43100, lr = 0.01
I0925 22:57:10.802012 19975 solver.cpp:357] Iteration 43200 (9.36614 iter/s, 10.6768s/100 iters), loss = 0.126489
I0925 22:57:10.802136 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.126489 (* 1 = 0.126489 loss)
I0925 22:57:10.802150 19975 sgd_solver.cpp:165] Iteration 43200, lr = 0.01
I0925 22:57:21.464763 19975 solver.cpp:357] Iteration 43300 (9.37821 iter/s, 10.663s/100 iters), loss = 0.102393
I0925 22:57:21.464828 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.102393 (* 1 = 0.102393 loss)
I0925 22:57:21.464839 19975 sgd_solver.cpp:165] Iteration 43300, lr = 0.01
I0925 22:57:27.334892 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:57:32.128741 19975 solver.cpp:357] Iteration 43400 (9.37709 iter/s, 10.6643s/100 iters), loss = 0.231607
I0925 22:57:32.128805 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.231607 (* 1 = 0.231607 loss)
I0925 22:57:32.128815 19975 sgd_solver.cpp:165] Iteration 43400, lr = 0.01
I0925 22:57:42.671906 19975 solver.cpp:514] Iteration 43500, Testing net (#0)
I0925 22:57:45.897400 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:57:45.909433 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.673168 (* 1 = 0.673168 loss)
I0925 22:57:45.909461 19975 solver.cpp:580]     Test net output #1: prob = 0.800901
I0925 22:57:46.014685 19975 solver.cpp:357] Iteration 43500 (7.2013 iter/s, 13.8864s/100 iters), loss = 0.0653092
I0925 22:57:46.014729 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0653092 (* 1 = 0.0653092 loss)
I0925 22:57:46.014742 19975 sgd_solver.cpp:165] Iteration 43500, lr = 0.01
I0925 22:57:56.673473 19975 solver.cpp:357] Iteration 43600 (9.38164 iter/s, 10.6591s/100 iters), loss = 0.184387
I0925 22:57:56.673537 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.184387 (* 1 = 0.184387 loss)
I0925 22:57:56.673547 19975 sgd_solver.cpp:165] Iteration 43600, lr = 0.01
I0925 22:58:07.339959 19975 solver.cpp:357] Iteration 43700 (9.37489 iter/s, 10.6668s/100 iters), loss = 0.121688
I0925 22:58:07.340024 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.121688 (* 1 = 0.121688 loss)
I0925 22:58:07.340034 19975 sgd_solver.cpp:165] Iteration 43700, lr = 0.01
I0925 22:58:12.149907 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:58:18.002820 19975 solver.cpp:357] Iteration 43800 (9.37809 iter/s, 10.6631s/100 iters), loss = 0.0571758
I0925 22:58:18.002956 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0571757 (* 1 = 0.0571757 loss)
I0925 22:58:18.002965 19975 sgd_solver.cpp:165] Iteration 43800, lr = 0.01
I0925 22:58:28.670439 19975 solver.cpp:357] Iteration 43900 (9.37396 iter/s, 10.6678s/100 iters), loss = 0.110554
I0925 22:58:28.670503 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.110554 (* 1 = 0.110554 loss)
I0925 22:58:28.670514 19975 sgd_solver.cpp:165] Iteration 43900, lr = 0.01
I0925 22:58:39.230054 19975 solver.cpp:514] Iteration 44000, Testing net (#0)
I0925 22:58:42.403105 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:58:42.415158 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.414075 (* 1 = 0.414075 loss)
I0925 22:58:42.415184 19975 solver.cpp:580]     Test net output #1: prob = 0.871702
I0925 22:58:42.520392 19975 solver.cpp:357] Iteration 44000 (7.22003 iter/s, 13.8504s/100 iters), loss = 0.0705732
I0925 22:58:42.520437 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0705732 (* 1 = 0.0705732 loss)
I0925 22:58:42.520447 19975 sgd_solver.cpp:165] Iteration 44000, lr = 0.01
I0925 22:58:53.187707 19975 solver.cpp:357] Iteration 44100 (9.37416 iter/s, 10.6676s/100 iters), loss = 0.151839
I0925 22:58:53.187868 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.151839 (* 1 = 0.151839 loss)
I0925 22:58:53.187878 19975 sgd_solver.cpp:165] Iteration 44100, lr = 0.01
I0925 22:58:57.032196 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:59:03.853972 19975 solver.cpp:357] Iteration 44200 (9.37519 iter/s, 10.6665s/100 iters), loss = 0.105258
I0925 22:59:03.854037 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.105258 (* 1 = 0.105258 loss)
I0925 22:59:03.854048 19975 sgd_solver.cpp:165] Iteration 44200, lr = 0.01
I0925 22:59:14.525233 19975 solver.cpp:357] Iteration 44300 (9.37072 iter/s, 10.6715s/100 iters), loss = 0.103799
I0925 22:59:14.525296 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.103799 (* 1 = 0.103799 loss)
I0925 22:59:14.525307 19975 sgd_solver.cpp:165] Iteration 44300, lr = 0.01
I0925 22:59:25.193786 19975 solver.cpp:357] Iteration 44400 (9.3731 iter/s, 10.6688s/100 iters), loss = 0.0726552
I0925 22:59:25.193943 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0726552 (* 1 = 0.0726552 loss)
I0925 22:59:25.193954 19975 sgd_solver.cpp:165] Iteration 44400, lr = 0.01
I0925 22:59:35.744644 19975 solver.cpp:514] Iteration 44500, Testing net (#0)
I0925 22:59:38.969071 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:59:38.980803 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.460389 (* 1 = 0.460389 loss)
I0925 22:59:38.980830 19975 solver.cpp:580]     Test net output #1: prob = 0.860502
I0925 22:59:39.085907 19975 solver.cpp:357] Iteration 44500 (7.19817 iter/s, 13.8924s/100 iters), loss = 0.0664314
I0925 22:59:39.085952 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0664313 (* 1 = 0.0664313 loss)
I0925 22:59:39.085965 19975 sgd_solver.cpp:165] Iteration 44500, lr = 0.01
I0925 22:59:41.974081 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 22:59:49.754254 19975 solver.cpp:357] Iteration 44600 (9.37327 iter/s, 10.6686s/100 iters), loss = 0.168841
I0925 22:59:49.754321 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.168841 (* 1 = 0.168841 loss)
I0925 22:59:49.754330 19975 sgd_solver.cpp:165] Iteration 44600, lr = 0.01
I0925 23:00:00.414064 19975 solver.cpp:357] Iteration 44700 (9.3808 iter/s, 10.6601s/100 iters), loss = 0.135307
I0925 23:00:00.414214 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.135307 (* 1 = 0.135307 loss)
I0925 23:00:00.414223 19975 sgd_solver.cpp:165] Iteration 44700, lr = 0.01
I0925 23:00:11.067291 19975 solver.cpp:357] Iteration 44800 (9.38667 iter/s, 10.6534s/100 iters), loss = 0.104855
I0925 23:00:11.067356 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.104855 (* 1 = 0.104855 loss)
I0925 23:00:11.067368 19975 sgd_solver.cpp:165] Iteration 44800, lr = 0.01
I0925 23:00:21.717154 19975 solver.cpp:357] Iteration 44900 (9.38956 iter/s, 10.6501s/100 iters), loss = 0.152117
I0925 23:00:21.717221 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.152117 (* 1 = 0.152117 loss)
I0925 23:00:21.717231 19975 sgd_solver.cpp:165] Iteration 44900, lr = 0.01
I0925 23:00:23.536634 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:00:32.258193 19975 solver.cpp:514] Iteration 45000, Testing net (#0)
I0925 23:00:35.448951 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:00:35.461498 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.51397 (* 1 = 0.51397 loss)
I0925 23:00:35.461525 19975 solver.cpp:580]     Test net output #1: prob = 0.846402
I0925 23:00:35.567237 19975 solver.cpp:357] Iteration 45000 (7.21998 iter/s, 13.8504s/100 iters), loss = 0.13683
I0925 23:00:35.567282 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.13683 (* 1 = 0.13683 loss)
I0925 23:00:35.567292 19975 sgd_solver.cpp:165] Iteration 45000, lr = 0.01
I0925 23:00:46.234000 19975 solver.cpp:357] Iteration 45100 (9.37467 iter/s, 10.667s/100 iters), loss = 0.136651
I0925 23:00:46.234063 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.136651 (* 1 = 0.136651 loss)
I0925 23:00:46.234074 19975 sgd_solver.cpp:165] Iteration 45100, lr = 0.01
I0925 23:00:56.893172 19975 solver.cpp:357] Iteration 45200 (9.38137 iter/s, 10.6594s/100 iters), loss = 0.0993869
I0925 23:00:56.893237 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0993868 (* 1 = 0.0993868 loss)
I0925 23:00:56.893249 19975 sgd_solver.cpp:165] Iteration 45200, lr = 0.01
I0925 23:01:07.531687 19975 solver.cpp:357] Iteration 45300 (9.39959 iter/s, 10.6388s/100 iters), loss = 0.130312
I0925 23:01:07.531837 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.130312 (* 1 = 0.130312 loss)
I0925 23:01:07.531848 19975 sgd_solver.cpp:165] Iteration 45300, lr = 0.01
I0925 23:01:08.392321 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:01:18.188995 19975 solver.cpp:357] Iteration 45400 (9.38309 iter/s, 10.6575s/100 iters), loss = 0.131281
I0925 23:01:18.189059 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.131281 (* 1 = 0.131281 loss)
I0925 23:01:18.189069 19975 sgd_solver.cpp:165] Iteration 45400, lr = 0.01
I0925 23:01:28.740535 19975 solver.cpp:514] Iteration 45500, Testing net (#0)
I0925 23:01:32.026234 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:01:32.038103 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.45578 (* 1 = 0.45578 loss)
I0925 23:01:32.038130 19975 solver.cpp:580]     Test net output #1: prob = 0.861501
I0925 23:01:32.143326 19975 solver.cpp:357] Iteration 45500 (7.16605 iter/s, 13.9547s/100 iters), loss = 0.0900302
I0925 23:01:32.143371 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0900301 (* 1 = 0.0900301 loss)
I0925 23:01:32.143383 19975 sgd_solver.cpp:165] Iteration 45500, lr = 0.01
I0925 23:01:42.807986 19975 solver.cpp:357] Iteration 45600 (9.37653 iter/s, 10.6649s/100 iters), loss = 0.101443
I0925 23:01:42.808136 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.101443 (* 1 = 0.101443 loss)
I0925 23:01:42.808147 19975 sgd_solver.cpp:165] Iteration 45600, lr = 0.01
I0925 23:01:53.365010 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:01:53.469147 19975 solver.cpp:357] Iteration 45700 (9.3797 iter/s, 10.6613s/100 iters), loss = 0.153092
I0925 23:01:53.469198 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.153092 (* 1 = 0.153092 loss)
I0925 23:01:53.469208 19975 sgd_solver.cpp:165] Iteration 45700, lr = 0.01
I0925 23:02:04.123097 19975 solver.cpp:357] Iteration 45800 (9.38597 iter/s, 10.6542s/100 iters), loss = 0.156897
I0925 23:02:04.123162 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.156897 (* 1 = 0.156897 loss)
I0925 23:02:04.123172 19975 sgd_solver.cpp:165] Iteration 45800, lr = 0.01
I0925 23:02:14.779250 19975 solver.cpp:357] Iteration 45900 (9.38404 iter/s, 10.6564s/100 iters), loss = 0.0928346
I0925 23:02:14.779350 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0928345 (* 1 = 0.0928345 loss)
I0925 23:02:14.779361 19975 sgd_solver.cpp:165] Iteration 45900, lr = 0.01
I0925 23:02:25.334179 19975 solver.cpp:514] Iteration 46000, Testing net (#0)
I0925 23:02:28.538336 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:02:28.550673 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.398827 (* 1 = 0.398827 loss)
I0925 23:02:28.550700 19975 solver.cpp:580]     Test net output #1: prob = 0.876402
I0925 23:02:28.655689 19975 solver.cpp:357] Iteration 46000 (7.2063 iter/s, 13.8767s/100 iters), loss = 0.116557
I0925 23:02:28.655731 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.116557 (* 1 = 0.116557 loss)
I0925 23:02:28.655741 19975 sgd_solver.cpp:165] Iteration 46000, lr = 0.01
I0925 23:02:38.136351 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:02:39.303444 19975 solver.cpp:357] Iteration 46100 (9.39143 iter/s, 10.648s/100 iters), loss = 0.0794291
I0925 23:02:39.303508 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.079429 (* 1 = 0.079429 loss)
I0925 23:02:39.303517 19975 sgd_solver.cpp:165] Iteration 46100, lr = 0.01
I0925 23:02:49.961966 19975 solver.cpp:357] Iteration 46200 (9.38196 iter/s, 10.6588s/100 iters), loss = 0.132052
I0925 23:02:49.962170 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.132052 (* 1 = 0.132052 loss)
I0925 23:02:49.962180 19975 sgd_solver.cpp:165] Iteration 46200, lr = 0.01
I0925 23:03:00.628317 19975 solver.cpp:357] Iteration 46300 (9.3752 iter/s, 10.6664s/100 iters), loss = 0.11124
I0925 23:03:00.628382 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.11124 (* 1 = 0.11124 loss)
I0925 23:03:00.628393 19975 sgd_solver.cpp:165] Iteration 46300, lr = 0.01
I0925 23:03:11.289165 19975 solver.cpp:357] Iteration 46400 (9.37992 iter/s, 10.6611s/100 iters), loss = 0.128635
I0925 23:03:11.289229 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.128635 (* 1 = 0.128635 loss)
I0925 23:03:11.289239 19975 sgd_solver.cpp:165] Iteration 46400, lr = 0.01
I0925 23:03:19.828145 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:03:21.852452 19975 solver.cpp:514] Iteration 46500, Testing net (#0)
I0925 23:03:25.057669 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:03:25.069689 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.499518 (* 1 = 0.499518 loss)
I0925 23:03:25.069715 19975 solver.cpp:580]     Test net output #1: prob = 0.852201
I0925 23:03:25.173939 19975 solver.cpp:357] Iteration 46500 (7.20197 iter/s, 13.8851s/100 iters), loss = 0.0900295
I0925 23:03:25.173982 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0900294 (* 1 = 0.0900294 loss)
I0925 23:03:25.173992 19975 sgd_solver.cpp:165] Iteration 46500, lr = 0.01
I0925 23:03:35.830776 19975 solver.cpp:357] Iteration 46600 (9.38343 iter/s, 10.6571s/100 iters), loss = 0.134842
I0925 23:03:35.830847 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.134842 (* 1 = 0.134842 loss)
I0925 23:03:35.830857 19975 sgd_solver.cpp:165] Iteration 46600, lr = 0.01
I0925 23:03:46.462954 19975 solver.cpp:357] Iteration 46700 (9.40522 iter/s, 10.6324s/100 iters), loss = 0.158131
I0925 23:03:46.463018 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.158131 (* 1 = 0.158131 loss)
I0925 23:03:46.463027 19975 sgd_solver.cpp:165] Iteration 46700, lr = 0.01
I0925 23:03:57.114989 19975 solver.cpp:357] Iteration 46800 (9.38768 iter/s, 10.6523s/100 iters), loss = 0.0886458
I0925 23:03:57.115118 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0886457 (* 1 = 0.0886457 loss)
I0925 23:03:57.115128 19975 sgd_solver.cpp:165] Iteration 46800, lr = 0.01
I0925 23:04:04.584940 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:04:07.772200 19975 solver.cpp:357] Iteration 46900 (9.38318 iter/s, 10.6574s/100 iters), loss = 0.197281
I0925 23:04:07.772266 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.197281 (* 1 = 0.197281 loss)
I0925 23:04:07.772276 19975 sgd_solver.cpp:165] Iteration 46900, lr = 0.01
I0925 23:04:18.328008 19975 solver.cpp:514] Iteration 47000, Testing net (#0)
I0925 23:04:21.562616 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:04:21.574579 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.541313 (* 1 = 0.541313 loss)
I0925 23:04:21.574605 19975 solver.cpp:580]     Test net output #1: prob = 0.846101
I0925 23:04:21.680152 19975 solver.cpp:357] Iteration 47000 (7.18997 iter/s, 13.9083s/100 iters), loss = 0.0723108
I0925 23:04:21.680196 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0723107 (* 1 = 0.0723107 loss)
I0925 23:04:21.680208 19975 sgd_solver.cpp:165] Iteration 47000, lr = 0.01
I0925 23:04:32.341195 19975 solver.cpp:357] Iteration 47100 (9.37974 iter/s, 10.6613s/100 iters), loss = 0.124848
I0925 23:04:32.341416 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.124848 (* 1 = 0.124848 loss)
I0925 23:04:32.341428 19975 sgd_solver.cpp:165] Iteration 47100, lr = 0.01
I0925 23:04:43.002591 19975 solver.cpp:357] Iteration 47200 (9.37958 iter/s, 10.6615s/100 iters), loss = 0.120194
I0925 23:04:43.002656 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.120194 (* 1 = 0.120194 loss)
I0925 23:04:43.002666 19975 sgd_solver.cpp:165] Iteration 47200, lr = 0.01
I0925 23:04:49.527243 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:04:53.669816 19975 solver.cpp:357] Iteration 47300 (9.37433 iter/s, 10.6674s/100 iters), loss = 0.140686
I0925 23:04:53.669880 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.140685 (* 1 = 0.140685 loss)
I0925 23:04:53.669891 19975 sgd_solver.cpp:165] Iteration 47300, lr = 0.01
I0925 23:05:04.348309 19975 solver.cpp:357] Iteration 47400 (9.36444 iter/s, 10.6787s/100 iters), loss = 0.0838936
I0925 23:05:04.348460 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0838935 (* 1 = 0.0838935 loss)
I0925 23:05:04.348470 19975 sgd_solver.cpp:165] Iteration 47400, lr = 0.01
I0925 23:05:14.922832 19975 solver.cpp:514] Iteration 47500, Testing net (#0)
I0925 23:05:18.116820 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:05:18.129328 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.481394 (* 1 = 0.481394 loss)
I0925 23:05:18.129356 19975 solver.cpp:580]     Test net output #1: prob = 0.850201
I0925 23:05:18.234217 19975 solver.cpp:357] Iteration 47500 (7.20144 iter/s, 13.8861s/100 iters), loss = 0.0718693
I0925 23:05:18.234261 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0718692 (* 1 = 0.0718692 loss)
I0925 23:05:18.234272 19975 sgd_solver.cpp:165] Iteration 47500, lr = 0.01
I0925 23:05:28.899392 19975 solver.cpp:357] Iteration 47600 (9.37612 iter/s, 10.6654s/100 iters), loss = 0.118318
I0925 23:05:28.899459 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.118318 (* 1 = 0.118318 loss)
I0925 23:05:28.899468 19975 sgd_solver.cpp:165] Iteration 47600, lr = 0.01
I0925 23:05:34.446938 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:05:39.553593 19975 solver.cpp:357] Iteration 47700 (9.38579 iter/s, 10.6544s/100 iters), loss = 0.159581
I0925 23:05:39.553658 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.15958 (* 1 = 0.15958 loss)
I0925 23:05:39.553665 19975 sgd_solver.cpp:165] Iteration 47700, lr = 0.01
I0925 23:05:50.222368 19975 solver.cpp:357] Iteration 47800 (9.37297 iter/s, 10.669s/100 iters), loss = 0.16786
I0925 23:05:50.222431 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.16786 (* 1 = 0.16786 loss)
I0925 23:05:50.222443 19975 sgd_solver.cpp:165] Iteration 47800, lr = 0.01
I0925 23:06:00.890290 19975 solver.cpp:357] Iteration 47900 (9.37372 iter/s, 10.6681s/100 iters), loss = 0.117709
I0925 23:06:00.890357 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.117708 (* 1 = 0.117708 loss)
I0925 23:06:00.890365 19975 sgd_solver.cpp:165] Iteration 47900, lr = 0.01
I0925 23:06:11.457743 19975 solver.cpp:514] Iteration 48000, Testing net (#0)
I0925 23:06:14.646853 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:06:14.658532 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.364433 (* 1 = 0.364433 loss)
I0925 23:06:14.658560 19975 solver.cpp:580]     Test net output #1: prob = 0.885301
I0925 23:06:14.763767 19975 solver.cpp:357] Iteration 48000 (7.20785 iter/s, 13.8738s/100 iters), loss = 0.064848
I0925 23:06:14.763809 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0648478 (* 1 = 0.0648478 loss)
I0925 23:06:14.763818 19975 sgd_solver.cpp:64] MultiStep Status: Iteration 48000, step = 2
I0925 23:06:14.763824 19975 sgd_solver.cpp:165] Iteration 48000, lr = 0.001
I0925 23:06:19.255096 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:06:25.409809 19975 solver.cpp:357] Iteration 48100 (9.39297 iter/s, 10.6463s/100 iters), loss = 0.0877602
I0925 23:06:25.409873 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.08776 (* 1 = 0.08776 loss)
I0925 23:06:25.409884 19975 sgd_solver.cpp:165] Iteration 48100, lr = 0.001
I0925 23:06:36.058181 19975 solver.cpp:357] Iteration 48200 (9.39094 iter/s, 10.6486s/100 iters), loss = 0.0470417
I0925 23:06:36.058243 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0470416 (* 1 = 0.0470416 loss)
I0925 23:06:36.058254 19975 sgd_solver.cpp:165] Iteration 48200, lr = 0.001
I0925 23:06:46.706248 19975 solver.cpp:357] Iteration 48300 (9.39121 iter/s, 10.6483s/100 iters), loss = 0.101487
I0925 23:06:46.706432 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.101487 (* 1 = 0.101487 loss)
I0925 23:06:46.706444 19975 sgd_solver.cpp:165] Iteration 48300, lr = 0.001
I0925 23:06:57.353754 19975 solver.cpp:357] Iteration 48400 (9.39181 iter/s, 10.6476s/100 iters), loss = 0.0716607
I0925 23:06:57.353818 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0716606 (* 1 = 0.0716606 loss)
I0925 23:06:57.353827 19975 sgd_solver.cpp:165] Iteration 48400, lr = 0.001
I0925 23:07:00.878295 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:07:07.904428 19975 solver.cpp:514] Iteration 48500, Testing net (#0)
I0925 23:07:11.103730 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:07:11.115577 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.277381 (* 1 = 0.277381 loss)
I0925 23:07:11.115604 19975 solver.cpp:580]     Test net output #1: prob = 0.914203
I0925 23:07:11.220348 19975 solver.cpp:357] Iteration 48500 (7.21143 iter/s, 13.8669s/100 iters), loss = 0.0828148
I0925 23:07:11.220391 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0828146 (* 1 = 0.0828146 loss)
I0925 23:07:11.220402 19975 sgd_solver.cpp:165] Iteration 48500, lr = 0.001
I0925 23:07:21.849164 19975 solver.cpp:357] Iteration 48600 (9.4082 iter/s, 10.629s/100 iters), loss = 0.101859
I0925 23:07:21.849319 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.101859 (* 1 = 0.101859 loss)
I0925 23:07:21.849330 19975 sgd_solver.cpp:165] Iteration 48600, lr = 0.001
I0925 23:07:32.507555 19975 solver.cpp:357] Iteration 48700 (9.38219 iter/s, 10.6585s/100 iters), loss = 0.052832
I0925 23:07:32.507620 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0528318 (* 1 = 0.0528318 loss)
I0925 23:07:32.507632 19975 sgd_solver.cpp:165] Iteration 48700, lr = 0.001
I0925 23:07:43.164155 19975 solver.cpp:357] Iteration 48800 (9.38369 iter/s, 10.6568s/100 iters), loss = 0.0684621
I0925 23:07:43.164223 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.068462 (* 1 = 0.068462 loss)
I0925 23:07:43.164232 19975 sgd_solver.cpp:165] Iteration 48800, lr = 0.001
I0925 23:07:45.726882 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:07:53.842108 19975 solver.cpp:357] Iteration 48900 (9.36493 iter/s, 10.6781s/100 iters), loss = 0.0939054
I0925 23:07:53.842257 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0939052 (* 1 = 0.0939052 loss)
I0925 23:07:53.842267 19975 sgd_solver.cpp:165] Iteration 48900, lr = 0.001
I0925 23:08:04.392333 19975 solver.cpp:514] Iteration 49000, Testing net (#0)
I0925 23:08:07.564954 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:08:07.577497 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.274684 (* 1 = 0.274684 loss)
I0925 23:08:07.577524 19975 solver.cpp:580]     Test net output #1: prob = 0.917602
I0925 23:08:07.682111 19975 solver.cpp:357] Iteration 49000 (7.22534 iter/s, 13.8402s/100 iters), loss = 0.0541182
I0925 23:08:07.682152 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0541181 (* 1 = 0.0541181 loss)
I0925 23:08:07.682163 19975 sgd_solver.cpp:165] Iteration 49000, lr = 0.001
I0925 23:08:18.335147 19975 solver.cpp:357] Iteration 49100 (9.38682 iter/s, 10.6532s/100 iters), loss = 0.0935972
I0925 23:08:18.335214 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.093597 (* 1 = 0.093597 loss)
I0925 23:08:18.335224 19975 sgd_solver.cpp:165] Iteration 49100, lr = 0.001
I0925 23:08:28.995065 19975 solver.cpp:357] Iteration 49200 (9.38078 iter/s, 10.6601s/100 iters), loss = 0.034042
I0925 23:08:28.995247 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0340418 (* 1 = 0.0340418 loss)
I0925 23:08:28.995257 19975 sgd_solver.cpp:165] Iteration 49200, lr = 0.001
I0925 23:08:30.495420 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:08:39.650532 19975 solver.cpp:357] Iteration 49300 (9.3848 iter/s, 10.6555s/100 iters), loss = 0.0798064
I0925 23:08:39.650596 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0798063 (* 1 = 0.0798063 loss)
I0925 23:08:39.650606 19975 sgd_solver.cpp:165] Iteration 49300, lr = 0.001
I0925 23:08:50.303315 19975 solver.cpp:357] Iteration 49400 (9.38706 iter/s, 10.653s/100 iters), loss = 0.0837544
I0925 23:08:50.303380 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0837543 (* 1 = 0.0837543 loss)
I0925 23:08:50.303391 19975 sgd_solver.cpp:165] Iteration 49400, lr = 0.001
I0925 23:09:00.852396 19975 solver.cpp:514] Iteration 49500, Testing net (#0)
I0925 23:09:04.120388 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:09:04.132845 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.269872 (* 1 = 0.269872 loss)
I0925 23:09:04.132872 19975 solver.cpp:580]     Test net output #1: prob = 0.919603
I0925 23:09:04.238344 19975 solver.cpp:357] Iteration 49500 (7.17603 iter/s, 13.9353s/100 iters), loss = 0.0720553
I0925 23:09:04.238387 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0720552 (* 1 = 0.0720552 loss)
I0925 23:09:04.238399 19975 sgd_solver.cpp:165] Iteration 49500, lr = 0.001
I0925 23:09:14.913177 19975 solver.cpp:357] Iteration 49600 (9.36765 iter/s, 10.675s/100 iters), loss = 0.0522034
I0925 23:09:14.913242 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0522033 (* 1 = 0.0522033 loss)
I0925 23:09:14.913252 19975 sgd_solver.cpp:165] Iteration 49600, lr = 0.001
I0925 23:09:15.454589 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:09:25.568799 19975 solver.cpp:357] Iteration 49700 (9.38456 iter/s, 10.6558s/100 iters), loss = 0.0785401
I0925 23:09:25.568862 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0785399 (* 1 = 0.0785399 loss)
I0925 23:09:25.568872 19975 sgd_solver.cpp:165] Iteration 49700, lr = 0.001
I0925 23:09:36.224480 19975 solver.cpp:357] Iteration 49800 (9.38451 iter/s, 10.6559s/100 iters), loss = 0.0457332
I0925 23:09:36.224632 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.045733 (* 1 = 0.045733 loss)
I0925 23:09:36.224643 19975 sgd_solver.cpp:165] Iteration 49800, lr = 0.001
I0925 23:09:46.892767 19975 solver.cpp:357] Iteration 49900 (9.3735 iter/s, 10.6684s/100 iters), loss = 0.0770039
I0925 23:09:46.892832 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0770037 (* 1 = 0.0770037 loss)
I0925 23:09:46.892843 19975 sgd_solver.cpp:165] Iteration 49900, lr = 0.001
I0925 23:09:57.032683 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:09:57.444495 19975 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_50000.caffemodel
I0925 23:09:57.452564 19975 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_50000.solverstate
I0925 23:09:57.455453 19975 solver.cpp:514] Iteration 50000, Testing net (#0)
I0925 23:10:00.655375 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:10:00.667434 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.265875 (* 1 = 0.265875 loss)
I0925 23:10:00.667461 19975 solver.cpp:580]     Test net output #1: prob = 0.919702
I0925 23:10:00.772285 19975 solver.cpp:357] Iteration 50000 (7.20473 iter/s, 13.8798s/100 iters), loss = 0.070536
I0925 23:10:00.772328 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0705358 (* 1 = 0.0705358 loss)
I0925 23:10:00.772338 19975 sgd_solver.cpp:165] Iteration 50000, lr = 0.001
I0925 23:10:11.438752 19975 solver.cpp:357] Iteration 50100 (9.37501 iter/s, 10.6667s/100 iters), loss = 0.0596615
I0925 23:10:11.438956 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0596614 (* 1 = 0.0596614 loss)
I0925 23:10:11.438967 19975 sgd_solver.cpp:165] Iteration 50100, lr = 0.001
I0925 23:10:22.111907 19975 solver.cpp:357] Iteration 50200 (9.36927 iter/s, 10.6732s/100 iters), loss = 0.0573137
I0925 23:10:22.111970 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0573136 (* 1 = 0.0573136 loss)
I0925 23:10:22.111981 19975 sgd_solver.cpp:165] Iteration 50200, lr = 0.001
I0925 23:10:32.778473 19975 solver.cpp:357] Iteration 50300 (9.37494 iter/s, 10.6667s/100 iters), loss = 0.0890051
I0925 23:10:32.778538 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.089005 (* 1 = 0.089005 loss)
I0925 23:10:32.778549 19975 sgd_solver.cpp:165] Iteration 50300, lr = 0.001
I0925 23:10:41.957056 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:10:43.440357 19975 solver.cpp:357] Iteration 50400 (9.37906 iter/s, 10.6621s/100 iters), loss = 0.0853569
I0925 23:10:43.440421 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0853568 (* 1 = 0.0853568 loss)
I0925 23:10:43.440430 19975 sgd_solver.cpp:165] Iteration 50400, lr = 0.001
I0925 23:10:53.991493 19975 solver.cpp:514] Iteration 50500, Testing net (#0)
I0925 23:10:57.208945 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:10:57.220934 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.264241 (* 1 = 0.264241 loss)
I0925 23:10:57.220962 19975 solver.cpp:580]     Test net output #1: prob = 0.919503
I0925 23:10:57.325911 19975 solver.cpp:357] Iteration 50500 (7.2016 iter/s, 13.8858s/100 iters), loss = 0.0594071
I0925 23:10:57.325955 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.059407 (* 1 = 0.059407 loss)
I0925 23:10:57.325965 19975 sgd_solver.cpp:165] Iteration 50500, lr = 0.001
I0925 23:11:07.982410 19975 solver.cpp:357] Iteration 50600 (9.38378 iter/s, 10.6567s/100 iters), loss = 0.0374057
I0925 23:11:07.982475 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0374056 (* 1 = 0.0374056 loss)
I0925 23:11:07.982484 19975 sgd_solver.cpp:165] Iteration 50600, lr = 0.001
I0925 23:11:18.647133 19975 solver.cpp:357] Iteration 50700 (9.37656 iter/s, 10.6649s/100 iters), loss = 0.0205685
I0925 23:11:18.647308 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0205683 (* 1 = 0.0205683 loss)
I0925 23:11:18.647318 19975 sgd_solver.cpp:165] Iteration 50700, lr = 0.001
I0925 23:11:26.855000 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:11:29.297703 19975 solver.cpp:357] Iteration 50800 (9.38912 iter/s, 10.6506s/100 iters), loss = 0.102018
I0925 23:11:29.297767 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.102018 (* 1 = 0.102018 loss)
I0925 23:11:29.297776 19975 sgd_solver.cpp:165] Iteration 50800, lr = 0.001
I0925 23:11:39.953619 19975 solver.cpp:357] Iteration 50900 (9.38431 iter/s, 10.6561s/100 iters), loss = 0.0224718
I0925 23:11:39.953683 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0224717 (* 1 = 0.0224717 loss)
I0925 23:11:39.953691 19975 sgd_solver.cpp:165] Iteration 50900, lr = 0.001
I0925 23:11:50.507196 19975 solver.cpp:514] Iteration 51000, Testing net (#0)
I0925 23:11:53.696053 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:11:53.708132 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.272845 (* 1 = 0.272845 loss)
I0925 23:11:53.708159 19975 solver.cpp:580]     Test net output #1: prob = 0.918502
I0925 23:11:53.813488 19975 solver.cpp:357] Iteration 51000 (7.21495 iter/s, 13.8601s/100 iters), loss = 0.0419524
I0925 23:11:53.813531 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0419523 (* 1 = 0.0419523 loss)
I0925 23:11:53.813542 19975 sgd_solver.cpp:165] Iteration 51000, lr = 0.001
I0925 23:12:04.476287 19975 solver.cpp:357] Iteration 51100 (9.37824 iter/s, 10.663s/100 iters), loss = 0.054594
I0925 23:12:04.476351 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0545938 (* 1 = 0.0545938 loss)
I0925 23:12:04.476361 19975 sgd_solver.cpp:165] Iteration 51100, lr = 0.001
I0925 23:12:11.628803 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:12:15.135218 19975 solver.cpp:357] Iteration 51200 (9.38166 iter/s, 10.6591s/100 iters), loss = 0.120335
I0925 23:12:15.135279 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.120335 (* 1 = 0.120335 loss)
I0925 23:12:15.135288 19975 sgd_solver.cpp:165] Iteration 51200, lr = 0.001
I0925 23:12:25.797158 19975 solver.cpp:357] Iteration 51300 (9.37901 iter/s, 10.6621s/100 iters), loss = 0.0481857
I0925 23:12:25.797364 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0481856 (* 1 = 0.0481856 loss)
I0925 23:12:25.797374 19975 sgd_solver.cpp:165] Iteration 51300, lr = 0.001
I0925 23:12:36.457233 19975 solver.cpp:357] Iteration 51400 (9.38078 iter/s, 10.6601s/100 iters), loss = 0.0372152
I0925 23:12:36.457298 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0372151 (* 1 = 0.0372151 loss)
I0925 23:12:36.457307 19975 sgd_solver.cpp:165] Iteration 51400, lr = 0.001
I0925 23:12:47.008956 19975 solver.cpp:514] Iteration 51500, Testing net (#0)
I0925 23:12:50.266350 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:12:50.278081 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.275948 (* 1 = 0.275948 loss)
I0925 23:12:50.278108 19975 solver.cpp:580]     Test net output #1: prob = 0.917802
I0925 23:12:50.383584 19975 solver.cpp:357] Iteration 51500 (7.18051 iter/s, 13.9266s/100 iters), loss = 0.0163978
I0925 23:12:50.383627 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0163977 (* 1 = 0.0163977 loss)
I0925 23:12:50.383639 19975 sgd_solver.cpp:165] Iteration 51500, lr = 0.001
I0925 23:12:56.568446 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:13:01.038301 19975 solver.cpp:357] Iteration 51600 (9.38535 iter/s, 10.6549s/100 iters), loss = 0.0278729
I0925 23:13:01.038367 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0278728 (* 1 = 0.0278728 loss)
I0925 23:13:01.038375 19975 sgd_solver.cpp:165] Iteration 51600, lr = 0.001
I0925 23:13:11.694730 19975 solver.cpp:357] Iteration 51700 (9.38387 iter/s, 10.6566s/100 iters), loss = 0.123851
I0925 23:13:11.694793 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.123851 (* 1 = 0.123851 loss)
I0925 23:13:11.694802 19975 sgd_solver.cpp:165] Iteration 51700, lr = 0.001
I0925 23:13:22.355442 19975 solver.cpp:357] Iteration 51800 (9.3801 iter/s, 10.6609s/100 iters), loss = 0.0333893
I0925 23:13:22.355506 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0333892 (* 1 = 0.0333892 loss)
I0925 23:13:22.355516 19975 sgd_solver.cpp:165] Iteration 51800, lr = 0.001
I0925 23:13:32.999996 19975 solver.cpp:357] Iteration 51900 (9.39433 iter/s, 10.6447s/100 iters), loss = 0.0369782
I0925 23:13:33.000145 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0369781 (* 1 = 0.0369781 loss)
I0925 23:13:33.000155 19975 sgd_solver.cpp:165] Iteration 51900, lr = 0.001
I0925 23:13:38.225080 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:13:43.545073 19975 solver.cpp:514] Iteration 52000, Testing net (#0)
I0925 23:13:46.749586 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:13:46.762023 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.269523 (* 1 = 0.269523 loss)
I0925 23:13:46.762050 19975 solver.cpp:580]     Test net output #1: prob = 0.919803
I0925 23:13:46.867560 19975 solver.cpp:357] Iteration 52000 (7.21099 iter/s, 13.8677s/100 iters), loss = 0.0610938
I0925 23:13:46.867605 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0610937 (* 1 = 0.0610937 loss)
I0925 23:13:46.867615 19975 sgd_solver.cpp:165] Iteration 52000, lr = 0.001
I0925 23:13:57.534968 19975 solver.cpp:357] Iteration 52100 (9.37419 iter/s, 10.6676s/100 iters), loss = 0.0378839
I0925 23:13:57.535035 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0378838 (* 1 = 0.0378838 loss)
I0925 23:13:57.535045 19975 sgd_solver.cpp:165] Iteration 52100, lr = 0.001
I0925 23:14:08.197460 19975 solver.cpp:357] Iteration 52200 (9.37853 iter/s, 10.6626s/100 iters), loss = 0.0564297
I0925 23:14:08.197613 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0564296 (* 1 = 0.0564296 loss)
I0925 23:14:08.197623 19975 sgd_solver.cpp:165] Iteration 52200, lr = 0.001
I0925 23:14:18.872817 19975 solver.cpp:357] Iteration 52300 (9.36731 iter/s, 10.6754s/100 iters), loss = 0.0425892
I0925 23:14:18.872882 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.042589 (* 1 = 0.042589 loss)
I0925 23:14:18.872894 19975 sgd_solver.cpp:165] Iteration 52300, lr = 0.001
I0925 23:14:23.046545 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:14:29.544878 19975 solver.cpp:357] Iteration 52400 (9.37013 iter/s, 10.6722s/100 iters), loss = 0.0699085
I0925 23:14:29.544941 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0699084 (* 1 = 0.0699084 loss)
I0925 23:14:29.544952 19975 sgd_solver.cpp:165] Iteration 52400, lr = 0.001
I0925 23:14:40.110517 19975 solver.cpp:514] Iteration 52500, Testing net (#0)
I0925 23:14:43.356962 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:14:43.368566 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.271318 (* 1 = 0.271318 loss)
I0925 23:14:43.368592 19975 solver.cpp:580]     Test net output #1: prob = 0.920402
I0925 23:14:43.473613 19975 solver.cpp:357] Iteration 52500 (7.17928 iter/s, 13.929s/100 iters), loss = 0.0545729
I0925 23:14:43.473656 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0545728 (* 1 = 0.0545728 loss)
I0925 23:14:43.473670 19975 sgd_solver.cpp:165] Iteration 52500, lr = 0.001
I0925 23:14:54.130671 19975 solver.cpp:357] Iteration 52600 (9.3833 iter/s, 10.6572s/100 iters), loss = 0.0378522
I0925 23:14:54.130739 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0378521 (* 1 = 0.0378521 loss)
I0925 23:14:54.130748 19975 sgd_solver.cpp:165] Iteration 52600, lr = 0.001
I0925 23:15:04.787693 19975 solver.cpp:357] Iteration 52700 (9.38336 iter/s, 10.6572s/100 iters), loss = 0.0679888
I0925 23:15:04.787758 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0679887 (* 1 = 0.0679887 loss)
I0925 23:15:04.787767 19975 sgd_solver.cpp:165] Iteration 52700, lr = 0.001
I0925 23:15:07.987417 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:15:15.445482 19975 solver.cpp:357] Iteration 52800 (9.38267 iter/s, 10.6579s/100 iters), loss = 0.0456057
I0925 23:15:15.445585 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0456056 (* 1 = 0.0456056 loss)
I0925 23:15:15.445596 19975 sgd_solver.cpp:165] Iteration 52800, lr = 0.001
I0925 23:15:26.093538 19975 solver.cpp:357] Iteration 52900 (9.39129 iter/s, 10.6482s/100 iters), loss = 0.0445456
I0925 23:15:26.093602 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0445455 (* 1 = 0.0445455 loss)
I0925 23:15:26.093614 19975 sgd_solver.cpp:165] Iteration 52900, lr = 0.001
I0925 23:15:36.641141 19975 solver.cpp:514] Iteration 53000, Testing net (#0)
I0925 23:15:39.876957 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:15:39.889062 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.274169 (* 1 = 0.274169 loss)
I0925 23:15:39.889089 19975 solver.cpp:580]     Test net output #1: prob = 0.921102
I0925 23:15:39.995301 19975 solver.cpp:357] Iteration 53000 (7.19321 iter/s, 13.902s/100 iters), loss = 0.0378398
I0925 23:15:39.995348 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0378396 (* 1 = 0.0378396 loss)
I0925 23:15:39.995359 19975 sgd_solver.cpp:165] Iteration 53000, lr = 0.001
I0925 23:15:50.655941 19975 solver.cpp:357] Iteration 53100 (9.38015 iter/s, 10.6608s/100 iters), loss = 0.0367294
I0925 23:15:50.656152 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0367292 (* 1 = 0.0367292 loss)
I0925 23:15:50.656163 19975 sgd_solver.cpp:165] Iteration 53100, lr = 0.001
I0925 23:15:52.807597 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:16:01.317176 19975 solver.cpp:357] Iteration 53200 (9.37977 iter/s, 10.6612s/100 iters), loss = 0.0309792
I0925 23:16:01.317236 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.030979 (* 1 = 0.030979 loss)
I0925 23:16:01.317245 19975 sgd_solver.cpp:165] Iteration 53200, lr = 0.001
I0925 23:16:11.955293 19975 solver.cpp:357] Iteration 53300 (9.40002 iter/s, 10.6383s/100 iters), loss = 0.0557838
I0925 23:16:11.955358 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0557836 (* 1 = 0.0557836 loss)
I0925 23:16:11.955369 19975 sgd_solver.cpp:165] Iteration 53300, lr = 0.001
I0925 23:16:22.614490 19975 solver.cpp:357] Iteration 53400 (9.38144 iter/s, 10.6593s/100 iters), loss = 0.0207802
I0925 23:16:22.614598 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.02078 (* 1 = 0.02078 loss)
I0925 23:16:22.614608 19975 sgd_solver.cpp:165] Iteration 53400, lr = 0.001
I0925 23:16:33.178284 19975 solver.cpp:514] Iteration 53500, Testing net (#0)
I0925 23:16:36.378980 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:16:36.391070 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.271257 (* 1 = 0.271257 loss)
I0925 23:16:36.391095 19975 solver.cpp:580]     Test net output #1: prob = 0.921202
I0925 23:16:36.496217 19975 solver.cpp:357] Iteration 53500 (7.20362 iter/s, 13.8819s/100 iters), loss = 0.0531413
I0925 23:16:36.496261 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0531412 (* 1 = 0.0531412 loss)
I0925 23:16:36.496271 19975 sgd_solver.cpp:165] Iteration 53500, lr = 0.001
I0925 23:16:37.674484 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:16:47.139436 19975 solver.cpp:357] Iteration 53600 (9.3955 iter/s, 10.6434s/100 iters), loss = 0.0529486
I0925 23:16:47.139503 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0529484 (* 1 = 0.0529484 loss)
I0925 23:16:47.139511 19975 sgd_solver.cpp:165] Iteration 53600, lr = 0.001
I0925 23:16:57.796620 19975 solver.cpp:357] Iteration 53700 (9.38321 iter/s, 10.6573s/100 iters), loss = 0.013949
I0925 23:16:57.796768 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0139488 (* 1 = 0.0139488 loss)
I0925 23:16:57.796777 19975 sgd_solver.cpp:165] Iteration 53700, lr = 0.001
I0925 23:17:08.436875 19975 solver.cpp:357] Iteration 53800 (9.39821 iter/s, 10.6403s/100 iters), loss = 0.017084
I0925 23:17:08.436940 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0170838 (* 1 = 0.0170838 loss)
I0925 23:17:08.436952 19975 sgd_solver.cpp:165] Iteration 53800, lr = 0.001
I0925 23:17:19.094897 19975 solver.cpp:357] Iteration 53900 (9.38247 iter/s, 10.6582s/100 iters), loss = 0.0834327
I0925 23:17:19.094964 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0834325 (* 1 = 0.0834325 loss)
I0925 23:17:19.094971 19975 sgd_solver.cpp:165] Iteration 53900, lr = 0.001
I0925 23:17:19.315261 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:17:29.656342 19975 solver.cpp:514] Iteration 54000, Testing net (#0)
I0925 23:17:32.866194 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:17:32.877697 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.276591 (* 1 = 0.276591 loss)
I0925 23:17:32.877724 19975 solver.cpp:580]     Test net output #1: prob = 0.920002
I0925 23:17:32.983237 19975 solver.cpp:357] Iteration 54000 (7.20017 iter/s, 13.8886s/100 iters), loss = 0.015158
I0925 23:17:32.983279 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0151579 (* 1 = 0.0151579 loss)
I0925 23:17:32.983294 19975 sgd_solver.cpp:165] Iteration 54000, lr = 0.001
I0925 23:17:43.641397 19975 solver.cpp:357] Iteration 54100 (9.38233 iter/s, 10.6583s/100 iters), loss = 0.0520566
I0925 23:17:43.641463 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0520565 (* 1 = 0.0520565 loss)
I0925 23:17:43.641472 19975 sgd_solver.cpp:165] Iteration 54100, lr = 0.001
I0925 23:17:54.305037 19975 solver.cpp:357] Iteration 54200 (9.37753 iter/s, 10.6638s/100 iters), loss = 0.0309108
I0925 23:17:54.305104 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0309106 (* 1 = 0.0309106 loss)
I0925 23:17:54.305114 19975 sgd_solver.cpp:165] Iteration 54200, lr = 0.001
I0925 23:18:04.133760 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:18:04.975339 19975 solver.cpp:357] Iteration 54300 (9.37168 iter/s, 10.6704s/100 iters), loss = 0.0422389
I0925 23:18:04.975402 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0422387 (* 1 = 0.0422387 loss)
I0925 23:18:04.975412 19975 sgd_solver.cpp:165] Iteration 54300, lr = 0.001
I0925 23:18:15.635058 19975 solver.cpp:357] Iteration 54400 (9.38098 iter/s, 10.6599s/100 iters), loss = 0.0682692
I0925 23:18:15.635124 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.068269 (* 1 = 0.068269 loss)
I0925 23:18:15.635134 19975 sgd_solver.cpp:165] Iteration 54400, lr = 0.001
I0925 23:18:26.208562 19975 solver.cpp:514] Iteration 54500, Testing net (#0)
I0925 23:18:29.426125 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:18:29.438686 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.278059 (* 1 = 0.278059 loss)
I0925 23:18:29.438714 19975 solver.cpp:580]     Test net output #1: prob = 0.920703
I0925 23:18:29.543496 19975 solver.cpp:357] Iteration 54500 (7.18977 iter/s, 13.9087s/100 iters), loss = 0.0501874
I0925 23:18:29.543541 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0501873 (* 1 = 0.0501873 loss)
I0925 23:18:29.543551 19975 sgd_solver.cpp:165] Iteration 54500, lr = 0.001
I0925 23:18:40.189666 19975 solver.cpp:357] Iteration 54600 (9.39291 iter/s, 10.6463s/100 iters), loss = 0.0182647
I0925 23:18:40.189822 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0182646 (* 1 = 0.0182646 loss)
I0925 23:18:40.189834 19975 sgd_solver.cpp:165] Iteration 54600, lr = 0.001
I0925 23:18:49.034312 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:18:50.837069 19975 solver.cpp:357] Iteration 54700 (9.39191 iter/s, 10.6475s/100 iters), loss = 0.0767872
I0925 23:18:50.837133 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.076787 (* 1 = 0.076787 loss)
I0925 23:18:50.837144 19975 sgd_solver.cpp:165] Iteration 54700, lr = 0.001
I0925 23:19:01.487560 19975 solver.cpp:357] Iteration 54800 (9.38911 iter/s, 10.6506s/100 iters), loss = 0.0160763
I0925 23:19:01.487623 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0160761 (* 1 = 0.0160761 loss)
I0925 23:19:01.487632 19975 sgd_solver.cpp:165] Iteration 54800, lr = 0.001
I0925 23:19:12.148372 19975 solver.cpp:357] Iteration 54900 (9.38002 iter/s, 10.661s/100 iters), loss = 0.0332841
I0925 23:19:12.148519 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0332839 (* 1 = 0.0332839 loss)
I0925 23:19:12.148530 19975 sgd_solver.cpp:165] Iteration 54900, lr = 0.001
I0925 23:19:22.706638 19975 solver.cpp:514] Iteration 55000, Testing net (#0)
I0925 23:19:25.900048 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:19:25.912137 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.278936 (* 1 = 0.278936 loss)
I0925 23:19:25.912163 19975 solver.cpp:580]     Test net output #1: prob = 0.919402
I0925 23:19:26.016750 19975 solver.cpp:357] Iteration 55000 (7.21058 iter/s, 13.8685s/100 iters), loss = 0.0291682
I0925 23:19:26.016794 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0291681 (* 1 = 0.0291681 loss)
I0925 23:19:26.016805 19975 sgd_solver.cpp:165] Iteration 55000, lr = 0.001
I0925 23:19:33.910271 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:19:36.683423 19975 solver.cpp:357] Iteration 55100 (9.37485 iter/s, 10.6668s/100 iters), loss = 0.039157
I0925 23:19:36.683486 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0391569 (* 1 = 0.0391569 loss)
I0925 23:19:36.683496 19975 sgd_solver.cpp:165] Iteration 55100, lr = 0.001
I0925 23:19:47.346824 19975 solver.cpp:357] Iteration 55200 (9.3777 iter/s, 10.6636s/100 iters), loss = 0.03776
I0925 23:19:47.347030 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0377598 (* 1 = 0.0377598 loss)
I0925 23:19:47.347040 19975 sgd_solver.cpp:165] Iteration 55200, lr = 0.001
I0925 23:19:58.007334 19975 solver.cpp:357] Iteration 55300 (9.37948 iter/s, 10.6616s/100 iters), loss = 0.0431035
I0925 23:19:58.007398 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0431034 (* 1 = 0.0431034 loss)
I0925 23:19:58.007407 19975 sgd_solver.cpp:165] Iteration 55300, lr = 0.001
I0925 23:20:08.671391 19975 solver.cpp:357] Iteration 55400 (9.37625 iter/s, 10.6652s/100 iters), loss = 0.0129403
I0925 23:20:08.671453 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0129401 (* 1 = 0.0129401 loss)
I0925 23:20:08.671464 19975 sgd_solver.cpp:165] Iteration 55400, lr = 0.001
I0925 23:20:15.500423 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:20:19.229468 19975 solver.cpp:514] Iteration 55500, Testing net (#0)
I0925 23:20:22.413317 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:20:22.426015 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.275845 (* 1 = 0.275845 loss)
I0925 23:20:22.426043 19975 solver.cpp:580]     Test net output #1: prob = 0.920702
I0925 23:20:22.530915 19975 solver.cpp:357] Iteration 55500 (7.21445 iter/s, 13.8611s/100 iters), loss = 0.0234309
I0925 23:20:22.530957 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0234308 (* 1 = 0.0234308 loss)
I0925 23:20:22.530972 19975 sgd_solver.cpp:165] Iteration 55500, lr = 0.001
I0925 23:20:33.180529 19975 solver.cpp:357] Iteration 55600 (9.38898 iter/s, 10.6508s/100 iters), loss = 0.028795
I0925 23:20:33.180594 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0287948 (* 1 = 0.0287948 loss)
I0925 23:20:33.180605 19975 sgd_solver.cpp:165] Iteration 55600, lr = 0.001
I0925 23:20:43.829567 19975 solver.cpp:357] Iteration 55700 (9.38953 iter/s, 10.6502s/100 iters), loss = 0.0320099
I0925 23:20:43.829633 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0320097 (* 1 = 0.0320097 loss)
I0925 23:20:43.829644 19975 sgd_solver.cpp:165] Iteration 55700, lr = 0.001
I0925 23:20:54.496780 19975 solver.cpp:357] Iteration 55800 (9.37355 iter/s, 10.6683s/100 iters), loss = 0.0532817
I0925 23:20:54.496925 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0532816 (* 1 = 0.0532816 loss)
I0925 23:20:54.496934 19975 sgd_solver.cpp:165] Iteration 55800, lr = 0.001
I0925 23:21:00.369307 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:21:05.164963 19975 solver.cpp:357] Iteration 55900 (9.37278 iter/s, 10.6692s/100 iters), loss = 0.0906533
I0925 23:21:05.165029 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0906532 (* 1 = 0.0906532 loss)
I0925 23:21:05.165037 19975 sgd_solver.cpp:165] Iteration 55900, lr = 0.001
I0925 23:21:15.727190 19975 solver.cpp:514] Iteration 56000, Testing net (#0)
I0925 23:21:18.923527 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:21:18.943857 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.272274 (* 1 = 0.272274 loss)
I0925 23:21:18.943887 19975 solver.cpp:580]     Test net output #1: prob = 0.920602
I0925 23:21:19.048238 19975 solver.cpp:357] Iteration 56000 (7.20217 iter/s, 13.8847s/100 iters), loss = 0.0299187
I0925 23:21:19.048282 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0299186 (* 1 = 0.0299186 loss)
I0925 23:21:19.048295 19975 sgd_solver.cpp:165] Iteration 56000, lr = 0.001
I0925 23:21:29.706734 19975 solver.cpp:357] Iteration 56100 (9.38124 iter/s, 10.6596s/100 iters), loss = 0.022854
I0925 23:21:29.706890 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0228539 (* 1 = 0.0228539 loss)
I0925 23:21:29.706900 19975 sgd_solver.cpp:165] Iteration 56100, lr = 0.001
I0925 23:21:40.357815 19975 solver.cpp:357] Iteration 56200 (9.38788 iter/s, 10.652s/100 iters), loss = 0.0270683
I0925 23:21:40.357878 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0270681 (* 1 = 0.0270681 loss)
I0925 23:21:40.357889 19975 sgd_solver.cpp:165] Iteration 56200, lr = 0.001
I0925 23:21:45.148061 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:21:51.001221 19975 solver.cpp:357] Iteration 56300 (9.39458 iter/s, 10.6444s/100 iters), loss = 0.0253381
I0925 23:21:51.001286 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.025338 (* 1 = 0.025338 loss)
I0925 23:21:51.001296 19975 sgd_solver.cpp:165] Iteration 56300, lr = 0.001
I0925 23:22:01.661707 19975 solver.cpp:357] Iteration 56400 (9.37955 iter/s, 10.6615s/100 iters), loss = 0.0307098
I0925 23:22:01.661840 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0307096 (* 1 = 0.0307096 loss)
I0925 23:22:01.661850 19975 sgd_solver.cpp:165] Iteration 56400, lr = 0.001
I0925 23:22:12.220820 19975 solver.cpp:514] Iteration 56500, Testing net (#0)
I0925 23:22:15.412328 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:22:15.424924 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.27828 (* 1 = 0.27828 loss)
I0925 23:22:15.424952 19975 solver.cpp:580]     Test net output #1: prob = 0.922502
I0925 23:22:15.529369 19975 solver.cpp:357] Iteration 56500 (7.21037 iter/s, 13.8689s/100 iters), loss = 0.0321655
I0925 23:22:15.529414 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0321653 (* 1 = 0.0321653 loss)
I0925 23:22:15.529429 19975 sgd_solver.cpp:165] Iteration 56500, lr = 0.001
I0925 23:22:26.187094 19975 solver.cpp:357] Iteration 56600 (9.38199 iter/s, 10.6587s/100 iters), loss = 0.0340707
I0925 23:22:26.187160 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0340706 (* 1 = 0.0340706 loss)
I0925 23:22:26.187171 19975 sgd_solver.cpp:165] Iteration 56600, lr = 0.001
I0925 23:22:30.034770 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:22:36.860323 19975 solver.cpp:357] Iteration 56700 (9.36839 iter/s, 10.6742s/100 iters), loss = 0.0302696
I0925 23:22:36.860430 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0302695 (* 1 = 0.0302695 loss)
I0925 23:22:36.860440 19975 sgd_solver.cpp:165] Iteration 56700, lr = 0.001
I0925 23:22:47.514530 19975 solver.cpp:357] Iteration 56800 (9.38517 iter/s, 10.6551s/100 iters), loss = 0.0238669
I0925 23:22:47.514593 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0238667 (* 1 = 0.0238667 loss)
I0925 23:22:47.514603 19975 sgd_solver.cpp:165] Iteration 56800, lr = 0.001
I0925 23:22:58.175221 19975 solver.cpp:357] Iteration 56900 (9.37943 iter/s, 10.6616s/100 iters), loss = 0.0322685
I0925 23:22:58.175282 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0322684 (* 1 = 0.0322684 loss)
I0925 23:22:58.175293 19975 sgd_solver.cpp:165] Iteration 56900, lr = 0.001
I0925 23:23:08.742686 19975 solver.cpp:514] Iteration 57000, Testing net (#0)
I0925 23:23:11.969825 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:23:11.982707 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.271913 (* 1 = 0.271913 loss)
I0925 23:23:11.982734 19975 solver.cpp:580]     Test net output #1: prob = 0.923802
I0925 23:23:12.088253 19975 solver.cpp:357] Iteration 57000 (7.18687 iter/s, 13.9143s/100 iters), loss = 0.045776
I0925 23:23:12.088296 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0457759 (* 1 = 0.0457759 loss)
I0925 23:23:12.088306 19975 sgd_solver.cpp:165] Iteration 57000, lr = 0.001
I0925 23:23:14.972796 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:23:22.754199 19975 solver.cpp:357] Iteration 57100 (9.37482 iter/s, 10.6669s/100 iters), loss = 0.0652945
I0925 23:23:22.754261 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0652943 (* 1 = 0.0652943 loss)
I0925 23:23:22.754271 19975 sgd_solver.cpp:165] Iteration 57100, lr = 0.001
I0925 23:23:33.427570 19975 solver.cpp:357] Iteration 57200 (9.36832 iter/s, 10.6743s/100 iters), loss = 0.0574098
I0925 23:23:33.427636 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0574097 (* 1 = 0.0574097 loss)
I0925 23:23:33.427646 19975 sgd_solver.cpp:165] Iteration 57200, lr = 0.001
I0925 23:23:44.083678 19975 solver.cpp:357] Iteration 57300 (9.38352 iter/s, 10.657s/100 iters), loss = 0.0221908
I0925 23:23:44.083880 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0221907 (* 1 = 0.0221907 loss)
I0925 23:23:44.083890 19975 sgd_solver.cpp:165] Iteration 57300, lr = 0.001
I0925 23:23:54.745800 19975 solver.cpp:357] Iteration 57400 (9.37835 iter/s, 10.6629s/100 iters), loss = 0.0235136
I0925 23:23:54.745863 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0235134 (* 1 = 0.0235134 loss)
I0925 23:23:54.745877 19975 sgd_solver.cpp:165] Iteration 57400, lr = 0.001
I0925 23:23:56.571524 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:24:05.302669 19975 solver.cpp:514] Iteration 57500, Testing net (#0)
I0925 23:24:08.519863 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:24:08.531977 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.275898 (* 1 = 0.275898 loss)
I0925 23:24:08.531999 19975 solver.cpp:580]     Test net output #1: prob = 0.918902
I0925 23:24:08.637668 19975 solver.cpp:357] Iteration 57500 (7.19786 iter/s, 13.893s/100 iters), loss = 0.0178149
I0925 23:24:08.637713 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0178147 (* 1 = 0.0178147 loss)
I0925 23:24:08.637724 19975 sgd_solver.cpp:165] Iteration 57500, lr = 0.001
I0925 23:24:19.317659 19975 solver.cpp:357] Iteration 57600 (9.36255 iter/s, 10.6809s/100 iters), loss = 0.0521592
I0925 23:24:19.317817 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.052159 (* 1 = 0.052159 loss)
I0925 23:24:19.317827 19975 sgd_solver.cpp:165] Iteration 57600, lr = 0.001
I0925 23:24:29.965097 19975 solver.cpp:357] Iteration 57700 (9.39128 iter/s, 10.6482s/100 iters), loss = 0.0316273
I0925 23:24:29.965158 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0316271 (* 1 = 0.0316271 loss)
I0925 23:24:29.965167 19975 sgd_solver.cpp:165] Iteration 57700, lr = 0.001
I0925 23:24:40.621871 19975 solver.cpp:357] Iteration 57800 (9.38298 iter/s, 10.6576s/100 iters), loss = 0.013327
I0925 23:24:40.621937 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0133268 (* 1 = 0.0133268 loss)
I0925 23:24:40.621948 19975 sgd_solver.cpp:165] Iteration 57800, lr = 0.001
I0925 23:24:41.482568 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:24:51.281301 19975 solver.cpp:357] Iteration 57900 (9.38065 iter/s, 10.6602s/100 iters), loss = 0.016089
I0925 23:24:51.281443 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0160889 (* 1 = 0.0160889 loss)
I0925 23:24:51.281453 19975 sgd_solver.cpp:165] Iteration 57900, lr = 0.001
I0925 23:25:01.838999 19975 solver.cpp:514] Iteration 58000, Testing net (#0)
I0925 23:25:05.058542 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:25:05.070471 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.289792 (* 1 = 0.289792 loss)
I0925 23:25:05.070497 19975 solver.cpp:580]     Test net output #1: prob = 0.917602
I0925 23:25:05.174731 19975 solver.cpp:357] Iteration 58000 (7.19713 iter/s, 13.8944s/100 iters), loss = 0.0275725
I0925 23:25:05.174777 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0275723 (* 1 = 0.0275723 loss)
I0925 23:25:05.174791 19975 sgd_solver.cpp:165] Iteration 58000, lr = 0.001
I0925 23:25:15.829685 19975 solver.cpp:357] Iteration 58100 (9.3846 iter/s, 10.6558s/100 iters), loss = 0.0363003
I0925 23:25:15.829749 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0363001 (* 1 = 0.0363001 loss)
I0925 23:25:15.829759 19975 sgd_solver.cpp:165] Iteration 58100, lr = 0.001
I0925 23:25:26.427513 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:25:26.531972 19975 solver.cpp:357] Iteration 58200 (9.34312 iter/s, 10.7031s/100 iters), loss = 0.0377868
I0925 23:25:26.532057 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0377866 (* 1 = 0.0377866 loss)
I0925 23:25:26.532073 19975 sgd_solver.cpp:165] Iteration 58200, lr = 0.001
I0925 23:25:37.208436 19975 solver.cpp:357] Iteration 58300 (9.36574 iter/s, 10.6772s/100 iters), loss = 0.0298606
I0925 23:25:37.208501 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0298605 (* 1 = 0.0298605 loss)
I0925 23:25:37.208511 19975 sgd_solver.cpp:165] Iteration 58300, lr = 0.001
I0925 23:25:47.874418 19975 solver.cpp:357] Iteration 58400 (9.37494 iter/s, 10.6667s/100 iters), loss = 0.0419557
I0925 23:25:47.874482 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0419556 (* 1 = 0.0419556 loss)
I0925 23:25:47.874491 19975 sgd_solver.cpp:165] Iteration 58400, lr = 0.001
I0925 23:25:58.420683 19975 solver.cpp:514] Iteration 58500, Testing net (#0)
I0925 23:26:01.624327 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:26:01.636482 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.282078 (* 1 = 0.282078 loss)
I0925 23:26:01.636508 19975 solver.cpp:580]     Test net output #1: prob = 0.921402
I0925 23:26:01.741374 19975 solver.cpp:357] Iteration 58500 (7.21087 iter/s, 13.868s/100 iters), loss = 0.0206147
I0925 23:26:01.741418 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0206146 (* 1 = 0.0206146 loss)
I0925 23:26:01.741430 19975 sgd_solver.cpp:165] Iteration 58500, lr = 0.001
I0925 23:26:11.233419 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:26:12.402390 19975 solver.cpp:357] Iteration 58600 (9.37931 iter/s, 10.6618s/100 iters), loss = 0.042496
I0925 23:26:12.402452 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0424959 (* 1 = 0.0424959 loss)
I0925 23:26:12.402462 19975 sgd_solver.cpp:165] Iteration 58600, lr = 0.001
I0925 23:26:23.052930 19975 solver.cpp:357] Iteration 58700 (9.38855 iter/s, 10.6513s/100 iters), loss = 0.0286254
I0925 23:26:23.052997 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0286252 (* 1 = 0.0286252 loss)
I0925 23:26:23.053006 19975 sgd_solver.cpp:165] Iteration 58700, lr = 0.001
I0925 23:26:33.707036 19975 solver.cpp:357] Iteration 58800 (9.38542 iter/s, 10.6548s/100 iters), loss = 0.0397232
I0925 23:26:33.707187 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0397231 (* 1 = 0.0397231 loss)
I0925 23:26:33.707197 19975 sgd_solver.cpp:165] Iteration 58800, lr = 0.001
I0925 23:26:44.391892 19975 solver.cpp:357] Iteration 58900 (9.3585 iter/s, 10.6855s/100 iters), loss = 0.0259887
I0925 23:26:44.391984 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0259885 (* 1 = 0.0259885 loss)
I0925 23:26:44.392001 19975 sgd_solver.cpp:165] Iteration 58900, lr = 0.001
I0925 23:26:52.962404 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:26:54.992338 19975 solver.cpp:514] Iteration 59000, Testing net (#0)
I0925 23:26:58.446458 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:26:58.458640 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.281825 (* 1 = 0.281825 loss)
I0925 23:26:58.458685 19975 solver.cpp:580]     Test net output #1: prob = 0.921302
I0925 23:26:58.564117 19975 solver.cpp:357] Iteration 59000 (7.05559 iter/s, 14.1732s/100 iters), loss = 0.0211586
I0925 23:26:58.564195 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0211584 (* 1 = 0.0211584 loss)
I0925 23:26:58.564209 19975 sgd_solver.cpp:165] Iteration 59000, lr = 0.001
I0925 23:27:09.265177 19975 solver.cpp:357] Iteration 59100 (9.34428 iter/s, 10.7017s/100 iters), loss = 0.0498472
I0925 23:27:09.265388 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.049847 (* 1 = 0.049847 loss)
I0925 23:27:09.265400 19975 sgd_solver.cpp:165] Iteration 59100, lr = 0.001
I0925 23:27:19.940251 19975 solver.cpp:357] Iteration 59200 (9.36714 iter/s, 10.6756s/100 iters), loss = 0.0244692
I0925 23:27:19.940315 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.024469 (* 1 = 0.024469 loss)
I0925 23:27:19.940326 19975 sgd_solver.cpp:165] Iteration 59200, lr = 0.001
I0925 23:27:30.587534 19975 solver.cpp:357] Iteration 59300 (9.39147 iter/s, 10.648s/100 iters), loss = 0.0252946
I0925 23:27:30.587597 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0252944 (* 1 = 0.0252944 loss)
I0925 23:27:30.587607 19975 sgd_solver.cpp:165] Iteration 59300, lr = 0.001
I0925 23:27:38.063642 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:27:41.254447 19975 solver.cpp:357] Iteration 59400 (9.3742 iter/s, 10.6676s/100 iters), loss = 0.0787912
I0925 23:27:41.254600 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.078791 (* 1 = 0.078791 loss)
I0925 23:27:41.254608 19975 sgd_solver.cpp:165] Iteration 59400, lr = 0.001
I0925 23:27:51.816149 19975 solver.cpp:514] Iteration 59500, Testing net (#0)
I0925 23:27:55.212276 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:27:55.224849 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.280081 (* 1 = 0.280081 loss)
I0925 23:27:55.224879 19975 solver.cpp:580]     Test net output #1: prob = 0.920002
I0925 23:27:55.330037 19975 solver.cpp:357] Iteration 59500 (7.10409 iter/s, 14.0764s/100 iters), loss = 0.0159739
I0925 23:27:55.330102 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0159737 (* 1 = 0.0159737 loss)
I0925 23:27:55.330113 19975 sgd_solver.cpp:165] Iteration 59500, lr = 0.001
I0925 23:28:06.011071 19975 solver.cpp:357] Iteration 59600 (9.36182 iter/s, 10.6817s/100 iters), loss = 0.0389857
I0925 23:28:06.011134 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0389855 (* 1 = 0.0389855 loss)
I0925 23:28:06.011147 19975 sgd_solver.cpp:165] Iteration 59600, lr = 0.001
I0925 23:28:16.656448 19975 solver.cpp:357] Iteration 59700 (9.39318 iter/s, 10.646s/100 iters), loss = 0.0239285
I0925 23:28:16.656610 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0239283 (* 1 = 0.0239283 loss)
I0925 23:28:16.656620 19975 sgd_solver.cpp:165] Iteration 59700, lr = 0.001
I0925 23:28:23.183076 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:28:27.323856 19975 solver.cpp:357] Iteration 59800 (9.37387 iter/s, 10.6679s/100 iters), loss = 0.0284081
I0925 23:28:27.323920 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0284079 (* 1 = 0.0284079 loss)
I0925 23:28:27.323930 19975 sgd_solver.cpp:165] Iteration 59800, lr = 0.001
I0925 23:28:37.973561 19975 solver.cpp:357] Iteration 59900 (9.38938 iter/s, 10.6503s/100 iters), loss = 0.0405084
I0925 23:28:37.973623 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0405082 (* 1 = 0.0405082 loss)
I0925 23:28:37.973634 19975 sgd_solver.cpp:165] Iteration 59900, lr = 0.001
I0925 23:28:48.518594 19975 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_60000.caffemodel
I0925 23:28:48.526715 19975 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_60000.solverstate
I0925 23:28:48.529757 19975 solver.cpp:514] Iteration 60000, Testing net (#0)
I0925 23:28:51.775583 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:28:51.796432 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.279885 (* 1 = 0.279885 loss)
I0925 23:28:51.796460 19975 solver.cpp:580]     Test net output #1: prob = 0.923402
I0925 23:28:51.901547 19975 solver.cpp:357] Iteration 60000 (7.17935 iter/s, 13.9288s/100 iters), loss = 0.0152738
I0925 23:28:51.901592 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0152736 (* 1 = 0.0152736 loss)
I0925 23:28:51.901602 19975 sgd_solver.cpp:165] Iteration 60000, lr = 0.001
I0925 23:29:02.591086 19975 solver.cpp:357] Iteration 60100 (9.35439 iter/s, 10.6902s/100 iters), loss = 0.0193748
I0925 23:29:02.591157 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0193746 (* 1 = 0.0193746 loss)
I0925 23:29:02.591167 19975 sgd_solver.cpp:165] Iteration 60100, lr = 0.001
I0925 23:29:08.224069 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:29:14.682962 19975 solver.cpp:357] Iteration 60200 (8.26955 iter/s, 12.0926s/100 iters), loss = 0.0301098
I0925 23:29:14.683115 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0301096 (* 1 = 0.0301096 loss)
I0925 23:29:14.683143 19975 sgd_solver.cpp:165] Iteration 60200, lr = 0.001
I0925 23:29:33.090663 19975 solver.cpp:357] Iteration 60300 (5.43284 iter/s, 18.4066s/100 iters), loss = 0.0265212
I0925 23:29:33.090903 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.026521 (* 1 = 0.026521 loss)
I0925 23:29:33.090915 19975 sgd_solver.cpp:165] Iteration 60300, lr = 0.001
I0925 23:29:52.910902 19975 solver.cpp:357] Iteration 60400 (5.04562 iter/s, 19.8192s/100 iters), loss = 0.0175474
I0925 23:29:52.910975 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0175472 (* 1 = 0.0175472 loss)
I0925 23:29:52.910987 19975 sgd_solver.cpp:165] Iteration 60400, lr = 0.001
I0925 23:30:12.203160 19975 solver.cpp:514] Iteration 60500, Testing net (#0)
I0925 23:30:23.839891 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:30:23.902782 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.286562 (* 1 = 0.286562 loss)
I0925 23:30:23.902931 19975 solver.cpp:580]     Test net output #1: prob = 0.921403
I0925 23:30:24.088260 19975 solver.cpp:357] Iteration 60500 (3.2075 iter/s, 31.177s/100 iters), loss = 0.0303202
I0925 23:30:24.088337 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.03032 (* 1 = 0.03032 loss)
I0925 23:30:24.088348 19975 sgd_solver.cpp:165] Iteration 60500, lr = 0.001
I0925 23:30:32.357188 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:30:44.116420 19975 solver.cpp:357] Iteration 60600 (4.99279 iter/s, 20.0289s/100 iters), loss = 0.0250594
I0925 23:30:44.116801 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0250592 (* 1 = 0.0250592 loss)
I0925 23:30:44.116838 19975 sgd_solver.cpp:165] Iteration 60600, lr = 0.001
I0925 23:31:04.082013 19975 solver.cpp:357] Iteration 60700 (5.00842 iter/s, 19.9664s/100 iters), loss = 0.0280634
I0925 23:31:04.082094 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0280632 (* 1 = 0.0280632 loss)
I0925 23:31:04.082105 19975 sgd_solver.cpp:165] Iteration 60700, lr = 0.001
I0925 23:31:24.034844 19975 solver.cpp:357] Iteration 60800 (5.01211 iter/s, 19.9517s/100 iters), loss = 0.0145383
I0925 23:31:24.034996 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0145381 (* 1 = 0.0145381 loss)
I0925 23:31:24.035023 19975 sgd_solver.cpp:165] Iteration 60800, lr = 0.001
I0925 23:31:42.645081 19975 solver.cpp:357] Iteration 60900 (5.37313 iter/s, 18.6111s/100 iters), loss = 0.0221579
I0925 23:31:42.645221 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0221577 (* 1 = 0.0221577 loss)
I0925 23:31:42.645247 19975 sgd_solver.cpp:165] Iteration 60900, lr = 0.001
I0925 23:31:49.239121 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:32:02.265805 19975 solver.cpp:514] Iteration 61000, Testing net (#0)
I0925 23:32:13.051558 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:32:13.104578 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.294802 (* 1 = 0.294802 loss)
I0925 23:32:13.104611 19975 solver.cpp:580]     Test net output #1: prob = 0.917302
I0925 23:32:13.288436 19975 solver.cpp:357] Iteration 61000 (3.26331 iter/s, 30.6438s/100 iters), loss = 0.0296099
I0925 23:32:13.288511 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0296097 (* 1 = 0.0296097 loss)
I0925 23:32:13.288523 19975 sgd_solver.cpp:165] Iteration 61000, lr = 0.001
I0925 23:32:27.202126 19975 solver.cpp:357] Iteration 61100 (7.18725 iter/s, 13.9135s/100 iters), loss = 0.0294937
I0925 23:32:27.202215 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0294935 (* 1 = 0.0294935 loss)
I0925 23:32:27.202227 19975 sgd_solver.cpp:165] Iteration 61100, lr = 0.001
I0925 23:32:37.982756 19975 solver.cpp:357] Iteration 61200 (9.27547 iter/s, 10.7811s/100 iters), loss = 0.0170878
I0925 23:32:37.982908 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0170876 (* 1 = 0.0170876 loss)
I0925 23:32:37.982920 19975 sgd_solver.cpp:165] Iteration 61200, lr = 0.001
I0925 23:32:54.346038 19975 solver.cpp:357] Iteration 61300 (6.11097 iter/s, 16.364s/100 iters), loss = 0.0339216
I0925 23:32:54.346176 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0339214 (* 1 = 0.0339214 loss)
I0925 23:32:54.346204 19975 sgd_solver.cpp:165] Iteration 61300, lr = 0.001
I0925 23:32:59.006144 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:33:14.138701 19975 solver.cpp:357] Iteration 61400 (5.05215 iter/s, 19.7935s/100 iters), loss = 0.0237173
I0925 23:33:14.138897 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0237171 (* 1 = 0.0237171 loss)
I0925 23:33:14.138909 19975 sgd_solver.cpp:165] Iteration 61400, lr = 0.001
I0925 23:33:33.696264 19975 solver.cpp:514] Iteration 61500, Testing net (#0)
I0925 23:33:46.307719 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:33:46.361861 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.284559 (* 1 = 0.284559 loss)
I0925 23:33:46.361945 19975 solver.cpp:580]     Test net output #1: prob = 0.922102
I0925 23:33:46.541334 19975 solver.cpp:357] Iteration 61500 (3.08615 iter/s, 32.4029s/100 iters), loss = 0.0133199
I0925 23:33:46.541406 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0133197 (* 1 = 0.0133197 loss)
I0925 23:33:46.541419 19975 sgd_solver.cpp:165] Iteration 61500, lr = 0.001
I0925 23:34:06.388339 19975 solver.cpp:357] Iteration 61600 (5.03846 iter/s, 19.8474s/100 iters), loss = 0.045616
I0925 23:34:06.388471 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0456158 (* 1 = 0.0456158 loss)
I0925 23:34:06.388499 19975 sgd_solver.cpp:165] Iteration 61600, lr = 0.001
I0925 23:34:26.037644 19975 solver.cpp:357] Iteration 61700 (5.08902 iter/s, 19.6501s/100 iters), loss = 0.0219702
I0925 23:34:26.037824 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.02197 (* 1 = 0.02197 loss)
I0925 23:34:26.037852 19975 sgd_solver.cpp:165] Iteration 61700, lr = 0.001
I0925 23:34:28.781683 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:34:45.691973 19975 solver.cpp:357] Iteration 61800 (5.08773 iter/s, 19.6551s/100 iters), loss = 0.0436507
I0925 23:34:45.692152 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0436505 (* 1 = 0.0436505 loss)
I0925 23:34:45.692198 19975 sgd_solver.cpp:165] Iteration 61800, lr = 0.001
I0925 23:35:04.540742 19975 solver.cpp:357] Iteration 61900 (5.30554 iter/s, 18.8482s/100 iters), loss = 0.0706286
I0925 23:35:04.540930 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0706284 (* 1 = 0.0706284 loss)
I0925 23:35:04.540957 19975 sgd_solver.cpp:165] Iteration 61900, lr = 0.001
I0925 23:35:23.753410 19975 solver.cpp:514] Iteration 62000, Testing net (#0)
I0925 23:35:35.985272 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:35:36.049165 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.292876 (* 1 = 0.292876 loss)
I0925 23:35:36.049289 19975 solver.cpp:580]     Test net output #1: prob = 0.921102
I0925 23:35:36.223747 19975 solver.cpp:357] Iteration 62000 (3.15613 iter/s, 31.6843s/100 iters), loss = 0.0478655
I0925 23:35:36.223876 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0478653 (* 1 = 0.0478653 loss)
I0925 23:35:36.223902 19975 sgd_solver.cpp:165] Iteration 62000, lr = 0.001
I0925 23:35:56.103670 19975 solver.cpp:357] Iteration 62100 (5.03029 iter/s, 19.8796s/100 iters), loss = 0.0268622
I0925 23:35:56.103806 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0268621 (* 1 = 0.0268621 loss)
I0925 23:35:56.103833 19975 sgd_solver.cpp:165] Iteration 62100, lr = 0.001
I0925 23:35:57.138177 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:36:15.767714 19975 solver.cpp:357] Iteration 62200 (5.08552 iter/s, 19.6637s/100 iters), loss = 0.0480591
I0925 23:36:15.767876 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0480589 (* 1 = 0.0480589 loss)
I0925 23:36:15.767889 19975 sgd_solver.cpp:165] Iteration 62200, lr = 0.001
I0925 23:36:35.456751 19975 solver.cpp:357] Iteration 62300 (5.07932 iter/s, 19.6877s/100 iters), loss = 0.0303534
I0925 23:36:35.456828 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0303532 (* 1 = 0.0303532 loss)
I0925 23:36:35.456840 19975 sgd_solver.cpp:165] Iteration 62300, lr = 0.001
I0925 23:36:54.952711 19975 solver.cpp:357] Iteration 62400 (5.12963 iter/s, 19.4946s/100 iters), loss = 0.0306416
I0925 23:36:54.952939 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0306414 (* 1 = 0.0306414 loss)
I0925 23:36:54.952951 19975 sgd_solver.cpp:165] Iteration 62400, lr = 0.001
I0925 23:37:13.450768 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:37:14.006283 19975 solver.cpp:514] Iteration 62500, Testing net (#0)
I0925 23:37:25.261942 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:37:25.301193 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.282885 (* 1 = 0.282885 loss)
I0925 23:37:25.301229 19975 solver.cpp:580]     Test net output #1: prob = 0.921802
I0925 23:37:25.487201 19975 solver.cpp:357] Iteration 62500 (3.27508 iter/s, 30.5336s/100 iters), loss = 0.0210575
I0925 23:37:25.487279 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0210574 (* 1 = 0.0210574 loss)
I0925 23:37:25.487290 19975 sgd_solver.cpp:165] Iteration 62500, lr = 0.001
I0925 23:37:45.279178 19975 solver.cpp:357] Iteration 62600 (5.05291 iter/s, 19.7906s/100 iters), loss = 0.0402096
I0925 23:37:45.279258 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0402094 (* 1 = 0.0402094 loss)
I0925 23:37:45.279269 19975 sgd_solver.cpp:165] Iteration 62600, lr = 0.001
I0925 23:38:04.942253 19975 solver.cpp:357] Iteration 62700 (5.08603 iter/s, 19.6617s/100 iters), loss = 0.0207963
I0925 23:38:04.942517 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0207962 (* 1 = 0.0207962 loss)
I0925 23:38:04.942543 19975 sgd_solver.cpp:165] Iteration 62700, lr = 0.001
I0925 23:38:24.641841 19975 solver.cpp:357] Iteration 62800 (5.07639 iter/s, 19.699s/100 iters), loss = 0.0443539
I0925 23:38:24.641916 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0443537 (* 1 = 0.0443537 loss)
I0925 23:38:24.641929 19975 sgd_solver.cpp:165] Iteration 62800, lr = 0.001
I0925 23:38:41.555454 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:38:44.267417 19975 solver.cpp:357] Iteration 62900 (5.09554 iter/s, 19.625s/100 iters), loss = 0.0540429
I0925 23:38:44.267498 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0540427 (* 1 = 0.0540427 loss)
I0925 23:38:44.267510 19975 sgd_solver.cpp:165] Iteration 62900, lr = 0.001
I0925 23:38:56.663689 19975 solver.cpp:514] Iteration 63000, Testing net (#0)
I0925 23:38:59.990156 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:39:00.002041 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.29746 (* 1 = 0.29746 loss)
I0925 23:39:00.002075 19975 solver.cpp:580]     Test net output #1: prob = 0.921002
I0925 23:39:00.108247 19975 solver.cpp:357] Iteration 63000 (6.31344 iter/s, 15.8392s/100 iters), loss = 0.0356795
I0925 23:39:00.108337 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0356794 (* 1 = 0.0356794 loss)
I0925 23:39:00.108353 19975 sgd_solver.cpp:165] Iteration 63000, lr = 0.001
I0925 23:39:10.805474 19975 solver.cpp:357] Iteration 63100 (9.34789 iter/s, 10.6976s/100 iters), loss = 0.0398681
I0925 23:39:10.805541 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.039868 (* 1 = 0.039868 loss)
I0925 23:39:10.805549 19975 sgd_solver.cpp:165] Iteration 63100, lr = 0.001
I0925 23:39:21.481096 19975 solver.cpp:357] Iteration 63200 (9.36679 iter/s, 10.676s/100 iters), loss = 0.0133203
I0925 23:39:21.481250 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0133202 (* 1 = 0.0133202 loss)
I0925 23:39:21.481258 19975 sgd_solver.cpp:165] Iteration 63200, lr = 0.001
I0925 23:39:29.706900 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:39:32.156227 19975 solver.cpp:357] Iteration 63300 (9.3673 iter/s, 10.6754s/100 iters), loss = 0.027236
I0925 23:39:32.156291 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0272358 (* 1 = 0.0272358 loss)
I0925 23:39:32.156301 19975 sgd_solver.cpp:165] Iteration 63300, lr = 0.001
I0925 23:39:42.840152 19975 solver.cpp:357] Iteration 63400 (9.35951 iter/s, 10.6843s/100 iters), loss = 0.0266198
I0925 23:39:42.840216 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0266197 (* 1 = 0.0266197 loss)
I0925 23:39:42.840226 19975 sgd_solver.cpp:165] Iteration 63400, lr = 0.001
I0925 23:39:53.413743 19975 solver.cpp:514] Iteration 63500, Testing net (#0)
I0925 23:39:56.599459 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:39:56.611466 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.292545 (* 1 = 0.292545 loss)
I0925 23:39:56.611493 19975 solver.cpp:580]     Test net output #1: prob = 0.921702
I0925 23:39:56.717411 19975 solver.cpp:357] Iteration 63500 (7.20576 iter/s, 13.8778s/100 iters), loss = 0.0219414
I0925 23:39:56.717455 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0219412 (* 1 = 0.0219412 loss)
I0925 23:39:56.717466 19975 sgd_solver.cpp:165] Iteration 63500, lr = 0.001
I0925 23:40:07.399348 19975 solver.cpp:357] Iteration 63600 (9.36124 iter/s, 10.6823s/100 iters), loss = 0.0267707
I0925 23:40:07.399413 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0267706 (* 1 = 0.0267706 loss)
I0925 23:40:07.399422 19975 sgd_solver.cpp:165] Iteration 63600, lr = 0.001
I0925 23:40:14.581063 19981 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:40:18.084688 19975 solver.cpp:357] Iteration 63700 (9.35828 iter/s, 10.6857s/100 iters), loss = 0.0503465
I0925 23:40:18.084753 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0503463 (* 1 = 0.0503463 loss)
I0925 23:40:18.084761 19975 sgd_solver.cpp:165] Iteration 63700, lr = 0.001
I0925 23:40:28.779810 19975 solver.cpp:357] Iteration 63800 (9.34972 iter/s, 10.6955s/100 iters), loss = 0.0261168
I0925 23:40:28.779964 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.0261166 (* 1 = 0.0261166 loss)
I0925 23:40:28.779974 19975 sgd_solver.cpp:165] Iteration 63800, lr = 0.001
I0925 23:40:39.449054 19975 solver.cpp:357] Iteration 63900 (9.37248 iter/s, 10.6695s/100 iters), loss = 0.0224412
I0925 23:40:39.449118 19975 solver.cpp:376]     Train net output #0: Softmax1 = 0.022441 (* 1 = 0.022441 loss)
I0925 23:40:39.449127 19975 sgd_solver.cpp:165] Iteration 63900, lr = 0.001
I0925 23:40:50.033324 19975 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_20_iter_64000.caffemodel
I0925 23:40:50.041481 19975 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_20_iter_64000.solverstate
I0925 23:40:50.070657 19975 solver.cpp:472] Iteration 64000, loss = 0.0170238
I0925 23:40:50.070699 19975 solver.cpp:514] Iteration 64000, Testing net (#0)
I0925 23:40:53.314075 19982 data_layer.cpp:73] Restarting data prefetching from start.
I0925 23:40:53.326182 19975 solver.cpp:580]     Test net output #0: Softmax1 = 0.300876 (* 1 = 0.300876 loss)
I0925 23:40:53.326210 19975 solver.cpp:580]     Test net output #1: prob = 0.920902
I0925 23:40:53.326217 19975 solver.cpp:479] Optimization Done.
I0925 23:40:53.326221 19975 caffe.cpp:326] Optimization Done.
