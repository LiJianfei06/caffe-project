WARNING: Logging before InitGoogleLogging() is written to STDERR
I0929 16:32:15.659374 25496 caffe.cpp:530] argc:5 lijianfei debug!!!!!!!!!!
I0929 16:32:15.659508 25496 caffe.cpp:533] argv[0]:../../build/tools/caffe lijianfei debug!!!!!!!!!!
I0929 16:32:15.659514 25496 caffe.cpp:533] argv[1]:train lijianfei debug!!!!!!!!!!
I0929 16:32:15.659518 25496 caffe.cpp:533] argv[2]:--solver=./solver.prototxt lijianfei debug!!!!!!!!!!
I0929 16:32:15.659521 25496 caffe.cpp:533] argv[3]:--weights= lijianfei debug!!!!!!!!!!
I0929 16:32:15.659525 25496 caffe.cpp:533] argv[4]:--gpu=0 lijianfei debug!!!!!!!!!!
I0929 16:32:15.659581 25496 caffe.cpp:548] use WITH_PYTHON_LAYER lijianfei debug!!!!!!!!!!
I0929 16:32:15.659777 25496 caffe.cpp:553] caffe::string(argv[1]):train lijianfei debug!!!!!!!!!!
I0929 16:32:15.669430 25496 caffe.cpp:238] stages: lijianfei debug!!!!!!!!!!!!
I0929 16:32:15.669471 25496 caffe.cpp:269] Using GPUs 0
I0929 16:32:15.681059 25496 caffe.cpp:274] GPU 0: GeForce GTX 1060 6GB
I0929 16:32:16.334869 25496 solver_factory.hpp:111] function Solver<Dtype>* CreateSolver()  lijianfei debug!!!!!!!!!!
I0929 16:32:16.334954 25496 solver_factory.hpp:113] type:Nesterov lijianfei debug!!!!!!!!!!
I0929 16:32:16.355463 25496 solver.cpp:97] Initializing solver from parameters: 
train_net: "./train_ResNet_32.prototxt"
test_net: "./test_ResNet_32.prototxt"
test_iter: 1000
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "./model_save/cifar10_ResNet_32"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
stepvalue: 32000
stepvalue: 48000
iter_size: 1
type: "Nesterov"
I0929 16:32:16.355787 25496 solver.cpp:167] Creating training net from train_net file: ./train_ResNet_32.prototxt
I0929 16:32:16.357429 25496 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./train_ResNet_32.prototxt
I0929 16:32:16.357457 25496 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0929 16:32:16.358860 25496 net.cpp:82] Initializing net from parameters: 
name: "ResNet-32"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: true
    crop_size: 32
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "conv2_1_1"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv2_4_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv2_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4_bn0"
  type: "BatchNorm"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_4_scale0"
  type: "Scale"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_4_ReLU0"
  type: "ReLU"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
}
layer {
  name: "conv2_4_1"
  type: "Convolution"
  bottom: "conv2_4_0"
  top: "conv2_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4bn1"
  type: "BatchNorm"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_4_scale1"
  type: "Scale"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_4"
  type: "Eltwise"
  bottom: "conv2_Eltwise_3"
  bottom: "conv2_4_1"
  top: "conv2_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_4ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_4"
  top: "conv2_Eltwise_4"
}
layer {
  name: "conv2_5_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_4"
  top: "conv2_5_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_5_bn0"
  type: "BatchNorm"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_5_scale0"
  type: "Scale"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_5_ReLU0"
  type: "ReLU"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
}
layer {
  name: "conv2_5_1"
  type: "Convolution"
  bottom: "conv2_5_0"
  top: "conv2_5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_5bn1"
  type: "BatchNorm"
  bottom: "conv2_5_1"
  top: "conv2_5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_5_scale1"
  type: "Scale"
  bottom: "conv2_5_1"
  top: "conv2_5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_5"
  type: "Eltwise"
  bottom: "conv2_Eltwise_4"
  bottom: "conv2_5_1"
  top: "conv2_Eltwise_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_5ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_5"
  top: "conv2_Eltwise_5"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_5"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_5"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv3_4_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv3_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4_bn0"
  type: "BatchNorm"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_4_scale0"
  type: "Scale"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_ReLU0"
  type: "ReLU"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
}
layer {
  name: "conv3_4_1"
  type: "Convolution"
  bottom: "conv3_4_0"
  top: "conv3_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4bn1"
  type: "BatchNorm"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_4_scale1"
  type: "Scale"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_4"
  type: "Eltwise"
  bottom: "conv3_Eltwise_3"
  bottom: "conv3_4_1"
  top: "conv3_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_4ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_4"
  top: "conv3_Eltwise_4"
}
layer {
  name: "conv3_5_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_4"
  top: "conv3_5_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_5_bn0"
  type: "BatchNorm"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_5_scale0"
  type: "Scale"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_5_ReLU0"
  type: "ReLU"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
}
layer {
  name: "conv3_5_1"
  type: "Convolution"
  bottom: "conv3_5_0"
  top: "conv3_5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_5bn1"
  type: "BatchNorm"
  bottom: "conv3_5_1"
  top: "conv3_5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_5_scale1"
  type: "Scale"
  bottom: "conv3_5_1"
  top: "conv3_5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_5"
  type: "Eltwise"
  bottom: "conv3_Eltwise_4"
  bottom: "conv3_5_1"
  top: "conv3_Eltwise_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_5ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_5"
  top: "conv3_Eltwise_5"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_5"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_5"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "conv4_4_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_3"
  top: "conv4_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_4_bn0"
  type: "BatchNorm"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_4_scale0"
  type: "Scale"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  
I0929 16:32:16.360148 25496 layer_factory.hpp:77] Creating layer Data1
I0929 16:32:16.360383 25496 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/train_lmdb
I0929 16:32:16.360435 25496 net.cpp:128] Creating Layer Data1
I0929 16:32:16.360446 25496 net.cpp:522] Data1 -> data
I0929 16:32:16.360482 25496 net.cpp:522] Data1 -> label
I0929 16:32:16.362798 25496 data_layer.cpp:45] output data size: 128,3,32,32
I0929 16:32:16.379585 25496 net.cpp:172] Setting up Data1
I0929 16:32:16.379650 25496 net.cpp:186] Top shape: 128 3 32 32 (393216)
I0929 16:32:16.379657 25496 net.cpp:186] Top shape: 128 (128)
I0929 16:32:16.379662 25496 net.cpp:194] Memory required for data: 1573376
I0929 16:32:16.379678 25496 layer_factory.hpp:77] Creating layer conv1
I0929 16:32:16.379716 25496 net.cpp:128] Creating Layer conv1
I0929 16:32:16.379726 25496 net.cpp:558] conv1 <- data
I0929 16:32:16.379750 25496 net.cpp:522] conv1 -> conv1
I0929 16:32:17.409235 25496 net.cpp:172] Setting up conv1
I0929 16:32:17.409304 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.409309 25496 net.cpp:194] Memory required for data: 9961984
I0929 16:32:17.409354 25496 layer_factory.hpp:77] Creating layer conv1/bn
I0929 16:32:17.409380 25496 net.cpp:128] Creating Layer conv1/bn
I0929 16:32:17.409387 25496 net.cpp:558] conv1/bn <- conv1
I0929 16:32:17.409396 25496 net.cpp:509] conv1/bn -> conv1 (in-place)
I0929 16:32:17.409672 25496 net.cpp:172] Setting up conv1/bn
I0929 16:32:17.409685 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.409692 25496 net.cpp:194] Memory required for data: 18350592
I0929 16:32:17.409704 25496 layer_factory.hpp:77] Creating layer conv1/scale
I0929 16:32:17.409714 25496 net.cpp:128] Creating Layer conv1/scale
I0929 16:32:17.409719 25496 net.cpp:558] conv1/scale <- conv1
I0929 16:32:17.409724 25496 net.cpp:509] conv1/scale -> conv1 (in-place)
I0929 16:32:17.409772 25496 layer_factory.hpp:77] Creating layer conv1/scale
I0929 16:32:17.409974 25496 net.cpp:172] Setting up conv1/scale
I0929 16:32:17.410003 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.410017 25496 net.cpp:194] Memory required for data: 26739200
I0929 16:32:17.410037 25496 layer_factory.hpp:77] Creating layer conv1/ReLU
I0929 16:32:17.410055 25496 net.cpp:128] Creating Layer conv1/ReLU
I0929 16:32:17.410080 25496 net.cpp:558] conv1/ReLU <- conv1
I0929 16:32:17.410100 25496 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I0929 16:32:17.410979 25496 net.cpp:172] Setting up conv1/ReLU
I0929 16:32:17.410996 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.411001 25496 net.cpp:194] Memory required for data: 35127808
I0929 16:32:17.411006 25496 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I0929 16:32:17.411015 25496 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I0929 16:32:17.411018 25496 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I0929 16:32:17.411028 25496 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I0929 16:32:17.411037 25496 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I0929 16:32:17.411084 25496 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I0929 16:32:17.411123 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.411134 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.411139 25496 net.cpp:194] Memory required for data: 51905024
I0929 16:32:17.411142 25496 layer_factory.hpp:77] Creating layer conv2_1_0
I0929 16:32:17.411159 25496 net.cpp:128] Creating Layer conv2_1_0
I0929 16:32:17.411164 25496 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I0929 16:32:17.411173 25496 net.cpp:522] conv2_1_0 -> conv2_1_0
I0929 16:32:17.417695 25496 net.cpp:172] Setting up conv2_1_0
I0929 16:32:17.417721 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.417726 25496 net.cpp:194] Memory required for data: 60293632
I0929 16:32:17.417739 25496 layer_factory.hpp:77] Creating layer conv2_1_bn0
I0929 16:32:17.417752 25496 net.cpp:128] Creating Layer conv2_1_bn0
I0929 16:32:17.417757 25496 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I0929 16:32:17.417770 25496 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I0929 16:32:17.418015 25496 net.cpp:172] Setting up conv2_1_bn0
I0929 16:32:17.418030 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.418033 25496 net.cpp:194] Memory required for data: 68682240
I0929 16:32:17.418045 25496 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0929 16:32:17.418056 25496 net.cpp:128] Creating Layer conv2_1_scale0
I0929 16:32:17.418061 25496 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I0929 16:32:17.418066 25496 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I0929 16:32:17.418107 25496 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0929 16:32:17.418285 25496 net.cpp:172] Setting up conv2_1_scale0
I0929 16:32:17.418298 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.418303 25496 net.cpp:194] Memory required for data: 77070848
I0929 16:32:17.418313 25496 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I0929 16:32:17.418318 25496 net.cpp:128] Creating Layer conv2_1_ReLU0
I0929 16:32:17.418323 25496 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I0929 16:32:17.418331 25496 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I0929 16:32:17.419787 25496 net.cpp:172] Setting up conv2_1_ReLU0
I0929 16:32:17.419804 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.419808 25496 net.cpp:194] Memory required for data: 85459456
I0929 16:32:17.419828 25496 layer_factory.hpp:77] Creating layer conv2_1_1
I0929 16:32:17.419843 25496 net.cpp:128] Creating Layer conv2_1_1
I0929 16:32:17.419850 25496 net.cpp:558] conv2_1_1 <- conv2_1_0
I0929 16:32:17.419859 25496 net.cpp:522] conv2_1_1 -> conv2_1_1
I0929 16:32:17.426543 25496 net.cpp:172] Setting up conv2_1_1
I0929 16:32:17.426570 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.426574 25496 net.cpp:194] Memory required for data: 93848064
I0929 16:32:17.426584 25496 layer_factory.hpp:77] Creating layer conv2_1bn1
I0929 16:32:17.426595 25496 net.cpp:128] Creating Layer conv2_1bn1
I0929 16:32:17.426600 25496 net.cpp:558] conv2_1bn1 <- conv2_1_1
I0929 16:32:17.426607 25496 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I0929 16:32:17.426833 25496 net.cpp:172] Setting up conv2_1bn1
I0929 16:32:17.426846 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.426849 25496 net.cpp:194] Memory required for data: 102236672
I0929 16:32:17.426865 25496 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0929 16:32:17.426873 25496 net.cpp:128] Creating Layer conv2_1_scale1
I0929 16:32:17.426877 25496 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I0929 16:32:17.426884 25496 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I0929 16:32:17.426923 25496 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0929 16:32:17.427100 25496 net.cpp:172] Setting up conv2_1_scale1
I0929 16:32:17.427112 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.427119 25496 net.cpp:194] Memory required for data: 110625280
I0929 16:32:17.427127 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I0929 16:32:17.427136 25496 net.cpp:128] Creating Layer conv2_Eltwise_1
I0929 16:32:17.427140 25496 net.cpp:558] conv2_Eltwise_1 <- conv1_conv1/ReLU_0_split_1
I0929 16:32:17.427147 25496 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I0929 16:32:17.427155 25496 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I0929 16:32:17.427184 25496 net.cpp:172] Setting up conv2_Eltwise_1
I0929 16:32:17.427219 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.427227 25496 net.cpp:194] Memory required for data: 119013888
I0929 16:32:17.427232 25496 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I0929 16:32:17.427239 25496 net.cpp:128] Creating Layer conv2_1ReLU_1
I0929 16:32:17.427243 25496 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I0929 16:32:17.427251 25496 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I0929 16:32:17.428642 25496 net.cpp:172] Setting up conv2_1ReLU_1
I0929 16:32:17.428663 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.428666 25496 net.cpp:194] Memory required for data: 127402496
I0929 16:32:17.428673 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 16:32:17.428680 25496 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 16:32:17.428685 25496 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I0929 16:32:17.428694 25496 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0929 16:32:17.428709 25496 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0929 16:32:17.428761 25496 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 16:32:17.428768 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.428774 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.428778 25496 net.cpp:194] Memory required for data: 144179712
I0929 16:32:17.428782 25496 layer_factory.hpp:77] Creating layer conv2_2_0
I0929 16:32:17.428798 25496 net.cpp:128] Creating Layer conv2_2_0
I0929 16:32:17.428803 25496 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0929 16:32:17.428810 25496 net.cpp:522] conv2_2_0 -> conv2_2_0
I0929 16:32:17.435379 25496 net.cpp:172] Setting up conv2_2_0
I0929 16:32:17.435405 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.435408 25496 net.cpp:194] Memory required for data: 152568320
I0929 16:32:17.435434 25496 layer_factory.hpp:77] Creating layer conv2_2_bn0
I0929 16:32:17.435446 25496 net.cpp:128] Creating Layer conv2_2_bn0
I0929 16:32:17.435454 25496 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I0929 16:32:17.435465 25496 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I0929 16:32:17.435693 25496 net.cpp:172] Setting up conv2_2_bn0
I0929 16:32:17.435705 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.435710 25496 net.cpp:194] Memory required for data: 160956928
I0929 16:32:17.435720 25496 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0929 16:32:17.435729 25496 net.cpp:128] Creating Layer conv2_2_scale0
I0929 16:32:17.435734 25496 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I0929 16:32:17.435740 25496 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I0929 16:32:17.435775 25496 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0929 16:32:17.435921 25496 net.cpp:172] Setting up conv2_2_scale0
I0929 16:32:17.435945 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.435950 25496 net.cpp:194] Memory required for data: 169345536
I0929 16:32:17.435959 25496 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I0929 16:32:17.435997 25496 net.cpp:128] Creating Layer conv2_2_ReLU0
I0929 16:32:17.436015 25496 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I0929 16:32:17.436036 25496 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I0929 16:32:17.437463 25496 net.cpp:172] Setting up conv2_2_ReLU0
I0929 16:32:17.437477 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.437482 25496 net.cpp:194] Memory required for data: 177734144
I0929 16:32:17.437487 25496 layer_factory.hpp:77] Creating layer conv2_2_1
I0929 16:32:17.437505 25496 net.cpp:128] Creating Layer conv2_2_1
I0929 16:32:17.437510 25496 net.cpp:558] conv2_2_1 <- conv2_2_0
I0929 16:32:17.437518 25496 net.cpp:522] conv2_2_1 -> conv2_2_1
I0929 16:32:17.444188 25496 net.cpp:172] Setting up conv2_2_1
I0929 16:32:17.444214 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.444218 25496 net.cpp:194] Memory required for data: 186122752
I0929 16:32:17.444228 25496 layer_factory.hpp:77] Creating layer conv2_2bn1
I0929 16:32:17.444241 25496 net.cpp:128] Creating Layer conv2_2bn1
I0929 16:32:17.444245 25496 net.cpp:558] conv2_2bn1 <- conv2_2_1
I0929 16:32:17.444253 25496 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I0929 16:32:17.444494 25496 net.cpp:172] Setting up conv2_2bn1
I0929 16:32:17.444505 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.444509 25496 net.cpp:194] Memory required for data: 194511360
I0929 16:32:17.444525 25496 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0929 16:32:17.444531 25496 net.cpp:128] Creating Layer conv2_2_scale1
I0929 16:32:17.444535 25496 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I0929 16:32:17.444541 25496 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I0929 16:32:17.444581 25496 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0929 16:32:17.444764 25496 net.cpp:172] Setting up conv2_2_scale1
I0929 16:32:17.444777 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.444782 25496 net.cpp:194] Memory required for data: 202899968
I0929 16:32:17.444790 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I0929 16:32:17.444799 25496 net.cpp:128] Creating Layer conv2_Eltwise_2
I0929 16:32:17.444804 25496 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0929 16:32:17.444809 25496 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I0929 16:32:17.444816 25496 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I0929 16:32:17.444842 25496 net.cpp:172] Setting up conv2_Eltwise_2
I0929 16:32:17.444849 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.444854 25496 net.cpp:194] Memory required for data: 211288576
I0929 16:32:17.444857 25496 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I0929 16:32:17.444864 25496 net.cpp:128] Creating Layer conv2_2ReLU_1
I0929 16:32:17.444867 25496 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I0929 16:32:17.444875 25496 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I0929 16:32:17.446290 25496 net.cpp:172] Setting up conv2_2ReLU_1
I0929 16:32:17.446307 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.446312 25496 net.cpp:194] Memory required for data: 219677184
I0929 16:32:17.446317 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 16:32:17.446324 25496 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 16:32:17.446334 25496 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I0929 16:32:17.446343 25496 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0929 16:32:17.446352 25496 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0929 16:32:17.446403 25496 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 16:32:17.446409 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.446415 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.446419 25496 net.cpp:194] Memory required for data: 236454400
I0929 16:32:17.446424 25496 layer_factory.hpp:77] Creating layer conv2_3_0
I0929 16:32:17.446436 25496 net.cpp:128] Creating Layer conv2_3_0
I0929 16:32:17.446441 25496 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0929 16:32:17.446450 25496 net.cpp:522] conv2_3_0 -> conv2_3_0
I0929 16:32:17.453014 25496 net.cpp:172] Setting up conv2_3_0
I0929 16:32:17.453042 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.453045 25496 net.cpp:194] Memory required for data: 244843008
I0929 16:32:17.453055 25496 layer_factory.hpp:77] Creating layer conv2_3_bn0
I0929 16:32:17.453068 25496 net.cpp:128] Creating Layer conv2_3_bn0
I0929 16:32:17.453073 25496 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I0929 16:32:17.453080 25496 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I0929 16:32:17.453316 25496 net.cpp:172] Setting up conv2_3_bn0
I0929 16:32:17.453364 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.453378 25496 net.cpp:194] Memory required for data: 253231616
I0929 16:32:17.453398 25496 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0929 16:32:17.453415 25496 net.cpp:128] Creating Layer conv2_3_scale0
I0929 16:32:17.453429 25496 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I0929 16:32:17.453444 25496 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I0929 16:32:17.453505 25496 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0929 16:32:17.453660 25496 net.cpp:172] Setting up conv2_3_scale0
I0929 16:32:17.453672 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.453677 25496 net.cpp:194] Memory required for data: 261620224
I0929 16:32:17.453685 25496 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I0929 16:32:17.453696 25496 net.cpp:128] Creating Layer conv2_3_ReLU0
I0929 16:32:17.453699 25496 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I0929 16:32:17.453706 25496 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I0929 16:32:17.455106 25496 net.cpp:172] Setting up conv2_3_ReLU0
I0929 16:32:17.455132 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.455138 25496 net.cpp:194] Memory required for data: 270008832
I0929 16:32:17.455144 25496 layer_factory.hpp:77] Creating layer conv2_3_1
I0929 16:32:17.455158 25496 net.cpp:128] Creating Layer conv2_3_1
I0929 16:32:17.455163 25496 net.cpp:558] conv2_3_1 <- conv2_3_0
I0929 16:32:17.455173 25496 net.cpp:522] conv2_3_1 -> conv2_3_1
I0929 16:32:17.461858 25496 net.cpp:172] Setting up conv2_3_1
I0929 16:32:17.461887 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.461892 25496 net.cpp:194] Memory required for data: 278397440
I0929 16:32:17.461905 25496 layer_factory.hpp:77] Creating layer conv2_3bn1
I0929 16:32:17.461912 25496 net.cpp:128] Creating Layer conv2_3bn1
I0929 16:32:17.461921 25496 net.cpp:558] conv2_3bn1 <- conv2_3_1
I0929 16:32:17.461947 25496 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I0929 16:32:17.462193 25496 net.cpp:172] Setting up conv2_3bn1
I0929 16:32:17.462218 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.462224 25496 net.cpp:194] Memory required for data: 286786048
I0929 16:32:17.462234 25496 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0929 16:32:17.462245 25496 net.cpp:128] Creating Layer conv2_3_scale1
I0929 16:32:17.462250 25496 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I0929 16:32:17.462256 25496 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I0929 16:32:17.462297 25496 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0929 16:32:17.462440 25496 net.cpp:172] Setting up conv2_3_scale1
I0929 16:32:17.462451 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.462455 25496 net.cpp:194] Memory required for data: 295174656
I0929 16:32:17.462463 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I0929 16:32:17.462471 25496 net.cpp:128] Creating Layer conv2_Eltwise_3
I0929 16:32:17.462476 25496 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0929 16:32:17.462489 25496 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I0929 16:32:17.462497 25496 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I0929 16:32:17.462528 25496 net.cpp:172] Setting up conv2_Eltwise_3
I0929 16:32:17.462538 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.462543 25496 net.cpp:194] Memory required for data: 303563264
I0929 16:32:17.462548 25496 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I0929 16:32:17.462553 25496 net.cpp:128] Creating Layer conv2_3ReLU_1
I0929 16:32:17.462558 25496 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I0929 16:32:17.462563 25496 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I0929 16:32:17.463944 25496 net.cpp:172] Setting up conv2_3ReLU_1
I0929 16:32:17.463963 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.463968 25496 net.cpp:194] Memory required for data: 311951872
I0929 16:32:17.463973 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 16:32:17.463982 25496 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 16:32:17.463987 25496 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I0929 16:32:17.463996 25496 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0929 16:32:17.464004 25496 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0929 16:32:17.464051 25496 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 16:32:17.464057 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.464063 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.464067 25496 net.cpp:194] Memory required for data: 328729088
I0929 16:32:17.464071 25496 layer_factory.hpp:77] Creating layer conv2_4_0
I0929 16:32:17.464085 25496 net.cpp:128] Creating Layer conv2_4_0
I0929 16:32:17.464090 25496 net.cpp:558] conv2_4_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0929 16:32:17.464098 25496 net.cpp:522] conv2_4_0 -> conv2_4_0
I0929 16:32:17.470693 25496 net.cpp:172] Setting up conv2_4_0
I0929 16:32:17.470721 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.470724 25496 net.cpp:194] Memory required for data: 337117696
I0929 16:32:17.470734 25496 layer_factory.hpp:77] Creating layer conv2_4_bn0
I0929 16:32:17.470746 25496 net.cpp:128] Creating Layer conv2_4_bn0
I0929 16:32:17.470752 25496 net.cpp:558] conv2_4_bn0 <- conv2_4_0
I0929 16:32:17.470760 25496 net.cpp:509] conv2_4_bn0 -> conv2_4_0 (in-place)
I0929 16:32:17.470998 25496 net.cpp:172] Setting up conv2_4_bn0
I0929 16:32:17.471011 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.471015 25496 net.cpp:194] Memory required for data: 345506304
I0929 16:32:17.471026 25496 layer_factory.hpp:77] Creating layer conv2_4_scale0
I0929 16:32:17.471035 25496 net.cpp:128] Creating Layer conv2_4_scale0
I0929 16:32:17.471040 25496 net.cpp:558] conv2_4_scale0 <- conv2_4_0
I0929 16:32:17.471046 25496 net.cpp:509] conv2_4_scale0 -> conv2_4_0 (in-place)
I0929 16:32:17.471086 25496 layer_factory.hpp:77] Creating layer conv2_4_scale0
I0929 16:32:17.471235 25496 net.cpp:172] Setting up conv2_4_scale0
I0929 16:32:17.471257 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.471261 25496 net.cpp:194] Memory required for data: 353894912
I0929 16:32:17.471269 25496 layer_factory.hpp:77] Creating layer conv2_4_ReLU0
I0929 16:32:17.471276 25496 net.cpp:128] Creating Layer conv2_4_ReLU0
I0929 16:32:17.471279 25496 net.cpp:558] conv2_4_ReLU0 <- conv2_4_0
I0929 16:32:17.471288 25496 net.cpp:509] conv2_4_ReLU0 -> conv2_4_0 (in-place)
I0929 16:32:17.472781 25496 net.cpp:172] Setting up conv2_4_ReLU0
I0929 16:32:17.472795 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.472800 25496 net.cpp:194] Memory required for data: 362283520
I0929 16:32:17.472805 25496 layer_factory.hpp:77] Creating layer conv2_4_1
I0929 16:32:17.472822 25496 net.cpp:128] Creating Layer conv2_4_1
I0929 16:32:17.472827 25496 net.cpp:558] conv2_4_1 <- conv2_4_0
I0929 16:32:17.472837 25496 net.cpp:522] conv2_4_1 -> conv2_4_1
I0929 16:32:17.479521 25496 net.cpp:172] Setting up conv2_4_1
I0929 16:32:17.479549 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.479553 25496 net.cpp:194] Memory required for data: 370672128
I0929 16:32:17.479563 25496 layer_factory.hpp:77] Creating layer conv2_4bn1
I0929 16:32:17.479573 25496 net.cpp:128] Creating Layer conv2_4bn1
I0929 16:32:17.479576 25496 net.cpp:558] conv2_4bn1 <- conv2_4_1
I0929 16:32:17.479585 25496 net.cpp:509] conv2_4bn1 -> conv2_4_1 (in-place)
I0929 16:32:17.479828 25496 net.cpp:172] Setting up conv2_4bn1
I0929 16:32:17.479872 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.479887 25496 net.cpp:194] Memory required for data: 379060736
I0929 16:32:17.479907 25496 layer_factory.hpp:77] Creating layer conv2_4_scale1
I0929 16:32:17.479923 25496 net.cpp:128] Creating Layer conv2_4_scale1
I0929 16:32:17.479936 25496 net.cpp:558] conv2_4_scale1 <- conv2_4_1
I0929 16:32:17.479954 25496 net.cpp:509] conv2_4_scale1 -> conv2_4_1 (in-place)
I0929 16:32:17.480005 25496 layer_factory.hpp:77] Creating layer conv2_4_scale1
I0929 16:32:17.480136 25496 net.cpp:172] Setting up conv2_4_scale1
I0929 16:32:17.480149 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.480154 25496 net.cpp:194] Memory required for data: 387449344
I0929 16:32:17.480161 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_4
I0929 16:32:17.480171 25496 net.cpp:128] Creating Layer conv2_Eltwise_4
I0929 16:32:17.480175 25496 net.cpp:558] conv2_Eltwise_4 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0929 16:32:17.480180 25496 net.cpp:558] conv2_Eltwise_4 <- conv2_4_1
I0929 16:32:17.480186 25496 net.cpp:522] conv2_Eltwise_4 -> conv2_Eltwise_4
I0929 16:32:17.480213 25496 net.cpp:172] Setting up conv2_Eltwise_4
I0929 16:32:17.480221 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.480224 25496 net.cpp:194] Memory required for data: 395837952
I0929 16:32:17.480228 25496 layer_factory.hpp:77] Creating layer conv2_4ReLU_1
I0929 16:32:17.480235 25496 net.cpp:128] Creating Layer conv2_4ReLU_1
I0929 16:32:17.480239 25496 net.cpp:558] conv2_4ReLU_1 <- conv2_Eltwise_4
I0929 16:32:17.480247 25496 net.cpp:509] conv2_4ReLU_1 -> conv2_Eltwise_4 (in-place)
I0929 16:32:17.481606 25496 net.cpp:172] Setting up conv2_4ReLU_1
I0929 16:32:17.481621 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.481626 25496 net.cpp:194] Memory required for data: 404226560
I0929 16:32:17.481631 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0929 16:32:17.481637 25496 net.cpp:128] Creating Layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0929 16:32:17.481642 25496 net.cpp:558] conv2_Eltwise_4_conv2_4ReLU_1_0_split <- conv2_Eltwise_4
I0929 16:32:17.481652 25496 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I0929 16:32:17.481660 25496 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I0929 16:32:17.481707 25496 net.cpp:172] Setting up conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0929 16:32:17.481729 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.481734 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.481739 25496 net.cpp:194] Memory required for data: 421003776
I0929 16:32:17.481743 25496 layer_factory.hpp:77] Creating layer conv2_5_0
I0929 16:32:17.481756 25496 net.cpp:128] Creating Layer conv2_5_0
I0929 16:32:17.481760 25496 net.cpp:558] conv2_5_0 <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I0929 16:32:17.481771 25496 net.cpp:522] conv2_5_0 -> conv2_5_0
I0929 16:32:17.485497 25496 net.cpp:172] Setting up conv2_5_0
I0929 16:32:17.485527 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.485532 25496 net.cpp:194] Memory required for data: 429392384
I0929 16:32:17.485555 25496 layer_factory.hpp:77] Creating layer conv2_5_bn0
I0929 16:32:17.485607 25496 net.cpp:128] Creating Layer conv2_5_bn0
I0929 16:32:17.485627 25496 net.cpp:558] conv2_5_bn0 <- conv2_5_0
I0929 16:32:17.485651 25496 net.cpp:509] conv2_5_bn0 -> conv2_5_0 (in-place)
I0929 16:32:17.485915 25496 net.cpp:172] Setting up conv2_5_bn0
I0929 16:32:17.485929 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.485941 25496 net.cpp:194] Memory required for data: 437780992
I0929 16:32:17.485952 25496 layer_factory.hpp:77] Creating layer conv2_5_scale0
I0929 16:32:17.485962 25496 net.cpp:128] Creating Layer conv2_5_scale0
I0929 16:32:17.485967 25496 net.cpp:558] conv2_5_scale0 <- conv2_5_0
I0929 16:32:17.485973 25496 net.cpp:509] conv2_5_scale0 -> conv2_5_0 (in-place)
I0929 16:32:17.486012 25496 layer_factory.hpp:77] Creating layer conv2_5_scale0
I0929 16:32:17.486155 25496 net.cpp:172] Setting up conv2_5_scale0
I0929 16:32:17.486166 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.486169 25496 net.cpp:194] Memory required for data: 446169600
I0929 16:32:17.486176 25496 layer_factory.hpp:77] Creating layer conv2_5_ReLU0
I0929 16:32:17.486183 25496 net.cpp:128] Creating Layer conv2_5_ReLU0
I0929 16:32:17.486187 25496 net.cpp:558] conv2_5_ReLU0 <- conv2_5_0
I0929 16:32:17.486192 25496 net.cpp:509] conv2_5_ReLU0 -> conv2_5_0 (in-place)
I0929 16:32:17.487481 25496 net.cpp:172] Setting up conv2_5_ReLU0
I0929 16:32:17.487507 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.487512 25496 net.cpp:194] Memory required for data: 454558208
I0929 16:32:17.487517 25496 layer_factory.hpp:77] Creating layer conv2_5_1
I0929 16:32:17.487534 25496 net.cpp:128] Creating Layer conv2_5_1
I0929 16:32:17.487540 25496 net.cpp:558] conv2_5_1 <- conv2_5_0
I0929 16:32:17.487547 25496 net.cpp:522] conv2_5_1 -> conv2_5_1
I0929 16:32:17.494238 25496 net.cpp:172] Setting up conv2_5_1
I0929 16:32:17.494261 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.494264 25496 net.cpp:194] Memory required for data: 462946816
I0929 16:32:17.494274 25496 layer_factory.hpp:77] Creating layer conv2_5bn1
I0929 16:32:17.494287 25496 net.cpp:128] Creating Layer conv2_5bn1
I0929 16:32:17.494292 25496 net.cpp:558] conv2_5bn1 <- conv2_5_1
I0929 16:32:17.494302 25496 net.cpp:509] conv2_5bn1 -> conv2_5_1 (in-place)
I0929 16:32:17.494549 25496 net.cpp:172] Setting up conv2_5bn1
I0929 16:32:17.494562 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.494566 25496 net.cpp:194] Memory required for data: 471335424
I0929 16:32:17.494576 25496 layer_factory.hpp:77] Creating layer conv2_5_scale1
I0929 16:32:17.494585 25496 net.cpp:128] Creating Layer conv2_5_scale1
I0929 16:32:17.494591 25496 net.cpp:558] conv2_5_scale1 <- conv2_5_1
I0929 16:32:17.494597 25496 net.cpp:509] conv2_5_scale1 -> conv2_5_1 (in-place)
I0929 16:32:17.494637 25496 layer_factory.hpp:77] Creating layer conv2_5_scale1
I0929 16:32:17.494786 25496 net.cpp:172] Setting up conv2_5_scale1
I0929 16:32:17.494798 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.494803 25496 net.cpp:194] Memory required for data: 479724032
I0929 16:32:17.494810 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_5
I0929 16:32:17.494818 25496 net.cpp:128] Creating Layer conv2_Eltwise_5
I0929 16:32:17.494845 25496 net.cpp:558] conv2_Eltwise_5 <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I0929 16:32:17.494853 25496 net.cpp:558] conv2_Eltwise_5 <- conv2_5_1
I0929 16:32:17.494861 25496 net.cpp:522] conv2_Eltwise_5 -> conv2_Eltwise_5
I0929 16:32:17.494891 25496 net.cpp:172] Setting up conv2_Eltwise_5
I0929 16:32:17.494902 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.494907 25496 net.cpp:194] Memory required for data: 488112640
I0929 16:32:17.494911 25496 layer_factory.hpp:77] Creating layer conv2_5ReLU_1
I0929 16:32:17.494917 25496 net.cpp:128] Creating Layer conv2_5ReLU_1
I0929 16:32:17.494922 25496 net.cpp:558] conv2_5ReLU_1 <- conv2_Eltwise_5
I0929 16:32:17.494927 25496 net.cpp:509] conv2_5ReLU_1 -> conv2_Eltwise_5 (in-place)
I0929 16:32:17.496311 25496 net.cpp:172] Setting up conv2_5ReLU_1
I0929 16:32:17.496325 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.496330 25496 net.cpp:194] Memory required for data: 496501248
I0929 16:32:17.496333 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0929 16:32:17.496340 25496 net.cpp:128] Creating Layer conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0929 16:32:17.496345 25496 net.cpp:558] conv2_Eltwise_5_conv2_5ReLU_1_0_split <- conv2_Eltwise_5
I0929 16:32:17.496353 25496 net.cpp:522] conv2_Eltwise_5_conv2_5ReLU_1_0_split -> conv2_Eltwise_5_conv2_5ReLU_1_0_split_0
I0929 16:32:17.496362 25496 net.cpp:522] conv2_Eltwise_5_conv2_5ReLU_1_0_split -> conv2_Eltwise_5_conv2_5ReLU_1_0_split_1
I0929 16:32:17.496408 25496 net.cpp:172] Setting up conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0929 16:32:17.496415 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.496421 25496 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0929 16:32:17.496425 25496 net.cpp:194] Memory required for data: 513278464
I0929 16:32:17.496429 25496 layer_factory.hpp:77] Creating layer conv3_1_0
I0929 16:32:17.496444 25496 net.cpp:128] Creating Layer conv3_1_0
I0929 16:32:17.496449 25496 net.cpp:558] conv3_1_0 <- conv2_Eltwise_5_conv2_5ReLU_1_0_split_0
I0929 16:32:17.496460 25496 net.cpp:522] conv3_1_0 -> conv3_1_0
I0929 16:32:17.503276 25496 net.cpp:172] Setting up conv3_1_0
I0929 16:32:17.503305 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.503310 25496 net.cpp:194] Memory required for data: 517472768
I0929 16:32:17.503324 25496 layer_factory.hpp:77] Creating layer conv3_1_bn0
I0929 16:32:17.503357 25496 net.cpp:128] Creating Layer conv3_1_bn0
I0929 16:32:17.503366 25496 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I0929 16:32:17.503374 25496 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I0929 16:32:17.503638 25496 net.cpp:172] Setting up conv3_1_bn0
I0929 16:32:17.503649 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.503654 25496 net.cpp:194] Memory required for data: 521667072
I0929 16:32:17.503664 25496 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0929 16:32:17.503675 25496 net.cpp:128] Creating Layer conv3_1_scale0
I0929 16:32:17.503684 25496 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I0929 16:32:17.503690 25496 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I0929 16:32:17.503736 25496 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0929 16:32:17.503890 25496 net.cpp:172] Setting up conv3_1_scale0
I0929 16:32:17.503901 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.503906 25496 net.cpp:194] Memory required for data: 525861376
I0929 16:32:17.503913 25496 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I0929 16:32:17.503923 25496 net.cpp:128] Creating Layer conv3_1_ReLU0
I0929 16:32:17.503928 25496 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I0929 16:32:17.503937 25496 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I0929 16:32:17.505167 25496 net.cpp:172] Setting up conv3_1_ReLU0
I0929 16:32:17.505180 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.505185 25496 net.cpp:194] Memory required for data: 530055680
I0929 16:32:17.505190 25496 layer_factory.hpp:77] Creating layer conv3_1_1
I0929 16:32:17.505226 25496 net.cpp:128] Creating Layer conv3_1_1
I0929 16:32:17.505234 25496 net.cpp:558] conv3_1_1 <- conv3_1_0
I0929 16:32:17.505245 25496 net.cpp:522] conv3_1_1 -> conv3_1_1
I0929 16:32:17.511937 25496 net.cpp:172] Setting up conv3_1_1
I0929 16:32:17.511976 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.511981 25496 net.cpp:194] Memory required for data: 534249984
I0929 16:32:17.511994 25496 layer_factory.hpp:77] Creating layer conv3_1bn1
I0929 16:32:17.512010 25496 net.cpp:128] Creating Layer conv3_1bn1
I0929 16:32:17.512019 25496 net.cpp:558] conv3_1bn1 <- conv3_1_1
I0929 16:32:17.512030 25496 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I0929 16:32:17.512280 25496 net.cpp:172] Setting up conv3_1bn1
I0929 16:32:17.512292 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.512297 25496 net.cpp:194] Memory required for data: 538444288
I0929 16:32:17.512308 25496 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0929 16:32:17.512326 25496 net.cpp:128] Creating Layer conv3_1_scale1
I0929 16:32:17.512334 25496 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I0929 16:32:17.512341 25496 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I0929 16:32:17.512382 25496 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0929 16:32:17.512531 25496 net.cpp:172] Setting up conv3_1_scale1
I0929 16:32:17.512542 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.512547 25496 net.cpp:194] Memory required for data: 542638592
I0929 16:32:17.512554 25496 layer_factory.hpp:77] Creating layer conv3_1_down
I0929 16:32:17.512573 25496 net.cpp:128] Creating Layer conv3_1_down
I0929 16:32:17.512583 25496 net.cpp:558] conv3_1_down <- conv2_Eltwise_5_conv2_5ReLU_1_0_split_1
I0929 16:32:17.512593 25496 net.cpp:522] conv3_1_down -> conv3_1_down
I0929 16:32:17.518503 25496 net.cpp:172] Setting up conv3_1_down
I0929 16:32:17.518530 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.518535 25496 net.cpp:194] Memory required for data: 546832896
I0929 16:32:17.518546 25496 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I0929 16:32:17.518571 25496 net.cpp:128] Creating Layer conv3_1_bn_down
I0929 16:32:17.518581 25496 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I0929 16:32:17.518589 25496 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I0929 16:32:17.518828 25496 net.cpp:172] Setting up conv3_1_bn_down
I0929 16:32:17.518841 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.518844 25496 net.cpp:194] Memory required for data: 551027200
I0929 16:32:17.518856 25496 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0929 16:32:17.518870 25496 net.cpp:128] Creating Layer conv3_1_scale_down
I0929 16:32:17.518880 25496 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I0929 16:32:17.518887 25496 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I0929 16:32:17.518925 25496 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0929 16:32:17.519062 25496 net.cpp:172] Setting up conv3_1_scale_down
I0929 16:32:17.519073 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.519078 25496 net.cpp:194] Memory required for data: 555221504
I0929 16:32:17.519086 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I0929 16:32:17.519095 25496 net.cpp:128] Creating Layer conv3_Eltwise_1
I0929 16:32:17.519099 25496 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I0929 16:32:17.519105 25496 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I0929 16:32:17.519114 25496 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I0929 16:32:17.519136 25496 net.cpp:172] Setting up conv3_Eltwise_1
I0929 16:32:17.519148 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.519152 25496 net.cpp:194] Memory required for data: 559415808
I0929 16:32:17.519157 25496 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I0929 16:32:17.519165 25496 net.cpp:128] Creating Layer conv3_1ReLU_1
I0929 16:32:17.519168 25496 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I0929 16:32:17.519173 25496 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I0929 16:32:17.520579 25496 net.cpp:172] Setting up conv3_1ReLU_1
I0929 16:32:17.520602 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.520607 25496 net.cpp:194] Memory required for data: 563610112
I0929 16:32:17.520612 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 16:32:17.520623 25496 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 16:32:17.520628 25496 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I0929 16:32:17.520637 25496 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0929 16:32:17.520648 25496 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0929 16:32:17.520699 25496 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 16:32:17.520709 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.520715 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.520720 25496 net.cpp:194] Memory required for data: 571998720
I0929 16:32:17.520723 25496 layer_factory.hpp:77] Creating layer conv3_2_0
I0929 16:32:17.520736 25496 net.cpp:128] Creating Layer conv3_2_0
I0929 16:32:17.520741 25496 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0929 16:32:17.520750 25496 net.cpp:522] conv3_2_0 -> conv3_2_0
I0929 16:32:17.527336 25496 net.cpp:172] Setting up conv3_2_0
I0929 16:32:17.527370 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.527375 25496 net.cpp:194] Memory required for data: 576193024
I0929 16:32:17.527389 25496 layer_factory.hpp:77] Creating layer conv3_2_bn0
I0929 16:32:17.527403 25496 net.cpp:128] Creating Layer conv3_2_bn0
I0929 16:32:17.527413 25496 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I0929 16:32:17.527423 25496 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I0929 16:32:17.527675 25496 net.cpp:172] Setting up conv3_2_bn0
I0929 16:32:17.527688 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.527691 25496 net.cpp:194] Memory required for data: 580387328
I0929 16:32:17.527703 25496 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0929 16:32:17.527714 25496 net.cpp:128] Creating Layer conv3_2_scale0
I0929 16:32:17.527719 25496 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I0929 16:32:17.527724 25496 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I0929 16:32:17.527770 25496 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0929 16:32:17.527910 25496 net.cpp:172] Setting up conv3_2_scale0
I0929 16:32:17.527925 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.527928 25496 net.cpp:194] Memory required for data: 584581632
I0929 16:32:17.527935 25496 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I0929 16:32:17.527946 25496 net.cpp:128] Creating Layer conv3_2_ReLU0
I0929 16:32:17.527951 25496 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I0929 16:32:17.527958 25496 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I0929 16:32:17.529390 25496 net.cpp:172] Setting up conv3_2_ReLU0
I0929 16:32:17.529407 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.529412 25496 net.cpp:194] Memory required for data: 588775936
I0929 16:32:17.529417 25496 layer_factory.hpp:77] Creating layer conv3_2_1
I0929 16:32:17.529430 25496 net.cpp:128] Creating Layer conv3_2_1
I0929 16:32:17.529435 25496 net.cpp:558] conv3_2_1 <- conv3_2_0
I0929 16:32:17.529445 25496 net.cpp:522] conv3_2_1 -> conv3_2_1
I0929 16:32:17.536149 25496 net.cpp:172] Setting up conv3_2_1
I0929 16:32:17.536178 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.536183 25496 net.cpp:194] Memory required for data: 592970240
I0929 16:32:17.536193 25496 layer_factory.hpp:77] Creating layer conv3_2bn1
I0929 16:32:17.536206 25496 net.cpp:128] Creating Layer conv3_2bn1
I0929 16:32:17.536252 25496 net.cpp:558] conv3_2bn1 <- conv3_2_1
I0929 16:32:17.536267 25496 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I0929 16:32:17.536520 25496 net.cpp:172] Setting up conv3_2bn1
I0929 16:32:17.536548 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.536569 25496 net.cpp:194] Memory required for data: 597164544
I0929 16:32:17.536581 25496 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0929 16:32:17.536594 25496 net.cpp:128] Creating Layer conv3_2_scale1
I0929 16:32:17.536602 25496 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I0929 16:32:17.536607 25496 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I0929 16:32:17.536655 25496 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0929 16:32:17.536798 25496 net.cpp:172] Setting up conv3_2_scale1
I0929 16:32:17.536808 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.536811 25496 net.cpp:194] Memory required for data: 601358848
I0929 16:32:17.536820 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I0929 16:32:17.536833 25496 net.cpp:128] Creating Layer conv3_Eltwise_2
I0929 16:32:17.536839 25496 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0929 16:32:17.536845 25496 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I0929 16:32:17.536856 25496 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I0929 16:32:17.536911 25496 net.cpp:172] Setting up conv3_Eltwise_2
I0929 16:32:17.536923 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.536928 25496 net.cpp:194] Memory required for data: 605553152
I0929 16:32:17.536932 25496 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I0929 16:32:17.536957 25496 net.cpp:128] Creating Layer conv3_2ReLU_1
I0929 16:32:17.536965 25496 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I0929 16:32:17.536972 25496 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I0929 16:32:17.538444 25496 net.cpp:172] Setting up conv3_2ReLU_1
I0929 16:32:17.538468 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.538472 25496 net.cpp:194] Memory required for data: 609747456
I0929 16:32:17.538478 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 16:32:17.538489 25496 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 16:32:17.538496 25496 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I0929 16:32:17.538504 25496 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0929 16:32:17.538513 25496 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0929 16:32:17.538568 25496 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 16:32:17.538610 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.538627 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.538640 25496 net.cpp:194] Memory required for data: 618136064
I0929 16:32:17.538653 25496 layer_factory.hpp:77] Creating layer conv3_3_0
I0929 16:32:17.538676 25496 net.cpp:128] Creating Layer conv3_3_0
I0929 16:32:17.538691 25496 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0929 16:32:17.538709 25496 net.cpp:522] conv3_3_0 -> conv3_3_0
I0929 16:32:17.545055 25496 net.cpp:172] Setting up conv3_3_0
I0929 16:32:17.545096 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.545101 25496 net.cpp:194] Memory required for data: 622330368
I0929 16:32:17.545114 25496 layer_factory.hpp:77] Creating layer conv3_3_bn0
I0929 16:32:17.545127 25496 net.cpp:128] Creating Layer conv3_3_bn0
I0929 16:32:17.545171 25496 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I0929 16:32:17.545203 25496 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I0929 16:32:17.545478 25496 net.cpp:172] Setting up conv3_3_bn0
I0929 16:32:17.545490 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.545495 25496 net.cpp:194] Memory required for data: 626524672
I0929 16:32:17.545506 25496 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0929 16:32:17.545536 25496 net.cpp:128] Creating Layer conv3_3_scale0
I0929 16:32:17.545548 25496 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I0929 16:32:17.545567 25496 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I0929 16:32:17.545627 25496 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0929 16:32:17.545800 25496 net.cpp:172] Setting up conv3_3_scale0
I0929 16:32:17.545812 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.545817 25496 net.cpp:194] Memory required for data: 630718976
I0929 16:32:17.545825 25496 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I0929 16:32:17.545853 25496 net.cpp:128] Creating Layer conv3_3_ReLU0
I0929 16:32:17.545867 25496 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I0929 16:32:17.545886 25496 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I0929 16:32:17.547065 25496 net.cpp:172] Setting up conv3_3_ReLU0
I0929 16:32:17.547091 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.547096 25496 net.cpp:194] Memory required for data: 634913280
I0929 16:32:17.547101 25496 layer_factory.hpp:77] Creating layer conv3_3_1
I0929 16:32:17.547118 25496 net.cpp:128] Creating Layer conv3_3_1
I0929 16:32:17.547152 25496 net.cpp:558] conv3_3_1 <- conv3_3_0
I0929 16:32:17.547173 25496 net.cpp:522] conv3_3_1 -> conv3_3_1
I0929 16:32:17.550303 25496 net.cpp:172] Setting up conv3_3_1
I0929 16:32:17.550348 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.550365 25496 net.cpp:194] Memory required for data: 639107584
I0929 16:32:17.550386 25496 layer_factory.hpp:77] Creating layer conv3_3bn1
I0929 16:32:17.550407 25496 net.cpp:128] Creating Layer conv3_3bn1
I0929 16:32:17.550421 25496 net.cpp:558] conv3_3bn1 <- conv3_3_1
I0929 16:32:17.550437 25496 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I0929 16:32:17.550706 25496 net.cpp:172] Setting up conv3_3bn1
I0929 16:32:17.550729 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.550741 25496 net.cpp:194] Memory required for data: 643301888
I0929 16:32:17.550761 25496 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0929 16:32:17.550781 25496 net.cpp:128] Creating Layer conv3_3_scale1
I0929 16:32:17.550794 25496 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I0929 16:32:17.550812 25496 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I0929 16:32:17.550868 25496 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0929 16:32:17.551020 25496 net.cpp:172] Setting up conv3_3_scale1
I0929 16:32:17.551045 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.551059 25496 net.cpp:194] Memory required for data: 647496192
I0929 16:32:17.551076 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I0929 16:32:17.551095 25496 net.cpp:128] Creating Layer conv3_Eltwise_3
I0929 16:32:17.551103 25496 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0929 16:32:17.551110 25496 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I0929 16:32:17.551115 25496 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I0929 16:32:17.551146 25496 net.cpp:172] Setting up conv3_Eltwise_3
I0929 16:32:17.551154 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.551160 25496 net.cpp:194] Memory required for data: 651690496
I0929 16:32:17.551164 25496 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I0929 16:32:17.551172 25496 net.cpp:128] Creating Layer conv3_3ReLU_1
I0929 16:32:17.551179 25496 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I0929 16:32:17.551187 25496 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I0929 16:32:17.551429 25496 net.cpp:172] Setting up conv3_3ReLU_1
I0929 16:32:17.551442 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.551446 25496 net.cpp:194] Memory required for data: 655884800
I0929 16:32:17.551455 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 16:32:17.551462 25496 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 16:32:17.551467 25496 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I0929 16:32:17.551476 25496 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0929 16:32:17.551487 25496 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0929 16:32:17.551539 25496 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 16:32:17.551548 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.551571 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.551578 25496 net.cpp:194] Memory required for data: 664273408
I0929 16:32:17.551584 25496 layer_factory.hpp:77] Creating layer conv3_4_0
I0929 16:32:17.551599 25496 net.cpp:128] Creating Layer conv3_4_0
I0929 16:32:17.551606 25496 net.cpp:558] conv3_4_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0929 16:32:17.551615 25496 net.cpp:522] conv3_4_0 -> conv3_4_0
I0929 16:32:17.553192 25496 net.cpp:172] Setting up conv3_4_0
I0929 16:32:17.553218 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.553222 25496 net.cpp:194] Memory required for data: 668467712
I0929 16:32:17.553234 25496 layer_factory.hpp:77] Creating layer conv3_4_bn0
I0929 16:32:17.553249 25496 net.cpp:128] Creating Layer conv3_4_bn0
I0929 16:32:17.553257 25496 net.cpp:558] conv3_4_bn0 <- conv3_4_0
I0929 16:32:17.553264 25496 net.cpp:509] conv3_4_bn0 -> conv3_4_0 (in-place)
I0929 16:32:17.553522 25496 net.cpp:172] Setting up conv3_4_bn0
I0929 16:32:17.553534 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.553537 25496 net.cpp:194] Memory required for data: 672662016
I0929 16:32:17.553560 25496 layer_factory.hpp:77] Creating layer conv3_4_scale0
I0929 16:32:17.553570 25496 net.cpp:128] Creating Layer conv3_4_scale0
I0929 16:32:17.553577 25496 net.cpp:558] conv3_4_scale0 <- conv3_4_0
I0929 16:32:17.553584 25496 net.cpp:509] conv3_4_scale0 -> conv3_4_0 (in-place)
I0929 16:32:17.553627 25496 layer_factory.hpp:77] Creating layer conv3_4_scale0
I0929 16:32:17.553767 25496 net.cpp:172] Setting up conv3_4_scale0
I0929 16:32:17.553777 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.553781 25496 net.cpp:194] Memory required for data: 676856320
I0929 16:32:17.553791 25496 layer_factory.hpp:77] Creating layer conv3_4_ReLU0
I0929 16:32:17.553799 25496 net.cpp:128] Creating Layer conv3_4_ReLU0
I0929 16:32:17.553804 25496 net.cpp:558] conv3_4_ReLU0 <- conv3_4_0
I0929 16:32:17.553813 25496 net.cpp:509] conv3_4_ReLU0 -> conv3_4_0 (in-place)
I0929 16:32:17.554077 25496 net.cpp:172] Setting up conv3_4_ReLU0
I0929 16:32:17.554092 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.554101 25496 net.cpp:194] Memory required for data: 681050624
I0929 16:32:17.554106 25496 layer_factory.hpp:77] Creating layer conv3_4_1
I0929 16:32:17.554121 25496 net.cpp:128] Creating Layer conv3_4_1
I0929 16:32:17.554128 25496 net.cpp:558] conv3_4_1 <- conv3_4_0
I0929 16:32:17.554139 25496 net.cpp:522] conv3_4_1 -> conv3_4_1
I0929 16:32:17.555538 25496 net.cpp:172] Setting up conv3_4_1
I0929 16:32:17.555560 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.555564 25496 net.cpp:194] Memory required for data: 685244928
I0929 16:32:17.555574 25496 layer_factory.hpp:77] Creating layer conv3_4bn1
I0929 16:32:17.555589 25496 net.cpp:128] Creating Layer conv3_4bn1
I0929 16:32:17.555598 25496 net.cpp:558] conv3_4bn1 <- conv3_4_1
I0929 16:32:17.555608 25496 net.cpp:509] conv3_4bn1 -> conv3_4_1 (in-place)
I0929 16:32:17.555855 25496 net.cpp:172] Setting up conv3_4bn1
I0929 16:32:17.555866 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.555871 25496 net.cpp:194] Memory required for data: 689439232
I0929 16:32:17.555879 25496 layer_factory.hpp:77] Creating layer conv3_4_scale1
I0929 16:32:17.555886 25496 net.cpp:128] Creating Layer conv3_4_scale1
I0929 16:32:17.555891 25496 net.cpp:558] conv3_4_scale1 <- conv3_4_1
I0929 16:32:17.555896 25496 net.cpp:509] conv3_4_scale1 -> conv3_4_1 (in-place)
I0929 16:32:17.555940 25496 layer_factory.hpp:77] Creating layer conv3_4_scale1
I0929 16:32:17.556082 25496 net.cpp:172] Setting up conv3_4_scale1
I0929 16:32:17.556092 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.556095 25496 net.cpp:194] Memory required for data: 693633536
I0929 16:32:17.556107 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_4
I0929 16:32:17.556115 25496 net.cpp:128] Creating Layer conv3_Eltwise_4
I0929 16:32:17.556125 25496 net.cpp:558] conv3_Eltwise_4 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0929 16:32:17.556146 25496 net.cpp:558] conv3_Eltwise_4 <- conv3_4_1
I0929 16:32:17.556156 25496 net.cpp:522] conv3_Eltwise_4 -> conv3_Eltwise_4
I0929 16:32:17.556181 25496 net.cpp:172] Setting up conv3_Eltwise_4
I0929 16:32:17.556191 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.556195 25496 net.cpp:194] Memory required for data: 697827840
I0929 16:32:17.556200 25496 layer_factory.hpp:77] Creating layer conv3_4ReLU_1
I0929 16:32:17.556210 25496 net.cpp:128] Creating Layer conv3_4ReLU_1
I0929 16:32:17.556215 25496 net.cpp:558] conv3_4ReLU_1 <- conv3_Eltwise_4
I0929 16:32:17.556221 25496 net.cpp:509] conv3_4ReLU_1 -> conv3_Eltwise_4 (in-place)
I0929 16:32:17.556457 25496 net.cpp:172] Setting up conv3_4ReLU_1
I0929 16:32:17.556470 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.556478 25496 net.cpp:194] Memory required for data: 702022144
I0929 16:32:17.556483 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0929 16:32:17.556494 25496 net.cpp:128] Creating Layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0929 16:32:17.556501 25496 net.cpp:558] conv3_Eltwise_4_conv3_4ReLU_1_0_split <- conv3_Eltwise_4
I0929 16:32:17.556510 25496 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I0929 16:32:17.556522 25496 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I0929 16:32:17.556571 25496 net.cpp:172] Setting up conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0929 16:32:17.556582 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.556591 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.556594 25496 net.cpp:194] Memory required for data: 710410752
I0929 16:32:17.556601 25496 layer_factory.hpp:77] Creating layer conv3_5_0
I0929 16:32:17.556612 25496 net.cpp:128] Creating Layer conv3_5_0
I0929 16:32:17.556618 25496 net.cpp:558] conv3_5_0 <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I0929 16:32:17.556627 25496 net.cpp:522] conv3_5_0 -> conv3_5_0
I0929 16:32:17.558028 25496 net.cpp:172] Setting up conv3_5_0
I0929 16:32:17.558051 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.558055 25496 net.cpp:194] Memory required for data: 714605056
I0929 16:32:17.558065 25496 layer_factory.hpp:77] Creating layer conv3_5_bn0
I0929 16:32:17.558077 25496 net.cpp:128] Creating Layer conv3_5_bn0
I0929 16:32:17.558084 25496 net.cpp:558] conv3_5_bn0 <- conv3_5_0
I0929 16:32:17.558094 25496 net.cpp:509] conv3_5_bn0 -> conv3_5_0 (in-place)
I0929 16:32:17.558343 25496 net.cpp:172] Setting up conv3_5_bn0
I0929 16:32:17.558353 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.558357 25496 net.cpp:194] Memory required for data: 718799360
I0929 16:32:17.558373 25496 layer_factory.hpp:77] Creating layer conv3_5_scale0
I0929 16:32:17.558380 25496 net.cpp:128] Creating Layer conv3_5_scale0
I0929 16:32:17.558388 25496 net.cpp:558] conv3_5_scale0 <- conv3_5_0
I0929 16:32:17.558393 25496 net.cpp:509] conv3_5_scale0 -> conv3_5_0 (in-place)
I0929 16:32:17.558434 25496 layer_factory.hpp:77] Creating layer conv3_5_scale0
I0929 16:32:17.558579 25496 net.cpp:172] Setting up conv3_5_scale0
I0929 16:32:17.558588 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.558593 25496 net.cpp:194] Memory required for data: 722993664
I0929 16:32:17.558603 25496 layer_factory.hpp:77] Creating layer conv3_5_ReLU0
I0929 16:32:17.558609 25496 net.cpp:128] Creating Layer conv3_5_ReLU0
I0929 16:32:17.558615 25496 net.cpp:558] conv3_5_ReLU0 <- conv3_5_0
I0929 16:32:17.558624 25496 net.cpp:509] conv3_5_ReLU0 -> conv3_5_0 (in-place)
I0929 16:32:17.559062 25496 net.cpp:172] Setting up conv3_5_ReLU0
I0929 16:32:17.559083 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.559088 25496 net.cpp:194] Memory required for data: 727187968
I0929 16:32:17.559094 25496 layer_factory.hpp:77] Creating layer conv3_5_1
I0929 16:32:17.559113 25496 net.cpp:128] Creating Layer conv3_5_1
I0929 16:32:17.559134 25496 net.cpp:558] conv3_5_1 <- conv3_5_0
I0929 16:32:17.559145 25496 net.cpp:522] conv3_5_1 -> conv3_5_1
I0929 16:32:17.560537 25496 net.cpp:172] Setting up conv3_5_1
I0929 16:32:17.560562 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.560566 25496 net.cpp:194] Memory required for data: 731382272
I0929 16:32:17.560576 25496 layer_factory.hpp:77] Creating layer conv3_5bn1
I0929 16:32:17.560587 25496 net.cpp:128] Creating Layer conv3_5bn1
I0929 16:32:17.560592 25496 net.cpp:558] conv3_5bn1 <- conv3_5_1
I0929 16:32:17.560602 25496 net.cpp:509] conv3_5bn1 -> conv3_5_1 (in-place)
I0929 16:32:17.560850 25496 net.cpp:172] Setting up conv3_5bn1
I0929 16:32:17.560860 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.560864 25496 net.cpp:194] Memory required for data: 735576576
I0929 16:32:17.560874 25496 layer_factory.hpp:77] Creating layer conv3_5_scale1
I0929 16:32:17.560880 25496 net.cpp:128] Creating Layer conv3_5_scale1
I0929 16:32:17.560889 25496 net.cpp:558] conv3_5_scale1 <- conv3_5_1
I0929 16:32:17.560894 25496 net.cpp:509] conv3_5_scale1 -> conv3_5_1 (in-place)
I0929 16:32:17.560936 25496 layer_factory.hpp:77] Creating layer conv3_5_scale1
I0929 16:32:17.561079 25496 net.cpp:172] Setting up conv3_5_scale1
I0929 16:32:17.561089 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.561094 25496 net.cpp:194] Memory required for data: 739770880
I0929 16:32:17.561101 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_5
I0929 16:32:17.561113 25496 net.cpp:128] Creating Layer conv3_Eltwise_5
I0929 16:32:17.561118 25496 net.cpp:558] conv3_Eltwise_5 <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I0929 16:32:17.561123 25496 net.cpp:558] conv3_Eltwise_5 <- conv3_5_1
I0929 16:32:17.561130 25496 net.cpp:522] conv3_Eltwise_5 -> conv3_Eltwise_5
I0929 16:32:17.561153 25496 net.cpp:172] Setting up conv3_Eltwise_5
I0929 16:32:17.561162 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.561167 25496 net.cpp:194] Memory required for data: 743965184
I0929 16:32:17.561170 25496 layer_factory.hpp:77] Creating layer conv3_5ReLU_1
I0929 16:32:17.561177 25496 net.cpp:128] Creating Layer conv3_5ReLU_1
I0929 16:32:17.561182 25496 net.cpp:558] conv3_5ReLU_1 <- conv3_Eltwise_5
I0929 16:32:17.561189 25496 net.cpp:509] conv3_5ReLU_1 -> conv3_Eltwise_5 (in-place)
I0929 16:32:17.561435 25496 net.cpp:172] Setting up conv3_5ReLU_1
I0929 16:32:17.561450 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.561457 25496 net.cpp:194] Memory required for data: 748159488
I0929 16:32:17.561462 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0929 16:32:17.561470 25496 net.cpp:128] Creating Layer conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0929 16:32:17.561475 25496 net.cpp:558] conv3_Eltwise_5_conv3_5ReLU_1_0_split <- conv3_Eltwise_5
I0929 16:32:17.561483 25496 net.cpp:522] conv3_Eltwise_5_conv3_5ReLU_1_0_split -> conv3_Eltwise_5_conv3_5ReLU_1_0_split_0
I0929 16:32:17.561494 25496 net.cpp:522] conv3_Eltwise_5_conv3_5ReLU_1_0_split -> conv3_Eltwise_5_conv3_5ReLU_1_0_split_1
I0929 16:32:17.561547 25496 net.cpp:172] Setting up conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0929 16:32:17.561553 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.561559 25496 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0929 16:32:17.561563 25496 net.cpp:194] Memory required for data: 756548096
I0929 16:32:17.561568 25496 layer_factory.hpp:77] Creating layer conv4_1_0
I0929 16:32:17.561579 25496 net.cpp:128] Creating Layer conv4_1_0
I0929 16:32:17.561584 25496 net.cpp:558] conv4_1_0 <- conv3_Eltwise_5_conv3_5ReLU_1_0_split_0
I0929 16:32:17.561595 25496 net.cpp:522] conv4_1_0 -> conv4_1_0
I0929 16:32:17.564735 25496 net.cpp:172] Setting up conv4_1_0
I0929 16:32:17.564766 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.564771 25496 net.cpp:194] Memory required for data: 758645248
I0929 16:32:17.564785 25496 layer_factory.hpp:77] Creating layer conv4_1_bn0
I0929 16:32:17.564800 25496 net.cpp:128] Creating Layer conv4_1_bn0
I0929 16:32:17.564824 25496 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I0929 16:32:17.564834 25496 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I0929 16:32:17.565102 25496 net.cpp:172] Setting up conv4_1_bn0
I0929 16:32:17.565112 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.565116 25496 net.cpp:194] Memory required for data: 760742400
I0929 16:32:17.565129 25496 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0929 16:32:17.565140 25496 net.cpp:128] Creating Layer conv4_1_scale0
I0929 16:32:17.565145 25496 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I0929 16:32:17.565151 25496 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I0929 16:32:17.565194 25496 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0929 16:32:17.565343 25496 net.cpp:172] Setting up conv4_1_scale0
I0929 16:32:17.565352 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.565356 25496 net.cpp:194] Memory required for data: 762839552
I0929 16:32:17.565366 25496 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I0929 16:32:17.565377 25496 net.cpp:128] Creating Layer conv4_1_ReLU0
I0929 16:32:17.565382 25496 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I0929 16:32:17.565387 25496 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I0929 16:32:17.565630 25496 net.cpp:172] Setting up conv4_1_ReLU0
I0929 16:32:17.565644 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.565651 25496 net.cpp:194] Memory required for data: 764936704
I0929 16:32:17.565656 25496 layer_factory.hpp:77] Creating layer conv4_1_1
I0929 16:32:17.565675 25496 net.cpp:128] Creating Layer conv4_1_1
I0929 16:32:17.565680 25496 net.cpp:558] conv4_1_1 <- conv4_1_0
I0929 16:32:17.565686 25496 net.cpp:522] conv4_1_1 -> conv4_1_1
I0929 16:32:17.567720 25496 net.cpp:172] Setting up conv4_1_1
I0929 16:32:17.567747 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.567752 25496 net.cpp:194] Memory required for data: 767033856
I0929 16:32:17.567764 25496 layer_factory.hpp:77] Creating layer conv4_1bn1
I0929 16:32:17.567775 25496 net.cpp:128] Creating Layer conv4_1bn1
I0929 16:32:17.567780 25496 net.cpp:558] conv4_1bn1 <- conv4_1_1
I0929 16:32:17.567790 25496 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I0929 16:32:17.568058 25496 net.cpp:172] Setting up conv4_1bn1
I0929 16:32:17.568068 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.568073 25496 net.cpp:194] Memory required for data: 769131008
I0929 16:32:17.568086 25496 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0929 16:32:17.568092 25496 net.cpp:128] Creating Layer conv4_1_scale1
I0929 16:32:17.568097 25496 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I0929 16:32:17.568104 25496 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I0929 16:32:17.568145 25496 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0929 16:32:17.568296 25496 net.cpp:172] Setting up conv4_1_scale1
I0929 16:32:17.568305 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.568310 25496 net.cpp:194] Memory required for data: 771228160
I0929 16:32:17.568320 25496 layer_factory.hpp:77] Creating layer conv4_1_down
I0929 16:32:17.568333 25496 net.cpp:128] Creating Layer conv4_1_down
I0929 16:32:17.568339 25496 net.cpp:558] conv4_1_down <- conv3_Eltwise_5_conv3_5ReLU_1_0_split_1
I0929 16:32:17.568348 25496 net.cpp:522] conv4_1_down -> conv4_1_down
I0929 16:32:17.569659 25496 net.cpp:172] Setting up conv4_1_down
I0929 16:32:17.569686 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.569690 25496 net.cpp:194] Memory required for data: 773325312
I0929 16:32:17.569701 25496 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I0929 16:32:17.569710 25496 net.cpp:128] Creating Layer conv4_1_bn_down
I0929 16:32:17.569715 25496 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I0929 16:32:17.569727 25496 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I0929 16:32:17.570010 25496 net.cpp:172] Setting up conv4_1_bn_down
I0929 16:32:17.570021 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.570025 25496 net.cpp:194] Memory required for data: 775422464
I0929 16:32:17.570058 25496 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0929 16:32:17.570068 25496 net.cpp:128] Creating Layer conv4_1_scale_down
I0929 16:32:17.570073 25496 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I0929 16:32:17.570080 25496 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I0929 16:32:17.570124 25496 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0929 16:32:17.570276 25496 net.cpp:172] Setting up conv4_1_scale_down
I0929 16:32:17.570287 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.570291 25496 net.cpp:194] Memory required for data: 777519616
I0929 16:32:17.570299 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I0929 16:32:17.570309 25496 net.cpp:128] Creating Layer conv4_Eltwise_1
I0929 16:32:17.570317 25496 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I0929 16:32:17.570322 25496 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I0929 16:32:17.570327 25496 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I0929 16:32:17.570356 25496 net.cpp:172] Setting up conv4_Eltwise_1
I0929 16:32:17.570365 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.570369 25496 net.cpp:194] Memory required for data: 779616768
I0929 16:32:17.570374 25496 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I0929 16:32:17.570381 25496 net.cpp:128] Creating Layer conv4_1ReLU_1
I0929 16:32:17.570385 25496 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I0929 16:32:17.570392 25496 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I0929 16:32:17.572449 25496 net.cpp:172] Setting up conv4_1ReLU_1
I0929 16:32:17.572475 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.572479 25496 net.cpp:194] Memory required for data: 781713920
I0929 16:32:17.572485 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 16:32:17.572494 25496 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 16:32:17.572499 25496 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I0929 16:32:17.572508 25496 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0929 16:32:17.572518 25496 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0929 16:32:17.572576 25496 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 16:32:17.572585 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.572592 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.572594 25496 net.cpp:194] Memory required for data: 785908224
I0929 16:32:17.572599 25496 layer_factory.hpp:77] Creating layer conv4_2_0
I0929 16:32:17.572613 25496 net.cpp:128] Creating Layer conv4_2_0
I0929 16:32:17.572618 25496 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0929 16:32:17.572626 25496 net.cpp:522] conv4_2_0 -> conv4_2_0
I0929 16:32:17.577679 25496 net.cpp:172] Setting up conv4_2_0
I0929 16:32:17.577708 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.577713 25496 net.cpp:194] Memory required for data: 788005376
I0929 16:32:17.577728 25496 layer_factory.hpp:77] Creating layer conv4_2_bn0
I0929 16:32:17.577738 25496 net.cpp:128] Creating Layer conv4_2_bn0
I0929 16:32:17.577742 25496 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I0929 16:32:17.577752 25496 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I0929 16:32:17.578030 25496 net.cpp:172] Setting up conv4_2_bn0
I0929 16:32:17.578042 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.578047 25496 net.cpp:194] Memory required for data: 790102528
I0929 16:32:17.578056 25496 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0929 16:32:17.578066 25496 net.cpp:128] Creating Layer conv4_2_scale0
I0929 16:32:17.578071 25496 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I0929 16:32:17.578078 25496 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I0929 16:32:17.578119 25496 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0929 16:32:17.578281 25496 net.cpp:172] Setting up conv4_2_scale0
I0929 16:32:17.578294 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.578315 25496 net.cpp:194] Memory required for data: 792199680
I0929 16:32:17.578323 25496 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I0929 16:32:17.578331 25496 net.cpp:128] Creating Layer conv4_2_ReLU0
I0929 16:32:17.578336 25496 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I0929 16:32:17.578346 25496 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I0929 16:32:17.579749 25496 net.cpp:172] Setting up conv4_2_ReLU0
I0929 16:32:17.579767 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.579771 25496 net.cpp:194] Memory required for data: 794296832
I0929 16:32:17.579777 25496 layer_factory.hpp:77] Creating layer conv4_2_1
I0929 16:32:17.579789 25496 net.cpp:128] Creating Layer conv4_2_1
I0929 16:32:17.579794 25496 net.cpp:558] conv4_2_1 <- conv4_2_0
I0929 16:32:17.579805 25496 net.cpp:522] conv4_2_1 -> conv4_2_1
I0929 16:32:17.586727 25496 net.cpp:172] Setting up conv4_2_1
I0929 16:32:17.586751 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.586756 25496 net.cpp:194] Memory required for data: 796393984
I0929 16:32:17.586766 25496 layer_factory.hpp:77] Creating layer conv4_2bn1
I0929 16:32:17.586782 25496 net.cpp:128] Creating Layer conv4_2bn1
I0929 16:32:17.586787 25496 net.cpp:558] conv4_2bn1 <- conv4_2_1
I0929 16:32:17.586794 25496 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I0929 16:32:17.587071 25496 net.cpp:172] Setting up conv4_2bn1
I0929 16:32:17.587083 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.587087 25496 net.cpp:194] Memory required for data: 798491136
I0929 16:32:17.587097 25496 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0929 16:32:17.587119 25496 net.cpp:128] Creating Layer conv4_2_scale1
I0929 16:32:17.587124 25496 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I0929 16:32:17.587131 25496 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I0929 16:32:17.587172 25496 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0929 16:32:17.587321 25496 net.cpp:172] Setting up conv4_2_scale1
I0929 16:32:17.587333 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.587337 25496 net.cpp:194] Memory required for data: 800588288
I0929 16:32:17.587345 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I0929 16:32:17.587357 25496 net.cpp:128] Creating Layer conv4_Eltwise_2
I0929 16:32:17.587361 25496 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0929 16:32:17.587366 25496 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I0929 16:32:17.587373 25496 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I0929 16:32:17.587404 25496 net.cpp:172] Setting up conv4_Eltwise_2
I0929 16:32:17.587412 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.587416 25496 net.cpp:194] Memory required for data: 802685440
I0929 16:32:17.587420 25496 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I0929 16:32:17.587427 25496 net.cpp:128] Creating Layer conv4_2ReLU_1
I0929 16:32:17.587431 25496 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I0929 16:32:17.587436 25496 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I0929 16:32:17.588559 25496 net.cpp:172] Setting up conv4_2ReLU_1
I0929 16:32:17.588578 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.588584 25496 net.cpp:194] Memory required for data: 804782592
I0929 16:32:17.588588 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 16:32:17.588596 25496 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 16:32:17.588600 25496 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I0929 16:32:17.588610 25496 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0929 16:32:17.588619 25496 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0929 16:32:17.588671 25496 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 16:32:17.588678 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.588685 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.588706 25496 net.cpp:194] Memory required for data: 808976896
I0929 16:32:17.588711 25496 layer_factory.hpp:77] Creating layer conv4_3_0
I0929 16:32:17.588726 25496 net.cpp:128] Creating Layer conv4_3_0
I0929 16:32:17.588732 25496 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0929 16:32:17.588738 25496 net.cpp:522] conv4_3_0 -> conv4_3_0
I0929 16:32:17.595295 25496 net.cpp:172] Setting up conv4_3_0
I0929 16:32:17.595321 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.595325 25496 net.cpp:194] Memory required for data: 811074048
I0929 16:32:17.595335 25496 layer_factory.hpp:77] Creating layer conv4_3_bn0
I0929 16:32:17.595347 25496 net.cpp:128] Creating Layer conv4_3_bn0
I0929 16:32:17.595353 25496 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I0929 16:32:17.595361 25496 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I0929 16:32:17.595633 25496 net.cpp:172] Setting up conv4_3_bn0
I0929 16:32:17.595646 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.595650 25496 net.cpp:194] Memory required for data: 813171200
I0929 16:32:17.595660 25496 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0929 16:32:17.595666 25496 net.cpp:128] Creating Layer conv4_3_scale0
I0929 16:32:17.595671 25496 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I0929 16:32:17.595676 25496 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I0929 16:32:17.595719 25496 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0929 16:32:17.595872 25496 net.cpp:172] Setting up conv4_3_scale0
I0929 16:32:17.595885 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.595891 25496 net.cpp:194] Memory required for data: 815268352
I0929 16:32:17.595898 25496 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I0929 16:32:17.595906 25496 net.cpp:128] Creating Layer conv4_3_ReLU0
I0929 16:32:17.595909 25496 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I0929 16:32:17.595918 25496 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I0929 16:32:17.597376 25496 net.cpp:172] Setting up conv4_3_ReLU0
I0929 16:32:17.597403 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.597406 25496 net.cpp:194] Memory required for data: 817365504
I0929 16:32:17.597411 25496 layer_factory.hpp:77] Creating layer conv4_3_1
I0929 16:32:17.597429 25496 net.cpp:128] Creating Layer conv4_3_1
I0929 16:32:17.597434 25496 net.cpp:558] conv4_3_1 <- conv4_3_0
I0929 16:32:17.597445 25496 net.cpp:522] conv4_3_1 -> conv4_3_1
I0929 16:32:17.604353 25496 net.cpp:172] Setting up conv4_3_1
I0929 16:32:17.604379 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.604384 25496 net.cpp:194] Memory required for data: 819462656
I0929 16:32:17.604395 25496 layer_factory.hpp:77] Creating layer conv4_3bn1
I0929 16:32:17.604408 25496 net.cpp:128] Creating Layer conv4_3bn1
I0929 16:32:17.604413 25496 net.cpp:558] conv4_3bn1 <- conv4_3_1
I0929 16:32:17.604419 25496 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I0929 16:32:17.604696 25496 net.cpp:172] Setting up conv4_3bn1
I0929 16:32:17.604708 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.604712 25496 net.cpp:194] Memory required for data: 821559808
I0929 16:32:17.604722 25496 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0929 16:32:17.604729 25496 net.cpp:128] Creating Layer conv4_3_scale1
I0929 16:32:17.604733 25496 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I0929 16:32:17.604738 25496 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I0929 16:32:17.604784 25496 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0929 16:32:17.604943 25496 net.cpp:172] Setting up conv4_3_scale1
I0929 16:32:17.604957 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.604961 25496 net.cpp:194] Memory required for data: 823656960
I0929 16:32:17.604972 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I0929 16:32:17.604979 25496 net.cpp:128] Creating Layer conv4_Eltwise_3
I0929 16:32:17.604984 25496 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0929 16:32:17.604990 25496 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I0929 16:32:17.604995 25496 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I0929 16:32:17.605037 25496 net.cpp:172] Setting up conv4_Eltwise_3
I0929 16:32:17.605046 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.605049 25496 net.cpp:194] Memory required for data: 825754112
I0929 16:32:17.605053 25496 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I0929 16:32:17.605062 25496 net.cpp:128] Creating Layer conv4_3ReLU_1
I0929 16:32:17.605065 25496 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I0929 16:32:17.605073 25496 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I0929 16:32:17.606231 25496 net.cpp:172] Setting up conv4_3ReLU_1
I0929 16:32:17.606248 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.606253 25496 net.cpp:194] Memory required for data: 827851264
I0929 16:32:17.606257 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0929 16:32:17.606266 25496 net.cpp:128] Creating Layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0929 16:32:17.606271 25496 net.cpp:558] conv4_Eltwise_3_conv4_3ReLU_1_0_split <- conv4_Eltwise_3
I0929 16:32:17.606279 25496 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I0929 16:32:17.606288 25496 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I0929 16:32:17.606343 25496 net.cpp:172] Setting up conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0929 16:32:17.606354 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.606360 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.606364 25496 net.cpp:194] Memory required for data: 832045568
I0929 16:32:17.606369 25496 layer_factory.hpp:77] Creating layer conv4_4_0
I0929 16:32:17.606380 25496 net.cpp:128] Creating Layer conv4_4_0
I0929 16:32:17.606385 25496 net.cpp:558] conv4_4_0 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I0929 16:32:17.606395 25496 net.cpp:522] conv4_4_0 -> conv4_4_0
I0929 16:32:17.612964 25496 net.cpp:172] Setting up conv4_4_0
I0929 16:32:17.612990 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.612994 25496 net.cpp:194] Memory required for data: 834142720
I0929 16:32:17.613009 25496 layer_factory.hpp:77] Creating layer conv4_4_bn0
I0929 16:32:17.613018 25496 net.cpp:128] Creating Layer conv4_4_bn0
I0929 16:32:17.613023 25496 net.cpp:558] conv4_4_bn0 <- conv4_4_0
I0929 16:32:17.613034 25496 net.cpp:509] conv4_4_bn0 -> conv4_4_0 (in-place)
I0929 16:32:17.613322 25496 net.cpp:172] Setting up conv4_4_bn0
I0929 16:32:17.613334 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.613338 25496 net.cpp:194] Memory required for data: 836239872
I0929 16:32:17.613348 25496 layer_factory.hpp:77] Creating layer conv4_4_scale0
I0929 16:32:17.613361 25496 net.cpp:128] Creating Layer conv4_4_scale0
I0929 16:32:17.613369 25496 net.cpp:558] conv4_4_scale0 <- conv4_4_0
I0929 16:32:17.613375 25496 net.cpp:509] conv4_4_scale0 -> conv4_4_0 (in-place)
I0929 16:32:17.613416 25496 layer_factory.hpp:77] Creating layer conv4_4_scale0
I0929 16:32:17.613571 25496 net.cpp:172] Setting up conv4_4_scale0
I0929 16:32:17.613581 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.613585 25496 net.cpp:194] Memory required for data: 838337024
I0929 16:32:17.613592 25496 layer_factory.hpp:77] Creating layer conv4_4_ReLU0
I0929 16:32:17.613601 25496 net.cpp:128] Creating Layer conv4_4_ReLU0
I0929 16:32:17.613606 25496 net.cpp:558] conv4_4_ReLU0 <- conv4_4_0
I0929 16:32:17.613617 25496 net.cpp:509] conv4_4_ReLU0 -> conv4_4_0 (in-place)
I0929 16:32:17.615036 25496 net.cpp:172] Setting up conv4_4_ReLU0
I0929 16:32:17.615056 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.615061 25496 net.cpp:194] Memory required for data: 840434176
I0929 16:32:17.615065 25496 layer_factory.hpp:77] Creating layer conv4_4_1
I0929 16:32:17.615078 25496 net.cpp:128] Creating Layer conv4_4_1
I0929 16:32:17.615087 25496 net.cpp:558] conv4_4_1 <- conv4_4_0
I0929 16:32:17.615094 25496 net.cpp:522] conv4_4_1 -> conv4_4_1
I0929 16:32:17.621966 25496 net.cpp:172] Setting up conv4_4_1
I0929 16:32:17.622007 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.622012 25496 net.cpp:194] Memory required for data: 842531328
I0929 16:32:17.622027 25496 layer_factory.hpp:77] Creating layer conv4_4bn1
I0929 16:32:17.622038 25496 net.cpp:128] Creating Layer conv4_4bn1
I0929 16:32:17.622056 25496 net.cpp:558] conv4_4bn1 <- conv4_4_1
I0929 16:32:17.622062 25496 net.cpp:509] conv4_4bn1 -> conv4_4_1 (in-place)
I0929 16:32:17.622347 25496 net.cpp:172] Setting up conv4_4bn1
I0929 16:32:17.622359 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.622362 25496 net.cpp:194] Memory required for data: 844628480
I0929 16:32:17.622372 25496 layer_factory.hpp:77] Creating layer conv4_4_scale1
I0929 16:32:17.622380 25496 net.cpp:128] Creating Layer conv4_4_scale1
I0929 16:32:17.622383 25496 net.cpp:558] conv4_4_scale1 <- conv4_4_1
I0929 16:32:17.622390 25496 net.cpp:509] conv4_4_scale1 -> conv4_4_1 (in-place)
I0929 16:32:17.622434 25496 layer_factory.hpp:77] Creating layer conv4_4_scale1
I0929 16:32:17.622589 25496 net.cpp:172] Setting up conv4_4_scale1
I0929 16:32:17.622601 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.622606 25496 net.cpp:194] Memory required for data: 846725632
I0929 16:32:17.622614 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_4
I0929 16:32:17.622627 25496 net.cpp:128] Creating Layer conv4_Eltwise_4
I0929 16:32:17.622632 25496 net.cpp:558] conv4_Eltwise_4 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I0929 16:32:17.622637 25496 net.cpp:558] conv4_Eltwise_4 <- conv4_4_1
I0929 16:32:17.622648 25496 net.cpp:522] conv4_Eltwise_4 -> conv4_Eltwise_4
I0929 16:32:17.622673 25496 net.cpp:172] Setting up conv4_Eltwise_4
I0929 16:32:17.622684 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.622687 25496 net.cpp:194] Memory required for data: 848822784
I0929 16:32:17.622691 25496 layer_factory.hpp:77] Creating layer conv4_4ReLU_1
I0929 16:32:17.622697 25496 net.cpp:128] Creating Layer conv4_4ReLU_1
I0929 16:32:17.622702 25496 net.cpp:558] conv4_4ReLU_1 <- conv4_Eltwise_4
I0929 16:32:17.622710 25496 net.cpp:509] conv4_4ReLU_1 -> conv4_Eltwise_4 (in-place)
I0929 16:32:17.623829 25496 net.cpp:172] Setting up conv4_4ReLU_1
I0929 16:32:17.623847 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.623853 25496 net.cpp:194] Memory required for data: 850919936
I0929 16:32:17.623858 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0929 16:32:17.623865 25496 net.cpp:128] Creating Layer conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0929 16:32:17.623870 25496 net.cpp:558] conv4_Eltwise_4_conv4_4ReLU_1_0_split <- conv4_Eltwise_4
I0929 16:32:17.623880 25496 net.cpp:522] conv4_Eltwise_4_conv4_4ReLU_1_0_split -> conv4_Eltwise_4_conv4_4ReLU_1_0_split_0
I0929 16:32:17.623889 25496 net.cpp:522] conv4_Eltwise_4_conv4_4ReLU_1_0_split -> conv4_Eltwise_4_conv4_4ReLU_1_0_split_1
I0929 16:32:17.623944 25496 net.cpp:172] Setting up conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0929 16:32:17.623956 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.623962 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.623965 25496 net.cpp:194] Memory required for data: 855114240
I0929 16:32:17.623970 25496 layer_factory.hpp:77] Creating layer conv4_5_0
I0929 16:32:17.623982 25496 net.cpp:128] Creating Layer conv4_5_0
I0929 16:32:17.623987 25496 net.cpp:558] conv4_5_0 <- conv4_Eltwise_4_conv4_4ReLU_1_0_split_0
I0929 16:32:17.623997 25496 net.cpp:522] conv4_5_0 -> conv4_5_0
I0929 16:32:17.630611 25496 net.cpp:172] Setting up conv4_5_0
I0929 16:32:17.630637 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.630642 25496 net.cpp:194] Memory required for data: 857211392
I0929 16:32:17.630656 25496 layer_factory.hpp:77] Creating layer conv4_5_bn0
I0929 16:32:17.630668 25496 net.cpp:128] Creating Layer conv4_5_bn0
I0929 16:32:17.630677 25496 net.cpp:558] conv4_5_bn0 <- conv4_5_0
I0929 16:32:17.630684 25496 net.cpp:509] conv4_5_bn0 -> conv4_5_0 (in-place)
I0929 16:32:17.630956 25496 net.cpp:172] Setting up conv4_5_bn0
I0929 16:32:17.630982 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.630987 25496 net.cpp:194] Memory required for data: 859308544
I0929 16:32:17.630997 25496 layer_factory.hpp:77] Creating layer conv4_5_scale0
I0929 16:32:17.631007 25496 net.cpp:128] Creating Layer conv4_5_scale0
I0929 16:32:17.631012 25496 net.cpp:558] conv4_5_scale0 <- conv4_5_0
I0929 16:32:17.631018 25496 net.cpp:509] conv4_5_scale0 -> conv4_5_0 (in-place)
I0929 16:32:17.631063 25496 layer_factory.hpp:77] Creating layer conv4_5_scale0
I0929 16:32:17.631223 25496 net.cpp:172] Setting up conv4_5_scale0
I0929 16:32:17.631234 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.631238 25496 net.cpp:194] Memory required for data: 861405696
I0929 16:32:17.631247 25496 layer_factory.hpp:77] Creating layer conv4_5_ReLU0
I0929 16:32:17.631260 25496 net.cpp:128] Creating Layer conv4_5_ReLU0
I0929 16:32:17.631268 25496 net.cpp:558] conv4_5_ReLU0 <- conv4_5_0
I0929 16:32:17.631273 25496 net.cpp:509] conv4_5_ReLU0 -> conv4_5_0 (in-place)
I0929 16:32:17.632678 25496 net.cpp:172] Setting up conv4_5_ReLU0
I0929 16:32:17.632702 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.632707 25496 net.cpp:194] Memory required for data: 863502848
I0929 16:32:17.632712 25496 layer_factory.hpp:77] Creating layer conv4_5_1
I0929 16:32:17.632730 25496 net.cpp:128] Creating Layer conv4_5_1
I0929 16:32:17.632735 25496 net.cpp:558] conv4_5_1 <- conv4_5_0
I0929 16:32:17.632745 25496 net.cpp:522] conv4_5_1 -> conv4_5_1
I0929 16:32:17.639664 25496 net.cpp:172] Setting up conv4_5_1
I0929 16:32:17.639693 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.639696 25496 net.cpp:194] Memory required for data: 865600000
I0929 16:32:17.639711 25496 layer_factory.hpp:77] Creating layer conv4_5bn1
I0929 16:32:17.639722 25496 net.cpp:128] Creating Layer conv4_5bn1
I0929 16:32:17.639732 25496 net.cpp:558] conv4_5bn1 <- conv4_5_1
I0929 16:32:17.639739 25496 net.cpp:509] conv4_5bn1 -> conv4_5_1 (in-place)
I0929 16:32:17.640023 25496 net.cpp:172] Setting up conv4_5bn1
I0929 16:32:17.640036 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.640040 25496 net.cpp:194] Memory required for data: 867697152
I0929 16:32:17.640050 25496 layer_factory.hpp:77] Creating layer conv4_5_scale1
I0929 16:32:17.640058 25496 net.cpp:128] Creating Layer conv4_5_scale1
I0929 16:32:17.640063 25496 net.cpp:558] conv4_5_scale1 <- conv4_5_1
I0929 16:32:17.640067 25496 net.cpp:509] conv4_5_scale1 -> conv4_5_1 (in-place)
I0929 16:32:17.640115 25496 layer_factory.hpp:77] Creating layer conv4_5_scale1
I0929 16:32:17.640270 25496 net.cpp:172] Setting up conv4_5_scale1
I0929 16:32:17.640285 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.640290 25496 net.cpp:194] Memory required for data: 869794304
I0929 16:32:17.640297 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_5
I0929 16:32:17.640305 25496 net.cpp:128] Creating Layer conv4_Eltwise_5
I0929 16:32:17.640310 25496 net.cpp:558] conv4_Eltwise_5 <- conv4_Eltwise_4_conv4_4ReLU_1_0_split_1
I0929 16:32:17.640314 25496 net.cpp:558] conv4_Eltwise_5 <- conv4_5_1
I0929 16:32:17.640321 25496 net.cpp:522] conv4_Eltwise_5 -> conv4_Eltwise_5
I0929 16:32:17.640345 25496 net.cpp:172] Setting up conv4_Eltwise_5
I0929 16:32:17.640352 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.640355 25496 net.cpp:194] Memory required for data: 871891456
I0929 16:32:17.640360 25496 layer_factory.hpp:77] Creating layer conv4_5ReLU_1
I0929 16:32:17.640367 25496 net.cpp:128] Creating Layer conv4_5ReLU_1
I0929 16:32:17.640370 25496 net.cpp:558] conv4_5ReLU_1 <- conv4_Eltwise_5
I0929 16:32:17.640378 25496 net.cpp:509] conv4_5ReLU_1 -> conv4_Eltwise_5 (in-place)
I0929 16:32:17.641525 25496 net.cpp:172] Setting up conv4_5ReLU_1
I0929 16:32:17.641538 25496 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0929 16:32:17.641544 25496 net.cpp:194] Memory required for data: 873988608
I0929 16:32:17.641549 25496 layer_factory.hpp:77] Creating layer Pooling1
I0929 16:32:17.641561 25496 net.cpp:128] Creating Layer Pooling1
I0929 16:32:17.641584 25496 net.cpp:558] Pooling1 <- conv4_Eltwise_5
I0929 16:32:17.641592 25496 net.cpp:522] Pooling1 -> Pooling1
I0929 16:32:17.643810 25496 net.cpp:172] Setting up Pooling1
I0929 16:32:17.643831 25496 net.cpp:186] Top shape: 128 64 1 1 (8192)
I0929 16:32:17.643836 25496 net.cpp:194] Memory required for data: 874021376
I0929 16:32:17.643841 25496 layer_factory.hpp:77] Creating layer fc1
I0929 16:32:17.643854 25496 net.cpp:128] Creating Layer fc1
I0929 16:32:17.643859 25496 net.cpp:558] fc1 <- Pooling1
I0929 16:32:17.643869 25496 net.cpp:522] fc1 -> fc1
I0929 16:32:17.644052 25496 net.cpp:172] Setting up fc1
I0929 16:32:17.644064 25496 net.cpp:186] Top shape: 128 10 (1280)
I0929 16:32:17.644068 25496 net.cpp:194] Memory required for data: 874026496
I0929 16:32:17.644078 25496 layer_factory.hpp:77] Creating layer Softmax1
I0929 16:32:17.644089 25496 net.cpp:128] Creating Layer Softmax1
I0929 16:32:17.644094 25496 net.cpp:558] Softmax1 <- fc1
I0929 16:32:17.644099 25496 net.cpp:558] Softmax1 <- label
I0929 16:32:17.644107 25496 net.cpp:522] Softmax1 -> Softmax1
I0929 16:32:17.644119 25496 layer_factory.hpp:77] Creating layer Softmax1
I0929 16:32:17.646104 25496 net.cpp:172] Setting up Softmax1
I0929 16:32:17.646131 25496 net.cpp:186] Top shape: (1)
I0929 16:32:17.646134 25496 net.cpp:189]     with loss weight 1
I0929 16:32:17.646169 25496 net.cpp:194] Memory required for data: 874026500
I0929 16:32:17.646175 25496 net.cpp:301] Softmax1 needs backward computation.
I0929 16:32:17.646180 25496 net.cpp:301] fc1 needs backward computation.
I0929 16:32:17.646184 25496 net.cpp:301] Pooling1 needs backward computation.
I0929 16:32:17.646188 25496 net.cpp:301] conv4_5ReLU_1 needs backward computation.
I0929 16:32:17.646193 25496 net.cpp:301] conv4_Eltwise_5 needs backward computation.
I0929 16:32:17.646198 25496 net.cpp:301] conv4_5_scale1 needs backward computation.
I0929 16:32:17.646201 25496 net.cpp:301] conv4_5bn1 needs backward computation.
I0929 16:32:17.646205 25496 net.cpp:301] conv4_5_1 needs backward computation.
I0929 16:32:17.646209 25496 net.cpp:301] conv4_5_ReLU0 needs backward computation.
I0929 16:32:17.646214 25496 net.cpp:301] conv4_5_scale0 needs backward computation.
I0929 16:32:17.646217 25496 net.cpp:301] conv4_5_bn0 needs backward computation.
I0929 16:32:17.646221 25496 net.cpp:301] conv4_5_0 needs backward computation.
I0929 16:32:17.646226 25496 net.cpp:301] conv4_Eltwise_4_conv4_4ReLU_1_0_split needs backward computation.
I0929 16:32:17.646230 25496 net.cpp:301] conv4_4ReLU_1 needs backward computation.
I0929 16:32:17.646234 25496 net.cpp:301] conv4_Eltwise_4 needs backward computation.
I0929 16:32:17.646239 25496 net.cpp:301] conv4_4_scale1 needs backward computation.
I0929 16:32:17.646244 25496 net.cpp:301] conv4_4bn1 needs backward computation.
I0929 16:32:17.646247 25496 net.cpp:301] conv4_4_1 needs backward computation.
I0929 16:32:17.646251 25496 net.cpp:301] conv4_4_ReLU0 needs backward computation.
I0929 16:32:17.646255 25496 net.cpp:301] conv4_4_scale0 needs backward computation.
I0929 16:32:17.646260 25496 net.cpp:301] conv4_4_bn0 needs backward computation.
I0929 16:32:17.646265 25496 net.cpp:301] conv4_4_0 needs backward computation.
I0929 16:32:17.646270 25496 net.cpp:301] conv4_Eltwise_3_conv4_3ReLU_1_0_split needs backward computation.
I0929 16:32:17.646275 25496 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I0929 16:32:17.646278 25496 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I0929 16:32:17.646283 25496 net.cpp:301] conv4_3_scale1 needs backward computation.
I0929 16:32:17.646287 25496 net.cpp:301] conv4_3bn1 needs backward computation.
I0929 16:32:17.646291 25496 net.cpp:301] conv4_3_1 needs backward computation.
I0929 16:32:17.646296 25496 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I0929 16:32:17.646299 25496 net.cpp:301] conv4_3_scale0 needs backward computation.
I0929 16:32:17.646303 25496 net.cpp:301] conv4_3_bn0 needs backward computation.
I0929 16:32:17.646307 25496 net.cpp:301] conv4_3_0 needs backward computation.
I0929 16:32:17.646328 25496 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I0929 16:32:17.646333 25496 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I0929 16:32:17.646338 25496 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I0929 16:32:17.646343 25496 net.cpp:301] conv4_2_scale1 needs backward computation.
I0929 16:32:17.646347 25496 net.cpp:301] conv4_2bn1 needs backward computation.
I0929 16:32:17.646353 25496 net.cpp:301] conv4_2_1 needs backward computation.
I0929 16:32:17.646356 25496 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I0929 16:32:17.646360 25496 net.cpp:301] conv4_2_scale0 needs backward computation.
I0929 16:32:17.646365 25496 net.cpp:301] conv4_2_bn0 needs backward computation.
I0929 16:32:17.646369 25496 net.cpp:301] conv4_2_0 needs backward computation.
I0929 16:32:17.646374 25496 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I0929 16:32:17.646383 25496 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I0929 16:32:17.646386 25496 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I0929 16:32:17.646391 25496 net.cpp:301] conv4_1_scale_down needs backward computation.
I0929 16:32:17.646396 25496 net.cpp:301] conv4_1_bn_down needs backward computation.
I0929 16:32:17.646400 25496 net.cpp:301] conv4_1_down needs backward computation.
I0929 16:32:17.646405 25496 net.cpp:301] conv4_1_scale1 needs backward computation.
I0929 16:32:17.646409 25496 net.cpp:301] conv4_1bn1 needs backward computation.
I0929 16:32:17.646414 25496 net.cpp:301] conv4_1_1 needs backward computation.
I0929 16:32:17.646419 25496 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I0929 16:32:17.646425 25496 net.cpp:301] conv4_1_scale0 needs backward computation.
I0929 16:32:17.646428 25496 net.cpp:301] conv4_1_bn0 needs backward computation.
I0929 16:32:17.646433 25496 net.cpp:301] conv4_1_0 needs backward computation.
I0929 16:32:17.646438 25496 net.cpp:301] conv3_Eltwise_5_conv3_5ReLU_1_0_split needs backward computation.
I0929 16:32:17.646443 25496 net.cpp:301] conv3_5ReLU_1 needs backward computation.
I0929 16:32:17.646447 25496 net.cpp:301] conv3_Eltwise_5 needs backward computation.
I0929 16:32:17.646453 25496 net.cpp:301] conv3_5_scale1 needs backward computation.
I0929 16:32:17.646457 25496 net.cpp:301] conv3_5bn1 needs backward computation.
I0929 16:32:17.646461 25496 net.cpp:301] conv3_5_1 needs backward computation.
I0929 16:32:17.646466 25496 net.cpp:301] conv3_5_ReLU0 needs backward computation.
I0929 16:32:17.646471 25496 net.cpp:301] conv3_5_scale0 needs backward computation.
I0929 16:32:17.646476 25496 net.cpp:301] conv3_5_bn0 needs backward computation.
I0929 16:32:17.646481 25496 net.cpp:301] conv3_5_0 needs backward computation.
I0929 16:32:17.646486 25496 net.cpp:301] conv3_Eltwise_4_conv3_4ReLU_1_0_split needs backward computation.
I0929 16:32:17.646490 25496 net.cpp:301] conv3_4ReLU_1 needs backward computation.
I0929 16:32:17.646494 25496 net.cpp:301] conv3_Eltwise_4 needs backward computation.
I0929 16:32:17.646500 25496 net.cpp:301] conv3_4_scale1 needs backward computation.
I0929 16:32:17.646504 25496 net.cpp:301] conv3_4bn1 needs backward computation.
I0929 16:32:17.646508 25496 net.cpp:301] conv3_4_1 needs backward computation.
I0929 16:32:17.646513 25496 net.cpp:301] conv3_4_ReLU0 needs backward computation.
I0929 16:32:17.646517 25496 net.cpp:301] conv3_4_scale0 needs backward computation.
I0929 16:32:17.646522 25496 net.cpp:301] conv3_4_bn0 needs backward computation.
I0929 16:32:17.646528 25496 net.cpp:301] conv3_4_0 needs backward computation.
I0929 16:32:17.646533 25496 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I0929 16:32:17.646536 25496 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I0929 16:32:17.646541 25496 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I0929 16:32:17.646546 25496 net.cpp:301] conv3_3_scale1 needs backward computation.
I0929 16:32:17.646553 25496 net.cpp:301] conv3_3bn1 needs backward computation.
I0929 16:32:17.646559 25496 net.cpp:301] conv3_3_1 needs backward computation.
I0929 16:32:17.646570 25496 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I0929 16:32:17.646576 25496 net.cpp:301] conv3_3_scale0 needs backward computation.
I0929 16:32:17.646580 25496 net.cpp:301] conv3_3_bn0 needs backward computation.
I0929 16:32:17.646584 25496 net.cpp:301] conv3_3_0 needs backward computation.
I0929 16:32:17.646589 25496 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I0929 16:32:17.646595 25496 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I0929 16:32:17.646600 25496 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I0929 16:32:17.646605 25496 net.cpp:301] conv3_2_scale1 needs backward computation.
I0929 16:32:17.646610 25496 net.cpp:301] conv3_2bn1 needs backward computation.
I0929 16:32:17.646613 25496 net.cpp:301] conv3_2_1 needs backward computation.
I0929 16:32:17.646618 25496 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I0929 16:32:17.646622 25496 net.cpp:301] conv3_2_scale0 needs backward computation.
I0929 16:32:17.646627 25496 net.cpp:301] conv3_2_bn0 needs backward computation.
I0929 16:32:17.646631 25496 net.cpp:301] conv3_2_0 needs backward computation.
I0929 16:32:17.646636 25496 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I0929 16:32:17.646641 25496 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I0929 16:32:17.646646 25496 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I0929 16:32:17.646651 25496 net.cpp:301] conv3_1_scale_down needs backward computation.
I0929 16:32:17.646656 25496 net.cpp:301] conv3_1_bn_down needs backward computation.
I0929 16:32:17.646661 25496 net.cpp:301] conv3_1_down needs backward computation.
I0929 16:32:17.646665 25496 net.cpp:301] conv3_1_scale1 needs backward computation.
I0929 16:32:17.646669 25496 net.cpp:301] conv3_1bn1 needs backward computation.
I0929 16:32:17.646674 25496 net.cpp:301] conv3_1_1 needs backward computation.
I0929 16:32:17.646678 25496 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I0929 16:32:17.646682 25496 net.cpp:301] conv3_1_scale0 needs backward computation.
I0929 16:32:17.646687 25496 net.cpp:301] conv3_1_bn0 needs backward computation.
I0929 16:32:17.646692 25496 net.cpp:301] conv3_1_0 needs backward computation.
I0929 16:32:17.646697 25496 net.cpp:301] conv2_Eltwise_5_conv2_5ReLU_1_0_split needs backward computation.
I0929 16:32:17.646701 25496 net.cpp:301] conv2_5ReLU_1 needs backward computation.
I0929 16:32:17.646705 25496 net.cpp:301] conv2_Eltwise_5 needs backward computation.
I0929 16:32:17.646711 25496 net.cpp:301] conv2_5_scale1 needs backward computation.
I0929 16:32:17.646715 25496 net.cpp:301] conv2_5bn1 needs backward computation.
I0929 16:32:17.646720 25496 net.cpp:301] conv2_5_1 needs backward computation.
I0929 16:32:17.646724 25496 net.cpp:301] conv2_5_ReLU0 needs backward computation.
I0929 16:32:17.646729 25496 net.cpp:301] conv2_5_scale0 needs backward computation.
I0929 16:32:17.646733 25496 net.cpp:301] conv2_5_bn0 needs backward computation.
I0929 16:32:17.646739 25496 net.cpp:301] conv2_5_0 needs backward computation.
I0929 16:32:17.646744 25496 net.cpp:301] conv2_Eltwise_4_conv2_4ReLU_1_0_split needs backward computation.
I0929 16:32:17.646749 25496 net.cpp:301] conv2_4ReLU_1 needs backward computation.
I0929 16:32:17.646752 25496 net.cpp:301] conv2_Eltwise_4 needs backward computation.
I0929 16:32:17.646757 25496 net.cpp:301] conv2_4_scale1 needs backward computation.
I0929 16:32:17.646762 25496 net.cpp:301] conv2_4bn1 needs backward computation.
I0929 16:32:17.646766 25496 net.cpp:301] conv2_4_1 needs backward computation.
I0929 16:32:17.646771 25496 net.cpp:301] conv2_4_ReLU0 needs backward computation.
I0929 16:32:17.646775 25496 net.cpp:301] conv2_4_scale0 needs backward computation.
I0929 16:32:17.646780 25496 net.cpp:301] conv2_4_bn0 needs backward computation.
I0929 16:32:17.646785 25496 net.cpp:301] conv2_4_0 needs backward computation.
I0929 16:32:17.646790 25496 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I0929 16:32:17.646811 25496 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I0929 16:32:17.646816 25496 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I0929 16:32:17.646821 25496 net.cpp:301] conv2_3_scale1 needs backward computation.
I0929 16:32:17.646826 25496 net.cpp:301] conv2_3bn1 needs backward computation.
I0929 16:32:17.646829 25496 net.cpp:301] conv2_3_1 needs backward computation.
I0929 16:32:17.646834 25496 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I0929 16:32:17.646838 25496 net.cpp:301] conv2_3_scale0 needs backward computation.
I0929 16:32:17.646843 25496 net.cpp:301] conv2_3_bn0 needs backward computation.
I0929 16:32:17.646847 25496 net.cpp:301] conv2_3_0 needs backward computation.
I0929 16:32:17.646852 25496 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I0929 16:32:17.646857 25496 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I0929 16:32:17.646862 25496 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I0929 16:32:17.646867 25496 net.cpp:301] conv2_2_scale1 needs backward computation.
I0929 16:32:17.646872 25496 net.cpp:301] conv2_2bn1 needs backward computation.
I0929 16:32:17.646876 25496 net.cpp:301] conv2_2_1 needs backward computation.
I0929 16:32:17.646881 25496 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I0929 16:32:17.646885 25496 net.cpp:301] conv2_2_scale0 needs backward computation.
I0929 16:32:17.646890 25496 net.cpp:301] conv2_2_bn0 needs backward computation.
I0929 16:32:17.646894 25496 net.cpp:301] conv2_2_0 needs backward computation.
I0929 16:32:17.646899 25496 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I0929 16:32:17.646904 25496 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I0929 16:32:17.646908 25496 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I0929 16:32:17.646914 25496 net.cpp:301] conv2_1_scale1 needs backward computation.
I0929 16:32:17.646919 25496 net.cpp:301] conv2_1bn1 needs backward computation.
I0929 16:32:17.646924 25496 net.cpp:301] conv2_1_1 needs backward computation.
I0929 16:32:17.646929 25496 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I0929 16:32:17.646932 25496 net.cpp:301] conv2_1_scale0 needs backward computation.
I0929 16:32:17.646937 25496 net.cpp:301] conv2_1_bn0 needs backward computation.
I0929 16:32:17.646948 25496 net.cpp:301] conv2_1_0 needs backward computation.
I0929 16:32:17.646953 25496 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I0929 16:32:17.646960 25496 net.cpp:301] conv1/ReLU needs backward computation.
I0929 16:32:17.646963 25496 net.cpp:301] conv1/scale needs backward computation.
I0929 16:32:17.646968 25496 net.cpp:301] conv1/bn needs backward computation.
I0929 16:32:17.646972 25496 net.cpp:301] conv1 needs backward computation.
I0929 16:32:17.646978 25496 net.cpp:303] Data1 does not need backward computation.
I0929 16:32:17.646982 25496 net.cpp:348] This network produces output Softmax1
I0929 16:32:17.647078 25496 net.cpp:363] Network initialization done.
I0929 16:32:17.659047 25496 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./test_ResNet_32.prototxt
I0929 16:32:17.659130 25496 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0929 16:32:17.659171 25496 solver.cpp:277] Creating test net (#0) specified by test_net file: ./test_ResNet_32.prototxt
I0929 16:32:17.664095 25496 net.cpp:82] Initializing net from parameters: 
name: "ResNet-32"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: false
    crop_size: 32
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/test_lmdb"
    batch_size: 10
    backend: LMDB
  }
  image_data_param {
    shuffle: false
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "conv2_1_1"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv2_4_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv2_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4_bn0"
  type: "BatchNorm"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_4_scale0"
  type: "Scale"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_4_ReLU0"
  type: "ReLU"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
}
layer {
  name: "conv2_4_1"
  type: "Convolution"
  bottom: "conv2_4_0"
  top: "conv2_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4bn1"
  type: "BatchNorm"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_4_scale1"
  type: "Scale"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_4"
  type: "Eltwise"
  bottom: "conv2_Eltwise_3"
  bottom: "conv2_4_1"
  top: "conv2_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_4ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_4"
  top: "conv2_Eltwise_4"
}
layer {
  name: "conv2_5_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_4"
  top: "conv2_5_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_5_bn0"
  type: "BatchNorm"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_5_scale0"
  type: "Scale"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_5_ReLU0"
  type: "ReLU"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
}
layer {
  name: "conv2_5_1"
  type: "Convolution"
  bottom: "conv2_5_0"
  top: "conv2_5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_5bn1"
  type: "BatchNorm"
  bottom: "conv2_5_1"
  top: "conv2_5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_5_scale1"
  type: "Scale"
  bottom: "conv2_5_1"
  top: "conv2_5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_5"
  type: "Eltwise"
  bottom: "conv2_Eltwise_4"
  bottom: "conv2_5_1"
  top: "conv2_Eltwise_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_5ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_5"
  top: "conv2_Eltwise_5"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_5"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_5"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv3_4_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv3_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4_bn0"
  type: "BatchNorm"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_scale0"
  type: "Scale"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_ReLU0"
  type: "ReLU"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
}
layer {
  name: "conv3_4_1"
  type: "Convolution"
  bottom: "conv3_4_0"
  top: "conv3_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4bn1"
  type: "BatchNorm"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_scale1"
  type: "Scale"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_4"
  type: "Eltwise"
  bottom: "conv3_Eltwise_3"
  bottom: "conv3_4_1"
  top: "conv3_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_4ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_4"
  top: "conv3_Eltwise_4"
}
layer {
  name: "conv3_5_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_4"
  top: "conv3_5_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_5_bn0"
  type: "BatchNorm"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_5_scale0"
  type: "Scale"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_5_ReLU0"
  type: "ReLU"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
}
layer {
  name: "conv3_5_1"
  type: "Convolution"
  bottom: "conv3_5_0"
  top: "conv3_5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_5bn1"
  type: "BatchNorm"
  bottom: "conv3_5_1"
  top: "conv3_5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_5_scale1"
  type: "Scale"
  bottom: "conv3_5_1"
  top: "conv3_5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_5"
  type: "Eltwise"
  bottom: "conv3_Eltwise_4"
  bottom: "conv3_5_1"
  top: "conv3_Eltwise_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_5ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_5"
  top: "conv3_Eltwise_5"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_5"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_5"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "conv4_4_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_3"
  top: "conv4_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_4_bn0"
  type: "BatchNorm"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4_scale0"
  type: "Scale"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name
I0929 16:32:17.666101 25496 layer_factory.hpp:77] Creating layer Data1
I0929 16:32:17.666198 25496 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/test_lmdb
I0929 16:32:17.666215 25496 net.cpp:128] Creating Layer Data1
I0929 16:32:17.666223 25496 net.cpp:522] Data1 -> data
I0929 16:32:17.666232 25496 net.cpp:522] Data1 -> label
I0929 16:32:17.666388 25496 data_layer.cpp:45] output data size: 10,3,32,32
I0929 16:32:17.673835 25496 net.cpp:172] Setting up Data1
I0929 16:32:17.673851 25496 net.cpp:186] Top shape: 10 3 32 32 (30720)
I0929 16:32:17.673856 25496 net.cpp:186] Top shape: 10 (10)
I0929 16:32:17.673861 25496 net.cpp:194] Memory required for data: 122920
I0929 16:32:17.673866 25496 layer_factory.hpp:77] Creating layer label_Data1_1_split
I0929 16:32:17.673874 25496 net.cpp:128] Creating Layer label_Data1_1_split
I0929 16:32:17.673878 25496 net.cpp:558] label_Data1_1_split <- label
I0929 16:32:17.673885 25496 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_0
I0929 16:32:17.673894 25496 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_1
I0929 16:32:17.673962 25496 net.cpp:172] Setting up label_Data1_1_split
I0929 16:32:17.673969 25496 net.cpp:186] Top shape: 10 (10)
I0929 16:32:17.673974 25496 net.cpp:186] Top shape: 10 (10)
I0929 16:32:17.673979 25496 net.cpp:194] Memory required for data: 123000
I0929 16:32:17.673982 25496 layer_factory.hpp:77] Creating layer conv1
I0929 16:32:17.673995 25496 net.cpp:128] Creating Layer conv1
I0929 16:32:17.674000 25496 net.cpp:558] conv1 <- data
I0929 16:32:17.674008 25496 net.cpp:522] conv1 -> conv1
I0929 16:32:17.682672 25496 net.cpp:172] Setting up conv1
I0929 16:32:17.682699 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.682704 25496 net.cpp:194] Memory required for data: 778360
I0929 16:32:17.682718 25496 layer_factory.hpp:77] Creating layer conv1/bn
I0929 16:32:17.682730 25496 net.cpp:128] Creating Layer conv1/bn
I0929 16:32:17.682735 25496 net.cpp:558] conv1/bn <- conv1
I0929 16:32:17.682744 25496 net.cpp:509] conv1/bn -> conv1 (in-place)
I0929 16:32:17.683035 25496 net.cpp:172] Setting up conv1/bn
I0929 16:32:17.683046 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.683050 25496 net.cpp:194] Memory required for data: 1433720
I0929 16:32:17.683068 25496 layer_factory.hpp:77] Creating layer conv1/scale
I0929 16:32:17.683079 25496 net.cpp:128] Creating Layer conv1/scale
I0929 16:32:17.683084 25496 net.cpp:558] conv1/scale <- conv1
I0929 16:32:17.683089 25496 net.cpp:509] conv1/scale -> conv1 (in-place)
I0929 16:32:17.683141 25496 layer_factory.hpp:77] Creating layer conv1/scale
I0929 16:32:17.683301 25496 net.cpp:172] Setting up conv1/scale
I0929 16:32:17.683308 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.683312 25496 net.cpp:194] Memory required for data: 2089080
I0929 16:32:17.683320 25496 layer_factory.hpp:77] Creating layer conv1/ReLU
I0929 16:32:17.683328 25496 net.cpp:128] Creating Layer conv1/ReLU
I0929 16:32:17.683333 25496 net.cpp:558] conv1/ReLU <- conv1
I0929 16:32:17.683338 25496 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I0929 16:32:17.683598 25496 net.cpp:172] Setting up conv1/ReLU
I0929 16:32:17.683611 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.683615 25496 net.cpp:194] Memory required for data: 2744440
I0929 16:32:17.683619 25496 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I0929 16:32:17.683646 25496 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I0929 16:32:17.683651 25496 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I0929 16:32:17.683660 25496 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I0929 16:32:17.683670 25496 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I0929 16:32:17.683723 25496 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I0929 16:32:17.683735 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.683742 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.683745 25496 net.cpp:194] Memory required for data: 4055160
I0929 16:32:17.683749 25496 layer_factory.hpp:77] Creating layer conv2_1_0
I0929 16:32:17.683761 25496 net.cpp:128] Creating Layer conv2_1_0
I0929 16:32:17.683766 25496 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I0929 16:32:17.683773 25496 net.cpp:522] conv2_1_0 -> conv2_1_0
I0929 16:32:17.689893 25496 net.cpp:172] Setting up conv2_1_0
I0929 16:32:17.689923 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.689944 25496 net.cpp:194] Memory required for data: 4710520
I0929 16:32:17.689962 25496 layer_factory.hpp:77] Creating layer conv2_1_bn0
I0929 16:32:17.689977 25496 net.cpp:128] Creating Layer conv2_1_bn0
I0929 16:32:17.689988 25496 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I0929 16:32:17.689997 25496 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I0929 16:32:17.690347 25496 net.cpp:172] Setting up conv2_1_bn0
I0929 16:32:17.690359 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.690366 25496 net.cpp:194] Memory required for data: 5365880
I0929 16:32:17.690379 25496 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0929 16:32:17.690387 25496 net.cpp:128] Creating Layer conv2_1_scale0
I0929 16:32:17.690392 25496 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I0929 16:32:17.690402 25496 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I0929 16:32:17.690462 25496 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0929 16:32:17.690659 25496 net.cpp:172] Setting up conv2_1_scale0
I0929 16:32:17.690672 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.690677 25496 net.cpp:194] Memory required for data: 6021240
I0929 16:32:17.690687 25496 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I0929 16:32:17.690695 25496 net.cpp:128] Creating Layer conv2_1_ReLU0
I0929 16:32:17.690701 25496 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I0929 16:32:17.690707 25496 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I0929 16:32:17.691517 25496 net.cpp:172] Setting up conv2_1_ReLU0
I0929 16:32:17.691537 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.691543 25496 net.cpp:194] Memory required for data: 6676600
I0929 16:32:17.691576 25496 layer_factory.hpp:77] Creating layer conv2_1_1
I0929 16:32:17.691606 25496 net.cpp:128] Creating Layer conv2_1_1
I0929 16:32:17.691687 25496 net.cpp:558] conv2_1_1 <- conv2_1_0
I0929 16:32:17.691701 25496 net.cpp:522] conv2_1_1 -> conv2_1_1
I0929 16:32:17.698381 25496 net.cpp:172] Setting up conv2_1_1
I0929 16:32:17.698415 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.698422 25496 net.cpp:194] Memory required for data: 7331960
I0929 16:32:17.698436 25496 layer_factory.hpp:77] Creating layer conv2_1bn1
I0929 16:32:17.698448 25496 net.cpp:128] Creating Layer conv2_1bn1
I0929 16:32:17.698456 25496 net.cpp:558] conv2_1bn1 <- conv2_1_1
I0929 16:32:17.698468 25496 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I0929 16:32:17.698895 25496 net.cpp:172] Setting up conv2_1bn1
I0929 16:32:17.698911 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.698917 25496 net.cpp:194] Memory required for data: 7987320
I0929 16:32:17.698935 25496 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0929 16:32:17.698951 25496 net.cpp:128] Creating Layer conv2_1_scale1
I0929 16:32:17.698958 25496 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I0929 16:32:17.698966 25496 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I0929 16:32:17.699044 25496 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0929 16:32:17.699307 25496 net.cpp:172] Setting up conv2_1_scale1
I0929 16:32:17.699323 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.699329 25496 net.cpp:194] Memory required for data: 8642680
I0929 16:32:17.699342 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I0929 16:32:17.699352 25496 net.cpp:128] Creating Layer conv2_Eltwise_1
I0929 16:32:17.699358 25496 net.cpp:558] conv2_Eltwise_1 <- conv1_conv1/ReLU_0_split_1
I0929 16:32:17.699367 25496 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I0929 16:32:17.699379 25496 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I0929 16:32:17.699424 25496 net.cpp:172] Setting up conv2_Eltwise_1
I0929 16:32:17.699435 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.699441 25496 net.cpp:194] Memory required for data: 9298040
I0929 16:32:17.699447 25496 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I0929 16:32:17.699456 25496 net.cpp:128] Creating Layer conv2_1ReLU_1
I0929 16:32:17.699462 25496 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I0929 16:32:17.699473 25496 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I0929 16:32:17.700387 25496 net.cpp:172] Setting up conv2_1ReLU_1
I0929 16:32:17.700423 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.700430 25496 net.cpp:194] Memory required for data: 9953400
I0929 16:32:17.700438 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 16:32:17.700453 25496 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 16:32:17.700460 25496 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I0929 16:32:17.700471 25496 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0929 16:32:17.700484 25496 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0929 16:32:17.700570 25496 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0929 16:32:17.700587 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.700595 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.700601 25496 net.cpp:194] Memory required for data: 11264120
I0929 16:32:17.700608 25496 layer_factory.hpp:77] Creating layer conv2_2_0
I0929 16:32:17.700625 25496 net.cpp:128] Creating Layer conv2_2_0
I0929 16:32:17.700633 25496 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0929 16:32:17.700647 25496 net.cpp:522] conv2_2_0 -> conv2_2_0
I0929 16:32:17.707146 25496 net.cpp:172] Setting up conv2_2_0
I0929 16:32:17.707172 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.707176 25496 net.cpp:194] Memory required for data: 11919480
I0929 16:32:17.707186 25496 layer_factory.hpp:77] Creating layer conv2_2_bn0
I0929 16:32:17.707195 25496 net.cpp:128] Creating Layer conv2_2_bn0
I0929 16:32:17.707199 25496 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I0929 16:32:17.707208 25496 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I0929 16:32:17.707497 25496 net.cpp:172] Setting up conv2_2_bn0
I0929 16:32:17.707509 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.707514 25496 net.cpp:194] Memory required for data: 12574840
I0929 16:32:17.707522 25496 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0929 16:32:17.707531 25496 net.cpp:128] Creating Layer conv2_2_scale0
I0929 16:32:17.707535 25496 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I0929 16:32:17.707543 25496 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I0929 16:32:17.707592 25496 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0929 16:32:17.707748 25496 net.cpp:172] Setting up conv2_2_scale0
I0929 16:32:17.707756 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.707761 25496 net.cpp:194] Memory required for data: 13230200
I0929 16:32:17.707768 25496 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I0929 16:32:17.707774 25496 net.cpp:128] Creating Layer conv2_2_ReLU0
I0929 16:32:17.707778 25496 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I0929 16:32:17.707783 25496 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I0929 16:32:17.709214 25496 net.cpp:172] Setting up conv2_2_ReLU0
I0929 16:32:17.709234 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.709239 25496 net.cpp:194] Memory required for data: 13885560
I0929 16:32:17.709244 25496 layer_factory.hpp:77] Creating layer conv2_2_1
I0929 16:32:17.709257 25496 net.cpp:128] Creating Layer conv2_2_1
I0929 16:32:17.709262 25496 net.cpp:558] conv2_2_1 <- conv2_2_0
I0929 16:32:17.709272 25496 net.cpp:522] conv2_2_1 -> conv2_2_1
I0929 16:32:17.716004 25496 net.cpp:172] Setting up conv2_2_1
I0929 16:32:17.716030 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.716034 25496 net.cpp:194] Memory required for data: 14540920
I0929 16:32:17.716044 25496 layer_factory.hpp:77] Creating layer conv2_2bn1
I0929 16:32:17.716055 25496 net.cpp:128] Creating Layer conv2_2bn1
I0929 16:32:17.716060 25496 net.cpp:558] conv2_2bn1 <- conv2_2_1
I0929 16:32:17.716069 25496 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I0929 16:32:17.716359 25496 net.cpp:172] Setting up conv2_2bn1
I0929 16:32:17.716372 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.716377 25496 net.cpp:194] Memory required for data: 15196280
I0929 16:32:17.716392 25496 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0929 16:32:17.716399 25496 net.cpp:128] Creating Layer conv2_2_scale1
I0929 16:32:17.716403 25496 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I0929 16:32:17.716410 25496 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I0929 16:32:17.716460 25496 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0929 16:32:17.716617 25496 net.cpp:172] Setting up conv2_2_scale1
I0929 16:32:17.716629 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.716634 25496 net.cpp:194] Memory required for data: 15851640
I0929 16:32:17.716641 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I0929 16:32:17.716650 25496 net.cpp:128] Creating Layer conv2_Eltwise_2
I0929 16:32:17.716655 25496 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0929 16:32:17.716660 25496 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I0929 16:32:17.716668 25496 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I0929 16:32:17.716697 25496 net.cpp:172] Setting up conv2_Eltwise_2
I0929 16:32:17.716703 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.716707 25496 net.cpp:194] Memory required for data: 16507000
I0929 16:32:17.716711 25496 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I0929 16:32:17.716717 25496 net.cpp:128] Creating Layer conv2_2ReLU_1
I0929 16:32:17.716722 25496 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I0929 16:32:17.716729 25496 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I0929 16:32:17.718068 25496 net.cpp:172] Setting up conv2_2ReLU_1
I0929 16:32:17.718086 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.718091 25496 net.cpp:194] Memory required for data: 17162360
I0929 16:32:17.718097 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 16:32:17.718108 25496 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 16:32:17.718113 25496 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I0929 16:32:17.718120 25496 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0929 16:32:17.718130 25496 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0929 16:32:17.718190 25496 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0929 16:32:17.718199 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.718205 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.718209 25496 net.cpp:194] Memory required for data: 18473080
I0929 16:32:17.718214 25496 layer_factory.hpp:77] Creating layer conv2_3_0
I0929 16:32:17.718225 25496 net.cpp:128] Creating Layer conv2_3_0
I0929 16:32:17.718230 25496 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0929 16:32:17.718240 25496 net.cpp:522] conv2_3_0 -> conv2_3_0
I0929 16:32:17.724831 25496 net.cpp:172] Setting up conv2_3_0
I0929 16:32:17.724858 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.724862 25496 net.cpp:194] Memory required for data: 19128440
I0929 16:32:17.724871 25496 layer_factory.hpp:77] Creating layer conv2_3_bn0
I0929 16:32:17.724882 25496 net.cpp:128] Creating Layer conv2_3_bn0
I0929 16:32:17.724887 25496 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I0929 16:32:17.724897 25496 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I0929 16:32:17.725191 25496 net.cpp:172] Setting up conv2_3_bn0
I0929 16:32:17.725203 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.725208 25496 net.cpp:194] Memory required for data: 19783800
I0929 16:32:17.725219 25496 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0929 16:32:17.725224 25496 net.cpp:128] Creating Layer conv2_3_scale0
I0929 16:32:17.725229 25496 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I0929 16:32:17.725234 25496 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I0929 16:32:17.725286 25496 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0929 16:32:17.725440 25496 net.cpp:172] Setting up conv2_3_scale0
I0929 16:32:17.725447 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.725451 25496 net.cpp:194] Memory required for data: 20439160
I0929 16:32:17.725459 25496 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I0929 16:32:17.725467 25496 net.cpp:128] Creating Layer conv2_3_ReLU0
I0929 16:32:17.725472 25496 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I0929 16:32:17.725477 25496 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I0929 16:32:17.726891 25496 net.cpp:172] Setting up conv2_3_ReLU0
I0929 16:32:17.726909 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.726913 25496 net.cpp:194] Memory required for data: 21094520
I0929 16:32:17.726917 25496 layer_factory.hpp:77] Creating layer conv2_3_1
I0929 16:32:17.726930 25496 net.cpp:128] Creating Layer conv2_3_1
I0929 16:32:17.726935 25496 net.cpp:558] conv2_3_1 <- conv2_3_0
I0929 16:32:17.726945 25496 net.cpp:522] conv2_3_1 -> conv2_3_1
I0929 16:32:17.733675 25496 net.cpp:172] Setting up conv2_3_1
I0929 16:32:17.733700 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.733705 25496 net.cpp:194] Memory required for data: 21749880
I0929 16:32:17.733714 25496 layer_factory.hpp:77] Creating layer conv2_3bn1
I0929 16:32:17.733728 25496 net.cpp:128] Creating Layer conv2_3bn1
I0929 16:32:17.733734 25496 net.cpp:558] conv2_3bn1 <- conv2_3_1
I0929 16:32:17.733741 25496 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I0929 16:32:17.734037 25496 net.cpp:172] Setting up conv2_3bn1
I0929 16:32:17.734050 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.734055 25496 net.cpp:194] Memory required for data: 22405240
I0929 16:32:17.734064 25496 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0929 16:32:17.734071 25496 net.cpp:128] Creating Layer conv2_3_scale1
I0929 16:32:17.734076 25496 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I0929 16:32:17.734084 25496 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I0929 16:32:17.734135 25496 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0929 16:32:17.734292 25496 net.cpp:172] Setting up conv2_3_scale1
I0929 16:32:17.734302 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.734306 25496 net.cpp:194] Memory required for data: 23060600
I0929 16:32:17.734313 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I0929 16:32:17.734320 25496 net.cpp:128] Creating Layer conv2_Eltwise_3
I0929 16:32:17.734325 25496 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0929 16:32:17.734330 25496 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I0929 16:32:17.734339 25496 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I0929 16:32:17.734367 25496 net.cpp:172] Setting up conv2_Eltwise_3
I0929 16:32:17.734376 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.734380 25496 net.cpp:194] Memory required for data: 23715960
I0929 16:32:17.734385 25496 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I0929 16:32:17.734405 25496 net.cpp:128] Creating Layer conv2_3ReLU_1
I0929 16:32:17.734411 25496 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I0929 16:32:17.734416 25496 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I0929 16:32:17.735739 25496 net.cpp:172] Setting up conv2_3ReLU_1
I0929 16:32:17.735764 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.735767 25496 net.cpp:194] Memory required for data: 24371320
I0929 16:32:17.735772 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 16:32:17.735783 25496 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 16:32:17.735790 25496 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I0929 16:32:17.735797 25496 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0929 16:32:17.735808 25496 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0929 16:32:17.735867 25496 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0929 16:32:17.735875 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.735880 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.735884 25496 net.cpp:194] Memory required for data: 25682040
I0929 16:32:17.735888 25496 layer_factory.hpp:77] Creating layer conv2_4_0
I0929 16:32:17.735900 25496 net.cpp:128] Creating Layer conv2_4_0
I0929 16:32:17.735905 25496 net.cpp:558] conv2_4_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0929 16:32:17.735914 25496 net.cpp:522] conv2_4_0 -> conv2_4_0
I0929 16:32:17.742511 25496 net.cpp:172] Setting up conv2_4_0
I0929 16:32:17.742537 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.742542 25496 net.cpp:194] Memory required for data: 26337400
I0929 16:32:17.742550 25496 layer_factory.hpp:77] Creating layer conv2_4_bn0
I0929 16:32:17.742561 25496 net.cpp:128] Creating Layer conv2_4_bn0
I0929 16:32:17.742566 25496 net.cpp:558] conv2_4_bn0 <- conv2_4_0
I0929 16:32:17.742573 25496 net.cpp:509] conv2_4_bn0 -> conv2_4_0 (in-place)
I0929 16:32:17.742862 25496 net.cpp:172] Setting up conv2_4_bn0
I0929 16:32:17.742874 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.742880 25496 net.cpp:194] Memory required for data: 26992760
I0929 16:32:17.742890 25496 layer_factory.hpp:77] Creating layer conv2_4_scale0
I0929 16:32:17.742897 25496 net.cpp:128] Creating Layer conv2_4_scale0
I0929 16:32:17.742902 25496 net.cpp:558] conv2_4_scale0 <- conv2_4_0
I0929 16:32:17.742908 25496 net.cpp:509] conv2_4_scale0 -> conv2_4_0 (in-place)
I0929 16:32:17.742960 25496 layer_factory.hpp:77] Creating layer conv2_4_scale0
I0929 16:32:17.743121 25496 net.cpp:172] Setting up conv2_4_scale0
I0929 16:32:17.743129 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.743132 25496 net.cpp:194] Memory required for data: 27648120
I0929 16:32:17.743140 25496 layer_factory.hpp:77] Creating layer conv2_4_ReLU0
I0929 16:32:17.743146 25496 net.cpp:128] Creating Layer conv2_4_ReLU0
I0929 16:32:17.743151 25496 net.cpp:558] conv2_4_ReLU0 <- conv2_4_0
I0929 16:32:17.743160 25496 net.cpp:509] conv2_4_ReLU0 -> conv2_4_0 (in-place)
I0929 16:32:17.744552 25496 net.cpp:172] Setting up conv2_4_ReLU0
I0929 16:32:17.744568 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.744572 25496 net.cpp:194] Memory required for data: 28303480
I0929 16:32:17.744577 25496 layer_factory.hpp:77] Creating layer conv2_4_1
I0929 16:32:17.744596 25496 net.cpp:128] Creating Layer conv2_4_1
I0929 16:32:17.744601 25496 net.cpp:558] conv2_4_1 <- conv2_4_0
I0929 16:32:17.744611 25496 net.cpp:522] conv2_4_1 -> conv2_4_1
I0929 16:32:17.751513 25496 net.cpp:172] Setting up conv2_4_1
I0929 16:32:17.751540 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.751544 25496 net.cpp:194] Memory required for data: 28958840
I0929 16:32:17.751554 25496 layer_factory.hpp:77] Creating layer conv2_4bn1
I0929 16:32:17.751564 25496 net.cpp:128] Creating Layer conv2_4bn1
I0929 16:32:17.751569 25496 net.cpp:558] conv2_4bn1 <- conv2_4_1
I0929 16:32:17.751596 25496 net.cpp:509] conv2_4bn1 -> conv2_4_1 (in-place)
I0929 16:32:17.751904 25496 net.cpp:172] Setting up conv2_4bn1
I0929 16:32:17.751917 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.751922 25496 net.cpp:194] Memory required for data: 29614200
I0929 16:32:17.751932 25496 layer_factory.hpp:77] Creating layer conv2_4_scale1
I0929 16:32:17.751940 25496 net.cpp:128] Creating Layer conv2_4_scale1
I0929 16:32:17.751943 25496 net.cpp:558] conv2_4_scale1 <- conv2_4_1
I0929 16:32:17.751951 25496 net.cpp:509] conv2_4_scale1 -> conv2_4_1 (in-place)
I0929 16:32:17.752002 25496 layer_factory.hpp:77] Creating layer conv2_4_scale1
I0929 16:32:17.752162 25496 net.cpp:172] Setting up conv2_4_scale1
I0929 16:32:17.752173 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.752178 25496 net.cpp:194] Memory required for data: 30269560
I0929 16:32:17.752185 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_4
I0929 16:32:17.752192 25496 net.cpp:128] Creating Layer conv2_Eltwise_4
I0929 16:32:17.752197 25496 net.cpp:558] conv2_Eltwise_4 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0929 16:32:17.752202 25496 net.cpp:558] conv2_Eltwise_4 <- conv2_4_1
I0929 16:32:17.752213 25496 net.cpp:522] conv2_Eltwise_4 -> conv2_Eltwise_4
I0929 16:32:17.752243 25496 net.cpp:172] Setting up conv2_Eltwise_4
I0929 16:32:17.752252 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.752256 25496 net.cpp:194] Memory required for data: 30924920
I0929 16:32:17.752260 25496 layer_factory.hpp:77] Creating layer conv2_4ReLU_1
I0929 16:32:17.752266 25496 net.cpp:128] Creating Layer conv2_4ReLU_1
I0929 16:32:17.752270 25496 net.cpp:558] conv2_4ReLU_1 <- conv2_Eltwise_4
I0929 16:32:17.752276 25496 net.cpp:509] conv2_4ReLU_1 -> conv2_Eltwise_4 (in-place)
I0929 16:32:17.753355 25496 net.cpp:172] Setting up conv2_4ReLU_1
I0929 16:32:17.753371 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.753376 25496 net.cpp:194] Memory required for data: 31580280
I0929 16:32:17.753381 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0929 16:32:17.753391 25496 net.cpp:128] Creating Layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0929 16:32:17.753396 25496 net.cpp:558] conv2_Eltwise_4_conv2_4ReLU_1_0_split <- conv2_Eltwise_4
I0929 16:32:17.753401 25496 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I0929 16:32:17.753412 25496 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I0929 16:32:17.753469 25496 net.cpp:172] Setting up conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0929 16:32:17.753476 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.753482 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.753486 25496 net.cpp:194] Memory required for data: 32891000
I0929 16:32:17.753490 25496 layer_factory.hpp:77] Creating layer conv2_5_0
I0929 16:32:17.753504 25496 net.cpp:128] Creating Layer conv2_5_0
I0929 16:32:17.753509 25496 net.cpp:558] conv2_5_0 <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I0929 16:32:17.753516 25496 net.cpp:522] conv2_5_0 -> conv2_5_0
I0929 16:32:17.760124 25496 net.cpp:172] Setting up conv2_5_0
I0929 16:32:17.760150 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.760155 25496 net.cpp:194] Memory required for data: 33546360
I0929 16:32:17.760174 25496 layer_factory.hpp:77] Creating layer conv2_5_bn0
I0929 16:32:17.760185 25496 net.cpp:128] Creating Layer conv2_5_bn0
I0929 16:32:17.760190 25496 net.cpp:558] conv2_5_bn0 <- conv2_5_0
I0929 16:32:17.760196 25496 net.cpp:509] conv2_5_bn0 -> conv2_5_0 (in-place)
I0929 16:32:17.760495 25496 net.cpp:172] Setting up conv2_5_bn0
I0929 16:32:17.760507 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.760511 25496 net.cpp:194] Memory required for data: 34201720
I0929 16:32:17.760521 25496 layer_factory.hpp:77] Creating layer conv2_5_scale0
I0929 16:32:17.760530 25496 net.cpp:128] Creating Layer conv2_5_scale0
I0929 16:32:17.760536 25496 net.cpp:558] conv2_5_scale0 <- conv2_5_0
I0929 16:32:17.760557 25496 net.cpp:509] conv2_5_scale0 -> conv2_5_0 (in-place)
I0929 16:32:17.760613 25496 layer_factory.hpp:77] Creating layer conv2_5_scale0
I0929 16:32:17.760773 25496 net.cpp:172] Setting up conv2_5_scale0
I0929 16:32:17.760782 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.760785 25496 net.cpp:194] Memory required for data: 34857080
I0929 16:32:17.760793 25496 layer_factory.hpp:77] Creating layer conv2_5_ReLU0
I0929 16:32:17.760803 25496 net.cpp:128] Creating Layer conv2_5_ReLU0
I0929 16:32:17.760808 25496 net.cpp:558] conv2_5_ReLU0 <- conv2_5_0
I0929 16:32:17.760813 25496 net.cpp:509] conv2_5_ReLU0 -> conv2_5_0 (in-place)
I0929 16:32:17.762194 25496 net.cpp:172] Setting up conv2_5_ReLU0
I0929 16:32:17.762218 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.762223 25496 net.cpp:194] Memory required for data: 35512440
I0929 16:32:17.762228 25496 layer_factory.hpp:77] Creating layer conv2_5_1
I0929 16:32:17.762243 25496 net.cpp:128] Creating Layer conv2_5_1
I0929 16:32:17.762249 25496 net.cpp:558] conv2_5_1 <- conv2_5_0
I0929 16:32:17.762256 25496 net.cpp:522] conv2_5_1 -> conv2_5_1
I0929 16:32:17.768975 25496 net.cpp:172] Setting up conv2_5_1
I0929 16:32:17.769001 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.769006 25496 net.cpp:194] Memory required for data: 36167800
I0929 16:32:17.769016 25496 layer_factory.hpp:77] Creating layer conv2_5bn1
I0929 16:32:17.769026 25496 net.cpp:128] Creating Layer conv2_5bn1
I0929 16:32:17.769032 25496 net.cpp:558] conv2_5bn1 <- conv2_5_1
I0929 16:32:17.769038 25496 net.cpp:509] conv2_5bn1 -> conv2_5_1 (in-place)
I0929 16:32:17.769335 25496 net.cpp:172] Setting up conv2_5bn1
I0929 16:32:17.769347 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.769351 25496 net.cpp:194] Memory required for data: 36823160
I0929 16:32:17.769361 25496 layer_factory.hpp:77] Creating layer conv2_5_scale1
I0929 16:32:17.769368 25496 net.cpp:128] Creating Layer conv2_5_scale1
I0929 16:32:17.769372 25496 net.cpp:558] conv2_5_scale1 <- conv2_5_1
I0929 16:32:17.769378 25496 net.cpp:509] conv2_5_scale1 -> conv2_5_1 (in-place)
I0929 16:32:17.769433 25496 layer_factory.hpp:77] Creating layer conv2_5_scale1
I0929 16:32:17.769596 25496 net.cpp:172] Setting up conv2_5_scale1
I0929 16:32:17.769603 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.769608 25496 net.cpp:194] Memory required for data: 37478520
I0929 16:32:17.769615 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_5
I0929 16:32:17.769621 25496 net.cpp:128] Creating Layer conv2_Eltwise_5
I0929 16:32:17.769629 25496 net.cpp:558] conv2_Eltwise_5 <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I0929 16:32:17.769635 25496 net.cpp:558] conv2_Eltwise_5 <- conv2_5_1
I0929 16:32:17.769641 25496 net.cpp:522] conv2_Eltwise_5 -> conv2_Eltwise_5
I0929 16:32:17.769672 25496 net.cpp:172] Setting up conv2_Eltwise_5
I0929 16:32:17.769680 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.769683 25496 net.cpp:194] Memory required for data: 38133880
I0929 16:32:17.769688 25496 layer_factory.hpp:77] Creating layer conv2_5ReLU_1
I0929 16:32:17.769695 25496 net.cpp:128] Creating Layer conv2_5ReLU_1
I0929 16:32:17.769698 25496 net.cpp:558] conv2_5ReLU_1 <- conv2_Eltwise_5
I0929 16:32:17.769706 25496 net.cpp:509] conv2_5ReLU_1 -> conv2_Eltwise_5 (in-place)
I0929 16:32:17.771034 25496 net.cpp:172] Setting up conv2_5ReLU_1
I0929 16:32:17.771050 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.771056 25496 net.cpp:194] Memory required for data: 38789240
I0929 16:32:17.771061 25496 layer_factory.hpp:77] Creating layer conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0929 16:32:17.771075 25496 net.cpp:128] Creating Layer conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0929 16:32:17.771080 25496 net.cpp:558] conv2_Eltwise_5_conv2_5ReLU_1_0_split <- conv2_Eltwise_5
I0929 16:32:17.771088 25496 net.cpp:522] conv2_Eltwise_5_conv2_5ReLU_1_0_split -> conv2_Eltwise_5_conv2_5ReLU_1_0_split_0
I0929 16:32:17.771097 25496 net.cpp:522] conv2_Eltwise_5_conv2_5ReLU_1_0_split -> conv2_Eltwise_5_conv2_5ReLU_1_0_split_1
I0929 16:32:17.771174 25496 net.cpp:172] Setting up conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0929 16:32:17.771181 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.771188 25496 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0929 16:32:17.771191 25496 net.cpp:194] Memory required for data: 40099960
I0929 16:32:17.771195 25496 layer_factory.hpp:77] Creating layer conv3_1_0
I0929 16:32:17.771209 25496 net.cpp:128] Creating Layer conv3_1_0
I0929 16:32:17.771214 25496 net.cpp:558] conv3_1_0 <- conv2_Eltwise_5_conv2_5ReLU_1_0_split_0
I0929 16:32:17.771225 25496 net.cpp:522] conv3_1_0 -> conv3_1_0
I0929 16:32:17.777843 25496 net.cpp:172] Setting up conv3_1_0
I0929 16:32:17.777870 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.777875 25496 net.cpp:194] Memory required for data: 40427640
I0929 16:32:17.777884 25496 layer_factory.hpp:77] Creating layer conv3_1_bn0
I0929 16:32:17.777895 25496 net.cpp:128] Creating Layer conv3_1_bn0
I0929 16:32:17.777900 25496 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I0929 16:32:17.777909 25496 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I0929 16:32:17.778213 25496 net.cpp:172] Setting up conv3_1_bn0
I0929 16:32:17.778225 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.778229 25496 net.cpp:194] Memory required for data: 40755320
I0929 16:32:17.778239 25496 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0929 16:32:17.778249 25496 net.cpp:128] Creating Layer conv3_1_scale0
I0929 16:32:17.778254 25496 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I0929 16:32:17.778259 25496 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I0929 16:32:17.778313 25496 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0929 16:32:17.778475 25496 net.cpp:172] Setting up conv3_1_scale0
I0929 16:32:17.778487 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.778491 25496 net.cpp:194] Memory required for data: 41083000
I0929 16:32:17.778499 25496 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I0929 16:32:17.778511 25496 net.cpp:128] Creating Layer conv3_1_ReLU0
I0929 16:32:17.778515 25496 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I0929 16:32:17.778522 25496 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I0929 16:32:17.779868 25496 net.cpp:172] Setting up conv3_1_ReLU0
I0929 16:32:17.779884 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.779888 25496 net.cpp:194] Memory required for data: 41410680
I0929 16:32:17.779893 25496 layer_factory.hpp:77] Creating layer conv3_1_1
I0929 16:32:17.779913 25496 net.cpp:128] Creating Layer conv3_1_1
I0929 16:32:17.779918 25496 net.cpp:558] conv3_1_1 <- conv3_1_0
I0929 16:32:17.779925 25496 net.cpp:522] conv3_1_1 -> conv3_1_1
I0929 16:32:17.786638 25496 net.cpp:172] Setting up conv3_1_1
I0929 16:32:17.786674 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.786679 25496 net.cpp:194] Memory required for data: 41738360
I0929 16:32:17.786687 25496 layer_factory.hpp:77] Creating layer conv3_1bn1
I0929 16:32:17.786700 25496 net.cpp:128] Creating Layer conv3_1bn1
I0929 16:32:17.786705 25496 net.cpp:558] conv3_1bn1 <- conv3_1_1
I0929 16:32:17.786713 25496 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I0929 16:32:17.787000 25496 net.cpp:172] Setting up conv3_1bn1
I0929 16:32:17.787014 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.787017 25496 net.cpp:194] Memory required for data: 42066040
I0929 16:32:17.787027 25496 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0929 16:32:17.787034 25496 net.cpp:128] Creating Layer conv3_1_scale1
I0929 16:32:17.787039 25496 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I0929 16:32:17.787047 25496 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I0929 16:32:17.787101 25496 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0929 16:32:17.787261 25496 net.cpp:172] Setting up conv3_1_scale1
I0929 16:32:17.787268 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.787272 25496 net.cpp:194] Memory required for data: 42393720
I0929 16:32:17.787281 25496 layer_factory.hpp:77] Creating layer conv3_1_down
I0929 16:32:17.787310 25496 net.cpp:128] Creating Layer conv3_1_down
I0929 16:32:17.787315 25496 net.cpp:558] conv3_1_down <- conv2_Eltwise_5_conv2_5ReLU_1_0_split_1
I0929 16:32:17.787323 25496 net.cpp:522] conv3_1_down -> conv3_1_down
I0929 16:32:17.790616 25496 net.cpp:172] Setting up conv3_1_down
I0929 16:32:17.790647 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.790652 25496 net.cpp:194] Memory required for data: 42721400
I0929 16:32:17.790661 25496 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I0929 16:32:17.790670 25496 net.cpp:128] Creating Layer conv3_1_bn_down
I0929 16:32:17.790675 25496 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I0929 16:32:17.790685 25496 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I0929 16:32:17.790972 25496 net.cpp:172] Setting up conv3_1_bn_down
I0929 16:32:17.790984 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.790988 25496 net.cpp:194] Memory required for data: 43049080
I0929 16:32:17.790998 25496 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0929 16:32:17.791005 25496 net.cpp:128] Creating Layer conv3_1_scale_down
I0929 16:32:17.791009 25496 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I0929 16:32:17.791015 25496 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I0929 16:32:17.791067 25496 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0929 16:32:17.791229 25496 net.cpp:172] Setting up conv3_1_scale_down
I0929 16:32:17.791242 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.791247 25496 net.cpp:194] Memory required for data: 43376760
I0929 16:32:17.791254 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I0929 16:32:17.791261 25496 net.cpp:128] Creating Layer conv3_Eltwise_1
I0929 16:32:17.791265 25496 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I0929 16:32:17.791270 25496 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I0929 16:32:17.791276 25496 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I0929 16:32:17.791303 25496 net.cpp:172] Setting up conv3_Eltwise_1
I0929 16:32:17.791309 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.791313 25496 net.cpp:194] Memory required for data: 43704440
I0929 16:32:17.791317 25496 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I0929 16:32:17.791323 25496 net.cpp:128] Creating Layer conv3_1ReLU_1
I0929 16:32:17.791328 25496 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I0929 16:32:17.791335 25496 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I0929 16:32:17.792666 25496 net.cpp:172] Setting up conv3_1ReLU_1
I0929 16:32:17.792690 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.792693 25496 net.cpp:194] Memory required for data: 44032120
I0929 16:32:17.792699 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 16:32:17.792706 25496 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 16:32:17.792712 25496 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I0929 16:32:17.792722 25496 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0929 16:32:17.792732 25496 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0929 16:32:17.792793 25496 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0929 16:32:17.792800 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.792806 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.792810 25496 net.cpp:194] Memory required for data: 44687480
I0929 16:32:17.792814 25496 layer_factory.hpp:77] Creating layer conv3_2_0
I0929 16:32:17.792827 25496 net.cpp:128] Creating Layer conv3_2_0
I0929 16:32:17.792832 25496 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0929 16:32:17.792841 25496 net.cpp:522] conv3_2_0 -> conv3_2_0
I0929 16:32:17.799644 25496 net.cpp:172] Setting up conv3_2_0
I0929 16:32:17.799671 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.799675 25496 net.cpp:194] Memory required for data: 45015160
I0929 16:32:17.799702 25496 layer_factory.hpp:77] Creating layer conv3_2_bn0
I0929 16:32:17.799713 25496 net.cpp:128] Creating Layer conv3_2_bn0
I0929 16:32:17.799718 25496 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I0929 16:32:17.799726 25496 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I0929 16:32:17.800019 25496 net.cpp:172] Setting up conv3_2_bn0
I0929 16:32:17.800029 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.800034 25496 net.cpp:194] Memory required for data: 45342840
I0929 16:32:17.800043 25496 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0929 16:32:17.800051 25496 net.cpp:128] Creating Layer conv3_2_scale0
I0929 16:32:17.800056 25496 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I0929 16:32:17.800065 25496 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I0929 16:32:17.800117 25496 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0929 16:32:17.800287 25496 net.cpp:172] Setting up conv3_2_scale0
I0929 16:32:17.800297 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.800300 25496 net.cpp:194] Memory required for data: 45670520
I0929 16:32:17.800308 25496 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I0929 16:32:17.800315 25496 net.cpp:128] Creating Layer conv3_2_ReLU0
I0929 16:32:17.800319 25496 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I0929 16:32:17.800326 25496 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I0929 16:32:17.801492 25496 net.cpp:172] Setting up conv3_2_ReLU0
I0929 16:32:17.801509 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.801515 25496 net.cpp:194] Memory required for data: 45998200
I0929 16:32:17.801519 25496 layer_factory.hpp:77] Creating layer conv3_2_1
I0929 16:32:17.801532 25496 net.cpp:128] Creating Layer conv3_2_1
I0929 16:32:17.801537 25496 net.cpp:558] conv3_2_1 <- conv3_2_0
I0929 16:32:17.801548 25496 net.cpp:522] conv3_2_1 -> conv3_2_1
I0929 16:32:17.808284 25496 net.cpp:172] Setting up conv3_2_1
I0929 16:32:17.808315 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.808320 25496 net.cpp:194] Memory required for data: 46325880
I0929 16:32:17.808331 25496 layer_factory.hpp:77] Creating layer conv3_2bn1
I0929 16:32:17.808341 25496 net.cpp:128] Creating Layer conv3_2bn1
I0929 16:32:17.808344 25496 net.cpp:558] conv3_2bn1 <- conv3_2_1
I0929 16:32:17.808354 25496 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I0929 16:32:17.808651 25496 net.cpp:172] Setting up conv3_2bn1
I0929 16:32:17.808661 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.808666 25496 net.cpp:194] Memory required for data: 46653560
I0929 16:32:17.808676 25496 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0929 16:32:17.808683 25496 net.cpp:128] Creating Layer conv3_2_scale1
I0929 16:32:17.808687 25496 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I0929 16:32:17.808693 25496 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I0929 16:32:17.808749 25496 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0929 16:32:17.808918 25496 net.cpp:172] Setting up conv3_2_scale1
I0929 16:32:17.808929 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.808933 25496 net.cpp:194] Memory required for data: 46981240
I0929 16:32:17.808941 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I0929 16:32:17.808950 25496 net.cpp:128] Creating Layer conv3_Eltwise_2
I0929 16:32:17.808955 25496 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0929 16:32:17.808961 25496 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I0929 16:32:17.808967 25496 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I0929 16:32:17.808995 25496 net.cpp:172] Setting up conv3_Eltwise_2
I0929 16:32:17.809002 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.809005 25496 net.cpp:194] Memory required for data: 47308920
I0929 16:32:17.809010 25496 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I0929 16:32:17.809016 25496 net.cpp:128] Creating Layer conv3_2ReLU_1
I0929 16:32:17.809020 25496 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I0929 16:32:17.809028 25496 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I0929 16:32:17.810340 25496 net.cpp:172] Setting up conv3_2ReLU_1
I0929 16:32:17.810360 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.810365 25496 net.cpp:194] Memory required for data: 47636600
I0929 16:32:17.810370 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 16:32:17.810379 25496 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 16:32:17.810384 25496 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I0929 16:32:17.810392 25496 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0929 16:32:17.810401 25496 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0929 16:32:17.810462 25496 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0929 16:32:17.810473 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.810479 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.810482 25496 net.cpp:194] Memory required for data: 48291960
I0929 16:32:17.810487 25496 layer_factory.hpp:77] Creating layer conv3_3_0
I0929 16:32:17.810500 25496 net.cpp:128] Creating Layer conv3_3_0
I0929 16:32:17.810504 25496 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0929 16:32:17.810513 25496 net.cpp:522] conv3_3_0 -> conv3_3_0
I0929 16:32:17.817162 25496 net.cpp:172] Setting up conv3_3_0
I0929 16:32:17.817199 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.817204 25496 net.cpp:194] Memory required for data: 48619640
I0929 16:32:17.817219 25496 layer_factory.hpp:77] Creating layer conv3_3_bn0
I0929 16:32:17.817230 25496 net.cpp:128] Creating Layer conv3_3_bn0
I0929 16:32:17.817236 25496 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I0929 16:32:17.817247 25496 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I0929 16:32:17.817553 25496 net.cpp:172] Setting up conv3_3_bn0
I0929 16:32:17.817564 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.817569 25496 net.cpp:194] Memory required for data: 48947320
I0929 16:32:17.817579 25496 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0929 16:32:17.817587 25496 net.cpp:128] Creating Layer conv3_3_scale0
I0929 16:32:17.817591 25496 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I0929 16:32:17.817602 25496 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I0929 16:32:17.817662 25496 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0929 16:32:17.817834 25496 net.cpp:172] Setting up conv3_3_scale0
I0929 16:32:17.817847 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.817850 25496 net.cpp:194] Memory required for data: 49275000
I0929 16:32:17.817858 25496 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I0929 16:32:17.817865 25496 net.cpp:128] Creating Layer conv3_3_ReLU0
I0929 16:32:17.817869 25496 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I0929 16:32:17.817875 25496 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I0929 16:32:17.819177 25496 net.cpp:172] Setting up conv3_3_ReLU0
I0929 16:32:17.819196 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.819200 25496 net.cpp:194] Memory required for data: 49602680
I0929 16:32:17.819205 25496 layer_factory.hpp:77] Creating layer conv3_3_1
I0929 16:32:17.819221 25496 net.cpp:128] Creating Layer conv3_3_1
I0929 16:32:17.819226 25496 net.cpp:558] conv3_3_1 <- conv3_3_0
I0929 16:32:17.819236 25496 net.cpp:522] conv3_3_1 -> conv3_3_1
I0929 16:32:17.825898 25496 net.cpp:172] Setting up conv3_3_1
I0929 16:32:17.825925 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.825937 25496 net.cpp:194] Memory required for data: 49930360
I0929 16:32:17.825947 25496 layer_factory.hpp:77] Creating layer conv3_3bn1
I0929 16:32:17.825959 25496 net.cpp:128] Creating Layer conv3_3bn1
I0929 16:32:17.825968 25496 net.cpp:558] conv3_3bn1 <- conv3_3_1
I0929 16:32:17.825978 25496 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I0929 16:32:17.826274 25496 net.cpp:172] Setting up conv3_3bn1
I0929 16:32:17.826285 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.826313 25496 net.cpp:194] Memory required for data: 50258040
I0929 16:32:17.826323 25496 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0929 16:32:17.826331 25496 net.cpp:128] Creating Layer conv3_3_scale1
I0929 16:32:17.826335 25496 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I0929 16:32:17.826344 25496 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I0929 16:32:17.826402 25496 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0929 16:32:17.826568 25496 net.cpp:172] Setting up conv3_3_scale1
I0929 16:32:17.826578 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.826583 25496 net.cpp:194] Memory required for data: 50585720
I0929 16:32:17.826594 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I0929 16:32:17.826606 25496 net.cpp:128] Creating Layer conv3_Eltwise_3
I0929 16:32:17.826611 25496 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0929 16:32:17.826617 25496 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I0929 16:32:17.826622 25496 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I0929 16:32:17.826648 25496 net.cpp:172] Setting up conv3_Eltwise_3
I0929 16:32:17.826658 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.826663 25496 net.cpp:194] Memory required for data: 50913400
I0929 16:32:17.826666 25496 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I0929 16:32:17.826675 25496 net.cpp:128] Creating Layer conv3_3ReLU_1
I0929 16:32:17.826680 25496 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I0929 16:32:17.826689 25496 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I0929 16:32:17.827947 25496 net.cpp:172] Setting up conv3_3ReLU_1
I0929 16:32:17.827975 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.827980 25496 net.cpp:194] Memory required for data: 51241080
I0929 16:32:17.827985 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 16:32:17.827993 25496 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 16:32:17.828002 25496 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I0929 16:32:17.828012 25496 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0929 16:32:17.828024 25496 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0929 16:32:17.828085 25496 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0929 16:32:17.828092 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.828099 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.828102 25496 net.cpp:194] Memory required for data: 51896440
I0929 16:32:17.828106 25496 layer_factory.hpp:77] Creating layer conv3_4_0
I0929 16:32:17.828121 25496 net.cpp:128] Creating Layer conv3_4_0
I0929 16:32:17.828126 25496 net.cpp:558] conv3_4_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0929 16:32:17.828135 25496 net.cpp:522] conv3_4_0 -> conv3_4_0
I0929 16:32:17.834758 25496 net.cpp:172] Setting up conv3_4_0
I0929 16:32:17.834789 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.834794 25496 net.cpp:194] Memory required for data: 52224120
I0929 16:32:17.834806 25496 layer_factory.hpp:77] Creating layer conv3_4_bn0
I0929 16:32:17.834820 25496 net.cpp:128] Creating Layer conv3_4_bn0
I0929 16:32:17.834826 25496 net.cpp:558] conv3_4_bn0 <- conv3_4_0
I0929 16:32:17.834837 25496 net.cpp:509] conv3_4_bn0 -> conv3_4_0 (in-place)
I0929 16:32:17.835134 25496 net.cpp:172] Setting up conv3_4_bn0
I0929 16:32:17.835146 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.835150 25496 net.cpp:194] Memory required for data: 52551800
I0929 16:32:17.835175 25496 layer_factory.hpp:77] Creating layer conv3_4_scale0
I0929 16:32:17.835186 25496 net.cpp:128] Creating Layer conv3_4_scale0
I0929 16:32:17.835191 25496 net.cpp:558] conv3_4_scale0 <- conv3_4_0
I0929 16:32:17.835196 25496 net.cpp:509] conv3_4_scale0 -> conv3_4_0 (in-place)
I0929 16:32:17.835258 25496 layer_factory.hpp:77] Creating layer conv3_4_scale0
I0929 16:32:17.835429 25496 net.cpp:172] Setting up conv3_4_scale0
I0929 16:32:17.835469 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.835472 25496 net.cpp:194] Memory required for data: 52879480
I0929 16:32:17.835480 25496 layer_factory.hpp:77] Creating layer conv3_4_ReLU0
I0929 16:32:17.835487 25496 net.cpp:128] Creating Layer conv3_4_ReLU0
I0929 16:32:17.835491 25496 net.cpp:558] conv3_4_ReLU0 <- conv3_4_0
I0929 16:32:17.835497 25496 net.cpp:509] conv3_4_ReLU0 -> conv3_4_0 (in-place)
I0929 16:32:17.836745 25496 net.cpp:172] Setting up conv3_4_ReLU0
I0929 16:32:17.836766 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.836769 25496 net.cpp:194] Memory required for data: 53207160
I0929 16:32:17.836774 25496 layer_factory.hpp:77] Creating layer conv3_4_1
I0929 16:32:17.836787 25496 net.cpp:128] Creating Layer conv3_4_1
I0929 16:32:17.836793 25496 net.cpp:558] conv3_4_1 <- conv3_4_0
I0929 16:32:17.836800 25496 net.cpp:522] conv3_4_1 -> conv3_4_1
I0929 16:32:17.843497 25496 net.cpp:172] Setting up conv3_4_1
I0929 16:32:17.843523 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.843528 25496 net.cpp:194] Memory required for data: 53534840
I0929 16:32:17.843538 25496 layer_factory.hpp:77] Creating layer conv3_4bn1
I0929 16:32:17.843547 25496 net.cpp:128] Creating Layer conv3_4bn1
I0929 16:32:17.843556 25496 net.cpp:558] conv3_4bn1 <- conv3_4_1
I0929 16:32:17.843564 25496 net.cpp:509] conv3_4bn1 -> conv3_4_1 (in-place)
I0929 16:32:17.843853 25496 net.cpp:172] Setting up conv3_4bn1
I0929 16:32:17.843864 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.843868 25496 net.cpp:194] Memory required for data: 53862520
I0929 16:32:17.843878 25496 layer_factory.hpp:77] Creating layer conv3_4_scale1
I0929 16:32:17.843888 25496 net.cpp:128] Creating Layer conv3_4_scale1
I0929 16:32:17.843895 25496 net.cpp:558] conv3_4_scale1 <- conv3_4_1
I0929 16:32:17.843900 25496 net.cpp:509] conv3_4_scale1 -> conv3_4_1 (in-place)
I0929 16:32:17.843958 25496 layer_factory.hpp:77] Creating layer conv3_4_scale1
I0929 16:32:17.844121 25496 net.cpp:172] Setting up conv3_4_scale1
I0929 16:32:17.844132 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.844136 25496 net.cpp:194] Memory required for data: 54190200
I0929 16:32:17.844144 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_4
I0929 16:32:17.844158 25496 net.cpp:128] Creating Layer conv3_Eltwise_4
I0929 16:32:17.844166 25496 net.cpp:558] conv3_Eltwise_4 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0929 16:32:17.844172 25496 net.cpp:558] conv3_Eltwise_4 <- conv3_4_1
I0929 16:32:17.844178 25496 net.cpp:522] conv3_Eltwise_4 -> conv3_Eltwise_4
I0929 16:32:17.844204 25496 net.cpp:172] Setting up conv3_Eltwise_4
I0929 16:32:17.844210 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.844214 25496 net.cpp:194] Memory required for data: 54517880
I0929 16:32:17.844218 25496 layer_factory.hpp:77] Creating layer conv3_4ReLU_1
I0929 16:32:17.844228 25496 net.cpp:128] Creating Layer conv3_4ReLU_1
I0929 16:32:17.844233 25496 net.cpp:558] conv3_4ReLU_1 <- conv3_Eltwise_4
I0929 16:32:17.844238 25496 net.cpp:509] conv3_4ReLU_1 -> conv3_Eltwise_4 (in-place)
I0929 16:32:17.845513 25496 net.cpp:172] Setting up conv3_4ReLU_1
I0929 16:32:17.845531 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.845535 25496 net.cpp:194] Memory required for data: 54845560
I0929 16:32:17.845541 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0929 16:32:17.845551 25496 net.cpp:128] Creating Layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0929 16:32:17.845556 25496 net.cpp:558] conv3_Eltwise_4_conv3_4ReLU_1_0_split <- conv3_Eltwise_4
I0929 16:32:17.845564 25496 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I0929 16:32:17.845572 25496 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I0929 16:32:17.845636 25496 net.cpp:172] Setting up conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0929 16:32:17.845649 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.845654 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.845674 25496 net.cpp:194] Memory required for data: 55500920
I0929 16:32:17.845679 25496 layer_factory.hpp:77] Creating layer conv3_5_0
I0929 16:32:17.845692 25496 net.cpp:128] Creating Layer conv3_5_0
I0929 16:32:17.845697 25496 net.cpp:558] conv3_5_0 <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I0929 16:32:17.845705 25496 net.cpp:522] conv3_5_0 -> conv3_5_0
I0929 16:32:17.852322 25496 net.cpp:172] Setting up conv3_5_0
I0929 16:32:17.852357 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.852362 25496 net.cpp:194] Memory required for data: 55828600
I0929 16:32:17.852375 25496 layer_factory.hpp:77] Creating layer conv3_5_bn0
I0929 16:32:17.852387 25496 net.cpp:128] Creating Layer conv3_5_bn0
I0929 16:32:17.852398 25496 net.cpp:558] conv3_5_bn0 <- conv3_5_0
I0929 16:32:17.852408 25496 net.cpp:509] conv3_5_bn0 -> conv3_5_0 (in-place)
I0929 16:32:17.852710 25496 net.cpp:172] Setting up conv3_5_bn0
I0929 16:32:17.852720 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.852725 25496 net.cpp:194] Memory required for data: 56156280
I0929 16:32:17.852735 25496 layer_factory.hpp:77] Creating layer conv3_5_scale0
I0929 16:32:17.852746 25496 net.cpp:128] Creating Layer conv3_5_scale0
I0929 16:32:17.852751 25496 net.cpp:558] conv3_5_scale0 <- conv3_5_0
I0929 16:32:17.852756 25496 net.cpp:509] conv3_5_scale0 -> conv3_5_0 (in-place)
I0929 16:32:17.852820 25496 layer_factory.hpp:77] Creating layer conv3_5_scale0
I0929 16:32:17.852998 25496 net.cpp:172] Setting up conv3_5_scale0
I0929 16:32:17.853010 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.853014 25496 net.cpp:194] Memory required for data: 56483960
I0929 16:32:17.853021 25496 layer_factory.hpp:77] Creating layer conv3_5_ReLU0
I0929 16:32:17.853030 25496 net.cpp:128] Creating Layer conv3_5_ReLU0
I0929 16:32:17.853035 25496 net.cpp:558] conv3_5_ReLU0 <- conv3_5_0
I0929 16:32:17.853040 25496 net.cpp:509] conv3_5_ReLU0 -> conv3_5_0 (in-place)
I0929 16:32:17.853555 25496 net.cpp:172] Setting up conv3_5_ReLU0
I0929 16:32:17.853577 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.853581 25496 net.cpp:194] Memory required for data: 56811640
I0929 16:32:17.853586 25496 layer_factory.hpp:77] Creating layer conv3_5_1
I0929 16:32:17.853603 25496 net.cpp:128] Creating Layer conv3_5_1
I0929 16:32:17.853610 25496 net.cpp:558] conv3_5_1 <- conv3_5_0
I0929 16:32:17.853617 25496 net.cpp:522] conv3_5_1 -> conv3_5_1
I0929 16:32:17.855181 25496 net.cpp:172] Setting up conv3_5_1
I0929 16:32:17.855208 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.855212 25496 net.cpp:194] Memory required for data: 57139320
I0929 16:32:17.855222 25496 layer_factory.hpp:77] Creating layer conv3_5bn1
I0929 16:32:17.855234 25496 net.cpp:128] Creating Layer conv3_5bn1
I0929 16:32:17.855239 25496 net.cpp:558] conv3_5bn1 <- conv3_5_1
I0929 16:32:17.855247 25496 net.cpp:509] conv3_5bn1 -> conv3_5_1 (in-place)
I0929 16:32:17.855541 25496 net.cpp:172] Setting up conv3_5bn1
I0929 16:32:17.855553 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.855557 25496 net.cpp:194] Memory required for data: 57467000
I0929 16:32:17.855567 25496 layer_factory.hpp:77] Creating layer conv3_5_scale1
I0929 16:32:17.855573 25496 net.cpp:128] Creating Layer conv3_5_scale1
I0929 16:32:17.855578 25496 net.cpp:558] conv3_5_scale1 <- conv3_5_1
I0929 16:32:17.855585 25496 net.cpp:509] conv3_5_scale1 -> conv3_5_1 (in-place)
I0929 16:32:17.855638 25496 layer_factory.hpp:77] Creating layer conv3_5_scale1
I0929 16:32:17.855803 25496 net.cpp:172] Setting up conv3_5_scale1
I0929 16:32:17.855818 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.855821 25496 net.cpp:194] Memory required for data: 57794680
I0929 16:32:17.855829 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_5
I0929 16:32:17.855836 25496 net.cpp:128] Creating Layer conv3_Eltwise_5
I0929 16:32:17.855841 25496 net.cpp:558] conv3_Eltwise_5 <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I0929 16:32:17.855847 25496 net.cpp:558] conv3_Eltwise_5 <- conv3_5_1
I0929 16:32:17.855876 25496 net.cpp:522] conv3_Eltwise_5 -> conv3_Eltwise_5
I0929 16:32:17.855903 25496 net.cpp:172] Setting up conv3_Eltwise_5
I0929 16:32:17.855914 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.855918 25496 net.cpp:194] Memory required for data: 58122360
I0929 16:32:17.855922 25496 layer_factory.hpp:77] Creating layer conv3_5ReLU_1
I0929 16:32:17.855928 25496 net.cpp:128] Creating Layer conv3_5ReLU_1
I0929 16:32:17.855932 25496 net.cpp:558] conv3_5ReLU_1 <- conv3_Eltwise_5
I0929 16:32:17.855938 25496 net.cpp:509] conv3_5ReLU_1 -> conv3_Eltwise_5 (in-place)
I0929 16:32:17.856199 25496 net.cpp:172] Setting up conv3_5ReLU_1
I0929 16:32:17.856209 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.856214 25496 net.cpp:194] Memory required for data: 58450040
I0929 16:32:17.856217 25496 layer_factory.hpp:77] Creating layer conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0929 16:32:17.856227 25496 net.cpp:128] Creating Layer conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0929 16:32:17.856232 25496 net.cpp:558] conv3_Eltwise_5_conv3_5ReLU_1_0_split <- conv3_Eltwise_5
I0929 16:32:17.856238 25496 net.cpp:522] conv3_Eltwise_5_conv3_5ReLU_1_0_split -> conv3_Eltwise_5_conv3_5ReLU_1_0_split_0
I0929 16:32:17.856250 25496 net.cpp:522] conv3_Eltwise_5_conv3_5ReLU_1_0_split -> conv3_Eltwise_5_conv3_5ReLU_1_0_split_1
I0929 16:32:17.856307 25496 net.cpp:172] Setting up conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0929 16:32:17.856313 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.856318 25496 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0929 16:32:17.856323 25496 net.cpp:194] Memory required for data: 59105400
I0929 16:32:17.856326 25496 layer_factory.hpp:77] Creating layer conv4_1_0
I0929 16:32:17.856340 25496 net.cpp:128] Creating Layer conv4_1_0
I0929 16:32:17.856345 25496 net.cpp:558] conv4_1_0 <- conv3_Eltwise_5_conv3_5ReLU_1_0_split_0
I0929 16:32:17.856353 25496 net.cpp:522] conv4_1_0 -> conv4_1_0
I0929 16:32:17.858080 25496 net.cpp:172] Setting up conv4_1_0
I0929 16:32:17.858103 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.858108 25496 net.cpp:194] Memory required for data: 59269240
I0929 16:32:17.858116 25496 layer_factory.hpp:77] Creating layer conv4_1_bn0
I0929 16:32:17.858129 25496 net.cpp:128] Creating Layer conv4_1_bn0
I0929 16:32:17.858134 25496 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I0929 16:32:17.858142 25496 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I0929 16:32:17.858454 25496 net.cpp:172] Setting up conv4_1_bn0
I0929 16:32:17.858466 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.858470 25496 net.cpp:194] Memory required for data: 59433080
I0929 16:32:17.858480 25496 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0929 16:32:17.858487 25496 net.cpp:128] Creating Layer conv4_1_scale0
I0929 16:32:17.858491 25496 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I0929 16:32:17.858496 25496 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I0929 16:32:17.858553 25496 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0929 16:32:17.858721 25496 net.cpp:172] Setting up conv4_1_scale0
I0929 16:32:17.858731 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.858736 25496 net.cpp:194] Memory required for data: 59596920
I0929 16:32:17.858742 25496 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I0929 16:32:17.858750 25496 net.cpp:128] Creating Layer conv4_1_ReLU0
I0929 16:32:17.858755 25496 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I0929 16:32:17.858760 25496 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I0929 16:32:17.859021 25496 net.cpp:172] Setting up conv4_1_ReLU0
I0929 16:32:17.859032 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.859035 25496 net.cpp:194] Memory required for data: 59760760
I0929 16:32:17.859040 25496 layer_factory.hpp:77] Creating layer conv4_1_1
I0929 16:32:17.859052 25496 net.cpp:128] Creating Layer conv4_1_1
I0929 16:32:17.859057 25496 net.cpp:558] conv4_1_1 <- conv4_1_0
I0929 16:32:17.859066 25496 net.cpp:522] conv4_1_1 -> conv4_1_1
I0929 16:32:17.862452 25496 net.cpp:172] Setting up conv4_1_1
I0929 16:32:17.862498 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.862504 25496 net.cpp:194] Memory required for data: 59924600
I0929 16:32:17.862515 25496 layer_factory.hpp:77] Creating layer conv4_1bn1
I0929 16:32:17.862534 25496 net.cpp:128] Creating Layer conv4_1bn1
I0929 16:32:17.862540 25496 net.cpp:558] conv4_1bn1 <- conv4_1_1
I0929 16:32:17.862551 25496 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I0929 16:32:17.862860 25496 net.cpp:172] Setting up conv4_1bn1
I0929 16:32:17.862869 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.862874 25496 net.cpp:194] Memory required for data: 60088440
I0929 16:32:17.862884 25496 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0929 16:32:17.862893 25496 net.cpp:128] Creating Layer conv4_1_scale1
I0929 16:32:17.862897 25496 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I0929 16:32:17.862903 25496 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I0929 16:32:17.862963 25496 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0929 16:32:17.863138 25496 net.cpp:172] Setting up conv4_1_scale1
I0929 16:32:17.863148 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.863152 25496 net.cpp:194] Memory required for data: 60252280
I0929 16:32:17.863160 25496 layer_factory.hpp:77] Creating layer conv4_1_down
I0929 16:32:17.863176 25496 net.cpp:128] Creating Layer conv4_1_down
I0929 16:32:17.863183 25496 net.cpp:558] conv4_1_down <- conv3_Eltwise_5_conv3_5ReLU_1_0_split_1
I0929 16:32:17.863191 25496 net.cpp:522] conv4_1_down -> conv4_1_down
I0929 16:32:17.864627 25496 net.cpp:172] Setting up conv4_1_down
I0929 16:32:17.864655 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.864660 25496 net.cpp:194] Memory required for data: 60416120
I0929 16:32:17.864670 25496 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I0929 16:32:17.864677 25496 net.cpp:128] Creating Layer conv4_1_bn_down
I0929 16:32:17.864687 25496 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I0929 16:32:17.864696 25496 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I0929 16:32:17.865001 25496 net.cpp:172] Setting up conv4_1_bn_down
I0929 16:32:17.865011 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.865015 25496 net.cpp:194] Memory required for data: 60579960
I0929 16:32:17.865025 25496 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0929 16:32:17.865033 25496 net.cpp:128] Creating Layer conv4_1_scale_down
I0929 16:32:17.865038 25496 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I0929 16:32:17.865046 25496 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I0929 16:32:17.865098 25496 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0929 16:32:17.865272 25496 net.cpp:172] Setting up conv4_1_scale_down
I0929 16:32:17.865281 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.865285 25496 net.cpp:194] Memory required for data: 60743800
I0929 16:32:17.865293 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I0929 16:32:17.865305 25496 net.cpp:128] Creating Layer conv4_Eltwise_1
I0929 16:32:17.865310 25496 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I0929 16:32:17.865315 25496 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I0929 16:32:17.865321 25496 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I0929 16:32:17.865353 25496 net.cpp:172] Setting up conv4_Eltwise_1
I0929 16:32:17.865360 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.865365 25496 net.cpp:194] Memory required for data: 60907640
I0929 16:32:17.865368 25496 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I0929 16:32:17.865375 25496 net.cpp:128] Creating Layer conv4_1ReLU_1
I0929 16:32:17.865378 25496 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I0929 16:32:17.865386 25496 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I0929 16:32:17.865866 25496 net.cpp:172] Setting up conv4_1ReLU_1
I0929 16:32:17.865888 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.865892 25496 net.cpp:194] Memory required for data: 61071480
I0929 16:32:17.865901 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 16:32:17.865926 25496 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 16:32:17.865941 25496 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I0929 16:32:17.865950 25496 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0929 16:32:17.865959 25496 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0929 16:32:17.866027 25496 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0929 16:32:17.866037 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.866044 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.866047 25496 net.cpp:194] Memory required for data: 61399160
I0929 16:32:17.866051 25496 layer_factory.hpp:77] Creating layer conv4_2_0
I0929 16:32:17.866063 25496 net.cpp:128] Creating Layer conv4_2_0
I0929 16:32:17.866068 25496 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0929 16:32:17.866077 25496 net.cpp:522] conv4_2_0 -> conv4_2_0
I0929 16:32:17.868269 25496 net.cpp:172] Setting up conv4_2_0
I0929 16:32:17.868300 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.868305 25496 net.cpp:194] Memory required for data: 61563000
I0929 16:32:17.868316 25496 layer_factory.hpp:77] Creating layer conv4_2_bn0
I0929 16:32:17.868330 25496 net.cpp:128] Creating Layer conv4_2_bn0
I0929 16:32:17.868337 25496 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I0929 16:32:17.868345 25496 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I0929 16:32:17.868659 25496 net.cpp:172] Setting up conv4_2_bn0
I0929 16:32:17.868669 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.868674 25496 net.cpp:194] Memory required for data: 61726840
I0929 16:32:17.868683 25496 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0929 16:32:17.868693 25496 net.cpp:128] Creating Layer conv4_2_scale0
I0929 16:32:17.868697 25496 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I0929 16:32:17.868703 25496 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I0929 16:32:17.868762 25496 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0929 16:32:17.868937 25496 net.cpp:172] Setting up conv4_2_scale0
I0929 16:32:17.868949 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.868957 25496 net.cpp:194] Memory required for data: 61890680
I0929 16:32:17.868964 25496 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I0929 16:32:17.868973 25496 net.cpp:128] Creating Layer conv4_2_ReLU0
I0929 16:32:17.868978 25496 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I0929 16:32:17.868983 25496 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I0929 16:32:17.869246 25496 net.cpp:172] Setting up conv4_2_ReLU0
I0929 16:32:17.869261 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.869269 25496 net.cpp:194] Memory required for data: 62054520
I0929 16:32:17.869274 25496 layer_factory.hpp:77] Creating layer conv4_2_1
I0929 16:32:17.869290 25496 net.cpp:128] Creating Layer conv4_2_1
I0929 16:32:17.869298 25496 net.cpp:558] conv4_2_1 <- conv4_2_0
I0929 16:32:17.869307 25496 net.cpp:522] conv4_2_1 -> conv4_2_1
I0929 16:32:17.872001 25496 net.cpp:172] Setting up conv4_2_1
I0929 16:32:17.872032 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.872037 25496 net.cpp:194] Memory required for data: 62218360
I0929 16:32:17.872047 25496 layer_factory.hpp:77] Creating layer conv4_2bn1
I0929 16:32:17.872068 25496 net.cpp:128] Creating Layer conv4_2bn1
I0929 16:32:17.872074 25496 net.cpp:558] conv4_2bn1 <- conv4_2_1
I0929 16:32:17.872082 25496 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I0929 16:32:17.872388 25496 net.cpp:172] Setting up conv4_2bn1
I0929 16:32:17.872398 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.872402 25496 net.cpp:194] Memory required for data: 62382200
I0929 16:32:17.872412 25496 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0929 16:32:17.872421 25496 net.cpp:128] Creating Layer conv4_2_scale1
I0929 16:32:17.872429 25496 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I0929 16:32:17.872455 25496 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I0929 16:32:17.872515 25496 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0929 16:32:17.872691 25496 net.cpp:172] Setting up conv4_2_scale1
I0929 16:32:17.872700 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.872705 25496 net.cpp:194] Memory required for data: 62546040
I0929 16:32:17.872714 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I0929 16:32:17.872723 25496 net.cpp:128] Creating Layer conv4_Eltwise_2
I0929 16:32:17.872730 25496 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0929 16:32:17.872735 25496 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I0929 16:32:17.872741 25496 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I0929 16:32:17.872774 25496 net.cpp:172] Setting up conv4_Eltwise_2
I0929 16:32:17.872781 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.872786 25496 net.cpp:194] Memory required for data: 62709880
I0929 16:32:17.872789 25496 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I0929 16:32:17.872797 25496 net.cpp:128] Creating Layer conv4_2ReLU_1
I0929 16:32:17.872804 25496 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I0929 16:32:17.872809 25496 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I0929 16:32:17.873066 25496 net.cpp:172] Setting up conv4_2ReLU_1
I0929 16:32:17.873080 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.873083 25496 net.cpp:194] Memory required for data: 62873720
I0929 16:32:17.873088 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 16:32:17.873095 25496 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 16:32:17.873100 25496 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I0929 16:32:17.873108 25496 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0929 16:32:17.873117 25496 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0929 16:32:17.873180 25496 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0929 16:32:17.873188 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.873193 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.873196 25496 net.cpp:194] Memory required for data: 63201400
I0929 16:32:17.873200 25496 layer_factory.hpp:77] Creating layer conv4_3_0
I0929 16:32:17.873211 25496 net.cpp:128] Creating Layer conv4_3_0
I0929 16:32:17.873216 25496 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0929 16:32:17.873225 25496 net.cpp:522] conv4_3_0 -> conv4_3_0
I0929 16:32:17.878772 25496 net.cpp:172] Setting up conv4_3_0
I0929 16:32:17.878800 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.878805 25496 net.cpp:194] Memory required for data: 63365240
I0929 16:32:17.878821 25496 layer_factory.hpp:77] Creating layer conv4_3_bn0
I0929 16:32:17.878834 25496 net.cpp:128] Creating Layer conv4_3_bn0
I0929 16:32:17.878839 25496 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I0929 16:32:17.878846 25496 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I0929 16:32:17.879168 25496 net.cpp:172] Setting up conv4_3_bn0
I0929 16:32:17.879179 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.879182 25496 net.cpp:194] Memory required for data: 63529080
I0929 16:32:17.879192 25496 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0929 16:32:17.879200 25496 net.cpp:128] Creating Layer conv4_3_scale0
I0929 16:32:17.879204 25496 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I0929 16:32:17.879210 25496 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I0929 16:32:17.879271 25496 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0929 16:32:17.879451 25496 net.cpp:172] Setting up conv4_3_scale0
I0929 16:32:17.879463 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.879467 25496 net.cpp:194] Memory required for data: 63692920
I0929 16:32:17.879475 25496 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I0929 16:32:17.879482 25496 net.cpp:128] Creating Layer conv4_3_ReLU0
I0929 16:32:17.879506 25496 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I0929 16:32:17.879515 25496 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I0929 16:32:17.880625 25496 net.cpp:172] Setting up conv4_3_ReLU0
I0929 16:32:17.880643 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.880647 25496 net.cpp:194] Memory required for data: 63856760
I0929 16:32:17.880652 25496 layer_factory.hpp:77] Creating layer conv4_3_1
I0929 16:32:17.880671 25496 net.cpp:128] Creating Layer conv4_3_1
I0929 16:32:17.880676 25496 net.cpp:558] conv4_3_1 <- conv4_3_0
I0929 16:32:17.880687 25496 net.cpp:522] conv4_3_1 -> conv4_3_1
I0929 16:32:17.887415 25496 net.cpp:172] Setting up conv4_3_1
I0929 16:32:17.887444 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.887447 25496 net.cpp:194] Memory required for data: 64020600
I0929 16:32:17.887459 25496 layer_factory.hpp:77] Creating layer conv4_3bn1
I0929 16:32:17.887466 25496 net.cpp:128] Creating Layer conv4_3bn1
I0929 16:32:17.887471 25496 net.cpp:558] conv4_3bn1 <- conv4_3_1
I0929 16:32:17.887481 25496 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I0929 16:32:17.887795 25496 net.cpp:172] Setting up conv4_3bn1
I0929 16:32:17.887807 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.887811 25496 net.cpp:194] Memory required for data: 64184440
I0929 16:32:17.887822 25496 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0929 16:32:17.887833 25496 net.cpp:128] Creating Layer conv4_3_scale1
I0929 16:32:17.887838 25496 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I0929 16:32:17.887845 25496 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I0929 16:32:17.887900 25496 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0929 16:32:17.888077 25496 net.cpp:172] Setting up conv4_3_scale1
I0929 16:32:17.888089 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.888093 25496 net.cpp:194] Memory required for data: 64348280
I0929 16:32:17.888101 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I0929 16:32:17.888110 25496 net.cpp:128] Creating Layer conv4_Eltwise_3
I0929 16:32:17.888115 25496 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0929 16:32:17.888120 25496 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I0929 16:32:17.888129 25496 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I0929 16:32:17.888160 25496 net.cpp:172] Setting up conv4_Eltwise_3
I0929 16:32:17.888166 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.888170 25496 net.cpp:194] Memory required for data: 64512120
I0929 16:32:17.888175 25496 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I0929 16:32:17.888183 25496 net.cpp:128] Creating Layer conv4_3ReLU_1
I0929 16:32:17.888188 25496 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I0929 16:32:17.888193 25496 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I0929 16:32:17.889461 25496 net.cpp:172] Setting up conv4_3ReLU_1
I0929 16:32:17.889483 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.889488 25496 net.cpp:194] Memory required for data: 64675960
I0929 16:32:17.889493 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0929 16:32:17.889505 25496 net.cpp:128] Creating Layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0929 16:32:17.889511 25496 net.cpp:558] conv4_Eltwise_3_conv4_3ReLU_1_0_split <- conv4_Eltwise_3
I0929 16:32:17.889518 25496 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I0929 16:32:17.889528 25496 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I0929 16:32:17.889592 25496 net.cpp:172] Setting up conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0929 16:32:17.889609 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.889616 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.889619 25496 net.cpp:194] Memory required for data: 65003640
I0929 16:32:17.889623 25496 layer_factory.hpp:77] Creating layer conv4_4_0
I0929 16:32:17.889636 25496 net.cpp:128] Creating Layer conv4_4_0
I0929 16:32:17.889642 25496 net.cpp:558] conv4_4_0 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I0929 16:32:17.889667 25496 net.cpp:522] conv4_4_0 -> conv4_4_0
I0929 16:32:17.896440 25496 net.cpp:172] Setting up conv4_4_0
I0929 16:32:17.896466 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.896471 25496 net.cpp:194] Memory required for data: 65167480
I0929 16:32:17.896481 25496 layer_factory.hpp:77] Creating layer conv4_4_bn0
I0929 16:32:17.896494 25496 net.cpp:128] Creating Layer conv4_4_bn0
I0929 16:32:17.896499 25496 net.cpp:558] conv4_4_bn0 <- conv4_4_0
I0929 16:32:17.896508 25496 net.cpp:509] conv4_4_bn0 -> conv4_4_0 (in-place)
I0929 16:32:17.896842 25496 net.cpp:172] Setting up conv4_4_bn0
I0929 16:32:17.896853 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.896857 25496 net.cpp:194] Memory required for data: 65331320
I0929 16:32:17.896868 25496 layer_factory.hpp:77] Creating layer conv4_4_scale0
I0929 16:32:17.896875 25496 net.cpp:128] Creating Layer conv4_4_scale0
I0929 16:32:17.896879 25496 net.cpp:558] conv4_4_scale0 <- conv4_4_0
I0929 16:32:17.896888 25496 net.cpp:509] conv4_4_scale0 -> conv4_4_0 (in-place)
I0929 16:32:17.896941 25496 layer_factory.hpp:77] Creating layer conv4_4_scale0
I0929 16:32:17.897127 25496 net.cpp:172] Setting up conv4_4_scale0
I0929 16:32:17.897140 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.897145 25496 net.cpp:194] Memory required for data: 65495160
I0929 16:32:17.897152 25496 layer_factory.hpp:77] Creating layer conv4_4_ReLU0
I0929 16:32:17.897158 25496 net.cpp:128] Creating Layer conv4_4_ReLU0
I0929 16:32:17.897162 25496 net.cpp:558] conv4_4_ReLU0 <- conv4_4_0
I0929 16:32:17.897171 25496 net.cpp:509] conv4_4_ReLU0 -> conv4_4_0 (in-place)
I0929 16:32:17.898278 25496 net.cpp:172] Setting up conv4_4_ReLU0
I0929 16:32:17.898295 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.898300 25496 net.cpp:194] Memory required for data: 65659000
I0929 16:32:17.898305 25496 layer_factory.hpp:77] Creating layer conv4_4_1
I0929 16:32:17.898319 25496 net.cpp:128] Creating Layer conv4_4_1
I0929 16:32:17.898324 25496 net.cpp:558] conv4_4_1 <- conv4_4_0
I0929 16:32:17.898334 25496 net.cpp:522] conv4_4_1 -> conv4_4_1
I0929 16:32:17.905023 25496 net.cpp:172] Setting up conv4_4_1
I0929 16:32:17.905050 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.905055 25496 net.cpp:194] Memory required for data: 65822840
I0929 16:32:17.905064 25496 layer_factory.hpp:77] Creating layer conv4_4bn1
I0929 16:32:17.905073 25496 net.cpp:128] Creating Layer conv4_4bn1
I0929 16:32:17.905078 25496 net.cpp:558] conv4_4bn1 <- conv4_4_1
I0929 16:32:17.905088 25496 net.cpp:509] conv4_4bn1 -> conv4_4_1 (in-place)
I0929 16:32:17.905408 25496 net.cpp:172] Setting up conv4_4bn1
I0929 16:32:17.905421 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.905426 25496 net.cpp:194] Memory required for data: 65986680
I0929 16:32:17.905436 25496 layer_factory.hpp:77] Creating layer conv4_4_scale1
I0929 16:32:17.905444 25496 net.cpp:128] Creating Layer conv4_4_scale1
I0929 16:32:17.905449 25496 net.cpp:558] conv4_4_scale1 <- conv4_4_1
I0929 16:32:17.905454 25496 net.cpp:509] conv4_4_scale1 -> conv4_4_1 (in-place)
I0929 16:32:17.905511 25496 layer_factory.hpp:77] Creating layer conv4_4_scale1
I0929 16:32:17.905707 25496 net.cpp:172] Setting up conv4_4_scale1
I0929 16:32:17.905719 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.905724 25496 net.cpp:194] Memory required for data: 66150520
I0929 16:32:17.905731 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_4
I0929 16:32:17.905741 25496 net.cpp:128] Creating Layer conv4_Eltwise_4
I0929 16:32:17.905746 25496 net.cpp:558] conv4_Eltwise_4 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I0929 16:32:17.905751 25496 net.cpp:558] conv4_Eltwise_4 <- conv4_4_1
I0929 16:32:17.905759 25496 net.cpp:522] conv4_Eltwise_4 -> conv4_Eltwise_4
I0929 16:32:17.905791 25496 net.cpp:172] Setting up conv4_Eltwise_4
I0929 16:32:17.905797 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.905800 25496 net.cpp:194] Memory required for data: 66314360
I0929 16:32:17.905820 25496 layer_factory.hpp:77] Creating layer conv4_4ReLU_1
I0929 16:32:17.905830 25496 net.cpp:128] Creating Layer conv4_4ReLU_1
I0929 16:32:17.905835 25496 net.cpp:558] conv4_4ReLU_1 <- conv4_Eltwise_4
I0929 16:32:17.905840 25496 net.cpp:509] conv4_4ReLU_1 -> conv4_Eltwise_4 (in-place)
I0929 16:32:17.907296 25496 net.cpp:172] Setting up conv4_4ReLU_1
I0929 16:32:17.907325 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.907330 25496 net.cpp:194] Memory required for data: 66478200
I0929 16:32:17.907335 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0929 16:32:17.907342 25496 net.cpp:128] Creating Layer conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0929 16:32:17.907348 25496 net.cpp:558] conv4_Eltwise_4_conv4_4ReLU_1_0_split <- conv4_Eltwise_4
I0929 16:32:17.907356 25496 net.cpp:522] conv4_Eltwise_4_conv4_4ReLU_1_0_split -> conv4_Eltwise_4_conv4_4ReLU_1_0_split_0
I0929 16:32:17.907366 25496 net.cpp:522] conv4_Eltwise_4_conv4_4ReLU_1_0_split -> conv4_Eltwise_4_conv4_4ReLU_1_0_split_1
I0929 16:32:17.907433 25496 net.cpp:172] Setting up conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0929 16:32:17.907452 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.907459 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.907462 25496 net.cpp:194] Memory required for data: 66805880
I0929 16:32:17.907466 25496 layer_factory.hpp:77] Creating layer conv4_5_0
I0929 16:32:17.907481 25496 net.cpp:128] Creating Layer conv4_5_0
I0929 16:32:17.907486 25496 net.cpp:558] conv4_5_0 <- conv4_Eltwise_4_conv4_4ReLU_1_0_split_0
I0929 16:32:17.907493 25496 net.cpp:522] conv4_5_0 -> conv4_5_0
I0929 16:32:17.914114 25496 net.cpp:172] Setting up conv4_5_0
I0929 16:32:17.914142 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.914147 25496 net.cpp:194] Memory required for data: 66969720
I0929 16:32:17.914157 25496 layer_factory.hpp:77] Creating layer conv4_5_bn0
I0929 16:32:17.914166 25496 net.cpp:128] Creating Layer conv4_5_bn0
I0929 16:32:17.914171 25496 net.cpp:558] conv4_5_bn0 <- conv4_5_0
I0929 16:32:17.914181 25496 net.cpp:509] conv4_5_bn0 -> conv4_5_0 (in-place)
I0929 16:32:17.914511 25496 net.cpp:172] Setting up conv4_5_bn0
I0929 16:32:17.914525 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.914530 25496 net.cpp:194] Memory required for data: 67133560
I0929 16:32:17.914538 25496 layer_factory.hpp:77] Creating layer conv4_5_scale0
I0929 16:32:17.914546 25496 net.cpp:128] Creating Layer conv4_5_scale0
I0929 16:32:17.914551 25496 net.cpp:558] conv4_5_scale0 <- conv4_5_0
I0929 16:32:17.914557 25496 net.cpp:509] conv4_5_scale0 -> conv4_5_0 (in-place)
I0929 16:32:17.914611 25496 layer_factory.hpp:77] Creating layer conv4_5_scale0
I0929 16:32:17.914799 25496 net.cpp:172] Setting up conv4_5_scale0
I0929 16:32:17.914813 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.914816 25496 net.cpp:194] Memory required for data: 67297400
I0929 16:32:17.914824 25496 layer_factory.hpp:77] Creating layer conv4_5_ReLU0
I0929 16:32:17.914832 25496 net.cpp:128] Creating Layer conv4_5_ReLU0
I0929 16:32:17.914837 25496 net.cpp:558] conv4_5_ReLU0 <- conv4_5_0
I0929 16:32:17.914842 25496 net.cpp:509] conv4_5_ReLU0 -> conv4_5_0 (in-place)
I0929 16:32:17.915941 25496 net.cpp:172] Setting up conv4_5_ReLU0
I0929 16:32:17.915964 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.915969 25496 net.cpp:194] Memory required for data: 67461240
I0929 16:32:17.915974 25496 layer_factory.hpp:77] Creating layer conv4_5_1
I0929 16:32:17.915988 25496 net.cpp:128] Creating Layer conv4_5_1
I0929 16:32:17.915994 25496 net.cpp:558] conv4_5_1 <- conv4_5_0
I0929 16:32:17.916004 25496 net.cpp:522] conv4_5_1 -> conv4_5_1
I0929 16:32:17.922745 25496 net.cpp:172] Setting up conv4_5_1
I0929 16:32:17.922771 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.922775 25496 net.cpp:194] Memory required for data: 67625080
I0929 16:32:17.922788 25496 layer_factory.hpp:77] Creating layer conv4_5bn1
I0929 16:32:17.922799 25496 net.cpp:128] Creating Layer conv4_5bn1
I0929 16:32:17.922806 25496 net.cpp:558] conv4_5bn1 <- conv4_5_1
I0929 16:32:17.922832 25496 net.cpp:509] conv4_5bn1 -> conv4_5_1 (in-place)
I0929 16:32:17.923156 25496 net.cpp:172] Setting up conv4_5bn1
I0929 16:32:17.923169 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.923173 25496 net.cpp:194] Memory required for data: 67788920
I0929 16:32:17.923183 25496 layer_factory.hpp:77] Creating layer conv4_5_scale1
I0929 16:32:17.923190 25496 net.cpp:128] Creating Layer conv4_5_scale1
I0929 16:32:17.923194 25496 net.cpp:558] conv4_5_scale1 <- conv4_5_1
I0929 16:32:17.923202 25496 net.cpp:509] conv4_5_scale1 -> conv4_5_1 (in-place)
I0929 16:32:17.923257 25496 layer_factory.hpp:77] Creating layer conv4_5_scale1
I0929 16:32:17.923440 25496 net.cpp:172] Setting up conv4_5_scale1
I0929 16:32:17.923452 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.923456 25496 net.cpp:194] Memory required for data: 67952760
I0929 16:32:17.923465 25496 layer_factory.hpp:77] Creating layer conv4_Eltwise_5
I0929 16:32:17.923470 25496 net.cpp:128] Creating Layer conv4_Eltwise_5
I0929 16:32:17.923475 25496 net.cpp:558] conv4_Eltwise_5 <- conv4_Eltwise_4_conv4_4ReLU_1_0_split_1
I0929 16:32:17.923480 25496 net.cpp:558] conv4_Eltwise_5 <- conv4_5_1
I0929 16:32:17.923490 25496 net.cpp:522] conv4_Eltwise_5 -> conv4_Eltwise_5
I0929 16:32:17.923521 25496 net.cpp:172] Setting up conv4_Eltwise_5
I0929 16:32:17.923528 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.923532 25496 net.cpp:194] Memory required for data: 68116600
I0929 16:32:17.923537 25496 layer_factory.hpp:77] Creating layer conv4_5ReLU_1
I0929 16:32:17.923542 25496 net.cpp:128] Creating Layer conv4_5ReLU_1
I0929 16:32:17.923547 25496 net.cpp:558] conv4_5ReLU_1 <- conv4_Eltwise_5
I0929 16:32:17.923555 25496 net.cpp:509] conv4_5ReLU_1 -> conv4_Eltwise_5 (in-place)
I0929 16:32:17.924798 25496 net.cpp:172] Setting up conv4_5ReLU_1
I0929 16:32:17.924814 25496 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0929 16:32:17.924820 25496 net.cpp:194] Memory required for data: 68280440
I0929 16:32:17.924824 25496 layer_factory.hpp:77] Creating layer Pooling1
I0929 16:32:17.924834 25496 net.cpp:128] Creating Layer Pooling1
I0929 16:32:17.924839 25496 net.cpp:558] Pooling1 <- conv4_Eltwise_5
I0929 16:32:17.924849 25496 net.cpp:522] Pooling1 -> Pooling1
I0929 16:32:17.927037 25496 net.cpp:172] Setting up Pooling1
I0929 16:32:17.927057 25496 net.cpp:186] Top shape: 10 64 1 1 (640)
I0929 16:32:17.927062 25496 net.cpp:194] Memory required for data: 68283000
I0929 16:32:17.927067 25496 layer_factory.hpp:77] Creating layer fc1
I0929 16:32:17.927083 25496 net.cpp:128] Creating Layer fc1
I0929 16:32:17.927088 25496 net.cpp:558] fc1 <- Pooling1
I0929 16:32:17.927094 25496 net.cpp:522] fc1 -> fc1
I0929 16:32:17.927294 25496 net.cpp:172] Setting up fc1
I0929 16:32:17.927306 25496 net.cpp:186] Top shape: 10 10 (100)
I0929 16:32:17.927310 25496 net.cpp:194] Memory required for data: 68283400
I0929 16:32:17.927320 25496 layer_factory.hpp:77] Creating layer fc1_fc1_0_split
I0929 16:32:17.927326 25496 net.cpp:128] Creating Layer fc1_fc1_0_split
I0929 16:32:17.927331 25496 net.cpp:558] fc1_fc1_0_split <- fc1
I0929 16:32:17.927340 25496 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_0
I0929 16:32:17.927347 25496 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_1
I0929 16:32:17.927399 25496 net.cpp:172] Setting up fc1_fc1_0_split
I0929 16:32:17.927407 25496 net.cpp:186] Top shape: 10 10 (100)
I0929 16:32:17.927412 25496 net.cpp:186] Top shape: 10 10 (100)
I0929 16:32:17.927415 25496 net.cpp:194] Memory required for data: 68284200
I0929 16:32:17.927419 25496 layer_factory.hpp:77] Creating layer Softmax1
I0929 16:32:17.927431 25496 net.cpp:128] Creating Layer Softmax1
I0929 16:32:17.927435 25496 net.cpp:558] Softmax1 <- fc1_fc1_0_split_0
I0929 16:32:17.927441 25496 net.cpp:558] Softmax1 <- label_Data1_1_split_0
I0929 16:32:17.927449 25496 net.cpp:522] Softmax1 -> Softmax1
I0929 16:32:17.927459 25496 layer_factory.hpp:77] Creating layer Softmax1
I0929 16:32:17.929386 25496 net.cpp:172] Setting up Softmax1
I0929 16:32:17.929428 25496 net.cpp:186] Top shape: (1)
I0929 16:32:17.929432 25496 net.cpp:189]     with loss weight 1
I0929 16:32:17.929452 25496 net.cpp:194] Memory required for data: 68284204
I0929 16:32:17.929457 25496 layer_factory.hpp:77] Creating layer prob
I0929 16:32:17.929466 25496 net.cpp:128] Creating Layer prob
I0929 16:32:17.929473 25496 net.cpp:558] prob <- fc1_fc1_0_split_1
I0929 16:32:17.929479 25496 net.cpp:558] prob <- label_Data1_1_split_1
I0929 16:32:17.929491 25496 net.cpp:522] prob -> prob
I0929 16:32:17.929502 25496 net.cpp:172] Setting up prob
I0929 16:32:17.929507 25496 net.cpp:186] Top shape: (1)
I0929 16:32:17.929512 25496 net.cpp:194] Memory required for data: 68284208
I0929 16:32:17.929517 25496 net.cpp:303] prob does not need backward computation.
I0929 16:32:17.929522 25496 net.cpp:301] Softmax1 needs backward computation.
I0929 16:32:17.929527 25496 net.cpp:301] fc1_fc1_0_split needs backward computation.
I0929 16:32:17.929530 25496 net.cpp:301] fc1 needs backward computation.
I0929 16:32:17.929534 25496 net.cpp:301] Pooling1 needs backward computation.
I0929 16:32:17.929539 25496 net.cpp:301] conv4_5ReLU_1 needs backward computation.
I0929 16:32:17.929543 25496 net.cpp:301] conv4_Eltwise_5 needs backward computation.
I0929 16:32:17.929548 25496 net.cpp:301] conv4_5_scale1 needs backward computation.
I0929 16:32:17.929553 25496 net.cpp:301] conv4_5bn1 needs backward computation.
I0929 16:32:17.929556 25496 net.cpp:301] conv4_5_1 needs backward computation.
I0929 16:32:17.929561 25496 net.cpp:301] conv4_5_ReLU0 needs backward computation.
I0929 16:32:17.929565 25496 net.cpp:301] conv4_5_scale0 needs backward computation.
I0929 16:32:17.929569 25496 net.cpp:301] conv4_5_bn0 needs backward computation.
I0929 16:32:17.929574 25496 net.cpp:301] conv4_5_0 needs backward computation.
I0929 16:32:17.929577 25496 net.cpp:301] conv4_Eltwise_4_conv4_4ReLU_1_0_split needs backward computation.
I0929 16:32:17.929582 25496 net.cpp:301] conv4_4ReLU_1 needs backward computation.
I0929 16:32:17.929586 25496 net.cpp:301] conv4_Eltwise_4 needs backward computation.
I0929 16:32:17.929591 25496 net.cpp:301] conv4_4_scale1 needs backward computation.
I0929 16:32:17.929595 25496 net.cpp:301] conv4_4bn1 needs backward computation.
I0929 16:32:17.929600 25496 net.cpp:301] conv4_4_1 needs backward computation.
I0929 16:32:17.929605 25496 net.cpp:301] conv4_4_ReLU0 needs backward computation.
I0929 16:32:17.929608 25496 net.cpp:301] conv4_4_scale0 needs backward computation.
I0929 16:32:17.929612 25496 net.cpp:301] conv4_4_bn0 needs backward computation.
I0929 16:32:17.929616 25496 net.cpp:301] conv4_4_0 needs backward computation.
I0929 16:32:17.929621 25496 net.cpp:301] conv4_Eltwise_3_conv4_3ReLU_1_0_split needs backward computation.
I0929 16:32:17.929626 25496 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I0929 16:32:17.929630 25496 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I0929 16:32:17.929636 25496 net.cpp:301] conv4_3_scale1 needs backward computation.
I0929 16:32:17.929642 25496 net.cpp:301] conv4_3bn1 needs backward computation.
I0929 16:32:17.929647 25496 net.cpp:301] conv4_3_1 needs backward computation.
I0929 16:32:17.929651 25496 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I0929 16:32:17.929656 25496 net.cpp:301] conv4_3_scale0 needs backward computation.
I0929 16:32:17.929661 25496 net.cpp:301] conv4_3_bn0 needs backward computation.
I0929 16:32:17.929664 25496 net.cpp:301] conv4_3_0 needs backward computation.
I0929 16:32:17.929669 25496 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I0929 16:32:17.929674 25496 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I0929 16:32:17.929678 25496 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I0929 16:32:17.929684 25496 net.cpp:301] conv4_2_scale1 needs backward computation.
I0929 16:32:17.929689 25496 net.cpp:301] conv4_2bn1 needs backward computation.
I0929 16:32:17.929693 25496 net.cpp:301] conv4_2_1 needs backward computation.
I0929 16:32:17.929697 25496 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I0929 16:32:17.929710 25496 net.cpp:301] conv4_2_scale0 needs backward computation.
I0929 16:32:17.929715 25496 net.cpp:301] conv4_2_bn0 needs backward computation.
I0929 16:32:17.929719 25496 net.cpp:301] conv4_2_0 needs backward computation.
I0929 16:32:17.929725 25496 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I0929 16:32:17.929730 25496 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I0929 16:32:17.929734 25496 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I0929 16:32:17.929740 25496 net.cpp:301] conv4_1_scale_down needs backward computation.
I0929 16:32:17.929745 25496 net.cpp:301] conv4_1_bn_down needs backward computation.
I0929 16:32:17.929749 25496 net.cpp:301] conv4_1_down needs backward computation.
I0929 16:32:17.929755 25496 net.cpp:301] conv4_1_scale1 needs backward computation.
I0929 16:32:17.929759 25496 net.cpp:301] conv4_1bn1 needs backward computation.
I0929 16:32:17.929764 25496 net.cpp:301] conv4_1_1 needs backward computation.
I0929 16:32:17.929769 25496 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I0929 16:32:17.929774 25496 net.cpp:301] conv4_1_scale0 needs backward computation.
I0929 16:32:17.929777 25496 net.cpp:301] conv4_1_bn0 needs backward computation.
I0929 16:32:17.929782 25496 net.cpp:301] conv4_1_0 needs backward computation.
I0929 16:32:17.929787 25496 net.cpp:301] conv3_Eltwise_5_conv3_5ReLU_1_0_split needs backward computation.
I0929 16:32:17.929792 25496 net.cpp:301] conv3_5ReLU_1 needs backward computation.
I0929 16:32:17.929797 25496 net.cpp:301] conv3_Eltwise_5 needs backward computation.
I0929 16:32:17.929802 25496 net.cpp:301] conv3_5_scale1 needs backward computation.
I0929 16:32:17.929807 25496 net.cpp:301] conv3_5bn1 needs backward computation.
I0929 16:32:17.929812 25496 net.cpp:301] conv3_5_1 needs backward computation.
I0929 16:32:17.929816 25496 net.cpp:301] conv3_5_ReLU0 needs backward computation.
I0929 16:32:17.929821 25496 net.cpp:301] conv3_5_scale0 needs backward computation.
I0929 16:32:17.929826 25496 net.cpp:301] conv3_5_bn0 needs backward computation.
I0929 16:32:17.929831 25496 net.cpp:301] conv3_5_0 needs backward computation.
I0929 16:32:17.929836 25496 net.cpp:301] conv3_Eltwise_4_conv3_4ReLU_1_0_split needs backward computation.
I0929 16:32:17.929841 25496 net.cpp:301] conv3_4ReLU_1 needs backward computation.
I0929 16:32:17.929846 25496 net.cpp:301] conv3_Eltwise_4 needs backward computation.
I0929 16:32:17.929852 25496 net.cpp:301] conv3_4_scale1 needs backward computation.
I0929 16:32:17.929855 25496 net.cpp:301] conv3_4bn1 needs backward computation.
I0929 16:32:17.929859 25496 net.cpp:301] conv3_4_1 needs backward computation.
I0929 16:32:17.929864 25496 net.cpp:301] conv3_4_ReLU0 needs backward computation.
I0929 16:32:17.929868 25496 net.cpp:301] conv3_4_scale0 needs backward computation.
I0929 16:32:17.929873 25496 net.cpp:301] conv3_4_bn0 needs backward computation.
I0929 16:32:17.929878 25496 net.cpp:301] conv3_4_0 needs backward computation.
I0929 16:32:17.929883 25496 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I0929 16:32:17.929891 25496 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I0929 16:32:17.929896 25496 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I0929 16:32:17.929903 25496 net.cpp:301] conv3_3_scale1 needs backward computation.
I0929 16:32:17.929906 25496 net.cpp:301] conv3_3bn1 needs backward computation.
I0929 16:32:17.929911 25496 net.cpp:301] conv3_3_1 needs backward computation.
I0929 16:32:17.929916 25496 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I0929 16:32:17.929920 25496 net.cpp:301] conv3_3_scale0 needs backward computation.
I0929 16:32:17.929924 25496 net.cpp:301] conv3_3_bn0 needs backward computation.
I0929 16:32:17.929937 25496 net.cpp:301] conv3_3_0 needs backward computation.
I0929 16:32:17.929944 25496 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I0929 16:32:17.929949 25496 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I0929 16:32:17.929960 25496 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I0929 16:32:17.929966 25496 net.cpp:301] conv3_2_scale1 needs backward computation.
I0929 16:32:17.929971 25496 net.cpp:301] conv3_2bn1 needs backward computation.
I0929 16:32:17.929975 25496 net.cpp:301] conv3_2_1 needs backward computation.
I0929 16:32:17.929980 25496 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I0929 16:32:17.929985 25496 net.cpp:301] conv3_2_scale0 needs backward computation.
I0929 16:32:17.929988 25496 net.cpp:301] conv3_2_bn0 needs backward computation.
I0929 16:32:17.929993 25496 net.cpp:301] conv3_2_0 needs backward computation.
I0929 16:32:17.929998 25496 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I0929 16:32:17.930003 25496 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I0929 16:32:17.930008 25496 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I0929 16:32:17.930013 25496 net.cpp:301] conv3_1_scale_down needs backward computation.
I0929 16:32:17.930018 25496 net.cpp:301] conv3_1_bn_down needs backward computation.
I0929 16:32:17.930022 25496 net.cpp:301] conv3_1_down needs backward computation.
I0929 16:32:17.930027 25496 net.cpp:301] conv3_1_scale1 needs backward computation.
I0929 16:32:17.930032 25496 net.cpp:301] conv3_1bn1 needs backward computation.
I0929 16:32:17.930037 25496 net.cpp:301] conv3_1_1 needs backward computation.
I0929 16:32:17.930040 25496 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I0929 16:32:17.930054 25496 net.cpp:301] conv3_1_scale0 needs backward computation.
I0929 16:32:17.930058 25496 net.cpp:301] conv3_1_bn0 needs backward computation.
I0929 16:32:17.930063 25496 net.cpp:301] conv3_1_0 needs backward computation.
I0929 16:32:17.930068 25496 net.cpp:301] conv2_Eltwise_5_conv2_5ReLU_1_0_split needs backward computation.
I0929 16:32:17.930073 25496 net.cpp:301] conv2_5ReLU_1 needs backward computation.
I0929 16:32:17.930078 25496 net.cpp:301] conv2_Eltwise_5 needs backward computation.
I0929 16:32:17.930083 25496 net.cpp:301] conv2_5_scale1 needs backward computation.
I0929 16:32:17.930092 25496 net.cpp:301] conv2_5bn1 needs backward computation.
I0929 16:32:17.930096 25496 net.cpp:301] conv2_5_1 needs backward computation.
I0929 16:32:17.930101 25496 net.cpp:301] conv2_5_ReLU0 needs backward computation.
I0929 16:32:17.930106 25496 net.cpp:301] conv2_5_scale0 needs backward computation.
I0929 16:32:17.930110 25496 net.cpp:301] conv2_5_bn0 needs backward computation.
I0929 16:32:17.930115 25496 net.cpp:301] conv2_5_0 needs backward computation.
I0929 16:32:17.930120 25496 net.cpp:301] conv2_Eltwise_4_conv2_4ReLU_1_0_split needs backward computation.
I0929 16:32:17.930125 25496 net.cpp:301] conv2_4ReLU_1 needs backward computation.
I0929 16:32:17.930130 25496 net.cpp:301] conv2_Eltwise_4 needs backward computation.
I0929 16:32:17.930135 25496 net.cpp:301] conv2_4_scale1 needs backward computation.
I0929 16:32:17.930140 25496 net.cpp:301] conv2_4bn1 needs backward computation.
I0929 16:32:17.930145 25496 net.cpp:301] conv2_4_1 needs backward computation.
I0929 16:32:17.930150 25496 net.cpp:301] conv2_4_ReLU0 needs backward computation.
I0929 16:32:17.930155 25496 net.cpp:301] conv2_4_scale0 needs backward computation.
I0929 16:32:17.930160 25496 net.cpp:301] conv2_4_bn0 needs backward computation.
I0929 16:32:17.930163 25496 net.cpp:301] conv2_4_0 needs backward computation.
I0929 16:32:17.930168 25496 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I0929 16:32:17.930173 25496 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I0929 16:32:17.930178 25496 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I0929 16:32:17.930183 25496 net.cpp:301] conv2_3_scale1 needs backward computation.
I0929 16:32:17.930188 25496 net.cpp:301] conv2_3bn1 needs backward computation.
I0929 16:32:17.930192 25496 net.cpp:301] conv2_3_1 needs backward computation.
I0929 16:32:17.930197 25496 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I0929 16:32:17.930202 25496 net.cpp:301] conv2_3_scale0 needs backward computation.
I0929 16:32:17.930214 25496 net.cpp:301] conv2_3_bn0 needs backward computation.
I0929 16:32:17.930219 25496 net.cpp:301] conv2_3_0 needs backward computation.
I0929 16:32:17.930223 25496 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I0929 16:32:17.930229 25496 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I0929 16:32:17.930234 25496 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I0929 16:32:17.930239 25496 net.cpp:301] conv2_2_scale1 needs backward computation.
I0929 16:32:17.930243 25496 net.cpp:301] conv2_2bn1 needs backward computation.
I0929 16:32:17.930248 25496 net.cpp:301] conv2_2_1 needs backward computation.
I0929 16:32:17.930253 25496 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I0929 16:32:17.930258 25496 net.cpp:301] conv2_2_scale0 needs backward computation.
I0929 16:32:17.930261 25496 net.cpp:301] conv2_2_bn0 needs backward computation.
I0929 16:32:17.930266 25496 net.cpp:301] conv2_2_0 needs backward computation.
I0929 16:32:17.930271 25496 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I0929 16:32:17.930276 25496 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I0929 16:32:17.930281 25496 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I0929 16:32:17.930286 25496 net.cpp:301] conv2_1_scale1 needs backward computation.
I0929 16:32:17.930291 25496 net.cpp:301] conv2_1bn1 needs backward computation.
I0929 16:32:17.930296 25496 net.cpp:301] conv2_1_1 needs backward computation.
I0929 16:32:17.930301 25496 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I0929 16:32:17.930305 25496 net.cpp:301] conv2_1_scale0 needs backward computation.
I0929 16:32:17.930310 25496 net.cpp:301] conv2_1_bn0 needs backward computation.
I0929 16:32:17.930315 25496 net.cpp:301] conv2_1_0 needs backward computation.
I0929 16:32:17.930320 25496 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I0929 16:32:17.930325 25496 net.cpp:301] conv1/ReLU needs backward computation.
I0929 16:32:17.930330 25496 net.cpp:301] conv1/scale needs backward computation.
I0929 16:32:17.930335 25496 net.cpp:301] conv1/bn needs backward computation.
I0929 16:32:17.930338 25496 net.cpp:301] conv1 needs backward computation.
I0929 16:32:17.930347 25496 net.cpp:303] label_Data1_1_split does not need backward computation.
I0929 16:32:17.930353 25496 net.cpp:303] Data1 does not need backward computation.
I0929 16:32:17.930357 25496 net.cpp:348] This network produces output Softmax1
I0929 16:32:17.930361 25496 net.cpp:348] This network produces output prob
I0929 16:32:17.930450 25496 net.cpp:363] Network initialization done.
I0929 16:32:17.931195 25496 solver.cpp:110] Solver scaffolding done.
I0929 16:32:17.944911 25496 caffe.cpp:313] Starting Optimization
I0929 16:32:17.944933 25496 solver.cpp:425] Solving ResNet-32
I0929 16:32:17.944938 25496 solver.cpp:427] Learning Rate Policy: multistep
I0929 16:32:17.950173 25496 solver.cpp:514] Iteration 0, Testing net (#0)
I0929 16:32:45.707247 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:32:45.847765 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.30259 (* 1 = 2.30259 loss)
I0929 16:32:45.847792 25496 solver.cpp:580]     Test net output #1: prob = 0
I0929 16:32:46.271399 25496 solver.cpp:357] Iteration 0 (0 iter/s, 28.3243s/100 iters), loss = 3.35153
I0929 16:32:46.271478 25496 solver.cpp:376]     Train net output #0: Softmax1 = 3.35153 (* 1 = 3.35153 loss)
I0929 16:32:46.271515 25496 sgd_solver.cpp:165] Iteration 0, lr = 0.1
I0929 16:33:31.043220 25496 solver.cpp:357] Iteration 100 (2.23372 iter/s, 44.7684s/100 iters), loss = 1.7339
I0929 16:33:31.043375 25496 solver.cpp:376]     Train net output #0: Softmax1 = 1.7339 (* 1 = 1.7339 loss)
I0929 16:33:31.043390 25496 sgd_solver.cpp:165] Iteration 100, lr = 0.1
I0929 16:34:21.480650 25496 solver.cpp:357] Iteration 200 (1.98279 iter/s, 50.4341s/100 iters), loss = 1.40333
I0929 16:34:21.480890 25496 solver.cpp:376]     Train net output #0: Softmax1 = 1.40333 (* 1 = 1.40333 loss)
I0929 16:34:21.480903 25496 sgd_solver.cpp:165] Iteration 200, lr = 0.1
I0929 16:35:12.554230 25496 solver.cpp:357] Iteration 300 (1.95808 iter/s, 51.0704s/100 iters), loss = 1.36453
I0929 16:35:12.555629 25496 solver.cpp:376]     Train net output #0: Softmax1 = 1.36453 (* 1 = 1.36453 loss)
I0929 16:35:12.555683 25496 sgd_solver.cpp:165] Iteration 300, lr = 0.1
I0929 16:35:56.309204 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:36:03.188746 25496 solver.cpp:357] Iteration 400 (1.97506 iter/s, 50.6315s/100 iters), loss = 1.31817
I0929 16:36:03.188907 25496 solver.cpp:376]     Train net output #0: Softmax1 = 1.31817 (* 1 = 1.31817 loss)
I0929 16:36:03.188935 25496 sgd_solver.cpp:165] Iteration 400, lr = 0.1
I0929 16:36:53.752044 25496 solver.cpp:514] Iteration 500, Testing net (#0)
I0929 16:37:26.622671 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:37:26.670545 25496 solver.cpp:580]     Test net output #0: Softmax1 = 3.53667 (* 1 = 3.53667 loss)
I0929 16:37:26.670668 25496 solver.cpp:580]     Test net output #1: prob = 0.1863
I0929 16:37:27.093605 25496 solver.cpp:357] Iteration 500 (1.1919 iter/s, 83.8995s/100 iters), loss = 1.06748
I0929 16:37:27.093771 25496 solver.cpp:376]     Train net output #0: Softmax1 = 1.06748 (* 1 = 1.06748 loss)
I0929 16:37:27.093801 25496 sgd_solver.cpp:165] Iteration 500, lr = 0.1
I0929 16:38:18.053510 25496 solver.cpp:357] Iteration 600 (1.96251 iter/s, 50.9551s/100 iters), loss = 0.981207
I0929 16:38:18.054435 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.981207 (* 1 = 0.981207 loss)
I0929 16:38:18.054482 25496 sgd_solver.cpp:165] Iteration 600, lr = 0.1
I0929 16:39:08.784770 25496 solver.cpp:357] Iteration 700 (1.97127 iter/s, 50.7287s/100 iters), loss = 0.848351
I0929 16:39:08.785069 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.848351 (* 1 = 0.848351 loss)
I0929 16:39:08.785096 25496 sgd_solver.cpp:165] Iteration 700, lr = 0.1
I0929 16:39:47.943130 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:39:59.532693 25496 solver.cpp:357] Iteration 800 (1.97062 iter/s, 50.7455s/100 iters), loss = 0.925441
I0929 16:39:59.532831 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.925441 (* 1 = 0.925441 loss)
I0929 16:39:59.532857 25496 sgd_solver.cpp:165] Iteration 800, lr = 0.1
I0929 16:40:50.450750 25496 solver.cpp:357] Iteration 900 (1.96403 iter/s, 50.9156s/100 iters), loss = 0.931237
I0929 16:40:50.450966 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.931237 (* 1 = 0.931237 loss)
I0929 16:40:50.450994 25496 sgd_solver.cpp:165] Iteration 900, lr = 0.1
I0929 16:41:41.075806 25496 solver.cpp:514] Iteration 1000, Testing net (#0)
I0929 16:42:13.846838 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:42:13.929875 25496 solver.cpp:580]     Test net output #0: Softmax1 = 3.39176 (* 1 = 3.39176 loss)
I0929 16:42:13.931234 25496 solver.cpp:580]     Test net output #1: prob = 0.104399
I0929 16:42:14.378832 25496 solver.cpp:357] Iteration 1000 (1.19153 iter/s, 83.9258s/100 iters), loss = 0.783484
I0929 16:42:14.378968 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.783484 (* 1 = 0.783484 loss)
I0929 16:42:14.378993 25496 sgd_solver.cpp:165] Iteration 1000, lr = 0.1
I0929 16:43:00.645259 25496 solver.cpp:357] Iteration 1100 (2.1615 iter/s, 46.2642s/100 iters), loss = 0.750333
I0929 16:43:00.645419 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.750333 (* 1 = 0.750333 loss)
I0929 16:43:00.645431 25496 sgd_solver.cpp:165] Iteration 1100, lr = 0.1
I0929 16:43:28.631747 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:43:42.228648 25496 solver.cpp:357] Iteration 1200 (2.40481 iter/s, 41.5833s/100 iters), loss = 0.742776
I0929 16:43:42.228842 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.742776 (* 1 = 0.742776 loss)
I0929 16:43:42.228853 25496 sgd_solver.cpp:165] Iteration 1200, lr = 0.1
I0929 16:44:24.110482 25496 solver.cpp:357] Iteration 1300 (2.38779 iter/s, 41.8798s/100 iters), loss = 0.689518
I0929 16:44:24.110729 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.689518 (* 1 = 0.689518 loss)
I0929 16:44:24.110743 25496 sgd_solver.cpp:165] Iteration 1300, lr = 0.1
I0929 16:45:06.103767 25496 solver.cpp:357] Iteration 1400 (2.38145 iter/s, 41.9912s/100 iters), loss = 0.691515
I0929 16:45:06.103971 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.691515 (* 1 = 0.691515 loss)
I0929 16:45:06.103983 25496 sgd_solver.cpp:165] Iteration 1400, lr = 0.1
I0929 16:45:48.083149 25496 solver.cpp:514] Iteration 1500, Testing net (#0)
I0929 16:46:15.922652 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:46:16.062933 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.94182 (* 1 = 2.94182 loss)
I0929 16:46:16.062986 25496 solver.cpp:580]     Test net output #1: prob = 0.109599
I0929 16:46:16.063014 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_1500.caffemodel
I0929 16:46:16.092322 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_1500.solverstate
I0929 16:46:16.096554 25496 solver.cpp:593]     Max_acc: 0.109599  with iter: 1500
I0929 16:46:16.442492 25496 solver.cpp:357] Iteration 1500 (1.42173 iter/s, 70.3368s/100 iters), loss = 0.59907
I0929 16:46:16.442565 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.59907 (* 1 = 0.59907 loss)
I0929 16:46:16.442577 25496 sgd_solver.cpp:165] Iteration 1500, lr = 0.1
I0929 16:46:40.727509 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:46:58.157253 25496 solver.cpp:357] Iteration 1600 (2.39735 iter/s, 41.7128s/100 iters), loss = 0.681211
I0929 16:46:58.157343 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.681211 (* 1 = 0.681211 loss)
I0929 16:46:58.157356 25496 sgd_solver.cpp:165] Iteration 1600, lr = 0.1
I0929 16:47:39.836966 25496 solver.cpp:357] Iteration 1700 (2.39936 iter/s, 41.6778s/100 iters), loss = 0.790254
I0929 16:47:39.837110 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.790254 (* 1 = 0.790254 loss)
I0929 16:47:39.837119 25496 sgd_solver.cpp:165] Iteration 1700, lr = 0.1
I0929 16:48:21.824749 25496 solver.cpp:357] Iteration 1800 (2.38164 iter/s, 41.9879s/100 iters), loss = 0.858606
I0929 16:48:21.824923 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.858606 (* 1 = 0.858606 loss)
I0929 16:48:21.824934 25496 sgd_solver.cpp:165] Iteration 1800, lr = 0.1
I0929 16:49:03.353494 25496 solver.cpp:357] Iteration 1900 (2.40808 iter/s, 41.5269s/100 iters), loss = 0.655064
I0929 16:49:03.353680 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.655064 (* 1 = 0.655064 loss)
I0929 16:49:03.353693 25496 sgd_solver.cpp:165] Iteration 1900, lr = 0.1
I0929 16:49:23.909826 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:49:44.754220 25496 solver.cpp:514] Iteration 2000, Testing net (#0)
I0929 16:50:12.642146 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:50:12.727919 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.86732 (* 1 = 2.86732 loss)
I0929 16:50:12.727963 25496 solver.cpp:580]     Test net output #1: prob = 0.126299
I0929 16:50:12.727980 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_2000.caffemodel
I0929 16:50:12.742478 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_2000.solverstate
I0929 16:50:12.746801 25496 solver.cpp:593]     Max_acc: 0.126299  with iter: 2000
I0929 16:50:13.123948 25496 solver.cpp:357] Iteration 2000 (1.43331 iter/s, 69.7688s/100 iters), loss = 0.592082
I0929 16:50:13.124001 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.592082 (* 1 = 0.592082 loss)
I0929 16:50:13.124014 25496 sgd_solver.cpp:165] Iteration 2000, lr = 0.1
I0929 16:50:54.932672 25496 solver.cpp:357] Iteration 2100 (2.39195 iter/s, 41.8068s/100 iters), loss = 0.638665
I0929 16:50:54.932876 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.638665 (* 1 = 0.638665 loss)
I0929 16:50:54.932888 25496 sgd_solver.cpp:165] Iteration 2100, lr = 0.1
I0929 16:51:36.898257 25496 solver.cpp:357] Iteration 2200 (2.3829 iter/s, 41.9657s/100 iters), loss = 0.68112
I0929 16:51:36.898439 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.68112 (* 1 = 0.68112 loss)
I0929 16:51:36.898452 25496 sgd_solver.cpp:165] Iteration 2200, lr = 0.1
I0929 16:52:19.232534 25496 solver.cpp:357] Iteration 2300 (2.36225 iter/s, 42.3325s/100 iters), loss = 0.556282
I0929 16:52:19.232715 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.556282 (* 1 = 0.556282 loss)
I0929 16:52:19.232728 25496 sgd_solver.cpp:165] Iteration 2300, lr = 0.1
I0929 16:52:35.911480 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:53:00.869633 25496 solver.cpp:357] Iteration 2400 (2.40181 iter/s, 41.6353s/100 iters), loss = 0.537361
I0929 16:53:00.869760 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.537361 (* 1 = 0.537361 loss)
I0929 16:53:00.869772 25496 sgd_solver.cpp:165] Iteration 2400, lr = 0.1
I0929 16:53:42.535271 25496 solver.cpp:514] Iteration 2500, Testing net (#0)
I0929 16:54:10.414281 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:54:10.449168 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.67703 (* 1 = 2.67703 loss)
I0929 16:54:10.449201 25496 solver.cpp:580]     Test net output #1: prob = 0.118499
I0929 16:54:10.449210 25496 solver.cpp:593]     Max_acc: 0.126299  with iter: 2000
I0929 16:54:10.822073 25496 solver.cpp:357] Iteration 2500 (1.42957 iter/s, 69.9509s/100 iters), loss = 0.647097
I0929 16:54:10.822118 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.647097 (* 1 = 0.647097 loss)
I0929 16:54:10.822130 25496 sgd_solver.cpp:165] Iteration 2500, lr = 0.1
I0929 16:54:52.531253 25496 solver.cpp:357] Iteration 2600 (2.39766 iter/s, 41.7074s/100 iters), loss = 0.665297
I0929 16:54:52.531437 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.665297 (* 1 = 0.665297 loss)
I0929 16:54:52.531450 25496 sgd_solver.cpp:165] Iteration 2600, lr = 0.1
I0929 16:55:34.400324 25496 solver.cpp:357] Iteration 2700 (2.3885 iter/s, 41.8673s/100 iters), loss = 0.763676
I0929 16:55:34.400455 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.763676 (* 1 = 0.763676 loss)
I0929 16:55:34.400467 25496 sgd_solver.cpp:165] Iteration 2700, lr = 0.1
I0929 16:55:46.994279 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:56:16.050246 25496 solver.cpp:357] Iteration 2800 (2.40107 iter/s, 41.6482s/100 iters), loss = 0.47878
I0929 16:56:16.050426 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.47878 (* 1 = 0.47878 loss)
I0929 16:56:16.050437 25496 sgd_solver.cpp:165] Iteration 2800, lr = 0.1
I0929 16:56:58.073909 25496 solver.cpp:357] Iteration 2900 (2.37971 iter/s, 42.0219s/100 iters), loss = 0.582089
I0929 16:56:58.074079 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.582089 (* 1 = 0.582089 loss)
I0929 16:56:58.074091 25496 sgd_solver.cpp:165] Iteration 2900, lr = 0.1
I0929 16:57:39.549453 25496 solver.cpp:514] Iteration 3000, Testing net (#0)
I0929 16:58:07.337357 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:58:07.466027 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.6678 (* 1 = 2.6678 loss)
I0929 16:58:07.466053 25496 solver.cpp:580]     Test net output #1: prob = 0.124299
I0929 16:58:07.466060 25496 solver.cpp:593]     Max_acc: 0.126299  with iter: 2000
I0929 16:58:07.735271 25496 solver.cpp:357] Iteration 3000 (1.4355 iter/s, 69.662s/100 iters), loss = 0.634526
I0929 16:58:07.735364 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.634526 (* 1 = 0.634526 loss)
I0929 16:58:07.735378 25496 sgd_solver.cpp:165] Iteration 3000, lr = 0.1
I0929 16:58:49.782482 25496 solver.cpp:357] Iteration 3100 (2.37834 iter/s, 42.0461s/100 iters), loss = 0.69923
I0929 16:58:49.782658 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.69923 (* 1 = 0.69923 loss)
I0929 16:58:49.782671 25496 sgd_solver.cpp:165] Iteration 3100, lr = 0.1
I0929 16:58:58.257812 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 16:59:31.630142 25496 solver.cpp:357] Iteration 3200 (2.38956 iter/s, 41.8487s/100 iters), loss = 0.613162
I0929 16:59:31.630344 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.613162 (* 1 = 0.613162 loss)
I0929 16:59:31.630357 25496 sgd_solver.cpp:165] Iteration 3200, lr = 0.1
I0929 17:00:13.331609 25496 solver.cpp:357] Iteration 3300 (2.39806 iter/s, 41.7005s/100 iters), loss = 0.648353
I0929 17:00:13.331743 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.648353 (* 1 = 0.648353 loss)
I0929 17:00:13.331754 25496 sgd_solver.cpp:165] Iteration 3300, lr = 0.1
I0929 17:00:55.220443 25496 solver.cpp:357] Iteration 3400 (2.38733 iter/s, 41.8878s/100 iters), loss = 0.484821
I0929 17:00:55.220634 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.484821 (* 1 = 0.484821 loss)
I0929 17:00:55.220646 25496 sgd_solver.cpp:165] Iteration 3400, lr = 0.1
I0929 17:01:36.482290 25496 solver.cpp:514] Iteration 3500, Testing net (#0)
I0929 17:02:04.322634 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:02:04.368588 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.26788 (* 1 = 2.26788 loss)
I0929 17:02:04.368628 25496 solver.cpp:580]     Test net output #1: prob = 0.2456
I0929 17:02:04.368641 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_3500.caffemodel
I0929 17:02:04.384064 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_3500.solverstate
I0929 17:02:04.388290 25496 solver.cpp:593]     Max_acc: 0.2456  with iter: 3500
I0929 17:02:04.761461 25496 solver.cpp:357] Iteration 3500 (1.43801 iter/s, 69.5407s/100 iters), loss = 0.648522
I0929 17:02:04.761512 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.648522 (* 1 = 0.648522 loss)
I0929 17:02:04.761526 25496 sgd_solver.cpp:165] Iteration 3500, lr = 0.1
I0929 17:02:09.476172 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:02:46.498205 25496 solver.cpp:357] Iteration 3600 (2.39604 iter/s, 41.7356s/100 iters), loss = 0.616925
I0929 17:02:46.498342 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.616925 (* 1 = 0.616925 loss)
I0929 17:02:46.498353 25496 sgd_solver.cpp:165] Iteration 3600, lr = 0.1
I0929 17:03:28.503556 25496 solver.cpp:357] Iteration 3700 (2.38072 iter/s, 42.0042s/100 iters), loss = 0.521169
I0929 17:03:28.503701 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.521169 (* 1 = 0.521169 loss)
I0929 17:03:28.503715 25496 sgd_solver.cpp:165] Iteration 3700, lr = 0.1
I0929 17:04:10.416957 25496 solver.cpp:357] Iteration 3800 (2.38594 iter/s, 41.9122s/100 iters), loss = 0.468252
I0929 17:04:10.417125 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.468252 (* 1 = 0.468252 loss)
I0929 17:04:10.417138 25496 sgd_solver.cpp:165] Iteration 3800, lr = 0.1
I0929 17:04:52.341023 25496 solver.cpp:357] Iteration 3900 (2.38533 iter/s, 41.9229s/100 iters), loss = 0.608243
I0929 17:04:52.341172 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.608243 (* 1 = 0.608243 loss)
I0929 17:04:52.341186 25496 sgd_solver.cpp:165] Iteration 3900, lr = 0.1
I0929 17:04:53.244467 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:05:33.945781 25496 solver.cpp:514] Iteration 4000, Testing net (#0)
I0929 17:06:01.708328 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:06:01.761907 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.07934 (* 1 = 2.07934 loss)
I0929 17:06:01.761965 25496 solver.cpp:580]     Test net output #1: prob = 0.3102
I0929 17:06:01.761981 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_4000.caffemodel
I0929 17:06:01.777632 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_4000.solverstate
I0929 17:06:01.781846 25496 solver.cpp:593]     Max_acc: 0.3102  with iter: 4000
I0929 17:06:02.153357 25496 solver.cpp:357] Iteration 4000 (1.43242 iter/s, 69.8118s/100 iters), loss = 0.642353
I0929 17:06:02.153414 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.642353 (* 1 = 0.642353 loss)
I0929 17:06:02.153425 25496 sgd_solver.cpp:165] Iteration 4000, lr = 0.1
I0929 17:06:43.858696 25496 solver.cpp:357] Iteration 4100 (2.39783 iter/s, 41.7043s/100 iters), loss = 0.566475
I0929 17:06:43.858952 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.566475 (* 1 = 0.566475 loss)
I0929 17:06:43.858964 25496 sgd_solver.cpp:165] Iteration 4100, lr = 0.1
I0929 17:07:25.637583 25496 solver.cpp:357] Iteration 4200 (2.39363 iter/s, 41.7776s/100 iters), loss = 0.485735
I0929 17:07:25.637768 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.485735 (* 1 = 0.485735 loss)
I0929 17:07:25.637780 25496 sgd_solver.cpp:165] Iteration 4200, lr = 0.1
I0929 17:08:04.341344 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:08:07.615169 25496 solver.cpp:357] Iteration 4300 (2.3823 iter/s, 41.9763s/100 iters), loss = 0.527983
I0929 17:08:07.615242 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.527983 (* 1 = 0.527983 loss)
I0929 17:08:07.615253 25496 sgd_solver.cpp:165] Iteration 4300, lr = 0.1
I0929 17:08:49.294339 25496 solver.cpp:357] Iteration 4400 (2.39923 iter/s, 41.68s/100 iters), loss = 0.536413
I0929 17:08:49.294471 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.536413 (* 1 = 0.536413 loss)
I0929 17:08:49.294484 25496 sgd_solver.cpp:165] Iteration 4400, lr = 0.1
I0929 17:09:31.035537 25496 solver.cpp:514] Iteration 4500, Testing net (#0)
I0929 17:09:58.829233 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:09:58.878569 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.76313 (* 1 = 1.76313 loss)
I0929 17:09:58.878608 25496 solver.cpp:580]     Test net output #1: prob = 0.4357
I0929 17:09:58.878623 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_4500.caffemodel
I0929 17:09:58.893321 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_4500.solverstate
I0929 17:09:58.897544 25496 solver.cpp:593]     Max_acc: 0.4357  with iter: 4500
I0929 17:09:59.270256 25496 solver.cpp:357] Iteration 4500 (1.42908 iter/s, 69.9751s/100 iters), loss = 0.622852
I0929 17:09:59.270308 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.622852 (* 1 = 0.622852 loss)
I0929 17:09:59.270321 25496 sgd_solver.cpp:165] Iteration 4500, lr = 0.1
I0929 17:10:41.131744 25496 solver.cpp:357] Iteration 4600 (2.38891 iter/s, 41.8601s/100 iters), loss = 0.447832
I0929 17:10:41.131935 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.447832 (* 1 = 0.447832 loss)
I0929 17:10:41.131949 25496 sgd_solver.cpp:165] Iteration 4600, lr = 0.1
I0929 17:11:16.264798 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:11:23.401301 25496 solver.cpp:357] Iteration 4700 (2.36585 iter/s, 42.2682s/100 iters), loss = 0.485635
I0929 17:11:23.401381 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.485635 (* 1 = 0.485635 loss)
I0929 17:11:23.401393 25496 sgd_solver.cpp:165] Iteration 4700, lr = 0.1
I0929 17:12:05.032918 25496 solver.cpp:357] Iteration 4800 (2.4021 iter/s, 41.6302s/100 iters), loss = 0.425596
I0929 17:12:05.033054 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.425596 (* 1 = 0.425596 loss)
I0929 17:12:05.033066 25496 sgd_solver.cpp:165] Iteration 4800, lr = 0.1
I0929 17:12:46.765430 25496 solver.cpp:357] Iteration 4900 (2.39618 iter/s, 41.7332s/100 iters), loss = 0.473183
I0929 17:12:46.765537 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.473183 (* 1 = 0.473183 loss)
I0929 17:12:46.765548 25496 sgd_solver.cpp:165] Iteration 4900, lr = 0.1
I0929 17:13:28.122617 25496 solver.cpp:514] Iteration 5000, Testing net (#0)
I0929 17:13:55.651125 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:13:55.689229 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.51891 (* 1 = 1.51891 loss)
I0929 17:13:55.689260 25496 solver.cpp:580]     Test net output #1: prob = 0.4774
I0929 17:13:55.689276 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_5000.caffemodel
I0929 17:13:55.705982 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_5000.solverstate
I0929 17:13:55.710222 25496 solver.cpp:593]     Max_acc: 0.4774  with iter: 5000
I0929 17:13:56.068583 25496 solver.cpp:357] Iteration 5000 (1.44291 iter/s, 69.3043s/100 iters), loss = 0.369329
I0929 17:13:56.068631 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.369329 (* 1 = 0.369329 loss)
I0929 17:13:56.068644 25496 sgd_solver.cpp:165] Iteration 5000, lr = 0.1
I0929 17:14:26.951210 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:14:37.728299 25496 solver.cpp:357] Iteration 5100 (2.40036 iter/s, 41.6604s/100 iters), loss = 0.496197
I0929 17:14:37.728382 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.496197 (* 1 = 0.496197 loss)
I0929 17:14:37.728395 25496 sgd_solver.cpp:165] Iteration 5100, lr = 0.1
I0929 17:15:19.582880 25496 solver.cpp:357] Iteration 5200 (2.38931 iter/s, 41.8531s/100 iters), loss = 0.636994
I0929 17:15:19.583040 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.636994 (* 1 = 0.636994 loss)
I0929 17:15:19.583052 25496 sgd_solver.cpp:165] Iteration 5200, lr = 0.1
I0929 17:16:01.558461 25496 solver.cpp:357] Iteration 5300 (2.38242 iter/s, 41.9741s/100 iters), loss = 0.617111
I0929 17:16:01.558575 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.617111 (* 1 = 0.617111 loss)
I0929 17:16:01.558588 25496 sgd_solver.cpp:165] Iteration 5300, lr = 0.1
I0929 17:16:43.638432 25496 solver.cpp:357] Iteration 5400 (2.37651 iter/s, 42.0785s/100 iters), loss = 0.291355
I0929 17:16:43.638594 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.291355 (* 1 = 0.291355 loss)
I0929 17:16:43.638607 25496 sgd_solver.cpp:165] Iteration 5400, lr = 0.1
I0929 17:17:10.380396 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:17:24.877585 25496 solver.cpp:514] Iteration 5500, Testing net (#0)
I0929 17:17:52.380424 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:17:52.428616 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.61404 (* 1 = 1.61404 loss)
I0929 17:17:52.428663 25496 solver.cpp:580]     Test net output #1: prob = 0.495
I0929 17:17:52.428679 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_5500.caffemodel
I0929 17:17:52.444953 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_5500.solverstate
I0929 17:17:52.449141 25496 solver.cpp:593]     Max_acc: 0.495  with iter: 5500
I0929 17:17:52.819264 25496 solver.cpp:357] Iteration 5500 (1.44551 iter/s, 69.1799s/100 iters), loss = 0.440148
I0929 17:17:52.819345 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.440148 (* 1 = 0.440148 loss)
I0929 17:17:52.819357 25496 sgd_solver.cpp:165] Iteration 5500, lr = 0.1
I0929 17:18:34.529721 25496 solver.cpp:357] Iteration 5600 (2.39756 iter/s, 41.709s/100 iters), loss = 0.446512
I0929 17:18:34.529892 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.446512 (* 1 = 0.446512 loss)
I0929 17:18:34.529904 25496 sgd_solver.cpp:165] Iteration 5600, lr = 0.1
I0929 17:19:16.721665 25496 solver.cpp:357] Iteration 5700 (2.3702 iter/s, 42.1905s/100 iters), loss = 0.475527
I0929 17:19:16.721812 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.475527 (* 1 = 0.475527 loss)
I0929 17:19:16.721824 25496 sgd_solver.cpp:165] Iteration 5700, lr = 0.1
I0929 17:19:58.571749 25496 solver.cpp:357] Iteration 5800 (2.38957 iter/s, 41.8486s/100 iters), loss = 0.347285
I0929 17:19:58.571923 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.347285 (* 1 = 0.347285 loss)
I0929 17:19:58.571936 25496 sgd_solver.cpp:165] Iteration 5800, lr = 0.1
I0929 17:20:21.766451 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:20:40.455771 25496 solver.cpp:357] Iteration 5900 (2.38763 iter/s, 41.8825s/100 iters), loss = 0.603553
I0929 17:20:40.455976 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.603553 (* 1 = 0.603553 loss)
I0929 17:20:40.455989 25496 sgd_solver.cpp:165] Iteration 5900, lr = 0.1
I0929 17:21:21.959149 25496 solver.cpp:514] Iteration 6000, Testing net (#0)
I0929 17:21:49.606686 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:21:49.744467 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.27075 (* 1 = 1.27075 loss)
I0929 17:21:49.744520 25496 solver.cpp:580]     Test net output #1: prob = 0.5896
I0929 17:21:49.744537 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_6000.caffemodel
I0929 17:21:49.761665 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_6000.solverstate
I0929 17:21:49.766083 25496 solver.cpp:593]     Max_acc: 0.5896  with iter: 6000
I0929 17:21:50.111861 25496 solver.cpp:357] Iteration 6000 (1.43565 iter/s, 69.6551s/100 iters), loss = 0.473152
I0929 17:21:50.111933 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.473152 (* 1 = 0.473152 loss)
I0929 17:21:50.111944 25496 sgd_solver.cpp:165] Iteration 6000, lr = 0.1
I0929 17:22:31.817765 25496 solver.cpp:357] Iteration 6100 (2.39783 iter/s, 41.7044s/100 iters), loss = 0.418918
I0929 17:22:31.817898 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.418918 (* 1 = 0.418918 loss)
I0929 17:22:31.817910 25496 sgd_solver.cpp:165] Iteration 6100, lr = 0.1
I0929 17:23:13.653885 25496 solver.cpp:357] Iteration 6200 (2.39037 iter/s, 41.8346s/100 iters), loss = 0.454171
I0929 17:23:13.654072 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.454171 (* 1 = 0.454171 loss)
I0929 17:23:13.654084 25496 sgd_solver.cpp:165] Iteration 6200, lr = 0.1
I0929 17:23:32.568027 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:23:55.464695 25496 solver.cpp:357] Iteration 6300 (2.39181 iter/s, 41.8093s/100 iters), loss = 0.378413
I0929 17:23:55.464823 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.378413 (* 1 = 0.378413 loss)
I0929 17:23:55.464835 25496 sgd_solver.cpp:165] Iteration 6300, lr = 0.1
I0929 17:24:37.193215 25496 solver.cpp:357] Iteration 6400 (2.39653 iter/s, 41.727s/100 iters), loss = 0.544372
I0929 17:24:37.193409 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.544372 (* 1 = 0.544372 loss)
I0929 17:24:37.193423 25496 sgd_solver.cpp:165] Iteration 6400, lr = 0.1
I0929 17:25:18.894176 25496 solver.cpp:514] Iteration 6500, Testing net (#0)
I0929 17:25:46.463695 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:25:46.568917 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.17654 (* 1 = 1.17654 loss)
I0929 17:25:46.568960 25496 solver.cpp:580]     Test net output #1: prob = 0.591101
I0929 17:25:46.568976 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_6500.caffemodel
I0929 17:25:46.584800 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_6500.solverstate
I0929 17:25:46.588989 25496 solver.cpp:593]     Max_acc: 0.591101  with iter: 6500
I0929 17:25:46.965013 25496 solver.cpp:357] Iteration 6500 (1.43326 iter/s, 69.7708s/100 iters), loss = 0.447336
I0929 17:25:46.965066 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.447336 (* 1 = 0.447336 loss)
I0929 17:25:46.965080 25496 sgd_solver.cpp:165] Iteration 6500, lr = 0.1
I0929 17:26:28.881665 25496 solver.cpp:357] Iteration 6600 (2.38577 iter/s, 41.9152s/100 iters), loss = 0.481456
I0929 17:26:28.881862 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.481456 (* 1 = 0.481456 loss)
I0929 17:26:28.881875 25496 sgd_solver.cpp:165] Iteration 6600, lr = 0.1
I0929 17:26:44.116617 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:27:10.934509 25496 solver.cpp:357] Iteration 6700 (2.37805 iter/s, 42.0513s/100 iters), loss = 0.553268
I0929 17:27:10.934790 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.553268 (* 1 = 0.553268 loss)
I0929 17:27:10.934804 25496 sgd_solver.cpp:165] Iteration 6700, lr = 0.1
I0929 17:27:53.001152 25496 solver.cpp:357] Iteration 6800 (2.37727 iter/s, 42.0651s/100 iters), loss = 0.464322
I0929 17:27:53.001310 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.464322 (* 1 = 0.464322 loss)
I0929 17:27:53.001323 25496 sgd_solver.cpp:165] Iteration 6800, lr = 0.1
I0929 17:28:34.670542 25496 solver.cpp:357] Iteration 6900 (2.39993 iter/s, 41.6679s/100 iters), loss = 0.478123
I0929 17:28:34.670675 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.478123 (* 1 = 0.478123 loss)
I0929 17:28:34.670686 25496 sgd_solver.cpp:165] Iteration 6900, lr = 0.1
I0929 17:29:15.896873 25496 solver.cpp:514] Iteration 7000, Testing net (#0)
I0929 17:29:43.595612 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:29:43.626713 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.87768 (* 1 = 1.87768 loss)
I0929 17:29:43.626747 25496 solver.cpp:580]     Test net output #1: prob = 0.4911
I0929 17:29:43.626754 25496 solver.cpp:593]     Max_acc: 0.591101  with iter: 6500
I0929 17:29:43.997707 25496 solver.cpp:357] Iteration 7000 (1.44246 iter/s, 69.3261s/100 iters), loss = 0.410394
I0929 17:29:43.997756 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.410394 (* 1 = 0.410394 loss)
I0929 17:29:43.997773 25496 sgd_solver.cpp:165] Iteration 7000, lr = 0.1
I0929 17:29:55.298669 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:30:25.662196 25496 solver.cpp:357] Iteration 7100 (2.40021 iter/s, 41.6629s/100 iters), loss = 0.48258
I0929 17:30:25.662372 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.48258 (* 1 = 0.48258 loss)
I0929 17:30:25.662385 25496 sgd_solver.cpp:165] Iteration 7100, lr = 0.1
I0929 17:31:07.561529 25496 solver.cpp:357] Iteration 7200 (2.38676 iter/s, 41.8978s/100 iters), loss = 0.547737
I0929 17:31:07.561699 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.547737 (* 1 = 0.547737 loss)
I0929 17:31:07.561712 25496 sgd_solver.cpp:165] Iteration 7200, lr = 0.1
I0929 17:31:49.479938 25496 solver.cpp:357] Iteration 7300 (2.38567 iter/s, 41.9169s/100 iters), loss = 0.321301
I0929 17:31:49.480099 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.321301 (* 1 = 0.321301 loss)
I0929 17:31:49.480111 25496 sgd_solver.cpp:165] Iteration 7300, lr = 0.1
I0929 17:32:31.628653 25496 solver.cpp:357] Iteration 7400 (2.37247 iter/s, 42.1501s/100 iters), loss = 0.546155
I0929 17:32:31.628824 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.546155 (* 1 = 0.546155 loss)
I0929 17:32:31.628836 25496 sgd_solver.cpp:165] Iteration 7400, lr = 0.1
I0929 17:32:38.837993 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:33:13.284173 25496 solver.cpp:514] Iteration 7500, Testing net (#0)
I0929 17:33:40.922053 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:33:41.043839 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.74584 (* 1 = 1.74584 loss)
I0929 17:33:41.043870 25496 solver.cpp:580]     Test net output #1: prob = 0.449099
I0929 17:33:41.043879 25496 solver.cpp:593]     Max_acc: 0.591101  with iter: 6500
I0929 17:33:41.413440 25496 solver.cpp:357] Iteration 7500 (1.43268 iter/s, 69.7991s/100 iters), loss = 0.418155
I0929 17:33:41.413588 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.418155 (* 1 = 0.418155 loss)
I0929 17:33:41.413604 25496 sgd_solver.cpp:165] Iteration 7500, lr = 0.1
I0929 17:34:23.219993 25496 solver.cpp:357] Iteration 7600 (2.39146 iter/s, 41.8155s/100 iters), loss = 0.411831
I0929 17:34:23.220109 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.411831 (* 1 = 0.411831 loss)
I0929 17:34:23.220121 25496 sgd_solver.cpp:165] Iteration 7600, lr = 0.1
I0929 17:35:04.952643 25496 solver.cpp:357] Iteration 7700 (2.39573 iter/s, 41.741s/100 iters), loss = 0.449997
I0929 17:35:04.952800 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.449997 (* 1 = 0.449997 loss)
I0929 17:35:04.952811 25496 sgd_solver.cpp:165] Iteration 7700, lr = 0.1
I0929 17:35:46.862709 25496 solver.cpp:357] Iteration 7800 (2.38562 iter/s, 41.9179s/100 iters), loss = 0.370648
I0929 17:35:46.862856 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.370648 (* 1 = 0.370648 loss)
I0929 17:35:46.862869 25496 sgd_solver.cpp:165] Iteration 7800, lr = 0.1
I0929 17:35:50.350108 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:36:28.645870 25496 solver.cpp:357] Iteration 7900 (2.39301 iter/s, 41.7884s/100 iters), loss = 0.457251
I0929 17:36:28.646070 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.457251 (* 1 = 0.457251 loss)
I0929 17:36:28.646083 25496 sgd_solver.cpp:165] Iteration 7900, lr = 0.1
I0929 17:37:10.035403 25496 solver.cpp:514] Iteration 8000, Testing net (#0)
I0929 17:37:37.487187 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:37:37.627084 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.923419 (* 1 = 0.923419 loss)
I0929 17:37:37.627120 25496 solver.cpp:580]     Test net output #1: prob = 0.6998
I0929 17:37:37.627133 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_8000.caffemodel
I0929 17:37:37.644481 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_8000.solverstate
I0929 17:37:37.649220 25496 solver.cpp:593]     Max_acc: 0.6998  with iter: 8000
I0929 17:37:37.994662 25496 solver.cpp:357] Iteration 8000 (1.44179 iter/s, 69.3581s/100 iters), loss = 0.410562
I0929 17:37:37.994741 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.410562 (* 1 = 0.410562 loss)
I0929 17:37:37.994752 25496 sgd_solver.cpp:165] Iteration 8000, lr = 0.1
I0929 17:38:19.842852 25496 solver.cpp:357] Iteration 8100 (2.38935 iter/s, 41.8524s/100 iters), loss = 0.32908
I0929 17:38:19.842996 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.32908 (* 1 = 0.32908 loss)
I0929 17:38:19.843006 25496 sgd_solver.cpp:165] Iteration 8100, lr = 0.1
I0929 17:39:01.040278 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:39:01.407913 25496 solver.cpp:357] Iteration 8200 (2.40553 iter/s, 41.5708s/100 iters), loss = 0.440533
I0929 17:39:01.408007 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.440533 (* 1 = 0.440533 loss)
I0929 17:39:01.408020 25496 sgd_solver.cpp:165] Iteration 8200, lr = 0.1
I0929 17:39:43.023517 25496 solver.cpp:357] Iteration 8300 (2.40274 iter/s, 41.6191s/100 iters), loss = 0.499686
I0929 17:39:43.023700 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.499686 (* 1 = 0.499686 loss)
I0929 17:39:43.023713 25496 sgd_solver.cpp:165] Iteration 8300, lr = 0.1
I0929 17:40:24.779965 25496 solver.cpp:357] Iteration 8400 (2.39466 iter/s, 41.7596s/100 iters), loss = 0.356053
I0929 17:40:24.780156 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.356053 (* 1 = 0.356053 loss)
I0929 17:40:24.780169 25496 sgd_solver.cpp:165] Iteration 8400, lr = 0.1
I0929 17:41:06.196784 25496 solver.cpp:514] Iteration 8500, Testing net (#0)
I0929 17:41:33.873522 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:41:34.003408 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.0152 (* 1 = 2.0152 loss)
I0929 17:41:34.003437 25496 solver.cpp:580]     Test net output #1: prob = 0.4532
I0929 17:41:34.003445 25496 solver.cpp:593]     Max_acc: 0.6998  with iter: 8000
I0929 17:41:34.365628 25496 solver.cpp:357] Iteration 8500 (1.43695 iter/s, 69.5918s/100 iters), loss = 0.450423
I0929 17:41:34.365705 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.450423 (* 1 = 0.450423 loss)
I0929 17:41:34.365717 25496 sgd_solver.cpp:165] Iteration 8500, lr = 0.1
I0929 17:42:11.614454 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:42:16.175897 25496 solver.cpp:357] Iteration 8600 (2.39149 iter/s, 41.8149s/100 iters), loss = 0.49864
I0929 17:42:16.175992 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.49864 (* 1 = 0.49864 loss)
I0929 17:42:16.176004 25496 sgd_solver.cpp:165] Iteration 8600, lr = 0.1
I0929 17:42:57.864931 25496 solver.cpp:357] Iteration 8700 (2.39858 iter/s, 41.6913s/100 iters), loss = 0.316671
I0929 17:42:57.865075 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.316671 (* 1 = 0.316671 loss)
I0929 17:42:57.865087 25496 sgd_solver.cpp:165] Iteration 8700, lr = 0.1
I0929 17:43:39.669405 25496 solver.cpp:357] Iteration 8800 (2.39197 iter/s, 41.8065s/100 iters), loss = 0.445109
I0929 17:43:39.669585 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.445109 (* 1 = 0.445109 loss)
I0929 17:43:39.669597 25496 sgd_solver.cpp:165] Iteration 8800, lr = 0.1
I0929 17:44:21.424814 25496 solver.cpp:357] Iteration 8900 (2.39479 iter/s, 41.7573s/100 iters), loss = 0.494409
I0929 17:44:21.424993 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.494409 (* 1 = 0.494409 loss)
I0929 17:44:21.425006 25496 sgd_solver.cpp:165] Iteration 8900, lr = 0.1
I0929 17:44:54.952456 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:45:02.785194 25496 solver.cpp:514] Iteration 9000, Testing net (#0)
I0929 17:45:30.695268 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:45:30.761868 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.19818 (* 1 = 1.19818 loss)
I0929 17:45:30.761900 25496 solver.cpp:580]     Test net output #1: prob = 0.6117
I0929 17:45:30.761907 25496 solver.cpp:593]     Max_acc: 0.6998  with iter: 8000
I0929 17:45:31.136492 25496 solver.cpp:357] Iteration 9000 (1.43439 iter/s, 69.7158s/100 iters), loss = 0.285746
I0929 17:45:31.136627 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.285746 (* 1 = 0.285746 loss)
I0929 17:45:31.136656 25496 sgd_solver.cpp:165] Iteration 9000, lr = 0.1
I0929 17:46:13.054560 25496 solver.cpp:357] Iteration 9100 (2.38553 iter/s, 41.9195s/100 iters), loss = 0.422918
I0929 17:46:13.054756 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.422918 (* 1 = 0.422918 loss)
I0929 17:46:13.054770 25496 sgd_solver.cpp:165] Iteration 9100, lr = 0.1
I0929 17:46:55.194757 25496 solver.cpp:357] Iteration 9200 (2.37296 iter/s, 42.1415s/100 iters), loss = 0.392554
I0929 17:46:55.194890 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.392554 (* 1 = 0.392554 loss)
I0929 17:46:55.194901 25496 sgd_solver.cpp:165] Iteration 9200, lr = 0.1
I0929 17:47:37.071435 25496 solver.cpp:357] Iteration 9300 (2.3879 iter/s, 41.8778s/100 iters), loss = 0.402905
I0929 17:47:37.071600 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.402905 (* 1 = 0.402905 loss)
I0929 17:47:37.071614 25496 sgd_solver.cpp:165] Iteration 9300, lr = 0.1
I0929 17:48:06.581298 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:48:19.026346 25496 solver.cpp:357] Iteration 9400 (2.38345 iter/s, 41.9559s/100 iters), loss = 0.502491
I0929 17:48:19.026566 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.502491 (* 1 = 0.502491 loss)
I0929 17:48:19.026578 25496 sgd_solver.cpp:165] Iteration 9400, lr = 0.1
I0929 17:49:00.560844 25496 solver.cpp:514] Iteration 9500, Testing net (#0)
I0929 17:49:28.582078 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:49:28.721006 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.831278 (* 1 = 0.831278 loss)
I0929 17:49:28.721108 25496 solver.cpp:580]     Test net output #1: prob = 0.7093
I0929 17:49:28.721160 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_9500.caffemodel
I0929 17:49:28.738163 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_9500.solverstate
I0929 17:49:28.742715 25496 solver.cpp:593]     Max_acc: 0.7093  with iter: 9500
I0929 17:49:29.087277 25496 solver.cpp:357] Iteration 9500 (1.42727 iter/s, 70.0638s/100 iters), loss = 0.47333
I0929 17:49:29.087352 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.47333 (* 1 = 0.47333 loss)
I0929 17:49:29.087364 25496 sgd_solver.cpp:165] Iteration 9500, lr = 0.1
I0929 17:50:11.002192 25496 solver.cpp:357] Iteration 9600 (2.38574 iter/s, 41.9156s/100 iters), loss = 0.421181
I0929 17:50:11.002404 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.421181 (* 1 = 0.421181 loss)
I0929 17:50:11.002416 25496 sgd_solver.cpp:165] Iteration 9600, lr = 0.1
I0929 17:50:52.790786 25496 solver.cpp:357] Iteration 9700 (2.39285 iter/s, 41.7912s/100 iters), loss = 0.444894
I0929 17:50:52.790958 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.444894 (* 1 = 0.444894 loss)
I0929 17:50:52.790971 25496 sgd_solver.cpp:165] Iteration 9700, lr = 0.1
I0929 17:51:18.289127 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:51:34.407780 25496 solver.cpp:357] Iteration 9800 (2.40272 iter/s, 41.6196s/100 iters), loss = 0.414003
I0929 17:51:34.407944 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.414003 (* 1 = 0.414003 loss)
I0929 17:51:34.407956 25496 sgd_solver.cpp:165] Iteration 9800, lr = 0.1
I0929 17:52:16.419931 25496 solver.cpp:357] Iteration 9900 (2.38024 iter/s, 42.0126s/100 iters), loss = 0.360427
I0929 17:52:16.420122 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.360427 (* 1 = 0.360427 loss)
I0929 17:52:16.420136 25496 sgd_solver.cpp:165] Iteration 9900, lr = 0.1
I0929 17:52:57.894729 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_10000.caffemodel
I0929 17:52:57.912186 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_10000.solverstate
I0929 17:52:58.000416 25496 solver.cpp:514] Iteration 10000, Testing net (#0)
I0929 17:53:25.631793 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:53:25.772051 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.892341 (* 1 = 0.892341 loss)
I0929 17:53:25.772080 25496 solver.cpp:580]     Test net output #1: prob = 0.7275
I0929 17:53:25.772094 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_10000.caffemodel
I0929 17:53:25.782191 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_10000.solverstate
I0929 17:53:25.786972 25496 solver.cpp:593]     Max_acc: 0.7275  with iter: 10000
I0929 17:53:26.127753 25496 solver.cpp:357] Iteration 10000 (1.43452 iter/s, 69.7099s/100 iters), loss = 0.3318
I0929 17:53:26.127835 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.3318 (* 1 = 0.3318 loss)
I0929 17:53:26.127848 25496 sgd_solver.cpp:165] Iteration 10000, lr = 0.1
I0929 17:54:08.122831 25496 solver.cpp:357] Iteration 10100 (2.38121 iter/s, 41.9954s/100 iters), loss = 0.467069
I0929 17:54:08.122992 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.467069 (* 1 = 0.467069 loss)
I0929 17:54:08.123004 25496 sgd_solver.cpp:165] Iteration 10100, lr = 0.1
I0929 17:54:29.812376 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:54:49.982657 25496 solver.cpp:357] Iteration 10200 (2.3888 iter/s, 41.8621s/100 iters), loss = 0.391197
I0929 17:54:49.982798 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.391197 (* 1 = 0.391197 loss)
I0929 17:54:49.982812 25496 sgd_solver.cpp:165] Iteration 10200, lr = 0.1
I0929 17:55:31.611717 25496 solver.cpp:357] Iteration 10300 (2.40216 iter/s, 41.6292s/100 iters), loss = 0.405168
I0929 17:55:31.611896 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.405168 (* 1 = 0.405168 loss)
I0929 17:55:31.611907 25496 sgd_solver.cpp:165] Iteration 10300, lr = 0.1
I0929 17:56:13.556576 25496 solver.cpp:357] Iteration 10400 (2.38408 iter/s, 41.945s/100 iters), loss = 0.389243
I0929 17:56:13.556715 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.389243 (* 1 = 0.389243 loss)
I0929 17:56:13.556727 25496 sgd_solver.cpp:165] Iteration 10400, lr = 0.1
I0929 17:56:54.962747 25496 solver.cpp:514] Iteration 10500, Testing net (#0)
I0929 17:57:22.655026 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:57:22.709520 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.04088 (* 1 = 1.04088 loss)
I0929 17:57:22.709553 25496 solver.cpp:580]     Test net output #1: prob = 0.6731
I0929 17:57:22.709561 25496 solver.cpp:593]     Max_acc: 0.7275  with iter: 10000
I0929 17:57:23.079355 25496 solver.cpp:357] Iteration 10500 (1.43834 iter/s, 69.5244s/100 iters), loss = 0.501975
I0929 17:57:23.079411 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.501975 (* 1 = 0.501975 loss)
I0929 17:57:23.079427 25496 sgd_solver.cpp:165] Iteration 10500, lr = 0.1
I0929 17:57:40.669252 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 17:58:04.849083 25496 solver.cpp:357] Iteration 10600 (2.39408 iter/s, 41.7697s/100 iters), loss = 0.420819
I0929 17:58:04.849158 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.420819 (* 1 = 0.420819 loss)
I0929 17:58:04.849169 25496 sgd_solver.cpp:165] Iteration 10600, lr = 0.1
I0929 17:58:46.463655 25496 solver.cpp:357] Iteration 10700 (2.403 iter/s, 41.6146s/100 iters), loss = 0.431904
I0929 17:58:46.463850 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.431904 (* 1 = 0.431904 loss)
I0929 17:58:46.463862 25496 sgd_solver.cpp:165] Iteration 10700, lr = 0.1
I0929 17:59:28.673589 25496 solver.cpp:357] Iteration 10800 (2.36911 iter/s, 42.2099s/100 iters), loss = 0.425471
I0929 17:59:28.673769 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.425471 (* 1 = 0.425471 loss)
I0929 17:59:28.673782 25496 sgd_solver.cpp:165] Iteration 10800, lr = 0.1
I0929 18:00:10.174638 25496 solver.cpp:357] Iteration 10900 (2.40958 iter/s, 41.5009s/100 iters), loss = 0.419415
I0929 18:00:10.174821 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.419415 (* 1 = 0.419415 loss)
I0929 18:00:10.174834 25496 sgd_solver.cpp:165] Iteration 10900, lr = 0.1
I0929 18:00:24.022461 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:00:51.795965 25496 solver.cpp:514] Iteration 11000, Testing net (#0)
I0929 18:01:19.484401 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:01:19.527740 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.983021 (* 1 = 0.983021 loss)
I0929 18:01:19.527770 25496 solver.cpp:580]     Test net output #1: prob = 0.686
I0929 18:01:19.527777 25496 solver.cpp:593]     Max_acc: 0.7275  with iter: 10000
I0929 18:01:19.900272 25496 solver.cpp:357] Iteration 11000 (1.43417 iter/s, 69.7269s/100 iters), loss = 0.536144
I0929 18:01:19.900323 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.536144 (* 1 = 0.536144 loss)
I0929 18:01:19.900334 25496 sgd_solver.cpp:165] Iteration 11000, lr = 0.1
I0929 18:02:01.525629 25496 solver.cpp:357] Iteration 11100 (2.40227 iter/s, 41.6273s/100 iters), loss = 0.510241
I0929 18:02:01.526003 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.510241 (* 1 = 0.510241 loss)
I0929 18:02:01.526080 25496 sgd_solver.cpp:165] Iteration 11100, lr = 0.1
I0929 18:02:43.475092 25496 solver.cpp:357] Iteration 11200 (2.38383 iter/s, 41.9493s/100 iters), loss = 0.347069
I0929 18:02:43.475219 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.347069 (* 1 = 0.347069 loss)
I0929 18:02:43.475232 25496 sgd_solver.cpp:165] Iteration 11200, lr = 0.1
I0929 18:03:25.188640 25496 solver.cpp:357] Iteration 11300 (2.39731 iter/s, 41.7134s/100 iters), loss = 0.539658
I0929 18:03:25.188817 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.539658 (* 1 = 0.539658 loss)
I0929 18:03:25.188830 25496 sgd_solver.cpp:165] Iteration 11300, lr = 0.1
I0929 18:03:35.192870 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:04:06.912714 25496 solver.cpp:357] Iteration 11400 (2.39671 iter/s, 41.7239s/100 iters), loss = 0.438207
I0929 18:04:06.912910 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.438207 (* 1 = 0.438207 loss)
I0929 18:04:06.912923 25496 sgd_solver.cpp:165] Iteration 11400, lr = 0.1
I0929 18:04:48.374202 25496 solver.cpp:514] Iteration 11500, Testing net (#0)
I0929 18:05:15.870173 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:05:15.957985 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.56883 (* 1 = 1.56883 loss)
I0929 18:05:15.958026 25496 solver.cpp:580]     Test net output #1: prob = 0.574801
I0929 18:05:15.958034 25496 solver.cpp:593]     Max_acc: 0.7275  with iter: 10000
I0929 18:05:16.312688 25496 solver.cpp:357] Iteration 11500 (1.4409 iter/s, 69.4011s/100 iters), loss = 0.490871
I0929 18:05:16.312754 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.490871 (* 1 = 0.490871 loss)
I0929 18:05:16.312765 25496 sgd_solver.cpp:165] Iteration 11500, lr = 0.1
I0929 18:05:58.224550 25496 solver.cpp:357] Iteration 11600 (2.38597 iter/s, 41.9116s/100 iters), loss = 0.374148
I0929 18:05:58.224710 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.374148 (* 1 = 0.374148 loss)
I0929 18:05:58.224721 25496 sgd_solver.cpp:165] Iteration 11600, lr = 0.1
I0929 18:06:39.863653 25496 solver.cpp:357] Iteration 11700 (2.40149 iter/s, 41.6409s/100 iters), loss = 0.374796
I0929 18:06:39.863831 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.374796 (* 1 = 0.374796 loss)
I0929 18:06:39.863844 25496 sgd_solver.cpp:165] Iteration 11700, lr = 0.1
I0929 18:06:45.995015 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:07:22.254415 25496 solver.cpp:357] Iteration 11800 (2.35902 iter/s, 42.3905s/100 iters), loss = 0.497644
I0929 18:07:22.254549 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.497644 (* 1 = 0.497644 loss)
I0929 18:07:22.254562 25496 sgd_solver.cpp:165] Iteration 11800, lr = 0.1
I0929 18:08:04.450700 25496 solver.cpp:357] Iteration 11900 (2.36989 iter/s, 42.196s/100 iters), loss = 0.438933
I0929 18:08:04.450839 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.438933 (* 1 = 0.438933 loss)
I0929 18:08:04.450851 25496 sgd_solver.cpp:165] Iteration 11900, lr = 0.1
I0929 18:08:45.956125 25496 solver.cpp:514] Iteration 12000, Testing net (#0)
I0929 18:09:13.893558 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:09:13.959239 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.42807 (* 1 = 1.42807 loss)
I0929 18:09:13.959271 25496 solver.cpp:580]     Test net output #1: prob = 0.5929
I0929 18:09:13.959280 25496 solver.cpp:593]     Max_acc: 0.7275  with iter: 10000
I0929 18:09:14.330137 25496 solver.cpp:357] Iteration 12000 (1.43102 iter/s, 69.8804s/100 iters), loss = 0.337516
I0929 18:09:14.330215 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.337516 (* 1 = 0.337516 loss)
I0929 18:09:14.330229 25496 sgd_solver.cpp:165] Iteration 12000, lr = 0.1
I0929 18:09:56.213145 25496 solver.cpp:357] Iteration 12100 (2.38762 iter/s, 41.8827s/100 iters), loss = 0.479843
I0929 18:09:56.213335 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.479843 (* 1 = 0.479843 loss)
I0929 18:09:56.213347 25496 sgd_solver.cpp:165] Iteration 12100, lr = 0.1
I0929 18:09:58.432113 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:10:38.194028 25496 solver.cpp:357] Iteration 12200 (2.38205 iter/s, 41.9806s/100 iters), loss = 0.308555
I0929 18:10:38.194205 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.308555 (* 1 = 0.308555 loss)
I0929 18:10:38.194216 25496 sgd_solver.cpp:165] Iteration 12200, lr = 0.1
I0929 18:11:20.216487 25496 solver.cpp:357] Iteration 12300 (2.3797 iter/s, 42.0221s/100 iters), loss = 0.413046
I0929 18:11:20.216665 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.413046 (* 1 = 0.413046 loss)
I0929 18:11:20.216678 25496 sgd_solver.cpp:165] Iteration 12300, lr = 0.1
I0929 18:12:02.259049 25496 solver.cpp:357] Iteration 12400 (2.37856 iter/s, 42.0422s/100 iters), loss = 0.61092
I0929 18:12:02.259187 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.61092 (* 1 = 0.61092 loss)
I0929 18:12:02.259200 25496 sgd_solver.cpp:165] Iteration 12400, lr = 0.1
I0929 18:12:42.153437 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:12:43.828471 25496 solver.cpp:514] Iteration 12500, Testing net (#0)
I0929 18:13:11.535552 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:13:11.607224 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.54685 (* 1 = 1.54685 loss)
I0929 18:13:11.607257 25496 solver.cpp:580]     Test net output #1: prob = 0.5438
I0929 18:13:11.607265 25496 solver.cpp:593]     Max_acc: 0.7275  with iter: 10000
I0929 18:13:11.945765 25496 solver.cpp:357] Iteration 12500 (1.43497 iter/s, 69.6876s/100 iters), loss = 0.457205
I0929 18:13:11.945845 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.457205 (* 1 = 0.457205 loss)
I0929 18:13:11.945858 25496 sgd_solver.cpp:165] Iteration 12500, lr = 0.1
I0929 18:13:53.837357 25496 solver.cpp:357] Iteration 12600 (2.38713 iter/s, 41.8912s/100 iters), loss = 0.372707
I0929 18:13:53.837535 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.372707 (* 1 = 0.372707 loss)
I0929 18:13:53.837548 25496 sgd_solver.cpp:165] Iteration 12600, lr = 0.1
I0929 18:14:35.742369 25496 solver.cpp:357] Iteration 12700 (2.38637 iter/s, 41.9047s/100 iters), loss = 0.510893
I0929 18:14:35.742488 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.510893 (* 1 = 0.510893 loss)
I0929 18:14:35.742501 25496 sgd_solver.cpp:165] Iteration 12700, lr = 0.1
I0929 18:15:17.619226 25496 solver.cpp:357] Iteration 12800 (2.38786 iter/s, 41.8786s/100 iters), loss = 0.349108
I0929 18:15:17.619405 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.349108 (* 1 = 0.349108 loss)
I0929 18:15:17.619418 25496 sgd_solver.cpp:165] Iteration 12800, lr = 0.1
I0929 18:15:54.151062 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:15:59.947348 25496 solver.cpp:357] Iteration 12900 (2.36252 iter/s, 42.3278s/100 iters), loss = 0.553997
I0929 18:15:59.947437 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.553997 (* 1 = 0.553997 loss)
I0929 18:15:59.947449 25496 sgd_solver.cpp:165] Iteration 12900, lr = 0.1
I0929 18:16:41.413291 25496 solver.cpp:514] Iteration 13000, Testing net (#0)
I0929 18:17:09.169899 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:17:09.301414 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.50086 (* 1 = 1.50086 loss)
I0929 18:17:09.301446 25496 solver.cpp:580]     Test net output #1: prob = 0.552301
I0929 18:17:09.301457 25496 solver.cpp:593]     Max_acc: 0.7275  with iter: 10000
I0929 18:17:09.569370 25496 solver.cpp:357] Iteration 13000 (1.43631 iter/s, 69.6228s/100 iters), loss = 0.337846
I0929 18:17:09.569463 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.337846 (* 1 = 0.337846 loss)
I0929 18:17:09.569476 25496 sgd_solver.cpp:165] Iteration 13000, lr = 0.1
I0929 18:17:51.740406 25496 solver.cpp:357] Iteration 13100 (2.37132 iter/s, 42.1707s/100 iters), loss = 0.308753
I0929 18:17:51.740586 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.308753 (* 1 = 0.308753 loss)
I0929 18:17:51.740597 25496 sgd_solver.cpp:165] Iteration 13100, lr = 0.1
I0929 18:18:33.499472 25496 solver.cpp:357] Iteration 13200 (2.39471 iter/s, 41.7587s/100 iters), loss = 0.454405
I0929 18:18:33.499662 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.454405 (* 1 = 0.454405 loss)
I0929 18:18:33.499675 25496 sgd_solver.cpp:165] Iteration 13200, lr = 0.1
I0929 18:19:05.722493 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:19:15.322515 25496 solver.cpp:357] Iteration 13300 (2.39105 iter/s, 41.8226s/100 iters), loss = 0.495627
I0929 18:19:15.322608 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.495627 (* 1 = 0.495627 loss)
I0929 18:19:15.322620 25496 sgd_solver.cpp:165] Iteration 13300, lr = 0.1
I0929 18:19:57.676226 25496 solver.cpp:357] Iteration 13400 (2.36109 iter/s, 42.3533s/100 iters), loss = 0.588082
I0929 18:19:57.676421 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.588082 (* 1 = 0.588082 loss)
I0929 18:19:57.676434 25496 sgd_solver.cpp:165] Iteration 13400, lr = 0.1
I0929 18:20:39.017786 25496 solver.cpp:514] Iteration 13500, Testing net (#0)
I0929 18:21:06.950980 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:21:07.022680 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.798317 (* 1 = 0.798317 loss)
I0929 18:21:07.022706 25496 solver.cpp:580]     Test net output #1: prob = 0.7379
I0929 18:21:07.022719 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_13500.caffemodel
I0929 18:21:07.038530 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_13500.solverstate
I0929 18:21:07.042814 25496 solver.cpp:593]     Max_acc: 0.7379  with iter: 13500
I0929 18:21:07.372786 25496 solver.cpp:357] Iteration 13500 (1.43477 iter/s, 69.6974s/100 iters), loss = 0.486795
I0929 18:21:07.372864 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.486795 (* 1 = 0.486795 loss)
I0929 18:21:07.372876 25496 sgd_solver.cpp:165] Iteration 13500, lr = 0.1
I0929 18:21:49.636750 25496 solver.cpp:357] Iteration 13600 (2.3661 iter/s, 42.2636s/100 iters), loss = 0.385005
I0929 18:21:49.636950 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.385005 (* 1 = 0.385005 loss)
I0929 18:21:49.636965 25496 sgd_solver.cpp:165] Iteration 13600, lr = 0.1
I0929 18:22:17.658777 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:22:31.506217 25496 solver.cpp:357] Iteration 13700 (2.3884 iter/s, 41.8691s/100 iters), loss = 0.483753
I0929 18:22:31.506350 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.483753 (* 1 = 0.483753 loss)
I0929 18:22:31.506363 25496 sgd_solver.cpp:165] Iteration 13700, lr = 0.1
I0929 18:23:13.421238 25496 solver.cpp:357] Iteration 13800 (2.3858 iter/s, 41.9146s/100 iters), loss = 0.351494
I0929 18:23:13.421416 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.351494 (* 1 = 0.351494 loss)
I0929 18:23:13.421427 25496 sgd_solver.cpp:165] Iteration 13800, lr = 0.1
I0929 18:23:55.510982 25496 solver.cpp:357] Iteration 13900 (2.38615 iter/s, 41.9086s/100 iters), loss = 0.318815
I0929 18:23:55.511173 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.318815 (* 1 = 0.318815 loss)
I0929 18:23:55.511188 25496 sgd_solver.cpp:165] Iteration 13900, lr = 0.1
I0929 18:24:37.351812 25496 solver.cpp:514] Iteration 14000, Testing net (#0)
I0929 18:25:05.211279 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:25:05.233979 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.18491 (* 1 = 1.18491 loss)
I0929 18:25:05.234015 25496 solver.cpp:580]     Test net output #1: prob = 0.6494
I0929 18:25:05.234024 25496 solver.cpp:593]     Max_acc: 0.7379  with iter: 13500
I0929 18:25:05.605408 25496 solver.cpp:357] Iteration 14000 (1.42663 iter/s, 70.0954s/100 iters), loss = 0.384642
I0929 18:25:05.605459 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.384642 (* 1 = 0.384642 loss)
I0929 18:25:05.605473 25496 sgd_solver.cpp:165] Iteration 14000, lr = 0.1
I0929 18:25:29.815708 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:25:47.230918 25496 solver.cpp:357] Iteration 14100 (2.39722 iter/s, 41.7151s/100 iters), loss = 0.325138
I0929 18:25:47.231001 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.325138 (* 1 = 0.325138 loss)
I0929 18:25:47.231012 25496 sgd_solver.cpp:165] Iteration 14100, lr = 0.1
I0929 18:26:29.275528 25496 solver.cpp:357] Iteration 14200 (2.37643 iter/s, 42.08s/100 iters), loss = 0.532196
I0929 18:26:29.275704 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.532196 (* 1 = 0.532196 loss)
I0929 18:26:29.275718 25496 sgd_solver.cpp:165] Iteration 14200, lr = 0.1
I0929 18:27:11.603513 25496 solver.cpp:357] Iteration 14300 (2.36436 iter/s, 42.2948s/100 iters), loss = 0.378787
I0929 18:27:11.603662 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.378787 (* 1 = 0.378787 loss)
I0929 18:27:11.603674 25496 sgd_solver.cpp:165] Iteration 14300, lr = 0.1
I0929 18:27:53.588760 25496 solver.cpp:357] Iteration 14400 (2.38316 iter/s, 41.961s/100 iters), loss = 0.440351
I0929 18:27:53.588940 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.440351 (* 1 = 0.440351 loss)
I0929 18:27:53.588953 25496 sgd_solver.cpp:165] Iteration 14400, lr = 0.1
I0929 18:28:14.289315 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:28:35.152473 25496 solver.cpp:514] Iteration 14500, Testing net (#0)
I0929 18:29:02.943950 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:29:03.083729 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.63538 (* 1 = 0.63538 loss)
I0929 18:29:03.083760 25496 solver.cpp:580]     Test net output #1: prob = 0.7805
I0929 18:29:03.083775 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_14500.caffemodel
I0929 18:29:03.100507 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_14500.solverstate
I0929 18:29:03.105245 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 18:29:03.440455 25496 solver.cpp:357] Iteration 14500 (1.43127 iter/s, 69.8682s/100 iters), loss = 0.370331
I0929 18:29:03.440539 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.370331 (* 1 = 0.370331 loss)
I0929 18:29:03.440551 25496 sgd_solver.cpp:165] Iteration 14500, lr = 0.1
I0929 18:29:45.368870 25496 solver.cpp:357] Iteration 14600 (2.38486 iter/s, 41.9311s/100 iters), loss = 0.383805
I0929 18:29:45.369029 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.383805 (* 1 = 0.383805 loss)
I0929 18:29:45.369042 25496 sgd_solver.cpp:165] Iteration 14600, lr = 0.1
I0929 18:30:27.079126 25496 solver.cpp:357] Iteration 14700 (2.40086 iter/s, 41.6517s/100 iters), loss = 0.384311
I0929 18:30:27.079319 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.384311 (* 1 = 0.384311 loss)
I0929 18:30:27.079332 25496 sgd_solver.cpp:165] Iteration 14700, lr = 0.1
I0929 18:31:09.200983 25496 solver.cpp:357] Iteration 14800 (2.37763 iter/s, 42.0587s/100 iters), loss = 0.345652
I0929 18:31:09.201170 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.345652 (* 1 = 0.345652 loss)
I0929 18:31:09.201184 25496 sgd_solver.cpp:165] Iteration 14800, lr = 0.1
I0929 18:31:25.602829 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:31:50.901278 25496 solver.cpp:357] Iteration 14900 (2.39975 iter/s, 41.671s/100 iters), loss = 0.249786
I0929 18:31:50.901448 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.249786 (* 1 = 0.249786 loss)
I0929 18:31:50.901460 25496 sgd_solver.cpp:165] Iteration 14900, lr = 0.1
I0929 18:32:32.346951 25496 solver.cpp:514] Iteration 15000, Testing net (#0)
I0929 18:32:59.963037 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:33:00.096357 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.13612 (* 1 = 2.13612 loss)
I0929 18:33:00.096385 25496 solver.cpp:580]     Test net output #1: prob = 0.4727
I0929 18:33:00.096393 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 18:33:00.446022 25496 solver.cpp:357] Iteration 15000 (1.43658 iter/s, 69.6096s/100 iters), loss = 0.446916
I0929 18:33:00.446096 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.446916 (* 1 = 0.446916 loss)
I0929 18:33:00.446108 25496 sgd_solver.cpp:165] Iteration 15000, lr = 0.1
I0929 18:33:42.375419 25496 solver.cpp:357] Iteration 15100 (2.37962 iter/s, 42.0235s/100 iters), loss = 0.435351
I0929 18:33:42.375612 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.435351 (* 1 = 0.435351 loss)
I0929 18:33:42.375627 25496 sgd_solver.cpp:165] Iteration 15100, lr = 0.1
I0929 18:34:24.007550 25496 solver.cpp:357] Iteration 15200 (2.40223 iter/s, 41.628s/100 iters), loss = 0.601845
I0929 18:34:24.007683 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.601845 (* 1 = 0.601845 loss)
I0929 18:34:24.007694 25496 sgd_solver.cpp:165] Iteration 15200, lr = 0.1
I0929 18:34:36.707139 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:35:05.954262 25496 solver.cpp:357] Iteration 15300 (2.38373 iter/s, 41.9511s/100 iters), loss = 0.420561
I0929 18:35:05.954380 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.420561 (* 1 = 0.420561 loss)
I0929 18:35:05.954391 25496 sgd_solver.cpp:165] Iteration 15300, lr = 0.1
I0929 18:35:47.791962 25496 solver.cpp:357] Iteration 15400 (2.38936 iter/s, 41.8522s/100 iters), loss = 0.485955
I0929 18:35:47.792227 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.485955 (* 1 = 0.485955 loss)
I0929 18:35:47.792239 25496 sgd_solver.cpp:165] Iteration 15400, lr = 0.1
I0929 18:36:29.237650 25496 solver.cpp:514] Iteration 15500, Testing net (#0)
I0929 18:36:57.244374 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:36:57.337314 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.30243 (* 1 = 1.30243 loss)
I0929 18:36:57.337347 25496 solver.cpp:580]     Test net output #1: prob = 0.5626
I0929 18:36:57.337355 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 18:36:57.704499 25496 solver.cpp:357] Iteration 15500 (1.4306 iter/s, 69.9009s/100 iters), loss = 0.4662
I0929 18:36:57.704586 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.4662 (* 1 = 0.4662 loss)
I0929 18:36:57.704598 25496 sgd_solver.cpp:165] Iteration 15500, lr = 0.1
I0929 18:37:39.407455 25496 solver.cpp:357] Iteration 15600 (2.39891 iter/s, 41.6857s/100 iters), loss = 0.339003
I0929 18:37:39.407593 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.339003 (* 1 = 0.339003 loss)
I0929 18:37:39.407604 25496 sgd_solver.cpp:165] Iteration 15600, lr = 0.1
I0929 18:37:47.875509 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:38:21.385368 25496 solver.cpp:357] Iteration 15700 (2.38225 iter/s, 41.9771s/100 iters), loss = 0.392695
I0929 18:38:21.385561 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.392695 (* 1 = 0.392695 loss)
I0929 18:38:21.385576 25496 sgd_solver.cpp:165] Iteration 15700, lr = 0.1
I0929 18:39:03.250414 25496 solver.cpp:357] Iteration 15800 (2.39118 iter/s, 41.8204s/100 iters), loss = 0.341722
I0929 18:39:03.250557 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.341722 (* 1 = 0.341722 loss)
I0929 18:39:03.250571 25496 sgd_solver.cpp:165] Iteration 15800, lr = 0.1
I0929 18:39:45.088088 25496 solver.cpp:357] Iteration 15900 (2.39266 iter/s, 41.7945s/100 iters), loss = 0.420968
I0929 18:39:45.088258 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.420968 (* 1 = 0.420968 loss)
I0929 18:39:45.088270 25496 sgd_solver.cpp:165] Iteration 15900, lr = 0.1
I0929 18:40:26.954917 25496 solver.cpp:514] Iteration 16000, Testing net (#0)
I0929 18:40:54.781273 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:40:54.853427 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.03046 (* 1 = 1.03046 loss)
I0929 18:40:54.853476 25496 solver.cpp:580]     Test net output #1: prob = 0.6704
I0929 18:40:54.853483 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 18:40:55.228020 25496 solver.cpp:357] Iteration 16000 (1.42621 iter/s, 70.1158s/100 iters), loss = 0.496781
I0929 18:40:55.228078 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.496781 (* 1 = 0.496781 loss)
I0929 18:40:55.228092 25496 sgd_solver.cpp:165] Iteration 16000, lr = 0.1
I0929 18:40:59.902410 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:41:36.716943 25496 solver.cpp:357] Iteration 16100 (2.41054 iter/s, 41.4844s/100 iters), loss = 0.398476
I0929 18:41:36.717075 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.398476 (* 1 = 0.398476 loss)
I0929 18:41:36.717087 25496 sgd_solver.cpp:165] Iteration 16100, lr = 0.1
I0929 18:42:19.100826 25496 solver.cpp:357] Iteration 16200 (2.35975 iter/s, 42.3773s/100 iters), loss = 0.413282
I0929 18:42:19.101001 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.413282 (* 1 = 0.413282 loss)
I0929 18:42:19.101013 25496 sgd_solver.cpp:165] Iteration 16200, lr = 0.1
I0929 18:43:00.820345 25496 solver.cpp:357] Iteration 16300 (2.39739 iter/s, 41.7121s/100 iters), loss = 0.293053
I0929 18:43:00.820536 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.293053 (* 1 = 0.293053 loss)
I0929 18:43:00.820549 25496 sgd_solver.cpp:165] Iteration 16300, lr = 0.1
I0929 18:43:42.871732 25496 solver.cpp:357] Iteration 16400 (2.3785 iter/s, 42.0434s/100 iters), loss = 0.468168
I0929 18:43:42.871906 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.468168 (* 1 = 0.468168 loss)
I0929 18:43:42.871917 25496 sgd_solver.cpp:165] Iteration 16400, lr = 0.1
I0929 18:43:43.778025 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:44:24.296663 25496 solver.cpp:514] Iteration 16500, Testing net (#0)
I0929 18:44:52.075139 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:44:52.215363 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.792131 (* 1 = 0.792131 loss)
I0929 18:44:52.215391 25496 solver.cpp:580]     Test net output #1: prob = 0.7394
I0929 18:44:52.215399 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 18:44:52.556496 25496 solver.cpp:357] Iteration 16500 (1.43525 iter/s, 69.6744s/100 iters), loss = 0.379285
I0929 18:44:52.556557 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.379285 (* 1 = 0.379285 loss)
I0929 18:44:52.556571 25496 sgd_solver.cpp:165] Iteration 16500, lr = 0.1
I0929 18:45:34.373186 25496 solver.cpp:357] Iteration 16600 (2.39173 iter/s, 41.8107s/100 iters), loss = 0.364482
I0929 18:45:34.373371 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.364482 (* 1 = 0.364482 loss)
I0929 18:45:34.373384 25496 sgd_solver.cpp:165] Iteration 16600, lr = 0.1
I0929 18:46:16.518173 25496 solver.cpp:357] Iteration 16700 (2.37306 iter/s, 42.1396s/100 iters), loss = 0.399885
I0929 18:46:16.518488 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.399885 (* 1 = 0.399885 loss)
I0929 18:46:16.518555 25496 sgd_solver.cpp:165] Iteration 16700, lr = 0.1
I0929 18:46:55.108944 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:46:58.320240 25496 solver.cpp:357] Iteration 16800 (2.39257 iter/s, 41.796s/100 iters), loss = 0.418995
I0929 18:46:58.320324 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.418995 (* 1 = 0.418995 loss)
I0929 18:46:58.320336 25496 sgd_solver.cpp:165] Iteration 16800, lr = 0.1
I0929 18:47:40.047601 25496 solver.cpp:357] Iteration 16900 (2.39689 iter/s, 41.7207s/100 iters), loss = 0.49686
I0929 18:47:40.047741 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.49686 (* 1 = 0.49686 loss)
I0929 18:47:40.047755 25496 sgd_solver.cpp:165] Iteration 16900, lr = 0.1
I0929 18:48:21.785656 25496 solver.cpp:514] Iteration 17000, Testing net (#0)
I0929 18:48:49.786433 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:48:49.865270 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.17161 (* 1 = 1.17161 loss)
I0929 18:48:49.865315 25496 solver.cpp:580]     Test net output #1: prob = 0.6648
I0929 18:48:49.865324 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 18:48:50.219780 25496 solver.cpp:357] Iteration 17000 (1.42528 iter/s, 70.1617s/100 iters), loss = 0.399847
I0929 18:48:50.219843 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.399847 (* 1 = 0.399847 loss)
I0929 18:48:50.219854 25496 sgd_solver.cpp:165] Iteration 17000, lr = 0.1
I0929 18:49:32.051834 25496 solver.cpp:357] Iteration 17100 (2.39094 iter/s, 41.8246s/100 iters), loss = 0.340896
I0929 18:49:32.051985 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.340896 (* 1 = 0.340896 loss)
I0929 18:49:32.051995 25496 sgd_solver.cpp:165] Iteration 17100, lr = 0.1
I0929 18:50:07.061028 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:50:14.084714 25496 solver.cpp:357] Iteration 17200 (2.37941 iter/s, 42.0272s/100 iters), loss = 0.330878
I0929 18:50:14.084802 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.330878 (* 1 = 0.330878 loss)
I0929 18:50:14.084813 25496 sgd_solver.cpp:165] Iteration 17200, lr = 0.1
I0929 18:50:56.078883 25496 solver.cpp:357] Iteration 17300 (2.38172 iter/s, 41.9864s/100 iters), loss = 0.302508
I0929 18:50:56.079017 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.302508 (* 1 = 0.302508 loss)
I0929 18:50:56.079031 25496 sgd_solver.cpp:165] Iteration 17300, lr = 0.1
I0929 18:51:38.128295 25496 solver.cpp:357] Iteration 17400 (2.3786 iter/s, 42.0415s/100 iters), loss = 0.444269
I0929 18:51:38.128525 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.444269 (* 1 = 0.444269 loss)
I0929 18:51:38.128538 25496 sgd_solver.cpp:165] Iteration 17400, lr = 0.1
I0929 18:52:19.896484 25496 solver.cpp:514] Iteration 17500, Testing net (#0)
I0929 18:52:47.614981 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:52:47.757122 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.935063 (* 1 = 0.935063 loss)
I0929 18:52:47.757153 25496 solver.cpp:580]     Test net output #1: prob = 0.7019
I0929 18:52:47.757158 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 18:52:48.103816 25496 solver.cpp:357] Iteration 17500 (1.42931 iter/s, 69.9638s/100 iters), loss = 0.317553
I0929 18:52:48.103901 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.317553 (* 1 = 0.317553 loss)
I0929 18:52:48.103914 25496 sgd_solver.cpp:165] Iteration 17500, lr = 0.1
I0929 18:53:19.170307 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:53:29.837155 25496 solver.cpp:357] Iteration 17600 (2.39662 iter/s, 41.7254s/100 iters), loss = 0.452407
I0929 18:53:29.837246 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.452407 (* 1 = 0.452407 loss)
I0929 18:53:29.837258 25496 sgd_solver.cpp:165] Iteration 17600, lr = 0.1
I0929 18:54:11.630651 25496 solver.cpp:357] Iteration 17700 (2.39143 iter/s, 41.816s/100 iters), loss = 0.550434
I0929 18:54:11.630825 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.550434 (* 1 = 0.550434 loss)
I0929 18:54:11.630837 25496 sgd_solver.cpp:165] Iteration 17700, lr = 0.1
I0929 18:54:53.491672 25496 solver.cpp:357] Iteration 17800 (2.38745 iter/s, 41.8856s/100 iters), loss = 0.455133
I0929 18:54:53.491844 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.455133 (* 1 = 0.455133 loss)
I0929 18:54:53.491858 25496 sgd_solver.cpp:165] Iteration 17800, lr = 0.1
I0929 18:55:35.783907 25496 solver.cpp:357] Iteration 17900 (2.36355 iter/s, 42.3093s/100 iters), loss = 0.311128
I0929 18:55:35.784095 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.311128 (* 1 = 0.311128 loss)
I0929 18:55:35.784108 25496 sgd_solver.cpp:165] Iteration 17900, lr = 0.1
I0929 18:56:02.558552 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:56:17.166810 25496 solver.cpp:514] Iteration 18000, Testing net (#0)
I0929 18:56:44.621868 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:56:44.756641 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.700354 (* 1 = 0.700354 loss)
I0929 18:56:44.756673 25496 solver.cpp:580]     Test net output #1: prob = 0.7602
I0929 18:56:44.756680 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 18:56:45.100888 25496 solver.cpp:357] Iteration 18000 (1.44228 iter/s, 69.3349s/100 iters), loss = 0.322394
I0929 18:56:45.100972 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.322394 (* 1 = 0.322394 loss)
I0929 18:56:45.100984 25496 sgd_solver.cpp:165] Iteration 18000, lr = 0.1
I0929 18:57:26.900286 25496 solver.cpp:357] Iteration 18100 (2.39207 iter/s, 41.8047s/100 iters), loss = 0.312012
I0929 18:57:26.900418 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.312012 (* 1 = 0.312012 loss)
I0929 18:57:26.900431 25496 sgd_solver.cpp:165] Iteration 18100, lr = 0.1
I0929 18:58:08.653514 25496 solver.cpp:357] Iteration 18200 (2.39485 iter/s, 41.7562s/100 iters), loss = 0.434642
I0929 18:58:08.653689 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.434642 (* 1 = 0.434642 loss)
I0929 18:58:08.653702 25496 sgd_solver.cpp:165] Iteration 18200, lr = 0.1
I0929 18:58:50.579854 25496 solver.cpp:357] Iteration 18300 (2.38506 iter/s, 41.9277s/100 iters), loss = 0.374673
I0929 18:58:50.580036 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.374673 (* 1 = 0.374673 loss)
I0929 18:58:50.580049 25496 sgd_solver.cpp:165] Iteration 18300, lr = 0.1
I0929 18:59:13.777457 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 18:59:32.693192 25496 solver.cpp:357] Iteration 18400 (2.37454 iter/s, 42.1135s/100 iters), loss = 0.667875
I0929 18:59:32.693418 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.667875 (* 1 = 0.667875 loss)
I0929 18:59:32.693430 25496 sgd_solver.cpp:165] Iteration 18400, lr = 0.1
I0929 19:00:14.054131 25496 solver.cpp:514] Iteration 18500, Testing net (#0)
I0929 19:00:41.830215 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:00:41.970407 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.773458 (* 1 = 0.773458 loss)
I0929 19:00:41.970456 25496 solver.cpp:580]     Test net output #1: prob = 0.7529
I0929 19:00:41.970463 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:00:42.312336 25496 solver.cpp:357] Iteration 18500 (1.43639 iter/s, 69.619s/100 iters), loss = 0.332119
I0929 19:00:42.312413 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.332119 (* 1 = 0.332119 loss)
I0929 19:00:42.312425 25496 sgd_solver.cpp:165] Iteration 18500, lr = 0.1
I0929 19:01:24.041771 25496 solver.cpp:357] Iteration 18600 (2.39648 iter/s, 41.7278s/100 iters), loss = 0.436283
I0929 19:01:24.041903 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.436283 (* 1 = 0.436283 loss)
I0929 19:01:24.041915 25496 sgd_solver.cpp:165] Iteration 18600, lr = 0.1
I0929 19:02:05.909709 25496 solver.cpp:357] Iteration 18700 (2.38858 iter/s, 41.8659s/100 iters), loss = 0.269384
I0929 19:02:05.909893 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.269384 (* 1 = 0.269384 loss)
I0929 19:02:05.909905 25496 sgd_solver.cpp:165] Iteration 18700, lr = 0.1
I0929 19:02:24.801611 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:02:47.699028 25496 solver.cpp:357] Iteration 18800 (2.39212 iter/s, 41.8039s/100 iters), loss = 0.277684
I0929 19:02:47.699208 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.277684 (* 1 = 0.277684 loss)
I0929 19:02:47.699219 25496 sgd_solver.cpp:165] Iteration 18800, lr = 0.1
I0929 19:03:29.420982 25496 solver.cpp:357] Iteration 18900 (2.39606 iter/s, 41.7352s/100 iters), loss = 0.422223
I0929 19:03:29.421154 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.422223 (* 1 = 0.422223 loss)
I0929 19:03:29.421167 25496 sgd_solver.cpp:165] Iteration 18900, lr = 0.1
I0929 19:04:10.859184 25496 solver.cpp:514] Iteration 19000, Testing net (#0)
I0929 19:04:38.372462 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:04:38.405549 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.77201 (* 1 = 2.77201 loss)
I0929 19:04:38.405582 25496 solver.cpp:580]     Test net output #1: prob = 0.3887
I0929 19:04:38.405591 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:04:38.779848 25496 solver.cpp:357] Iteration 19000 (1.44145 iter/s, 69.3746s/100 iters), loss = 0.407985
I0929 19:04:38.779897 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.407985 (* 1 = 0.407985 loss)
I0929 19:04:38.779911 25496 sgd_solver.cpp:165] Iteration 19000, lr = 0.1
I0929 19:05:20.704670 25496 solver.cpp:357] Iteration 19100 (2.38492 iter/s, 41.9302s/100 iters), loss = 0.295556
I0929 19:05:20.704855 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.295556 (* 1 = 0.295556 loss)
I0929 19:05:20.704869 25496 sgd_solver.cpp:165] Iteration 19100, lr = 0.1
I0929 19:05:35.807773 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:06:02.904467 25496 solver.cpp:357] Iteration 19200 (2.36947 iter/s, 42.2036s/100 iters), loss = 0.365177
I0929 19:06:02.904603 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.365177 (* 1 = 0.365177 loss)
I0929 19:06:02.904615 25496 sgd_solver.cpp:165] Iteration 19200, lr = 0.1
I0929 19:06:44.600769 25496 solver.cpp:357] Iteration 19300 (2.39814 iter/s, 41.6989s/100 iters), loss = 0.292963
I0929 19:06:44.600951 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.292963 (* 1 = 0.292963 loss)
I0929 19:06:44.600963 25496 sgd_solver.cpp:165] Iteration 19300, lr = 0.1
I0929 19:07:26.385124 25496 solver.cpp:357] Iteration 19400 (2.39314 iter/s, 41.7861s/100 iters), loss = 0.373069
I0929 19:07:26.385335 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.373069 (* 1 = 0.373069 loss)
I0929 19:07:26.385349 25496 sgd_solver.cpp:165] Iteration 19400, lr = 0.1
I0929 19:08:07.809432 25496 solver.cpp:514] Iteration 19500, Testing net (#0)
I0929 19:08:35.568363 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:08:35.708664 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.94705 (* 1 = 1.94705 loss)
I0929 19:08:35.708693 25496 solver.cpp:580]     Test net output #1: prob = 0.5434
I0929 19:08:35.708700 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:08:36.056912 25496 solver.cpp:357] Iteration 19500 (1.43523 iter/s, 69.675s/100 iters), loss = 0.362283
I0929 19:08:36.057000 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.362283 (* 1 = 0.362283 loss)
I0929 19:08:36.057013 25496 sgd_solver.cpp:165] Iteration 19500, lr = 0.1
I0929 19:08:47.442149 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:09:17.989537 25496 solver.cpp:357] Iteration 19600 (2.38475 iter/s, 41.9332s/100 iters), loss = 0.428725
I0929 19:09:17.989688 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.428725 (* 1 = 0.428725 loss)
I0929 19:09:17.989699 25496 sgd_solver.cpp:165] Iteration 19600, lr = 0.1
I0929 19:10:00.405110 25496 solver.cpp:357] Iteration 19700 (2.3575 iter/s, 42.4178s/100 iters), loss = 0.465614
I0929 19:10:00.405243 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.465614 (* 1 = 0.465614 loss)
I0929 19:10:00.405256 25496 sgd_solver.cpp:165] Iteration 19700, lr = 0.1
I0929 19:10:41.845378 25496 solver.cpp:357] Iteration 19800 (2.41299 iter/s, 41.4424s/100 iters), loss = 0.316256
I0929 19:10:41.845561 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.316256 (* 1 = 0.316256 loss)
I0929 19:10:41.845572 25496 sgd_solver.cpp:165] Iteration 19800, lr = 0.1
I0929 19:11:23.907829 25496 solver.cpp:357] Iteration 19900 (2.37777 iter/s, 42.0563s/100 iters), loss = 0.465728
I0929 19:11:23.907956 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.465728 (* 1 = 0.465728 loss)
I0929 19:11:23.907968 25496 sgd_solver.cpp:165] Iteration 19900, lr = 0.1
I0929 19:11:31.152117 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:12:05.465037 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_20000.caffemodel
I0929 19:12:05.494665 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_20000.solverstate
I0929 19:12:05.500824 25496 solver.cpp:514] Iteration 20000, Testing net (#0)
I0929 19:12:33.461611 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:12:33.535917 25496 solver.cpp:580]     Test net output #0: Softmax1 = 3.42543 (* 1 = 3.42543 loss)
I0929 19:12:33.535959 25496 solver.cpp:580]     Test net output #1: prob = 0.359899
I0929 19:12:33.535967 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:12:33.889416 25496 solver.cpp:357] Iteration 20000 (1.42911 iter/s, 69.9735s/100 iters), loss = 0.315537
I0929 19:12:33.889479 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.315537 (* 1 = 0.315537 loss)
I0929 19:12:33.889492 25496 sgd_solver.cpp:165] Iteration 20000, lr = 0.1
I0929 19:13:15.799325 25496 solver.cpp:357] Iteration 20100 (2.38635 iter/s, 41.9051s/100 iters), loss = 0.327873
I0929 19:13:15.799509 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.327873 (* 1 = 0.327873 loss)
I0929 19:13:15.799523 25496 sgd_solver.cpp:165] Iteration 20100, lr = 0.1
I0929 19:13:58.187634 25496 solver.cpp:357] Iteration 20200 (2.35927 iter/s, 42.386s/100 iters), loss = 0.372181
I0929 19:13:58.187829 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.372181 (* 1 = 0.372181 loss)
I0929 19:13:58.187842 25496 sgd_solver.cpp:165] Iteration 20200, lr = 0.1
I0929 19:14:40.307713 25496 solver.cpp:357] Iteration 20300 (2.37438 iter/s, 42.1163s/100 iters), loss = 0.371114
I0929 19:14:40.307981 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.371114 (* 1 = 0.371114 loss)
I0929 19:14:40.307996 25496 sgd_solver.cpp:165] Iteration 20300, lr = 0.1
I0929 19:14:43.687325 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:15:22.368696 25496 solver.cpp:357] Iteration 20400 (2.37769 iter/s, 42.0576s/100 iters), loss = 0.346688
I0929 19:15:22.368901 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.346688 (* 1 = 0.346688 loss)
I0929 19:15:22.368914 25496 sgd_solver.cpp:165] Iteration 20400, lr = 0.1
I0929 19:16:04.110985 25496 solver.cpp:514] Iteration 20500, Testing net (#0)
I0929 19:16:31.878121 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:16:32.012122 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.06803 (* 1 = 1.06803 loss)
I0929 19:16:32.012153 25496 solver.cpp:580]     Test net output #1: prob = 0.653001
I0929 19:16:32.012166 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:16:32.363035 25496 solver.cpp:357] Iteration 20500 (1.42876 iter/s, 69.9909s/100 iters), loss = 0.321678
I0929 19:16:32.363111 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.321678 (* 1 = 0.321678 loss)
I0929 19:16:32.363123 25496 sgd_solver.cpp:165] Iteration 20500, lr = 0.1
I0929 19:17:14.363060 25496 solver.cpp:357] Iteration 20600 (2.3811 iter/s, 41.9975s/100 iters), loss = 0.358416
I0929 19:17:14.363263 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.358416 (* 1 = 0.358416 loss)
I0929 19:17:14.363276 25496 sgd_solver.cpp:165] Iteration 20600, lr = 0.1
I0929 19:17:55.893833 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:17:56.137297 25496 solver.cpp:357] Iteration 20700 (2.39395 iter/s, 41.7719s/100 iters), loss = 0.369358
I0929 19:17:56.137379 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.369358 (* 1 = 0.369358 loss)
I0929 19:17:56.137392 25496 sgd_solver.cpp:165] Iteration 20700, lr = 0.1
I0929 19:18:38.251305 25496 solver.cpp:357] Iteration 20800 (2.37451 iter/s, 42.1139s/100 iters), loss = 0.437342
I0929 19:18:38.251456 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.437342 (* 1 = 0.437342 loss)
I0929 19:18:38.251469 25496 sgd_solver.cpp:165] Iteration 20800, lr = 0.1
I0929 19:19:20.229660 25496 solver.cpp:357] Iteration 20900 (2.38229 iter/s, 41.9764s/100 iters), loss = 0.346271
I0929 19:19:20.229835 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.346271 (* 1 = 0.346271 loss)
I0929 19:19:20.229847 25496 sgd_solver.cpp:165] Iteration 20900, lr = 0.1
I0929 19:20:01.890877 25496 solver.cpp:514] Iteration 21000, Testing net (#0)
I0929 19:20:29.729660 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:20:29.803005 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.24585 (* 1 = 2.24585 loss)
I0929 19:20:29.803035 25496 solver.cpp:580]     Test net output #1: prob = 0.426799
I0929 19:20:29.803042 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:20:30.174518 25496 solver.cpp:357] Iteration 21000 (1.42973 iter/s, 69.9433s/100 iters), loss = 0.33179
I0929 19:20:30.174612 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.33179 (* 1 = 0.33179 loss)
I0929 19:20:30.174624 25496 sgd_solver.cpp:165] Iteration 21000, lr = 0.1
I0929 19:21:07.370986 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:21:11.834131 25496 solver.cpp:357] Iteration 21100 (2.4005 iter/s, 41.6579s/100 iters), loss = 0.397086
I0929 19:21:11.834208 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.397086 (* 1 = 0.397086 loss)
I0929 19:21:11.834220 25496 sgd_solver.cpp:165] Iteration 21100, lr = 0.1
I0929 19:21:53.802937 25496 solver.cpp:357] Iteration 21200 (2.38281 iter/s, 41.9672s/100 iters), loss = 0.337755
I0929 19:21:53.803149 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.337755 (* 1 = 0.337755 loss)
I0929 19:21:53.803177 25496 sgd_solver.cpp:165] Iteration 21200, lr = 0.1
I0929 19:22:35.685780 25496 solver.cpp:357] Iteration 21300 (2.3877 iter/s, 41.8813s/100 iters), loss = 0.398538
I0929 19:22:35.686069 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.398538 (* 1 = 0.398538 loss)
I0929 19:22:35.686084 25496 sgd_solver.cpp:165] Iteration 21300, lr = 0.1
I0929 19:23:17.833959 25496 solver.cpp:357] Iteration 21400 (2.37266 iter/s, 42.1467s/100 iters), loss = 0.474231
I0929 19:23:17.834045 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.474231 (* 1 = 0.474231 loss)
I0929 19:23:17.834059 25496 sgd_solver.cpp:165] Iteration 21400, lr = 0.1
I0929 19:23:51.174365 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:23:59.192953 25496 solver.cpp:514] Iteration 21500, Testing net (#0)
I0929 19:24:26.782358 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:24:26.914906 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.56076 (* 1 = 1.56076 loss)
I0929 19:24:26.914976 25496 solver.cpp:580]     Test net output #1: prob = 0.576901
I0929 19:24:26.914991 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:24:27.253808 25496 solver.cpp:357] Iteration 21500 (1.44053 iter/s, 69.419s/100 iters), loss = 0.245991
I0929 19:24:27.253880 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.245991 (* 1 = 0.245991 loss)
I0929 19:24:27.253893 25496 sgd_solver.cpp:165] Iteration 21500, lr = 0.1
I0929 19:25:08.909593 25496 solver.cpp:357] Iteration 21600 (2.4007 iter/s, 41.6544s/100 iters), loss = 0.497295
I0929 19:25:08.909788 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.497295 (* 1 = 0.497295 loss)
I0929 19:25:08.909801 25496 sgd_solver.cpp:165] Iteration 21600, lr = 0.1
I0929 19:25:50.822814 25496 solver.cpp:357] Iteration 21700 (2.38595 iter/s, 41.912s/100 iters), loss = 0.336266
I0929 19:25:50.822995 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.336266 (* 1 = 0.336266 loss)
I0929 19:25:50.823007 25496 sgd_solver.cpp:165] Iteration 21700, lr = 0.1
I0929 19:26:32.872284 25496 solver.cpp:357] Iteration 21800 (2.37822 iter/s, 42.0482s/100 iters), loss = 0.417577
I0929 19:26:32.872428 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.417577 (* 1 = 0.417577 loss)
I0929 19:26:32.872440 25496 sgd_solver.cpp:165] Iteration 21800, lr = 0.1
I0929 19:27:02.420959 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:27:14.689918 25496 solver.cpp:357] Iteration 21900 (2.39141 iter/s, 41.8164s/100 iters), loss = 0.494977
I0929 19:27:14.690102 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.494977 (* 1 = 0.494977 loss)
I0929 19:27:14.690115 25496 sgd_solver.cpp:165] Iteration 21900, lr = 0.1
I0929 19:27:56.102408 25496 solver.cpp:514] Iteration 22000, Testing net (#0)
I0929 19:28:23.911048 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:28:24.048877 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.40704 (* 1 = 1.40704 loss)
I0929 19:28:24.048928 25496 solver.cpp:580]     Test net output #1: prob = 0.6088
I0929 19:28:24.048936 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:28:24.380947 25496 solver.cpp:357] Iteration 22000 (1.43493 iter/s, 69.69s/100 iters), loss = 0.433557
I0929 19:28:24.381029 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.433557 (* 1 = 0.433557 loss)
I0929 19:28:24.381042 25496 sgd_solver.cpp:165] Iteration 22000, lr = 0.1
I0929 19:29:06.353982 25496 solver.cpp:357] Iteration 22100 (2.38303 iter/s, 41.9633s/100 iters), loss = 0.334545
I0929 19:29:06.354130 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.334545 (* 1 = 0.334545 loss)
I0929 19:29:06.354143 25496 sgd_solver.cpp:165] Iteration 22100, lr = 0.1
I0929 19:29:48.328455 25496 solver.cpp:357] Iteration 22200 (2.38277 iter/s, 41.9679s/100 iters), loss = 0.399407
I0929 19:29:48.328629 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.399407 (* 1 = 0.399407 loss)
I0929 19:29:48.328641 25496 sgd_solver.cpp:165] Iteration 22200, lr = 0.1
I0929 19:30:13.870854 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:30:30.098007 25496 solver.cpp:357] Iteration 22300 (2.39452 iter/s, 41.762s/100 iters), loss = 0.268397
I0929 19:30:30.098207 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.268397 (* 1 = 0.268397 loss)
I0929 19:30:30.098219 25496 sgd_solver.cpp:165] Iteration 22300, lr = 0.1
I0929 19:31:12.152432 25496 solver.cpp:357] Iteration 22400 (2.37825 iter/s, 42.0476s/100 iters), loss = 0.320978
I0929 19:31:12.152566 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.320978 (* 1 = 0.320978 loss)
I0929 19:31:12.152578 25496 sgd_solver.cpp:165] Iteration 22400, lr = 0.1
I0929 19:31:53.687268 25496 solver.cpp:514] Iteration 22500, Testing net (#0)
I0929 19:32:21.499554 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:32:21.537183 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.972859 (* 1 = 0.972859 loss)
I0929 19:32:21.537222 25496 solver.cpp:580]     Test net output #1: prob = 0.6945
I0929 19:32:21.537228 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:32:21.896389 25496 solver.cpp:357] Iteration 22500 (1.43399 iter/s, 69.7357s/100 iters), loss = 0.32642
I0929 19:32:21.896451 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.32642 (* 1 = 0.32642 loss)
I0929 19:32:21.896463 25496 sgd_solver.cpp:165] Iteration 22500, lr = 0.1
I0929 19:33:04.048069 25496 solver.cpp:357] Iteration 22600 (2.37267 iter/s, 42.1465s/100 iters), loss = 0.399904
I0929 19:33:04.048213 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.399904 (* 1 = 0.399904 loss)
I0929 19:33:04.048225 25496 sgd_solver.cpp:165] Iteration 22600, lr = 0.1
I0929 19:33:25.743805 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:33:45.905624 25496 solver.cpp:357] Iteration 22700 (2.38932 iter/s, 41.8529s/100 iters), loss = 0.341716
I0929 19:33:45.905810 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.341716 (* 1 = 0.341716 loss)
I0929 19:33:45.905824 25496 sgd_solver.cpp:165] Iteration 22700, lr = 0.1
I0929 19:34:27.700968 25496 solver.cpp:357] Iteration 22800 (2.39286 iter/s, 41.7911s/100 iters), loss = 0.343035
I0929 19:34:27.701160 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.343035 (* 1 = 0.343035 loss)
I0929 19:34:27.701174 25496 sgd_solver.cpp:165] Iteration 22800, lr = 0.1
I0929 19:35:09.481564 25496 solver.cpp:357] Iteration 22900 (2.39368 iter/s, 41.7766s/100 iters), loss = 0.401751
I0929 19:35:09.481757 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.401751 (* 1 = 0.401751 loss)
I0929 19:35:09.481770 25496 sgd_solver.cpp:165] Iteration 22900, lr = 0.1
I0929 19:35:51.091115 25496 solver.cpp:514] Iteration 23000, Testing net (#0)
I0929 19:36:18.995632 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:36:19.143798 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.768823 (* 1 = 0.768823 loss)
I0929 19:36:19.143824 25496 solver.cpp:580]     Test net output #1: prob = 0.7296
I0929 19:36:19.143831 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:36:19.420933 25496 solver.cpp:357] Iteration 23000 (1.4299 iter/s, 69.9348s/100 iters), loss = 0.498271
I0929 19:36:19.421025 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.498271 (* 1 = 0.498271 loss)
I0929 19:36:19.421038 25496 sgd_solver.cpp:165] Iteration 23000, lr = 0.1
I0929 19:36:36.880332 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:37:00.996919 25496 solver.cpp:357] Iteration 23100 (2.40543 iter/s, 41.5727s/100 iters), loss = 0.485538
I0929 19:37:00.997004 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.485538 (* 1 = 0.485538 loss)
I0929 19:37:00.997017 25496 sgd_solver.cpp:165] Iteration 23100, lr = 0.1
I0929 19:37:43.122464 25496 solver.cpp:357] Iteration 23200 (2.37403 iter/s, 42.1224s/100 iters), loss = 0.35246
I0929 19:37:43.122637 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.35246 (* 1 = 0.35246 loss)
I0929 19:37:43.122649 25496 sgd_solver.cpp:165] Iteration 23200, lr = 0.1
I0929 19:38:24.915879 25496 solver.cpp:357] Iteration 23300 (2.39289 iter/s, 41.7904s/100 iters), loss = 0.337126
I0929 19:38:24.916138 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.337126 (* 1 = 0.337126 loss)
I0929 19:38:24.916152 25496 sgd_solver.cpp:165] Iteration 23300, lr = 0.1
I0929 19:39:06.914089 25496 solver.cpp:357] Iteration 23400 (2.38122 iter/s, 41.9953s/100 iters), loss = 0.321491
I0929 19:39:06.914239 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.321491 (* 1 = 0.321491 loss)
I0929 19:39:06.914252 25496 sgd_solver.cpp:165] Iteration 23400, lr = 0.1
I0929 19:39:20.674544 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:39:48.200520 25496 solver.cpp:514] Iteration 23500, Testing net (#0)
I0929 19:40:15.663264 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:40:15.713443 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.679096 (* 1 = 0.679096 loss)
I0929 19:40:15.713485 25496 solver.cpp:580]     Test net output #1: prob = 0.7726
I0929 19:40:15.713491 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:40:16.076560 25496 solver.cpp:357] Iteration 23500 (1.44589 iter/s, 69.1615s/100 iters), loss = 0.269316
I0929 19:40:16.076618 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.269316 (* 1 = 0.269316 loss)
I0929 19:40:16.076630 25496 sgd_solver.cpp:165] Iteration 23500, lr = 0.1
I0929 19:40:58.065448 25496 solver.cpp:357] Iteration 23600 (2.38173 iter/s, 41.9863s/100 iters), loss = 0.411782
I0929 19:40:58.065627 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.411782 (* 1 = 0.411782 loss)
I0929 19:40:58.065641 25496 sgd_solver.cpp:165] Iteration 23600, lr = 0.1
I0929 19:41:40.192143 25496 solver.cpp:357] Iteration 23700 (2.37393 iter/s, 42.1242s/100 iters), loss = 0.337436
I0929 19:41:40.192322 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.337436 (* 1 = 0.337436 loss)
I0929 19:41:40.192334 25496 sgd_solver.cpp:165] Iteration 23700, lr = 0.1
I0929 19:42:22.177415 25496 solver.cpp:357] Iteration 23800 (2.38193 iter/s, 41.9828s/100 iters), loss = 0.418826
I0929 19:42:22.177568 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.418826 (* 1 = 0.418826 loss)
I0929 19:42:22.177582 25496 sgd_solver.cpp:165] Iteration 23800, lr = 0.1
I0929 19:42:32.269779 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:43:04.097188 25496 solver.cpp:357] Iteration 23900 (2.38564 iter/s, 41.9174s/100 iters), loss = 0.363199
I0929 19:43:04.097508 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.363199 (* 1 = 0.363199 loss)
I0929 19:43:04.097522 25496 sgd_solver.cpp:165] Iteration 23900, lr = 0.1
I0929 19:43:45.600085 25496 solver.cpp:514] Iteration 24000, Testing net (#0)
I0929 19:44:13.415529 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:44:13.499851 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.760759 (* 1 = 0.760759 loss)
I0929 19:44:13.499882 25496 solver.cpp:580]     Test net output #1: prob = 0.751
I0929 19:44:13.499888 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:44:13.870663 25496 solver.cpp:357] Iteration 24000 (1.43326 iter/s, 69.771s/100 iters), loss = 0.433237
I0929 19:44:13.870762 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.433237 (* 1 = 0.433237 loss)
I0929 19:44:13.870775 25496 sgd_solver.cpp:165] Iteration 24000, lr = 0.1
I0929 19:44:55.599944 25496 solver.cpp:357] Iteration 24100 (2.39653 iter/s, 41.727s/100 iters), loss = 0.49502
I0929 19:44:55.600111 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.49502 (* 1 = 0.49502 loss)
I0929 19:44:55.600123 25496 sgd_solver.cpp:165] Iteration 24100, lr = 0.1
I0929 19:45:37.706889 25496 solver.cpp:357] Iteration 24200 (2.37478 iter/s, 42.1092s/100 iters), loss = 0.356421
I0929 19:45:37.707033 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.356421 (* 1 = 0.356421 loss)
I0929 19:45:37.707044 25496 sgd_solver.cpp:165] Iteration 24200, lr = 0.1
I0929 19:45:43.663323 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:46:19.555899 25496 solver.cpp:357] Iteration 24300 (2.38864 iter/s, 41.8648s/100 iters), loss = 0.491157
I0929 19:46:19.556156 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.491157 (* 1 = 0.491157 loss)
I0929 19:46:19.556171 25496 sgd_solver.cpp:165] Iteration 24300, lr = 0.1
I0929 19:47:00.953722 25496 solver.cpp:357] Iteration 24400 (2.41491 iter/s, 41.4094s/100 iters), loss = 0.460689
I0929 19:47:00.953902 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.460689 (* 1 = 0.460689 loss)
I0929 19:47:00.953915 25496 sgd_solver.cpp:165] Iteration 24400, lr = 0.1
I0929 19:47:42.585391 25496 solver.cpp:514] Iteration 24500, Testing net (#0)
I0929 19:48:10.233994 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:48:10.367635 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.3204 (* 1 = 1.3204 loss)
I0929 19:48:10.367662 25496 solver.cpp:580]     Test net output #1: prob = 0.649999
I0929 19:48:10.367671 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:48:10.713737 25496 solver.cpp:357] Iteration 24500 (1.43313 iter/s, 69.7772s/100 iters), loss = 0.423911
I0929 19:48:10.713812 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.423911 (* 1 = 0.423911 loss)
I0929 19:48:10.713825 25496 sgd_solver.cpp:165] Iteration 24500, lr = 0.1
I0929 19:48:52.596833 25496 solver.cpp:357] Iteration 24600 (2.38717 iter/s, 41.8906s/100 iters), loss = 0.367469
I0929 19:48:52.596961 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.367469 (* 1 = 0.367469 loss)
I0929 19:48:52.596973 25496 sgd_solver.cpp:165] Iteration 24600, lr = 0.1
I0929 19:48:54.831588 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:49:34.560582 25496 solver.cpp:357] Iteration 24700 (2.38265 iter/s, 41.9701s/100 iters), loss = 0.307586
I0929 19:49:34.560768 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.307586 (* 1 = 0.307586 loss)
I0929 19:49:34.560781 25496 sgd_solver.cpp:165] Iteration 24700, lr = 0.1
I0929 19:50:16.624228 25496 solver.cpp:357] Iteration 24800 (2.37704 iter/s, 42.0691s/100 iters), loss = 0.328979
I0929 19:50:16.624415 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.328979 (* 1 = 0.328979 loss)
I0929 19:50:16.624428 25496 sgd_solver.cpp:165] Iteration 24800, lr = 0.1
I0929 19:50:58.529059 25496 solver.cpp:357] Iteration 24900 (2.3861 iter/s, 41.9094s/100 iters), loss = 0.450827
I0929 19:50:58.529238 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.450827 (* 1 = 0.450827 loss)
I0929 19:50:58.529250 25496 sgd_solver.cpp:165] Iteration 24900, lr = 0.1
I0929 19:51:38.533411 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:51:40.190940 25496 solver.cpp:514] Iteration 25000, Testing net (#0)
I0929 19:52:07.991026 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:52:08.077713 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.38758 (* 1 = 1.38758 loss)
I0929 19:52:08.077754 25496 solver.cpp:580]     Test net output #1: prob = 0.610101
I0929 19:52:08.077761 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:52:08.428334 25496 solver.cpp:357] Iteration 25000 (1.43048 iter/s, 69.9068s/100 iters), loss = 0.367424
I0929 19:52:08.428400 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.367424 (* 1 = 0.367424 loss)
I0929 19:52:08.428411 25496 sgd_solver.cpp:165] Iteration 25000, lr = 0.1
I0929 19:52:50.516502 25496 solver.cpp:357] Iteration 25100 (2.3758 iter/s, 42.0911s/100 iters), loss = 0.349698
I0929 19:52:50.516629 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.349698 (* 1 = 0.349698 loss)
I0929 19:52:50.516643 25496 sgd_solver.cpp:165] Iteration 25100, lr = 0.1
I0929 19:53:32.605749 25496 solver.cpp:357] Iteration 25200 (2.37577 iter/s, 42.0917s/100 iters), loss = 0.553747
I0929 19:53:32.605878 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.553747 (* 1 = 0.553747 loss)
I0929 19:53:32.605891 25496 sgd_solver.cpp:165] Iteration 25200, lr = 0.1
I0929 19:54:14.211567 25496 solver.cpp:357] Iteration 25300 (2.40339 iter/s, 41.6078s/100 iters), loss = 0.336807
I0929 19:54:14.211783 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.336807 (* 1 = 0.336807 loss)
I0929 19:54:14.211796 25496 sgd_solver.cpp:165] Iteration 25300, lr = 0.1
I0929 19:54:50.610589 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:54:56.343344 25496 solver.cpp:357] Iteration 25400 (2.37341 iter/s, 42.1335s/100 iters), loss = 0.510618
I0929 19:54:56.343431 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.510618 (* 1 = 0.510618 loss)
I0929 19:54:56.343444 25496 sgd_solver.cpp:165] Iteration 25400, lr = 0.1
I0929 19:55:38.182770 25496 solver.cpp:514] Iteration 25500, Testing net (#0)
I0929 19:56:05.856375 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:56:05.991293 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.20469 (* 1 = 1.20469 loss)
I0929 19:56:05.991351 25496 solver.cpp:580]     Test net output #1: prob = 0.6579
I0929 19:56:05.991358 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 19:56:06.335521 25496 solver.cpp:357] Iteration 25500 (1.42866 iter/s, 69.9959s/100 iters), loss = 0.354257
I0929 19:56:06.335597 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.354257 (* 1 = 0.354257 loss)
I0929 19:56:06.335609 25496 sgd_solver.cpp:165] Iteration 25500, lr = 0.1
I0929 19:56:47.908860 25496 solver.cpp:357] Iteration 25600 (2.40533 iter/s, 41.5744s/100 iters), loss = 0.294503
I0929 19:56:47.909054 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.294503 (* 1 = 0.294503 loss)
I0929 19:56:47.909083 25496 sgd_solver.cpp:165] Iteration 25600, lr = 0.1
I0929 19:57:29.821530 25496 solver.cpp:357] Iteration 25700 (2.38586 iter/s, 41.9135s/100 iters), loss = 0.276518
I0929 19:57:29.821673 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.276518 (* 1 = 0.276518 loss)
I0929 19:57:29.821686 25496 sgd_solver.cpp:165] Iteration 25700, lr = 0.1
I0929 19:58:02.292577 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 19:58:11.718286 25496 solver.cpp:357] Iteration 25800 (2.38678 iter/s, 41.8975s/100 iters), loss = 0.485305
I0929 19:58:11.718365 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.485305 (* 1 = 0.485305 loss)
I0929 19:58:11.718379 25496 sgd_solver.cpp:165] Iteration 25800, lr = 0.1
I0929 19:58:53.520133 25496 solver.cpp:357] Iteration 25900 (2.39221 iter/s, 41.8024s/100 iters), loss = 0.393406
I0929 19:58:53.520287 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.393406 (* 1 = 0.393406 loss)
I0929 19:58:53.520299 25496 sgd_solver.cpp:165] Iteration 25900, lr = 0.1
I0929 19:59:35.103914 25496 solver.cpp:514] Iteration 26000, Testing net (#0)
I0929 20:00:02.796186 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:00:02.829519 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.34278 (* 1 = 1.34278 loss)
I0929 20:00:02.829555 25496 solver.cpp:580]     Test net output #1: prob = 0.638
I0929 20:00:02.829563 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:00:03.202497 25496 solver.cpp:357] Iteration 26000 (1.43504 iter/s, 69.6845s/100 iters), loss = 0.396693
I0929 20:00:03.202548 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.396693 (* 1 = 0.396693 loss)
I0929 20:00:03.202561 25496 sgd_solver.cpp:165] Iteration 26000, lr = 0.1
I0929 20:00:45.083467 25496 solver.cpp:357] Iteration 26100 (2.3877 iter/s, 41.8813s/100 iters), loss = 0.337926
I0929 20:00:45.083829 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.337926 (* 1 = 0.337926 loss)
I0929 20:00:45.083899 25496 sgd_solver.cpp:165] Iteration 26100, lr = 0.1
I0929 20:01:13.644918 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:01:27.498666 25496 solver.cpp:357] Iteration 26200 (2.35763 iter/s, 42.4155s/100 iters), loss = 0.391017
I0929 20:01:27.498839 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.391017 (* 1 = 0.391017 loss)
I0929 20:01:27.498852 25496 sgd_solver.cpp:165] Iteration 26200, lr = 0.1
I0929 20:02:09.575381 25496 solver.cpp:357] Iteration 26300 (2.3766 iter/s, 42.0769s/100 iters), loss = 0.327733
I0929 20:02:09.575668 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.327733 (* 1 = 0.327733 loss)
I0929 20:02:09.575682 25496 sgd_solver.cpp:165] Iteration 26300, lr = 0.1
I0929 20:02:51.405282 25496 solver.cpp:357] Iteration 26400 (2.3907 iter/s, 41.8287s/100 iters), loss = 0.364399
I0929 20:02:51.405428 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.364399 (* 1 = 0.364399 loss)
I0929 20:02:51.405441 25496 sgd_solver.cpp:165] Iteration 26400, lr = 0.1
I0929 20:03:32.912765 25496 solver.cpp:514] Iteration 26500, Testing net (#0)
I0929 20:04:00.752123 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:04:00.843822 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.80686 (* 1 = 1.80686 loss)
I0929 20:04:00.843856 25496 solver.cpp:580]     Test net output #1: prob = 0.5118
I0929 20:04:00.843864 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:04:01.213502 25496 solver.cpp:357] Iteration 26500 (1.43255 iter/s, 69.8057s/100 iters), loss = 0.40622
I0929 20:04:01.213696 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.40622 (* 1 = 0.40622 loss)
I0929 20:04:01.213740 25496 sgd_solver.cpp:165] Iteration 26500, lr = 0.1
I0929 20:04:25.532548 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:04:42.941476 25496 solver.cpp:357] Iteration 26600 (2.3966 iter/s, 41.7258s/100 iters), loss = 0.345034
I0929 20:04:42.941551 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.345034 (* 1 = 0.345034 loss)
I0929 20:04:42.941562 25496 sgd_solver.cpp:165] Iteration 26600, lr = 0.1
I0929 20:05:24.920900 25496 solver.cpp:357] Iteration 26700 (2.38223 iter/s, 41.9774s/100 iters), loss = 0.405741
I0929 20:05:24.921038 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.405741 (* 1 = 0.405741 loss)
I0929 20:05:24.921051 25496 sgd_solver.cpp:165] Iteration 26700, lr = 0.1
I0929 20:06:06.555142 25496 solver.cpp:357] Iteration 26800 (2.40198 iter/s, 41.6323s/100 iters), loss = 0.327261
I0929 20:06:06.555274 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.327261 (* 1 = 0.327261 loss)
I0929 20:06:06.555285 25496 sgd_solver.cpp:165] Iteration 26800, lr = 0.1
I0929 20:06:48.892315 25496 solver.cpp:357] Iteration 26900 (2.36209 iter/s, 42.3354s/100 iters), loss = 0.324198
I0929 20:06:48.892457 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.324198 (* 1 = 0.324198 loss)
I0929 20:06:48.892469 25496 sgd_solver.cpp:165] Iteration 26900, lr = 0.1
I0929 20:07:09.465036 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:07:30.259579 25496 solver.cpp:514] Iteration 27000, Testing net (#0)
I0929 20:07:57.820588 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:07:57.928748 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.786881 (* 1 = 0.786881 loss)
I0929 20:07:57.928781 25496 solver.cpp:580]     Test net output #1: prob = 0.7342
I0929 20:07:57.928786 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:07:58.250773 25496 solver.cpp:357] Iteration 27000 (1.44181 iter/s, 69.3572s/100 iters), loss = 0.423307
I0929 20:07:58.250823 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.423307 (* 1 = 0.423307 loss)
I0929 20:07:58.250834 25496 sgd_solver.cpp:165] Iteration 27000, lr = 0.1
I0929 20:08:40.222303 25496 solver.cpp:357] Iteration 27100 (2.38254 iter/s, 41.9721s/100 iters), loss = 0.495409
I0929 20:08:40.222487 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.495409 (* 1 = 0.495409 loss)
I0929 20:08:40.222502 25496 sgd_solver.cpp:165] Iteration 27100, lr = 0.1
I0929 20:09:21.898221 25496 solver.cpp:357] Iteration 27200 (2.39955 iter/s, 41.6745s/100 iters), loss = 0.43222
I0929 20:09:21.898399 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.43222 (* 1 = 0.43222 loss)
I0929 20:09:21.898413 25496 sgd_solver.cpp:165] Iteration 27200, lr = 0.1
I0929 20:10:03.784706 25496 solver.cpp:357] Iteration 27300 (2.38748 iter/s, 41.8851s/100 iters), loss = 0.253564
I0929 20:10:03.784903 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.253564 (* 1 = 0.253564 loss)
I0929 20:10:03.784916 25496 sgd_solver.cpp:165] Iteration 27300, lr = 0.1
I0929 20:10:20.269162 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:10:46.079552 25496 solver.cpp:357] Iteration 27400 (2.36443 iter/s, 42.2936s/100 iters), loss = 0.393165
I0929 20:10:46.079720 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.393165 (* 1 = 0.393165 loss)
I0929 20:10:46.079732 25496 sgd_solver.cpp:165] Iteration 27400, lr = 0.1
I0929 20:11:27.789819 25496 solver.cpp:514] Iteration 27500, Testing net (#0)
I0929 20:11:55.455114 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:11:55.504387 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.138 (* 1 = 1.138 loss)
I0929 20:11:55.504427 25496 solver.cpp:580]     Test net output #1: prob = 0.641901
I0929 20:11:55.504436 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:11:55.855414 25496 solver.cpp:357] Iteration 27500 (1.43313 iter/s, 69.7774s/100 iters), loss = 0.479177
I0929 20:11:55.855479 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.479177 (* 1 = 0.479177 loss)
I0929 20:11:55.855489 25496 sgd_solver.cpp:165] Iteration 27500, lr = 0.1
I0929 20:12:37.830369 25496 solver.cpp:357] Iteration 27600 (2.38244 iter/s, 41.9738s/100 iters), loss = 0.368269
I0929 20:12:37.830556 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.368269 (* 1 = 0.368269 loss)
I0929 20:12:37.830569 25496 sgd_solver.cpp:165] Iteration 27600, lr = 0.1
I0929 20:13:19.919062 25496 solver.cpp:357] Iteration 27700 (2.37599 iter/s, 42.0877s/100 iters), loss = 0.457877
I0929 20:13:19.919250 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.457877 (* 1 = 0.457877 loss)
I0929 20:13:19.919263 25496 sgd_solver.cpp:165] Iteration 27700, lr = 0.1
I0929 20:13:32.468881 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:14:01.827913 25496 solver.cpp:357] Iteration 27800 (2.38619 iter/s, 41.9078s/100 iters), loss = 0.317212
I0929 20:14:01.828014 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.317212 (* 1 = 0.317212 loss)
I0929 20:14:01.828027 25496 sgd_solver.cpp:165] Iteration 27800, lr = 0.1
I0929 20:14:43.773999 25496 solver.cpp:357] Iteration 27900 (2.38407 iter/s, 41.9451s/100 iters), loss = 0.52226
I0929 20:14:43.774135 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.52226 (* 1 = 0.52226 loss)
I0929 20:14:43.774149 25496 sgd_solver.cpp:165] Iteration 27900, lr = 0.1
I0929 20:15:25.052275 25496 solver.cpp:514] Iteration 28000, Testing net (#0)
I0929 20:15:52.937844 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:15:52.967758 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.73743 (* 1 = 1.73743 loss)
I0929 20:15:52.967790 25496 solver.cpp:580]     Test net output #1: prob = 0.564101
I0929 20:15:52.967799 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:15:53.338807 25496 solver.cpp:357] Iteration 28000 (1.43751 iter/s, 69.5648s/100 iters), loss = 0.451624
I0929 20:15:53.338855 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.451624 (* 1 = 0.451624 loss)
I0929 20:15:53.338871 25496 sgd_solver.cpp:165] Iteration 28000, lr = 0.1
I0929 20:16:35.275770 25496 solver.cpp:357] Iteration 28100 (2.38458 iter/s, 41.9361s/100 iters), loss = 0.340355
I0929 20:16:35.275950 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.340355 (* 1 = 0.340355 loss)
I0929 20:16:35.275964 25496 sgd_solver.cpp:165] Iteration 28100, lr = 0.1
I0929 20:16:43.694578 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:17:17.426533 25496 solver.cpp:357] Iteration 28200 (2.37248 iter/s, 42.1499s/100 iters), loss = 0.459137
I0929 20:17:17.426707 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.459137 (* 1 = 0.459137 loss)
I0929 20:17:17.426718 25496 sgd_solver.cpp:165] Iteration 28200, lr = 0.1
I0929 20:17:59.327530 25496 solver.cpp:357] Iteration 28300 (2.38662 iter/s, 41.9002s/100 iters), loss = 0.337437
I0929 20:17:59.327736 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.337437 (* 1 = 0.337437 loss)
I0929 20:17:59.327747 25496 sgd_solver.cpp:165] Iteration 28300, lr = 0.1
I0929 20:18:40.983268 25496 solver.cpp:357] Iteration 28400 (2.40056 iter/s, 41.6569s/100 iters), loss = 0.295064
I0929 20:18:40.983469 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.295064 (* 1 = 0.295064 loss)
I0929 20:18:40.983482 25496 sgd_solver.cpp:165] Iteration 28400, lr = 0.1
I0929 20:19:22.999212 25496 solver.cpp:514] Iteration 28500, Testing net (#0)
I0929 20:19:50.774317 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:19:50.916631 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.913206 (* 1 = 0.913206 loss)
I0929 20:19:50.916676 25496 solver.cpp:580]     Test net output #1: prob = 0.6915
I0929 20:19:50.916682 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:19:51.262404 25496 solver.cpp:357] Iteration 28500 (1.42289 iter/s, 70.2794s/100 iters), loss = 0.410984
I0929 20:19:51.262485 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.410984 (* 1 = 0.410984 loss)
I0929 20:19:51.262497 25496 sgd_solver.cpp:165] Iteration 28500, lr = 0.1
I0929 20:19:55.889741 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:20:33.320943 25496 solver.cpp:357] Iteration 28600 (2.37768 iter/s, 42.0578s/100 iters), loss = 0.472523
I0929 20:20:33.321105 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.472523 (* 1 = 0.472523 loss)
I0929 20:20:33.321121 25496 sgd_solver.cpp:165] Iteration 28600, lr = 0.1
I0929 20:21:15.647869 25496 solver.cpp:357] Iteration 28700 (2.3626 iter/s, 42.3263s/100 iters), loss = 0.399237
I0929 20:21:15.648054 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.399237 (* 1 = 0.399237 loss)
I0929 20:21:15.648066 25496 sgd_solver.cpp:165] Iteration 28700, lr = 0.1
I0929 20:21:57.284919 25496 solver.cpp:357] Iteration 28800 (2.40175 iter/s, 41.6364s/100 iters), loss = 0.268615
I0929 20:21:57.285066 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.268615 (* 1 = 0.268615 loss)
I0929 20:21:57.285078 25496 sgd_solver.cpp:165] Iteration 28800, lr = 0.1
I0929 20:22:39.239794 25496 solver.cpp:357] Iteration 28900 (2.38355 iter/s, 41.9542s/100 iters), loss = 0.416057
I0929 20:22:39.239981 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.416057 (* 1 = 0.416057 loss)
I0929 20:22:39.239995 25496 sgd_solver.cpp:165] Iteration 28900, lr = 0.1
I0929 20:22:40.125941 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:23:20.470392 25496 solver.cpp:514] Iteration 29000, Testing net (#0)
I0929 20:23:48.202380 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:23:48.344975 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.58818 (* 1 = 1.58818 loss)
I0929 20:23:48.345041 25496 solver.cpp:580]     Test net output #1: prob = 0.5895
I0929 20:23:48.345052 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:23:48.687613 25496 solver.cpp:357] Iteration 29000 (1.43992 iter/s, 69.4482s/100 iters), loss = 0.325771
I0929 20:23:48.687680 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.325771 (* 1 = 0.325771 loss)
I0929 20:23:48.687691 25496 sgd_solver.cpp:165] Iteration 29000, lr = 0.1
I0929 20:24:30.417034 25496 solver.cpp:357] Iteration 29100 (2.39643 iter/s, 41.7288s/100 iters), loss = 0.393296
I0929 20:24:30.417223 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.393296 (* 1 = 0.393296 loss)
I0929 20:24:30.417237 25496 sgd_solver.cpp:165] Iteration 29100, lr = 0.1
I0929 20:25:12.523067 25496 solver.cpp:357] Iteration 29200 (2.37499 iter/s, 42.1054s/100 iters), loss = 0.344763
I0929 20:25:12.523231 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.344763 (* 1 = 0.344763 loss)
I0929 20:25:12.523244 25496 sgd_solver.cpp:165] Iteration 29200, lr = 0.1
I0929 20:25:51.347944 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:25:54.597393 25496 solver.cpp:357] Iteration 29300 (2.37678 iter/s, 42.0737s/100 iters), loss = 0.317814
I0929 20:25:54.597474 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.317814 (* 1 = 0.317814 loss)
I0929 20:25:54.597487 25496 sgd_solver.cpp:165] Iteration 29300, lr = 0.1
I0929 20:26:36.618139 25496 solver.cpp:357] Iteration 29400 (2.37981 iter/s, 42.0202s/100 iters), loss = 0.313433
I0929 20:26:36.618383 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.313433 (* 1 = 0.313433 loss)
I0929 20:26:36.618402 25496 sgd_solver.cpp:165] Iteration 29400, lr = 0.1
I0929 20:27:17.871875 25496 solver.cpp:514] Iteration 29500, Testing net (#0)
I0929 20:27:45.320919 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:27:45.384975 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.79197 (* 1 = 1.79197 loss)
I0929 20:27:45.385007 25496 solver.cpp:580]     Test net output #1: prob = 0.534
I0929 20:27:45.385015 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:27:45.751224 25496 solver.cpp:357] Iteration 29500 (1.44647 iter/s, 69.1336s/100 iters), loss = 0.41461
I0929 20:27:45.751389 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.41461 (* 1 = 0.41461 loss)
I0929 20:27:45.751416 25496 sgd_solver.cpp:165] Iteration 29500, lr = 0.1
I0929 20:28:27.714853 25496 solver.cpp:357] Iteration 29600 (2.38305 iter/s, 41.9631s/100 iters), loss = 0.313553
I0929 20:28:27.715039 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.313553 (* 1 = 0.313553 loss)
I0929 20:28:27.715051 25496 sgd_solver.cpp:165] Iteration 29600, lr = 0.1
I0929 20:29:02.877048 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:29:09.847079 25496 solver.cpp:357] Iteration 29700 (2.37351 iter/s, 42.1317s/100 iters), loss = 0.298371
I0929 20:29:09.847159 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.298371 (* 1 = 0.298371 loss)
I0929 20:29:09.847172 25496 sgd_solver.cpp:165] Iteration 29700, lr = 0.1
I0929 20:29:52.284835 25496 solver.cpp:357] Iteration 29800 (2.35642 iter/s, 42.4373s/100 iters), loss = 0.314804
I0929 20:29:52.284940 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.314804 (* 1 = 0.314804 loss)
I0929 20:29:52.284951 25496 sgd_solver.cpp:165] Iteration 29800, lr = 0.1
I0929 20:30:34.048099 25496 solver.cpp:357] Iteration 29900 (2.39436 iter/s, 41.7648s/100 iters), loss = 0.406322
I0929 20:30:34.048280 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.406322 (* 1 = 0.406322 loss)
I0929 20:30:34.048293 25496 sgd_solver.cpp:165] Iteration 29900, lr = 0.1
I0929 20:31:15.717821 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_30000.caffemodel
I0929 20:31:15.735762 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_30000.solverstate
I0929 20:31:15.741328 25496 solver.cpp:514] Iteration 30000, Testing net (#0)
I0929 20:31:43.778105 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:31:43.918977 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.974306 (* 1 = 0.974306 loss)
I0929 20:31:43.919005 25496 solver.cpp:580]     Test net output #1: prob = 0.6874
I0929 20:31:43.919013 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:31:44.262917 25496 solver.cpp:357] Iteration 30000 (1.42419 iter/s, 70.2155s/100 iters), loss = 0.350614
I0929 20:31:44.262998 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.350614 (* 1 = 0.350614 loss)
I0929 20:31:44.263011 25496 sgd_solver.cpp:165] Iteration 30000, lr = 0.1
I0929 20:32:15.265007 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:32:26.027364 25496 solver.cpp:357] Iteration 30100 (2.39441 iter/s, 41.7639s/100 iters), loss = 0.406339
I0929 20:32:26.027451 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.406339 (* 1 = 0.406339 loss)
I0929 20:32:26.027463 25496 sgd_solver.cpp:165] Iteration 30100, lr = 0.1
I0929 20:33:07.855341 25496 solver.cpp:357] Iteration 30200 (2.39077 iter/s, 41.8275s/100 iters), loss = 0.413354
I0929 20:33:07.855612 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.413354 (* 1 = 0.413354 loss)
I0929 20:33:07.855625 25496 sgd_solver.cpp:165] Iteration 30200, lr = 0.1
I0929 20:33:49.887557 25496 solver.cpp:357] Iteration 30300 (2.37916 iter/s, 42.0317s/100 iters), loss = 0.44911
I0929 20:33:49.887888 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.44911 (* 1 = 0.44911 loss)
I0929 20:33:49.887954 25496 sgd_solver.cpp:165] Iteration 30300, lr = 0.1
I0929 20:34:31.666431 25496 solver.cpp:357] Iteration 30400 (2.39358 iter/s, 41.7784s/100 iters), loss = 0.229915
I0929 20:34:31.666625 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.229915 (* 1 = 0.229915 loss)
I0929 20:34:31.666637 25496 sgd_solver.cpp:165] Iteration 30400, lr = 0.1
I0929 20:34:58.449208 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:35:13.180392 25496 solver.cpp:514] Iteration 30500, Testing net (#0)
I0929 20:35:40.848690 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:35:40.989192 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.97421 (* 1 = 0.97421 loss)
I0929 20:35:40.989218 25496 solver.cpp:580]     Test net output #1: prob = 0.673
I0929 20:35:40.989225 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:35:41.325021 25496 solver.cpp:357] Iteration 30500 (1.43556 iter/s, 69.6593s/100 iters), loss = 0.335486
I0929 20:35:41.325104 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.335486 (* 1 = 0.335486 loss)
I0929 20:35:41.325116 25496 sgd_solver.cpp:165] Iteration 30500, lr = 0.1
I0929 20:36:22.955235 25496 solver.cpp:357] Iteration 30600 (2.40213 iter/s, 41.6297s/100 iters), loss = 0.314793
I0929 20:36:22.955370 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.314793 (* 1 = 0.314793 loss)
I0929 20:36:22.955382 25496 sgd_solver.cpp:165] Iteration 30600, lr = 0.1
I0929 20:37:04.948580 25496 solver.cpp:357] Iteration 30700 (2.38136 iter/s, 41.9927s/100 iters), loss = 0.500068
I0929 20:37:04.948773 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.500068 (* 1 = 0.500068 loss)
I0929 20:37:04.948786 25496 sgd_solver.cpp:165] Iteration 30700, lr = 0.1
I0929 20:37:46.714505 25496 solver.cpp:357] Iteration 30800 (2.39433 iter/s, 41.7653s/100 iters), loss = 0.302529
I0929 20:37:46.714658 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.302529 (* 1 = 0.302529 loss)
I0929 20:37:46.714668 25496 sgd_solver.cpp:165] Iteration 30800, lr = 0.1
I0929 20:38:09.709298 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:38:28.671396 25496 solver.cpp:357] Iteration 30900 (2.38332 iter/s, 41.9583s/100 iters), loss = 0.500624
I0929 20:38:28.671553 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.500624 (* 1 = 0.500624 loss)
I0929 20:38:28.671566 25496 sgd_solver.cpp:165] Iteration 30900, lr = 0.1
I0929 20:39:10.521893 25496 solver.cpp:514] Iteration 31000, Testing net (#0)
I0929 20:39:38.180142 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:39:38.233177 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.808328 (* 1 = 0.808328 loss)
I0929 20:39:38.233218 25496 solver.cpp:580]     Test net output #1: prob = 0.7342
I0929 20:39:38.233224 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:39:38.591120 25496 solver.cpp:357] Iteration 31000 (1.4302 iter/s, 69.9201s/100 iters), loss = 0.423326
I0929 20:39:38.591181 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.423326 (* 1 = 0.423326 loss)
I0929 20:39:38.591192 25496 sgd_solver.cpp:165] Iteration 31000, lr = 0.1
I0929 20:40:20.545817 25496 solver.cpp:357] Iteration 31100 (2.38356 iter/s, 41.9541s/100 iters), loss = 0.365029
I0929 20:40:20.545987 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.365029 (* 1 = 0.365029 loss)
I0929 20:40:20.546001 25496 sgd_solver.cpp:165] Iteration 31100, lr = 0.1
I0929 20:41:02.416690 25496 solver.cpp:357] Iteration 31200 (2.38833 iter/s, 41.8703s/100 iters), loss = 0.270206
I0929 20:41:02.416859 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.270206 (* 1 = 0.270206 loss)
I0929 20:41:02.416873 25496 sgd_solver.cpp:165] Iteration 31200, lr = 0.1
I0929 20:41:21.475199 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:41:44.456984 25496 solver.cpp:357] Iteration 31300 (2.3787 iter/s, 42.0397s/100 iters), loss = 0.26953
I0929 20:41:44.457242 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.26953 (* 1 = 0.26953 loss)
I0929 20:41:44.457257 25496 sgd_solver.cpp:165] Iteration 31300, lr = 0.1
I0929 20:42:26.363837 25496 solver.cpp:357] Iteration 31400 (2.38628 iter/s, 41.9063s/100 iters), loss = 0.56723
I0929 20:42:26.363979 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.56723 (* 1 = 0.56723 loss)
I0929 20:42:26.363991 25496 sgd_solver.cpp:165] Iteration 31400, lr = 0.1
I0929 20:43:07.933321 25496 solver.cpp:514] Iteration 31500, Testing net (#0)
I0929 20:43:35.724761 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:43:35.865006 25496 solver.cpp:580]     Test net output #0: Softmax1 = 2.05122 (* 1 = 2.05122 loss)
I0929 20:43:35.865036 25496 solver.cpp:580]     Test net output #1: prob = 0.5303
I0929 20:43:35.865043 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:43:36.204605 25496 solver.cpp:357] Iteration 31500 (1.43182 iter/s, 69.8413s/100 iters), loss = 0.350671
I0929 20:43:36.204696 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.350671 (* 1 = 0.350671 loss)
I0929 20:43:36.204710 25496 sgd_solver.cpp:165] Iteration 31500, lr = 0.1
I0929 20:44:17.979682 25496 solver.cpp:357] Iteration 31600 (2.3938 iter/s, 41.7745s/100 iters), loss = 0.431612
I0929 20:44:17.979846 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.431612 (* 1 = 0.431612 loss)
I0929 20:44:17.979859 25496 sgd_solver.cpp:165] Iteration 31600, lr = 0.1
I0929 20:44:33.355238 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:45:00.067494 25496 solver.cpp:357] Iteration 31700 (2.3759 iter/s, 42.0893s/100 iters), loss = 0.423902
I0929 20:45:00.067646 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.423902 (* 1 = 0.423902 loss)
I0929 20:45:00.067657 25496 sgd_solver.cpp:165] Iteration 31700, lr = 0.1
I0929 20:45:42.003201 25496 solver.cpp:357] Iteration 31800 (2.38452 iter/s, 41.9372s/100 iters), loss = 0.358858
I0929 20:45:42.003374 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.358858 (* 1 = 0.358858 loss)
I0929 20:45:42.003386 25496 sgd_solver.cpp:165] Iteration 31800, lr = 0.1
I0929 20:46:23.692929 25496 solver.cpp:357] Iteration 31900 (2.3987 iter/s, 41.6892s/100 iters), loss = 0.415617
I0929 20:46:23.693048 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.415617 (* 1 = 0.415617 loss)
I0929 20:46:23.693060 25496 sgd_solver.cpp:165] Iteration 31900, lr = 0.1
I0929 20:47:05.151839 25496 solver.cpp:514] Iteration 32000, Testing net (#0)
I0929 20:47:33.119285 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:47:33.180609 25496 solver.cpp:580]     Test net output #0: Softmax1 = 1.28526 (* 1 = 1.28526 loss)
I0929 20:47:33.180649 25496 solver.cpp:580]     Test net output #1: prob = 0.65
I0929 20:47:33.180656 25496 solver.cpp:593]     Max_acc: 0.7805  with iter: 14500
I0929 20:47:33.532488 25496 solver.cpp:357] Iteration 32000 (1.4318 iter/s, 69.8422s/100 iters), loss = 0.343884
I0929 20:47:33.532557 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.343884 (* 1 = 0.343884 loss)
I0929 20:47:33.532567 25496 sgd_solver.cpp:64] MultiStep Status: Iteration 32000, step = 1
I0929 20:47:33.532573 25496 sgd_solver.cpp:165] Iteration 32000, lr = 0.01
I0929 20:47:44.927405 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:48:15.622232 25496 solver.cpp:357] Iteration 32100 (2.37591 iter/s, 42.0892s/100 iters), loss = 0.214695
I0929 20:48:15.622381 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.214695 (* 1 = 0.214695 loss)
I0929 20:48:15.622392 25496 sgd_solver.cpp:165] Iteration 32100, lr = 0.01
I0929 20:48:57.634809 25496 solver.cpp:357] Iteration 32200 (2.38027 iter/s, 42.0121s/100 iters), loss = 0.297562
I0929 20:48:57.635057 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.297562 (* 1 = 0.297562 loss)
I0929 20:48:57.635069 25496 sgd_solver.cpp:165] Iteration 32200, lr = 0.01
I0929 20:49:39.453424 25496 solver.cpp:357] Iteration 32300 (2.39131 iter/s, 41.8181s/100 iters), loss = 0.150239
I0929 20:49:39.453544 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.150239 (* 1 = 0.150239 loss)
I0929 20:49:39.453557 25496 sgd_solver.cpp:165] Iteration 32300, lr = 0.01
I0929 20:50:21.325248 25496 solver.cpp:357] Iteration 32400 (2.38827 iter/s, 41.8713s/100 iters), loss = 0.199486
I0929 20:50:21.325424 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.199486 (* 1 = 0.199486 loss)
I0929 20:50:21.325436 25496 sgd_solver.cpp:165] Iteration 32400, lr = 0.01
I0929 20:50:28.314918 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:51:02.647079 25496 solver.cpp:514] Iteration 32500, Testing net (#0)
I0929 20:51:30.455688 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:51:30.556638 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.414417 (* 1 = 0.414417 loss)
I0929 20:51:30.556664 25496 solver.cpp:580]     Test net output #1: prob = 0.857701
I0929 20:51:30.556677 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_32500.caffemodel
I0929 20:51:30.572546 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_32500.solverstate
I0929 20:51:30.577214 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 20:51:30.909584 25496 solver.cpp:357] Iteration 32500 (1.43709 iter/s, 69.585s/100 iters), loss = 0.147237
I0929 20:51:30.909669 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.147237 (* 1 = 0.147237 loss)
I0929 20:51:30.909680 25496 sgd_solver.cpp:165] Iteration 32500, lr = 0.01
I0929 20:52:12.652580 25496 solver.cpp:357] Iteration 32600 (2.39564 iter/s, 41.7425s/100 iters), loss = 0.147117
I0929 20:52:12.652765 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.147117 (* 1 = 0.147117 loss)
I0929 20:52:12.652776 25496 sgd_solver.cpp:165] Iteration 32600, lr = 0.01
I0929 20:52:54.394527 25496 solver.cpp:357] Iteration 32700 (2.3957 iter/s, 41.7415s/100 iters), loss = 0.16882
I0929 20:52:54.394724 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.16882 (* 1 = 0.16882 loss)
I0929 20:52:54.394737 25496 sgd_solver.cpp:165] Iteration 32700, lr = 0.01
I0929 20:53:36.368475 25496 solver.cpp:357] Iteration 32800 (2.38235 iter/s, 41.9754s/100 iters), loss = 0.132342
I0929 20:53:36.368551 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.132342 (* 1 = 0.132342 loss)
I0929 20:53:36.368562 25496 sgd_solver.cpp:165] Iteration 32800, lr = 0.01
I0929 20:53:39.809921 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:54:18.294900 25496 solver.cpp:357] Iteration 32900 (2.38516 iter/s, 41.9259s/100 iters), loss = 0.144221
I0929 20:54:18.295079 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.144221 (* 1 = 0.144221 loss)
I0929 20:54:18.295092 25496 sgd_solver.cpp:165] Iteration 32900, lr = 0.01
I0929 20:55:03.072476 25496 solver.cpp:514] Iteration 33000, Testing net (#0)
I0929 20:55:36.423111 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:55:36.587293 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.441375 (* 1 = 0.441375 loss)
I0929 20:55:36.587407 25496 solver.cpp:580]     Test net output #1: prob = 0.843802
I0929 20:55:36.587451 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 20:55:37.020038 25496 solver.cpp:357] Iteration 33000 (1.27023 iter/s, 78.7261s/100 iters), loss = 0.147306
I0929 20:55:37.020207 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.147306 (* 1 = 0.147306 loss)
I0929 20:55:37.020234 25496 sgd_solver.cpp:165] Iteration 33000, lr = 0.01
I0929 20:56:28.266057 25496 solver.cpp:357] Iteration 33100 (1.95139 iter/s, 51.2455s/100 iters), loss = 0.185467
I0929 20:56:28.266458 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.185467 (* 1 = 0.185467 loss)
I0929 20:56:28.266486 25496 sgd_solver.cpp:165] Iteration 33100, lr = 0.01
I0929 20:57:18.063710 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 20:57:18.454761 25496 solver.cpp:357] Iteration 33200 (1.99249 iter/s, 50.1885s/100 iters), loss = 0.151768
I0929 20:57:18.454927 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.151768 (* 1 = 0.151768 loss)
I0929 20:57:18.454953 25496 sgd_solver.cpp:165] Iteration 33200, lr = 0.01
I0929 20:58:09.521092 25496 solver.cpp:357] Iteration 33300 (1.95824 iter/s, 51.0662s/100 iters), loss = 0.17413
I0929 20:58:09.521270 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.17413 (* 1 = 0.17413 loss)
I0929 20:58:09.521296 25496 sgd_solver.cpp:165] Iteration 33300, lr = 0.01
I0929 20:59:00.145287 25496 solver.cpp:357] Iteration 33400 (1.97527 iter/s, 50.626s/100 iters), loss = 0.115854
I0929 20:59:00.145689 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.115854 (* 1 = 0.115854 loss)
I0929 20:59:00.145721 25496 sgd_solver.cpp:165] Iteration 33400, lr = 0.01
I0929 20:59:50.303458 25496 solver.cpp:514] Iteration 33500, Testing net (#0)
I0929 21:00:22.412081 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:00:22.503448 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.574186 (* 1 = 0.574186 loss)
I0929 21:00:22.503569 25496 solver.cpp:580]     Test net output #1: prob = 0.810601
I0929 21:00:22.503590 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:00:22.941756 25496 solver.cpp:357] Iteration 33500 (1.20774 iter/s, 82.7994s/100 iters), loss = 0.150827
I0929 21:00:22.941912 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.150827 (* 1 = 0.150827 loss)
I0929 21:00:22.941942 25496 sgd_solver.cpp:165] Iteration 33500, lr = 0.01
I0929 21:01:08.373157 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:01:13.804611 25496 solver.cpp:357] Iteration 33600 (1.96616 iter/s, 50.8606s/100 iters), loss = 0.166099
I0929 21:01:13.804723 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.166099 (* 1 = 0.166099 loss)
I0929 21:01:13.804749 25496 sgd_solver.cpp:165] Iteration 33600, lr = 0.01
I0929 21:02:04.683068 25496 solver.cpp:357] Iteration 33700 (1.96547 iter/s, 50.8783s/100 iters), loss = 0.191135
I0929 21:02:04.686026 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.191135 (* 1 = 0.191135 loss)
I0929 21:02:04.686054 25496 sgd_solver.cpp:165] Iteration 33700, lr = 0.01
I0929 21:02:55.297142 25496 solver.cpp:357] Iteration 33800 (1.97582 iter/s, 50.6118s/100 iters), loss = 0.118412
I0929 21:02:55.297394 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.118412 (* 1 = 0.118412 loss)
I0929 21:02:55.297422 25496 sgd_solver.cpp:165] Iteration 33800, lr = 0.01
I0929 21:03:45.916704 25496 solver.cpp:357] Iteration 33900 (1.97561 iter/s, 50.6173s/100 iters), loss = 0.170302
I0929 21:03:45.921113 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.170302 (* 1 = 0.170302 loss)
I0929 21:03:45.921182 25496 sgd_solver.cpp:165] Iteration 33900, lr = 0.01
I0929 21:04:24.506377 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:04:32.493679 25496 solver.cpp:514] Iteration 34000, Testing net (#0)
I0929 21:05:00.160583 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:05:00.285686 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.547161 (* 1 = 0.547161 loss)
I0929 21:05:00.285717 25496 solver.cpp:580]     Test net output #1: prob = 0.814701
I0929 21:05:00.285723 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:05:00.654229 25496 solver.cpp:357] Iteration 34000 (1.33808 iter/s, 74.7342s/100 iters), loss = 0.124353
I0929 21:05:00.654300 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.124353 (* 1 = 0.124353 loss)
I0929 21:05:00.654312 25496 sgd_solver.cpp:165] Iteration 34000, lr = 0.01
I0929 21:05:42.239673 25496 solver.cpp:357] Iteration 34100 (2.40459 iter/s, 41.5871s/100 iters), loss = 0.152367
I0929 21:05:42.239898 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.152367 (* 1 = 0.152367 loss)
I0929 21:05:42.239912 25496 sgd_solver.cpp:165] Iteration 34100, lr = 0.01
I0929 21:06:24.365269 25496 solver.cpp:357] Iteration 34200 (2.37388 iter/s, 42.1251s/100 iters), loss = 0.0767698
I0929 21:06:24.365453 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0767698 (* 1 = 0.0767698 loss)
I0929 21:06:24.365464 25496 sgd_solver.cpp:165] Iteration 34200, lr = 0.01
I0929 21:07:06.398934 25496 solver.cpp:357] Iteration 34300 (2.37907 iter/s, 42.0332s/100 iters), loss = 0.0903124
I0929 21:07:06.399117 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0903125 (* 1 = 0.0903125 loss)
I0929 21:07:06.399132 25496 sgd_solver.cpp:165] Iteration 34300, lr = 0.01
I0929 21:07:35.913853 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:07:48.548935 25496 solver.cpp:357] Iteration 34400 (2.3725 iter/s, 42.1496s/100 iters), loss = 0.2056
I0929 21:07:48.549118 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.2056 (* 1 = 0.2056 loss)
I0929 21:07:48.549129 25496 sgd_solver.cpp:165] Iteration 34400, lr = 0.01
I0929 21:08:30.332710 25496 solver.cpp:514] Iteration 34500, Testing net (#0)
I0929 21:08:58.064440 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:08:58.169317 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.661621 (* 1 = 0.661621 loss)
I0929 21:08:58.169358 25496 solver.cpp:580]     Test net output #1: prob = 0.7904
I0929 21:08:58.169364 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:08:58.515094 25496 solver.cpp:357] Iteration 34500 (1.42925 iter/s, 69.9668s/100 iters), loss = 0.144581
I0929 21:08:58.515156 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.144582 (* 1 = 0.144582 loss)
I0929 21:08:58.515168 25496 sgd_solver.cpp:165] Iteration 34500, lr = 0.01
I0929 21:09:40.451270 25496 solver.cpp:357] Iteration 34600 (2.3846 iter/s, 41.9357s/100 iters), loss = 0.150456
I0929 21:09:40.451453 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.150456 (* 1 = 0.150456 loss)
I0929 21:09:40.451467 25496 sgd_solver.cpp:165] Iteration 34600, lr = 0.01
I0929 21:10:22.055363 25496 solver.cpp:357] Iteration 34700 (2.40364 iter/s, 41.6036s/100 iters), loss = 0.156785
I0929 21:10:22.055543 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.156785 (* 1 = 0.156785 loss)
I0929 21:10:22.055555 25496 sgd_solver.cpp:165] Iteration 34700, lr = 0.01
I0929 21:10:47.433452 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:11:03.775871 25496 solver.cpp:357] Iteration 34800 (2.39759 iter/s, 41.7085s/100 iters), loss = 0.133976
I0929 21:11:03.776000 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.133976 (* 1 = 0.133976 loss)
I0929 21:11:03.776013 25496 sgd_solver.cpp:165] Iteration 34800, lr = 0.01
I0929 21:11:45.570787 25496 solver.cpp:357] Iteration 34900 (2.39424 iter/s, 41.7669s/100 iters), loss = 0.0884424
I0929 21:11:45.570969 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0884424 (* 1 = 0.0884424 loss)
I0929 21:11:45.570983 25496 sgd_solver.cpp:165] Iteration 34900, lr = 0.01
I0929 21:12:27.204398 25496 solver.cpp:514] Iteration 35000, Testing net (#0)
I0929 21:12:55.080029 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:12:55.189294 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.52645 (* 1 = 0.52645 loss)
I0929 21:12:55.189323 25496 solver.cpp:580]     Test net output #1: prob = 0.821601
I0929 21:12:55.189330 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:12:55.557337 25496 solver.cpp:357] Iteration 35000 (1.42961 iter/s, 69.9491s/100 iters), loss = 0.109156
I0929 21:12:55.557422 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.109156 (* 1 = 0.109156 loss)
I0929 21:12:55.557440 25496 sgd_solver.cpp:165] Iteration 35000, lr = 0.01
I0929 21:13:38.029299 25496 solver.cpp:357] Iteration 35100 (2.35559 iter/s, 42.4522s/100 iters), loss = 0.0772342
I0929 21:13:38.029680 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0772343 (* 1 = 0.0772343 loss)
I0929 21:13:38.029693 25496 sgd_solver.cpp:165] Iteration 35100, lr = 0.01
I0929 21:13:59.853158 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:14:20.072929 25496 solver.cpp:357] Iteration 35200 (2.37945 iter/s, 42.0265s/100 iters), loss = 0.146173
I0929 21:14:20.073052 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.146173 (* 1 = 0.146173 loss)
I0929 21:14:20.073065 25496 sgd_solver.cpp:165] Iteration 35200, lr = 0.01
I0929 21:15:02.014600 25496 solver.cpp:357] Iteration 35300 (2.38501 iter/s, 41.9286s/100 iters), loss = 0.106484
I0929 21:15:02.014726 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.106485 (* 1 = 0.106485 loss)
I0929 21:15:02.014739 25496 sgd_solver.cpp:165] Iteration 35300, lr = 0.01
I0929 21:15:44.118386 25496 solver.cpp:357] Iteration 35400 (2.37584 iter/s, 42.0903s/100 iters), loss = 0.126645
I0929 21:15:44.118580 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.126645 (* 1 = 0.126645 loss)
I0929 21:15:44.118593 25496 sgd_solver.cpp:165] Iteration 35400, lr = 0.01
I0929 21:16:25.903431 25496 solver.cpp:514] Iteration 35500, Testing net (#0)
I0929 21:16:53.696660 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:16:53.768589 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.710689 (* 1 = 0.710689 loss)
I0929 21:16:53.768631 25496 solver.cpp:580]     Test net output #1: prob = 0.7798
I0929 21:16:53.768638 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:16:54.132206 25496 solver.cpp:357] Iteration 35500 (1.42865 iter/s, 69.996s/100 iters), loss = 0.106266
I0929 21:16:54.132272 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.106267 (* 1 = 0.106267 loss)
I0929 21:16:54.132284 25496 sgd_solver.cpp:165] Iteration 35500, lr = 0.01
I0929 21:17:12.100980 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:17:36.422528 25496 solver.cpp:357] Iteration 35600 (2.36517 iter/s, 42.2802s/100 iters), loss = 0.124214
I0929 21:17:36.422612 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.124214 (* 1 = 0.124214 loss)
I0929 21:17:36.422624 25496 sgd_solver.cpp:165] Iteration 35600, lr = 0.01
I0929 21:18:18.307147 25496 solver.cpp:357] Iteration 35700 (2.38803 iter/s, 41.8755s/100 iters), loss = 0.10574
I0929 21:18:18.307312 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.10574 (* 1 = 0.10574 loss)
I0929 21:18:18.307322 25496 sgd_solver.cpp:165] Iteration 35700, lr = 0.01
I0929 21:19:00.222054 25496 solver.cpp:357] Iteration 35800 (2.38626 iter/s, 41.9066s/100 iters), loss = 0.113732
I0929 21:19:00.222425 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.113732 (* 1 = 0.113732 loss)
I0929 21:19:00.222494 25496 sgd_solver.cpp:165] Iteration 35800, lr = 0.01
I0929 21:19:41.866030 25496 solver.cpp:357] Iteration 35900 (2.40175 iter/s, 41.6363s/100 iters), loss = 0.0851406
I0929 21:19:41.866209 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0851407 (* 1 = 0.0851407 loss)
I0929 21:19:41.866220 25496 sgd_solver.cpp:165] Iteration 35900, lr = 0.01
I0929 21:19:55.934329 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:20:23.608682 25496 solver.cpp:514] Iteration 36000, Testing net (#0)
I0929 21:20:51.350006 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:20:51.492257 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.59249 (* 1 = 0.59249 loss)
I0929 21:20:51.492380 25496 solver.cpp:580]     Test net output #1: prob = 0.807201
I0929 21:20:51.492426 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:20:51.839174 25496 solver.cpp:357] Iteration 36000 (1.42933 iter/s, 69.963s/100 iters), loss = 0.118203
I0929 21:20:51.839260 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.118203 (* 1 = 0.118203 loss)
I0929 21:20:51.839272 25496 sgd_solver.cpp:165] Iteration 36000, lr = 0.01
I0929 21:21:34.204581 25496 solver.cpp:357] Iteration 36100 (2.36077 iter/s, 42.359s/100 iters), loss = 0.153011
I0929 21:21:34.204891 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.153011 (* 1 = 0.153011 loss)
I0929 21:21:34.204905 25496 sgd_solver.cpp:165] Iteration 36100, lr = 0.01
I0929 21:22:16.886246 25496 solver.cpp:357] Iteration 36200 (2.34326 iter/s, 42.6756s/100 iters), loss = 0.0614086
I0929 21:22:16.886453 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0614086 (* 1 = 0.0614086 loss)
I0929 21:22:16.886467 25496 sgd_solver.cpp:165] Iteration 36200, lr = 0.01
I0929 21:23:13.790297 25496 solver.cpp:357] Iteration 36300 (1.75756 iter/s, 56.8972s/100 iters), loss = 0.121816
I0929 21:23:13.790452 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.121816 (* 1 = 0.121816 loss)
I0929 21:23:13.790465 25496 sgd_solver.cpp:165] Iteration 36300, lr = 0.01
I0929 21:23:28.342598 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:24:13.872201 25496 solver.cpp:357] Iteration 36400 (1.66464 iter/s, 60.073s/100 iters), loss = 0.0955849
I0929 21:24:13.872386 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.095585 (* 1 = 0.095585 loss)
I0929 21:24:13.872400 25496 sgd_solver.cpp:165] Iteration 36400, lr = 0.01
I0929 21:25:12.815816 25496 solver.cpp:514] Iteration 36500, Testing net (#0)
I0929 21:26:00.286190 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:26:00.485823 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.670775 (* 1 = 0.670775 loss)
I0929 21:26:00.485872 25496 solver.cpp:580]     Test net output #1: prob = 0.795601
I0929 21:26:00.485879 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:26:00.963721 25496 solver.cpp:357] Iteration 36500 (0.93388 iter/s, 107.08s/100 iters), loss = 0.108687
I0929 21:26:00.963898 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.108687 (* 1 = 0.108687 loss)
I0929 21:26:00.963924 25496 sgd_solver.cpp:165] Iteration 36500, lr = 0.01
I0929 21:27:00.266094 25496 solver.cpp:357] Iteration 36600 (1.68643 iter/s, 59.2967s/100 iters), loss = 0.0860173
I0929 21:27:00.266306 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0860173 (* 1 = 0.0860173 loss)
I0929 21:27:00.266332 25496 sgd_solver.cpp:165] Iteration 36600, lr = 0.01
I0929 21:27:59.825104 25496 solver.cpp:357] Iteration 36700 (1.67908 iter/s, 59.5564s/100 iters), loss = 0.0901811
I0929 21:27:59.825240 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0901811 (* 1 = 0.0901811 loss)
I0929 21:27:59.825254 25496 sgd_solver.cpp:165] Iteration 36700, lr = 0.01
I0929 21:28:08.385092 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:28:59.758558 25496 solver.cpp:357] Iteration 36800 (1.66779 iter/s, 59.9597s/100 iters), loss = 0.144312
I0929 21:28:59.758764 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.144312 (* 1 = 0.144312 loss)
I0929 21:28:59.758791 25496 sgd_solver.cpp:165] Iteration 36800, lr = 0.01
I0929 21:29:59.629278 25496 solver.cpp:357] Iteration 36900 (1.66972 iter/s, 59.8902s/100 iters), loss = 0.146229
I0929 21:29:59.629452 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.146229 (* 1 = 0.146229 loss)
I0929 21:29:59.629464 25496 sgd_solver.cpp:165] Iteration 36900, lr = 0.01
I0929 21:30:58.897997 25496 solver.cpp:514] Iteration 37000, Testing net (#0)
I0929 21:31:46.408634 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:31:46.578783 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.466505 (* 1 = 0.466505 loss)
I0929 21:31:46.578907 25496 solver.cpp:580]     Test net output #1: prob = 0.848301
I0929 21:31:46.578959 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:31:47.014559 25496 solver.cpp:357] Iteration 37000 (0.930998 iter/s, 107.412s/100 iters), loss = 0.198475
I0929 21:31:47.014647 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.198475 (* 1 = 0.198475 loss)
I0929 21:31:47.014659 25496 sgd_solver.cpp:165] Iteration 37000, lr = 0.01
I0929 21:32:46.608530 25496 solver.cpp:357] Iteration 37100 (1.67773 iter/s, 59.6044s/100 iters), loss = 0.0639929
I0929 21:32:46.608783 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0639929 (* 1 = 0.0639929 loss)
I0929 21:32:46.608796 25496 sgd_solver.cpp:165] Iteration 37100, lr = 0.01
I0929 21:32:49.764731 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:33:46.180635 25496 solver.cpp:357] Iteration 37200 (1.67843 iter/s, 59.5796s/100 iters), loss = 0.0837398
I0929 21:33:46.180855 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0837399 (* 1 = 0.0837399 loss)
I0929 21:33:46.180882 25496 sgd_solver.cpp:165] Iteration 37200, lr = 0.01
I0929 21:34:45.788705 25496 solver.cpp:357] Iteration 37300 (1.67746 iter/s, 59.6141s/100 iters), loss = 0.103973
I0929 21:34:45.788831 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.103973 (* 1 = 0.103973 loss)
I0929 21:34:45.788844 25496 sgd_solver.cpp:165] Iteration 37300, lr = 0.01
I0929 21:35:45.304432 25496 solver.cpp:357] Iteration 37400 (1.68003 iter/s, 59.5226s/100 iters), loss = 0.118243
I0929 21:35:45.304646 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.118243 (* 1 = 0.118243 loss)
I0929 21:35:45.304672 25496 sgd_solver.cpp:165] Iteration 37400, lr = 0.01
I0929 21:36:41.960369 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:36:44.265928 25496 solver.cpp:514] Iteration 37500, Testing net (#0)
I0929 21:37:30.450453 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:37:30.652885 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.508718 (* 1 = 0.508718 loss)
I0929 21:37:30.652930 25496 solver.cpp:580]     Test net output #1: prob = 0.836901
I0929 21:37:30.652936 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:37:31.112188 25496 solver.cpp:357] Iteration 37500 (0.94503 iter/s, 105.817s/100 iters), loss = 0.0826859
I0929 21:37:31.112308 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.082686 (* 1 = 0.082686 loss)
I0929 21:37:31.112323 25496 sgd_solver.cpp:165] Iteration 37500, lr = 0.01
I0929 21:38:30.658103 25496 solver.cpp:357] Iteration 37600 (1.67931 iter/s, 59.5481s/100 iters), loss = 0.166357
I0929 21:38:30.658269 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.166357 (* 1 = 0.166357 loss)
I0929 21:38:30.658284 25496 sgd_solver.cpp:165] Iteration 37600, lr = 0.01
I0929 21:39:30.187196 25496 solver.cpp:357] Iteration 37700 (1.67987 iter/s, 59.5284s/100 iters), loss = 0.0942255
I0929 21:39:30.187358 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0942256 (* 1 = 0.0942256 loss)
I0929 21:39:30.187372 25496 sgd_solver.cpp:165] Iteration 37700, lr = 0.01
I0929 21:40:29.300168 25496 solver.cpp:357] Iteration 37800 (1.69167 iter/s, 59.1133s/100 iters), loss = 0.0872611
I0929 21:40:29.300406 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0872612 (* 1 = 0.0872612 loss)
I0929 21:40:29.300438 25496 sgd_solver.cpp:165] Iteration 37800, lr = 0.01
I0929 21:41:20.859098 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:41:29.004415 25496 solver.cpp:357] Iteration 37900 (1.6749 iter/s, 59.7049s/100 iters), loss = 0.190128
I0929 21:41:29.004575 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.190128 (* 1 = 0.190128 loss)
I0929 21:41:29.004601 25496 sgd_solver.cpp:165] Iteration 37900, lr = 0.01
I0929 21:42:28.889981 25496 solver.cpp:514] Iteration 38000, Testing net (#0)
I0929 21:43:15.678647 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:43:15.875285 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.753387 (* 1 = 0.753387 loss)
I0929 21:43:15.875414 25496 solver.cpp:580]     Test net output #1: prob = 0.784901
I0929 21:43:15.875437 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:43:16.308356 25496 solver.cpp:357] Iteration 38000 (0.931925 iter/s, 107.305s/100 iters), loss = 0.0796437
I0929 21:43:16.308440 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0796437 (* 1 = 0.0796437 loss)
I0929 21:43:16.308457 25496 sgd_solver.cpp:165] Iteration 38000, lr = 0.01
I0929 21:44:15.957141 25496 solver.cpp:357] Iteration 38100 (1.67654 iter/s, 59.6465s/100 iters), loss = 0.0563984
I0929 21:44:15.957357 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0563984 (* 1 = 0.0563984 loss)
I0929 21:44:15.957372 25496 sgd_solver.cpp:165] Iteration 38100, lr = 0.01
I0929 21:45:15.312888 25496 solver.cpp:357] Iteration 38200 (1.68479 iter/s, 59.3544s/100 iters), loss = 0.105198
I0929 21:45:15.313056 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.105198 (* 1 = 0.105198 loss)
I0929 21:45:15.313069 25496 sgd_solver.cpp:165] Iteration 38200, lr = 0.01
I0929 21:46:01.166752 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:46:14.639292 25496 solver.cpp:357] Iteration 38300 (1.68569 iter/s, 59.3228s/100 iters), loss = 0.142372
I0929 21:46:14.639452 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.142372 (* 1 = 0.142372 loss)
I0929 21:46:14.639478 25496 sgd_solver.cpp:165] Iteration 38300, lr = 0.01
I0929 21:47:14.007954 25496 solver.cpp:357] Iteration 38400 (1.68445 iter/s, 59.3665s/100 iters), loss = 0.0997897
I0929 21:47:14.008129 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0997897 (* 1 = 0.0997897 loss)
I0929 21:47:14.008143 25496 sgd_solver.cpp:165] Iteration 38400, lr = 0.01
I0929 21:48:13.500443 25496 solver.cpp:514] Iteration 38500, Testing net (#0)
I0929 21:49:00.571317 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:49:00.758421 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.519638 (* 1 = 0.519638 loss)
I0929 21:49:00.758533 25496 solver.cpp:580]     Test net output #1: prob = 0.835401
I0929 21:49:00.758553 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:49:01.245213 25496 solver.cpp:357] Iteration 38500 (0.932546 iter/s, 107.233s/100 iters), loss = 0.101428
I0929 21:49:01.245374 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.101428 (* 1 = 0.101428 loss)
I0929 21:49:01.245406 25496 sgd_solver.cpp:165] Iteration 38500, lr = 0.01
I0929 21:50:00.968184 25496 solver.cpp:357] Iteration 38600 (1.67449 iter/s, 59.7198s/100 iters), loss = 0.069097
I0929 21:50:00.968459 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0690971 (* 1 = 0.0690971 loss)
I0929 21:50:00.968487 25496 sgd_solver.cpp:165] Iteration 38600, lr = 0.01
I0929 21:50:40.994272 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:51:00.670615 25496 solver.cpp:357] Iteration 38700 (1.67502 iter/s, 59.7007s/100 iters), loss = 0.134813
I0929 21:51:00.670706 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.134813 (* 1 = 0.134813 loss)
I0929 21:51:00.670718 25496 sgd_solver.cpp:165] Iteration 38700, lr = 0.01
I0929 21:51:59.993674 25496 solver.cpp:357] Iteration 38800 (1.68579 iter/s, 59.3193s/100 iters), loss = 0.110229
I0929 21:51:59.993832 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.110229 (* 1 = 0.110229 loss)
I0929 21:51:59.993845 25496 sgd_solver.cpp:165] Iteration 38800, lr = 0.01
I0929 21:52:59.889638 25496 solver.cpp:357] Iteration 38900 (1.66967 iter/s, 59.8922s/100 iters), loss = 0.102523
I0929 21:52:59.889780 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.102523 (* 1 = 0.102523 loss)
I0929 21:52:59.889793 25496 sgd_solver.cpp:165] Iteration 38900, lr = 0.01
I0929 21:53:58.812211 25496 solver.cpp:514] Iteration 39000, Testing net (#0)
I0929 21:54:45.829825 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:54:46.036958 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.693589 (* 1 = 0.693589 loss)
I0929 21:54:46.037001 25496 solver.cpp:580]     Test net output #1: prob = 0.7888
I0929 21:54:46.037009 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 21:54:46.485690 25496 solver.cpp:357] Iteration 39000 (0.938148 iter/s, 106.593s/100 iters), loss = 0.0890552
I0929 21:54:46.485788 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0890553 (* 1 = 0.0890553 loss)
I0929 21:54:46.485800 25496 sgd_solver.cpp:165] Iteration 39000, lr = 0.01
I0929 21:55:21.122056 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:55:45.733570 25496 solver.cpp:357] Iteration 39100 (1.68793 iter/s, 59.2443s/100 iters), loss = 0.114672
I0929 21:55:45.733716 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.114672 (* 1 = 0.114672 loss)
I0929 21:55:45.733742 25496 sgd_solver.cpp:165] Iteration 39100, lr = 0.01
I0929 21:56:45.381659 25496 solver.cpp:357] Iteration 39200 (1.67654 iter/s, 59.6468s/100 iters), loss = 0.135726
I0929 21:56:45.381876 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.135726 (* 1 = 0.135726 loss)
I0929 21:56:45.381901 25496 sgd_solver.cpp:165] Iteration 39200, lr = 0.01
I0929 21:57:45.307242 25496 solver.cpp:357] Iteration 39300 (1.66878 iter/s, 59.924s/100 iters), loss = 0.0990064
I0929 21:57:45.307327 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0990064 (* 1 = 0.0990064 loss)
I0929 21:57:45.307339 25496 sgd_solver.cpp:165] Iteration 39300, lr = 0.01
I0929 21:58:44.863808 25496 solver.cpp:357] Iteration 39400 (1.67917 iter/s, 59.5531s/100 iters), loss = 0.0936917
I0929 21:58:44.864039 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0936918 (* 1 = 0.0936918 loss)
I0929 21:58:44.864081 25496 sgd_solver.cpp:165] Iteration 39400, lr = 0.01
I0929 21:59:13.594664 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 21:59:43.774046 25496 solver.cpp:514] Iteration 39500, Testing net (#0)
I0929 22:00:30.733068 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:00:30.903450 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.865418 (* 1 = 0.865418 loss)
I0929 22:00:30.903589 25496 solver.cpp:580]     Test net output #1: prob = 0.782
I0929 22:00:30.903610 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 22:00:31.386732 25496 solver.cpp:357] Iteration 39500 (0.938774 iter/s, 106.522s/100 iters), loss = 0.0723477
I0929 22:00:31.386812 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0723478 (* 1 = 0.0723478 loss)
I0929 22:00:31.386826 25496 sgd_solver.cpp:165] Iteration 39500, lr = 0.01
I0929 22:01:31.220041 25496 solver.cpp:357] Iteration 39600 (1.6714 iter/s, 59.8299s/100 iters), loss = 0.131147
I0929 22:01:31.220181 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.131148 (* 1 = 0.131148 loss)
I0929 22:01:31.220194 25496 sgd_solver.cpp:165] Iteration 39600, lr = 0.01
I0929 22:02:31.263104 25496 solver.cpp:357] Iteration 39700 (1.66557 iter/s, 60.0396s/100 iters), loss = 0.107034
I0929 22:02:31.263293 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.107034 (* 1 = 0.107034 loss)
I0929 22:02:31.263325 25496 sgd_solver.cpp:165] Iteration 39700, lr = 0.01
I0929 22:03:30.974014 25496 solver.cpp:357] Iteration 39800 (1.67483 iter/s, 59.7076s/100 iters), loss = 0.0734824
I0929 22:03:30.974195 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0734824 (* 1 = 0.0734824 loss)
I0929 22:03:30.974208 25496 sgd_solver.cpp:165] Iteration 39800, lr = 0.01
I0929 22:03:54.410981 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:04:30.585847 25496 solver.cpp:357] Iteration 39900 (1.67761 iter/s, 59.6085s/100 iters), loss = 0.0850305
I0929 22:04:30.586030 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0850305 (* 1 = 0.0850305 loss)
I0929 22:04:30.586045 25496 sgd_solver.cpp:165] Iteration 39900, lr = 0.01
I0929 22:05:30.078647 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_40000.caffemodel
I0929 22:05:30.103924 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_40000.solverstate
I0929 22:05:30.138557 25496 solver.cpp:514] Iteration 40000, Testing net (#0)
I0929 22:06:16.399461 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:06:16.589224 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.601271 (* 1 = 0.601271 loss)
I0929 22:06:16.589308 25496 solver.cpp:580]     Test net output #1: prob = 0.820101
I0929 22:06:16.589329 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 22:06:17.069504 25496 solver.cpp:357] Iteration 40000 (0.939117 iter/s, 106.483s/100 iters), loss = 0.132636
I0929 22:06:17.069679 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.132636 (* 1 = 0.132636 loss)
I0929 22:06:17.069710 25496 sgd_solver.cpp:165] Iteration 40000, lr = 0.01
I0929 22:07:16.808701 25496 solver.cpp:357] Iteration 40100 (1.67397 iter/s, 59.7382s/100 iters), loss = 0.0813693
I0929 22:07:16.808934 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0813694 (* 1 = 0.0813694 loss)
I0929 22:07:16.808948 25496 sgd_solver.cpp:165] Iteration 40100, lr = 0.01
I0929 22:08:16.768527 25496 solver.cpp:357] Iteration 40200 (1.66783 iter/s, 59.9581s/100 iters), loss = 0.127221
I0929 22:08:16.768692 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.127221 (* 1 = 0.127221 loss)
I0929 22:08:16.768707 25496 sgd_solver.cpp:165] Iteration 40200, lr = 0.01
I0929 22:08:34.850646 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:09:16.149395 25496 solver.cpp:357] Iteration 40300 (1.68413 iter/s, 59.3777s/100 iters), loss = 0.0872063
I0929 22:09:16.149581 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0872063 (* 1 = 0.0872063 loss)
I0929 22:09:16.149610 25496 sgd_solver.cpp:165] Iteration 40300, lr = 0.01
I0929 22:10:15.784013 25496 solver.cpp:357] Iteration 40400 (1.67692 iter/s, 59.633s/100 iters), loss = 0.129724
I0929 22:10:15.784207 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.129724 (* 1 = 0.129724 loss)
I0929 22:10:15.784220 25496 sgd_solver.cpp:165] Iteration 40400, lr = 0.01
I0929 22:11:14.730659 25496 solver.cpp:514] Iteration 40500, Testing net (#0)
I0929 22:12:02.013216 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:12:02.211119 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.653398 (* 1 = 0.653398 loss)
I0929 22:12:02.211269 25496 solver.cpp:580]     Test net output #1: prob = 0.8178
I0929 22:12:02.211308 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 22:12:02.670485 25496 solver.cpp:357] Iteration 40500 (0.935592 iter/s, 106.884s/100 iters), loss = 0.0923984
I0929 22:12:02.670682 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0923985 (* 1 = 0.0923985 loss)
I0929 22:12:02.670727 25496 sgd_solver.cpp:165] Iteration 40500, lr = 0.01
I0929 22:13:02.711009 25496 solver.cpp:357] Iteration 40600 (1.66561 iter/s, 60.0381s/100 iters), loss = 0.0874536
I0929 22:13:02.711251 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0874536 (* 1 = 0.0874536 loss)
I0929 22:13:02.711294 25496 sgd_solver.cpp:165] Iteration 40600, lr = 0.01
I0929 22:13:14.567517 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:14:01.870398 25496 solver.cpp:357] Iteration 40700 (1.69039 iter/s, 59.1579s/100 iters), loss = 0.107269
I0929 22:14:01.870527 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.107269 (* 1 = 0.107269 loss)
I0929 22:14:01.870538 25496 sgd_solver.cpp:165] Iteration 40700, lr = 0.01
I0929 22:15:01.689291 25496 solver.cpp:357] Iteration 40800 (1.6717 iter/s, 59.8195s/100 iters), loss = 0.0587362
I0929 22:15:01.689589 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0587362 (* 1 = 0.0587362 loss)
I0929 22:15:01.689627 25496 sgd_solver.cpp:165] Iteration 40800, lr = 0.01
I0929 22:16:01.728893 25496 solver.cpp:357] Iteration 40900 (1.66566 iter/s, 60.0364s/100 iters), loss = 0.0577358
I0929 22:16:01.729010 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0577358 (* 1 = 0.0577358 loss)
I0929 22:16:01.729024 25496 sgd_solver.cpp:165] Iteration 40900, lr = 0.01
I0929 22:17:00.566079 25496 solver.cpp:514] Iteration 41000, Testing net (#0)
I0929 22:17:46.865803 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:17:47.053853 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.518726 (* 1 = 0.518726 loss)
I0929 22:17:47.053977 25496 solver.cpp:580]     Test net output #1: prob = 0.843501
I0929 22:17:47.054000 25496 solver.cpp:593]     Max_acc: 0.857701  with iter: 32500
I0929 22:17:47.539289 25496 solver.cpp:357] Iteration 41000 (0.945087 iter/s, 105.81s/100 iters), loss = 0.0958022
I0929 22:17:47.539443 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0958023 (* 1 = 0.0958023 loss)
I0929 22:17:47.539474 25496 sgd_solver.cpp:165] Iteration 41000, lr = 0.01
I0929 22:17:54.136448 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:18:47.206702 25496 solver.cpp:357] Iteration 41100 (1.67598 iter/s, 59.6665s/100 iters), loss = 0.131686
I0929 22:18:47.206912 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.131687 (* 1 = 0.131687 loss)
I0929 22:18:47.206924 25496 sgd_solver.cpp:165] Iteration 41100, lr = 0.01
I0929 22:19:46.289939 25496 solver.cpp:357] Iteration 41200 (1.69259 iter/s, 59.0811s/100 iters), loss = 0.0786466
I0929 22:19:46.290148 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0786466 (* 1 = 0.0786466 loss)
I0929 22:19:46.290175 25496 sgd_solver.cpp:165] Iteration 41200, lr = 0.01
I0929 22:20:46.053714 25496 solver.cpp:357] Iteration 41300 (1.67324 iter/s, 59.7642s/100 iters), loss = 0.0746898
I0929 22:20:46.053858 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0746899 (* 1 = 0.0746899 loss)
I0929 22:20:46.053881 25496 sgd_solver.cpp:165] Iteration 41300, lr = 0.01
I0929 22:21:45.600397 25496 solver.cpp:357] Iteration 41400 (1.67935 iter/s, 59.5469s/100 iters), loss = 0.0967593
I0929 22:21:45.600566 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0967593 (* 1 = 0.0967593 loss)
I0929 22:21:45.600594 25496 sgd_solver.cpp:165] Iteration 41400, lr = 0.01
I0929 22:21:46.863168 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:22:44.637796 25496 solver.cpp:514] Iteration 41500, Testing net (#0)
I0929 22:23:31.649684 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:23:31.840281 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.40511 (* 1 = 0.40511 loss)
I0929 22:23:31.840323 25496 solver.cpp:580]     Test net output #1: prob = 0.872402
I0929 22:23:31.840338 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_41500.caffemodel
I0929 22:23:31.856185 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_41500.solverstate
I0929 22:23:31.860412 25496 solver.cpp:593]     Max_acc: 0.872402  with iter: 41500
I0929 22:23:32.359220 25496 solver.cpp:357] Iteration 41500 (0.936673 iter/s, 106.761s/100 iters), loss = 0.0536469
I0929 22:23:32.359302 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.053647 (* 1 = 0.053647 loss)
I0929 22:23:32.359314 25496 sgd_solver.cpp:165] Iteration 41500, lr = 0.01
I0929 22:24:31.783496 25496 solver.cpp:357] Iteration 41600 (1.68285 iter/s, 59.423s/100 iters), loss = 0.129447
I0929 22:24:31.783682 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.129447 (* 1 = 0.129447 loss)
I0929 22:24:31.783709 25496 sgd_solver.cpp:165] Iteration 41600, lr = 0.01
I0929 22:25:31.455276 25496 solver.cpp:357] Iteration 41700 (1.6759 iter/s, 59.6695s/100 iters), loss = 0.0855853
I0929 22:25:31.455433 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0855854 (* 1 = 0.0855854 loss)
I0929 22:25:31.455446 25496 sgd_solver.cpp:165] Iteration 41700, lr = 0.01
I0929 22:26:26.838634 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:26:31.374331 25496 solver.cpp:357] Iteration 41800 (1.66892 iter/s, 59.919s/100 iters), loss = 0.157799
I0929 22:26:31.374414 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.157799 (* 1 = 0.157799 loss)
I0929 22:26:31.374428 25496 sgd_solver.cpp:165] Iteration 41800, lr = 0.01
I0929 22:27:31.358005 25496 solver.cpp:357] Iteration 41900 (1.66719 iter/s, 59.9813s/100 iters), loss = 0.102504
I0929 22:27:31.358124 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.102504 (* 1 = 0.102504 loss)
I0929 22:27:31.358136 25496 sgd_solver.cpp:165] Iteration 41900, lr = 0.01
I0929 22:28:29.865555 25496 solver.cpp:514] Iteration 42000, Testing net (#0)
I0929 22:29:16.440389 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:29:16.603449 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.566512 (* 1 = 0.566512 loss)
I0929 22:29:16.603493 25496 solver.cpp:580]     Test net output #1: prob = 0.844001
I0929 22:29:16.603500 25496 solver.cpp:593]     Max_acc: 0.872402  with iter: 41500
I0929 22:29:17.063808 25496 solver.cpp:357] Iteration 42000 (0.945998 iter/s, 105.708s/100 iters), loss = 0.0840443
I0929 22:29:17.063905 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0840443 (* 1 = 0.0840443 loss)
I0929 22:29:17.063917 25496 sgd_solver.cpp:165] Iteration 42000, lr = 0.01
I0929 22:30:16.248219 25496 solver.cpp:357] Iteration 42100 (1.68971 iter/s, 59.1819s/100 iters), loss = 0.0453446
I0929 22:30:16.248373 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0453446 (* 1 = 0.0453446 loss)
I0929 22:30:16.248384 25496 sgd_solver.cpp:165] Iteration 42100, lr = 0.01
I0929 22:31:05.913774 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:31:16.044260 25496 solver.cpp:357] Iteration 42200 (1.67242 iter/s, 59.7934s/100 iters), loss = 0.0626947
I0929 22:31:16.044343 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0626948 (* 1 = 0.0626948 loss)
I0929 22:31:16.044356 25496 sgd_solver.cpp:165] Iteration 42200, lr = 0.01
I0929 22:32:15.267567 25496 solver.cpp:357] Iteration 42300 (1.68855 iter/s, 59.2223s/100 iters), loss = 0.048909
I0929 22:32:15.267804 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0489091 (* 1 = 0.0489091 loss)
I0929 22:32:15.267833 25496 sgd_solver.cpp:165] Iteration 42300, lr = 0.01
I0929 22:33:15.117228 25496 solver.cpp:357] Iteration 42400 (1.67087 iter/s, 59.8489s/100 iters), loss = 0.1143
I0929 22:33:15.117439 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.1143 (* 1 = 0.1143 loss)
I0929 22:33:15.117466 25496 sgd_solver.cpp:165] Iteration 42400, lr = 0.01
I0929 22:34:14.425523 25496 solver.cpp:514] Iteration 42500, Testing net (#0)
I0929 22:35:01.537456 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:35:01.732136 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.504267 (* 1 = 0.504267 loss)
I0929 22:35:01.732262 25496 solver.cpp:580]     Test net output #1: prob = 0.846901
I0929 22:35:01.732290 25496 solver.cpp:593]     Max_acc: 0.872402  with iter: 41500
I0929 22:35:02.200809 25496 solver.cpp:357] Iteration 42500 (0.933846 iter/s, 107.084s/100 iters), loss = 0.0796434
I0929 22:35:02.200893 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0796434 (* 1 = 0.0796434 loss)
I0929 22:35:02.200906 25496 sgd_solver.cpp:165] Iteration 42500, lr = 0.01
I0929 22:35:45.733330 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:36:01.268577 25496 solver.cpp:357] Iteration 42600 (1.69303 iter/s, 59.0658s/100 iters), loss = 0.13188
I0929 22:36:01.268667 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.13188 (* 1 = 0.13188 loss)
I0929 22:36:01.268679 25496 sgd_solver.cpp:165] Iteration 42600, lr = 0.01
I0929 22:37:00.842053 25496 solver.cpp:357] Iteration 42700 (1.67868 iter/s, 59.5707s/100 iters), loss = 0.100435
I0929 22:37:00.842208 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.100435 (* 1 = 0.100435 loss)
I0929 22:37:00.842234 25496 sgd_solver.cpp:165] Iteration 42700, lr = 0.01
I0929 22:38:00.398159 25496 solver.cpp:357] Iteration 42800 (1.67908 iter/s, 59.5565s/100 iters), loss = 0.0532575
I0929 22:38:00.398479 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0532575 (* 1 = 0.0532575 loss)
I0929 22:38:00.398551 25496 sgd_solver.cpp:165] Iteration 42800, lr = 0.01
I0929 22:38:59.621817 25496 solver.cpp:357] Iteration 42900 (1.68859 iter/s, 59.2208s/100 iters), loss = 0.0572639
I0929 22:38:59.622011 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.057264 (* 1 = 0.057264 loss)
I0929 22:38:59.622025 25496 sgd_solver.cpp:165] Iteration 42900, lr = 0.01
I0929 22:39:37.873064 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:39:58.805990 25496 solver.cpp:514] Iteration 43000, Testing net (#0)
I0929 22:40:45.815326 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:40:45.959918 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.347933 (* 1 = 0.347933 loss)
I0929 22:40:45.959967 25496 solver.cpp:580]     Test net output #1: prob = 0.888702
I0929 22:40:45.959982 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_43000.caffemodel
I0929 22:40:45.977855 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_43000.solverstate
I0929 22:40:45.981976 25496 solver.cpp:593]     Max_acc: 0.888702  with iter: 43000
I0929 22:40:46.459076 25496 solver.cpp:357] Iteration 43000 (0.936017 iter/s, 106.836s/100 iters), loss = 0.104594
I0929 22:40:46.459223 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.104594 (* 1 = 0.104594 loss)
I0929 22:40:46.459250 25496 sgd_solver.cpp:165] Iteration 43000, lr = 0.01
I0929 22:41:46.060209 25496 solver.cpp:357] Iteration 43100 (1.67785 iter/s, 59.6s/100 iters), loss = 0.0494984
I0929 22:41:46.060489 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0494984 (* 1 = 0.0494984 loss)
I0929 22:41:46.060523 25496 sgd_solver.cpp:165] Iteration 43100, lr = 0.01
I0929 22:42:45.628896 25496 solver.cpp:357] Iteration 43200 (1.6788 iter/s, 59.5662s/100 iters), loss = 0.154355
I0929 22:42:45.629101 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.154355 (* 1 = 0.154355 loss)
I0929 22:42:45.629130 25496 sgd_solver.cpp:165] Iteration 43200, lr = 0.01
I0929 22:43:45.012197 25496 solver.cpp:357] Iteration 43300 (1.68394 iter/s, 59.3847s/100 iters), loss = 0.0769233
I0929 22:43:45.012351 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0769233 (* 1 = 0.0769233 loss)
I0929 22:43:45.012368 25496 sgd_solver.cpp:165] Iteration 43300, lr = 0.01
I0929 22:44:17.500496 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:44:44.138567 25496 solver.cpp:357] Iteration 43400 (1.69137 iter/s, 59.1236s/100 iters), loss = 0.139672
I0929 22:44:44.138705 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.139672 (* 1 = 0.139672 loss)
I0929 22:44:44.138728 25496 sgd_solver.cpp:165] Iteration 43400, lr = 0.01
I0929 22:45:43.167484 25496 solver.cpp:514] Iteration 43500, Testing net (#0)
I0929 22:46:29.433624 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:46:29.623328 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.534916 (* 1 = 0.534916 loss)
I0929 22:46:29.623433 25496 solver.cpp:580]     Test net output #1: prob = 0.849001
I0929 22:46:29.623456 25496 solver.cpp:593]     Max_acc: 0.888702  with iter: 43000
I0929 22:46:30.088161 25496 solver.cpp:357] Iteration 43500 (0.943823 iter/s, 105.952s/100 iters), loss = 0.0950855
I0929 22:46:30.088323 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0950856 (* 1 = 0.0950856 loss)
I0929 22:46:30.088349 25496 sgd_solver.cpp:165] Iteration 43500, lr = 0.01
I0929 22:47:29.707916 25496 solver.cpp:357] Iteration 43600 (1.67732 iter/s, 59.619s/100 iters), loss = 0.122547
I0929 22:47:29.708072 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.122547 (* 1 = 0.122547 loss)
I0929 22:47:29.708086 25496 sgd_solver.cpp:165] Iteration 43600, lr = 0.01
I0929 22:48:29.387480 25496 solver.cpp:357] Iteration 43700 (1.6757 iter/s, 59.6766s/100 iters), loss = 0.0675383
I0929 22:48:29.387610 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0675383 (* 1 = 0.0675383 loss)
I0929 22:48:29.387624 25496 sgd_solver.cpp:165] Iteration 43700, lr = 0.01
I0929 22:48:56.129408 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:49:28.373098 25496 solver.cpp:357] Iteration 43800 (1.69538 iter/s, 58.9837s/100 iters), loss = 0.0523228
I0929 22:49:28.373244 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0523228 (* 1 = 0.0523228 loss)
I0929 22:49:28.373256 25496 sgd_solver.cpp:165] Iteration 43800, lr = 0.01
I0929 22:50:28.443562 25496 solver.cpp:357] Iteration 43900 (1.66474 iter/s, 60.0695s/100 iters), loss = 0.0435682
I0929 22:50:28.443792 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0435682 (* 1 = 0.0435682 loss)
I0929 22:50:28.443806 25496 sgd_solver.cpp:165] Iteration 43900, lr = 0.01
I0929 22:51:27.541976 25496 solver.cpp:514] Iteration 44000, Testing net (#0)
I0929 22:52:14.720434 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:52:14.847563 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.655079 (* 1 = 0.655079 loss)
I0929 22:52:14.847671 25496 solver.cpp:580]     Test net output #1: prob = 0.829101
I0929 22:52:14.847692 25496 solver.cpp:593]     Max_acc: 0.888702  with iter: 43000
I0929 22:52:15.328438 25496 solver.cpp:357] Iteration 44000 (0.935585 iter/s, 106.885s/100 iters), loss = 0.0819627
I0929 22:52:15.328589 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0819628 (* 1 = 0.0819628 loss)
I0929 22:52:15.328616 25496 sgd_solver.cpp:165] Iteration 44000, lr = 0.01
I0929 22:53:15.314770 25496 solver.cpp:357] Iteration 44100 (1.66708 iter/s, 59.9852s/100 iters), loss = 0.0742525
I0929 22:53:15.314939 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0742526 (* 1 = 0.0742526 loss)
I0929 22:53:15.314952 25496 sgd_solver.cpp:165] Iteration 44100, lr = 0.01
I0929 22:53:36.502595 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:54:14.360486 25496 solver.cpp:357] Iteration 44200 (1.69347 iter/s, 59.0505s/100 iters), loss = 0.0954735
I0929 22:54:14.360697 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0954736 (* 1 = 0.0954736 loss)
I0929 22:54:14.360725 25496 sgd_solver.cpp:165] Iteration 44200, lr = 0.01
I0929 22:55:14.454550 25496 solver.cpp:357] Iteration 44300 (1.66396 iter/s, 60.0974s/100 iters), loss = 0.169067
I0929 22:55:14.454771 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.169067 (* 1 = 0.169067 loss)
I0929 22:55:14.454798 25496 sgd_solver.cpp:165] Iteration 44300, lr = 0.01
I0929 22:56:14.054519 25496 solver.cpp:357] Iteration 44400 (1.67775 iter/s, 59.6036s/100 iters), loss = 0.123648
I0929 22:56:14.054715 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.123649 (* 1 = 0.123649 loss)
I0929 22:56:14.054746 25496 sgd_solver.cpp:165] Iteration 44400, lr = 0.01
I0929 22:57:13.270999 25496 solver.cpp:514] Iteration 44500, Testing net (#0)
I0929 22:57:59.108141 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:57:59.280316 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.455831 (* 1 = 0.455831 loss)
I0929 22:57:59.280445 25496 solver.cpp:580]     Test net output #1: prob = 0.864602
I0929 22:57:59.280463 25496 solver.cpp:593]     Max_acc: 0.888702  with iter: 43000
I0929 22:57:59.758572 25496 solver.cpp:357] Iteration 44500 (0.945964 iter/s, 105.712s/100 iters), loss = 0.0352921
I0929 22:57:59.758658 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0352921 (* 1 = 0.0352921 loss)
I0929 22:57:59.758671 25496 sgd_solver.cpp:165] Iteration 44500, lr = 0.01
I0929 22:58:16.163784 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 22:58:59.376822 25496 solver.cpp:357] Iteration 44600 (1.67731 iter/s, 59.6192s/100 iters), loss = 0.13926
I0929 22:58:59.376986 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.13926 (* 1 = 0.13926 loss)
I0929 22:58:59.376998 25496 sgd_solver.cpp:165] Iteration 44600, lr = 0.01
I0929 22:59:59.053285 25496 solver.cpp:357] Iteration 44700 (1.67562 iter/s, 59.6792s/100 iters), loss = 0.134521
I0929 22:59:59.053457 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.134521 (* 1 = 0.134521 loss)
I0929 22:59:59.053469 25496 sgd_solver.cpp:165] Iteration 44700, lr = 0.01
I0929 23:00:58.529211 25496 solver.cpp:357] Iteration 44800 (1.68128 iter/s, 59.4784s/100 iters), loss = 0.0492123
I0929 23:00:58.529368 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0492123 (* 1 = 0.0492123 loss)
I0929 23:00:58.529381 25496 sgd_solver.cpp:165] Iteration 44800, lr = 0.01
I0929 23:01:58.163118 25496 solver.cpp:357] Iteration 44900 (1.67684 iter/s, 59.6361s/100 iters), loss = 0.132865
I0929 23:01:58.163336 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.132865 (* 1 = 0.132865 loss)
I0929 23:01:58.163349 25496 sgd_solver.cpp:165] Iteration 44900, lr = 0.01
I0929 23:02:08.581845 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:02:57.301909 25496 solver.cpp:514] Iteration 45000, Testing net (#0)
I0929 23:03:44.012989 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:03:44.191933 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.528834 (* 1 = 0.528834 loss)
I0929 23:03:44.191975 25496 solver.cpp:580]     Test net output #1: prob = 0.858601
I0929 23:03:44.191987 25496 solver.cpp:593]     Max_acc: 0.888702  with iter: 43000
I0929 23:03:44.668745 25496 solver.cpp:357] Iteration 45000 (0.938877 iter/s, 106.51s/100 iters), loss = 0.0772691
I0929 23:03:44.668835 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0772692 (* 1 = 0.0772692 loss)
I0929 23:03:44.668848 25496 sgd_solver.cpp:165] Iteration 45000, lr = 0.01
I0929 23:04:44.564018 25496 solver.cpp:357] Iteration 45100 (1.6696 iter/s, 59.8946s/100 iters), loss = 0.0690859
I0929 23:04:44.564219 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0690859 (* 1 = 0.0690859 loss)
I0929 23:04:44.564251 25496 sgd_solver.cpp:165] Iteration 45100, lr = 0.01
I0929 23:05:43.604405 25496 solver.cpp:357] Iteration 45200 (1.69372 iter/s, 59.0418s/100 iters), loss = 0.115468
I0929 23:05:43.604593 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.115468 (* 1 = 0.115468 loss)
I0929 23:05:43.604606 25496 sgd_solver.cpp:165] Iteration 45200, lr = 0.01
I0929 23:06:43.141137 25496 solver.cpp:357] Iteration 45300 (1.67966 iter/s, 59.5358s/100 iters), loss = 0.0553438
I0929 23:06:43.141314 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0553439 (* 1 = 0.0553439 loss)
I0929 23:06:43.141328 25496 sgd_solver.cpp:165] Iteration 45300, lr = 0.01
I0929 23:06:47.954059 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:07:42.560729 25496 solver.cpp:357] Iteration 45400 (1.68298 iter/s, 59.4185s/100 iters), loss = 0.0605071
I0929 23:07:42.560914 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0605072 (* 1 = 0.0605072 loss)
I0929 23:07:42.560925 25496 sgd_solver.cpp:165] Iteration 45400, lr = 0.01
I0929 23:08:41.106571 25496 solver.cpp:514] Iteration 45500, Testing net (#0)
I0929 23:09:27.778991 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:09:27.958055 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.474193 (* 1 = 0.474193 loss)
I0929 23:09:27.958099 25496 solver.cpp:580]     Test net output #1: prob = 0.874801
I0929 23:09:27.958106 25496 solver.cpp:593]     Max_acc: 0.888702  with iter: 43000
I0929 23:09:28.456190 25496 solver.cpp:357] Iteration 45500 (0.944317 iter/s, 105.897s/100 iters), loss = 0.0378526
I0929 23:09:28.456324 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0378527 (* 1 = 0.0378527 loss)
I0929 23:09:28.456349 25496 sgd_solver.cpp:165] Iteration 45500, lr = 0.01
I0929 23:10:27.881204 25496 solver.cpp:357] Iteration 45600 (1.68271 iter/s, 59.4279s/100 iters), loss = 0.0590041
I0929 23:10:27.881398 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0590042 (* 1 = 0.0590042 loss)
I0929 23:10:27.881428 25496 sgd_solver.cpp:165] Iteration 45600, lr = 0.01
I0929 23:11:27.063186 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:11:27.439837 25496 solver.cpp:357] Iteration 45700 (1.679 iter/s, 59.5594s/100 iters), loss = 0.0951846
I0929 23:11:27.439921 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0951848 (* 1 = 0.0951848 loss)
I0929 23:11:27.439934 25496 sgd_solver.cpp:165] Iteration 45700, lr = 0.01
I0929 23:12:26.478034 25496 solver.cpp:357] Iteration 45800 (1.69382 iter/s, 59.0381s/100 iters), loss = 0.199068
I0929 23:12:26.478188 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.199068 (* 1 = 0.199068 loss)
I0929 23:12:26.478214 25496 sgd_solver.cpp:165] Iteration 45800, lr = 0.01
I0929 23:13:26.025357 25496 solver.cpp:357] Iteration 45900 (1.67926 iter/s, 59.5499s/100 iters), loss = 0.0423055
I0929 23:13:26.025660 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0423056 (* 1 = 0.0423056 loss)
I0929 23:13:26.025717 25496 sgd_solver.cpp:165] Iteration 45900, lr = 0.01
I0929 23:14:25.285318 25496 solver.cpp:514] Iteration 46000, Testing net (#0)
I0929 23:15:12.277498 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:15:12.464762 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.386573 (* 1 = 0.386573 loss)
I0929 23:15:12.464802 25496 solver.cpp:580]     Test net output #1: prob = 0.883402
I0929 23:15:12.464810 25496 solver.cpp:593]     Max_acc: 0.888702  with iter: 43000
I0929 23:15:12.882889 25496 solver.cpp:357] Iteration 46000 (0.935822 iter/s, 106.858s/100 iters), loss = 0.0841359
I0929 23:15:12.883064 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.084136 (* 1 = 0.084136 loss)
I0929 23:15:12.883106 25496 sgd_solver.cpp:165] Iteration 46000, lr = 0.01
I0929 23:16:05.947764 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:16:12.490731 25496 solver.cpp:357] Iteration 46100 (1.67758 iter/s, 59.6097s/100 iters), loss = 0.165642
I0929 23:16:12.490816 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.165642 (* 1 = 0.165642 loss)
I0929 23:16:12.490829 25496 sgd_solver.cpp:165] Iteration 46100, lr = 0.01
I0929 23:17:12.327327 25496 solver.cpp:357] Iteration 46200 (1.67127 iter/s, 59.8348s/100 iters), loss = 0.0794002
I0929 23:17:12.327489 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0794004 (* 1 = 0.0794004 loss)
I0929 23:17:12.327503 25496 sgd_solver.cpp:165] Iteration 46200, lr = 0.01
I0929 23:18:12.047284 25496 solver.cpp:357] Iteration 46300 (1.67451 iter/s, 59.719s/100 iters), loss = 0.138632
I0929 23:18:12.047528 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.138632 (* 1 = 0.138632 loss)
I0929 23:18:12.047567 25496 sgd_solver.cpp:165] Iteration 46300, lr = 0.01
I0929 23:19:11.661841 25496 solver.cpp:357] Iteration 46400 (1.6775 iter/s, 59.6127s/100 iters), loss = 0.132682
I0929 23:19:11.662029 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.132682 (* 1 = 0.132682 loss)
I0929 23:19:11.662056 25496 sgd_solver.cpp:165] Iteration 46400, lr = 0.01
I0929 23:19:58.954331 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:20:10.435251 25496 solver.cpp:514] Iteration 46500, Testing net (#0)
I0929 23:20:57.663035 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:20:57.866801 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.527189 (* 1 = 0.527189 loss)
I0929 23:20:57.866909 25496 solver.cpp:580]     Test net output #1: prob = 0.852301
I0929 23:20:57.866930 25496 solver.cpp:593]     Max_acc: 0.888702  with iter: 43000
I0929 23:20:58.319427 25496 solver.cpp:357] Iteration 46500 (0.937577 iter/s, 106.658s/100 iters), loss = 0.0532613
I0929 23:20:58.319579 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0532614 (* 1 = 0.0532614 loss)
I0929 23:20:58.319607 25496 sgd_solver.cpp:165] Iteration 46500, lr = 0.01
I0929 23:21:57.858459 25496 solver.cpp:357] Iteration 46600 (1.6796 iter/s, 59.5378s/100 iters), loss = 0.139852
I0929 23:21:57.858650 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.139852 (* 1 = 0.139852 loss)
I0929 23:21:57.858664 25496 sgd_solver.cpp:165] Iteration 46600, lr = 0.01
I0929 23:22:56.957103 25496 solver.cpp:357] Iteration 46700 (1.6921 iter/s, 59.0983s/100 iters), loss = 0.0395252
I0929 23:22:56.957310 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0395254 (* 1 = 0.0395254 loss)
I0929 23:22:56.957355 25496 sgd_solver.cpp:165] Iteration 46700, lr = 0.01
I0929 23:23:56.595921 25496 solver.cpp:357] Iteration 46800 (1.67682 iter/s, 59.6368s/100 iters), loss = 0.0714728
I0929 23:23:56.596138 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.071473 (* 1 = 0.071473 loss)
I0929 23:23:56.596165 25496 sgd_solver.cpp:165] Iteration 46800, lr = 0.01
I0929 23:24:38.879289 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:24:56.714284 25496 solver.cpp:357] Iteration 46900 (1.66339 iter/s, 60.118s/100 iters), loss = 0.129696
I0929 23:24:56.714371 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.129697 (* 1 = 0.129697 loss)
I0929 23:24:56.714385 25496 sgd_solver.cpp:165] Iteration 46900, lr = 0.01
I0929 23:25:56.009158 25496 solver.cpp:514] Iteration 47000, Testing net (#0)
I0929 23:26:41.791698 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:26:41.941232 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.528815 (* 1 = 0.528815 loss)
I0929 23:26:41.941275 25496 solver.cpp:580]     Test net output #1: prob = 0.856001
I0929 23:26:41.941283 25496 solver.cpp:593]     Max_acc: 0.888702  with iter: 43000
I0929 23:26:42.331941 25496 solver.cpp:357] Iteration 47000 (0.946814 iter/s, 105.617s/100 iters), loss = 0.0619097
I0929 23:26:42.332038 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0619099 (* 1 = 0.0619099 loss)
I0929 23:26:42.332052 25496 sgd_solver.cpp:165] Iteration 47000, lr = 0.01
I0929 23:27:41.954756 25496 solver.cpp:357] Iteration 47100 (1.67727 iter/s, 59.6207s/100 iters), loss = 0.0790621
I0929 23:27:41.954947 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0790623 (* 1 = 0.0790623 loss)
I0929 23:27:41.954960 25496 sgd_solver.cpp:165] Iteration 47100, lr = 0.01
I0929 23:28:41.778683 25496 solver.cpp:357] Iteration 47200 (1.67186 iter/s, 59.8136s/100 iters), loss = 0.084964
I0929 23:28:41.778823 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0849642 (* 1 = 0.0849642 loss)
I0929 23:28:41.778837 25496 sgd_solver.cpp:165] Iteration 47200, lr = 0.01
I0929 23:29:18.432018 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:29:41.364706 25496 solver.cpp:357] Iteration 47300 (1.67858 iter/s, 59.5743s/100 iters), loss = 0.112553
I0929 23:29:41.364848 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.112554 (* 1 = 0.112554 loss)
I0929 23:29:41.364874 25496 sgd_solver.cpp:165] Iteration 47300, lr = 0.01
I0929 23:30:41.034196 25496 solver.cpp:357] Iteration 47400 (1.67615 iter/s, 59.6605s/100 iters), loss = 0.133676
I0929 23:30:41.034435 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.133677 (* 1 = 0.133677 loss)
I0929 23:30:41.034466 25496 sgd_solver.cpp:165] Iteration 47400, lr = 0.01
I0929 23:31:40.302860 25496 solver.cpp:514] Iteration 47500, Testing net (#0)
I0929 23:32:27.122964 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:32:27.319082 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.410328 (* 1 = 0.410328 loss)
I0929 23:32:27.319124 25496 solver.cpp:580]     Test net output #1: prob = 0.885502
I0929 23:32:27.319131 25496 solver.cpp:593]     Max_acc: 0.888702  with iter: 43000
I0929 23:32:27.770159 25496 solver.cpp:357] Iteration 47500 (0.937015 iter/s, 106.722s/100 iters), loss = 0.128299
I0929 23:32:27.770248 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.1283 (* 1 = 0.1283 loss)
I0929 23:32:27.770262 25496 sgd_solver.cpp:165] Iteration 47500, lr = 0.01
I0929 23:33:27.293097 25496 solver.cpp:357] Iteration 47600 (1.68028 iter/s, 59.514s/100 iters), loss = 0.133238
I0929 23:33:27.293256 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.133238 (* 1 = 0.133238 loss)
I0929 23:33:27.293268 25496 sgd_solver.cpp:165] Iteration 47600, lr = 0.01
I0929 23:33:58.282003 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:34:26.500442 25496 solver.cpp:357] Iteration 47700 (1.68917 iter/s, 59.2007s/100 iters), loss = 0.101882
I0929 23:34:26.500538 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.101882 (* 1 = 0.101882 loss)
I0929 23:34:26.500552 25496 sgd_solver.cpp:165] Iteration 47700, lr = 0.01
I0929 23:35:26.052166 25496 solver.cpp:357] Iteration 47800 (1.67939 iter/s, 59.5453s/100 iters), loss = 0.079829
I0929 23:35:26.052340 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0798292 (* 1 = 0.0798292 loss)
I0929 23:35:26.052352 25496 sgd_solver.cpp:165] Iteration 47800, lr = 0.01
I0929 23:36:25.480814 25496 solver.cpp:357] Iteration 47900 (1.6829 iter/s, 59.4213s/100 iters), loss = 0.112816
I0929 23:36:25.481073 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.112817 (* 1 = 0.112817 loss)
I0929 23:36:25.481104 25496 sgd_solver.cpp:165] Iteration 47900, lr = 0.01
I0929 23:37:24.784278 25496 solver.cpp:514] Iteration 48000, Testing net (#0)
I0929 23:38:10.464355 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:38:10.670289 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.47918 (* 1 = 0.47918 loss)
I0929 23:38:10.670387 25496 solver.cpp:580]     Test net output #1: prob = 0.869302
I0929 23:38:10.670397 25496 solver.cpp:593]     Max_acc: 0.888702  with iter: 43000
I0929 23:38:11.152070 25496 solver.cpp:357] Iteration 48000 (0.946391 iter/s, 105.665s/100 iters), loss = 0.146758
I0929 23:38:11.152200 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.146758 (* 1 = 0.146758 loss)
I0929 23:38:11.152222 25496 sgd_solver.cpp:64] MultiStep Status: Iteration 48000, step = 2
I0929 23:38:11.152241 25496 sgd_solver.cpp:165] Iteration 48000, lr = 0.001
I0929 23:38:36.081663 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:39:10.607043 25496 solver.cpp:357] Iteration 48100 (1.68204 iter/s, 59.4516s/100 iters), loss = 0.0942814
I0929 23:39:10.607180 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0942816 (* 1 = 0.0942816 loss)
I0929 23:39:10.607194 25496 sgd_solver.cpp:165] Iteration 48100, lr = 0.001
I0929 23:40:10.094740 25496 solver.cpp:357] Iteration 48200 (1.6812 iter/s, 59.4815s/100 iters), loss = 0.0409567
I0929 23:40:10.094900 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0409569 (* 1 = 0.0409569 loss)
I0929 23:40:10.094915 25496 sgd_solver.cpp:165] Iteration 48200, lr = 0.001
I0929 23:41:09.899634 25496 solver.cpp:357] Iteration 48300 (1.67227 iter/s, 59.799s/100 iters), loss = 0.0288919
I0929 23:41:09.899773 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0288921 (* 1 = 0.0288921 loss)
I0929 23:41:09.899787 25496 sgd_solver.cpp:165] Iteration 48300, lr = 0.001
I0929 23:42:08.958698 25496 solver.cpp:357] Iteration 48400 (1.69332 iter/s, 59.0556s/100 iters), loss = 0.0594871
I0929 23:42:08.958907 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0594873 (* 1 = 0.0594873 loss)
I0929 23:42:08.958922 25496 sgd_solver.cpp:165] Iteration 48400, lr = 0.001
I0929 23:42:28.796615 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:43:08.518965 25496 solver.cpp:514] Iteration 48500, Testing net (#0)
I0929 23:43:54.917870 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:43:55.124616 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.302032 (* 1 = 0.302032 loss)
I0929 23:43:55.124720 25496 solver.cpp:580]     Test net output #1: prob = 0.912502
I0929 23:43:55.124752 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_48500.caffemodel
I0929 23:43:55.139603 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_48500.solverstate
I0929 23:43:55.143626 25496 solver.cpp:593]     Max_acc: 0.912502  with iter: 48500
I0929 23:43:55.638738 25496 solver.cpp:357] Iteration 48500 (0.937437 iter/s, 106.674s/100 iters), loss = 0.0245602
I0929 23:43:55.638823 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0245604 (* 1 = 0.0245604 loss)
I0929 23:43:55.638835 25496 sgd_solver.cpp:165] Iteration 48500, lr = 0.001
I0929 23:44:55.140566 25496 solver.cpp:357] Iteration 48600 (1.6807 iter/s, 59.4988s/100 iters), loss = 0.0627822
I0929 23:44:55.140802 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0627823 (* 1 = 0.0627823 loss)
I0929 23:44:55.140830 25496 sgd_solver.cpp:165] Iteration 48600, lr = 0.001
I0929 23:45:54.443019 25496 solver.cpp:357] Iteration 48700 (1.68635 iter/s, 59.2996s/100 iters), loss = 0.012155
I0929 23:45:54.443279 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0121552 (* 1 = 0.0121552 loss)
I0929 23:45:54.443323 25496 sgd_solver.cpp:165] Iteration 48700, lr = 0.001
I0929 23:46:54.526000 25496 solver.cpp:357] Iteration 48800 (1.66448 iter/s, 60.079s/100 iters), loss = 0.0228837
I0929 23:46:54.526199 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0228839 (* 1 = 0.0228839 loss)
I0929 23:46:54.526211 25496 sgd_solver.cpp:165] Iteration 48800, lr = 0.001
I0929 23:47:08.837769 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:47:53.922129 25496 solver.cpp:357] Iteration 48900 (1.68363 iter/s, 59.3955s/100 iters), loss = 0.0252416
I0929 23:47:53.922363 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0252418 (* 1 = 0.0252418 loss)
I0929 23:47:53.922395 25496 sgd_solver.cpp:165] Iteration 48900, lr = 0.001
I0929 23:48:52.539834 25496 solver.cpp:514] Iteration 49000, Testing net (#0)
I0929 23:49:39.606309 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:49:39.811884 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.270396 (* 1 = 0.270396 loss)
I0929 23:49:39.811995 25496 solver.cpp:580]     Test net output #1: prob = 0.922302
I0929 23:49:39.812028 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_49000.caffemodel
I0929 23:49:39.828903 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_49000.solverstate
I0929 23:49:39.833279 25496 solver.cpp:593]     Max_acc: 0.922302  with iter: 49000
I0929 23:49:40.316076 25496 solver.cpp:357] Iteration 49000 (0.939929 iter/s, 106.391s/100 iters), loss = 0.0286231
I0929 23:49:40.316169 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0286233 (* 1 = 0.0286233 loss)
I0929 23:49:40.316184 25496 sgd_solver.cpp:165] Iteration 49000, lr = 0.001
I0929 23:50:39.952271 25496 solver.cpp:357] Iteration 49100 (1.67691 iter/s, 59.6334s/100 iters), loss = 0.0138476
I0929 23:50:39.952441 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0138478 (* 1 = 0.0138478 loss)
I0929 23:50:39.952456 25496 sgd_solver.cpp:165] Iteration 49100, lr = 0.001
I0929 23:51:39.631880 25496 solver.cpp:357] Iteration 49200 (1.67574 iter/s, 59.6751s/100 iters), loss = 0.0380725
I0929 23:51:39.632076 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0380727 (* 1 = 0.0380727 loss)
I0929 23:51:39.632104 25496 sgd_solver.cpp:165] Iteration 49200, lr = 0.001
I0929 23:51:48.059660 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:52:38.955024 25496 solver.cpp:357] Iteration 49300 (1.68576 iter/s, 59.3203s/100 iters), loss = 0.064569
I0929 23:52:38.955212 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0645692 (* 1 = 0.0645692 loss)
I0929 23:52:38.955225 25496 sgd_solver.cpp:165] Iteration 49300, lr = 0.001
I0929 23:53:38.663163 25496 solver.cpp:357] Iteration 49400 (1.67494 iter/s, 59.7038s/100 iters), loss = 0.0425982
I0929 23:53:38.663303 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0425984 (* 1 = 0.0425984 loss)
I0929 23:53:38.663317 25496 sgd_solver.cpp:165] Iteration 49400, lr = 0.001
I0929 23:54:37.799881 25496 solver.cpp:514] Iteration 49500, Testing net (#0)
I0929 23:55:24.541766 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:55:24.712252 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.272338 (* 1 = 0.272338 loss)
I0929 23:55:24.712361 25496 solver.cpp:580]     Test net output #1: prob = 0.921102
I0929 23:55:24.712381 25496 solver.cpp:593]     Max_acc: 0.922302  with iter: 49000
I0929 23:55:25.192571 25496 solver.cpp:357] Iteration 49500 (0.938745 iter/s, 106.525s/100 iters), loss = 0.0405256
I0929 23:55:25.192663 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0405258 (* 1 = 0.0405258 loss)
I0929 23:55:25.192677 25496 sgd_solver.cpp:165] Iteration 49500, lr = 0.001
I0929 23:56:24.738831 25496 solver.cpp:357] Iteration 49600 (1.67944 iter/s, 59.5436s/100 iters), loss = 0.0197703
I0929 23:56:24.739001 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0197705 (* 1 = 0.0197705 loss)
I0929 23:56:24.739013 25496 sgd_solver.cpp:165] Iteration 49600, lr = 0.001
I0929 23:56:27.776314 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0929 23:57:24.400076 25496 solver.cpp:357] Iteration 49700 (1.67625 iter/s, 59.657s/100 iters), loss = 0.0268452
I0929 23:57:24.400324 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0268454 (* 1 = 0.0268454 loss)
I0929 23:57:24.400339 25496 sgd_solver.cpp:165] Iteration 49700, lr = 0.001
I0929 23:58:24.419713 25496 solver.cpp:357] Iteration 49800 (1.66618 iter/s, 60.0177s/100 iters), loss = 0.0276655
I0929 23:58:24.419875 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0276656 (* 1 = 0.0276656 loss)
I0929 23:58:24.419889 25496 sgd_solver.cpp:165] Iteration 49800, lr = 0.001
I0929 23:59:24.006877 25496 solver.cpp:357] Iteration 49900 (1.67829 iter/s, 59.5846s/100 iters), loss = 0.0296702
I0929 23:59:24.007134 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0296704 (* 1 = 0.0296704 loss)
I0929 23:59:24.007166 25496 sgd_solver.cpp:165] Iteration 49900, lr = 0.001
I0930 00:00:20.729729 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:00:23.096365 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_50000.caffemodel
I0930 00:00:23.125840 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_50000.solverstate
I0930 00:00:23.132424 25496 solver.cpp:514] Iteration 50000, Testing net (#0)
I0930 00:01:09.706380 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:01:09.907203 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.267659 (* 1 = 0.267659 loss)
I0930 00:01:09.907313 25496 solver.cpp:580]     Test net output #1: prob = 0.924102
I0930 00:01:09.907344 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_50000.caffemodel
I0930 00:01:09.919910 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_50000.solverstate
I0930 00:01:09.925592 25496 solver.cpp:593]     Max_acc: 0.924102  with iter: 50000
I0930 00:01:10.377384 25496 solver.cpp:357] Iteration 50000 (0.940124 iter/s, 106.369s/100 iters), loss = 0.041867
I0930 00:01:10.377477 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0418671 (* 1 = 0.0418671 loss)
I0930 00:01:10.377490 25496 sgd_solver.cpp:165] Iteration 50000, lr = 0.001
I0930 00:02:10.226112 25496 solver.cpp:357] Iteration 50100 (1.67096 iter/s, 59.846s/100 iters), loss = 0.0147975
I0930 00:02:10.226269 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0147977 (* 1 = 0.0147977 loss)
I0930 00:02:10.226284 25496 sgd_solver.cpp:165] Iteration 50100, lr = 0.001
I0930 00:03:10.295469 25496 solver.cpp:357] Iteration 50200 (1.6649 iter/s, 60.0635s/100 iters), loss = 0.0367407
I0930 00:03:10.295735 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0367409 (* 1 = 0.0367409 loss)
I0930 00:03:10.295763 25496 sgd_solver.cpp:165] Iteration 50200, lr = 0.001
I0930 00:04:09.355940 25496 solver.cpp:357] Iteration 50300 (1.69333 iter/s, 59.0554s/100 iters), loss = 0.00921562
I0930 00:04:09.356076 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00921581 (* 1 = 0.00921581 loss)
I0930 00:04:09.356091 25496 sgd_solver.cpp:165] Iteration 50300, lr = 0.001
I0930 00:05:00.911535 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:05:09.103549 25496 solver.cpp:357] Iteration 50400 (1.67389 iter/s, 59.741s/100 iters), loss = 0.106474
I0930 00:05:09.103708 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.106474 (* 1 = 0.106474 loss)
I0930 00:05:09.103760 25496 sgd_solver.cpp:165] Iteration 50400, lr = 0.001
I0930 00:06:08.745237 25496 solver.cpp:514] Iteration 50500, Testing net (#0)
I0930 00:06:54.404413 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:06:54.617796 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.267065 (* 1 = 0.267065 loss)
I0930 00:06:54.617897 25496 solver.cpp:580]     Test net output #1: prob = 0.925002
I0930 00:06:54.617926 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_50500.caffemodel
I0930 00:06:54.634402 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_50500.solverstate
I0930 00:06:54.638366 25496 solver.cpp:593]     Max_acc: 0.925002  with iter: 50500
I0930 00:06:55.107177 25496 solver.cpp:357] Iteration 50500 (0.943417 iter/s, 105.998s/100 iters), loss = 0.0143011
I0930 00:06:55.107254 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0143013 (* 1 = 0.0143013 loss)
I0930 00:06:55.107267 25496 sgd_solver.cpp:165] Iteration 50500, lr = 0.001
I0930 00:07:54.784997 25496 solver.cpp:357] Iteration 50600 (1.67578 iter/s, 59.6737s/100 iters), loss = 0.0194024
I0930 00:07:54.785226 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0194026 (* 1 = 0.0194026 loss)
I0930 00:07:54.785241 25496 sgd_solver.cpp:165] Iteration 50600, lr = 0.001
I0930 00:08:54.094873 25496 solver.cpp:357] Iteration 50700 (1.68618 iter/s, 59.3056s/100 iters), loss = 0.0262009
I0930 00:08:54.095086 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0262011 (* 1 = 0.0262011 loss)
I0930 00:08:54.095118 25496 sgd_solver.cpp:165] Iteration 50700, lr = 0.001
I0930 00:09:40.045395 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:09:53.443011 25496 solver.cpp:357] Iteration 50800 (1.68509 iter/s, 59.344s/100 iters), loss = 0.0150667
I0930 00:09:53.443157 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0150669 (* 1 = 0.0150669 loss)
I0930 00:09:53.443186 25496 sgd_solver.cpp:165] Iteration 50800, lr = 0.001
I0930 00:10:52.671855 25496 solver.cpp:357] Iteration 50900 (1.68847 iter/s, 59.2253s/100 iters), loss = 0.0259672
I0930 00:10:52.671990 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0259674 (* 1 = 0.0259674 loss)
I0930 00:10:52.672004 25496 sgd_solver.cpp:165] Iteration 50900, lr = 0.001
I0930 00:11:51.783365 25496 solver.cpp:514] Iteration 51000, Testing net (#0)
I0930 00:12:38.672595 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:12:38.866308 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.276054 (* 1 = 0.276054 loss)
I0930 00:12:38.866343 25496 solver.cpp:580]     Test net output #1: prob = 0.923802
I0930 00:12:38.866360 25496 solver.cpp:593]     Max_acc: 0.925002  with iter: 50500
I0930 00:12:39.310204 25496 solver.cpp:357] Iteration 51000 (0.937806 iter/s, 106.632s/100 iters), loss = 0.0222803
I0930 00:12:39.310297 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0222805 (* 1 = 0.0222805 loss)
I0930 00:12:39.310310 25496 sgd_solver.cpp:165] Iteration 51000, lr = 0.001
I0930 00:13:38.696132 25496 solver.cpp:357] Iteration 51100 (1.68405 iter/s, 59.3805s/100 iters), loss = 0.0300959
I0930 00:13:38.696264 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0300961 (* 1 = 0.0300961 loss)
I0930 00:13:38.696276 25496 sgd_solver.cpp:165] Iteration 51100, lr = 0.001
I0930 00:14:18.889582 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:14:38.656179 25496 solver.cpp:357] Iteration 51200 (1.66792 iter/s, 59.9547s/100 iters), loss = 0.0343262
I0930 00:14:38.656270 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0343264 (* 1 = 0.0343264 loss)
I0930 00:14:38.656283 25496 sgd_solver.cpp:165] Iteration 51200, lr = 0.001
I0930 00:15:38.059906 25496 solver.cpp:357] Iteration 51300 (1.68349 iter/s, 59.4005s/100 iters), loss = 0.013726
I0930 00:15:38.060072 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0137262 (* 1 = 0.0137262 loss)
I0930 00:15:38.060086 25496 sgd_solver.cpp:165] Iteration 51300, lr = 0.001
I0930 00:16:37.738695 25496 solver.cpp:357] Iteration 51400 (1.67573 iter/s, 59.6755s/100 iters), loss = 0.0186031
I0930 00:16:37.738906 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0186033 (* 1 = 0.0186033 loss)
I0930 00:16:37.738936 25496 sgd_solver.cpp:165] Iteration 51400, lr = 0.001
I0930 00:17:36.714593 25496 solver.cpp:514] Iteration 51500, Testing net (#0)
I0930 00:18:22.280220 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:18:22.473492 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.275928 (* 1 = 0.275928 loss)
I0930 00:18:22.473657 25496 solver.cpp:580]     Test net output #1: prob = 0.925302
I0930 00:18:22.473704 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_51500.caffemodel
I0930 00:18:22.490974 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_51500.solverstate
I0930 00:18:22.495456 25496 solver.cpp:593]     Max_acc: 0.925302  with iter: 51500
I0930 00:18:22.968210 25496 solver.cpp:357] Iteration 51500 (0.950345 iter/s, 105.225s/100 iters), loss = 0.0151488
I0930 00:18:22.968350 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.015149 (* 1 = 0.015149 loss)
I0930 00:18:22.968377 25496 sgd_solver.cpp:165] Iteration 51500, lr = 0.001
I0930 00:18:57.753815 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:19:22.233642 25496 solver.cpp:357] Iteration 51600 (1.68745 iter/s, 59.2611s/100 iters), loss = 0.0154647
I0930 00:19:22.233731 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0154649 (* 1 = 0.0154649 loss)
I0930 00:19:22.233743 25496 sgd_solver.cpp:165] Iteration 51600, lr = 0.001
I0930 00:20:21.905757 25496 solver.cpp:357] Iteration 51700 (1.67592 iter/s, 59.6686s/100 iters), loss = 0.0167748
I0930 00:20:21.905905 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.016775 (* 1 = 0.016775 loss)
I0930 00:20:21.905918 25496 sgd_solver.cpp:165] Iteration 51700, lr = 0.001
I0930 00:21:21.700839 25496 solver.cpp:357] Iteration 51800 (1.67247 iter/s, 59.7917s/100 iters), loss = 0.0516549
I0930 00:21:21.700975 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.051655 (* 1 = 0.051655 loss)
I0930 00:21:21.700989 25496 sgd_solver.cpp:165] Iteration 51800, lr = 0.001
I0930 00:22:21.546684 25496 solver.cpp:357] Iteration 51900 (1.67103 iter/s, 59.8432s/100 iters), loss = 0.0303528
I0930 00:22:21.546874 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.030353 (* 1 = 0.030353 loss)
I0930 00:22:21.546901 25496 sgd_solver.cpp:165] Iteration 51900, lr = 0.001
I0930 00:22:50.684337 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:23:20.631448 25496 solver.cpp:514] Iteration 52000, Testing net (#0)
I0930 00:24:06.738777 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:24:06.950654 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.283113 (* 1 = 0.283113 loss)
I0930 00:24:06.950803 25496 solver.cpp:580]     Test net output #1: prob = 0.924802
I0930 00:24:06.950839 25496 solver.cpp:593]     Max_acc: 0.925302  with iter: 51500
I0930 00:24:07.408162 25496 solver.cpp:357] Iteration 52000 (0.944656 iter/s, 105.859s/100 iters), loss = 0.010611
I0930 00:24:07.408241 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0106112 (* 1 = 0.0106112 loss)
I0930 00:24:07.408254 25496 sgd_solver.cpp:165] Iteration 52000, lr = 0.001
I0930 00:25:06.188810 25496 solver.cpp:357] Iteration 52100 (1.70138 iter/s, 58.7759s/100 iters), loss = 0.0394564
I0930 00:25:06.190893 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0394565 (* 1 = 0.0394565 loss)
I0930 00:25:06.190955 25496 sgd_solver.cpp:165] Iteration 52100, lr = 0.001
I0930 00:26:05.738365 25496 solver.cpp:357] Iteration 52200 (1.67941 iter/s, 59.5448s/100 iters), loss = 0.0109644
I0930 00:26:05.738538 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0109646 (* 1 = 0.0109646 loss)
I0930 00:26:05.738551 25496 sgd_solver.cpp:165] Iteration 52200, lr = 0.001
I0930 00:27:05.911865 25496 solver.cpp:357] Iteration 52300 (1.66193 iter/s, 60.1709s/100 iters), loss = 0.0159639
I0930 00:27:05.912053 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0159641 (* 1 = 0.0159641 loss)
I0930 00:27:05.912081 25496 sgd_solver.cpp:165] Iteration 52300, lr = 0.001
I0930 00:27:29.093999 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:28:05.756961 25496 solver.cpp:357] Iteration 52400 (1.67105 iter/s, 59.8427s/100 iters), loss = 0.0262521
I0930 00:28:05.757417 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0262523 (* 1 = 0.0262523 loss)
I0930 00:28:05.757489 25496 sgd_solver.cpp:165] Iteration 52400, lr = 0.001
I0930 00:29:04.298460 25496 solver.cpp:514] Iteration 52500, Testing net (#0)
I0930 00:29:51.692062 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:29:51.882897 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.278223 (* 1 = 0.278223 loss)
I0930 00:29:51.882937 25496 solver.cpp:580]     Test net output #1: prob = 0.924202
I0930 00:29:51.882949 25496 solver.cpp:593]     Max_acc: 0.925302  with iter: 51500
I0930 00:29:52.365677 25496 solver.cpp:357] Iteration 52500 (0.938032 iter/s, 106.606s/100 iters), loss = 0.0320164
I0930 00:29:52.365764 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0320165 (* 1 = 0.0320165 loss)
I0930 00:29:52.365777 25496 sgd_solver.cpp:165] Iteration 52500, lr = 0.001
I0930 00:30:51.953071 25496 solver.cpp:357] Iteration 52600 (1.67834 iter/s, 59.5827s/100 iters), loss = 0.0186976
I0930 00:30:51.953202 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0186978 (* 1 = 0.0186978 loss)
I0930 00:30:51.953217 25496 sgd_solver.cpp:165] Iteration 52600, lr = 0.001
I0930 00:31:52.272402 25496 solver.cpp:357] Iteration 52700 (1.65792 iter/s, 60.3167s/100 iters), loss = 0.031374
I0930 00:31:52.272754 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0313742 (* 1 = 0.0313742 loss)
I0930 00:31:52.272827 25496 sgd_solver.cpp:165] Iteration 52700, lr = 0.001
I0930 00:32:10.542838 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:32:52.315165 25496 solver.cpp:357] Iteration 52800 (1.66561 iter/s, 60.0381s/100 iters), loss = 0.00952837
I0930 00:32:52.315376 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00952853 (* 1 = 0.00952853 loss)
I0930 00:32:52.315403 25496 sgd_solver.cpp:165] Iteration 52800, lr = 0.001
I0930 00:33:52.164988 25496 solver.cpp:357] Iteration 52900 (1.67092 iter/s, 59.8472s/100 iters), loss = 0.010034
I0930 00:33:52.166898 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0100342 (* 1 = 0.0100342 loss)
I0930 00:33:52.166925 25496 sgd_solver.cpp:165] Iteration 52900, lr = 0.001
I0930 00:34:51.574427 25496 solver.cpp:514] Iteration 53000, Testing net (#0)
I0930 00:35:38.599191 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:35:38.741379 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.284882 (* 1 = 0.284882 loss)
I0930 00:35:38.741425 25496 solver.cpp:580]     Test net output #1: prob = 0.923402
I0930 00:35:38.741431 25496 solver.cpp:593]     Max_acc: 0.925302  with iter: 51500
I0930 00:35:39.235806 25496 solver.cpp:357] Iteration 53000 (0.933984 iter/s, 107.068s/100 iters), loss = 0.0104081
I0930 00:35:39.235893 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0104083 (* 1 = 0.0104083 loss)
I0930 00:35:39.235905 25496 sgd_solver.cpp:165] Iteration 53000, lr = 0.001
I0930 00:36:38.950954 25496 solver.cpp:357] Iteration 53100 (1.67457 iter/s, 59.7167s/100 iters), loss = 0.013357
I0930 00:36:38.951179 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0133571 (* 1 = 0.0133571 loss)
I0930 00:36:38.951210 25496 sgd_solver.cpp:165] Iteration 53100, lr = 0.001
I0930 00:36:50.935535 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:37:38.640525 25496 solver.cpp:357] Iteration 53200 (1.67503 iter/s, 59.7004s/100 iters), loss = 0.0476448
I0930 00:37:38.640676 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0476449 (* 1 = 0.0476449 loss)
I0930 00:37:38.640691 25496 sgd_solver.cpp:165] Iteration 53200, lr = 0.001
I0930 00:38:38.587046 25496 solver.cpp:357] Iteration 53300 (1.66791 iter/s, 59.9551s/100 iters), loss = 0.00524952
I0930 00:38:38.587290 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00524967 (* 1 = 0.00524967 loss)
I0930 00:38:38.587334 25496 sgd_solver.cpp:165] Iteration 53300, lr = 0.001
I0930 00:39:38.369393 25496 solver.cpp:357] Iteration 53400 (1.67252 iter/s, 59.79s/100 iters), loss = 0.0107455
I0930 00:39:38.371085 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0107457 (* 1 = 0.0107457 loss)
I0930 00:39:38.371140 25496 sgd_solver.cpp:165] Iteration 53400, lr = 0.001
I0930 00:40:36.495820 25496 solver.cpp:514] Iteration 53500, Testing net (#0)
I0930 00:41:23.314904 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:41:23.500579 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.282163 (* 1 = 0.282163 loss)
I0930 00:41:23.500720 25496 solver.cpp:580]     Test net output #1: prob = 0.926202
I0930 00:41:23.500766 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_53500.caffemodel
I0930 00:41:23.517426 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_53500.solverstate
I0930 00:41:23.521718 25496 solver.cpp:593]     Max_acc: 0.926202  with iter: 53500
I0930 00:41:23.964406 25496 solver.cpp:357] Iteration 53500 (0.946889 iter/s, 105.609s/100 iters), loss = 0.0212854
I0930 00:41:23.964502 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0212855 (* 1 = 0.0212855 loss)
I0930 00:41:23.964516 25496 sgd_solver.cpp:165] Iteration 53500, lr = 0.001
I0930 00:41:30.767129 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:42:24.145382 25496 solver.cpp:357] Iteration 53600 (1.66156 iter/s, 60.1844s/100 iters), loss = 0.0196056
I0930 00:42:24.145596 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0196058 (* 1 = 0.0196058 loss)
I0930 00:42:24.145622 25496 sgd_solver.cpp:165] Iteration 53600, lr = 0.001
I0930 00:43:23.358285 25496 solver.cpp:357] Iteration 53700 (1.6887 iter/s, 59.2172s/100 iters), loss = 0.0302116
I0930 00:43:23.358485 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0302117 (* 1 = 0.0302117 loss)
I0930 00:43:23.358515 25496 sgd_solver.cpp:165] Iteration 53700, lr = 0.001
I0930 00:44:23.140177 25496 solver.cpp:357] Iteration 53800 (1.67263 iter/s, 59.7861s/100 iters), loss = 0.0181936
I0930 00:44:23.140311 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0181937 (* 1 = 0.0181937 loss)
I0930 00:44:23.140326 25496 sgd_solver.cpp:165] Iteration 53800, lr = 0.001
I0930 00:45:22.324043 25496 solver.cpp:357] Iteration 53900 (1.6895 iter/s, 59.1891s/100 iters), loss = 0.0306986
I0930 00:45:22.324254 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0306988 (* 1 = 0.0306988 loss)
I0930 00:45:22.324282 25496 sgd_solver.cpp:165] Iteration 53900, lr = 0.001
I0930 00:45:23.665187 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:46:21.460469 25496 solver.cpp:514] Iteration 54000, Testing net (#0)
I0930 00:47:07.268489 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:47:07.464272 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.284544 (* 1 = 0.284544 loss)
I0930 00:47:07.464373 25496 solver.cpp:580]     Test net output #1: prob = 0.926502
I0930 00:47:07.464404 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_54000.caffemodel
I0930 00:47:07.481842 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_54000.solverstate
I0930 00:47:07.485908 25496 solver.cpp:593]     Max_acc: 0.926502  with iter: 54000
I0930 00:47:07.945709 25496 solver.cpp:357] Iteration 54000 (0.946712 iter/s, 105.629s/100 iters), loss = 0.030524
I0930 00:47:07.945865 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0305242 (* 1 = 0.0305242 loss)
I0930 00:47:07.945915 25496 sgd_solver.cpp:165] Iteration 54000, lr = 0.001
I0930 00:48:07.603232 25496 solver.cpp:357] Iteration 54100 (1.67623 iter/s, 59.6578s/100 iters), loss = 0.0128888
I0930 00:48:07.603410 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0128889 (* 1 = 0.0128889 loss)
I0930 00:48:07.603435 25496 sgd_solver.cpp:165] Iteration 54100, lr = 0.001
I0930 00:49:07.019482 25496 solver.cpp:357] Iteration 54200 (1.68296 iter/s, 59.4192s/100 iters), loss = 0.00744952
I0930 00:49:07.019712 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00744968 (* 1 = 0.00744968 loss)
I0930 00:49:07.019726 25496 sgd_solver.cpp:165] Iteration 54200, lr = 0.001
I0930 00:50:01.919922 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:50:06.561501 25496 solver.cpp:357] Iteration 54300 (1.6795 iter/s, 59.5415s/100 iters), loss = 0.0269717
I0930 00:50:06.561591 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0269719 (* 1 = 0.0269719 loss)
I0930 00:50:06.561605 25496 sgd_solver.cpp:165] Iteration 54300, lr = 0.001
I0930 00:51:05.534596 25496 solver.cpp:357] Iteration 54400 (1.69571 iter/s, 58.9723s/100 iters), loss = 0.0144595
I0930 00:51:05.534752 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0144596 (* 1 = 0.0144596 loss)
I0930 00:51:05.534765 25496 sgd_solver.cpp:165] Iteration 54400, lr = 0.001
I0930 00:52:04.772104 25496 solver.cpp:514] Iteration 54500, Testing net (#0)
I0930 00:52:52.226748 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:52:52.396926 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.283435 (* 1 = 0.283435 loss)
I0930 00:52:52.397038 25496 solver.cpp:580]     Test net output #1: prob = 0.925302
I0930 00:52:52.397059 25496 solver.cpp:593]     Max_acc: 0.926502  with iter: 54000
I0930 00:52:52.876852 25496 solver.cpp:357] Iteration 54500 (0.931585 iter/s, 107.344s/100 iters), loss = 0.0327565
I0930 00:52:52.877005 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0327567 (* 1 = 0.0327567 loss)
I0930 00:52:52.877029 25496 sgd_solver.cpp:165] Iteration 54500, lr = 0.001
I0930 00:53:52.922286 25496 solver.cpp:357] Iteration 54600 (1.66538 iter/s, 60.0464s/100 iters), loss = 0.00306624
I0930 00:53:52.922479 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0030664 (* 1 = 0.0030664 loss)
I0930 00:53:52.922507 25496 sgd_solver.cpp:165] Iteration 54600, lr = 0.001
I0930 00:54:42.518096 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:54:52.356192 25496 solver.cpp:357] Iteration 54700 (1.68256 iter/s, 59.4333s/100 iters), loss = 0.00757661
I0930 00:54:52.356287 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00757677 (* 1 = 0.00757677 loss)
I0930 00:54:52.356302 25496 sgd_solver.cpp:165] Iteration 54700, lr = 0.001
I0930 00:55:51.958279 25496 solver.cpp:357] Iteration 54800 (1.67779 iter/s, 59.6024s/100 iters), loss = 0.00696843
I0930 00:55:51.958413 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00696859 (* 1 = 0.00696859 loss)
I0930 00:55:51.958426 25496 sgd_solver.cpp:165] Iteration 54800, lr = 0.001
I0930 00:56:51.327634 25496 solver.cpp:357] Iteration 54900 (1.68442 iter/s, 59.3675s/100 iters), loss = 0.0213728
I0930 00:56:51.327818 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.021373 (* 1 = 0.021373 loss)
I0930 00:56:51.327845 25496 sgd_solver.cpp:165] Iteration 54900, lr = 0.001
I0930 00:57:50.702148 25496 solver.cpp:514] Iteration 55000, Testing net (#0)
I0930 00:58:36.566052 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:58:36.747609 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.285245 (* 1 = 0.285245 loss)
I0930 00:58:36.747716 25496 solver.cpp:580]     Test net output #1: prob = 0.926402
I0930 00:58:36.747737 25496 solver.cpp:593]     Max_acc: 0.926502  with iter: 54000
I0930 00:58:37.221263 25496 solver.cpp:357] Iteration 55000 (0.944329 iter/s, 105.895s/100 iters), loss = 0.00864091
I0930 00:58:37.221426 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00864106 (* 1 = 0.00864106 loss)
I0930 00:58:37.221477 25496 sgd_solver.cpp:165] Iteration 55000, lr = 0.001
I0930 00:59:21.678913 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 00:59:37.297071 25496 solver.cpp:357] Iteration 55100 (1.66462 iter/s, 60.0737s/100 iters), loss = 0.0267655
I0930 00:59:37.297235 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0267656 (* 1 = 0.0267656 loss)
I0930 00:59:37.297261 25496 sgd_solver.cpp:165] Iteration 55100, lr = 0.001
I0930 01:00:37.177211 25496 solver.cpp:357] Iteration 55200 (1.67004 iter/s, 59.8787s/100 iters), loss = 0.025305
I0930 01:00:37.177495 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0253052 (* 1 = 0.0253052 loss)
I0930 01:00:37.177515 25496 sgd_solver.cpp:165] Iteration 55200, lr = 0.001
I0930 01:01:36.352780 25496 solver.cpp:357] Iteration 55300 (1.68995 iter/s, 59.1732s/100 iters), loss = 0.0127009
I0930 01:01:36.353061 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0127011 (* 1 = 0.0127011 loss)
I0930 01:01:36.353091 25496 sgd_solver.cpp:165] Iteration 55300, lr = 0.001
I0930 01:02:36.052081 25496 solver.cpp:357] Iteration 55400 (1.67513 iter/s, 59.6969s/100 iters), loss = 0.0105095
I0930 01:02:36.052438 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0105097 (* 1 = 0.0105097 loss)
I0930 01:02:36.052515 25496 sgd_solver.cpp:165] Iteration 55400, lr = 0.001
I0930 01:03:13.967660 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:03:34.921471 25496 solver.cpp:514] Iteration 55500, Testing net (#0)
I0930 01:04:21.563403 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:04:21.758245 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.293602 (* 1 = 0.293602 loss)
I0930 01:04:21.758342 25496 solver.cpp:580]     Test net output #1: prob = 0.924402
I0930 01:04:21.758363 25496 solver.cpp:593]     Max_acc: 0.926502  with iter: 54000
I0930 01:04:22.234143 25496 solver.cpp:357] Iteration 55500 (0.941776 iter/s, 106.182s/100 iters), loss = 0.0237034
I0930 01:04:22.234344 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0237036 (* 1 = 0.0237036 loss)
I0930 01:04:22.234390 25496 sgd_solver.cpp:165] Iteration 55500, lr = 0.001
I0930 01:05:21.647711 25496 solver.cpp:357] Iteration 55600 (1.68315 iter/s, 59.4126s/100 iters), loss = 0.018859
I0930 01:05:21.649431 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0188592 (* 1 = 0.0188592 loss)
I0930 01:05:21.649737 25496 sgd_solver.cpp:165] Iteration 55600, lr = 0.001
I0930 01:06:21.204193 25496 solver.cpp:357] Iteration 55700 (1.67915 iter/s, 59.5539s/100 iters), loss = 0.0276679
I0930 01:06:21.204327 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0276681 (* 1 = 0.0276681 loss)
I0930 01:06:21.204341 25496 sgd_solver.cpp:165] Iteration 55700, lr = 0.001
I0930 01:07:20.504873 25496 solver.cpp:357] Iteration 55800 (1.6864 iter/s, 59.298s/100 iters), loss = 0.00644802
I0930 01:07:20.505357 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00644818 (* 1 = 0.00644818 loss)
I0930 01:07:20.505388 25496 sgd_solver.cpp:165] Iteration 55800, lr = 0.001
I0930 01:07:53.246482 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:08:20.023399 25496 solver.cpp:357] Iteration 55900 (1.6802 iter/s, 59.5168s/100 iters), loss = 0.057293
I0930 01:08:20.023488 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0572932 (* 1 = 0.0572932 loss)
I0930 01:08:20.023501 25496 sgd_solver.cpp:165] Iteration 55900, lr = 0.001
I0930 01:09:18.803758 25496 solver.cpp:514] Iteration 56000, Testing net (#0)
I0930 01:10:05.510763 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:10:05.728679 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.290657 (* 1 = 0.290657 loss)
I0930 01:10:05.728785 25496 solver.cpp:580]     Test net output #1: prob = 0.924802
I0930 01:10:05.728806 25496 solver.cpp:593]     Max_acc: 0.926502  with iter: 54000
I0930 01:10:06.211215 25496 solver.cpp:357] Iteration 56000 (0.94174 iter/s, 106.186s/100 iters), loss = 0.00907297
I0930 01:10:06.211385 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00907314 (* 1 = 0.00907314 loss)
I0930 01:10:06.211400 25496 sgd_solver.cpp:165] Iteration 56000, lr = 0.001
I0930 01:11:06.091049 25496 solver.cpp:357] Iteration 56100 (1.67023 iter/s, 59.8721s/100 iters), loss = 0.0412277
I0930 01:11:06.091214 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0412278 (* 1 = 0.0412278 loss)
I0930 01:11:06.091228 25496 sgd_solver.cpp:165] Iteration 56100, lr = 0.001
I0930 01:12:05.958245 25496 solver.cpp:357] Iteration 56200 (1.67061 iter/s, 59.8582s/100 iters), loss = 0.0298167
I0930 01:12:05.958457 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0298168 (* 1 = 0.0298168 loss)
I0930 01:12:05.958472 25496 sgd_solver.cpp:165] Iteration 56200, lr = 0.001
I0930 01:12:33.284754 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:13:05.594280 25496 solver.cpp:357] Iteration 56300 (1.67713 iter/s, 59.6258s/100 iters), loss = 0.0247006
I0930 01:13:05.594430 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0247007 (* 1 = 0.0247007 loss)
I0930 01:13:05.594444 25496 sgd_solver.cpp:165] Iteration 56300, lr = 0.001
I0930 01:14:04.574990 25496 solver.cpp:357] Iteration 56400 (1.69572 iter/s, 58.9719s/100 iters), loss = 0.0190431
I0930 01:14:04.575206 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0190433 (* 1 = 0.0190433 loss)
I0930 01:14:04.575238 25496 sgd_solver.cpp:165] Iteration 56400, lr = 0.001
I0930 01:15:04.018645 25496 solver.cpp:514] Iteration 56500, Testing net (#0)
I0930 01:15:50.590713 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:15:50.776499 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.298885 (* 1 = 0.298885 loss)
I0930 01:15:50.776538 25496 solver.cpp:580]     Test net output #1: prob = 0.924302
I0930 01:15:50.776546 25496 solver.cpp:593]     Max_acc: 0.926502  with iter: 54000
I0930 01:15:51.219290 25496 solver.cpp:357] Iteration 56500 (0.937805 iter/s, 106.632s/100 iters), loss = 0.00730579
I0930 01:15:51.219370 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00730595 (* 1 = 0.00730595 loss)
I0930 01:15:51.219383 25496 sgd_solver.cpp:165] Iteration 56500, lr = 0.001
I0930 01:16:39.115849 25496 solver.cpp:357] Iteration 56600 (2.08816 iter/s, 47.8891s/100 iters), loss = 0.0097135
I0930 01:16:39.116032 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00971367 (* 1 = 0.00971367 loss)
I0930 01:16:39.116046 25496 sgd_solver.cpp:165] Iteration 56600, lr = 0.001
I0930 01:16:54.405688 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:17:21.324323 25496 solver.cpp:357] Iteration 56700 (2.36945 iter/s, 42.2038s/100 iters), loss = 0.0127059
I0930 01:17:21.324512 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0127061 (* 1 = 0.0127061 loss)
I0930 01:17:21.324525 25496 sgd_solver.cpp:165] Iteration 56700, lr = 0.001
I0930 01:18:03.288040 25496 solver.cpp:357] Iteration 56800 (2.38326 iter/s, 41.9593s/100 iters), loss = 0.0272057
I0930 01:18:03.288169 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0272058 (* 1 = 0.0272058 loss)
I0930 01:18:03.288182 25496 sgd_solver.cpp:165] Iteration 56800, lr = 0.001
I0930 01:18:45.385941 25496 solver.cpp:357] Iteration 56900 (2.37566 iter/s, 42.0936s/100 iters), loss = 0.0193646
I0930 01:18:45.386082 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0193647 (* 1 = 0.0193647 loss)
I0930 01:18:45.386095 25496 sgd_solver.cpp:165] Iteration 56900, lr = 0.001
I0930 01:19:27.502701 25496 solver.cpp:514] Iteration 57000, Testing net (#0)
I0930 01:19:55.607374 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:19:55.652412 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.295165 (* 1 = 0.295165 loss)
I0930 01:19:55.652452 25496 solver.cpp:580]     Test net output #1: prob = 0.925602
I0930 01:19:55.652458 25496 solver.cpp:593]     Max_acc: 0.926502  with iter: 54000
I0930 01:19:56.011440 25496 solver.cpp:357] Iteration 57000 (1.41598 iter/s, 70.6222s/100 iters), loss = 0.0131176
I0930 01:19:56.011502 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0131178 (* 1 = 0.0131178 loss)
I0930 01:19:56.011513 25496 sgd_solver.cpp:165] Iteration 57000, lr = 0.001
I0930 01:20:07.404641 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:20:38.431829 25496 solver.cpp:357] Iteration 57100 (2.35757 iter/s, 42.4165s/100 iters), loss = 0.0112267
I0930 01:20:38.431996 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0112269 (* 1 = 0.0112269 loss)
I0930 01:20:38.432008 25496 sgd_solver.cpp:165] Iteration 57100, lr = 0.001
I0930 01:21:20.504225 25496 solver.cpp:357] Iteration 57200 (2.37707 iter/s, 42.0687s/100 iters), loss = 0.0288756
I0930 01:21:20.504503 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0288757 (* 1 = 0.0288757 loss)
I0930 01:21:20.504516 25496 sgd_solver.cpp:165] Iteration 57200, lr = 0.001
I0930 01:22:02.443691 25496 solver.cpp:357] Iteration 57300 (2.38459 iter/s, 41.9359s/100 iters), loss = 0.0099365
I0930 01:22:02.443845 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00993667 (* 1 = 0.00993667 loss)
I0930 01:22:02.443858 25496 sgd_solver.cpp:165] Iteration 57300, lr = 0.001
I0930 01:22:44.737061 25496 solver.cpp:357] Iteration 57400 (2.36463 iter/s, 42.2899s/100 iters), loss = 0.016851
I0930 01:22:44.737244 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0168511 (* 1 = 0.0168511 loss)
I0930 01:22:44.737257 25496 sgd_solver.cpp:165] Iteration 57400, lr = 0.001
I0930 01:22:52.134495 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:23:26.792300 25496 solver.cpp:514] Iteration 57500, Testing net (#0)
I0930 01:23:54.857347 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:23:54.900198 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.287986 (* 1 = 0.287986 loss)
I0930 01:23:54.900238 25496 solver.cpp:580]     Test net output #1: prob = 0.927302
I0930 01:23:54.900251 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_57500.caffemodel
I0930 01:23:54.913761 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_57500.solverstate
I0930 01:23:54.918093 25496 solver.cpp:593]     Max_acc: 0.927302  with iter: 57500
I0930 01:23:55.291177 25496 solver.cpp:357] Iteration 57500 (1.41743 iter/s, 70.55s/100 iters), loss = 0.0140868
I0930 01:23:55.291227 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.014087 (* 1 = 0.014087 loss)
I0930 01:23:55.291240 25496 sgd_solver.cpp:165] Iteration 57500, lr = 0.001
I0930 01:24:37.149775 25496 solver.cpp:357] Iteration 57600 (2.38918 iter/s, 41.8553s/100 iters), loss = 0.00942271
I0930 01:24:37.149947 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00942288 (* 1 = 0.00942288 loss)
I0930 01:24:37.149961 25496 sgd_solver.cpp:165] Iteration 57600, lr = 0.001
I0930 01:25:19.145172 25496 solver.cpp:357] Iteration 57700 (2.38139 iter/s, 41.9922s/100 iters), loss = 0.00698484
I0930 01:25:19.145351 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00698501 (* 1 = 0.00698501 loss)
I0930 01:25:19.145365 25496 sgd_solver.cpp:165] Iteration 57700, lr = 0.001
I0930 01:26:01.677661 25496 solver.cpp:357] Iteration 57800 (2.35131 iter/s, 42.5294s/100 iters), loss = 0.00782808
I0930 01:26:01.677830 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00782825 (* 1 = 0.00782825 loss)
I0930 01:26:01.677845 25496 sgd_solver.cpp:165] Iteration 57800, lr = 0.001
I0930 01:26:05.183439 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:26:43.639915 25496 solver.cpp:357] Iteration 57900 (2.38326 iter/s, 41.9593s/100 iters), loss = 0.00579313
I0930 01:26:43.640282 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0057933 (* 1 = 0.0057933 loss)
I0930 01:26:43.640352 25496 sgd_solver.cpp:165] Iteration 57900, lr = 0.001
I0930 01:27:25.018940 25496 solver.cpp:514] Iteration 58000, Testing net (#0)
I0930 01:27:52.680253 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:27:52.815148 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.29263 (* 1 = 0.29263 loss)
I0930 01:27:52.815202 25496 solver.cpp:580]     Test net output #1: prob = 0.927302
I0930 01:27:52.815208 25496 solver.cpp:593]     Max_acc: 0.927302  with iter: 57500
I0930 01:27:53.145256 25496 solver.cpp:357] Iteration 58000 (1.43881 iter/s, 69.5019s/100 iters), loss = 0.00825677
I0930 01:27:53.145340 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00825694 (* 1 = 0.00825694 loss)
I0930 01:27:53.145352 25496 sgd_solver.cpp:165] Iteration 58000, lr = 0.001
I0930 01:28:35.257480 25496 solver.cpp:357] Iteration 58100 (2.37477 iter/s, 42.1094s/100 iters), loss = 0.0157503
I0930 01:28:35.257755 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0157505 (* 1 = 0.0157505 loss)
I0930 01:28:35.257768 25496 sgd_solver.cpp:165] Iteration 58100, lr = 0.001
I0930 01:29:17.183558 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:29:17.509107 25496 solver.cpp:357] Iteration 58200 (2.36693 iter/s, 42.2488s/100 iters), loss = 0.0303371
I0930 01:29:17.509184 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0303373 (* 1 = 0.0303373 loss)
I0930 01:29:17.509196 25496 sgd_solver.cpp:165] Iteration 58200, lr = 0.001
I0930 01:29:59.505009 25496 solver.cpp:357] Iteration 58300 (2.38134 iter/s, 41.9932s/100 iters), loss = 0.0244988
I0930 01:29:59.505136 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.024499 (* 1 = 0.024499 loss)
I0930 01:29:59.505147 25496 sgd_solver.cpp:165] Iteration 58300, lr = 0.001
I0930 01:30:41.580018 25496 solver.cpp:357] Iteration 58400 (2.37686 iter/s, 42.0723s/100 iters), loss = 0.0097038
I0930 01:30:41.580219 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00970397 (* 1 = 0.00970397 loss)
I0930 01:30:41.580233 25496 sgd_solver.cpp:165] Iteration 58400, lr = 0.001
I0930 01:31:23.283689 25496 solver.cpp:514] Iteration 58500, Testing net (#0)
I0930 01:31:51.173733 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:31:51.303972 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.304145 (* 1 = 0.304145 loss)
I0930 01:31:51.304000 25496 solver.cpp:580]     Test net output #1: prob = 0.923902
I0930 01:31:51.304008 25496 solver.cpp:593]     Max_acc: 0.927302  with iter: 57500
I0930 01:31:51.668004 25496 solver.cpp:357] Iteration 58500 (1.42684 iter/s, 70.0851s/100 iters), loss = 0.00484576
I0930 01:31:51.668078 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00484593 (* 1 = 0.00484593 loss)
I0930 01:31:51.668090 25496 sgd_solver.cpp:165] Iteration 58500, lr = 0.001
I0930 01:32:29.348026 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:32:33.919601 25496 solver.cpp:357] Iteration 58600 (2.3668 iter/s, 42.2511s/100 iters), loss = 0.0174404
I0930 01:32:33.919687 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0174406 (* 1 = 0.0174406 loss)
I0930 01:32:33.919700 25496 sgd_solver.cpp:165] Iteration 58600, lr = 0.001
I0930 01:33:15.926937 25496 solver.cpp:357] Iteration 58700 (2.38068 iter/s, 42.0048s/100 iters), loss = 0.00728205
I0930 01:33:15.927119 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00728222 (* 1 = 0.00728222 loss)
I0930 01:33:15.927131 25496 sgd_solver.cpp:165] Iteration 58700, lr = 0.001
I0930 01:33:58.236407 25496 solver.cpp:357] Iteration 58800 (2.36368 iter/s, 42.3069s/100 iters), loss = 0.0156403
I0930 01:33:58.236596 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0156405 (* 1 = 0.0156405 loss)
I0930 01:33:58.236609 25496 sgd_solver.cpp:165] Iteration 58800, lr = 0.001
I0930 01:34:40.177958 25496 solver.cpp:357] Iteration 58900 (2.38441 iter/s, 41.939s/100 iters), loss = 0.0138312
I0930 01:34:40.178138 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0138314 (* 1 = 0.0138314 loss)
I0930 01:34:40.178151 25496 sgd_solver.cpp:165] Iteration 58900, lr = 0.001
I0930 01:35:13.943878 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:35:21.922389 25496 solver.cpp:514] Iteration 59000, Testing net (#0)
I0930 01:35:49.738925 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:35:49.874106 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.300899 (* 1 = 0.300899 loss)
I0930 01:35:49.874131 25496 solver.cpp:580]     Test net output #1: prob = 0.925703
I0930 01:35:49.874138 25496 solver.cpp:593]     Max_acc: 0.927302  with iter: 57500
I0930 01:35:50.236577 25496 solver.cpp:357] Iteration 59000 (1.42743 iter/s, 70.056s/100 iters), loss = 0.00817386
I0930 01:35:50.236650 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00817403 (* 1 = 0.00817403 loss)
I0930 01:35:50.236661 25496 sgd_solver.cpp:165] Iteration 59000, lr = 0.001
I0930 01:36:31.944844 25496 solver.cpp:357] Iteration 59100 (2.39762 iter/s, 41.7079s/100 iters), loss = 0.0155072
I0930 01:36:31.945094 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0155074 (* 1 = 0.0155074 loss)
I0930 01:36:31.945106 25496 sgd_solver.cpp:165] Iteration 59100, lr = 0.001
I0930 01:37:14.313182 25496 solver.cpp:357] Iteration 59200 (2.36039 iter/s, 42.3659s/100 iters), loss = 0.0105614
I0930 01:37:14.313345 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0105616 (* 1 = 0.0105616 loss)
I0930 01:37:14.313357 25496 sgd_solver.cpp:165] Iteration 59200, lr = 0.001
I0930 01:37:56.288837 25496 solver.cpp:357] Iteration 59300 (2.38235 iter/s, 41.9753s/100 iters), loss = 0.0070726
I0930 01:37:56.289029 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00707277 (* 1 = 0.00707277 loss)
I0930 01:37:56.289042 25496 sgd_solver.cpp:165] Iteration 59300, lr = 0.001
I0930 01:38:25.574100 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:38:38.230317 25496 solver.cpp:357] Iteration 59400 (2.38441 iter/s, 41.9391s/100 iters), loss = 0.0488118
I0930 01:38:38.230515 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.048812 (* 1 = 0.048812 loss)
I0930 01:38:38.230526 25496 sgd_solver.cpp:165] Iteration 59400, lr = 0.001
I0930 01:39:20.002298 25496 solver.cpp:514] Iteration 59500, Testing net (#0)
I0930 01:39:48.046730 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:39:48.093760 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.29356 (* 1 = 0.29356 loss)
I0930 01:39:48.093801 25496 solver.cpp:580]     Test net output #1: prob = 0.926102
I0930 01:39:48.093808 25496 solver.cpp:593]     Max_acc: 0.927302  with iter: 57500
I0930 01:39:48.457626 25496 solver.cpp:357] Iteration 59500 (1.424 iter/s, 70.2248s/100 iters), loss = 0.0048914
I0930 01:39:48.457690 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00489158 (* 1 = 0.00489158 loss)
I0930 01:39:48.457702 25496 sgd_solver.cpp:165] Iteration 59500, lr = 0.001
I0930 01:40:30.561535 25496 solver.cpp:357] Iteration 59600 (2.37521 iter/s, 42.1016s/100 iters), loss = 0.0173429
I0930 01:40:30.561718 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0173431 (* 1 = 0.0173431 loss)
I0930 01:40:30.561731 25496 sgd_solver.cpp:165] Iteration 59600, lr = 0.001
I0930 01:41:12.540127 25496 solver.cpp:357] Iteration 59700 (2.3823 iter/s, 41.9762s/100 iters), loss = 0.0086298
I0930 01:41:12.540256 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00862998 (* 1 = 0.00862998 loss)
I0930 01:41:12.540268 25496 sgd_solver.cpp:165] Iteration 59700, lr = 0.001
I0930 01:41:38.378602 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:41:54.620123 25496 solver.cpp:357] Iteration 59800 (2.37656 iter/s, 42.0777s/100 iters), loss = 0.00276859
I0930 01:41:54.620306 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00276877 (* 1 = 0.00276877 loss)
I0930 01:41:54.620321 25496 sgd_solver.cpp:165] Iteration 59800, lr = 0.001
I0930 01:42:36.471911 25496 solver.cpp:357] Iteration 59900 (2.38952 iter/s, 41.8495s/100 iters), loss = 0.0103961
I0930 01:42:36.472061 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0103962 (* 1 = 0.0103962 loss)
I0930 01:42:36.472074 25496 sgd_solver.cpp:165] Iteration 59900, lr = 0.001
I0930 01:43:17.961851 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_60000.caffemodel
I0930 01:43:17.980859 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_60000.solverstate
I0930 01:43:17.986018 25496 solver.cpp:514] Iteration 60000, Testing net (#0)
I0930 01:43:46.036818 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:43:46.153161 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.30342 (* 1 = 0.30342 loss)
I0930 01:43:46.153203 25496 solver.cpp:580]     Test net output #1: prob = 0.926802
I0930 01:43:46.153209 25496 solver.cpp:593]     Max_acc: 0.927302  with iter: 57500
I0930 01:43:46.504886 25496 solver.cpp:357] Iteration 60000 (1.42791 iter/s, 70.0327s/100 iters), loss = 0.0116873
I0930 01:43:46.504951 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0116875 (* 1 = 0.0116875 loss)
I0930 01:43:46.504963 25496 sgd_solver.cpp:165] Iteration 60000, lr = 0.001
I0930 01:44:28.362661 25496 solver.cpp:357] Iteration 60100 (2.38917 iter/s, 41.8555s/100 iters), loss = 0.0104969
I0930 01:44:28.362927 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0104971 (* 1 = 0.0104971 loss)
I0930 01:44:28.362941 25496 sgd_solver.cpp:165] Iteration 60100, lr = 0.001
I0930 01:44:50.396137 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:45:10.455016 25496 solver.cpp:357] Iteration 60200 (2.37539 iter/s, 42.0984s/100 iters), loss = 0.00476517
I0930 01:45:10.455207 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00476536 (* 1 = 0.00476536 loss)
I0930 01:45:10.455221 25496 sgd_solver.cpp:165] Iteration 60200, lr = 0.001
I0930 01:45:52.677117 25496 solver.cpp:357] Iteration 60300 (2.36811 iter/s, 42.2277s/100 iters), loss = 0.0143362
I0930 01:45:52.677300 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0143364 (* 1 = 0.0143364 loss)
I0930 01:45:52.677314 25496 sgd_solver.cpp:165] Iteration 60300, lr = 0.001
I0930 01:46:34.789157 25496 solver.cpp:357] Iteration 60400 (2.37433 iter/s, 42.1171s/100 iters), loss = 0.0101067
I0930 01:46:34.789311 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0101069 (* 1 = 0.0101069 loss)
I0930 01:46:34.789324 25496 sgd_solver.cpp:165] Iteration 60400, lr = 0.001
I0930 01:47:16.655989 25496 solver.cpp:514] Iteration 60500, Testing net (#0)
I0930 01:47:44.688850 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:47:44.744379 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.304908 (* 1 = 0.304908 loss)
I0930 01:47:44.744421 25496 solver.cpp:580]     Test net output #1: prob = 0.924402
I0930 01:47:44.744427 25496 solver.cpp:593]     Max_acc: 0.927302  with iter: 57500
I0930 01:47:45.108371 25496 solver.cpp:357] Iteration 60500 (1.42191 iter/s, 70.3281s/100 iters), loss = 0.0511422
I0930 01:47:45.108433 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0511424 (* 1 = 0.0511424 loss)
I0930 01:47:45.108445 25496 sgd_solver.cpp:165] Iteration 60500, lr = 0.001
I0930 01:48:02.808811 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:48:27.103241 25496 solver.cpp:357] Iteration 60600 (2.38103 iter/s, 41.9987s/100 iters), loss = 0.00712697
I0930 01:48:27.103329 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00712717 (* 1 = 0.00712717 loss)
I0930 01:48:27.103343 25496 sgd_solver.cpp:165] Iteration 60600, lr = 0.001
I0930 01:49:09.169370 25496 solver.cpp:357] Iteration 60700 (2.3769 iter/s, 42.0716s/100 iters), loss = 0.00775462
I0930 01:49:09.169493 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00775482 (* 1 = 0.00775482 loss)
I0930 01:49:09.169505 25496 sgd_solver.cpp:165] Iteration 60700, lr = 0.001
I0930 01:49:51.550194 25496 solver.cpp:357] Iteration 60800 (2.35938 iter/s, 42.3839s/100 iters), loss = 0.0140387
I0930 01:49:51.550372 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0140389 (* 1 = 0.0140389 loss)
I0930 01:49:51.550386 25496 sgd_solver.cpp:165] Iteration 60800, lr = 0.001
I0930 01:50:33.413892 25496 solver.cpp:357] Iteration 60900 (2.38855 iter/s, 41.8664s/100 iters), loss = 0.0203137
I0930 01:50:33.414062 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0203139 (* 1 = 0.0203139 loss)
I0930 01:50:33.414075 25496 sgd_solver.cpp:165] Iteration 60900, lr = 0.001
I0930 01:50:47.187561 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:51:15.293748 25496 solver.cpp:514] Iteration 61000, Testing net (#0)
I0930 01:51:43.181588 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:51:43.301797 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.298334 (* 1 = 0.298334 loss)
I0930 01:51:43.301837 25496 solver.cpp:580]     Test net output #1: prob = 0.925802
I0930 01:51:43.301844 25496 solver.cpp:593]     Max_acc: 0.927302  with iter: 57500
I0930 01:51:43.651865 25496 solver.cpp:357] Iteration 61000 (1.42362 iter/s, 70.2433s/100 iters), loss = 0.0284272
I0930 01:51:43.651932 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0284274 (* 1 = 0.0284274 loss)
I0930 01:51:43.651944 25496 sgd_solver.cpp:165] Iteration 61000, lr = 0.001
I0930 01:52:25.973750 25496 solver.cpp:357] Iteration 61100 (2.36273 iter/s, 42.3239s/100 iters), loss = 0.0077678
I0930 01:52:25.974017 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.007768 (* 1 = 0.007768 loss)
I0930 01:52:25.974031 25496 sgd_solver.cpp:165] Iteration 61100, lr = 0.001
I0930 01:53:08.148553 25496 solver.cpp:357] Iteration 61200 (2.37099 iter/s, 42.1765s/100 iters), loss = 0.0076629
I0930 01:53:08.148723 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00766311 (* 1 = 0.00766311 loss)
I0930 01:53:08.148736 25496 sgd_solver.cpp:165] Iteration 61200, lr = 0.001
I0930 01:53:50.379904 25496 solver.cpp:357] Iteration 61300 (2.36771 iter/s, 42.2349s/100 iters), loss = 0.0256725
I0930 01:53:50.380106 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0256727 (* 1 = 0.0256727 loss)
I0930 01:53:50.380120 25496 sgd_solver.cpp:165] Iteration 61300, lr = 0.001
I0930 01:54:00.675081 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:54:32.355504 25496 solver.cpp:357] Iteration 61400 (2.38227 iter/s, 41.9768s/100 iters), loss = 0.00551376
I0930 01:54:32.355693 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00551396 (* 1 = 0.00551396 loss)
I0930 01:54:32.355707 25496 sgd_solver.cpp:165] Iteration 61400, lr = 0.001
I0930 01:55:14.100797 25496 solver.cpp:514] Iteration 61500, Testing net (#0)
I0930 01:55:42.059756 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:55:42.159776 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.306317 (* 1 = 0.306317 loss)
I0930 01:55:42.159826 25496 solver.cpp:580]     Test net output #1: prob = 0.925902
I0930 01:55:42.159832 25496 solver.cpp:593]     Max_acc: 0.927302  with iter: 57500
I0930 01:55:42.500340 25496 solver.cpp:357] Iteration 61500 (1.42556 iter/s, 70.148s/100 iters), loss = 0.0214506
I0930 01:55:42.500406 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0214508 (* 1 = 0.0214508 loss)
I0930 01:55:42.500418 25496 sgd_solver.cpp:165] Iteration 61500, lr = 0.001
I0930 01:56:25.039408 25496 solver.cpp:357] Iteration 61600 (2.35074 iter/s, 42.5398s/100 iters), loss = 0.00550734
I0930 01:56:25.039564 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00550754 (* 1 = 0.00550754 loss)
I0930 01:56:25.039575 25496 sgd_solver.cpp:165] Iteration 61600, lr = 0.001
I0930 01:57:07.073743 25496 solver.cpp:357] Iteration 61700 (2.37887 iter/s, 42.0368s/100 iters), loss = 0.0115258
I0930 01:57:07.073938 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.011526 (* 1 = 0.011526 loss)
I0930 01:57:07.073951 25496 sgd_solver.cpp:165] Iteration 61700, lr = 0.001
I0930 01:57:13.103633 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:57:48.984953 25496 solver.cpp:357] Iteration 61800 (2.38597 iter/s, 41.9117s/100 iters), loss = 0.0420093
I0930 01:57:48.985134 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0420095 (* 1 = 0.0420095 loss)
I0930 01:57:48.985148 25496 sgd_solver.cpp:165] Iteration 61800, lr = 0.001
I0930 01:58:31.049484 25496 solver.cpp:357] Iteration 61900 (2.37728 iter/s, 42.0648s/100 iters), loss = 0.0110157
I0930 01:58:31.049679 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0110159 (* 1 = 0.0110159 loss)
I0930 01:58:31.049692 25496 sgd_solver.cpp:165] Iteration 61900, lr = 0.001
I0930 01:59:12.917038 25496 solver.cpp:514] Iteration 62000, Testing net (#0)
I0930 01:59:40.764389 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 01:59:40.906942 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.300955 (* 1 = 0.300955 loss)
I0930 01:59:40.906968 25496 solver.cpp:580]     Test net output #1: prob = 0.927602
I0930 01:59:40.906982 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_62000.caffemodel
I0930 01:59:40.922354 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_62000.solverstate
I0930 01:59:40.926508 25496 solver.cpp:593]     Max_acc: 0.927602  with iter: 62000
I0930 01:59:41.273042 25496 solver.cpp:357] Iteration 62000 (1.42399 iter/s, 70.2253s/100 iters), loss = 0.0134016
I0930 01:59:41.273125 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0134018 (* 1 = 0.0134018 loss)
I0930 01:59:41.273138 25496 sgd_solver.cpp:165] Iteration 62000, lr = 0.001
I0930 02:00:23.447860 25496 solver.cpp:357] Iteration 62100 (2.37108 iter/s, 42.1748s/100 iters), loss = 0.00865413
I0930 02:00:23.448071 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00865433 (* 1 = 0.00865433 loss)
I0930 02:00:23.448083 25496 sgd_solver.cpp:165] Iteration 62100, lr = 0.001
I0930 02:00:25.673038 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 02:01:05.677669 25496 solver.cpp:357] Iteration 62200 (2.368 iter/s, 42.2298s/100 iters), loss = 0.0101423
I0930 02:01:05.677858 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0101425 (* 1 = 0.0101425 loss)
I0930 02:01:05.677870 25496 sgd_solver.cpp:165] Iteration 62200, lr = 0.001
I0930 02:01:47.798534 25496 solver.cpp:357] Iteration 62300 (2.37413 iter/s, 42.1207s/100 iters), loss = 0.0260303
I0930 02:01:47.798679 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0260305 (* 1 = 0.0260305 loss)
I0930 02:01:47.798691 25496 sgd_solver.cpp:165] Iteration 62300, lr = 0.001
I0930 02:02:30.023102 25496 solver.cpp:357] Iteration 62400 (2.3683 iter/s, 42.2243s/100 iters), loss = 0.0138604
I0930 02:02:30.023233 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0138606 (* 1 = 0.0138606 loss)
I0930 02:02:30.023247 25496 sgd_solver.cpp:165] Iteration 62400, lr = 0.001
I0930 02:03:09.802933 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 02:03:11.529892 25496 solver.cpp:514] Iteration 62500, Testing net (#0)
I0930 02:03:39.430369 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 02:03:39.571007 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.31193 (* 1 = 0.31193 loss)
I0930 02:03:39.571056 25496 solver.cpp:580]     Test net output #1: prob = 0.926402
I0930 02:03:39.571063 25496 solver.cpp:593]     Max_acc: 0.927602  with iter: 62000
I0930 02:03:39.915005 25496 solver.cpp:357] Iteration 62500 (1.43076 iter/s, 69.8928s/100 iters), loss = 0.00401113
I0930 02:03:39.915119 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00401134 (* 1 = 0.00401134 loss)
I0930 02:03:39.915132 25496 sgd_solver.cpp:165] Iteration 62500, lr = 0.001
I0930 02:04:21.816368 25496 solver.cpp:357] Iteration 62600 (2.38658 iter/s, 41.9009s/100 iters), loss = 0.00864228
I0930 02:04:21.816536 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00864249 (* 1 = 0.00864249 loss)
I0930 02:04:21.816548 25496 sgd_solver.cpp:165] Iteration 62600, lr = 0.001
I0930 02:05:03.834504 25496 solver.cpp:357] Iteration 62700 (2.37995 iter/s, 42.0176s/100 iters), loss = 0.0099858
I0930 02:05:03.834658 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00998602 (* 1 = 0.00998602 loss)
I0930 02:05:03.834671 25496 sgd_solver.cpp:165] Iteration 62700, lr = 0.001
I0930 02:05:46.032904 25496 solver.cpp:357] Iteration 62800 (2.36968 iter/s, 42.1999s/100 iters), loss = 0.00564722
I0930 02:05:46.033037 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00564744 (* 1 = 0.00564744 loss)
I0930 02:05:46.033051 25496 sgd_solver.cpp:165] Iteration 62800, lr = 0.001
I0930 02:06:22.198055 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 02:06:27.971237 25496 solver.cpp:357] Iteration 62900 (2.38449 iter/s, 41.9377s/100 iters), loss = 0.0107772
I0930 02:06:27.971329 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0107774 (* 1 = 0.0107774 loss)
I0930 02:06:27.971341 25496 sgd_solver.cpp:165] Iteration 62900, lr = 0.001
I0930 02:07:09.765157 25496 solver.cpp:514] Iteration 63000, Testing net (#0)
I0930 02:07:37.615615 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 02:07:37.680274 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.310182 (* 1 = 0.310182 loss)
I0930 02:07:37.680305 25496 solver.cpp:580]     Test net output #1: prob = 0.925802
I0930 02:07:37.680311 25496 solver.cpp:593]     Max_acc: 0.927602  with iter: 62000
I0930 02:07:38.047997 25496 solver.cpp:357] Iteration 63000 (1.427 iter/s, 70.0771s/100 iters), loss = 0.013214
I0930 02:07:38.048064 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0132142 (* 1 = 0.0132142 loss)
I0930 02:07:38.048077 25496 sgd_solver.cpp:165] Iteration 63000, lr = 0.001
I0930 02:08:19.894433 25496 solver.cpp:357] Iteration 63100 (2.38973 iter/s, 41.8457s/100 iters), loss = 0.0184966
I0930 02:08:19.894532 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0184968 (* 1 = 0.0184968 loss)
I0930 02:08:19.894546 25496 sgd_solver.cpp:165] Iteration 63100, lr = 0.001
I0930 02:09:01.531486 25496 solver.cpp:357] Iteration 63200 (2.40175 iter/s, 41.6363s/100 iters), loss = 0.0133139
I0930 02:09:01.531661 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0133141 (* 1 = 0.0133141 loss)
I0930 02:09:01.531673 25496 sgd_solver.cpp:165] Iteration 63200, lr = 0.001
I0930 02:09:33.931849 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 02:09:43.422448 25496 solver.cpp:357] Iteration 63300 (2.3872 iter/s, 41.8901s/100 iters), loss = 0.0130021
I0930 02:09:43.422523 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.0130024 (* 1 = 0.0130024 loss)
I0930 02:09:43.422534 25496 sgd_solver.cpp:165] Iteration 63300, lr = 0.001
I0930 02:10:25.204716 25496 solver.cpp:357] Iteration 63400 (2.39341 iter/s, 41.7814s/100 iters), loss = 0.00749338
I0930 02:10:25.204906 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00749359 (* 1 = 0.00749359 loss)
I0930 02:10:25.204921 25496 sgd_solver.cpp:165] Iteration 63400, lr = 0.001
I0930 02:11:07.044625 25496 solver.cpp:514] Iteration 63500, Testing net (#0)
I0930 02:11:35.002666 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 02:11:35.116122 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.307517 (* 1 = 0.307517 loss)
I0930 02:11:35.116163 25496 solver.cpp:580]     Test net output #1: prob = 0.926702
I0930 02:11:35.116170 25496 solver.cpp:593]     Max_acc: 0.927602  with iter: 62000
I0930 02:11:35.467430 25496 solver.cpp:357] Iteration 63500 (1.42323 iter/s, 70.2627s/100 iters), loss = 0.00404185
I0930 02:11:35.467497 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00404205 (* 1 = 0.00404205 loss)
I0930 02:11:35.467509 25496 sgd_solver.cpp:165] Iteration 63500, lr = 0.001
I0930 02:12:17.775327 25496 solver.cpp:357] Iteration 63600 (2.36368 iter/s, 42.307s/100 iters), loss = 0.00704981
I0930 02:12:17.775475 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00705002 (* 1 = 0.00705002 loss)
I0930 02:12:17.775488 25496 sgd_solver.cpp:165] Iteration 63600, lr = 0.001
I0930 02:12:45.999440 25501 data_layer.cpp:73] Restarting data prefetching from start.
I0930 02:12:59.838990 25496 solver.cpp:357] Iteration 63700 (2.3774 iter/s, 42.0627s/100 iters), loss = 0.00762063
I0930 02:12:59.839165 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00762083 (* 1 = 0.00762083 loss)
I0930 02:12:59.839177 25496 sgd_solver.cpp:165] Iteration 63700, lr = 0.001
I0930 02:13:41.748302 25496 solver.cpp:357] Iteration 63800 (2.38616 iter/s, 41.9083s/100 iters), loss = 0.00479657
I0930 02:13:41.748468 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00479677 (* 1 = 0.00479677 loss)
I0930 02:13:41.748481 25496 sgd_solver.cpp:165] Iteration 63800, lr = 0.001
I0930 02:14:23.804608 25496 solver.cpp:357] Iteration 63900 (2.37782 iter/s, 42.0553s/100 iters), loss = 0.0057079
I0930 02:14:23.804832 25496 solver.cpp:376]     Train net output #0: Softmax1 = 0.00570811 (* 1 = 0.00570811 loss)
I0930 02:14:23.804847 25496 sgd_solver.cpp:165] Iteration 63900, lr = 0.001
I0930 02:15:05.478452 25496 solver.cpp:684] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_64000.caffemodel
I0930 02:15:05.493758 25496 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_64000.solverstate
I0930 02:15:05.599663 25496 solver.cpp:472] Iteration 64000, loss = 0.00682742
I0930 02:15:05.599719 25496 solver.cpp:514] Iteration 64000, Testing net (#0)
I0930 02:15:33.628412 25502 data_layer.cpp:73] Restarting data prefetching from start.
I0930 02:15:33.698593 25496 solver.cpp:580]     Test net output #0: Softmax1 = 0.305362 (* 1 = 0.305362 loss)
I0930 02:15:33.698621 25496 solver.cpp:580]     Test net output #1: prob = 0.926302
I0930 02:15:33.698627 25496 solver.cpp:593]     Max_acc: 0.927602  with iter: 62000
I0930 02:15:33.698638 25496 solver.cpp:479] Optimization Done.
I0930 02:15:33.698642 25496 caffe.cpp:326] Optimization Done.
