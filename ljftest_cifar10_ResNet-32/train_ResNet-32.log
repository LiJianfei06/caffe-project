WARNING: Logging before InitGoogleLogging() is written to STDERR
I0927 00:20:21.952291 19128 caffe.cpp:530] argc:5 lijianfei debug!!!!!!!!!!
I0927 00:20:21.952427 19128 caffe.cpp:533] argv[0]:../../build/tools/caffe lijianfei debug!!!!!!!!!!
I0927 00:20:21.952435 19128 caffe.cpp:533] argv[1]:train lijianfei debug!!!!!!!!!!
I0927 00:20:21.952440 19128 caffe.cpp:533] argv[2]:--solver=./solver.prototxt lijianfei debug!!!!!!!!!!
I0927 00:20:21.952443 19128 caffe.cpp:533] argv[3]:--weights= lijianfei debug!!!!!!!!!!
I0927 00:20:21.952446 19128 caffe.cpp:533] argv[4]:--gpu=0 lijianfei debug!!!!!!!!!!
I0927 00:20:21.952514 19128 caffe.cpp:548] use WITH_PYTHON_LAYER lijianfei debug!!!!!!!!!!
I0927 00:20:21.952714 19128 caffe.cpp:553] caffe::string(argv[1]):train lijianfei debug!!!!!!!!!!
I0927 00:20:21.954509 19128 caffe.cpp:238] stages: lijianfei debug!!!!!!!!!!!!
I0927 00:20:21.954547 19128 caffe.cpp:269] Using GPUs 0
I0927 00:20:21.960813 19128 caffe.cpp:274] GPU 0: GeForce GTX 1060 6GB
I0927 00:20:22.629109 19128 solver_factory.hpp:111] function Solver<Dtype>* CreateSolver()  lijianfei debug!!!!!!!!!!
I0927 00:20:22.629158 19128 solver_factory.hpp:113] type:Nesterov lijianfei debug!!!!!!!!!!
I0927 00:20:22.726241 19128 solver.cpp:97] Initializing solver from parameters: 
train_net: "./train_ResNet_32.prototxt"
test_net: "./test_ResNet_32.prototxt"
test_iter: 1000
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 10000
snapshot_prefix: "./model_save/cifar10_ResNet_32"
solver_mode: GPU
device_id: 0
train_state {
  level: 0
  stage: ""
}
stepvalue: 32000
stepvalue: 48000
iter_size: 1
type: "Nesterov"
I0927 00:20:22.726547 19128 solver.cpp:167] Creating training net from train_net file: ./train_ResNet_32.prototxt
I0927 00:20:22.727922 19128 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./train_ResNet_32.prototxt
I0927 00:20:22.727948 19128 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0927 00:20:22.729336 19128 net.cpp:82] Initializing net from parameters: 
name: "ResNet-32"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: true
    crop_size: 32
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/train_lmdb"
    batch_size: 128
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "conv2_1_1"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv2_4_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv2_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4_bn0"
  type: "BatchNorm"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_4_scale0"
  type: "Scale"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_4_ReLU0"
  type: "ReLU"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
}
layer {
  name: "conv2_4_1"
  type: "Convolution"
  bottom: "conv2_4_0"
  top: "conv2_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4bn1"
  type: "BatchNorm"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_4_scale1"
  type: "Scale"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_4"
  type: "Eltwise"
  bottom: "conv2_Eltwise_3"
  bottom: "conv2_4_1"
  top: "conv2_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_4ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_4"
  top: "conv2_Eltwise_4"
}
layer {
  name: "conv2_5_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_4"
  top: "conv2_5_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_5_bn0"
  type: "BatchNorm"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_5_scale0"
  type: "Scale"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_5_ReLU0"
  type: "ReLU"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
}
layer {
  name: "conv2_5_1"
  type: "Convolution"
  bottom: "conv2_5_0"
  top: "conv2_5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_5bn1"
  type: "BatchNorm"
  bottom: "conv2_5_1"
  top: "conv2_5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_5_scale1"
  type: "Scale"
  bottom: "conv2_5_1"
  top: "conv2_5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_5"
  type: "Eltwise"
  bottom: "conv2_Eltwise_4"
  bottom: "conv2_5_1"
  top: "conv2_Eltwise_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_5ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_5"
  top: "conv2_Eltwise_5"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_5"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_5"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv3_4_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv3_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4_bn0"
  type: "BatchNorm"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_4_scale0"
  type: "Scale"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_ReLU0"
  type: "ReLU"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
}
layer {
  name: "conv3_4_1"
  type: "Convolution"
  bottom: "conv3_4_0"
  top: "conv3_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4bn1"
  type: "BatchNorm"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_4_scale1"
  type: "Scale"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_4"
  type: "Eltwise"
  bottom: "conv3_Eltwise_3"
  bottom: "conv3_4_1"
  top: "conv3_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_4ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_4"
  top: "conv3_Eltwise_4"
}
layer {
  name: "conv3_5_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_4"
  top: "conv3_5_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_5_bn0"
  type: "BatchNorm"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_5_scale0"
  type: "Scale"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_5_ReLU0"
  type: "ReLU"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
}
layer {
  name: "conv3_5_1"
  type: "Convolution"
  bottom: "conv3_5_0"
  top: "conv3_5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_5bn1"
  type: "BatchNorm"
  bottom: "conv3_5_1"
  top: "conv3_5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_5_scale1"
  type: "Scale"
  bottom: "conv3_5_1"
  top: "conv3_5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_5"
  type: "Eltwise"
  bottom: "conv3_Eltwise_4"
  bottom: "conv3_5_1"
  top: "conv3_Eltwise_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_5ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_5"
  top: "conv3_Eltwise_5"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_5"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_5"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "conv4_4_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_3"
  top: "conv4_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_4_bn0"
  type: "BatchNorm"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_4_scale0"
  type: "Scale"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  
I0927 00:20:22.730046 19128 layer_factory.hpp:77] Creating layer Data1
I0927 00:20:22.730242 19128 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/train_lmdb
I0927 00:20:22.730311 19128 net.cpp:128] Creating Layer Data1
I0927 00:20:22.730324 19128 net.cpp:522] Data1 -> data
I0927 00:20:22.730355 19128 net.cpp:522] Data1 -> label
I0927 00:20:22.732218 19128 data_layer.cpp:45] output data size: 128,3,32,32
I0927 00:20:22.745985 19128 net.cpp:172] Setting up Data1
I0927 00:20:22.746054 19128 net.cpp:186] Top shape: 128 3 32 32 (393216)
I0927 00:20:22.746062 19128 net.cpp:186] Top shape: 128 (128)
I0927 00:20:22.746067 19128 net.cpp:194] Memory required for data: 1573376
I0927 00:20:22.746083 19128 layer_factory.hpp:77] Creating layer conv1
I0927 00:20:22.746124 19128 net.cpp:128] Creating Layer conv1
I0927 00:20:22.746173 19128 net.cpp:558] conv1 <- data
I0927 00:20:22.746213 19128 net.cpp:522] conv1 -> conv1
I0927 00:20:23.799186 19128 net.cpp:172] Setting up conv1
I0927 00:20:23.799249 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.799254 19128 net.cpp:194] Memory required for data: 9961984
I0927 00:20:23.799300 19128 layer_factory.hpp:77] Creating layer conv1/bn
I0927 00:20:23.799324 19128 net.cpp:128] Creating Layer conv1/bn
I0927 00:20:23.799329 19128 net.cpp:558] conv1/bn <- conv1
I0927 00:20:23.799340 19128 net.cpp:509] conv1/bn -> conv1 (in-place)
I0927 00:20:23.799619 19128 net.cpp:172] Setting up conv1/bn
I0927 00:20:23.799633 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.799636 19128 net.cpp:194] Memory required for data: 18350592
I0927 00:20:23.799650 19128 layer_factory.hpp:77] Creating layer conv1/scale
I0927 00:20:23.799659 19128 net.cpp:128] Creating Layer conv1/scale
I0927 00:20:23.799664 19128 net.cpp:558] conv1/scale <- conv1
I0927 00:20:23.799670 19128 net.cpp:509] conv1/scale -> conv1 (in-place)
I0927 00:20:23.799717 19128 layer_factory.hpp:77] Creating layer conv1/scale
I0927 00:20:23.799863 19128 net.cpp:172] Setting up conv1/scale
I0927 00:20:23.799932 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.799949 19128 net.cpp:194] Memory required for data: 26739200
I0927 00:20:23.799970 19128 layer_factory.hpp:77] Creating layer conv1/ReLU
I0927 00:20:23.799990 19128 net.cpp:128] Creating Layer conv1/ReLU
I0927 00:20:23.800007 19128 net.cpp:558] conv1/ReLU <- conv1
I0927 00:20:23.800025 19128 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I0927 00:20:23.800848 19128 net.cpp:172] Setting up conv1/ReLU
I0927 00:20:23.800865 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.800870 19128 net.cpp:194] Memory required for data: 35127808
I0927 00:20:23.800879 19128 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I0927 00:20:23.800886 19128 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I0927 00:20:23.800891 19128 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I0927 00:20:23.800899 19128 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I0927 00:20:23.800906 19128 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I0927 00:20:23.800951 19128 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I0927 00:20:23.800958 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.800966 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.800969 19128 net.cpp:194] Memory required for data: 51905024
I0927 00:20:23.800973 19128 layer_factory.hpp:77] Creating layer conv2_1_0
I0927 00:20:23.800987 19128 net.cpp:128] Creating Layer conv2_1_0
I0927 00:20:23.800990 19128 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I0927 00:20:23.800997 19128 net.cpp:522] conv2_1_0 -> conv2_1_0
I0927 00:20:23.807523 19128 net.cpp:172] Setting up conv2_1_0
I0927 00:20:23.807554 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.807559 19128 net.cpp:194] Memory required for data: 60293632
I0927 00:20:23.807574 19128 layer_factory.hpp:77] Creating layer conv2_1_bn0
I0927 00:20:23.807584 19128 net.cpp:128] Creating Layer conv2_1_bn0
I0927 00:20:23.807591 19128 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I0927 00:20:23.807598 19128 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I0927 00:20:23.807832 19128 net.cpp:172] Setting up conv2_1_bn0
I0927 00:20:23.807843 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.807849 19128 net.cpp:194] Memory required for data: 68682240
I0927 00:20:23.807859 19128 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0927 00:20:23.807868 19128 net.cpp:128] Creating Layer conv2_1_scale0
I0927 00:20:23.807873 19128 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I0927 00:20:23.807878 19128 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I0927 00:20:23.807917 19128 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0927 00:20:23.808099 19128 net.cpp:172] Setting up conv2_1_scale0
I0927 00:20:23.808125 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.808140 19128 net.cpp:194] Memory required for data: 77070848
I0927 00:20:23.808163 19128 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I0927 00:20:23.808177 19128 net.cpp:128] Creating Layer conv2_1_ReLU0
I0927 00:20:23.808182 19128 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I0927 00:20:23.808188 19128 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I0927 00:20:23.809609 19128 net.cpp:172] Setting up conv2_1_ReLU0
I0927 00:20:23.809628 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.809631 19128 net.cpp:194] Memory required for data: 85459456
I0927 00:20:23.809650 19128 layer_factory.hpp:77] Creating layer conv2_1_1
I0927 00:20:23.809665 19128 net.cpp:128] Creating Layer conv2_1_1
I0927 00:20:23.809674 19128 net.cpp:558] conv2_1_1 <- conv2_1_0
I0927 00:20:23.809681 19128 net.cpp:522] conv2_1_1 -> conv2_1_1
I0927 00:20:23.816334 19128 net.cpp:172] Setting up conv2_1_1
I0927 00:20:23.816361 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.816366 19128 net.cpp:194] Memory required for data: 93848064
I0927 00:20:23.816376 19128 layer_factory.hpp:77] Creating layer conv2_1bn1
I0927 00:20:23.816388 19128 net.cpp:128] Creating Layer conv2_1bn1
I0927 00:20:23.816393 19128 net.cpp:558] conv2_1bn1 <- conv2_1_1
I0927 00:20:23.816402 19128 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I0927 00:20:23.816633 19128 net.cpp:172] Setting up conv2_1bn1
I0927 00:20:23.816645 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.816649 19128 net.cpp:194] Memory required for data: 102236672
I0927 00:20:23.816665 19128 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0927 00:20:23.816673 19128 net.cpp:128] Creating Layer conv2_1_scale1
I0927 00:20:23.816678 19128 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I0927 00:20:23.816682 19128 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I0927 00:20:23.816722 19128 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0927 00:20:23.816893 19128 net.cpp:172] Setting up conv2_1_scale1
I0927 00:20:23.816905 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.816910 19128 net.cpp:194] Memory required for data: 110625280
I0927 00:20:23.816918 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I0927 00:20:23.816932 19128 net.cpp:128] Creating Layer conv2_Eltwise_1
I0927 00:20:23.816936 19128 net.cpp:558] conv2_Eltwise_1 <- conv1_conv1/ReLU_0_split_1
I0927 00:20:23.816942 19128 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I0927 00:20:23.816948 19128 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I0927 00:20:23.816979 19128 net.cpp:172] Setting up conv2_Eltwise_1
I0927 00:20:23.817011 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.817037 19128 net.cpp:194] Memory required for data: 119013888
I0927 00:20:23.817046 19128 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I0927 00:20:23.817054 19128 net.cpp:128] Creating Layer conv2_1ReLU_1
I0927 00:20:23.817059 19128 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I0927 00:20:23.817067 19128 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I0927 00:20:23.818390 19128 net.cpp:172] Setting up conv2_1ReLU_1
I0927 00:20:23.818416 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.818420 19128 net.cpp:194] Memory required for data: 127402496
I0927 00:20:23.818426 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0927 00:20:23.818436 19128 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0927 00:20:23.818441 19128 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I0927 00:20:23.818449 19128 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0927 00:20:23.818465 19128 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0927 00:20:23.818516 19128 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0927 00:20:23.818569 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.818579 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.818583 19128 net.cpp:194] Memory required for data: 144179712
I0927 00:20:23.818588 19128 layer_factory.hpp:77] Creating layer conv2_2_0
I0927 00:20:23.818604 19128 net.cpp:128] Creating Layer conv2_2_0
I0927 00:20:23.818609 19128 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0927 00:20:23.818619 19128 net.cpp:522] conv2_2_0 -> conv2_2_0
I0927 00:20:23.825107 19128 net.cpp:172] Setting up conv2_2_0
I0927 00:20:23.825135 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.825139 19128 net.cpp:194] Memory required for data: 152568320
I0927 00:20:23.825166 19128 layer_factory.hpp:77] Creating layer conv2_2_bn0
I0927 00:20:23.825178 19128 net.cpp:128] Creating Layer conv2_2_bn0
I0927 00:20:23.825184 19128 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I0927 00:20:23.825194 19128 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I0927 00:20:23.825428 19128 net.cpp:172] Setting up conv2_2_bn0
I0927 00:20:23.825440 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.825444 19128 net.cpp:194] Memory required for data: 160956928
I0927 00:20:23.825454 19128 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0927 00:20:23.825466 19128 net.cpp:128] Creating Layer conv2_2_scale0
I0927 00:20:23.825471 19128 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I0927 00:20:23.825477 19128 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I0927 00:20:23.825516 19128 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0927 00:20:23.825657 19128 net.cpp:172] Setting up conv2_2_scale0
I0927 00:20:23.825665 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.825670 19128 net.cpp:194] Memory required for data: 169345536
I0927 00:20:23.825676 19128 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I0927 00:20:23.825683 19128 net.cpp:128] Creating Layer conv2_2_ReLU0
I0927 00:20:23.825688 19128 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I0927 00:20:23.825697 19128 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I0927 00:20:23.827188 19128 net.cpp:172] Setting up conv2_2_ReLU0
I0927 00:20:23.827208 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.827213 19128 net.cpp:194] Memory required for data: 177734144
I0927 00:20:23.827217 19128 layer_factory.hpp:77] Creating layer conv2_2_1
I0927 00:20:23.827230 19128 net.cpp:128] Creating Layer conv2_2_1
I0927 00:20:23.827235 19128 net.cpp:558] conv2_2_1 <- conv2_2_0
I0927 00:20:23.827245 19128 net.cpp:522] conv2_2_1 -> conv2_2_1
I0927 00:20:23.833065 19128 net.cpp:172] Setting up conv2_2_1
I0927 00:20:23.833091 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.833096 19128 net.cpp:194] Memory required for data: 186122752
I0927 00:20:23.833108 19128 layer_factory.hpp:77] Creating layer conv2_2bn1
I0927 00:20:23.833117 19128 net.cpp:128] Creating Layer conv2_2bn1
I0927 00:20:23.833125 19128 net.cpp:558] conv2_2bn1 <- conv2_2_1
I0927 00:20:23.833134 19128 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I0927 00:20:23.833377 19128 net.cpp:172] Setting up conv2_2bn1
I0927 00:20:23.833425 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.833434 19128 net.cpp:194] Memory required for data: 194511360
I0927 00:20:23.833449 19128 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0927 00:20:23.833458 19128 net.cpp:128] Creating Layer conv2_2_scale1
I0927 00:20:23.833462 19128 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I0927 00:20:23.833468 19128 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I0927 00:20:23.833518 19128 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0927 00:20:23.833678 19128 net.cpp:172] Setting up conv2_2_scale1
I0927 00:20:23.833690 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.833696 19128 net.cpp:194] Memory required for data: 202899968
I0927 00:20:23.833704 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I0927 00:20:23.833714 19128 net.cpp:128] Creating Layer conv2_Eltwise_2
I0927 00:20:23.833719 19128 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0927 00:20:23.833725 19128 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I0927 00:20:23.833734 19128 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I0927 00:20:23.833758 19128 net.cpp:172] Setting up conv2_Eltwise_2
I0927 00:20:23.833765 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.833770 19128 net.cpp:194] Memory required for data: 211288576
I0927 00:20:23.833773 19128 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I0927 00:20:23.833782 19128 net.cpp:128] Creating Layer conv2_2ReLU_1
I0927 00:20:23.833786 19128 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I0927 00:20:23.833792 19128 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I0927 00:20:23.834033 19128 net.cpp:172] Setting up conv2_2ReLU_1
I0927 00:20:23.834075 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.834094 19128 net.cpp:194] Memory required for data: 219677184
I0927 00:20:23.834102 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0927 00:20:23.834113 19128 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0927 00:20:23.834118 19128 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I0927 00:20:23.834128 19128 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0927 00:20:23.834136 19128 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0927 00:20:23.834187 19128 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0927 00:20:23.834200 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.834208 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.834211 19128 net.cpp:194] Memory required for data: 236454400
I0927 00:20:23.834215 19128 layer_factory.hpp:77] Creating layer conv2_3_0
I0927 00:20:23.834228 19128 net.cpp:128] Creating Layer conv2_3_0
I0927 00:20:23.834233 19128 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0927 00:20:23.834239 19128 net.cpp:522] conv2_3_0 -> conv2_3_0
I0927 00:20:23.837435 19128 net.cpp:172] Setting up conv2_3_0
I0927 00:20:23.837463 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.837468 19128 net.cpp:194] Memory required for data: 244843008
I0927 00:20:23.837478 19128 layer_factory.hpp:77] Creating layer conv2_3_bn0
I0927 00:20:23.837489 19128 net.cpp:128] Creating Layer conv2_3_bn0
I0927 00:20:23.837494 19128 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I0927 00:20:23.837502 19128 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I0927 00:20:23.837756 19128 net.cpp:172] Setting up conv2_3_bn0
I0927 00:20:23.837764 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.837769 19128 net.cpp:194] Memory required for data: 253231616
I0927 00:20:23.837779 19128 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0927 00:20:23.837785 19128 net.cpp:128] Creating Layer conv2_3_scale0
I0927 00:20:23.837790 19128 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I0927 00:20:23.837796 19128 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I0927 00:20:23.837838 19128 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0927 00:20:23.837972 19128 net.cpp:172] Setting up conv2_3_scale0
I0927 00:20:23.837980 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.837983 19128 net.cpp:194] Memory required for data: 261620224
I0927 00:20:23.837991 19128 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I0927 00:20:23.837999 19128 net.cpp:128] Creating Layer conv2_3_ReLU0
I0927 00:20:23.838003 19128 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I0927 00:20:23.838012 19128 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I0927 00:20:23.838491 19128 net.cpp:172] Setting up conv2_3_ReLU0
I0927 00:20:23.838508 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.838513 19128 net.cpp:194] Memory required for data: 270008832
I0927 00:20:23.838518 19128 layer_factory.hpp:77] Creating layer conv2_3_1
I0927 00:20:23.838532 19128 net.cpp:128] Creating Layer conv2_3_1
I0927 00:20:23.838537 19128 net.cpp:558] conv2_3_1 <- conv2_3_0
I0927 00:20:23.838548 19128 net.cpp:522] conv2_3_1 -> conv2_3_1
I0927 00:20:23.843425 19128 net.cpp:172] Setting up conv2_3_1
I0927 00:20:23.843452 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.843457 19128 net.cpp:194] Memory required for data: 278397440
I0927 00:20:23.843467 19128 layer_factory.hpp:77] Creating layer conv2_3bn1
I0927 00:20:23.843480 19128 net.cpp:128] Creating Layer conv2_3bn1
I0927 00:20:23.843485 19128 net.cpp:558] conv2_3bn1 <- conv2_3_1
I0927 00:20:23.843492 19128 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I0927 00:20:23.843745 19128 net.cpp:172] Setting up conv2_3bn1
I0927 00:20:23.843770 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.843775 19128 net.cpp:194] Memory required for data: 286786048
I0927 00:20:23.843786 19128 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0927 00:20:23.843797 19128 net.cpp:128] Creating Layer conv2_3_scale1
I0927 00:20:23.843801 19128 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I0927 00:20:23.843808 19128 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I0927 00:20:23.843850 19128 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0927 00:20:23.843989 19128 net.cpp:172] Setting up conv2_3_scale1
I0927 00:20:23.843997 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.844002 19128 net.cpp:194] Memory required for data: 295174656
I0927 00:20:23.844009 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I0927 00:20:23.844019 19128 net.cpp:128] Creating Layer conv2_Eltwise_3
I0927 00:20:23.844024 19128 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0927 00:20:23.844029 19128 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I0927 00:20:23.844035 19128 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I0927 00:20:23.844065 19128 net.cpp:172] Setting up conv2_Eltwise_3
I0927 00:20:23.844072 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.844076 19128 net.cpp:194] Memory required for data: 303563264
I0927 00:20:23.844080 19128 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I0927 00:20:23.844086 19128 net.cpp:128] Creating Layer conv2_3ReLU_1
I0927 00:20:23.844090 19128 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I0927 00:20:23.844100 19128 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I0927 00:20:23.844331 19128 net.cpp:172] Setting up conv2_3ReLU_1
I0927 00:20:23.844342 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.844347 19128 net.cpp:194] Memory required for data: 311951872
I0927 00:20:23.844350 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0927 00:20:23.844358 19128 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0927 00:20:23.844362 19128 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I0927 00:20:23.844372 19128 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0927 00:20:23.844379 19128 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0927 00:20:23.844427 19128 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0927 00:20:23.844434 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.844440 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.844444 19128 net.cpp:194] Memory required for data: 328729088
I0927 00:20:23.844449 19128 layer_factory.hpp:77] Creating layer conv2_4_0
I0927 00:20:23.844460 19128 net.cpp:128] Creating Layer conv2_4_0
I0927 00:20:23.844465 19128 net.cpp:558] conv2_4_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0927 00:20:23.844475 19128 net.cpp:522] conv2_4_0 -> conv2_4_0
I0927 00:20:23.850064 19128 net.cpp:172] Setting up conv2_4_0
I0927 00:20:23.850095 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.850098 19128 net.cpp:194] Memory required for data: 337117696
I0927 00:20:23.850114 19128 layer_factory.hpp:77] Creating layer conv2_4_bn0
I0927 00:20:23.850126 19128 net.cpp:128] Creating Layer conv2_4_bn0
I0927 00:20:23.850132 19128 net.cpp:558] conv2_4_bn0 <- conv2_4_0
I0927 00:20:23.850142 19128 net.cpp:509] conv2_4_bn0 -> conv2_4_0 (in-place)
I0927 00:20:23.850390 19128 net.cpp:172] Setting up conv2_4_bn0
I0927 00:20:23.850399 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.850402 19128 net.cpp:194] Memory required for data: 345506304
I0927 00:20:23.850412 19128 layer_factory.hpp:77] Creating layer conv2_4_scale0
I0927 00:20:23.850426 19128 net.cpp:128] Creating Layer conv2_4_scale0
I0927 00:20:23.850431 19128 net.cpp:558] conv2_4_scale0 <- conv2_4_0
I0927 00:20:23.850437 19128 net.cpp:509] conv2_4_scale0 -> conv2_4_0 (in-place)
I0927 00:20:23.850481 19128 layer_factory.hpp:77] Creating layer conv2_4_scale0
I0927 00:20:23.850646 19128 net.cpp:172] Setting up conv2_4_scale0
I0927 00:20:23.850657 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.850662 19128 net.cpp:194] Memory required for data: 353894912
I0927 00:20:23.850672 19128 layer_factory.hpp:77] Creating layer conv2_4_ReLU0
I0927 00:20:23.850679 19128 net.cpp:128] Creating Layer conv2_4_ReLU0
I0927 00:20:23.850684 19128 net.cpp:558] conv2_4_ReLU0 <- conv2_4_0
I0927 00:20:23.850695 19128 net.cpp:509] conv2_4_ReLU0 -> conv2_4_0 (in-place)
I0927 00:20:23.852102 19128 net.cpp:172] Setting up conv2_4_ReLU0
I0927 00:20:23.852123 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.852128 19128 net.cpp:194] Memory required for data: 362283520
I0927 00:20:23.852133 19128 layer_factory.hpp:77] Creating layer conv2_4_1
I0927 00:20:23.852151 19128 net.cpp:128] Creating Layer conv2_4_1
I0927 00:20:23.852195 19128 net.cpp:558] conv2_4_1 <- conv2_4_0
I0927 00:20:23.852208 19128 net.cpp:522] conv2_4_1 -> conv2_4_1
I0927 00:20:23.858825 19128 net.cpp:172] Setting up conv2_4_1
I0927 00:20:23.858852 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.858857 19128 net.cpp:194] Memory required for data: 370672128
I0927 00:20:23.858871 19128 layer_factory.hpp:77] Creating layer conv2_4bn1
I0927 00:20:23.858883 19128 net.cpp:128] Creating Layer conv2_4bn1
I0927 00:20:23.858889 19128 net.cpp:558] conv2_4bn1 <- conv2_4_1
I0927 00:20:23.858896 19128 net.cpp:509] conv2_4bn1 -> conv2_4_1 (in-place)
I0927 00:20:23.859148 19128 net.cpp:172] Setting up conv2_4bn1
I0927 00:20:23.859158 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.859163 19128 net.cpp:194] Memory required for data: 379060736
I0927 00:20:23.859172 19128 layer_factory.hpp:77] Creating layer conv2_4_scale1
I0927 00:20:23.859179 19128 net.cpp:128] Creating Layer conv2_4_scale1
I0927 00:20:23.859184 19128 net.cpp:558] conv2_4_scale1 <- conv2_4_1
I0927 00:20:23.859191 19128 net.cpp:509] conv2_4_scale1 -> conv2_4_1 (in-place)
I0927 00:20:23.859236 19128 layer_factory.hpp:77] Creating layer conv2_4_scale1
I0927 00:20:23.859375 19128 net.cpp:172] Setting up conv2_4_scale1
I0927 00:20:23.859390 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.859393 19128 net.cpp:194] Memory required for data: 387449344
I0927 00:20:23.859401 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_4
I0927 00:20:23.859447 19128 net.cpp:128] Creating Layer conv2_Eltwise_4
I0927 00:20:23.859457 19128 net.cpp:558] conv2_Eltwise_4 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0927 00:20:23.859462 19128 net.cpp:558] conv2_Eltwise_4 <- conv2_4_1
I0927 00:20:23.859468 19128 net.cpp:522] conv2_Eltwise_4 -> conv2_Eltwise_4
I0927 00:20:23.859505 19128 net.cpp:172] Setting up conv2_Eltwise_4
I0927 00:20:23.859534 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.859541 19128 net.cpp:194] Memory required for data: 395837952
I0927 00:20:23.859546 19128 layer_factory.hpp:77] Creating layer conv2_4ReLU_1
I0927 00:20:23.859556 19128 net.cpp:128] Creating Layer conv2_4ReLU_1
I0927 00:20:23.859561 19128 net.cpp:558] conv2_4ReLU_1 <- conv2_Eltwise_4
I0927 00:20:23.859587 19128 net.cpp:509] conv2_4ReLU_1 -> conv2_Eltwise_4 (in-place)
I0927 00:20:23.860908 19128 net.cpp:172] Setting up conv2_4ReLU_1
I0927 00:20:23.860927 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.860931 19128 net.cpp:194] Memory required for data: 404226560
I0927 00:20:23.860936 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0927 00:20:23.860952 19128 net.cpp:128] Creating Layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0927 00:20:23.860957 19128 net.cpp:558] conv2_Eltwise_4_conv2_4ReLU_1_0_split <- conv2_Eltwise_4
I0927 00:20:23.860963 19128 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I0927 00:20:23.860971 19128 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I0927 00:20:23.861023 19128 net.cpp:172] Setting up conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0927 00:20:23.861052 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.861058 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.861063 19128 net.cpp:194] Memory required for data: 421003776
I0927 00:20:23.861066 19128 layer_factory.hpp:77] Creating layer conv2_5_0
I0927 00:20:23.861078 19128 net.cpp:128] Creating Layer conv2_5_0
I0927 00:20:23.861086 19128 net.cpp:558] conv2_5_0 <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I0927 00:20:23.861093 19128 net.cpp:522] conv2_5_0 -> conv2_5_0
I0927 00:20:23.867588 19128 net.cpp:172] Setting up conv2_5_0
I0927 00:20:23.867614 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.867619 19128 net.cpp:194] Memory required for data: 429392384
I0927 00:20:23.867640 19128 layer_factory.hpp:77] Creating layer conv2_5_bn0
I0927 00:20:23.867650 19128 net.cpp:128] Creating Layer conv2_5_bn0
I0927 00:20:23.867655 19128 net.cpp:558] conv2_5_bn0 <- conv2_5_0
I0927 00:20:23.867669 19128 net.cpp:509] conv2_5_bn0 -> conv2_5_0 (in-place)
I0927 00:20:23.867919 19128 net.cpp:172] Setting up conv2_5_bn0
I0927 00:20:23.867933 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.867938 19128 net.cpp:194] Memory required for data: 437780992
I0927 00:20:23.867949 19128 layer_factory.hpp:77] Creating layer conv2_5_scale0
I0927 00:20:23.867959 19128 net.cpp:128] Creating Layer conv2_5_scale0
I0927 00:20:23.867964 19128 net.cpp:558] conv2_5_scale0 <- conv2_5_0
I0927 00:20:23.867969 19128 net.cpp:509] conv2_5_scale0 -> conv2_5_0 (in-place)
I0927 00:20:23.868010 19128 layer_factory.hpp:77] Creating layer conv2_5_scale0
I0927 00:20:23.868154 19128 net.cpp:172] Setting up conv2_5_scale0
I0927 00:20:23.868166 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.868172 19128 net.cpp:194] Memory required for data: 446169600
I0927 00:20:23.868181 19128 layer_factory.hpp:77] Creating layer conv2_5_ReLU0
I0927 00:20:23.868188 19128 net.cpp:128] Creating Layer conv2_5_ReLU0
I0927 00:20:23.868192 19128 net.cpp:558] conv2_5_ReLU0 <- conv2_5_0
I0927 00:20:23.868201 19128 net.cpp:509] conv2_5_ReLU0 -> conv2_5_0 (in-place)
I0927 00:20:23.869690 19128 net.cpp:172] Setting up conv2_5_ReLU0
I0927 00:20:23.869716 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.869720 19128 net.cpp:194] Memory required for data: 454558208
I0927 00:20:23.869727 19128 layer_factory.hpp:77] Creating layer conv2_5_1
I0927 00:20:23.869742 19128 net.cpp:128] Creating Layer conv2_5_1
I0927 00:20:23.869747 19128 net.cpp:558] conv2_5_1 <- conv2_5_0
I0927 00:20:23.869761 19128 net.cpp:522] conv2_5_1 -> conv2_5_1
I0927 00:20:23.876410 19128 net.cpp:172] Setting up conv2_5_1
I0927 00:20:23.876437 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.876441 19128 net.cpp:194] Memory required for data: 462946816
I0927 00:20:23.876451 19128 layer_factory.hpp:77] Creating layer conv2_5bn1
I0927 00:20:23.876466 19128 net.cpp:128] Creating Layer conv2_5bn1
I0927 00:20:23.876471 19128 net.cpp:558] conv2_5bn1 <- conv2_5_1
I0927 00:20:23.876479 19128 net.cpp:509] conv2_5bn1 -> conv2_5_1 (in-place)
I0927 00:20:23.876731 19128 net.cpp:172] Setting up conv2_5bn1
I0927 00:20:23.876744 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.876749 19128 net.cpp:194] Memory required for data: 471335424
I0927 00:20:23.876757 19128 layer_factory.hpp:77] Creating layer conv2_5_scale1
I0927 00:20:23.876767 19128 net.cpp:128] Creating Layer conv2_5_scale1
I0927 00:20:23.876772 19128 net.cpp:558] conv2_5_scale1 <- conv2_5_1
I0927 00:20:23.876778 19128 net.cpp:509] conv2_5_scale1 -> conv2_5_1 (in-place)
I0927 00:20:23.876819 19128 layer_factory.hpp:77] Creating layer conv2_5_scale1
I0927 00:20:23.876965 19128 net.cpp:172] Setting up conv2_5_scale1
I0927 00:20:23.876978 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.876982 19128 net.cpp:194] Memory required for data: 479724032
I0927 00:20:23.876991 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_5
I0927 00:20:23.876999 19128 net.cpp:128] Creating Layer conv2_Eltwise_5
I0927 00:20:23.877027 19128 net.cpp:558] conv2_Eltwise_5 <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I0927 00:20:23.877033 19128 net.cpp:558] conv2_Eltwise_5 <- conv2_5_1
I0927 00:20:23.877039 19128 net.cpp:522] conv2_Eltwise_5 -> conv2_Eltwise_5
I0927 00:20:23.877070 19128 net.cpp:172] Setting up conv2_Eltwise_5
I0927 00:20:23.877082 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.877087 19128 net.cpp:194] Memory required for data: 488112640
I0927 00:20:23.877091 19128 layer_factory.hpp:77] Creating layer conv2_5ReLU_1
I0927 00:20:23.877099 19128 net.cpp:128] Creating Layer conv2_5ReLU_1
I0927 00:20:23.877102 19128 net.cpp:558] conv2_5ReLU_1 <- conv2_Eltwise_5
I0927 00:20:23.877110 19128 net.cpp:509] conv2_5ReLU_1 -> conv2_Eltwise_5 (in-place)
I0927 00:20:23.878479 19128 net.cpp:172] Setting up conv2_5ReLU_1
I0927 00:20:23.878494 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.878497 19128 net.cpp:194] Memory required for data: 496501248
I0927 00:20:23.878502 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0927 00:20:23.878510 19128 net.cpp:128] Creating Layer conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0927 00:20:23.878515 19128 net.cpp:558] conv2_Eltwise_5_conv2_5ReLU_1_0_split <- conv2_Eltwise_5
I0927 00:20:23.878525 19128 net.cpp:522] conv2_Eltwise_5_conv2_5ReLU_1_0_split -> conv2_Eltwise_5_conv2_5ReLU_1_0_split_0
I0927 00:20:23.878533 19128 net.cpp:522] conv2_Eltwise_5_conv2_5ReLU_1_0_split -> conv2_Eltwise_5_conv2_5ReLU_1_0_split_1
I0927 00:20:23.878584 19128 net.cpp:172] Setting up conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0927 00:20:23.878592 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.878598 19128 net.cpp:186] Top shape: 128 16 32 32 (2097152)
I0927 00:20:23.878602 19128 net.cpp:194] Memory required for data: 513278464
I0927 00:20:23.878607 19128 layer_factory.hpp:77] Creating layer conv3_1_0
I0927 00:20:23.878618 19128 net.cpp:128] Creating Layer conv3_1_0
I0927 00:20:23.878623 19128 net.cpp:558] conv3_1_0 <- conv2_Eltwise_5_conv2_5ReLU_1_0_split_0
I0927 00:20:23.878634 19128 net.cpp:522] conv3_1_0 -> conv3_1_0
I0927 00:20:23.885264 19128 net.cpp:172] Setting up conv3_1_0
I0927 00:20:23.885295 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.885300 19128 net.cpp:194] Memory required for data: 517472768
I0927 00:20:23.885313 19128 layer_factory.hpp:77] Creating layer conv3_1_bn0
I0927 00:20:23.885324 19128 net.cpp:128] Creating Layer conv3_1_bn0
I0927 00:20:23.885330 19128 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I0927 00:20:23.885344 19128 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I0927 00:20:23.885605 19128 net.cpp:172] Setting up conv3_1_bn0
I0927 00:20:23.885617 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.885622 19128 net.cpp:194] Memory required for data: 521667072
I0927 00:20:23.885632 19128 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0927 00:20:23.885640 19128 net.cpp:128] Creating Layer conv3_1_scale0
I0927 00:20:23.885645 19128 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I0927 00:20:23.885650 19128 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I0927 00:20:23.885694 19128 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0927 00:20:23.885844 19128 net.cpp:172] Setting up conv3_1_scale0
I0927 00:20:23.885852 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.885857 19128 net.cpp:194] Memory required for data: 525861376
I0927 00:20:23.885865 19128 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I0927 00:20:23.885872 19128 net.cpp:128] Creating Layer conv3_1_ReLU0
I0927 00:20:23.885876 19128 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I0927 00:20:23.885885 19128 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I0927 00:20:23.887063 19128 net.cpp:172] Setting up conv3_1_ReLU0
I0927 00:20:23.887082 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.887087 19128 net.cpp:194] Memory required for data: 530055680
I0927 00:20:23.887091 19128 layer_factory.hpp:77] Creating layer conv3_1_1
I0927 00:20:23.887123 19128 net.cpp:128] Creating Layer conv3_1_1
I0927 00:20:23.887133 19128 net.cpp:558] conv3_1_1 <- conv3_1_0
I0927 00:20:23.887143 19128 net.cpp:522] conv3_1_1 -> conv3_1_1
I0927 00:20:23.893761 19128 net.cpp:172] Setting up conv3_1_1
I0927 00:20:23.893788 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.893792 19128 net.cpp:194] Memory required for data: 534249984
I0927 00:20:23.893802 19128 layer_factory.hpp:77] Creating layer conv3_1bn1
I0927 00:20:23.893813 19128 net.cpp:128] Creating Layer conv3_1bn1
I0927 00:20:23.893818 19128 net.cpp:558] conv3_1bn1 <- conv3_1_1
I0927 00:20:23.893828 19128 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I0927 00:20:23.894080 19128 net.cpp:172] Setting up conv3_1bn1
I0927 00:20:23.894091 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.894098 19128 net.cpp:194] Memory required for data: 538444288
I0927 00:20:23.894106 19128 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0927 00:20:23.894116 19128 net.cpp:128] Creating Layer conv3_1_scale1
I0927 00:20:23.894121 19128 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I0927 00:20:23.894126 19128 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I0927 00:20:23.894170 19128 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0927 00:20:23.894316 19128 net.cpp:172] Setting up conv3_1_scale1
I0927 00:20:23.894327 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.894332 19128 net.cpp:194] Memory required for data: 542638592
I0927 00:20:23.894340 19128 layer_factory.hpp:77] Creating layer conv3_1_down
I0927 00:20:23.894354 19128 net.cpp:128] Creating Layer conv3_1_down
I0927 00:20:23.894359 19128 net.cpp:558] conv3_1_down <- conv2_Eltwise_5_conv2_5ReLU_1_0_split_1
I0927 00:20:23.894367 19128 net.cpp:522] conv3_1_down -> conv3_1_down
I0927 00:20:23.900285 19128 net.cpp:172] Setting up conv3_1_down
I0927 00:20:23.900313 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.900318 19128 net.cpp:194] Memory required for data: 546832896
I0927 00:20:23.900328 19128 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I0927 00:20:23.900352 19128 net.cpp:128] Creating Layer conv3_1_bn_down
I0927 00:20:23.900362 19128 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I0927 00:20:23.900368 19128 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I0927 00:20:23.900614 19128 net.cpp:172] Setting up conv3_1_bn_down
I0927 00:20:23.900629 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.900632 19128 net.cpp:194] Memory required for data: 551027200
I0927 00:20:23.900643 19128 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0927 00:20:23.900653 19128 net.cpp:128] Creating Layer conv3_1_scale_down
I0927 00:20:23.900658 19128 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I0927 00:20:23.900666 19128 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I0927 00:20:23.900708 19128 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0927 00:20:23.900847 19128 net.cpp:172] Setting up conv3_1_scale_down
I0927 00:20:23.900856 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.900859 19128 net.cpp:194] Memory required for data: 555221504
I0927 00:20:23.900867 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I0927 00:20:23.900878 19128 net.cpp:128] Creating Layer conv3_Eltwise_1
I0927 00:20:23.900883 19128 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I0927 00:20:23.900888 19128 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I0927 00:20:23.900894 19128 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I0927 00:20:23.900918 19128 net.cpp:172] Setting up conv3_Eltwise_1
I0927 00:20:23.900926 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.900930 19128 net.cpp:194] Memory required for data: 559415808
I0927 00:20:23.900934 19128 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I0927 00:20:23.900941 19128 net.cpp:128] Creating Layer conv3_1ReLU_1
I0927 00:20:23.900945 19128 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I0927 00:20:23.900954 19128 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I0927 00:20:23.902351 19128 net.cpp:172] Setting up conv3_1ReLU_1
I0927 00:20:23.902374 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.902379 19128 net.cpp:194] Memory required for data: 563610112
I0927 00:20:23.902384 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0927 00:20:23.902396 19128 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0927 00:20:23.902402 19128 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I0927 00:20:23.902412 19128 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0927 00:20:23.902421 19128 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0927 00:20:23.902472 19128 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0927 00:20:23.902482 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.902488 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.902493 19128 net.cpp:194] Memory required for data: 571998720
I0927 00:20:23.902496 19128 layer_factory.hpp:77] Creating layer conv3_2_0
I0927 00:20:23.902510 19128 net.cpp:128] Creating Layer conv3_2_0
I0927 00:20:23.902515 19128 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0927 00:20:23.902524 19128 net.cpp:522] conv3_2_0 -> conv3_2_0
I0927 00:20:23.909047 19128 net.cpp:172] Setting up conv3_2_0
I0927 00:20:23.909076 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.909081 19128 net.cpp:194] Memory required for data: 576193024
I0927 00:20:23.909095 19128 layer_factory.hpp:77] Creating layer conv3_2_bn0
I0927 00:20:23.909103 19128 net.cpp:128] Creating Layer conv3_2_bn0
I0927 00:20:23.909108 19128 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I0927 00:20:23.909121 19128 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I0927 00:20:23.909375 19128 net.cpp:172] Setting up conv3_2_bn0
I0927 00:20:23.909387 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.909391 19128 net.cpp:194] Memory required for data: 580387328
I0927 00:20:23.909402 19128 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0927 00:20:23.909409 19128 net.cpp:128] Creating Layer conv3_2_scale0
I0927 00:20:23.909415 19128 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I0927 00:20:23.909420 19128 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I0927 00:20:23.909462 19128 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0927 00:20:23.909607 19128 net.cpp:172] Setting up conv3_2_scale0
I0927 00:20:23.909624 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.909628 19128 net.cpp:194] Memory required for data: 584581632
I0927 00:20:23.909636 19128 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I0927 00:20:23.909646 19128 net.cpp:128] Creating Layer conv3_2_ReLU0
I0927 00:20:23.909651 19128 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I0927 00:20:23.909657 19128 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I0927 00:20:23.911084 19128 net.cpp:172] Setting up conv3_2_ReLU0
I0927 00:20:23.911104 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.911108 19128 net.cpp:194] Memory required for data: 588775936
I0927 00:20:23.911113 19128 layer_factory.hpp:77] Creating layer conv3_2_1
I0927 00:20:23.911126 19128 net.cpp:128] Creating Layer conv3_2_1
I0927 00:20:23.911131 19128 net.cpp:558] conv3_2_1 <- conv3_2_0
I0927 00:20:23.911141 19128 net.cpp:522] conv3_2_1 -> conv3_2_1
I0927 00:20:23.917822 19128 net.cpp:172] Setting up conv3_2_1
I0927 00:20:23.917850 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.917853 19128 net.cpp:194] Memory required for data: 592970240
I0927 00:20:23.917863 19128 layer_factory.hpp:77] Creating layer conv3_2bn1
I0927 00:20:23.917876 19128 net.cpp:128] Creating Layer conv3_2bn1
I0927 00:20:23.917881 19128 net.cpp:558] conv3_2bn1 <- conv3_2_1
I0927 00:20:23.917889 19128 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I0927 00:20:23.918143 19128 net.cpp:172] Setting up conv3_2bn1
I0927 00:20:23.918150 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.918170 19128 net.cpp:194] Memory required for data: 597164544
I0927 00:20:23.918181 19128 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0927 00:20:23.918191 19128 net.cpp:128] Creating Layer conv3_2_scale1
I0927 00:20:23.918196 19128 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I0927 00:20:23.918201 19128 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I0927 00:20:23.918243 19128 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0927 00:20:23.918392 19128 net.cpp:172] Setting up conv3_2_scale1
I0927 00:20:23.918404 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.918411 19128 net.cpp:194] Memory required for data: 601358848
I0927 00:20:23.918418 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I0927 00:20:23.918428 19128 net.cpp:128] Creating Layer conv3_Eltwise_2
I0927 00:20:23.918433 19128 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0927 00:20:23.918438 19128 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I0927 00:20:23.918445 19128 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I0927 00:20:23.918469 19128 net.cpp:172] Setting up conv3_Eltwise_2
I0927 00:20:23.918476 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.918480 19128 net.cpp:194] Memory required for data: 605553152
I0927 00:20:23.918484 19128 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I0927 00:20:23.918491 19128 net.cpp:128] Creating Layer conv3_2ReLU_1
I0927 00:20:23.918495 19128 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I0927 00:20:23.918503 19128 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I0927 00:20:23.920115 19128 net.cpp:172] Setting up conv3_2ReLU_1
I0927 00:20:23.920141 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.920146 19128 net.cpp:194] Memory required for data: 609747456
I0927 00:20:23.920151 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0927 00:20:23.920161 19128 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0927 00:20:23.920166 19128 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I0927 00:20:23.920176 19128 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0927 00:20:23.920184 19128 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0927 00:20:23.920244 19128 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0927 00:20:23.920253 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.920258 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.920262 19128 net.cpp:194] Memory required for data: 618136064
I0927 00:20:23.920266 19128 layer_factory.hpp:77] Creating layer conv3_3_0
I0927 00:20:23.920279 19128 net.cpp:128] Creating Layer conv3_3_0
I0927 00:20:23.920284 19128 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0927 00:20:23.920292 19128 net.cpp:522] conv3_3_0 -> conv3_3_0
I0927 00:20:23.926589 19128 net.cpp:172] Setting up conv3_3_0
I0927 00:20:23.926615 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.926620 19128 net.cpp:194] Memory required for data: 622330368
I0927 00:20:23.926630 19128 layer_factory.hpp:77] Creating layer conv3_3_bn0
I0927 00:20:23.926640 19128 net.cpp:128] Creating Layer conv3_3_bn0
I0927 00:20:23.926645 19128 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I0927 00:20:23.926654 19128 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I0927 00:20:23.926916 19128 net.cpp:172] Setting up conv3_3_bn0
I0927 00:20:23.926930 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.926934 19128 net.cpp:194] Memory required for data: 626524672
I0927 00:20:23.926944 19128 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0927 00:20:23.926951 19128 net.cpp:128] Creating Layer conv3_3_scale0
I0927 00:20:23.926955 19128 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I0927 00:20:23.926964 19128 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I0927 00:20:23.927003 19128 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0927 00:20:23.927170 19128 net.cpp:172] Setting up conv3_3_scale0
I0927 00:20:23.927181 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.927186 19128 net.cpp:194] Memory required for data: 630718976
I0927 00:20:23.927193 19128 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I0927 00:20:23.927199 19128 net.cpp:128] Creating Layer conv3_3_ReLU0
I0927 00:20:23.927204 19128 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I0927 00:20:23.927211 19128 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I0927 00:20:23.928665 19128 net.cpp:172] Setting up conv3_3_ReLU0
I0927 00:20:23.928691 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.928696 19128 net.cpp:194] Memory required for data: 634913280
I0927 00:20:23.928701 19128 layer_factory.hpp:77] Creating layer conv3_3_1
I0927 00:20:23.928719 19128 net.cpp:128] Creating Layer conv3_3_1
I0927 00:20:23.928723 19128 net.cpp:558] conv3_3_1 <- conv3_3_0
I0927 00:20:23.928731 19128 net.cpp:522] conv3_3_1 -> conv3_3_1
I0927 00:20:23.935325 19128 net.cpp:172] Setting up conv3_3_1
I0927 00:20:23.935353 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.935356 19128 net.cpp:194] Memory required for data: 639107584
I0927 00:20:23.935366 19128 layer_factory.hpp:77] Creating layer conv3_3bn1
I0927 00:20:23.935377 19128 net.cpp:128] Creating Layer conv3_3bn1
I0927 00:20:23.935384 19128 net.cpp:558] conv3_3bn1 <- conv3_3_1
I0927 00:20:23.935392 19128 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I0927 00:20:23.935652 19128 net.cpp:172] Setting up conv3_3bn1
I0927 00:20:23.935659 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.935663 19128 net.cpp:194] Memory required for data: 643301888
I0927 00:20:23.935673 19128 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0927 00:20:23.935680 19128 net.cpp:128] Creating Layer conv3_3_scale1
I0927 00:20:23.935684 19128 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I0927 00:20:23.935693 19128 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I0927 00:20:23.935731 19128 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0927 00:20:23.935878 19128 net.cpp:172] Setting up conv3_3_scale1
I0927 00:20:23.935889 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.935895 19128 net.cpp:194] Memory required for data: 647496192
I0927 00:20:23.935904 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I0927 00:20:23.935910 19128 net.cpp:128] Creating Layer conv3_Eltwise_3
I0927 00:20:23.935915 19128 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0927 00:20:23.935920 19128 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I0927 00:20:23.935930 19128 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I0927 00:20:23.935951 19128 net.cpp:172] Setting up conv3_Eltwise_3
I0927 00:20:23.935958 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.935962 19128 net.cpp:194] Memory required for data: 651690496
I0927 00:20:23.935966 19128 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I0927 00:20:23.935976 19128 net.cpp:128] Creating Layer conv3_3ReLU_1
I0927 00:20:23.935981 19128 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I0927 00:20:23.935986 19128 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I0927 00:20:23.937364 19128 net.cpp:172] Setting up conv3_3ReLU_1
I0927 00:20:23.937381 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.937386 19128 net.cpp:194] Memory required for data: 655884800
I0927 00:20:23.937391 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0927 00:20:23.937403 19128 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0927 00:20:23.937408 19128 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I0927 00:20:23.937415 19128 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0927 00:20:23.937424 19128 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0927 00:20:23.937475 19128 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0927 00:20:23.937484 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.937505 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.937510 19128 net.cpp:194] Memory required for data: 664273408
I0927 00:20:23.937513 19128 layer_factory.hpp:77] Creating layer conv3_4_0
I0927 00:20:23.937526 19128 net.cpp:128] Creating Layer conv3_4_0
I0927 00:20:23.937532 19128 net.cpp:558] conv3_4_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0927 00:20:23.937541 19128 net.cpp:522] conv3_4_0 -> conv3_4_0
I0927 00:20:23.944315 19128 net.cpp:172] Setting up conv3_4_0
I0927 00:20:23.944344 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.944348 19128 net.cpp:194] Memory required for data: 668467712
I0927 00:20:23.944358 19128 layer_factory.hpp:77] Creating layer conv3_4_bn0
I0927 00:20:23.944370 19128 net.cpp:128] Creating Layer conv3_4_bn0
I0927 00:20:23.944375 19128 net.cpp:558] conv3_4_bn0 <- conv3_4_0
I0927 00:20:23.944384 19128 net.cpp:509] conv3_4_bn0 -> conv3_4_0 (in-place)
I0927 00:20:23.944653 19128 net.cpp:172] Setting up conv3_4_bn0
I0927 00:20:23.944664 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.944669 19128 net.cpp:194] Memory required for data: 672662016
I0927 00:20:23.944690 19128 layer_factory.hpp:77] Creating layer conv3_4_scale0
I0927 00:20:23.944700 19128 net.cpp:128] Creating Layer conv3_4_scale0
I0927 00:20:23.944705 19128 net.cpp:558] conv3_4_scale0 <- conv3_4_0
I0927 00:20:23.944711 19128 net.cpp:509] conv3_4_scale0 -> conv3_4_0 (in-place)
I0927 00:20:23.944752 19128 layer_factory.hpp:77] Creating layer conv3_4_scale0
I0927 00:20:23.944898 19128 net.cpp:172] Setting up conv3_4_scale0
I0927 00:20:23.944906 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.944911 19128 net.cpp:194] Memory required for data: 676856320
I0927 00:20:23.944918 19128 layer_factory.hpp:77] Creating layer conv3_4_ReLU0
I0927 00:20:23.944924 19128 net.cpp:128] Creating Layer conv3_4_ReLU0
I0927 00:20:23.944928 19128 net.cpp:558] conv3_4_ReLU0 <- conv3_4_0
I0927 00:20:23.944941 19128 net.cpp:509] conv3_4_ReLU0 -> conv3_4_0 (in-place)
I0927 00:20:23.946125 19128 net.cpp:172] Setting up conv3_4_ReLU0
I0927 00:20:23.946144 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.946149 19128 net.cpp:194] Memory required for data: 681050624
I0927 00:20:23.946153 19128 layer_factory.hpp:77] Creating layer conv3_4_1
I0927 00:20:23.946166 19128 net.cpp:128] Creating Layer conv3_4_1
I0927 00:20:23.946171 19128 net.cpp:558] conv3_4_1 <- conv3_4_0
I0927 00:20:23.946182 19128 net.cpp:522] conv3_4_1 -> conv3_4_1
I0927 00:20:23.952807 19128 net.cpp:172] Setting up conv3_4_1
I0927 00:20:23.952836 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.952841 19128 net.cpp:194] Memory required for data: 685244928
I0927 00:20:23.952850 19128 layer_factory.hpp:77] Creating layer conv3_4bn1
I0927 00:20:23.952859 19128 net.cpp:128] Creating Layer conv3_4bn1
I0927 00:20:23.952864 19128 net.cpp:558] conv3_4bn1 <- conv3_4_1
I0927 00:20:23.952873 19128 net.cpp:509] conv3_4bn1 -> conv3_4_1 (in-place)
I0927 00:20:23.953137 19128 net.cpp:172] Setting up conv3_4bn1
I0927 00:20:23.953150 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.953155 19128 net.cpp:194] Memory required for data: 689439232
I0927 00:20:23.953164 19128 layer_factory.hpp:77] Creating layer conv3_4_scale1
I0927 00:20:23.953171 19128 net.cpp:128] Creating Layer conv3_4_scale1
I0927 00:20:23.953176 19128 net.cpp:558] conv3_4_scale1 <- conv3_4_1
I0927 00:20:23.953181 19128 net.cpp:509] conv3_4_scale1 -> conv3_4_1 (in-place)
I0927 00:20:23.953224 19128 layer_factory.hpp:77] Creating layer conv3_4_scale1
I0927 00:20:23.953372 19128 net.cpp:172] Setting up conv3_4_scale1
I0927 00:20:23.953379 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.953383 19128 net.cpp:194] Memory required for data: 693633536
I0927 00:20:23.953392 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_4
I0927 00:20:23.953400 19128 net.cpp:128] Creating Layer conv3_Eltwise_4
I0927 00:20:23.953405 19128 net.cpp:558] conv3_Eltwise_4 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0927 00:20:23.953428 19128 net.cpp:558] conv3_Eltwise_4 <- conv3_4_1
I0927 00:20:23.953434 19128 net.cpp:522] conv3_Eltwise_4 -> conv3_Eltwise_4
I0927 00:20:23.953457 19128 net.cpp:172] Setting up conv3_Eltwise_4
I0927 00:20:23.953464 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.953469 19128 net.cpp:194] Memory required for data: 697827840
I0927 00:20:23.953474 19128 layer_factory.hpp:77] Creating layer conv3_4ReLU_1
I0927 00:20:23.953483 19128 net.cpp:128] Creating Layer conv3_4ReLU_1
I0927 00:20:23.953488 19128 net.cpp:558] conv3_4ReLU_1 <- conv3_Eltwise_4
I0927 00:20:23.953495 19128 net.cpp:509] conv3_4ReLU_1 -> conv3_Eltwise_4 (in-place)
I0927 00:20:23.954869 19128 net.cpp:172] Setting up conv3_4ReLU_1
I0927 00:20:23.954885 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.954890 19128 net.cpp:194] Memory required for data: 702022144
I0927 00:20:23.954895 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0927 00:20:23.954906 19128 net.cpp:128] Creating Layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0927 00:20:23.954912 19128 net.cpp:558] conv3_Eltwise_4_conv3_4ReLU_1_0_split <- conv3_Eltwise_4
I0927 00:20:23.954921 19128 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I0927 00:20:23.954931 19128 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I0927 00:20:23.954985 19128 net.cpp:172] Setting up conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0927 00:20:23.954993 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.954998 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.955003 19128 net.cpp:194] Memory required for data: 710410752
I0927 00:20:23.955006 19128 layer_factory.hpp:77] Creating layer conv3_5_0
I0927 00:20:23.955019 19128 net.cpp:128] Creating Layer conv3_5_0
I0927 00:20:23.955024 19128 net.cpp:558] conv3_5_0 <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I0927 00:20:23.955034 19128 net.cpp:522] conv3_5_0 -> conv3_5_0
I0927 00:20:23.961598 19128 net.cpp:172] Setting up conv3_5_0
I0927 00:20:23.961627 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.961632 19128 net.cpp:194] Memory required for data: 714605056
I0927 00:20:23.961642 19128 layer_factory.hpp:77] Creating layer conv3_5_bn0
I0927 00:20:23.961652 19128 net.cpp:128] Creating Layer conv3_5_bn0
I0927 00:20:23.961658 19128 net.cpp:558] conv3_5_bn0 <- conv3_5_0
I0927 00:20:23.961668 19128 net.cpp:509] conv3_5_bn0 -> conv3_5_0 (in-place)
I0927 00:20:23.961928 19128 net.cpp:172] Setting up conv3_5_bn0
I0927 00:20:23.961941 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.961946 19128 net.cpp:194] Memory required for data: 718799360
I0927 00:20:23.961956 19128 layer_factory.hpp:77] Creating layer conv3_5_scale0
I0927 00:20:23.961962 19128 net.cpp:128] Creating Layer conv3_5_scale0
I0927 00:20:23.961967 19128 net.cpp:558] conv3_5_scale0 <- conv3_5_0
I0927 00:20:23.961972 19128 net.cpp:509] conv3_5_scale0 -> conv3_5_0 (in-place)
I0927 00:20:23.962018 19128 layer_factory.hpp:77] Creating layer conv3_5_scale0
I0927 00:20:23.962164 19128 net.cpp:172] Setting up conv3_5_scale0
I0927 00:20:23.962172 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.962175 19128 net.cpp:194] Memory required for data: 722993664
I0927 00:20:23.962183 19128 layer_factory.hpp:77] Creating layer conv3_5_ReLU0
I0927 00:20:23.962193 19128 net.cpp:128] Creating Layer conv3_5_ReLU0
I0927 00:20:23.962198 19128 net.cpp:558] conv3_5_ReLU0 <- conv3_5_0
I0927 00:20:23.962203 19128 net.cpp:509] conv3_5_ReLU0 -> conv3_5_0 (in-place)
I0927 00:20:23.963634 19128 net.cpp:172] Setting up conv3_5_ReLU0
I0927 00:20:23.963660 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.963665 19128 net.cpp:194] Memory required for data: 727187968
I0927 00:20:23.963670 19128 layer_factory.hpp:77] Creating layer conv3_5_1
I0927 00:20:23.963686 19128 net.cpp:128] Creating Layer conv3_5_1
I0927 00:20:23.963711 19128 net.cpp:558] conv3_5_1 <- conv3_5_0
I0927 00:20:23.963723 19128 net.cpp:522] conv3_5_1 -> conv3_5_1
I0927 00:20:23.970355 19128 net.cpp:172] Setting up conv3_5_1
I0927 00:20:23.970382 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.970387 19128 net.cpp:194] Memory required for data: 731382272
I0927 00:20:23.970397 19128 layer_factory.hpp:77] Creating layer conv3_5bn1
I0927 00:20:23.970410 19128 net.cpp:128] Creating Layer conv3_5bn1
I0927 00:20:23.970415 19128 net.cpp:558] conv3_5bn1 <- conv3_5_1
I0927 00:20:23.970422 19128 net.cpp:509] conv3_5bn1 -> conv3_5_1 (in-place)
I0927 00:20:23.970688 19128 net.cpp:172] Setting up conv3_5bn1
I0927 00:20:23.970702 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.970706 19128 net.cpp:194] Memory required for data: 735576576
I0927 00:20:23.970716 19128 layer_factory.hpp:77] Creating layer conv3_5_scale1
I0927 00:20:23.970723 19128 net.cpp:128] Creating Layer conv3_5_scale1
I0927 00:20:23.970727 19128 net.cpp:558] conv3_5_scale1 <- conv3_5_1
I0927 00:20:23.970736 19128 net.cpp:509] conv3_5_scale1 -> conv3_5_1 (in-place)
I0927 00:20:23.970777 19128 layer_factory.hpp:77] Creating layer conv3_5_scale1
I0927 00:20:23.970942 19128 net.cpp:172] Setting up conv3_5_scale1
I0927 00:20:23.970954 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.970958 19128 net.cpp:194] Memory required for data: 739770880
I0927 00:20:23.970966 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_5
I0927 00:20:23.970973 19128 net.cpp:128] Creating Layer conv3_Eltwise_5
I0927 00:20:23.970978 19128 net.cpp:558] conv3_Eltwise_5 <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I0927 00:20:23.970983 19128 net.cpp:558] conv3_Eltwise_5 <- conv3_5_1
I0927 00:20:23.970989 19128 net.cpp:522] conv3_Eltwise_5 -> conv3_Eltwise_5
I0927 00:20:23.971015 19128 net.cpp:172] Setting up conv3_Eltwise_5
I0927 00:20:23.971022 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.971026 19128 net.cpp:194] Memory required for data: 743965184
I0927 00:20:23.971031 19128 layer_factory.hpp:77] Creating layer conv3_5ReLU_1
I0927 00:20:23.971037 19128 net.cpp:128] Creating Layer conv3_5ReLU_1
I0927 00:20:23.971041 19128 net.cpp:558] conv3_5ReLU_1 <- conv3_Eltwise_5
I0927 00:20:23.971050 19128 net.cpp:509] conv3_5ReLU_1 -> conv3_Eltwise_5 (in-place)
I0927 00:20:23.972421 19128 net.cpp:172] Setting up conv3_5ReLU_1
I0927 00:20:23.972437 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.972443 19128 net.cpp:194] Memory required for data: 748159488
I0927 00:20:23.972448 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0927 00:20:23.972455 19128 net.cpp:128] Creating Layer conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0927 00:20:23.972460 19128 net.cpp:558] conv3_Eltwise_5_conv3_5ReLU_1_0_split <- conv3_Eltwise_5
I0927 00:20:23.972470 19128 net.cpp:522] conv3_Eltwise_5_conv3_5ReLU_1_0_split -> conv3_Eltwise_5_conv3_5ReLU_1_0_split_0
I0927 00:20:23.972478 19128 net.cpp:522] conv3_Eltwise_5_conv3_5ReLU_1_0_split -> conv3_Eltwise_5_conv3_5ReLU_1_0_split_1
I0927 00:20:23.972532 19128 net.cpp:172] Setting up conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0927 00:20:23.972539 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.972545 19128 net.cpp:186] Top shape: 128 32 16 16 (1048576)
I0927 00:20:23.972549 19128 net.cpp:194] Memory required for data: 756548096
I0927 00:20:23.972553 19128 layer_factory.hpp:77] Creating layer conv4_1_0
I0927 00:20:23.972565 19128 net.cpp:128] Creating Layer conv4_1_0
I0927 00:20:23.972570 19128 net.cpp:558] conv4_1_0 <- conv3_Eltwise_5_conv3_5ReLU_1_0_split_0
I0927 00:20:23.972581 19128 net.cpp:522] conv4_1_0 -> conv4_1_0
I0927 00:20:23.979408 19128 net.cpp:172] Setting up conv4_1_0
I0927 00:20:23.979437 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.979442 19128 net.cpp:194] Memory required for data: 758645248
I0927 00:20:23.979454 19128 layer_factory.hpp:77] Creating layer conv4_1_bn0
I0927 00:20:23.979466 19128 net.cpp:128] Creating Layer conv4_1_bn0
I0927 00:20:23.979492 19128 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I0927 00:20:23.979502 19128 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I0927 00:20:23.979784 19128 net.cpp:172] Setting up conv4_1_bn0
I0927 00:20:23.979799 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.979802 19128 net.cpp:194] Memory required for data: 760742400
I0927 00:20:23.979812 19128 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0927 00:20:23.979822 19128 net.cpp:128] Creating Layer conv4_1_scale0
I0927 00:20:23.979827 19128 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I0927 00:20:23.979833 19128 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I0927 00:20:23.979877 19128 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0927 00:20:23.980036 19128 net.cpp:172] Setting up conv4_1_scale0
I0927 00:20:23.980048 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.980052 19128 net.cpp:194] Memory required for data: 762839552
I0927 00:20:23.980060 19128 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I0927 00:20:23.980067 19128 net.cpp:128] Creating Layer conv4_1_ReLU0
I0927 00:20:23.980072 19128 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I0927 00:20:23.980079 19128 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I0927 00:20:23.981214 19128 net.cpp:172] Setting up conv4_1_ReLU0
I0927 00:20:23.981231 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.981236 19128 net.cpp:194] Memory required for data: 764936704
I0927 00:20:23.981240 19128 layer_factory.hpp:77] Creating layer conv4_1_1
I0927 00:20:23.981254 19128 net.cpp:128] Creating Layer conv4_1_1
I0927 00:20:23.981259 19128 net.cpp:558] conv4_1_1 <- conv4_1_0
I0927 00:20:23.981274 19128 net.cpp:522] conv4_1_1 -> conv4_1_1
I0927 00:20:23.988190 19128 net.cpp:172] Setting up conv4_1_1
I0927 00:20:23.988220 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.988225 19128 net.cpp:194] Memory required for data: 767033856
I0927 00:20:23.988235 19128 layer_factory.hpp:77] Creating layer conv4_1bn1
I0927 00:20:23.988245 19128 net.cpp:128] Creating Layer conv4_1bn1
I0927 00:20:23.988250 19128 net.cpp:558] conv4_1bn1 <- conv4_1_1
I0927 00:20:23.988260 19128 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I0927 00:20:23.988553 19128 net.cpp:172] Setting up conv4_1bn1
I0927 00:20:23.988565 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.988569 19128 net.cpp:194] Memory required for data: 769131008
I0927 00:20:23.988579 19128 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0927 00:20:23.988586 19128 net.cpp:128] Creating Layer conv4_1_scale1
I0927 00:20:23.988591 19128 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I0927 00:20:23.988600 19128 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I0927 00:20:23.988641 19128 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0927 00:20:23.988798 19128 net.cpp:172] Setting up conv4_1_scale1
I0927 00:20:23.988809 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.988813 19128 net.cpp:194] Memory required for data: 771228160
I0927 00:20:23.988821 19128 layer_factory.hpp:77] Creating layer conv4_1_down
I0927 00:20:23.988833 19128 net.cpp:128] Creating Layer conv4_1_down
I0927 00:20:23.988843 19128 net.cpp:558] conv4_1_down <- conv3_Eltwise_5_conv3_5ReLU_1_0_split_1
I0927 00:20:23.988852 19128 net.cpp:522] conv4_1_down -> conv4_1_down
I0927 00:20:23.994570 19128 net.cpp:172] Setting up conv4_1_down
I0927 00:20:23.994596 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.994601 19128 net.cpp:194] Memory required for data: 773325312
I0927 00:20:23.994611 19128 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I0927 00:20:23.994622 19128 net.cpp:128] Creating Layer conv4_1_bn_down
I0927 00:20:23.994627 19128 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I0927 00:20:23.994637 19128 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I0927 00:20:23.994916 19128 net.cpp:172] Setting up conv4_1_bn_down
I0927 00:20:23.994928 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.994932 19128 net.cpp:194] Memory required for data: 775422464
I0927 00:20:23.994961 19128 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0927 00:20:23.994971 19128 net.cpp:128] Creating Layer conv4_1_scale_down
I0927 00:20:23.994976 19128 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I0927 00:20:23.994982 19128 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I0927 00:20:23.995026 19128 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0927 00:20:23.995182 19128 net.cpp:172] Setting up conv4_1_scale_down
I0927 00:20:23.995193 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.995198 19128 net.cpp:194] Memory required for data: 777519616
I0927 00:20:23.995205 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I0927 00:20:23.995215 19128 net.cpp:128] Creating Layer conv4_Eltwise_1
I0927 00:20:23.995220 19128 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I0927 00:20:23.995225 19128 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I0927 00:20:23.995234 19128 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I0927 00:20:23.995256 19128 net.cpp:172] Setting up conv4_Eltwise_1
I0927 00:20:23.995263 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.995267 19128 net.cpp:194] Memory required for data: 779616768
I0927 00:20:23.995272 19128 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I0927 00:20:23.995278 19128 net.cpp:128] Creating Layer conv4_1ReLU_1
I0927 00:20:23.995283 19128 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I0927 00:20:23.995291 19128 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I0927 00:20:23.996598 19128 net.cpp:172] Setting up conv4_1ReLU_1
I0927 00:20:23.996623 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.996628 19128 net.cpp:194] Memory required for data: 781713920
I0927 00:20:23.996634 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0927 00:20:23.996644 19128 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0927 00:20:23.996654 19128 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I0927 00:20:23.996661 19128 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0927 00:20:23.996670 19128 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0927 00:20:23.996728 19128 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0927 00:20:23.996735 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.996742 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:23.996745 19128 net.cpp:194] Memory required for data: 785908224
I0927 00:20:23.996749 19128 layer_factory.hpp:77] Creating layer conv4_2_0
I0927 00:20:23.996762 19128 net.cpp:128] Creating Layer conv4_2_0
I0927 00:20:23.996767 19128 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0927 00:20:23.996776 19128 net.cpp:522] conv4_2_0 -> conv4_2_0
I0927 00:20:24.003336 19128 net.cpp:172] Setting up conv4_2_0
I0927 00:20:24.003362 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.003367 19128 net.cpp:194] Memory required for data: 788005376
I0927 00:20:24.003377 19128 layer_factory.hpp:77] Creating layer conv4_2_bn0
I0927 00:20:24.003388 19128 net.cpp:128] Creating Layer conv4_2_bn0
I0927 00:20:24.003394 19128 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I0927 00:20:24.003401 19128 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I0927 00:20:24.003679 19128 net.cpp:172] Setting up conv4_2_bn0
I0927 00:20:24.003690 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.003696 19128 net.cpp:194] Memory required for data: 790102528
I0927 00:20:24.003706 19128 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0927 00:20:24.003716 19128 net.cpp:128] Creating Layer conv4_2_scale0
I0927 00:20:24.003721 19128 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I0927 00:20:24.003726 19128 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I0927 00:20:24.003769 19128 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0927 00:20:24.003922 19128 net.cpp:172] Setting up conv4_2_scale0
I0927 00:20:24.003929 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.003952 19128 net.cpp:194] Memory required for data: 792199680
I0927 00:20:24.003960 19128 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I0927 00:20:24.003969 19128 net.cpp:128] Creating Layer conv4_2_ReLU0
I0927 00:20:24.003974 19128 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I0927 00:20:24.003979 19128 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I0927 00:20:24.005394 19128 net.cpp:172] Setting up conv4_2_ReLU0
I0927 00:20:24.005414 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.005419 19128 net.cpp:194] Memory required for data: 794296832
I0927 00:20:24.005422 19128 layer_factory.hpp:77] Creating layer conv4_2_1
I0927 00:20:24.005439 19128 net.cpp:128] Creating Layer conv4_2_1
I0927 00:20:24.005445 19128 net.cpp:558] conv4_2_1 <- conv4_2_0
I0927 00:20:24.005452 19128 net.cpp:522] conv4_2_1 -> conv4_2_1
I0927 00:20:24.012377 19128 net.cpp:172] Setting up conv4_2_1
I0927 00:20:24.012404 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.012409 19128 net.cpp:194] Memory required for data: 796393984
I0927 00:20:24.012419 19128 layer_factory.hpp:77] Creating layer conv4_2bn1
I0927 00:20:24.012431 19128 net.cpp:128] Creating Layer conv4_2bn1
I0927 00:20:24.012437 19128 net.cpp:558] conv4_2bn1 <- conv4_2_1
I0927 00:20:24.012449 19128 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I0927 00:20:24.012733 19128 net.cpp:172] Setting up conv4_2bn1
I0927 00:20:24.012747 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.012750 19128 net.cpp:194] Memory required for data: 798491136
I0927 00:20:24.012760 19128 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0927 00:20:24.012778 19128 net.cpp:128] Creating Layer conv4_2_scale1
I0927 00:20:24.012784 19128 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I0927 00:20:24.012789 19128 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I0927 00:20:24.012832 19128 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0927 00:20:24.012989 19128 net.cpp:172] Setting up conv4_2_scale1
I0927 00:20:24.012996 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.013000 19128 net.cpp:194] Memory required for data: 800588288
I0927 00:20:24.013010 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I0927 00:20:24.013015 19128 net.cpp:128] Creating Layer conv4_Eltwise_2
I0927 00:20:24.013020 19128 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0927 00:20:24.013025 19128 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I0927 00:20:24.013031 19128 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I0927 00:20:24.013061 19128 net.cpp:172] Setting up conv4_Eltwise_2
I0927 00:20:24.013069 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.013073 19128 net.cpp:194] Memory required for data: 802685440
I0927 00:20:24.013077 19128 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I0927 00:20:24.013083 19128 net.cpp:128] Creating Layer conv4_2ReLU_1
I0927 00:20:24.013087 19128 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I0927 00:20:24.013093 19128 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I0927 00:20:24.013347 19128 net.cpp:172] Setting up conv4_2ReLU_1
I0927 00:20:24.013358 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.013363 19128 net.cpp:194] Memory required for data: 804782592
I0927 00:20:24.013367 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0927 00:20:24.013375 19128 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0927 00:20:24.013379 19128 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I0927 00:20:24.013389 19128 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0927 00:20:24.013397 19128 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0927 00:20:24.013453 19128 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0927 00:20:24.013460 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.013466 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.013485 19128 net.cpp:194] Memory required for data: 808976896
I0927 00:20:24.013490 19128 layer_factory.hpp:77] Creating layer conv4_3_0
I0927 00:20:24.013502 19128 net.cpp:128] Creating Layer conv4_3_0
I0927 00:20:24.013507 19128 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0927 00:20:24.013516 19128 net.cpp:522] conv4_3_0 -> conv4_3_0
I0927 00:20:24.015941 19128 net.cpp:172] Setting up conv4_3_0
I0927 00:20:24.015970 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.015975 19128 net.cpp:194] Memory required for data: 811074048
I0927 00:20:24.015985 19128 layer_factory.hpp:77] Creating layer conv4_3_bn0
I0927 00:20:24.015998 19128 net.cpp:128] Creating Layer conv4_3_bn0
I0927 00:20:24.016003 19128 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I0927 00:20:24.016010 19128 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I0927 00:20:24.016286 19128 net.cpp:172] Setting up conv4_3_bn0
I0927 00:20:24.016299 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.016304 19128 net.cpp:194] Memory required for data: 813171200
I0927 00:20:24.016314 19128 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0927 00:20:24.016321 19128 net.cpp:128] Creating Layer conv4_3_scale0
I0927 00:20:24.016325 19128 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I0927 00:20:24.016331 19128 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I0927 00:20:24.016376 19128 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0927 00:20:24.016537 19128 net.cpp:172] Setting up conv4_3_scale0
I0927 00:20:24.016548 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.016553 19128 net.cpp:194] Memory required for data: 815268352
I0927 00:20:24.016561 19128 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I0927 00:20:24.016571 19128 net.cpp:128] Creating Layer conv4_3_ReLU0
I0927 00:20:24.016575 19128 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I0927 00:20:24.016582 19128 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I0927 00:20:24.017081 19128 net.cpp:172] Setting up conv4_3_ReLU0
I0927 00:20:24.017103 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.017107 19128 net.cpp:194] Memory required for data: 817365504
I0927 00:20:24.017112 19128 layer_factory.hpp:77] Creating layer conv4_3_1
I0927 00:20:24.017129 19128 net.cpp:128] Creating Layer conv4_3_1
I0927 00:20:24.017138 19128 net.cpp:558] conv4_3_1 <- conv4_3_0
I0927 00:20:24.017146 19128 net.cpp:522] conv4_3_1 -> conv4_3_1
I0927 00:20:24.023128 19128 net.cpp:172] Setting up conv4_3_1
I0927 00:20:24.023159 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.023164 19128 net.cpp:194] Memory required for data: 819462656
I0927 00:20:24.023177 19128 layer_factory.hpp:77] Creating layer conv4_3bn1
I0927 00:20:24.023190 19128 net.cpp:128] Creating Layer conv4_3bn1
I0927 00:20:24.023196 19128 net.cpp:558] conv4_3bn1 <- conv4_3_1
I0927 00:20:24.023203 19128 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I0927 00:20:24.023612 19128 net.cpp:172] Setting up conv4_3bn1
I0927 00:20:24.023624 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.023630 19128 net.cpp:194] Memory required for data: 821559808
I0927 00:20:24.023641 19128 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0927 00:20:24.023650 19128 net.cpp:128] Creating Layer conv4_3_scale1
I0927 00:20:24.023654 19128 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I0927 00:20:24.023663 19128 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I0927 00:20:24.023710 19128 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0927 00:20:24.023870 19128 net.cpp:172] Setting up conv4_3_scale1
I0927 00:20:24.023886 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.023891 19128 net.cpp:194] Memory required for data: 823656960
I0927 00:20:24.023900 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I0927 00:20:24.023908 19128 net.cpp:128] Creating Layer conv4_Eltwise_3
I0927 00:20:24.023914 19128 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0927 00:20:24.023919 19128 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I0927 00:20:24.023928 19128 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I0927 00:20:24.023977 19128 net.cpp:172] Setting up conv4_Eltwise_3
I0927 00:20:24.023986 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.023990 19128 net.cpp:194] Memory required for data: 825754112
I0927 00:20:24.023994 19128 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I0927 00:20:24.024003 19128 net.cpp:128] Creating Layer conv4_3ReLU_1
I0927 00:20:24.024006 19128 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I0927 00:20:24.024015 19128 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I0927 00:20:24.024909 19128 net.cpp:172] Setting up conv4_3ReLU_1
I0927 00:20:24.024924 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.024930 19128 net.cpp:194] Memory required for data: 827851264
I0927 00:20:24.024935 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0927 00:20:24.024942 19128 net.cpp:128] Creating Layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0927 00:20:24.024946 19128 net.cpp:558] conv4_Eltwise_3_conv4_3ReLU_1_0_split <- conv4_Eltwise_3
I0927 00:20:24.024956 19128 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I0927 00:20:24.024966 19128 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I0927 00:20:24.025024 19128 net.cpp:172] Setting up conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0927 00:20:24.025035 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.025041 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.025045 19128 net.cpp:194] Memory required for data: 832045568
I0927 00:20:24.025049 19128 layer_factory.hpp:77] Creating layer conv4_4_0
I0927 00:20:24.025063 19128 net.cpp:128] Creating Layer conv4_4_0
I0927 00:20:24.025068 19128 net.cpp:558] conv4_4_0 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I0927 00:20:24.025079 19128 net.cpp:522] conv4_4_0 -> conv4_4_0
I0927 00:20:24.031678 19128 net.cpp:172] Setting up conv4_4_0
I0927 00:20:24.031705 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.031710 19128 net.cpp:194] Memory required for data: 834142720
I0927 00:20:24.031724 19128 layer_factory.hpp:77] Creating layer conv4_4_bn0
I0927 00:20:24.031739 19128 net.cpp:128] Creating Layer conv4_4_bn0
I0927 00:20:24.031749 19128 net.cpp:558] conv4_4_bn0 <- conv4_4_0
I0927 00:20:24.031756 19128 net.cpp:509] conv4_4_bn0 -> conv4_4_0 (in-place)
I0927 00:20:24.032042 19128 net.cpp:172] Setting up conv4_4_bn0
I0927 00:20:24.032053 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.032058 19128 net.cpp:194] Memory required for data: 836239872
I0927 00:20:24.032068 19128 layer_factory.hpp:77] Creating layer conv4_4_scale0
I0927 00:20:24.032078 19128 net.cpp:128] Creating Layer conv4_4_scale0
I0927 00:20:24.032083 19128 net.cpp:558] conv4_4_scale0 <- conv4_4_0
I0927 00:20:24.032088 19128 net.cpp:509] conv4_4_scale0 -> conv4_4_0 (in-place)
I0927 00:20:24.032135 19128 layer_factory.hpp:77] Creating layer conv4_4_scale0
I0927 00:20:24.032299 19128 net.cpp:172] Setting up conv4_4_scale0
I0927 00:20:24.032310 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.032315 19128 net.cpp:194] Memory required for data: 838337024
I0927 00:20:24.032322 19128 layer_factory.hpp:77] Creating layer conv4_4_ReLU0
I0927 00:20:24.032331 19128 net.cpp:128] Creating Layer conv4_4_ReLU0
I0927 00:20:24.032336 19128 net.cpp:558] conv4_4_ReLU0 <- conv4_4_0
I0927 00:20:24.032342 19128 net.cpp:509] conv4_4_ReLU0 -> conv4_4_0 (in-place)
I0927 00:20:24.033735 19128 net.cpp:172] Setting up conv4_4_ReLU0
I0927 00:20:24.033753 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.033758 19128 net.cpp:194] Memory required for data: 840434176
I0927 00:20:24.033763 19128 layer_factory.hpp:77] Creating layer conv4_4_1
I0927 00:20:24.033784 19128 net.cpp:128] Creating Layer conv4_4_1
I0927 00:20:24.033797 19128 net.cpp:558] conv4_4_1 <- conv4_4_0
I0927 00:20:24.033804 19128 net.cpp:522] conv4_4_1 -> conv4_4_1
I0927 00:20:24.040730 19128 net.cpp:172] Setting up conv4_4_1
I0927 00:20:24.040773 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.040778 19128 net.cpp:194] Memory required for data: 842531328
I0927 00:20:24.040792 19128 layer_factory.hpp:77] Creating layer conv4_4bn1
I0927 00:20:24.040804 19128 net.cpp:128] Creating Layer conv4_4bn1
I0927 00:20:24.040817 19128 net.cpp:558] conv4_4bn1 <- conv4_4_1
I0927 00:20:24.040827 19128 net.cpp:509] conv4_4bn1 -> conv4_4_1 (in-place)
I0927 00:20:24.041123 19128 net.cpp:172] Setting up conv4_4bn1
I0927 00:20:24.041136 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.041141 19128 net.cpp:194] Memory required for data: 844628480
I0927 00:20:24.041152 19128 layer_factory.hpp:77] Creating layer conv4_4_scale1
I0927 00:20:24.041158 19128 net.cpp:128] Creating Layer conv4_4_scale1
I0927 00:20:24.041162 19128 net.cpp:558] conv4_4_scale1 <- conv4_4_1
I0927 00:20:24.041170 19128 net.cpp:509] conv4_4_scale1 -> conv4_4_1 (in-place)
I0927 00:20:24.041216 19128 layer_factory.hpp:77] Creating layer conv4_4_scale1
I0927 00:20:24.041378 19128 net.cpp:172] Setting up conv4_4_scale1
I0927 00:20:24.041391 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.041396 19128 net.cpp:194] Memory required for data: 846725632
I0927 00:20:24.041405 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_4
I0927 00:20:24.041412 19128 net.cpp:128] Creating Layer conv4_Eltwise_4
I0927 00:20:24.041417 19128 net.cpp:558] conv4_Eltwise_4 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I0927 00:20:24.041422 19128 net.cpp:558] conv4_Eltwise_4 <- conv4_4_1
I0927 00:20:24.041431 19128 net.cpp:522] conv4_Eltwise_4 -> conv4_Eltwise_4
I0927 00:20:24.041455 19128 net.cpp:172] Setting up conv4_Eltwise_4
I0927 00:20:24.041462 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.041466 19128 net.cpp:194] Memory required for data: 848822784
I0927 00:20:24.041471 19128 layer_factory.hpp:77] Creating layer conv4_4ReLU_1
I0927 00:20:24.041479 19128 net.cpp:128] Creating Layer conv4_4ReLU_1
I0927 00:20:24.041484 19128 net.cpp:558] conv4_4ReLU_1 <- conv4_Eltwise_4
I0927 00:20:24.041489 19128 net.cpp:509] conv4_4ReLU_1 -> conv4_Eltwise_4 (in-place)
I0927 00:20:24.042511 19128 net.cpp:172] Setting up conv4_4ReLU_1
I0927 00:20:24.042527 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.042532 19128 net.cpp:194] Memory required for data: 850919936
I0927 00:20:24.042537 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0927 00:20:24.042547 19128 net.cpp:128] Creating Layer conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0927 00:20:24.042552 19128 net.cpp:558] conv4_Eltwise_4_conv4_4ReLU_1_0_split <- conv4_Eltwise_4
I0927 00:20:24.042560 19128 net.cpp:522] conv4_Eltwise_4_conv4_4ReLU_1_0_split -> conv4_Eltwise_4_conv4_4ReLU_1_0_split_0
I0927 00:20:24.042568 19128 net.cpp:522] conv4_Eltwise_4_conv4_4ReLU_1_0_split -> conv4_Eltwise_4_conv4_4ReLU_1_0_split_1
I0927 00:20:24.042627 19128 net.cpp:172] Setting up conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0927 00:20:24.042635 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.042641 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.042645 19128 net.cpp:194] Memory required for data: 855114240
I0927 00:20:24.042649 19128 layer_factory.hpp:77] Creating layer conv4_5_0
I0927 00:20:24.042661 19128 net.cpp:128] Creating Layer conv4_5_0
I0927 00:20:24.042670 19128 net.cpp:558] conv4_5_0 <- conv4_Eltwise_4_conv4_4ReLU_1_0_split_0
I0927 00:20:24.042676 19128 net.cpp:522] conv4_5_0 -> conv4_5_0
I0927 00:20:24.049260 19128 net.cpp:172] Setting up conv4_5_0
I0927 00:20:24.049288 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.049291 19128 net.cpp:194] Memory required for data: 857211392
I0927 00:20:24.049301 19128 layer_factory.hpp:77] Creating layer conv4_5_bn0
I0927 00:20:24.049314 19128 net.cpp:128] Creating Layer conv4_5_bn0
I0927 00:20:24.049319 19128 net.cpp:558] conv4_5_bn0 <- conv4_5_0
I0927 00:20:24.049329 19128 net.cpp:509] conv4_5_bn0 -> conv4_5_0 (in-place)
I0927 00:20:24.049616 19128 net.cpp:172] Setting up conv4_5_bn0
I0927 00:20:24.049644 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.049649 19128 net.cpp:194] Memory required for data: 859308544
I0927 00:20:24.049659 19128 layer_factory.hpp:77] Creating layer conv4_5_scale0
I0927 00:20:24.049674 19128 net.cpp:128] Creating Layer conv4_5_scale0
I0927 00:20:24.049679 19128 net.cpp:558] conv4_5_scale0 <- conv4_5_0
I0927 00:20:24.049685 19128 net.cpp:509] conv4_5_scale0 -> conv4_5_0 (in-place)
I0927 00:20:24.049731 19128 layer_factory.hpp:77] Creating layer conv4_5_scale0
I0927 00:20:24.049895 19128 net.cpp:172] Setting up conv4_5_scale0
I0927 00:20:24.049901 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.049906 19128 net.cpp:194] Memory required for data: 861405696
I0927 00:20:24.049914 19128 layer_factory.hpp:77] Creating layer conv4_5_ReLU0
I0927 00:20:24.049923 19128 net.cpp:128] Creating Layer conv4_5_ReLU0
I0927 00:20:24.049928 19128 net.cpp:558] conv4_5_ReLU0 <- conv4_5_0
I0927 00:20:24.049937 19128 net.cpp:509] conv4_5_ReLU0 -> conv4_5_0 (in-place)
I0927 00:20:24.051326 19128 net.cpp:172] Setting up conv4_5_ReLU0
I0927 00:20:24.051352 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.051355 19128 net.cpp:194] Memory required for data: 863502848
I0927 00:20:24.051360 19128 layer_factory.hpp:77] Creating layer conv4_5_1
I0927 00:20:24.051375 19128 net.cpp:128] Creating Layer conv4_5_1
I0927 00:20:24.051381 19128 net.cpp:558] conv4_5_1 <- conv4_5_0
I0927 00:20:24.051393 19128 net.cpp:522] conv4_5_1 -> conv4_5_1
I0927 00:20:24.058401 19128 net.cpp:172] Setting up conv4_5_1
I0927 00:20:24.058429 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.058434 19128 net.cpp:194] Memory required for data: 865600000
I0927 00:20:24.058444 19128 layer_factory.hpp:77] Creating layer conv4_5bn1
I0927 00:20:24.058455 19128 net.cpp:128] Creating Layer conv4_5bn1
I0927 00:20:24.058461 19128 net.cpp:558] conv4_5bn1 <- conv4_5_1
I0927 00:20:24.058470 19128 net.cpp:509] conv4_5bn1 -> conv4_5_1 (in-place)
I0927 00:20:24.058770 19128 net.cpp:172] Setting up conv4_5bn1
I0927 00:20:24.058784 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.058789 19128 net.cpp:194] Memory required for data: 867697152
I0927 00:20:24.058799 19128 layer_factory.hpp:77] Creating layer conv4_5_scale1
I0927 00:20:24.058805 19128 net.cpp:128] Creating Layer conv4_5_scale1
I0927 00:20:24.058817 19128 net.cpp:558] conv4_5_scale1 <- conv4_5_1
I0927 00:20:24.058827 19128 net.cpp:509] conv4_5_scale1 -> conv4_5_1 (in-place)
I0927 00:20:24.058871 19128 layer_factory.hpp:77] Creating layer conv4_5_scale1
I0927 00:20:24.059038 19128 net.cpp:172] Setting up conv4_5_scale1
I0927 00:20:24.059046 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.059051 19128 net.cpp:194] Memory required for data: 869794304
I0927 00:20:24.059058 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_5
I0927 00:20:24.059067 19128 net.cpp:128] Creating Layer conv4_Eltwise_5
I0927 00:20:24.059072 19128 net.cpp:558] conv4_Eltwise_5 <- conv4_Eltwise_4_conv4_4ReLU_1_0_split_1
I0927 00:20:24.059077 19128 net.cpp:558] conv4_Eltwise_5 <- conv4_5_1
I0927 00:20:24.059085 19128 net.cpp:522] conv4_Eltwise_5 -> conv4_Eltwise_5
I0927 00:20:24.059109 19128 net.cpp:172] Setting up conv4_Eltwise_5
I0927 00:20:24.059116 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.059120 19128 net.cpp:194] Memory required for data: 871891456
I0927 00:20:24.059124 19128 layer_factory.hpp:77] Creating layer conv4_5ReLU_1
I0927 00:20:24.059134 19128 net.cpp:128] Creating Layer conv4_5ReLU_1
I0927 00:20:24.059139 19128 net.cpp:558] conv4_5ReLU_1 <- conv4_Eltwise_5
I0927 00:20:24.059144 19128 net.cpp:509] conv4_5ReLU_1 -> conv4_Eltwise_5 (in-place)
I0927 00:20:24.060118 19128 net.cpp:172] Setting up conv4_5ReLU_1
I0927 00:20:24.060134 19128 net.cpp:186] Top shape: 128 64 8 8 (524288)
I0927 00:20:24.060139 19128 net.cpp:194] Memory required for data: 873988608
I0927 00:20:24.060144 19128 layer_factory.hpp:77] Creating layer Pooling1
I0927 00:20:24.060155 19128 net.cpp:128] Creating Layer Pooling1
I0927 00:20:24.060178 19128 net.cpp:558] Pooling1 <- conv4_Eltwise_5
I0927 00:20:24.060186 19128 net.cpp:522] Pooling1 -> Pooling1
I0927 00:20:24.060811 19128 net.cpp:172] Setting up Pooling1
I0927 00:20:24.060828 19128 net.cpp:186] Top shape: 128 64 1 1 (8192)
I0927 00:20:24.060832 19128 net.cpp:194] Memory required for data: 874021376
I0927 00:20:24.060837 19128 layer_factory.hpp:77] Creating layer fc1
I0927 00:20:24.060850 19128 net.cpp:128] Creating Layer fc1
I0927 00:20:24.060855 19128 net.cpp:558] fc1 <- Pooling1
I0927 00:20:24.060865 19128 net.cpp:522] fc1 -> fc1
I0927 00:20:24.061041 19128 net.cpp:172] Setting up fc1
I0927 00:20:24.061053 19128 net.cpp:186] Top shape: 128 10 (1280)
I0927 00:20:24.061058 19128 net.cpp:194] Memory required for data: 874026496
I0927 00:20:24.061066 19128 layer_factory.hpp:77] Creating layer Softmax1
I0927 00:20:24.061074 19128 net.cpp:128] Creating Layer Softmax1
I0927 00:20:24.061079 19128 net.cpp:558] Softmax1 <- fc1
I0927 00:20:24.061084 19128 net.cpp:558] Softmax1 <- label
I0927 00:20:24.061090 19128 net.cpp:522] Softmax1 -> Softmax1
I0927 00:20:24.061100 19128 layer_factory.hpp:77] Creating layer Softmax1
I0927 00:20:24.061739 19128 net.cpp:172] Setting up Softmax1
I0927 00:20:24.061761 19128 net.cpp:186] Top shape: (1)
I0927 00:20:24.061766 19128 net.cpp:189]     with loss weight 1
I0927 00:20:24.061794 19128 net.cpp:194] Memory required for data: 874026500
I0927 00:20:24.061800 19128 net.cpp:301] Softmax1 needs backward computation.
I0927 00:20:24.061805 19128 net.cpp:301] fc1 needs backward computation.
I0927 00:20:24.061810 19128 net.cpp:301] Pooling1 needs backward computation.
I0927 00:20:24.061815 19128 net.cpp:301] conv4_5ReLU_1 needs backward computation.
I0927 00:20:24.061818 19128 net.cpp:301] conv4_Eltwise_5 needs backward computation.
I0927 00:20:24.061823 19128 net.cpp:301] conv4_5_scale1 needs backward computation.
I0927 00:20:24.061827 19128 net.cpp:301] conv4_5bn1 needs backward computation.
I0927 00:20:24.061831 19128 net.cpp:301] conv4_5_1 needs backward computation.
I0927 00:20:24.061836 19128 net.cpp:301] conv4_5_ReLU0 needs backward computation.
I0927 00:20:24.061841 19128 net.cpp:301] conv4_5_scale0 needs backward computation.
I0927 00:20:24.061844 19128 net.cpp:301] conv4_5_bn0 needs backward computation.
I0927 00:20:24.061848 19128 net.cpp:301] conv4_5_0 needs backward computation.
I0927 00:20:24.061853 19128 net.cpp:301] conv4_Eltwise_4_conv4_4ReLU_1_0_split needs backward computation.
I0927 00:20:24.061857 19128 net.cpp:301] conv4_4ReLU_1 needs backward computation.
I0927 00:20:24.061861 19128 net.cpp:301] conv4_Eltwise_4 needs backward computation.
I0927 00:20:24.061866 19128 net.cpp:301] conv4_4_scale1 needs backward computation.
I0927 00:20:24.061870 19128 net.cpp:301] conv4_4bn1 needs backward computation.
I0927 00:20:24.061874 19128 net.cpp:301] conv4_4_1 needs backward computation.
I0927 00:20:24.061878 19128 net.cpp:301] conv4_4_ReLU0 needs backward computation.
I0927 00:20:24.061883 19128 net.cpp:301] conv4_4_scale0 needs backward computation.
I0927 00:20:24.061887 19128 net.cpp:301] conv4_4_bn0 needs backward computation.
I0927 00:20:24.061890 19128 net.cpp:301] conv4_4_0 needs backward computation.
I0927 00:20:24.061895 19128 net.cpp:301] conv4_Eltwise_3_conv4_3ReLU_1_0_split needs backward computation.
I0927 00:20:24.061899 19128 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I0927 00:20:24.061904 19128 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I0927 00:20:24.061909 19128 net.cpp:301] conv4_3_scale1 needs backward computation.
I0927 00:20:24.061913 19128 net.cpp:301] conv4_3bn1 needs backward computation.
I0927 00:20:24.061918 19128 net.cpp:301] conv4_3_1 needs backward computation.
I0927 00:20:24.061921 19128 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I0927 00:20:24.061926 19128 net.cpp:301] conv4_3_scale0 needs backward computation.
I0927 00:20:24.061930 19128 net.cpp:301] conv4_3_bn0 needs backward computation.
I0927 00:20:24.061935 19128 net.cpp:301] conv4_3_0 needs backward computation.
I0927 00:20:24.061956 19128 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I0927 00:20:24.061964 19128 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I0927 00:20:24.061969 19128 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I0927 00:20:24.061975 19128 net.cpp:301] conv4_2_scale1 needs backward computation.
I0927 00:20:24.061980 19128 net.cpp:301] conv4_2bn1 needs backward computation.
I0927 00:20:24.061983 19128 net.cpp:301] conv4_2_1 needs backward computation.
I0927 00:20:24.061988 19128 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I0927 00:20:24.061992 19128 net.cpp:301] conv4_2_scale0 needs backward computation.
I0927 00:20:24.061997 19128 net.cpp:301] conv4_2_bn0 needs backward computation.
I0927 00:20:24.062001 19128 net.cpp:301] conv4_2_0 needs backward computation.
I0927 00:20:24.062007 19128 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I0927 00:20:24.062012 19128 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I0927 00:20:24.062016 19128 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I0927 00:20:24.062021 19128 net.cpp:301] conv4_1_scale_down needs backward computation.
I0927 00:20:24.062026 19128 net.cpp:301] conv4_1_bn_down needs backward computation.
I0927 00:20:24.062031 19128 net.cpp:301] conv4_1_down needs backward computation.
I0927 00:20:24.062036 19128 net.cpp:301] conv4_1_scale1 needs backward computation.
I0927 00:20:24.062041 19128 net.cpp:301] conv4_1bn1 needs backward computation.
I0927 00:20:24.062044 19128 net.cpp:301] conv4_1_1 needs backward computation.
I0927 00:20:24.062049 19128 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I0927 00:20:24.062053 19128 net.cpp:301] conv4_1_scale0 needs backward computation.
I0927 00:20:24.062058 19128 net.cpp:301] conv4_1_bn0 needs backward computation.
I0927 00:20:24.062062 19128 net.cpp:301] conv4_1_0 needs backward computation.
I0927 00:20:24.062067 19128 net.cpp:301] conv3_Eltwise_5_conv3_5ReLU_1_0_split needs backward computation.
I0927 00:20:24.062072 19128 net.cpp:301] conv3_5ReLU_1 needs backward computation.
I0927 00:20:24.062077 19128 net.cpp:301] conv3_Eltwise_5 needs backward computation.
I0927 00:20:24.062083 19128 net.cpp:301] conv3_5_scale1 needs backward computation.
I0927 00:20:24.062088 19128 net.cpp:301] conv3_5bn1 needs backward computation.
I0927 00:20:24.062091 19128 net.cpp:301] conv3_5_1 needs backward computation.
I0927 00:20:24.062096 19128 net.cpp:301] conv3_5_ReLU0 needs backward computation.
I0927 00:20:24.062101 19128 net.cpp:301] conv3_5_scale0 needs backward computation.
I0927 00:20:24.062105 19128 net.cpp:301] conv3_5_bn0 needs backward computation.
I0927 00:20:24.062109 19128 net.cpp:301] conv3_5_0 needs backward computation.
I0927 00:20:24.062114 19128 net.cpp:301] conv3_Eltwise_4_conv3_4ReLU_1_0_split needs backward computation.
I0927 00:20:24.062119 19128 net.cpp:301] conv3_4ReLU_1 needs backward computation.
I0927 00:20:24.062124 19128 net.cpp:301] conv3_Eltwise_4 needs backward computation.
I0927 00:20:24.062132 19128 net.cpp:301] conv3_4_scale1 needs backward computation.
I0927 00:20:24.062137 19128 net.cpp:301] conv3_4bn1 needs backward computation.
I0927 00:20:24.062141 19128 net.cpp:301] conv3_4_1 needs backward computation.
I0927 00:20:24.062146 19128 net.cpp:301] conv3_4_ReLU0 needs backward computation.
I0927 00:20:24.062151 19128 net.cpp:301] conv3_4_scale0 needs backward computation.
I0927 00:20:24.062155 19128 net.cpp:301] conv3_4_bn0 needs backward computation.
I0927 00:20:24.062160 19128 net.cpp:301] conv3_4_0 needs backward computation.
I0927 00:20:24.062165 19128 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I0927 00:20:24.062170 19128 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I0927 00:20:24.062175 19128 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I0927 00:20:24.062180 19128 net.cpp:301] conv3_3_scale1 needs backward computation.
I0927 00:20:24.062186 19128 net.cpp:301] conv3_3bn1 needs backward computation.
I0927 00:20:24.062189 19128 net.cpp:301] conv3_3_1 needs backward computation.
I0927 00:20:24.062201 19128 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I0927 00:20:24.062206 19128 net.cpp:301] conv3_3_scale0 needs backward computation.
I0927 00:20:24.062211 19128 net.cpp:301] conv3_3_bn0 needs backward computation.
I0927 00:20:24.062214 19128 net.cpp:301] conv3_3_0 needs backward computation.
I0927 00:20:24.062219 19128 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I0927 00:20:24.062224 19128 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I0927 00:20:24.062228 19128 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I0927 00:20:24.062234 19128 net.cpp:301] conv3_2_scale1 needs backward computation.
I0927 00:20:24.062239 19128 net.cpp:301] conv3_2bn1 needs backward computation.
I0927 00:20:24.062243 19128 net.cpp:301] conv3_2_1 needs backward computation.
I0927 00:20:24.062248 19128 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I0927 00:20:24.062252 19128 net.cpp:301] conv3_2_scale0 needs backward computation.
I0927 00:20:24.062258 19128 net.cpp:301] conv3_2_bn0 needs backward computation.
I0927 00:20:24.062261 19128 net.cpp:301] conv3_2_0 needs backward computation.
I0927 00:20:24.062266 19128 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I0927 00:20:24.062271 19128 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I0927 00:20:24.062275 19128 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I0927 00:20:24.062281 19128 net.cpp:301] conv3_1_scale_down needs backward computation.
I0927 00:20:24.062286 19128 net.cpp:301] conv3_1_bn_down needs backward computation.
I0927 00:20:24.062290 19128 net.cpp:301] conv3_1_down needs backward computation.
I0927 00:20:24.062295 19128 net.cpp:301] conv3_1_scale1 needs backward computation.
I0927 00:20:24.062300 19128 net.cpp:301] conv3_1bn1 needs backward computation.
I0927 00:20:24.062304 19128 net.cpp:301] conv3_1_1 needs backward computation.
I0927 00:20:24.062309 19128 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I0927 00:20:24.062314 19128 net.cpp:301] conv3_1_scale0 needs backward computation.
I0927 00:20:24.062319 19128 net.cpp:301] conv3_1_bn0 needs backward computation.
I0927 00:20:24.062324 19128 net.cpp:301] conv3_1_0 needs backward computation.
I0927 00:20:24.062328 19128 net.cpp:301] conv2_Eltwise_5_conv2_5ReLU_1_0_split needs backward computation.
I0927 00:20:24.062333 19128 net.cpp:301] conv2_5ReLU_1 needs backward computation.
I0927 00:20:24.062337 19128 net.cpp:301] conv2_Eltwise_5 needs backward computation.
I0927 00:20:24.062343 19128 net.cpp:301] conv2_5_scale1 needs backward computation.
I0927 00:20:24.062347 19128 net.cpp:301] conv2_5bn1 needs backward computation.
I0927 00:20:24.062352 19128 net.cpp:301] conv2_5_1 needs backward computation.
I0927 00:20:24.062357 19128 net.cpp:301] conv2_5_ReLU0 needs backward computation.
I0927 00:20:24.062361 19128 net.cpp:301] conv2_5_scale0 needs backward computation.
I0927 00:20:24.062366 19128 net.cpp:301] conv2_5_bn0 needs backward computation.
I0927 00:20:24.062371 19128 net.cpp:301] conv2_5_0 needs backward computation.
I0927 00:20:24.062379 19128 net.cpp:301] conv2_Eltwise_4_conv2_4ReLU_1_0_split needs backward computation.
I0927 00:20:24.062384 19128 net.cpp:301] conv2_4ReLU_1 needs backward computation.
I0927 00:20:24.062389 19128 net.cpp:301] conv2_Eltwise_4 needs backward computation.
I0927 00:20:24.062396 19128 net.cpp:301] conv2_4_scale1 needs backward computation.
I0927 00:20:24.062399 19128 net.cpp:301] conv2_4bn1 needs backward computation.
I0927 00:20:24.062404 19128 net.cpp:301] conv2_4_1 needs backward computation.
I0927 00:20:24.062408 19128 net.cpp:301] conv2_4_ReLU0 needs backward computation.
I0927 00:20:24.062413 19128 net.cpp:301] conv2_4_scale0 needs backward computation.
I0927 00:20:24.062418 19128 net.cpp:301] conv2_4_bn0 needs backward computation.
I0927 00:20:24.062422 19128 net.cpp:301] conv2_4_0 needs backward computation.
I0927 00:20:24.062428 19128 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I0927 00:20:24.062439 19128 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I0927 00:20:24.062444 19128 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I0927 00:20:24.062449 19128 net.cpp:301] conv2_3_scale1 needs backward computation.
I0927 00:20:24.062453 19128 net.cpp:301] conv2_3bn1 needs backward computation.
I0927 00:20:24.062458 19128 net.cpp:301] conv2_3_1 needs backward computation.
I0927 00:20:24.062463 19128 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I0927 00:20:24.062467 19128 net.cpp:301] conv2_3_scale0 needs backward computation.
I0927 00:20:24.062471 19128 net.cpp:301] conv2_3_bn0 needs backward computation.
I0927 00:20:24.062475 19128 net.cpp:301] conv2_3_0 needs backward computation.
I0927 00:20:24.062480 19128 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I0927 00:20:24.062485 19128 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I0927 00:20:24.062489 19128 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I0927 00:20:24.062494 19128 net.cpp:301] conv2_2_scale1 needs backward computation.
I0927 00:20:24.062500 19128 net.cpp:301] conv2_2bn1 needs backward computation.
I0927 00:20:24.062503 19128 net.cpp:301] conv2_2_1 needs backward computation.
I0927 00:20:24.062507 19128 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I0927 00:20:24.062512 19128 net.cpp:301] conv2_2_scale0 needs backward computation.
I0927 00:20:24.062516 19128 net.cpp:301] conv2_2_bn0 needs backward computation.
I0927 00:20:24.062520 19128 net.cpp:301] conv2_2_0 needs backward computation.
I0927 00:20:24.062525 19128 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I0927 00:20:24.062530 19128 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I0927 00:20:24.062535 19128 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I0927 00:20:24.062541 19128 net.cpp:301] conv2_1_scale1 needs backward computation.
I0927 00:20:24.062547 19128 net.cpp:301] conv2_1bn1 needs backward computation.
I0927 00:20:24.062552 19128 net.cpp:301] conv2_1_1 needs backward computation.
I0927 00:20:24.062556 19128 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I0927 00:20:24.062561 19128 net.cpp:301] conv2_1_scale0 needs backward computation.
I0927 00:20:24.062566 19128 net.cpp:301] conv2_1_bn0 needs backward computation.
I0927 00:20:24.062569 19128 net.cpp:301] conv2_1_0 needs backward computation.
I0927 00:20:24.062575 19128 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I0927 00:20:24.062579 19128 net.cpp:301] conv1/ReLU needs backward computation.
I0927 00:20:24.062584 19128 net.cpp:301] conv1/scale needs backward computation.
I0927 00:20:24.062588 19128 net.cpp:301] conv1/bn needs backward computation.
I0927 00:20:24.062593 19128 net.cpp:301] conv1 needs backward computation.
I0927 00:20:24.062598 19128 net.cpp:303] Data1 does not need backward computation.
I0927 00:20:24.062602 19128 net.cpp:348] This network produces output Softmax1
I0927 00:20:24.062688 19128 net.cpp:363] Network initialization done.
I0927 00:20:24.064452 19128 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: ./test_ResNet_32.prototxt
I0927 00:20:24.064471 19128 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0927 00:20:24.064481 19128 solver.cpp:277] Creating test net (#0) specified by test_net file: ./test_ResNet_32.prototxt
I0927 00:20:24.065649 19128 net.cpp:82] Initializing net from parameters: 
name: "ResNet-32"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: false
    crop_size: 32
    mean_value: 125.3
    mean_value: 122.9
    mean_value: 113.8
  }
  data_param {
    source: "/home/lijianfei/datasets/cifar10_40/test_lmdb"
    batch_size: 10
    backend: LMDB
  }
  image_data_param {
    shuffle: false
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1_0"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1_bn0"
  type: "BatchNorm"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale0"
  type: "Scale"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1_ReLU0"
  type: "ReLU"
  bottom: "conv2_1_0"
  top: "conv2_1_0"
}
layer {
  name: "conv2_1_1"
  type: "Convolution"
  bottom: "conv2_1_0"
  top: "conv2_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_1bn1"
  type: "BatchNorm"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1_scale1"
  type: "Scale"
  bottom: "conv2_1_1"
  top: "conv2_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_1"
  type: "Eltwise"
  bottom: "conv1"
  bottom: "conv2_1_1"
  top: "conv2_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_1ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_1"
  top: "conv2_Eltwise_1"
}
layer {
  name: "conv2_2_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_1"
  top: "conv2_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2_bn0"
  type: "BatchNorm"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale0"
  type: "Scale"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2_ReLU0"
  type: "ReLU"
  bottom: "conv2_2_0"
  top: "conv2_2_0"
}
layer {
  name: "conv2_2_1"
  type: "Convolution"
  bottom: "conv2_2_0"
  top: "conv2_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_2bn1"
  type: "BatchNorm"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2_scale1"
  type: "Scale"
  bottom: "conv2_2_1"
  top: "conv2_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_2"
  type: "Eltwise"
  bottom: "conv2_Eltwise_1"
  bottom: "conv2_2_1"
  top: "conv2_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_2ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_2"
  top: "conv2_Eltwise_2"
}
layer {
  name: "conv2_3_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_2"
  top: "conv2_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3_bn0"
  type: "BatchNorm"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale0"
  type: "Scale"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_3_ReLU0"
  type: "ReLU"
  bottom: "conv2_3_0"
  top: "conv2_3_0"
}
layer {
  name: "conv2_3_1"
  type: "Convolution"
  bottom: "conv2_3_0"
  top: "conv2_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_3bn1"
  type: "BatchNorm"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_3_scale1"
  type: "Scale"
  bottom: "conv2_3_1"
  top: "conv2_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_3"
  type: "Eltwise"
  bottom: "conv2_Eltwise_2"
  bottom: "conv2_3_1"
  top: "conv2_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_3ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_3"
  top: "conv2_Eltwise_3"
}
layer {
  name: "conv2_4_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_3"
  top: "conv2_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4_bn0"
  type: "BatchNorm"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_4_scale0"
  type: "Scale"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_4_ReLU0"
  type: "ReLU"
  bottom: "conv2_4_0"
  top: "conv2_4_0"
}
layer {
  name: "conv2_4_1"
  type: "Convolution"
  bottom: "conv2_4_0"
  top: "conv2_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_4bn1"
  type: "BatchNorm"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_4_scale1"
  type: "Scale"
  bottom: "conv2_4_1"
  top: "conv2_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_4"
  type: "Eltwise"
  bottom: "conv2_Eltwise_3"
  bottom: "conv2_4_1"
  top: "conv2_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_4ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_4"
  top: "conv2_Eltwise_4"
}
layer {
  name: "conv2_5_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_4"
  top: "conv2_5_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_5_bn0"
  type: "BatchNorm"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_5_scale0"
  type: "Scale"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_5_ReLU0"
  type: "ReLU"
  bottom: "conv2_5_0"
  top: "conv2_5_0"
}
layer {
  name: "conv2_5_1"
  type: "Convolution"
  bottom: "conv2_5_0"
  top: "conv2_5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv2_5bn1"
  type: "BatchNorm"
  bottom: "conv2_5_1"
  top: "conv2_5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_5_scale1"
  type: "Scale"
  bottom: "conv2_5_1"
  top: "conv2_5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_Eltwise_5"
  type: "Eltwise"
  bottom: "conv2_Eltwise_4"
  bottom: "conv2_5_1"
  top: "conv2_Eltwise_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2_5ReLU_1"
  type: "ReLU"
  bottom: "conv2_Eltwise_5"
  top: "conv2_Eltwise_5"
}
layer {
  name: "conv3_1_0"
  type: "Convolution"
  bottom: "conv2_Eltwise_5"
  top: "conv3_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn0"
  type: "BatchNorm"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale0"
  type: "Scale"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_ReLU0"
  type: "ReLU"
  bottom: "conv3_1_0"
  top: "conv3_1_0"
}
layer {
  name: "conv3_1_1"
  type: "Convolution"
  bottom: "conv3_1_0"
  top: "conv3_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1bn1"
  type: "BatchNorm"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale1"
  type: "Scale"
  bottom: "conv3_1_1"
  top: "conv3_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1_down"
  type: "Convolution"
  bottom: "conv2_Eltwise_5"
  top: "conv3_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_1_bn_down"
  type: "BatchNorm"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1_scale_down"
  type: "Scale"
  bottom: "conv3_1_down"
  top: "conv3_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_1"
  type: "Eltwise"
  bottom: "conv3_1_1"
  bottom: "conv3_1_down"
  top: "conv3_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_1ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_1"
  top: "conv3_Eltwise_1"
}
layer {
  name: "conv3_2_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_1"
  top: "conv3_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2_bn0"
  type: "BatchNorm"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale0"
  type: "Scale"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2_ReLU0"
  type: "ReLU"
  bottom: "conv3_2_0"
  top: "conv3_2_0"
}
layer {
  name: "conv3_2_1"
  type: "Convolution"
  bottom: "conv3_2_0"
  top: "conv3_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_2bn1"
  type: "BatchNorm"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2_scale1"
  type: "Scale"
  bottom: "conv3_2_1"
  top: "conv3_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_2"
  type: "Eltwise"
  bottom: "conv3_Eltwise_1"
  bottom: "conv3_2_1"
  top: "conv3_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_2"
  top: "conv3_Eltwise_2"
}
layer {
  name: "conv3_3_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_2"
  top: "conv3_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3_bn0"
  type: "BatchNorm"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale0"
  type: "Scale"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3_ReLU0"
  type: "ReLU"
  bottom: "conv3_3_0"
  top: "conv3_3_0"
}
layer {
  name: "conv3_3_1"
  type: "Convolution"
  bottom: "conv3_3_0"
  top: "conv3_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_3bn1"
  type: "BatchNorm"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3_scale1"
  type: "Scale"
  bottom: "conv3_3_1"
  top: "conv3_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_3"
  type: "Eltwise"
  bottom: "conv3_Eltwise_2"
  bottom: "conv3_3_1"
  top: "conv3_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_3"
  top: "conv3_Eltwise_3"
}
layer {
  name: "conv3_4_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_3"
  top: "conv3_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4_bn0"
  type: "BatchNorm"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_scale0"
  type: "Scale"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_4_ReLU0"
  type: "ReLU"
  bottom: "conv3_4_0"
  top: "conv3_4_0"
}
layer {
  name: "conv3_4_1"
  type: "Convolution"
  bottom: "conv3_4_0"
  top: "conv3_4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_4bn1"
  type: "BatchNorm"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_4_scale1"
  type: "Scale"
  bottom: "conv3_4_1"
  top: "conv3_4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_4"
  type: "Eltwise"
  bottom: "conv3_Eltwise_3"
  bottom: "conv3_4_1"
  top: "conv3_Eltwise_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_4ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_4"
  top: "conv3_Eltwise_4"
}
layer {
  name: "conv3_5_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_4"
  top: "conv3_5_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_5_bn0"
  type: "BatchNorm"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_5_scale0"
  type: "Scale"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_5_ReLU0"
  type: "ReLU"
  bottom: "conv3_5_0"
  top: "conv3_5_0"
}
layer {
  name: "conv3_5_1"
  type: "Convolution"
  bottom: "conv3_5_0"
  top: "conv3_5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv3_5bn1"
  type: "BatchNorm"
  bottom: "conv3_5_1"
  top: "conv3_5_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_5_scale1"
  type: "Scale"
  bottom: "conv3_5_1"
  top: "conv3_5_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_Eltwise_5"
  type: "Eltwise"
  bottom: "conv3_Eltwise_4"
  bottom: "conv3_5_1"
  top: "conv3_Eltwise_5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_5ReLU_1"
  type: "ReLU"
  bottom: "conv3_Eltwise_5"
  top: "conv3_Eltwise_5"
}
layer {
  name: "conv4_1_0"
  type: "Convolution"
  bottom: "conv3_Eltwise_5"
  top: "conv4_1_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn0"
  type: "BatchNorm"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale0"
  type: "Scale"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_ReLU0"
  type: "ReLU"
  bottom: "conv4_1_0"
  top: "conv4_1_0"
}
layer {
  name: "conv4_1_1"
  type: "Convolution"
  bottom: "conv4_1_0"
  top: "conv4_1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1bn1"
  type: "BatchNorm"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale1"
  type: "Scale"
  bottom: "conv4_1_1"
  top: "conv4_1_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1_down"
  type: "Convolution"
  bottom: "conv3_Eltwise_5"
  top: "conv4_1_down"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_1_bn_down"
  type: "BatchNorm"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1_scale_down"
  type: "Scale"
  bottom: "conv4_1_down"
  top: "conv4_1_down"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_1"
  type: "Eltwise"
  bottom: "conv4_1_1"
  bottom: "conv4_1_down"
  top: "conv4_Eltwise_1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_1ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_1"
  top: "conv4_Eltwise_1"
}
layer {
  name: "conv4_2_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_1"
  top: "conv4_2_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2_bn0"
  type: "BatchNorm"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale0"
  type: "Scale"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2_ReLU0"
  type: "ReLU"
  bottom: "conv4_2_0"
  top: "conv4_2_0"
}
layer {
  name: "conv4_2_1"
  type: "Convolution"
  bottom: "conv4_2_0"
  top: "conv4_2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_2bn1"
  type: "BatchNorm"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2_scale1"
  type: "Scale"
  bottom: "conv4_2_1"
  top: "conv4_2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_2"
  type: "Eltwise"
  bottom: "conv4_Eltwise_1"
  bottom: "conv4_2_1"
  top: "conv4_Eltwise_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_2"
  top: "conv4_Eltwise_2"
}
layer {
  name: "conv4_3_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_2"
  top: "conv4_3_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_bn0"
  type: "BatchNorm"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale0"
  type: "Scale"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3_ReLU0"
  type: "ReLU"
  bottom: "conv4_3_0"
  top: "conv4_3_0"
}
layer {
  name: "conv4_3_1"
  type: "Convolution"
  bottom: "conv4_3_0"
  top: "conv4_3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3bn1"
  type: "BatchNorm"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3_scale1"
  type: "Scale"
  bottom: "conv4_3_1"
  top: "conv4_3_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_Eltwise_3"
  type: "Eltwise"
  bottom: "conv4_Eltwise_2"
  bottom: "conv4_3_1"
  top: "conv4_Eltwise_3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3ReLU_1"
  type: "ReLU"
  bottom: "conv4_Eltwise_3"
  top: "conv4_Eltwise_3"
}
layer {
  name: "conv4_4_0"
  type: "Convolution"
  bottom: "conv4_Eltwise_3"
  top: "conv4_4_0"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_4_bn0"
  type: "BatchNorm"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_4_scale0"
  type: "Scale"
  bottom: "conv4_4_0"
  top: "conv4_4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name
I0927 00:20:24.066231 19128 layer_factory.hpp:77] Creating layer Data1
I0927 00:20:24.066318 19128 db_lmdb.cpp:35] Opened lmdb /home/lijianfei/datasets/cifar10_40/test_lmdb
I0927 00:20:24.066352 19128 net.cpp:128] Creating Layer Data1
I0927 00:20:24.066360 19128 net.cpp:522] Data1 -> data
I0927 00:20:24.066371 19128 net.cpp:522] Data1 -> label
I0927 00:20:24.066532 19128 data_layer.cpp:45] output data size: 10,3,32,32
I0927 00:20:24.074779 19128 net.cpp:172] Setting up Data1
I0927 00:20:24.074797 19128 net.cpp:186] Top shape: 10 3 32 32 (30720)
I0927 00:20:24.074803 19128 net.cpp:186] Top shape: 10 (10)
I0927 00:20:24.074807 19128 net.cpp:194] Memory required for data: 122920
I0927 00:20:24.074826 19128 layer_factory.hpp:77] Creating layer label_Data1_1_split
I0927 00:20:24.074836 19128 net.cpp:128] Creating Layer label_Data1_1_split
I0927 00:20:24.074841 19128 net.cpp:558] label_Data1_1_split <- label
I0927 00:20:24.074847 19128 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_0
I0927 00:20:24.074856 19128 net.cpp:522] label_Data1_1_split -> label_Data1_1_split_1
I0927 00:20:24.074923 19128 net.cpp:172] Setting up label_Data1_1_split
I0927 00:20:24.074930 19128 net.cpp:186] Top shape: 10 (10)
I0927 00:20:24.074935 19128 net.cpp:186] Top shape: 10 (10)
I0927 00:20:24.074939 19128 net.cpp:194] Memory required for data: 123000
I0927 00:20:24.074944 19128 layer_factory.hpp:77] Creating layer conv1
I0927 00:20:24.074955 19128 net.cpp:128] Creating Layer conv1
I0927 00:20:24.074962 19128 net.cpp:558] conv1 <- data
I0927 00:20:24.074970 19128 net.cpp:522] conv1 -> conv1
I0927 00:20:24.083653 19128 net.cpp:172] Setting up conv1
I0927 00:20:24.083683 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.083688 19128 net.cpp:194] Memory required for data: 778360
I0927 00:20:24.083703 19128 layer_factory.hpp:77] Creating layer conv1/bn
I0927 00:20:24.083722 19128 net.cpp:128] Creating Layer conv1/bn
I0927 00:20:24.083730 19128 net.cpp:558] conv1/bn <- conv1
I0927 00:20:24.083740 19128 net.cpp:509] conv1/bn -> conv1 (in-place)
I0927 00:20:24.084077 19128 net.cpp:172] Setting up conv1/bn
I0927 00:20:24.084090 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.084095 19128 net.cpp:194] Memory required for data: 1433720
I0927 00:20:24.084110 19128 layer_factory.hpp:77] Creating layer conv1/scale
I0927 00:20:24.084121 19128 net.cpp:128] Creating Layer conv1/scale
I0927 00:20:24.084128 19128 net.cpp:558] conv1/scale <- conv1
I0927 00:20:24.084134 19128 net.cpp:509] conv1/scale -> conv1 (in-place)
I0927 00:20:24.084211 19128 layer_factory.hpp:77] Creating layer conv1/scale
I0927 00:20:24.084456 19128 net.cpp:172] Setting up conv1/scale
I0927 00:20:24.084476 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.084481 19128 net.cpp:194] Memory required for data: 2089080
I0927 00:20:24.084502 19128 layer_factory.hpp:77] Creating layer conv1/ReLU
I0927 00:20:24.084520 19128 net.cpp:128] Creating Layer conv1/ReLU
I0927 00:20:24.084525 19128 net.cpp:558] conv1/ReLU <- conv1
I0927 00:20:24.084535 19128 net.cpp:509] conv1/ReLU -> conv1 (in-place)
I0927 00:20:24.084883 19128 net.cpp:172] Setting up conv1/ReLU
I0927 00:20:24.084902 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.084905 19128 net.cpp:194] Memory required for data: 2744440
I0927 00:20:24.084910 19128 layer_factory.hpp:77] Creating layer conv1_conv1/ReLU_0_split
I0927 00:20:24.084957 19128 net.cpp:128] Creating Layer conv1_conv1/ReLU_0_split
I0927 00:20:24.084962 19128 net.cpp:558] conv1_conv1/ReLU_0_split <- conv1
I0927 00:20:24.084976 19128 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_0
I0927 00:20:24.084995 19128 net.cpp:522] conv1_conv1/ReLU_0_split -> conv1_conv1/ReLU_0_split_1
I0927 00:20:24.085088 19128 net.cpp:172] Setting up conv1_conv1/ReLU_0_split
I0927 00:20:24.085100 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.085106 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.085110 19128 net.cpp:194] Memory required for data: 4055160
I0927 00:20:24.085114 19128 layer_factory.hpp:77] Creating layer conv2_1_0
I0927 00:20:24.085127 19128 net.cpp:128] Creating Layer conv2_1_0
I0927 00:20:24.085131 19128 net.cpp:558] conv2_1_0 <- conv1_conv1/ReLU_0_split_0
I0927 00:20:24.085141 19128 net.cpp:522] conv2_1_0 -> conv2_1_0
I0927 00:20:24.090240 19128 net.cpp:172] Setting up conv2_1_0
I0927 00:20:24.090270 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.090276 19128 net.cpp:194] Memory required for data: 4710520
I0927 00:20:24.090292 19128 layer_factory.hpp:77] Creating layer conv2_1_bn0
I0927 00:20:24.090307 19128 net.cpp:128] Creating Layer conv2_1_bn0
I0927 00:20:24.090313 19128 net.cpp:558] conv2_1_bn0 <- conv2_1_0
I0927 00:20:24.090322 19128 net.cpp:509] conv2_1_bn0 -> conv2_1_0 (in-place)
I0927 00:20:24.090693 19128 net.cpp:172] Setting up conv2_1_bn0
I0927 00:20:24.090708 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.090713 19128 net.cpp:194] Memory required for data: 5365880
I0927 00:20:24.090725 19128 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0927 00:20:24.090734 19128 net.cpp:128] Creating Layer conv2_1_scale0
I0927 00:20:24.090739 19128 net.cpp:558] conv2_1_scale0 <- conv2_1_0
I0927 00:20:24.090751 19128 net.cpp:509] conv2_1_scale0 -> conv2_1_0 (in-place)
I0927 00:20:24.090828 19128 layer_factory.hpp:77] Creating layer conv2_1_scale0
I0927 00:20:24.091037 19128 net.cpp:172] Setting up conv2_1_scale0
I0927 00:20:24.091051 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.091056 19128 net.cpp:194] Memory required for data: 6021240
I0927 00:20:24.091066 19128 layer_factory.hpp:77] Creating layer conv2_1_ReLU0
I0927 00:20:24.091074 19128 net.cpp:128] Creating Layer conv2_1_ReLU0
I0927 00:20:24.091080 19128 net.cpp:558] conv2_1_ReLU0 <- conv2_1_0
I0927 00:20:24.091089 19128 net.cpp:509] conv2_1_ReLU0 -> conv2_1_0 (in-place)
I0927 00:20:24.094431 19128 net.cpp:172] Setting up conv2_1_ReLU0
I0927 00:20:24.094465 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.094470 19128 net.cpp:194] Memory required for data: 6676600
I0927 00:20:24.094476 19128 layer_factory.hpp:77] Creating layer conv2_1_1
I0927 00:20:24.094493 19128 net.cpp:128] Creating Layer conv2_1_1
I0927 00:20:24.094501 19128 net.cpp:558] conv2_1_1 <- conv2_1_0
I0927 00:20:24.094513 19128 net.cpp:522] conv2_1_1 -> conv2_1_1
I0927 00:20:24.098995 19128 net.cpp:172] Setting up conv2_1_1
I0927 00:20:24.099023 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.099030 19128 net.cpp:194] Memory required for data: 7331960
I0927 00:20:24.099041 19128 layer_factory.hpp:77] Creating layer conv2_1bn1
I0927 00:20:24.099052 19128 net.cpp:128] Creating Layer conv2_1bn1
I0927 00:20:24.099067 19128 net.cpp:558] conv2_1bn1 <- conv2_1_1
I0927 00:20:24.099079 19128 net.cpp:509] conv2_1bn1 -> conv2_1_1 (in-place)
I0927 00:20:24.099442 19128 net.cpp:172] Setting up conv2_1bn1
I0927 00:20:24.099455 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.099460 19128 net.cpp:194] Memory required for data: 7987320
I0927 00:20:24.099475 19128 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0927 00:20:24.099486 19128 net.cpp:128] Creating Layer conv2_1_scale1
I0927 00:20:24.099495 19128 net.cpp:558] conv2_1_scale1 <- conv2_1_1
I0927 00:20:24.099503 19128 net.cpp:509] conv2_1_scale1 -> conv2_1_1 (in-place)
I0927 00:20:24.099570 19128 layer_factory.hpp:77] Creating layer conv2_1_scale1
I0927 00:20:24.099803 19128 net.cpp:172] Setting up conv2_1_scale1
I0927 00:20:24.099817 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.099823 19128 net.cpp:194] Memory required for data: 8642680
I0927 00:20:24.099833 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_1
I0927 00:20:24.099846 19128 net.cpp:128] Creating Layer conv2_Eltwise_1
I0927 00:20:24.099854 19128 net.cpp:558] conv2_Eltwise_1 <- conv1_conv1/ReLU_0_split_1
I0927 00:20:24.099861 19128 net.cpp:558] conv2_Eltwise_1 <- conv2_1_1
I0927 00:20:24.099869 19128 net.cpp:522] conv2_Eltwise_1 -> conv2_Eltwise_1
I0927 00:20:24.099913 19128 net.cpp:172] Setting up conv2_Eltwise_1
I0927 00:20:24.099925 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.099933 19128 net.cpp:194] Memory required for data: 9298040
I0927 00:20:24.099939 19128 layer_factory.hpp:77] Creating layer conv2_1ReLU_1
I0927 00:20:24.099947 19128 net.cpp:128] Creating Layer conv2_1ReLU_1
I0927 00:20:24.099953 19128 net.cpp:558] conv2_1ReLU_1 <- conv2_Eltwise_1
I0927 00:20:24.099963 19128 net.cpp:509] conv2_1ReLU_1 -> conv2_Eltwise_1 (in-place)
I0927 00:20:24.100968 19128 net.cpp:172] Setting up conv2_1ReLU_1
I0927 00:20:24.100997 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.101003 19128 net.cpp:194] Memory required for data: 9953400
I0927 00:20:24.101011 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0927 00:20:24.101027 19128 net.cpp:128] Creating Layer conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0927 00:20:24.101032 19128 net.cpp:558] conv2_Eltwise_1_conv2_1ReLU_1_0_split <- conv2_Eltwise_1
I0927 00:20:24.101042 19128 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0927 00:20:24.101052 19128 net.cpp:522] conv2_Eltwise_1_conv2_1ReLU_1_0_split -> conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0927 00:20:24.101125 19128 net.cpp:172] Setting up conv2_Eltwise_1_conv2_1ReLU_1_0_split
I0927 00:20:24.101138 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.101145 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.101151 19128 net.cpp:194] Memory required for data: 11264120
I0927 00:20:24.101156 19128 layer_factory.hpp:77] Creating layer conv2_2_0
I0927 00:20:24.101173 19128 net.cpp:128] Creating Layer conv2_2_0
I0927 00:20:24.101179 19128 net.cpp:558] conv2_2_0 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_0
I0927 00:20:24.101188 19128 net.cpp:522] conv2_2_0 -> conv2_2_0
I0927 00:20:24.107704 19128 net.cpp:172] Setting up conv2_2_0
I0927 00:20:24.107734 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.107740 19128 net.cpp:194] Memory required for data: 11919480
I0927 00:20:24.107753 19128 layer_factory.hpp:77] Creating layer conv2_2_bn0
I0927 00:20:24.107769 19128 net.cpp:128] Creating Layer conv2_2_bn0
I0927 00:20:24.107779 19128 net.cpp:558] conv2_2_bn0 <- conv2_2_0
I0927 00:20:24.107787 19128 net.cpp:509] conv2_2_bn0 -> conv2_2_0 (in-place)
I0927 00:20:24.108158 19128 net.cpp:172] Setting up conv2_2_bn0
I0927 00:20:24.108171 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.108176 19128 net.cpp:194] Memory required for data: 12574840
I0927 00:20:24.108188 19128 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0927 00:20:24.108197 19128 net.cpp:128] Creating Layer conv2_2_scale0
I0927 00:20:24.108203 19128 net.cpp:558] conv2_2_scale0 <- conv2_2_0
I0927 00:20:24.108212 19128 net.cpp:509] conv2_2_scale0 -> conv2_2_0 (in-place)
I0927 00:20:24.108278 19128 layer_factory.hpp:77] Creating layer conv2_2_scale0
I0927 00:20:24.108484 19128 net.cpp:172] Setting up conv2_2_scale0
I0927 00:20:24.108501 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.108510 19128 net.cpp:194] Memory required for data: 13230200
I0927 00:20:24.108520 19128 layer_factory.hpp:77] Creating layer conv2_2_ReLU0
I0927 00:20:24.108528 19128 net.cpp:128] Creating Layer conv2_2_ReLU0
I0927 00:20:24.108533 19128 net.cpp:558] conv2_2_ReLU0 <- conv2_2_0
I0927 00:20:24.108543 19128 net.cpp:509] conv2_2_ReLU0 -> conv2_2_0 (in-place)
I0927 00:20:24.109688 19128 net.cpp:172] Setting up conv2_2_ReLU0
I0927 00:20:24.109714 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.109719 19128 net.cpp:194] Memory required for data: 13885560
I0927 00:20:24.109724 19128 layer_factory.hpp:77] Creating layer conv2_2_1
I0927 00:20:24.109740 19128 net.cpp:128] Creating Layer conv2_2_1
I0927 00:20:24.109746 19128 net.cpp:558] conv2_2_1 <- conv2_2_0
I0927 00:20:24.109763 19128 net.cpp:522] conv2_2_1 -> conv2_2_1
I0927 00:20:24.116410 19128 net.cpp:172] Setting up conv2_2_1
I0927 00:20:24.116438 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.116443 19128 net.cpp:194] Memory required for data: 14540920
I0927 00:20:24.116456 19128 layer_factory.hpp:77] Creating layer conv2_2bn1
I0927 00:20:24.116464 19128 net.cpp:128] Creating Layer conv2_2bn1
I0927 00:20:24.116469 19128 net.cpp:558] conv2_2bn1 <- conv2_2_1
I0927 00:20:24.116482 19128 net.cpp:509] conv2_2bn1 -> conv2_2_1 (in-place)
I0927 00:20:24.116786 19128 net.cpp:172] Setting up conv2_2bn1
I0927 00:20:24.116798 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.116802 19128 net.cpp:194] Memory required for data: 15196280
I0927 00:20:24.116817 19128 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0927 00:20:24.116824 19128 net.cpp:128] Creating Layer conv2_2_scale1
I0927 00:20:24.116829 19128 net.cpp:558] conv2_2_scale1 <- conv2_2_1
I0927 00:20:24.116835 19128 net.cpp:509] conv2_2_scale1 -> conv2_2_1 (in-place)
I0927 00:20:24.116889 19128 layer_factory.hpp:77] Creating layer conv2_2_scale1
I0927 00:20:24.117058 19128 net.cpp:172] Setting up conv2_2_scale1
I0927 00:20:24.117070 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.117074 19128 net.cpp:194] Memory required for data: 15851640
I0927 00:20:24.117082 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_2
I0927 00:20:24.117092 19128 net.cpp:128] Creating Layer conv2_Eltwise_2
I0927 00:20:24.117097 19128 net.cpp:558] conv2_Eltwise_2 <- conv2_Eltwise_1_conv2_1ReLU_1_0_split_1
I0927 00:20:24.117102 19128 net.cpp:558] conv2_Eltwise_2 <- conv2_2_1
I0927 00:20:24.117111 19128 net.cpp:522] conv2_Eltwise_2 -> conv2_Eltwise_2
I0927 00:20:24.117141 19128 net.cpp:172] Setting up conv2_Eltwise_2
I0927 00:20:24.117152 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.117157 19128 net.cpp:194] Memory required for data: 16507000
I0927 00:20:24.117161 19128 layer_factory.hpp:77] Creating layer conv2_2ReLU_1
I0927 00:20:24.117171 19128 net.cpp:128] Creating Layer conv2_2ReLU_1
I0927 00:20:24.117175 19128 net.cpp:558] conv2_2ReLU_1 <- conv2_Eltwise_2
I0927 00:20:24.117180 19128 net.cpp:509] conv2_2ReLU_1 -> conv2_Eltwise_2 (in-place)
I0927 00:20:24.118440 19128 net.cpp:172] Setting up conv2_2ReLU_1
I0927 00:20:24.118454 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.118459 19128 net.cpp:194] Memory required for data: 17162360
I0927 00:20:24.118463 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0927 00:20:24.118474 19128 net.cpp:128] Creating Layer conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0927 00:20:24.118477 19128 net.cpp:558] conv2_Eltwise_2_conv2_2ReLU_1_0_split <- conv2_Eltwise_2
I0927 00:20:24.118484 19128 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0927 00:20:24.118494 19128 net.cpp:522] conv2_Eltwise_2_conv2_2ReLU_1_0_split -> conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0927 00:20:24.118554 19128 net.cpp:172] Setting up conv2_Eltwise_2_conv2_2ReLU_1_0_split
I0927 00:20:24.118562 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.118568 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.118572 19128 net.cpp:194] Memory required for data: 18473080
I0927 00:20:24.118577 19128 layer_factory.hpp:77] Creating layer conv2_3_0
I0927 00:20:24.118589 19128 net.cpp:128] Creating Layer conv2_3_0
I0927 00:20:24.118594 19128 net.cpp:558] conv2_3_0 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_0
I0927 00:20:24.118604 19128 net.cpp:522] conv2_3_0 -> conv2_3_0
I0927 00:20:24.125138 19128 net.cpp:172] Setting up conv2_3_0
I0927 00:20:24.125169 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.125174 19128 net.cpp:194] Memory required for data: 19128440
I0927 00:20:24.125183 19128 layer_factory.hpp:77] Creating layer conv2_3_bn0
I0927 00:20:24.125192 19128 net.cpp:128] Creating Layer conv2_3_bn0
I0927 00:20:24.125196 19128 net.cpp:558] conv2_3_bn0 <- conv2_3_0
I0927 00:20:24.125206 19128 net.cpp:509] conv2_3_bn0 -> conv2_3_0 (in-place)
I0927 00:20:24.125504 19128 net.cpp:172] Setting up conv2_3_bn0
I0927 00:20:24.125516 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.125522 19128 net.cpp:194] Memory required for data: 19783800
I0927 00:20:24.125532 19128 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0927 00:20:24.125540 19128 net.cpp:128] Creating Layer conv2_3_scale0
I0927 00:20:24.125543 19128 net.cpp:558] conv2_3_scale0 <- conv2_3_0
I0927 00:20:24.125551 19128 net.cpp:509] conv2_3_scale0 -> conv2_3_0 (in-place)
I0927 00:20:24.125602 19128 layer_factory.hpp:77] Creating layer conv2_3_scale0
I0927 00:20:24.125768 19128 net.cpp:172] Setting up conv2_3_scale0
I0927 00:20:24.125787 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.125790 19128 net.cpp:194] Memory required for data: 20439160
I0927 00:20:24.125799 19128 layer_factory.hpp:77] Creating layer conv2_3_ReLU0
I0927 00:20:24.125808 19128 net.cpp:128] Creating Layer conv2_3_ReLU0
I0927 00:20:24.125813 19128 net.cpp:558] conv2_3_ReLU0 <- conv2_3_0
I0927 00:20:24.125818 19128 net.cpp:509] conv2_3_ReLU0 -> conv2_3_0 (in-place)
I0927 00:20:24.127212 19128 net.cpp:172] Setting up conv2_3_ReLU0
I0927 00:20:24.127233 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.127238 19128 net.cpp:194] Memory required for data: 21094520
I0927 00:20:24.127241 19128 layer_factory.hpp:77] Creating layer conv2_3_1
I0927 00:20:24.127256 19128 net.cpp:128] Creating Layer conv2_3_1
I0927 00:20:24.127262 19128 net.cpp:558] conv2_3_1 <- conv2_3_0
I0927 00:20:24.127269 19128 net.cpp:522] conv2_3_1 -> conv2_3_1
I0927 00:20:24.133922 19128 net.cpp:172] Setting up conv2_3_1
I0927 00:20:24.133949 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.133955 19128 net.cpp:194] Memory required for data: 21749880
I0927 00:20:24.133965 19128 layer_factory.hpp:77] Creating layer conv2_3bn1
I0927 00:20:24.133978 19128 net.cpp:128] Creating Layer conv2_3bn1
I0927 00:20:24.133985 19128 net.cpp:558] conv2_3bn1 <- conv2_3_1
I0927 00:20:24.133991 19128 net.cpp:509] conv2_3bn1 -> conv2_3_1 (in-place)
I0927 00:20:24.134290 19128 net.cpp:172] Setting up conv2_3bn1
I0927 00:20:24.134304 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.134310 19128 net.cpp:194] Memory required for data: 22405240
I0927 00:20:24.134320 19128 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0927 00:20:24.134326 19128 net.cpp:128] Creating Layer conv2_3_scale1
I0927 00:20:24.134331 19128 net.cpp:558] conv2_3_scale1 <- conv2_3_1
I0927 00:20:24.134340 19128 net.cpp:509] conv2_3_scale1 -> conv2_3_1 (in-place)
I0927 00:20:24.134390 19128 layer_factory.hpp:77] Creating layer conv2_3_scale1
I0927 00:20:24.134560 19128 net.cpp:172] Setting up conv2_3_scale1
I0927 00:20:24.134572 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.134577 19128 net.cpp:194] Memory required for data: 23060600
I0927 00:20:24.134584 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_3
I0927 00:20:24.134591 19128 net.cpp:128] Creating Layer conv2_Eltwise_3
I0927 00:20:24.134595 19128 net.cpp:558] conv2_Eltwise_3 <- conv2_Eltwise_2_conv2_2ReLU_1_0_split_1
I0927 00:20:24.134600 19128 net.cpp:558] conv2_Eltwise_3 <- conv2_3_1
I0927 00:20:24.134608 19128 net.cpp:522] conv2_Eltwise_3 -> conv2_Eltwise_3
I0927 00:20:24.134639 19128 net.cpp:172] Setting up conv2_Eltwise_3
I0927 00:20:24.134649 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.134652 19128 net.cpp:194] Memory required for data: 23715960
I0927 00:20:24.134656 19128 layer_factory.hpp:77] Creating layer conv2_3ReLU_1
I0927 00:20:24.134678 19128 net.cpp:128] Creating Layer conv2_3ReLU_1
I0927 00:20:24.134683 19128 net.cpp:558] conv2_3ReLU_1 <- conv2_Eltwise_3
I0927 00:20:24.134690 19128 net.cpp:509] conv2_3ReLU_1 -> conv2_Eltwise_3 (in-place)
I0927 00:20:24.135977 19128 net.cpp:172] Setting up conv2_3ReLU_1
I0927 00:20:24.136003 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.136008 19128 net.cpp:194] Memory required for data: 24371320
I0927 00:20:24.136013 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0927 00:20:24.136023 19128 net.cpp:128] Creating Layer conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0927 00:20:24.136029 19128 net.cpp:558] conv2_Eltwise_3_conv2_3ReLU_1_0_split <- conv2_Eltwise_3
I0927 00:20:24.136036 19128 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0927 00:20:24.136050 19128 net.cpp:522] conv2_Eltwise_3_conv2_3ReLU_1_0_split -> conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0927 00:20:24.136109 19128 net.cpp:172] Setting up conv2_Eltwise_3_conv2_3ReLU_1_0_split
I0927 00:20:24.136117 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.136123 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.136126 19128 net.cpp:194] Memory required for data: 25682040
I0927 00:20:24.136132 19128 layer_factory.hpp:77] Creating layer conv2_4_0
I0927 00:20:24.136144 19128 net.cpp:128] Creating Layer conv2_4_0
I0927 00:20:24.136149 19128 net.cpp:558] conv2_4_0 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_0
I0927 00:20:24.136157 19128 net.cpp:522] conv2_4_0 -> conv2_4_0
I0927 00:20:24.142765 19128 net.cpp:172] Setting up conv2_4_0
I0927 00:20:24.142791 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.142796 19128 net.cpp:194] Memory required for data: 26337400
I0927 00:20:24.142807 19128 layer_factory.hpp:77] Creating layer conv2_4_bn0
I0927 00:20:24.142827 19128 net.cpp:128] Creating Layer conv2_4_bn0
I0927 00:20:24.142832 19128 net.cpp:558] conv2_4_bn0 <- conv2_4_0
I0927 00:20:24.142838 19128 net.cpp:509] conv2_4_bn0 -> conv2_4_0 (in-place)
I0927 00:20:24.143136 19128 net.cpp:172] Setting up conv2_4_bn0
I0927 00:20:24.143149 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.143154 19128 net.cpp:194] Memory required for data: 26992760
I0927 00:20:24.143165 19128 layer_factory.hpp:77] Creating layer conv2_4_scale0
I0927 00:20:24.143172 19128 net.cpp:128] Creating Layer conv2_4_scale0
I0927 00:20:24.143177 19128 net.cpp:558] conv2_4_scale0 <- conv2_4_0
I0927 00:20:24.143182 19128 net.cpp:509] conv2_4_scale0 -> conv2_4_0 (in-place)
I0927 00:20:24.143236 19128 layer_factory.hpp:77] Creating layer conv2_4_scale0
I0927 00:20:24.143398 19128 net.cpp:172] Setting up conv2_4_scale0
I0927 00:20:24.143405 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.143409 19128 net.cpp:194] Memory required for data: 27648120
I0927 00:20:24.143417 19128 layer_factory.hpp:77] Creating layer conv2_4_ReLU0
I0927 00:20:24.143424 19128 net.cpp:128] Creating Layer conv2_4_ReLU0
I0927 00:20:24.143427 19128 net.cpp:558] conv2_4_ReLU0 <- conv2_4_0
I0927 00:20:24.143437 19128 net.cpp:509] conv2_4_ReLU0 -> conv2_4_0 (in-place)
I0927 00:20:24.144783 19128 net.cpp:172] Setting up conv2_4_ReLU0
I0927 00:20:24.144803 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.144807 19128 net.cpp:194] Memory required for data: 28303480
I0927 00:20:24.144811 19128 layer_factory.hpp:77] Creating layer conv2_4_1
I0927 00:20:24.144829 19128 net.cpp:128] Creating Layer conv2_4_1
I0927 00:20:24.144834 19128 net.cpp:558] conv2_4_1 <- conv2_4_0
I0927 00:20:24.144848 19128 net.cpp:522] conv2_4_1 -> conv2_4_1
I0927 00:20:24.151801 19128 net.cpp:172] Setting up conv2_4_1
I0927 00:20:24.151829 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.151834 19128 net.cpp:194] Memory required for data: 28958840
I0927 00:20:24.151844 19128 layer_factory.hpp:77] Creating layer conv2_4bn1
I0927 00:20:24.151855 19128 net.cpp:128] Creating Layer conv2_4bn1
I0927 00:20:24.151861 19128 net.cpp:558] conv2_4bn1 <- conv2_4_1
I0927 00:20:24.151885 19128 net.cpp:509] conv2_4bn1 -> conv2_4_1 (in-place)
I0927 00:20:24.152199 19128 net.cpp:172] Setting up conv2_4bn1
I0927 00:20:24.152213 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.152218 19128 net.cpp:194] Memory required for data: 29614200
I0927 00:20:24.152228 19128 layer_factory.hpp:77] Creating layer conv2_4_scale1
I0927 00:20:24.152235 19128 net.cpp:128] Creating Layer conv2_4_scale1
I0927 00:20:24.152240 19128 net.cpp:558] conv2_4_scale1 <- conv2_4_1
I0927 00:20:24.152248 19128 net.cpp:509] conv2_4_scale1 -> conv2_4_1 (in-place)
I0927 00:20:24.152303 19128 layer_factory.hpp:77] Creating layer conv2_4_scale1
I0927 00:20:24.152470 19128 net.cpp:172] Setting up conv2_4_scale1
I0927 00:20:24.152482 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.152487 19128 net.cpp:194] Memory required for data: 30269560
I0927 00:20:24.152495 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_4
I0927 00:20:24.152503 19128 net.cpp:128] Creating Layer conv2_Eltwise_4
I0927 00:20:24.152508 19128 net.cpp:558] conv2_Eltwise_4 <- conv2_Eltwise_3_conv2_3ReLU_1_0_split_1
I0927 00:20:24.152513 19128 net.cpp:558] conv2_Eltwise_4 <- conv2_4_1
I0927 00:20:24.152524 19128 net.cpp:522] conv2_Eltwise_4 -> conv2_Eltwise_4
I0927 00:20:24.152554 19128 net.cpp:172] Setting up conv2_Eltwise_4
I0927 00:20:24.152564 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.152567 19128 net.cpp:194] Memory required for data: 30924920
I0927 00:20:24.152571 19128 layer_factory.hpp:77] Creating layer conv2_4ReLU_1
I0927 00:20:24.152578 19128 net.cpp:128] Creating Layer conv2_4ReLU_1
I0927 00:20:24.152582 19128 net.cpp:558] conv2_4ReLU_1 <- conv2_Eltwise_4
I0927 00:20:24.152588 19128 net.cpp:509] conv2_4ReLU_1 -> conv2_Eltwise_4 (in-place)
I0927 00:20:24.153627 19128 net.cpp:172] Setting up conv2_4ReLU_1
I0927 00:20:24.153646 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.153651 19128 net.cpp:194] Memory required for data: 31580280
I0927 00:20:24.153656 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0927 00:20:24.153664 19128 net.cpp:128] Creating Layer conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0927 00:20:24.153668 19128 net.cpp:558] conv2_Eltwise_4_conv2_4ReLU_1_0_split <- conv2_Eltwise_4
I0927 00:20:24.153676 19128 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I0927 00:20:24.153687 19128 net.cpp:522] conv2_Eltwise_4_conv2_4ReLU_1_0_split -> conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I0927 00:20:24.153744 19128 net.cpp:172] Setting up conv2_Eltwise_4_conv2_4ReLU_1_0_split
I0927 00:20:24.153753 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.153759 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.153762 19128 net.cpp:194] Memory required for data: 32891000
I0927 00:20:24.153766 19128 layer_factory.hpp:77] Creating layer conv2_5_0
I0927 00:20:24.153781 19128 net.cpp:128] Creating Layer conv2_5_0
I0927 00:20:24.153786 19128 net.cpp:558] conv2_5_0 <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_0
I0927 00:20:24.153793 19128 net.cpp:522] conv2_5_0 -> conv2_5_0
I0927 00:20:24.160372 19128 net.cpp:172] Setting up conv2_5_0
I0927 00:20:24.160398 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.160403 19128 net.cpp:194] Memory required for data: 33546360
I0927 00:20:24.160423 19128 layer_factory.hpp:77] Creating layer conv2_5_bn0
I0927 00:20:24.160434 19128 net.cpp:128] Creating Layer conv2_5_bn0
I0927 00:20:24.160439 19128 net.cpp:558] conv2_5_bn0 <- conv2_5_0
I0927 00:20:24.160451 19128 net.cpp:509] conv2_5_bn0 -> conv2_5_0 (in-place)
I0927 00:20:24.160751 19128 net.cpp:172] Setting up conv2_5_bn0
I0927 00:20:24.160768 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.160771 19128 net.cpp:194] Memory required for data: 34201720
I0927 00:20:24.160781 19128 layer_factory.hpp:77] Creating layer conv2_5_scale0
I0927 00:20:24.160791 19128 net.cpp:128] Creating Layer conv2_5_scale0
I0927 00:20:24.160796 19128 net.cpp:558] conv2_5_scale0 <- conv2_5_0
I0927 00:20:24.160820 19128 net.cpp:509] conv2_5_scale0 -> conv2_5_0 (in-place)
I0927 00:20:24.160877 19128 layer_factory.hpp:77] Creating layer conv2_5_scale0
I0927 00:20:24.161046 19128 net.cpp:172] Setting up conv2_5_scale0
I0927 00:20:24.161053 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.161058 19128 net.cpp:194] Memory required for data: 34857080
I0927 00:20:24.161067 19128 layer_factory.hpp:77] Creating layer conv2_5_ReLU0
I0927 00:20:24.161075 19128 net.cpp:128] Creating Layer conv2_5_ReLU0
I0927 00:20:24.161080 19128 net.cpp:558] conv2_5_ReLU0 <- conv2_5_0
I0927 00:20:24.161085 19128 net.cpp:509] conv2_5_ReLU0 -> conv2_5_0 (in-place)
I0927 00:20:24.162396 19128 net.cpp:172] Setting up conv2_5_ReLU0
I0927 00:20:24.162425 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.162430 19128 net.cpp:194] Memory required for data: 35512440
I0927 00:20:24.162436 19128 layer_factory.hpp:77] Creating layer conv2_5_1
I0927 00:20:24.162449 19128 net.cpp:128] Creating Layer conv2_5_1
I0927 00:20:24.162454 19128 net.cpp:558] conv2_5_1 <- conv2_5_0
I0927 00:20:24.162462 19128 net.cpp:522] conv2_5_1 -> conv2_5_1
I0927 00:20:24.169148 19128 net.cpp:172] Setting up conv2_5_1
I0927 00:20:24.169176 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.169181 19128 net.cpp:194] Memory required for data: 36167800
I0927 00:20:24.169190 19128 layer_factory.hpp:77] Creating layer conv2_5bn1
I0927 00:20:24.169201 19128 net.cpp:128] Creating Layer conv2_5bn1
I0927 00:20:24.169206 19128 net.cpp:558] conv2_5bn1 <- conv2_5_1
I0927 00:20:24.169216 19128 net.cpp:509] conv2_5bn1 -> conv2_5_1 (in-place)
I0927 00:20:24.169517 19128 net.cpp:172] Setting up conv2_5bn1
I0927 00:20:24.169529 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.169533 19128 net.cpp:194] Memory required for data: 36823160
I0927 00:20:24.169543 19128 layer_factory.hpp:77] Creating layer conv2_5_scale1
I0927 00:20:24.169550 19128 net.cpp:128] Creating Layer conv2_5_scale1
I0927 00:20:24.169554 19128 net.cpp:558] conv2_5_scale1 <- conv2_5_1
I0927 00:20:24.169560 19128 net.cpp:509] conv2_5_scale1 -> conv2_5_1 (in-place)
I0927 00:20:24.169612 19128 layer_factory.hpp:77] Creating layer conv2_5_scale1
I0927 00:20:24.169782 19128 net.cpp:172] Setting up conv2_5_scale1
I0927 00:20:24.169790 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.169795 19128 net.cpp:194] Memory required for data: 37478520
I0927 00:20:24.169802 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_5
I0927 00:20:24.169811 19128 net.cpp:128] Creating Layer conv2_Eltwise_5
I0927 00:20:24.169816 19128 net.cpp:558] conv2_Eltwise_5 <- conv2_Eltwise_4_conv2_4ReLU_1_0_split_1
I0927 00:20:24.169822 19128 net.cpp:558] conv2_Eltwise_5 <- conv2_5_1
I0927 00:20:24.169828 19128 net.cpp:522] conv2_Eltwise_5 -> conv2_Eltwise_5
I0927 00:20:24.169862 19128 net.cpp:172] Setting up conv2_Eltwise_5
I0927 00:20:24.169869 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.169873 19128 net.cpp:194] Memory required for data: 38133880
I0927 00:20:24.169878 19128 layer_factory.hpp:77] Creating layer conv2_5ReLU_1
I0927 00:20:24.169883 19128 net.cpp:128] Creating Layer conv2_5ReLU_1
I0927 00:20:24.169888 19128 net.cpp:558] conv2_5ReLU_1 <- conv2_Eltwise_5
I0927 00:20:24.169896 19128 net.cpp:509] conv2_5ReLU_1 -> conv2_Eltwise_5 (in-place)
I0927 00:20:24.171206 19128 net.cpp:172] Setting up conv2_5ReLU_1
I0927 00:20:24.171222 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.171226 19128 net.cpp:194] Memory required for data: 38789240
I0927 00:20:24.171232 19128 layer_factory.hpp:77] Creating layer conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0927 00:20:24.171239 19128 net.cpp:128] Creating Layer conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0927 00:20:24.171247 19128 net.cpp:558] conv2_Eltwise_5_conv2_5ReLU_1_0_split <- conv2_Eltwise_5
I0927 00:20:24.171255 19128 net.cpp:522] conv2_Eltwise_5_conv2_5ReLU_1_0_split -> conv2_Eltwise_5_conv2_5ReLU_1_0_split_0
I0927 00:20:24.171264 19128 net.cpp:522] conv2_Eltwise_5_conv2_5ReLU_1_0_split -> conv2_Eltwise_5_conv2_5ReLU_1_0_split_1
I0927 00:20:24.171341 19128 net.cpp:172] Setting up conv2_Eltwise_5_conv2_5ReLU_1_0_split
I0927 00:20:24.171350 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.171355 19128 net.cpp:186] Top shape: 10 16 32 32 (163840)
I0927 00:20:24.171360 19128 net.cpp:194] Memory required for data: 40099960
I0927 00:20:24.171365 19128 layer_factory.hpp:77] Creating layer conv3_1_0
I0927 00:20:24.171377 19128 net.cpp:128] Creating Layer conv3_1_0
I0927 00:20:24.171382 19128 net.cpp:558] conv3_1_0 <- conv2_Eltwise_5_conv2_5ReLU_1_0_split_0
I0927 00:20:24.171393 19128 net.cpp:522] conv3_1_0 -> conv3_1_0
I0927 00:20:24.177950 19128 net.cpp:172] Setting up conv3_1_0
I0927 00:20:24.177980 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.177985 19128 net.cpp:194] Memory required for data: 40427640
I0927 00:20:24.177999 19128 layer_factory.hpp:77] Creating layer conv3_1_bn0
I0927 00:20:24.178009 19128 net.cpp:128] Creating Layer conv3_1_bn0
I0927 00:20:24.178014 19128 net.cpp:558] conv3_1_bn0 <- conv3_1_0
I0927 00:20:24.178021 19128 net.cpp:509] conv3_1_bn0 -> conv3_1_0 (in-place)
I0927 00:20:24.178313 19128 net.cpp:172] Setting up conv3_1_bn0
I0927 00:20:24.178325 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.178330 19128 net.cpp:194] Memory required for data: 40755320
I0927 00:20:24.178340 19128 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0927 00:20:24.178350 19128 net.cpp:128] Creating Layer conv3_1_scale0
I0927 00:20:24.178355 19128 net.cpp:558] conv3_1_scale0 <- conv3_1_0
I0927 00:20:24.178361 19128 net.cpp:509] conv3_1_scale0 -> conv3_1_0 (in-place)
I0927 00:20:24.178414 19128 layer_factory.hpp:77] Creating layer conv3_1_scale0
I0927 00:20:24.178578 19128 net.cpp:172] Setting up conv3_1_scale0
I0927 00:20:24.178586 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.178591 19128 net.cpp:194] Memory required for data: 41083000
I0927 00:20:24.178598 19128 layer_factory.hpp:77] Creating layer conv3_1_ReLU0
I0927 00:20:24.178611 19128 net.cpp:128] Creating Layer conv3_1_ReLU0
I0927 00:20:24.178616 19128 net.cpp:558] conv3_1_ReLU0 <- conv3_1_0
I0927 00:20:24.178622 19128 net.cpp:509] conv3_1_ReLU0 -> conv3_1_0 (in-place)
I0927 00:20:24.179991 19128 net.cpp:172] Setting up conv3_1_ReLU0
I0927 00:20:24.180011 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.180016 19128 net.cpp:194] Memory required for data: 41410680
I0927 00:20:24.180021 19128 layer_factory.hpp:77] Creating layer conv3_1_1
I0927 00:20:24.180037 19128 net.cpp:128] Creating Layer conv3_1_1
I0927 00:20:24.180042 19128 net.cpp:558] conv3_1_1 <- conv3_1_0
I0927 00:20:24.180052 19128 net.cpp:522] conv3_1_1 -> conv3_1_1
I0927 00:20:24.186739 19128 net.cpp:172] Setting up conv3_1_1
I0927 00:20:24.186766 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.186771 19128 net.cpp:194] Memory required for data: 41738360
I0927 00:20:24.186781 19128 layer_factory.hpp:77] Creating layer conv3_1bn1
I0927 00:20:24.186792 19128 net.cpp:128] Creating Layer conv3_1bn1
I0927 00:20:24.186799 19128 net.cpp:558] conv3_1bn1 <- conv3_1_1
I0927 00:20:24.186807 19128 net.cpp:509] conv3_1bn1 -> conv3_1_1 (in-place)
I0927 00:20:24.187108 19128 net.cpp:172] Setting up conv3_1bn1
I0927 00:20:24.187120 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.187125 19128 net.cpp:194] Memory required for data: 42066040
I0927 00:20:24.187135 19128 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0927 00:20:24.187145 19128 net.cpp:128] Creating Layer conv3_1_scale1
I0927 00:20:24.187150 19128 net.cpp:558] conv3_1_scale1 <- conv3_1_1
I0927 00:20:24.187156 19128 net.cpp:509] conv3_1_scale1 -> conv3_1_1 (in-place)
I0927 00:20:24.187211 19128 layer_factory.hpp:77] Creating layer conv3_1_scale1
I0927 00:20:24.187381 19128 net.cpp:172] Setting up conv3_1_scale1
I0927 00:20:24.187389 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.187393 19128 net.cpp:194] Memory required for data: 42393720
I0927 00:20:24.187402 19128 layer_factory.hpp:77] Creating layer conv3_1_down
I0927 00:20:24.187435 19128 net.cpp:128] Creating Layer conv3_1_down
I0927 00:20:24.187441 19128 net.cpp:558] conv3_1_down <- conv2_Eltwise_5_conv2_5ReLU_1_0_split_1
I0927 00:20:24.187448 19128 net.cpp:522] conv3_1_down -> conv3_1_down
I0927 00:20:24.193325 19128 net.cpp:172] Setting up conv3_1_down
I0927 00:20:24.193351 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.193356 19128 net.cpp:194] Memory required for data: 42721400
I0927 00:20:24.193365 19128 layer_factory.hpp:77] Creating layer conv3_1_bn_down
I0927 00:20:24.193374 19128 net.cpp:128] Creating Layer conv3_1_bn_down
I0927 00:20:24.193379 19128 net.cpp:558] conv3_1_bn_down <- conv3_1_down
I0927 00:20:24.193388 19128 net.cpp:509] conv3_1_bn_down -> conv3_1_down (in-place)
I0927 00:20:24.193686 19128 net.cpp:172] Setting up conv3_1_bn_down
I0927 00:20:24.193697 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.193701 19128 net.cpp:194] Memory required for data: 43049080
I0927 00:20:24.193711 19128 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0927 00:20:24.193718 19128 net.cpp:128] Creating Layer conv3_1_scale_down
I0927 00:20:24.193722 19128 net.cpp:558] conv3_1_scale_down <- conv3_1_down
I0927 00:20:24.193730 19128 net.cpp:509] conv3_1_scale_down -> conv3_1_down (in-place)
I0927 00:20:24.193781 19128 layer_factory.hpp:77] Creating layer conv3_1_scale_down
I0927 00:20:24.193948 19128 net.cpp:172] Setting up conv3_1_scale_down
I0927 00:20:24.193955 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.193959 19128 net.cpp:194] Memory required for data: 43376760
I0927 00:20:24.193967 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_1
I0927 00:20:24.193974 19128 net.cpp:128] Creating Layer conv3_Eltwise_1
I0927 00:20:24.193979 19128 net.cpp:558] conv3_Eltwise_1 <- conv3_1_1
I0927 00:20:24.193984 19128 net.cpp:558] conv3_Eltwise_1 <- conv3_1_down
I0927 00:20:24.193992 19128 net.cpp:522] conv3_Eltwise_1 -> conv3_Eltwise_1
I0927 00:20:24.194016 19128 net.cpp:172] Setting up conv3_Eltwise_1
I0927 00:20:24.194023 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.194027 19128 net.cpp:194] Memory required for data: 43704440
I0927 00:20:24.194031 19128 layer_factory.hpp:77] Creating layer conv3_1ReLU_1
I0927 00:20:24.194041 19128 net.cpp:128] Creating Layer conv3_1ReLU_1
I0927 00:20:24.194046 19128 net.cpp:558] conv3_1ReLU_1 <- conv3_Eltwise_1
I0927 00:20:24.194051 19128 net.cpp:509] conv3_1ReLU_1 -> conv3_Eltwise_1 (in-place)
I0927 00:20:24.194559 19128 net.cpp:172] Setting up conv3_1ReLU_1
I0927 00:20:24.194582 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.194587 19128 net.cpp:194] Memory required for data: 44032120
I0927 00:20:24.194592 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0927 00:20:24.194600 19128 net.cpp:128] Creating Layer conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0927 00:20:24.194605 19128 net.cpp:558] conv3_Eltwise_1_conv3_1ReLU_1_0_split <- conv3_Eltwise_1
I0927 00:20:24.194614 19128 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0927 00:20:24.194623 19128 net.cpp:522] conv3_Eltwise_1_conv3_1ReLU_1_0_split -> conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0927 00:20:24.194684 19128 net.cpp:172] Setting up conv3_Eltwise_1_conv3_1ReLU_1_0_split
I0927 00:20:24.194692 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.194699 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.194702 19128 net.cpp:194] Memory required for data: 44687480
I0927 00:20:24.194706 19128 layer_factory.hpp:77] Creating layer conv3_2_0
I0927 00:20:24.194718 19128 net.cpp:128] Creating Layer conv3_2_0
I0927 00:20:24.194723 19128 net.cpp:558] conv3_2_0 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_0
I0927 00:20:24.194732 19128 net.cpp:522] conv3_2_0 -> conv3_2_0
I0927 00:20:24.196665 19128 net.cpp:172] Setting up conv3_2_0
I0927 00:20:24.196688 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.196692 19128 net.cpp:194] Memory required for data: 45015160
I0927 00:20:24.196720 19128 layer_factory.hpp:77] Creating layer conv3_2_bn0
I0927 00:20:24.196732 19128 net.cpp:128] Creating Layer conv3_2_bn0
I0927 00:20:24.196738 19128 net.cpp:558] conv3_2_bn0 <- conv3_2_0
I0927 00:20:24.196744 19128 net.cpp:509] conv3_2_bn0 -> conv3_2_0 (in-place)
I0927 00:20:24.197048 19128 net.cpp:172] Setting up conv3_2_bn0
I0927 00:20:24.197057 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.197060 19128 net.cpp:194] Memory required for data: 45342840
I0927 00:20:24.197070 19128 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0927 00:20:24.197077 19128 net.cpp:128] Creating Layer conv3_2_scale0
I0927 00:20:24.197082 19128 net.cpp:558] conv3_2_scale0 <- conv3_2_0
I0927 00:20:24.197089 19128 net.cpp:509] conv3_2_scale0 -> conv3_2_0 (in-place)
I0927 00:20:24.197141 19128 layer_factory.hpp:77] Creating layer conv3_2_scale0
I0927 00:20:24.197311 19128 net.cpp:172] Setting up conv3_2_scale0
I0927 00:20:24.197319 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.197322 19128 net.cpp:194] Memory required for data: 45670520
I0927 00:20:24.197330 19128 layer_factory.hpp:77] Creating layer conv3_2_ReLU0
I0927 00:20:24.197337 19128 net.cpp:128] Creating Layer conv3_2_ReLU0
I0927 00:20:24.197341 19128 net.cpp:558] conv3_2_ReLU0 <- conv3_2_0
I0927 00:20:24.197350 19128 net.cpp:509] conv3_2_ReLU0 -> conv3_2_0 (in-place)
I0927 00:20:24.198302 19128 net.cpp:172] Setting up conv3_2_ReLU0
I0927 00:20:24.198312 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.198316 19128 net.cpp:194] Memory required for data: 45998200
I0927 00:20:24.198321 19128 layer_factory.hpp:77] Creating layer conv3_2_1
I0927 00:20:24.198333 19128 net.cpp:128] Creating Layer conv3_2_1
I0927 00:20:24.198338 19128 net.cpp:558] conv3_2_1 <- conv3_2_0
I0927 00:20:24.198348 19128 net.cpp:522] conv3_2_1 -> conv3_2_1
I0927 00:20:24.205117 19128 net.cpp:172] Setting up conv3_2_1
I0927 00:20:24.205148 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.205153 19128 net.cpp:194] Memory required for data: 46325880
I0927 00:20:24.205168 19128 layer_factory.hpp:77] Creating layer conv3_2bn1
I0927 00:20:24.205178 19128 net.cpp:128] Creating Layer conv3_2bn1
I0927 00:20:24.205183 19128 net.cpp:558] conv3_2bn1 <- conv3_2_1
I0927 00:20:24.205193 19128 net.cpp:509] conv3_2bn1 -> conv3_2_1 (in-place)
I0927 00:20:24.205504 19128 net.cpp:172] Setting up conv3_2bn1
I0927 00:20:24.205518 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.205521 19128 net.cpp:194] Memory required for data: 46653560
I0927 00:20:24.205531 19128 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0927 00:20:24.205539 19128 net.cpp:128] Creating Layer conv3_2_scale1
I0927 00:20:24.205544 19128 net.cpp:558] conv3_2_scale1 <- conv3_2_1
I0927 00:20:24.205549 19128 net.cpp:509] conv3_2_scale1 -> conv3_2_1 (in-place)
I0927 00:20:24.205608 19128 layer_factory.hpp:77] Creating layer conv3_2_scale1
I0927 00:20:24.205783 19128 net.cpp:172] Setting up conv3_2_scale1
I0927 00:20:24.205796 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.205801 19128 net.cpp:194] Memory required for data: 46981240
I0927 00:20:24.205809 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_2
I0927 00:20:24.205818 19128 net.cpp:128] Creating Layer conv3_Eltwise_2
I0927 00:20:24.205823 19128 net.cpp:558] conv3_Eltwise_2 <- conv3_Eltwise_1_conv3_1ReLU_1_0_split_1
I0927 00:20:24.205828 19128 net.cpp:558] conv3_Eltwise_2 <- conv3_2_1
I0927 00:20:24.205834 19128 net.cpp:522] conv3_Eltwise_2 -> conv3_Eltwise_2
I0927 00:20:24.205863 19128 net.cpp:172] Setting up conv3_Eltwise_2
I0927 00:20:24.205870 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.205874 19128 net.cpp:194] Memory required for data: 47308920
I0927 00:20:24.205878 19128 layer_factory.hpp:77] Creating layer conv3_2ReLU_1
I0927 00:20:24.205884 19128 net.cpp:128] Creating Layer conv3_2ReLU_1
I0927 00:20:24.205888 19128 net.cpp:558] conv3_2ReLU_1 <- conv3_Eltwise_2
I0927 00:20:24.205898 19128 net.cpp:509] conv3_2ReLU_1 -> conv3_Eltwise_2 (in-place)
I0927 00:20:24.207132 19128 net.cpp:172] Setting up conv3_2ReLU_1
I0927 00:20:24.207154 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.207159 19128 net.cpp:194] Memory required for data: 47636600
I0927 00:20:24.207165 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0927 00:20:24.207176 19128 net.cpp:128] Creating Layer conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0927 00:20:24.207181 19128 net.cpp:558] conv3_Eltwise_2_conv3_2ReLU_1_0_split <- conv3_Eltwise_2
I0927 00:20:24.207192 19128 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0927 00:20:24.207204 19128 net.cpp:522] conv3_Eltwise_2_conv3_2ReLU_1_0_split -> conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0927 00:20:24.207267 19128 net.cpp:172] Setting up conv3_Eltwise_2_conv3_2ReLU_1_0_split
I0927 00:20:24.207278 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.207283 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.207288 19128 net.cpp:194] Memory required for data: 48291960
I0927 00:20:24.207291 19128 layer_factory.hpp:77] Creating layer conv3_3_0
I0927 00:20:24.207305 19128 net.cpp:128] Creating Layer conv3_3_0
I0927 00:20:24.207310 19128 net.cpp:558] conv3_3_0 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_0
I0927 00:20:24.207320 19128 net.cpp:522] conv3_3_0 -> conv3_3_0
I0927 00:20:24.213868 19128 net.cpp:172] Setting up conv3_3_0
I0927 00:20:24.213896 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.213901 19128 net.cpp:194] Memory required for data: 48619640
I0927 00:20:24.213915 19128 layer_factory.hpp:77] Creating layer conv3_3_bn0
I0927 00:20:24.213927 19128 net.cpp:128] Creating Layer conv3_3_bn0
I0927 00:20:24.213932 19128 net.cpp:558] conv3_3_bn0 <- conv3_3_0
I0927 00:20:24.213946 19128 net.cpp:509] conv3_3_bn0 -> conv3_3_0 (in-place)
I0927 00:20:24.214252 19128 net.cpp:172] Setting up conv3_3_bn0
I0927 00:20:24.214260 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.214264 19128 net.cpp:194] Memory required for data: 48947320
I0927 00:20:24.214274 19128 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0927 00:20:24.214282 19128 net.cpp:128] Creating Layer conv3_3_scale0
I0927 00:20:24.214285 19128 net.cpp:558] conv3_3_scale0 <- conv3_3_0
I0927 00:20:24.214296 19128 net.cpp:509] conv3_3_scale0 -> conv3_3_0 (in-place)
I0927 00:20:24.214349 19128 layer_factory.hpp:77] Creating layer conv3_3_scale0
I0927 00:20:24.214520 19128 net.cpp:172] Setting up conv3_3_scale0
I0927 00:20:24.214529 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.214532 19128 net.cpp:194] Memory required for data: 49275000
I0927 00:20:24.214540 19128 layer_factory.hpp:77] Creating layer conv3_3_ReLU0
I0927 00:20:24.214547 19128 net.cpp:128] Creating Layer conv3_3_ReLU0
I0927 00:20:24.214551 19128 net.cpp:558] conv3_3_ReLU0 <- conv3_3_0
I0927 00:20:24.214560 19128 net.cpp:509] conv3_3_ReLU0 -> conv3_3_0 (in-place)
I0927 00:20:24.215919 19128 net.cpp:172] Setting up conv3_3_ReLU0
I0927 00:20:24.215939 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.215943 19128 net.cpp:194] Memory required for data: 49602680
I0927 00:20:24.215948 19128 layer_factory.hpp:77] Creating layer conv3_3_1
I0927 00:20:24.215961 19128 net.cpp:128] Creating Layer conv3_3_1
I0927 00:20:24.215967 19128 net.cpp:558] conv3_3_1 <- conv3_3_0
I0927 00:20:24.215977 19128 net.cpp:522] conv3_3_1 -> conv3_3_1
I0927 00:20:24.222718 19128 net.cpp:172] Setting up conv3_3_1
I0927 00:20:24.222744 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.222749 19128 net.cpp:194] Memory required for data: 49930360
I0927 00:20:24.222759 19128 layer_factory.hpp:77] Creating layer conv3_3bn1
I0927 00:20:24.222771 19128 net.cpp:128] Creating Layer conv3_3bn1
I0927 00:20:24.222776 19128 net.cpp:558] conv3_3bn1 <- conv3_3_1
I0927 00:20:24.222790 19128 net.cpp:509] conv3_3bn1 -> conv3_3_1 (in-place)
I0927 00:20:24.223114 19128 net.cpp:172] Setting up conv3_3bn1
I0927 00:20:24.223121 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.223140 19128 net.cpp:194] Memory required for data: 50258040
I0927 00:20:24.223152 19128 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0927 00:20:24.223160 19128 net.cpp:128] Creating Layer conv3_3_scale1
I0927 00:20:24.223165 19128 net.cpp:558] conv3_3_scale1 <- conv3_3_1
I0927 00:20:24.223171 19128 net.cpp:509] conv3_3_scale1 -> conv3_3_1 (in-place)
I0927 00:20:24.223228 19128 layer_factory.hpp:77] Creating layer conv3_3_scale1
I0927 00:20:24.223403 19128 net.cpp:172] Setting up conv3_3_scale1
I0927 00:20:24.223424 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.223428 19128 net.cpp:194] Memory required for data: 50585720
I0927 00:20:24.223438 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_3
I0927 00:20:24.223448 19128 net.cpp:128] Creating Layer conv3_Eltwise_3
I0927 00:20:24.223453 19128 net.cpp:558] conv3_Eltwise_3 <- conv3_Eltwise_2_conv3_2ReLU_1_0_split_1
I0927 00:20:24.223459 19128 net.cpp:558] conv3_Eltwise_3 <- conv3_3_1
I0927 00:20:24.223465 19128 net.cpp:522] conv3_Eltwise_3 -> conv3_Eltwise_3
I0927 00:20:24.223495 19128 net.cpp:172] Setting up conv3_Eltwise_3
I0927 00:20:24.223501 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.223505 19128 net.cpp:194] Memory required for data: 50913400
I0927 00:20:24.223510 19128 layer_factory.hpp:77] Creating layer conv3_3ReLU_1
I0927 00:20:24.223516 19128 net.cpp:128] Creating Layer conv3_3ReLU_1
I0927 00:20:24.223520 19128 net.cpp:558] conv3_3ReLU_1 <- conv3_Eltwise_3
I0927 00:20:24.223528 19128 net.cpp:509] conv3_3ReLU_1 -> conv3_Eltwise_3 (in-place)
I0927 00:20:24.224730 19128 net.cpp:172] Setting up conv3_3ReLU_1
I0927 00:20:24.224753 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.224757 19128 net.cpp:194] Memory required for data: 51241080
I0927 00:20:24.224763 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0927 00:20:24.224771 19128 net.cpp:128] Creating Layer conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0927 00:20:24.224776 19128 net.cpp:558] conv3_Eltwise_3_conv3_3ReLU_1_0_split <- conv3_Eltwise_3
I0927 00:20:24.224787 19128 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0927 00:20:24.224797 19128 net.cpp:522] conv3_Eltwise_3_conv3_3ReLU_1_0_split -> conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0927 00:20:24.224864 19128 net.cpp:172] Setting up conv3_Eltwise_3_conv3_3ReLU_1_0_split
I0927 00:20:24.224877 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.224884 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.224887 19128 net.cpp:194] Memory required for data: 51896440
I0927 00:20:24.224891 19128 layer_factory.hpp:77] Creating layer conv3_4_0
I0927 00:20:24.224905 19128 net.cpp:128] Creating Layer conv3_4_0
I0927 00:20:24.224910 19128 net.cpp:558] conv3_4_0 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_0
I0927 00:20:24.224920 19128 net.cpp:522] conv3_4_0 -> conv3_4_0
I0927 00:20:24.231489 19128 net.cpp:172] Setting up conv3_4_0
I0927 00:20:24.231515 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.231520 19128 net.cpp:194] Memory required for data: 52224120
I0927 00:20:24.231530 19128 layer_factory.hpp:77] Creating layer conv3_4_bn0
I0927 00:20:24.231544 19128 net.cpp:128] Creating Layer conv3_4_bn0
I0927 00:20:24.231549 19128 net.cpp:558] conv3_4_bn0 <- conv3_4_0
I0927 00:20:24.231559 19128 net.cpp:509] conv3_4_bn0 -> conv3_4_0 (in-place)
I0927 00:20:24.231859 19128 net.cpp:172] Setting up conv3_4_bn0
I0927 00:20:24.231873 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.231878 19128 net.cpp:194] Memory required for data: 52551800
I0927 00:20:24.231902 19128 layer_factory.hpp:77] Creating layer conv3_4_scale0
I0927 00:20:24.231910 19128 net.cpp:128] Creating Layer conv3_4_scale0
I0927 00:20:24.231914 19128 net.cpp:558] conv3_4_scale0 <- conv3_4_0
I0927 00:20:24.231922 19128 net.cpp:509] conv3_4_scale0 -> conv3_4_0 (in-place)
I0927 00:20:24.231977 19128 layer_factory.hpp:77] Creating layer conv3_4_scale0
I0927 00:20:24.232151 19128 net.cpp:172] Setting up conv3_4_scale0
I0927 00:20:24.232177 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.232182 19128 net.cpp:194] Memory required for data: 52879480
I0927 00:20:24.232190 19128 layer_factory.hpp:77] Creating layer conv3_4_ReLU0
I0927 00:20:24.232197 19128 net.cpp:128] Creating Layer conv3_4_ReLU0
I0927 00:20:24.232203 19128 net.cpp:558] conv3_4_ReLU0 <- conv3_4_0
I0927 00:20:24.232208 19128 net.cpp:509] conv3_4_ReLU0 -> conv3_4_0 (in-place)
I0927 00:20:24.233537 19128 net.cpp:172] Setting up conv3_4_ReLU0
I0927 00:20:24.233559 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.233563 19128 net.cpp:194] Memory required for data: 53207160
I0927 00:20:24.233568 19128 layer_factory.hpp:77] Creating layer conv3_4_1
I0927 00:20:24.233585 19128 net.cpp:128] Creating Layer conv3_4_1
I0927 00:20:24.233592 19128 net.cpp:558] conv3_4_1 <- conv3_4_0
I0927 00:20:24.233603 19128 net.cpp:522] conv3_4_1 -> conv3_4_1
I0927 00:20:24.240211 19128 net.cpp:172] Setting up conv3_4_1
I0927 00:20:24.240237 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.240242 19128 net.cpp:194] Memory required for data: 53534840
I0927 00:20:24.240255 19128 layer_factory.hpp:77] Creating layer conv3_4bn1
I0927 00:20:24.240264 19128 net.cpp:128] Creating Layer conv3_4bn1
I0927 00:20:24.240269 19128 net.cpp:558] conv3_4bn1 <- conv3_4_1
I0927 00:20:24.240276 19128 net.cpp:509] conv3_4bn1 -> conv3_4_1 (in-place)
I0927 00:20:24.240576 19128 net.cpp:172] Setting up conv3_4bn1
I0927 00:20:24.240586 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.240591 19128 net.cpp:194] Memory required for data: 53862520
I0927 00:20:24.240600 19128 layer_factory.hpp:77] Creating layer conv3_4_scale1
I0927 00:20:24.240610 19128 net.cpp:128] Creating Layer conv3_4_scale1
I0927 00:20:24.240615 19128 net.cpp:558] conv3_4_scale1 <- conv3_4_1
I0927 00:20:24.240620 19128 net.cpp:509] conv3_4_scale1 -> conv3_4_1 (in-place)
I0927 00:20:24.240679 19128 layer_factory.hpp:77] Creating layer conv3_4_scale1
I0927 00:20:24.240849 19128 net.cpp:172] Setting up conv3_4_scale1
I0927 00:20:24.240857 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.240861 19128 net.cpp:194] Memory required for data: 54190200
I0927 00:20:24.240869 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_4
I0927 00:20:24.240878 19128 net.cpp:128] Creating Layer conv3_Eltwise_4
I0927 00:20:24.240883 19128 net.cpp:558] conv3_Eltwise_4 <- conv3_Eltwise_3_conv3_3ReLU_1_0_split_1
I0927 00:20:24.240887 19128 net.cpp:558] conv3_Eltwise_4 <- conv3_4_1
I0927 00:20:24.240893 19128 net.cpp:522] conv3_Eltwise_4 -> conv3_Eltwise_4
I0927 00:20:24.240918 19128 net.cpp:172] Setting up conv3_Eltwise_4
I0927 00:20:24.240926 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.240929 19128 net.cpp:194] Memory required for data: 54517880
I0927 00:20:24.240933 19128 layer_factory.hpp:77] Creating layer conv3_4ReLU_1
I0927 00:20:24.240942 19128 net.cpp:128] Creating Layer conv3_4ReLU_1
I0927 00:20:24.240947 19128 net.cpp:558] conv3_4ReLU_1 <- conv3_Eltwise_4
I0927 00:20:24.240955 19128 net.cpp:509] conv3_4ReLU_1 -> conv3_Eltwise_4 (in-place)
I0927 00:20:24.241209 19128 net.cpp:172] Setting up conv3_4ReLU_1
I0927 00:20:24.241225 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.241230 19128 net.cpp:194] Memory required for data: 54845560
I0927 00:20:24.241233 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0927 00:20:24.241243 19128 net.cpp:128] Creating Layer conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0927 00:20:24.241247 19128 net.cpp:558] conv3_Eltwise_4_conv3_4ReLU_1_0_split <- conv3_Eltwise_4
I0927 00:20:24.241256 19128 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I0927 00:20:24.241264 19128 net.cpp:522] conv3_Eltwise_4_conv3_4ReLU_1_0_split -> conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I0927 00:20:24.241323 19128 net.cpp:172] Setting up conv3_Eltwise_4_conv3_4ReLU_1_0_split
I0927 00:20:24.241333 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.241338 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.241358 19128 net.cpp:194] Memory required for data: 55500920
I0927 00:20:24.241363 19128 layer_factory.hpp:77] Creating layer conv3_5_0
I0927 00:20:24.241374 19128 net.cpp:128] Creating Layer conv3_5_0
I0927 00:20:24.241379 19128 net.cpp:558] conv3_5_0 <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_0
I0927 00:20:24.241389 19128 net.cpp:522] conv3_5_0 -> conv3_5_0
I0927 00:20:24.246786 19128 net.cpp:172] Setting up conv3_5_0
I0927 00:20:24.246824 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.246829 19128 net.cpp:194] Memory required for data: 55828600
I0927 00:20:24.246839 19128 layer_factory.hpp:77] Creating layer conv3_5_bn0
I0927 00:20:24.246847 19128 net.cpp:128] Creating Layer conv3_5_bn0
I0927 00:20:24.246852 19128 net.cpp:558] conv3_5_bn0 <- conv3_5_0
I0927 00:20:24.246862 19128 net.cpp:509] conv3_5_bn0 -> conv3_5_0 (in-place)
I0927 00:20:24.247172 19128 net.cpp:172] Setting up conv3_5_bn0
I0927 00:20:24.247185 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.247189 19128 net.cpp:194] Memory required for data: 56156280
I0927 00:20:24.247198 19128 layer_factory.hpp:77] Creating layer conv3_5_scale0
I0927 00:20:24.247205 19128 net.cpp:128] Creating Layer conv3_5_scale0
I0927 00:20:24.247210 19128 net.cpp:558] conv3_5_scale0 <- conv3_5_0
I0927 00:20:24.247215 19128 net.cpp:509] conv3_5_scale0 -> conv3_5_0 (in-place)
I0927 00:20:24.247272 19128 layer_factory.hpp:77] Creating layer conv3_5_scale0
I0927 00:20:24.247442 19128 net.cpp:172] Setting up conv3_5_scale0
I0927 00:20:24.247452 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.247457 19128 net.cpp:194] Memory required for data: 56483960
I0927 00:20:24.247464 19128 layer_factory.hpp:77] Creating layer conv3_5_ReLU0
I0927 00:20:24.247472 19128 net.cpp:128] Creating Layer conv3_5_ReLU0
I0927 00:20:24.247475 19128 net.cpp:558] conv3_5_ReLU0 <- conv3_5_0
I0927 00:20:24.247480 19128 net.cpp:509] conv3_5_ReLU0 -> conv3_5_0 (in-place)
I0927 00:20:24.248805 19128 net.cpp:172] Setting up conv3_5_ReLU0
I0927 00:20:24.248831 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.248836 19128 net.cpp:194] Memory required for data: 56811640
I0927 00:20:24.248842 19128 layer_factory.hpp:77] Creating layer conv3_5_1
I0927 00:20:24.248859 19128 net.cpp:128] Creating Layer conv3_5_1
I0927 00:20:24.248864 19128 net.cpp:558] conv3_5_1 <- conv3_5_0
I0927 00:20:24.248877 19128 net.cpp:522] conv3_5_1 -> conv3_5_1
I0927 00:20:24.255543 19128 net.cpp:172] Setting up conv3_5_1
I0927 00:20:24.255570 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.255575 19128 net.cpp:194] Memory required for data: 57139320
I0927 00:20:24.255589 19128 layer_factory.hpp:77] Creating layer conv3_5bn1
I0927 00:20:24.255600 19128 net.cpp:128] Creating Layer conv3_5bn1
I0927 00:20:24.255609 19128 net.cpp:558] conv3_5bn1 <- conv3_5_1
I0927 00:20:24.255619 19128 net.cpp:509] conv3_5bn1 -> conv3_5_1 (in-place)
I0927 00:20:24.255926 19128 net.cpp:172] Setting up conv3_5bn1
I0927 00:20:24.255939 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.255942 19128 net.cpp:194] Memory required for data: 57467000
I0927 00:20:24.255952 19128 layer_factory.hpp:77] Creating layer conv3_5_scale1
I0927 00:20:24.255959 19128 net.cpp:128] Creating Layer conv3_5_scale1
I0927 00:20:24.255964 19128 net.cpp:558] conv3_5_scale1 <- conv3_5_1
I0927 00:20:24.255972 19128 net.cpp:509] conv3_5_scale1 -> conv3_5_1 (in-place)
I0927 00:20:24.256029 19128 layer_factory.hpp:77] Creating layer conv3_5_scale1
I0927 00:20:24.256207 19128 net.cpp:172] Setting up conv3_5_scale1
I0927 00:20:24.256217 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.256222 19128 net.cpp:194] Memory required for data: 57794680
I0927 00:20:24.256230 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_5
I0927 00:20:24.256237 19128 net.cpp:128] Creating Layer conv3_Eltwise_5
I0927 00:20:24.256242 19128 net.cpp:558] conv3_Eltwise_5 <- conv3_Eltwise_4_conv3_4ReLU_1_0_split_1
I0927 00:20:24.256247 19128 net.cpp:558] conv3_Eltwise_5 <- conv3_5_1
I0927 00:20:24.256275 19128 net.cpp:522] conv3_Eltwise_5 -> conv3_Eltwise_5
I0927 00:20:24.256304 19128 net.cpp:172] Setting up conv3_Eltwise_5
I0927 00:20:24.256312 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.256316 19128 net.cpp:194] Memory required for data: 58122360
I0927 00:20:24.256321 19128 layer_factory.hpp:77] Creating layer conv3_5ReLU_1
I0927 00:20:24.256327 19128 net.cpp:128] Creating Layer conv3_5ReLU_1
I0927 00:20:24.256332 19128 net.cpp:558] conv3_5ReLU_1 <- conv3_Eltwise_5
I0927 00:20:24.256337 19128 net.cpp:509] conv3_5ReLU_1 -> conv3_Eltwise_5 (in-place)
I0927 00:20:24.257551 19128 net.cpp:172] Setting up conv3_5ReLU_1
I0927 00:20:24.257572 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.257577 19128 net.cpp:194] Memory required for data: 58450040
I0927 00:20:24.257581 19128 layer_factory.hpp:77] Creating layer conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0927 00:20:24.257592 19128 net.cpp:128] Creating Layer conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0927 00:20:24.257597 19128 net.cpp:558] conv3_Eltwise_5_conv3_5ReLU_1_0_split <- conv3_Eltwise_5
I0927 00:20:24.257604 19128 net.cpp:522] conv3_Eltwise_5_conv3_5ReLU_1_0_split -> conv3_Eltwise_5_conv3_5ReLU_1_0_split_0
I0927 00:20:24.257614 19128 net.cpp:522] conv3_Eltwise_5_conv3_5ReLU_1_0_split -> conv3_Eltwise_5_conv3_5ReLU_1_0_split_1
I0927 00:20:24.257686 19128 net.cpp:172] Setting up conv3_Eltwise_5_conv3_5ReLU_1_0_split
I0927 00:20:24.257694 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.257700 19128 net.cpp:186] Top shape: 10 32 16 16 (81920)
I0927 00:20:24.257704 19128 net.cpp:194] Memory required for data: 59105400
I0927 00:20:24.257709 19128 layer_factory.hpp:77] Creating layer conv4_1_0
I0927 00:20:24.257724 19128 net.cpp:128] Creating Layer conv4_1_0
I0927 00:20:24.257728 19128 net.cpp:558] conv4_1_0 <- conv3_Eltwise_5_conv3_5ReLU_1_0_split_0
I0927 00:20:24.257735 19128 net.cpp:522] conv4_1_0 -> conv4_1_0
I0927 00:20:24.264300 19128 net.cpp:172] Setting up conv4_1_0
I0927 00:20:24.264328 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.264333 19128 net.cpp:194] Memory required for data: 59269240
I0927 00:20:24.264346 19128 layer_factory.hpp:77] Creating layer conv4_1_bn0
I0927 00:20:24.264360 19128 net.cpp:128] Creating Layer conv4_1_bn0
I0927 00:20:24.264369 19128 net.cpp:558] conv4_1_bn0 <- conv4_1_0
I0927 00:20:24.264376 19128 net.cpp:509] conv4_1_bn0 -> conv4_1_0 (in-place)
I0927 00:20:24.264701 19128 net.cpp:172] Setting up conv4_1_bn0
I0927 00:20:24.264713 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.264716 19128 net.cpp:194] Memory required for data: 59433080
I0927 00:20:24.264726 19128 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0927 00:20:24.264734 19128 net.cpp:128] Creating Layer conv4_1_scale0
I0927 00:20:24.264746 19128 net.cpp:558] conv4_1_scale0 <- conv4_1_0
I0927 00:20:24.264752 19128 net.cpp:509] conv4_1_scale0 -> conv4_1_0 (in-place)
I0927 00:20:24.264812 19128 layer_factory.hpp:77] Creating layer conv4_1_scale0
I0927 00:20:24.264993 19128 net.cpp:172] Setting up conv4_1_scale0
I0927 00:20:24.265003 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.265007 19128 net.cpp:194] Memory required for data: 59596920
I0927 00:20:24.265015 19128 layer_factory.hpp:77] Creating layer conv4_1_ReLU0
I0927 00:20:24.265022 19128 net.cpp:128] Creating Layer conv4_1_ReLU0
I0927 00:20:24.265027 19128 net.cpp:558] conv4_1_ReLU0 <- conv4_1_0
I0927 00:20:24.265031 19128 net.cpp:509] conv4_1_ReLU0 -> conv4_1_0 (in-place)
I0927 00:20:24.266299 19128 net.cpp:172] Setting up conv4_1_ReLU0
I0927 00:20:24.266321 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.266326 19128 net.cpp:194] Memory required for data: 59760760
I0927 00:20:24.266331 19128 layer_factory.hpp:77] Creating layer conv4_1_1
I0927 00:20:24.266343 19128 net.cpp:128] Creating Layer conv4_1_1
I0927 00:20:24.266348 19128 net.cpp:558] conv4_1_1 <- conv4_1_0
I0927 00:20:24.266356 19128 net.cpp:522] conv4_1_1 -> conv4_1_1
I0927 00:20:24.273008 19128 net.cpp:172] Setting up conv4_1_1
I0927 00:20:24.273056 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.273061 19128 net.cpp:194] Memory required for data: 59924600
I0927 00:20:24.273072 19128 layer_factory.hpp:77] Creating layer conv4_1bn1
I0927 00:20:24.273087 19128 net.cpp:128] Creating Layer conv4_1bn1
I0927 00:20:24.273093 19128 net.cpp:558] conv4_1bn1 <- conv4_1_1
I0927 00:20:24.273103 19128 net.cpp:509] conv4_1bn1 -> conv4_1_1 (in-place)
I0927 00:20:24.273427 19128 net.cpp:172] Setting up conv4_1bn1
I0927 00:20:24.273440 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.273445 19128 net.cpp:194] Memory required for data: 60088440
I0927 00:20:24.273455 19128 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0927 00:20:24.273463 19128 net.cpp:128] Creating Layer conv4_1_scale1
I0927 00:20:24.273468 19128 net.cpp:558] conv4_1_scale1 <- conv4_1_1
I0927 00:20:24.273473 19128 net.cpp:509] conv4_1_scale1 -> conv4_1_1 (in-place)
I0927 00:20:24.273535 19128 layer_factory.hpp:77] Creating layer conv4_1_scale1
I0927 00:20:24.273718 19128 net.cpp:172] Setting up conv4_1_scale1
I0927 00:20:24.273730 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.273735 19128 net.cpp:194] Memory required for data: 60252280
I0927 00:20:24.273742 19128 layer_factory.hpp:77] Creating layer conv4_1_down
I0927 00:20:24.273756 19128 net.cpp:128] Creating Layer conv4_1_down
I0927 00:20:24.273762 19128 net.cpp:558] conv4_1_down <- conv3_Eltwise_5_conv3_5ReLU_1_0_split_1
I0927 00:20:24.273769 19128 net.cpp:522] conv4_1_down -> conv4_1_down
I0927 00:20:24.279606 19128 net.cpp:172] Setting up conv4_1_down
I0927 00:20:24.279636 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.279641 19128 net.cpp:194] Memory required for data: 60416120
I0927 00:20:24.279651 19128 layer_factory.hpp:77] Creating layer conv4_1_bn_down
I0927 00:20:24.279661 19128 net.cpp:128] Creating Layer conv4_1_bn_down
I0927 00:20:24.279666 19128 net.cpp:558] conv4_1_bn_down <- conv4_1_down
I0927 00:20:24.279675 19128 net.cpp:509] conv4_1_bn_down -> conv4_1_down (in-place)
I0927 00:20:24.279994 19128 net.cpp:172] Setting up conv4_1_bn_down
I0927 00:20:24.280007 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.280011 19128 net.cpp:194] Memory required for data: 60579960
I0927 00:20:24.280021 19128 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0927 00:20:24.280028 19128 net.cpp:128] Creating Layer conv4_1_scale_down
I0927 00:20:24.280032 19128 net.cpp:558] conv4_1_scale_down <- conv4_1_down
I0927 00:20:24.280041 19128 net.cpp:509] conv4_1_scale_down -> conv4_1_down (in-place)
I0927 00:20:24.280099 19128 layer_factory.hpp:77] Creating layer conv4_1_scale_down
I0927 00:20:24.280278 19128 net.cpp:172] Setting up conv4_1_scale_down
I0927 00:20:24.280290 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.280294 19128 net.cpp:194] Memory required for data: 60743800
I0927 00:20:24.280303 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_1
I0927 00:20:24.280313 19128 net.cpp:128] Creating Layer conv4_Eltwise_1
I0927 00:20:24.280318 19128 net.cpp:558] conv4_Eltwise_1 <- conv4_1_1
I0927 00:20:24.280323 19128 net.cpp:558] conv4_Eltwise_1 <- conv4_1_down
I0927 00:20:24.280329 19128 net.cpp:522] conv4_Eltwise_1 -> conv4_Eltwise_1
I0927 00:20:24.280362 19128 net.cpp:172] Setting up conv4_Eltwise_1
I0927 00:20:24.280369 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.280373 19128 net.cpp:194] Memory required for data: 60907640
I0927 00:20:24.280377 19128 layer_factory.hpp:77] Creating layer conv4_1ReLU_1
I0927 00:20:24.280383 19128 net.cpp:128] Creating Layer conv4_1ReLU_1
I0927 00:20:24.280388 19128 net.cpp:558] conv4_1ReLU_1 <- conv4_Eltwise_1
I0927 00:20:24.280396 19128 net.cpp:509] conv4_1ReLU_1 -> conv4_Eltwise_1 (in-place)
I0927 00:20:24.281601 19128 net.cpp:172] Setting up conv4_1ReLU_1
I0927 00:20:24.281625 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.281630 19128 net.cpp:194] Memory required for data: 61071480
I0927 00:20:24.281635 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0927 00:20:24.281666 19128 net.cpp:128] Creating Layer conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0927 00:20:24.281672 19128 net.cpp:558] conv4_Eltwise_1_conv4_1ReLU_1_0_split <- conv4_Eltwise_1
I0927 00:20:24.281679 19128 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0927 00:20:24.281688 19128 net.cpp:522] conv4_Eltwise_1_conv4_1ReLU_1_0_split -> conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0927 00:20:24.281759 19128 net.cpp:172] Setting up conv4_Eltwise_1_conv4_1ReLU_1_0_split
I0927 00:20:24.281774 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.281780 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.281783 19128 net.cpp:194] Memory required for data: 61399160
I0927 00:20:24.281787 19128 layer_factory.hpp:77] Creating layer conv4_2_0
I0927 00:20:24.281800 19128 net.cpp:128] Creating Layer conv4_2_0
I0927 00:20:24.281805 19128 net.cpp:558] conv4_2_0 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_0
I0927 00:20:24.281814 19128 net.cpp:522] conv4_2_0 -> conv4_2_0
I0927 00:20:24.288574 19128 net.cpp:172] Setting up conv4_2_0
I0927 00:20:24.288604 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.288610 19128 net.cpp:194] Memory required for data: 61563000
I0927 00:20:24.288625 19128 layer_factory.hpp:77] Creating layer conv4_2_bn0
I0927 00:20:24.288636 19128 net.cpp:128] Creating Layer conv4_2_bn0
I0927 00:20:24.288646 19128 net.cpp:558] conv4_2_bn0 <- conv4_2_0
I0927 00:20:24.288653 19128 net.cpp:509] conv4_2_bn0 -> conv4_2_0 (in-place)
I0927 00:20:24.288978 19128 net.cpp:172] Setting up conv4_2_bn0
I0927 00:20:24.288990 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.288995 19128 net.cpp:194] Memory required for data: 61726840
I0927 00:20:24.289005 19128 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0927 00:20:24.289021 19128 net.cpp:128] Creating Layer conv4_2_scale0
I0927 00:20:24.289024 19128 net.cpp:558] conv4_2_scale0 <- conv4_2_0
I0927 00:20:24.289031 19128 net.cpp:509] conv4_2_scale0 -> conv4_2_0 (in-place)
I0927 00:20:24.289088 19128 layer_factory.hpp:77] Creating layer conv4_2_scale0
I0927 00:20:24.289269 19128 net.cpp:172] Setting up conv4_2_scale0
I0927 00:20:24.289279 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.289284 19128 net.cpp:194] Memory required for data: 61890680
I0927 00:20:24.289292 19128 layer_factory.hpp:77] Creating layer conv4_2_ReLU0
I0927 00:20:24.289299 19128 net.cpp:128] Creating Layer conv4_2_ReLU0
I0927 00:20:24.289304 19128 net.cpp:558] conv4_2_ReLU0 <- conv4_2_0
I0927 00:20:24.289309 19128 net.cpp:509] conv4_2_ReLU0 -> conv4_2_0 (in-place)
I0927 00:20:24.290334 19128 net.cpp:172] Setting up conv4_2_ReLU0
I0927 00:20:24.290354 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.290357 19128 net.cpp:194] Memory required for data: 62054520
I0927 00:20:24.290362 19128 layer_factory.hpp:77] Creating layer conv4_2_1
I0927 00:20:24.290385 19128 net.cpp:128] Creating Layer conv4_2_1
I0927 00:20:24.290392 19128 net.cpp:558] conv4_2_1 <- conv4_2_0
I0927 00:20:24.290403 19128 net.cpp:522] conv4_2_1 -> conv4_2_1
I0927 00:20:24.297058 19128 net.cpp:172] Setting up conv4_2_1
I0927 00:20:24.297087 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.297092 19128 net.cpp:194] Memory required for data: 62218360
I0927 00:20:24.297107 19128 layer_factory.hpp:77] Creating layer conv4_2bn1
I0927 00:20:24.297129 19128 net.cpp:128] Creating Layer conv4_2bn1
I0927 00:20:24.297143 19128 net.cpp:558] conv4_2bn1 <- conv4_2_1
I0927 00:20:24.297150 19128 net.cpp:509] conv4_2bn1 -> conv4_2_1 (in-place)
I0927 00:20:24.297472 19128 net.cpp:172] Setting up conv4_2bn1
I0927 00:20:24.297483 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.297487 19128 net.cpp:194] Memory required for data: 62382200
I0927 00:20:24.297498 19128 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0927 00:20:24.297508 19128 net.cpp:128] Creating Layer conv4_2_scale1
I0927 00:20:24.297513 19128 net.cpp:558] conv4_2_scale1 <- conv4_2_1
I0927 00:20:24.297535 19128 net.cpp:509] conv4_2_scale1 -> conv4_2_1 (in-place)
I0927 00:20:24.297595 19128 layer_factory.hpp:77] Creating layer conv4_2_scale1
I0927 00:20:24.297785 19128 net.cpp:172] Setting up conv4_2_scale1
I0927 00:20:24.297791 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.297796 19128 net.cpp:194] Memory required for data: 62546040
I0927 00:20:24.297804 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_2
I0927 00:20:24.297813 19128 net.cpp:128] Creating Layer conv4_Eltwise_2
I0927 00:20:24.297818 19128 net.cpp:558] conv4_Eltwise_2 <- conv4_Eltwise_1_conv4_1ReLU_1_0_split_1
I0927 00:20:24.297823 19128 net.cpp:558] conv4_Eltwise_2 <- conv4_2_1
I0927 00:20:24.297830 19128 net.cpp:522] conv4_Eltwise_2 -> conv4_Eltwise_2
I0927 00:20:24.297863 19128 net.cpp:172] Setting up conv4_Eltwise_2
I0927 00:20:24.297984 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.297989 19128 net.cpp:194] Memory required for data: 62709880
I0927 00:20:24.297993 19128 layer_factory.hpp:77] Creating layer conv4_2ReLU_1
I0927 00:20:24.298000 19128 net.cpp:128] Creating Layer conv4_2ReLU_1
I0927 00:20:24.298005 19128 net.cpp:558] conv4_2ReLU_1 <- conv4_Eltwise_2
I0927 00:20:24.298010 19128 net.cpp:509] conv4_2ReLU_1 -> conv4_Eltwise_2 (in-place)
I0927 00:20:24.299072 19128 net.cpp:172] Setting up conv4_2ReLU_1
I0927 00:20:24.299089 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.299094 19128 net.cpp:194] Memory required for data: 62873720
I0927 00:20:24.299099 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0927 00:20:24.299109 19128 net.cpp:128] Creating Layer conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0927 00:20:24.299114 19128 net.cpp:558] conv4_Eltwise_2_conv4_2ReLU_1_0_split <- conv4_Eltwise_2
I0927 00:20:24.299124 19128 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0927 00:20:24.299131 19128 net.cpp:522] conv4_Eltwise_2_conv4_2ReLU_1_0_split -> conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0927 00:20:24.299196 19128 net.cpp:172] Setting up conv4_Eltwise_2_conv4_2ReLU_1_0_split
I0927 00:20:24.299214 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.299221 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.299224 19128 net.cpp:194] Memory required for data: 63201400
I0927 00:20:24.299228 19128 layer_factory.hpp:77] Creating layer conv4_3_0
I0927 00:20:24.299240 19128 net.cpp:128] Creating Layer conv4_3_0
I0927 00:20:24.299247 19128 net.cpp:558] conv4_3_0 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_0
I0927 00:20:24.299255 19128 net.cpp:522] conv4_3_0 -> conv4_3_0
I0927 00:20:24.306022 19128 net.cpp:172] Setting up conv4_3_0
I0927 00:20:24.306051 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.306056 19128 net.cpp:194] Memory required for data: 63365240
I0927 00:20:24.306066 19128 layer_factory.hpp:77] Creating layer conv4_3_bn0
I0927 00:20:24.306077 19128 net.cpp:128] Creating Layer conv4_3_bn0
I0927 00:20:24.306082 19128 net.cpp:558] conv4_3_bn0 <- conv4_3_0
I0927 00:20:24.306092 19128 net.cpp:509] conv4_3_bn0 -> conv4_3_0 (in-place)
I0927 00:20:24.306432 19128 net.cpp:172] Setting up conv4_3_bn0
I0927 00:20:24.306444 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.306448 19128 net.cpp:194] Memory required for data: 63529080
I0927 00:20:24.306459 19128 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0927 00:20:24.306466 19128 net.cpp:128] Creating Layer conv4_3_scale0
I0927 00:20:24.306471 19128 net.cpp:558] conv4_3_scale0 <- conv4_3_0
I0927 00:20:24.306479 19128 net.cpp:509] conv4_3_scale0 -> conv4_3_0 (in-place)
I0927 00:20:24.306533 19128 layer_factory.hpp:77] Creating layer conv4_3_scale0
I0927 00:20:24.306716 19128 net.cpp:172] Setting up conv4_3_scale0
I0927 00:20:24.306730 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.306735 19128 net.cpp:194] Memory required for data: 63692920
I0927 00:20:24.306742 19128 layer_factory.hpp:77] Creating layer conv4_3_ReLU0
I0927 00:20:24.306748 19128 net.cpp:128] Creating Layer conv4_3_ReLU0
I0927 00:20:24.306768 19128 net.cpp:558] conv4_3_ReLU0 <- conv4_3_0
I0927 00:20:24.306777 19128 net.cpp:509] conv4_3_ReLU0 -> conv4_3_0 (in-place)
I0927 00:20:24.307821 19128 net.cpp:172] Setting up conv4_3_ReLU0
I0927 00:20:24.307842 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.307847 19128 net.cpp:194] Memory required for data: 63856760
I0927 00:20:24.307852 19128 layer_factory.hpp:77] Creating layer conv4_3_1
I0927 00:20:24.307869 19128 net.cpp:128] Creating Layer conv4_3_1
I0927 00:20:24.307878 19128 net.cpp:558] conv4_3_1 <- conv4_3_0
I0927 00:20:24.307888 19128 net.cpp:522] conv4_3_1 -> conv4_3_1
I0927 00:20:24.314549 19128 net.cpp:172] Setting up conv4_3_1
I0927 00:20:24.314576 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.314580 19128 net.cpp:194] Memory required for data: 64020600
I0927 00:20:24.314594 19128 layer_factory.hpp:77] Creating layer conv4_3bn1
I0927 00:20:24.314606 19128 net.cpp:128] Creating Layer conv4_3bn1
I0927 00:20:24.314616 19128 net.cpp:558] conv4_3bn1 <- conv4_3_1
I0927 00:20:24.314623 19128 net.cpp:509] conv4_3bn1 -> conv4_3_1 (in-place)
I0927 00:20:24.314965 19128 net.cpp:172] Setting up conv4_3bn1
I0927 00:20:24.314976 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.314981 19128 net.cpp:194] Memory required for data: 64184440
I0927 00:20:24.314991 19128 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0927 00:20:24.315002 19128 net.cpp:128] Creating Layer conv4_3_scale1
I0927 00:20:24.315011 19128 net.cpp:558] conv4_3_scale1 <- conv4_3_1
I0927 00:20:24.315018 19128 net.cpp:509] conv4_3_scale1 -> conv4_3_1 (in-place)
I0927 00:20:24.315076 19128 layer_factory.hpp:77] Creating layer conv4_3_scale1
I0927 00:20:24.315261 19128 net.cpp:172] Setting up conv4_3_scale1
I0927 00:20:24.315273 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.315277 19128 net.cpp:194] Memory required for data: 64348280
I0927 00:20:24.315285 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_3
I0927 00:20:24.315291 19128 net.cpp:128] Creating Layer conv4_Eltwise_3
I0927 00:20:24.315296 19128 net.cpp:558] conv4_Eltwise_3 <- conv4_Eltwise_2_conv4_2ReLU_1_0_split_1
I0927 00:20:24.315302 19128 net.cpp:558] conv4_Eltwise_3 <- conv4_3_1
I0927 00:20:24.315310 19128 net.cpp:522] conv4_Eltwise_3 -> conv4_Eltwise_3
I0927 00:20:24.315341 19128 net.cpp:172] Setting up conv4_Eltwise_3
I0927 00:20:24.315348 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.315352 19128 net.cpp:194] Memory required for data: 64512120
I0927 00:20:24.315356 19128 layer_factory.hpp:77] Creating layer conv4_3ReLU_1
I0927 00:20:24.315366 19128 net.cpp:128] Creating Layer conv4_3ReLU_1
I0927 00:20:24.315369 19128 net.cpp:558] conv4_3ReLU_1 <- conv4_Eltwise_3
I0927 00:20:24.315376 19128 net.cpp:509] conv4_3ReLU_1 -> conv4_Eltwise_3 (in-place)
I0927 00:20:24.316589 19128 net.cpp:172] Setting up conv4_3ReLU_1
I0927 00:20:24.316613 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.316618 19128 net.cpp:194] Memory required for data: 64675960
I0927 00:20:24.316623 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0927 00:20:24.316634 19128 net.cpp:128] Creating Layer conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0927 00:20:24.316639 19128 net.cpp:558] conv4_Eltwise_3_conv4_3ReLU_1_0_split <- conv4_Eltwise_3
I0927 00:20:24.316648 19128 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I0927 00:20:24.316659 19128 net.cpp:522] conv4_Eltwise_3_conv4_3ReLU_1_0_split -> conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I0927 00:20:24.316725 19128 net.cpp:172] Setting up conv4_Eltwise_3_conv4_3ReLU_1_0_split
I0927 00:20:24.316732 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.316738 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.316743 19128 net.cpp:194] Memory required for data: 65003640
I0927 00:20:24.316747 19128 layer_factory.hpp:77] Creating layer conv4_4_0
I0927 00:20:24.316761 19128 net.cpp:128] Creating Layer conv4_4_0
I0927 00:20:24.316767 19128 net.cpp:558] conv4_4_0 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_0
I0927 00:20:24.316792 19128 net.cpp:522] conv4_4_0 -> conv4_4_0
I0927 00:20:24.323639 19128 net.cpp:172] Setting up conv4_4_0
I0927 00:20:24.323669 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.323674 19128 net.cpp:194] Memory required for data: 65167480
I0927 00:20:24.323685 19128 layer_factory.hpp:77] Creating layer conv4_4_bn0
I0927 00:20:24.323694 19128 net.cpp:128] Creating Layer conv4_4_bn0
I0927 00:20:24.323699 19128 net.cpp:558] conv4_4_bn0 <- conv4_4_0
I0927 00:20:24.323716 19128 net.cpp:509] conv4_4_bn0 -> conv4_4_0 (in-place)
I0927 00:20:24.324059 19128 net.cpp:172] Setting up conv4_4_bn0
I0927 00:20:24.324074 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.324077 19128 net.cpp:194] Memory required for data: 65331320
I0927 00:20:24.324087 19128 layer_factory.hpp:77] Creating layer conv4_4_scale0
I0927 00:20:24.324095 19128 net.cpp:128] Creating Layer conv4_4_scale0
I0927 00:20:24.324100 19128 net.cpp:558] conv4_4_scale0 <- conv4_4_0
I0927 00:20:24.324107 19128 net.cpp:509] conv4_4_scale0 -> conv4_4_0 (in-place)
I0927 00:20:24.324163 19128 layer_factory.hpp:77] Creating layer conv4_4_scale0
I0927 00:20:24.324348 19128 net.cpp:172] Setting up conv4_4_scale0
I0927 00:20:24.324359 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.324364 19128 net.cpp:194] Memory required for data: 65495160
I0927 00:20:24.324373 19128 layer_factory.hpp:77] Creating layer conv4_4_ReLU0
I0927 00:20:24.324381 19128 net.cpp:128] Creating Layer conv4_4_ReLU0
I0927 00:20:24.324386 19128 net.cpp:558] conv4_4_ReLU0 <- conv4_4_0
I0927 00:20:24.324391 19128 net.cpp:509] conv4_4_ReLU0 -> conv4_4_0 (in-place)
I0927 00:20:24.325399 19128 net.cpp:172] Setting up conv4_4_ReLU0
I0927 00:20:24.325418 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.325423 19128 net.cpp:194] Memory required for data: 65659000
I0927 00:20:24.325428 19128 layer_factory.hpp:77] Creating layer conv4_4_1
I0927 00:20:24.325448 19128 net.cpp:128] Creating Layer conv4_4_1
I0927 00:20:24.325455 19128 net.cpp:558] conv4_4_1 <- conv4_4_0
I0927 00:20:24.325464 19128 net.cpp:522] conv4_4_1 -> conv4_4_1
I0927 00:20:24.332145 19128 net.cpp:172] Setting up conv4_4_1
I0927 00:20:24.332172 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.332177 19128 net.cpp:194] Memory required for data: 65822840
I0927 00:20:24.332191 19128 layer_factory.hpp:77] Creating layer conv4_4bn1
I0927 00:20:24.332202 19128 net.cpp:128] Creating Layer conv4_4bn1
I0927 00:20:24.332212 19128 net.cpp:558] conv4_4bn1 <- conv4_4_1
I0927 00:20:24.332221 19128 net.cpp:509] conv4_4bn1 -> conv4_4_1 (in-place)
I0927 00:20:24.332553 19128 net.cpp:172] Setting up conv4_4bn1
I0927 00:20:24.332564 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.332568 19128 net.cpp:194] Memory required for data: 65986680
I0927 00:20:24.332579 19128 layer_factory.hpp:77] Creating layer conv4_4_scale1
I0927 00:20:24.332588 19128 net.cpp:128] Creating Layer conv4_4_scale1
I0927 00:20:24.332593 19128 net.cpp:558] conv4_4_scale1 <- conv4_4_1
I0927 00:20:24.332598 19128 net.cpp:509] conv4_4_scale1 -> conv4_4_1 (in-place)
I0927 00:20:24.332656 19128 layer_factory.hpp:77] Creating layer conv4_4_scale1
I0927 00:20:24.332854 19128 net.cpp:172] Setting up conv4_4_scale1
I0927 00:20:24.332867 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.332873 19128 net.cpp:194] Memory required for data: 66150520
I0927 00:20:24.332881 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_4
I0927 00:20:24.332890 19128 net.cpp:128] Creating Layer conv4_Eltwise_4
I0927 00:20:24.332895 19128 net.cpp:558] conv4_Eltwise_4 <- conv4_Eltwise_3_conv4_3ReLU_1_0_split_1
I0927 00:20:24.332900 19128 net.cpp:558] conv4_Eltwise_4 <- conv4_4_1
I0927 00:20:24.332909 19128 net.cpp:522] conv4_Eltwise_4 -> conv4_Eltwise_4
I0927 00:20:24.332942 19128 net.cpp:172] Setting up conv4_Eltwise_4
I0927 00:20:24.332948 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.332952 19128 net.cpp:194] Memory required for data: 66314360
I0927 00:20:24.332974 19128 layer_factory.hpp:77] Creating layer conv4_4ReLU_1
I0927 00:20:24.332984 19128 net.cpp:128] Creating Layer conv4_4ReLU_1
I0927 00:20:24.332989 19128 net.cpp:558] conv4_4ReLU_1 <- conv4_Eltwise_4
I0927 00:20:24.332994 19128 net.cpp:509] conv4_4ReLU_1 -> conv4_Eltwise_4 (in-place)
I0927 00:20:24.334429 19128 net.cpp:172] Setting up conv4_4ReLU_1
I0927 00:20:24.334455 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.334458 19128 net.cpp:194] Memory required for data: 66478200
I0927 00:20:24.334465 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0927 00:20:24.334473 19128 net.cpp:128] Creating Layer conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0927 00:20:24.334478 19128 net.cpp:558] conv4_Eltwise_4_conv4_4ReLU_1_0_split <- conv4_Eltwise_4
I0927 00:20:24.334488 19128 net.cpp:522] conv4_Eltwise_4_conv4_4ReLU_1_0_split -> conv4_Eltwise_4_conv4_4ReLU_1_0_split_0
I0927 00:20:24.334501 19128 net.cpp:522] conv4_Eltwise_4_conv4_4ReLU_1_0_split -> conv4_Eltwise_4_conv4_4ReLU_1_0_split_1
I0927 00:20:24.334573 19128 net.cpp:172] Setting up conv4_Eltwise_4_conv4_4ReLU_1_0_split
I0927 00:20:24.334580 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.334586 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.334590 19128 net.cpp:194] Memory required for data: 66805880
I0927 00:20:24.334595 19128 layer_factory.hpp:77] Creating layer conv4_5_0
I0927 00:20:24.334610 19128 net.cpp:128] Creating Layer conv4_5_0
I0927 00:20:24.334615 19128 net.cpp:558] conv4_5_0 <- conv4_Eltwise_4_conv4_4ReLU_1_0_split_0
I0927 00:20:24.334623 19128 net.cpp:522] conv4_5_0 -> conv4_5_0
I0927 00:20:24.341195 19128 net.cpp:172] Setting up conv4_5_0
I0927 00:20:24.341223 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.341228 19128 net.cpp:194] Memory required for data: 66969720
I0927 00:20:24.341238 19128 layer_factory.hpp:77] Creating layer conv4_5_bn0
I0927 00:20:24.341248 19128 net.cpp:128] Creating Layer conv4_5_bn0
I0927 00:20:24.341253 19128 net.cpp:558] conv4_5_bn0 <- conv4_5_0
I0927 00:20:24.341264 19128 net.cpp:509] conv4_5_bn0 -> conv4_5_0 (in-place)
I0927 00:20:24.341611 19128 net.cpp:172] Setting up conv4_5_bn0
I0927 00:20:24.341626 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.341631 19128 net.cpp:194] Memory required for data: 67133560
I0927 00:20:24.341641 19128 layer_factory.hpp:77] Creating layer conv4_5_scale0
I0927 00:20:24.341652 19128 net.cpp:128] Creating Layer conv4_5_scale0
I0927 00:20:24.341658 19128 net.cpp:558] conv4_5_scale0 <- conv4_5_0
I0927 00:20:24.341665 19128 net.cpp:509] conv4_5_scale0 -> conv4_5_0 (in-place)
I0927 00:20:24.341722 19128 layer_factory.hpp:77] Creating layer conv4_5_scale0
I0927 00:20:24.341924 19128 net.cpp:172] Setting up conv4_5_scale0
I0927 00:20:24.341933 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.341936 19128 net.cpp:194] Memory required for data: 67297400
I0927 00:20:24.341944 19128 layer_factory.hpp:77] Creating layer conv4_5_ReLU0
I0927 00:20:24.341953 19128 net.cpp:128] Creating Layer conv4_5_ReLU0
I0927 00:20:24.341958 19128 net.cpp:558] conv4_5_ReLU0 <- conv4_5_0
I0927 00:20:24.341964 19128 net.cpp:509] conv4_5_ReLU0 -> conv4_5_0 (in-place)
I0927 00:20:24.342972 19128 net.cpp:172] Setting up conv4_5_ReLU0
I0927 00:20:24.343001 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.343006 19128 net.cpp:194] Memory required for data: 67461240
I0927 00:20:24.343013 19128 layer_factory.hpp:77] Creating layer conv4_5_1
I0927 00:20:24.343026 19128 net.cpp:128] Creating Layer conv4_5_1
I0927 00:20:24.343032 19128 net.cpp:558] conv4_5_1 <- conv4_5_0
I0927 00:20:24.343040 19128 net.cpp:522] conv4_5_1 -> conv4_5_1
I0927 00:20:24.349764 19128 net.cpp:172] Setting up conv4_5_1
I0927 00:20:24.349792 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.349797 19128 net.cpp:194] Memory required for data: 67625080
I0927 00:20:24.349812 19128 layer_factory.hpp:77] Creating layer conv4_5bn1
I0927 00:20:24.349823 19128 net.cpp:128] Creating Layer conv4_5bn1
I0927 00:20:24.349835 19128 net.cpp:558] conv4_5bn1 <- conv4_5_1
I0927 00:20:24.349867 19128 net.cpp:509] conv4_5bn1 -> conv4_5_1 (in-place)
I0927 00:20:24.350205 19128 net.cpp:172] Setting up conv4_5bn1
I0927 00:20:24.350217 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.350221 19128 net.cpp:194] Memory required for data: 67788920
I0927 00:20:24.350232 19128 layer_factory.hpp:77] Creating layer conv4_5_scale1
I0927 00:20:24.350239 19128 net.cpp:128] Creating Layer conv4_5_scale1
I0927 00:20:24.350244 19128 net.cpp:558] conv4_5_scale1 <- conv4_5_1
I0927 00:20:24.350251 19128 net.cpp:509] conv4_5_scale1 -> conv4_5_1 (in-place)
I0927 00:20:24.350308 19128 layer_factory.hpp:77] Creating layer conv4_5_scale1
I0927 00:20:24.350503 19128 net.cpp:172] Setting up conv4_5_scale1
I0927 00:20:24.350515 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.350519 19128 net.cpp:194] Memory required for data: 67952760
I0927 00:20:24.350528 19128 layer_factory.hpp:77] Creating layer conv4_Eltwise_5
I0927 00:20:24.350538 19128 net.cpp:128] Creating Layer conv4_Eltwise_5
I0927 00:20:24.350543 19128 net.cpp:558] conv4_Eltwise_5 <- conv4_Eltwise_4_conv4_4ReLU_1_0_split_1
I0927 00:20:24.350548 19128 net.cpp:558] conv4_Eltwise_5 <- conv4_5_1
I0927 00:20:24.350554 19128 net.cpp:522] conv4_Eltwise_5 -> conv4_Eltwise_5
I0927 00:20:24.350589 19128 net.cpp:172] Setting up conv4_Eltwise_5
I0927 00:20:24.350595 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.350600 19128 net.cpp:194] Memory required for data: 68116600
I0927 00:20:24.350605 19128 layer_factory.hpp:77] Creating layer conv4_5ReLU_1
I0927 00:20:24.350610 19128 net.cpp:128] Creating Layer conv4_5ReLU_1
I0927 00:20:24.350615 19128 net.cpp:558] conv4_5ReLU_1 <- conv4_Eltwise_5
I0927 00:20:24.350626 19128 net.cpp:509] conv4_5ReLU_1 -> conv4_Eltwise_5 (in-place)
I0927 00:20:24.351801 19128 net.cpp:172] Setting up conv4_5ReLU_1
I0927 00:20:24.351821 19128 net.cpp:186] Top shape: 10 64 8 8 (40960)
I0927 00:20:24.351826 19128 net.cpp:194] Memory required for data: 68280440
I0927 00:20:24.351831 19128 layer_factory.hpp:77] Creating layer Pooling1
I0927 00:20:24.351840 19128 net.cpp:128] Creating Layer Pooling1
I0927 00:20:24.351845 19128 net.cpp:558] Pooling1 <- conv4_Eltwise_5
I0927 00:20:24.351856 19128 net.cpp:522] Pooling1 -> Pooling1
I0927 00:20:24.354001 19128 net.cpp:172] Setting up Pooling1
I0927 00:20:24.354019 19128 net.cpp:186] Top shape: 10 64 1 1 (640)
I0927 00:20:24.354023 19128 net.cpp:194] Memory required for data: 68283000
I0927 00:20:24.354028 19128 layer_factory.hpp:77] Creating layer fc1
I0927 00:20:24.354040 19128 net.cpp:128] Creating Layer fc1
I0927 00:20:24.354045 19128 net.cpp:558] fc1 <- Pooling1
I0927 00:20:24.354053 19128 net.cpp:522] fc1 -> fc1
I0927 00:20:24.354254 19128 net.cpp:172] Setting up fc1
I0927 00:20:24.354267 19128 net.cpp:186] Top shape: 10 10 (100)
I0927 00:20:24.354271 19128 net.cpp:194] Memory required for data: 68283400
I0927 00:20:24.354280 19128 layer_factory.hpp:77] Creating layer fc1_fc1_0_split
I0927 00:20:24.354287 19128 net.cpp:128] Creating Layer fc1_fc1_0_split
I0927 00:20:24.354292 19128 net.cpp:558] fc1_fc1_0_split <- fc1
I0927 00:20:24.354300 19128 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_0
I0927 00:20:24.354308 19128 net.cpp:522] fc1_fc1_0_split -> fc1_fc1_0_split_1
I0927 00:20:24.354365 19128 net.cpp:172] Setting up fc1_fc1_0_split
I0927 00:20:24.354372 19128 net.cpp:186] Top shape: 10 10 (100)
I0927 00:20:24.354378 19128 net.cpp:186] Top shape: 10 10 (100)
I0927 00:20:24.354382 19128 net.cpp:194] Memory required for data: 68284200
I0927 00:20:24.354387 19128 layer_factory.hpp:77] Creating layer Softmax1
I0927 00:20:24.354393 19128 net.cpp:128] Creating Layer Softmax1
I0927 00:20:24.354398 19128 net.cpp:558] Softmax1 <- fc1_fc1_0_split_0
I0927 00:20:24.354403 19128 net.cpp:558] Softmax1 <- label_Data1_1_split_0
I0927 00:20:24.354413 19128 net.cpp:522] Softmax1 -> Softmax1
I0927 00:20:24.354423 19128 layer_factory.hpp:77] Creating layer Softmax1
I0927 00:20:24.356313 19128 net.cpp:172] Setting up Softmax1
I0927 00:20:24.356357 19128 net.cpp:186] Top shape: (1)
I0927 00:20:24.356362 19128 net.cpp:189]     with loss weight 1
I0927 00:20:24.356379 19128 net.cpp:194] Memory required for data: 68284204
I0927 00:20:24.356384 19128 layer_factory.hpp:77] Creating layer prob
I0927 00:20:24.356391 19128 net.cpp:128] Creating Layer prob
I0927 00:20:24.356396 19128 net.cpp:558] prob <- fc1_fc1_0_split_1
I0927 00:20:24.356405 19128 net.cpp:558] prob <- label_Data1_1_split_1
I0927 00:20:24.356415 19128 net.cpp:522] prob -> prob
I0927 00:20:24.356425 19128 net.cpp:172] Setting up prob
I0927 00:20:24.356431 19128 net.cpp:186] Top shape: (1)
I0927 00:20:24.356434 19128 net.cpp:194] Memory required for data: 68284208
I0927 00:20:24.356438 19128 net.cpp:303] prob does not need backward computation.
I0927 00:20:24.356444 19128 net.cpp:301] Softmax1 needs backward computation.
I0927 00:20:24.356449 19128 net.cpp:301] fc1_fc1_0_split needs backward computation.
I0927 00:20:24.356453 19128 net.cpp:301] fc1 needs backward computation.
I0927 00:20:24.356458 19128 net.cpp:301] Pooling1 needs backward computation.
I0927 00:20:24.356462 19128 net.cpp:301] conv4_5ReLU_1 needs backward computation.
I0927 00:20:24.356467 19128 net.cpp:301] conv4_Eltwise_5 needs backward computation.
I0927 00:20:24.356472 19128 net.cpp:301] conv4_5_scale1 needs backward computation.
I0927 00:20:24.356477 19128 net.cpp:301] conv4_5bn1 needs backward computation.
I0927 00:20:24.356480 19128 net.cpp:301] conv4_5_1 needs backward computation.
I0927 00:20:24.356484 19128 net.cpp:301] conv4_5_ReLU0 needs backward computation.
I0927 00:20:24.356488 19128 net.cpp:301] conv4_5_scale0 needs backward computation.
I0927 00:20:24.356492 19128 net.cpp:301] conv4_5_bn0 needs backward computation.
I0927 00:20:24.356498 19128 net.cpp:301] conv4_5_0 needs backward computation.
I0927 00:20:24.356501 19128 net.cpp:301] conv4_Eltwise_4_conv4_4ReLU_1_0_split needs backward computation.
I0927 00:20:24.356506 19128 net.cpp:301] conv4_4ReLU_1 needs backward computation.
I0927 00:20:24.356510 19128 net.cpp:301] conv4_Eltwise_4 needs backward computation.
I0927 00:20:24.356515 19128 net.cpp:301] conv4_4_scale1 needs backward computation.
I0927 00:20:24.356519 19128 net.cpp:301] conv4_4bn1 needs backward computation.
I0927 00:20:24.356524 19128 net.cpp:301] conv4_4_1 needs backward computation.
I0927 00:20:24.356528 19128 net.cpp:301] conv4_4_ReLU0 needs backward computation.
I0927 00:20:24.356535 19128 net.cpp:301] conv4_4_scale0 needs backward computation.
I0927 00:20:24.356539 19128 net.cpp:301] conv4_4_bn0 needs backward computation.
I0927 00:20:24.356544 19128 net.cpp:301] conv4_4_0 needs backward computation.
I0927 00:20:24.356549 19128 net.cpp:301] conv4_Eltwise_3_conv4_3ReLU_1_0_split needs backward computation.
I0927 00:20:24.356552 19128 net.cpp:301] conv4_3ReLU_1 needs backward computation.
I0927 00:20:24.356557 19128 net.cpp:301] conv4_Eltwise_3 needs backward computation.
I0927 00:20:24.356562 19128 net.cpp:301] conv4_3_scale1 needs backward computation.
I0927 00:20:24.356566 19128 net.cpp:301] conv4_3bn1 needs backward computation.
I0927 00:20:24.356570 19128 net.cpp:301] conv4_3_1 needs backward computation.
I0927 00:20:24.356575 19128 net.cpp:301] conv4_3_ReLU0 needs backward computation.
I0927 00:20:24.356578 19128 net.cpp:301] conv4_3_scale0 needs backward computation.
I0927 00:20:24.356583 19128 net.cpp:301] conv4_3_bn0 needs backward computation.
I0927 00:20:24.356587 19128 net.cpp:301] conv4_3_0 needs backward computation.
I0927 00:20:24.356592 19128 net.cpp:301] conv4_Eltwise_2_conv4_2ReLU_1_0_split needs backward computation.
I0927 00:20:24.356596 19128 net.cpp:301] conv4_2ReLU_1 needs backward computation.
I0927 00:20:24.356601 19128 net.cpp:301] conv4_Eltwise_2 needs backward computation.
I0927 00:20:24.356608 19128 net.cpp:301] conv4_2_scale1 needs backward computation.
I0927 00:20:24.356613 19128 net.cpp:301] conv4_2bn1 needs backward computation.
I0927 00:20:24.356617 19128 net.cpp:301] conv4_2_1 needs backward computation.
I0927 00:20:24.356621 19128 net.cpp:301] conv4_2_ReLU0 needs backward computation.
I0927 00:20:24.356633 19128 net.cpp:301] conv4_2_scale0 needs backward computation.
I0927 00:20:24.356638 19128 net.cpp:301] conv4_2_bn0 needs backward computation.
I0927 00:20:24.356642 19128 net.cpp:301] conv4_2_0 needs backward computation.
I0927 00:20:24.356648 19128 net.cpp:301] conv4_Eltwise_1_conv4_1ReLU_1_0_split needs backward computation.
I0927 00:20:24.356652 19128 net.cpp:301] conv4_1ReLU_1 needs backward computation.
I0927 00:20:24.356657 19128 net.cpp:301] conv4_Eltwise_1 needs backward computation.
I0927 00:20:24.356662 19128 net.cpp:301] conv4_1_scale_down needs backward computation.
I0927 00:20:24.356667 19128 net.cpp:301] conv4_1_bn_down needs backward computation.
I0927 00:20:24.356672 19128 net.cpp:301] conv4_1_down needs backward computation.
I0927 00:20:24.356676 19128 net.cpp:301] conv4_1_scale1 needs backward computation.
I0927 00:20:24.356681 19128 net.cpp:301] conv4_1bn1 needs backward computation.
I0927 00:20:24.356685 19128 net.cpp:301] conv4_1_1 needs backward computation.
I0927 00:20:24.356690 19128 net.cpp:301] conv4_1_ReLU0 needs backward computation.
I0927 00:20:24.356694 19128 net.cpp:301] conv4_1_scale0 needs backward computation.
I0927 00:20:24.356699 19128 net.cpp:301] conv4_1_bn0 needs backward computation.
I0927 00:20:24.356703 19128 net.cpp:301] conv4_1_0 needs backward computation.
I0927 00:20:24.356709 19128 net.cpp:301] conv3_Eltwise_5_conv3_5ReLU_1_0_split needs backward computation.
I0927 00:20:24.356714 19128 net.cpp:301] conv3_5ReLU_1 needs backward computation.
I0927 00:20:24.356719 19128 net.cpp:301] conv3_Eltwise_5 needs backward computation.
I0927 00:20:24.356724 19128 net.cpp:301] conv3_5_scale1 needs backward computation.
I0927 00:20:24.356729 19128 net.cpp:301] conv3_5bn1 needs backward computation.
I0927 00:20:24.356732 19128 net.cpp:301] conv3_5_1 needs backward computation.
I0927 00:20:24.356736 19128 net.cpp:301] conv3_5_ReLU0 needs backward computation.
I0927 00:20:24.356740 19128 net.cpp:301] conv3_5_scale0 needs backward computation.
I0927 00:20:24.356745 19128 net.cpp:301] conv3_5_bn0 needs backward computation.
I0927 00:20:24.356750 19128 net.cpp:301] conv3_5_0 needs backward computation.
I0927 00:20:24.356755 19128 net.cpp:301] conv3_Eltwise_4_conv3_4ReLU_1_0_split needs backward computation.
I0927 00:20:24.356760 19128 net.cpp:301] conv3_4ReLU_1 needs backward computation.
I0927 00:20:24.356765 19128 net.cpp:301] conv3_Eltwise_4 needs backward computation.
I0927 00:20:24.356772 19128 net.cpp:301] conv3_4_scale1 needs backward computation.
I0927 00:20:24.356777 19128 net.cpp:301] conv3_4bn1 needs backward computation.
I0927 00:20:24.356781 19128 net.cpp:301] conv3_4_1 needs backward computation.
I0927 00:20:24.356786 19128 net.cpp:301] conv3_4_ReLU0 needs backward computation.
I0927 00:20:24.356791 19128 net.cpp:301] conv3_4_scale0 needs backward computation.
I0927 00:20:24.356794 19128 net.cpp:301] conv3_4_bn0 needs backward computation.
I0927 00:20:24.356799 19128 net.cpp:301] conv3_4_0 needs backward computation.
I0927 00:20:24.356804 19128 net.cpp:301] conv3_Eltwise_3_conv3_3ReLU_1_0_split needs backward computation.
I0927 00:20:24.356809 19128 net.cpp:301] conv3_3ReLU_1 needs backward computation.
I0927 00:20:24.356814 19128 net.cpp:301] conv3_Eltwise_3 needs backward computation.
I0927 00:20:24.356819 19128 net.cpp:301] conv3_3_scale1 needs backward computation.
I0927 00:20:24.356823 19128 net.cpp:301] conv3_3bn1 needs backward computation.
I0927 00:20:24.356828 19128 net.cpp:301] conv3_3_1 needs backward computation.
I0927 00:20:24.356832 19128 net.cpp:301] conv3_3_ReLU0 needs backward computation.
I0927 00:20:24.356837 19128 net.cpp:301] conv3_3_scale0 needs backward computation.
I0927 00:20:24.356842 19128 net.cpp:301] conv3_3_bn0 needs backward computation.
I0927 00:20:24.356847 19128 net.cpp:301] conv3_3_0 needs backward computation.
I0927 00:20:24.356851 19128 net.cpp:301] conv3_Eltwise_2_conv3_2ReLU_1_0_split needs backward computation.
I0927 00:20:24.356856 19128 net.cpp:301] conv3_2ReLU_1 needs backward computation.
I0927 00:20:24.356868 19128 net.cpp:301] conv3_Eltwise_2 needs backward computation.
I0927 00:20:24.356873 19128 net.cpp:301] conv3_2_scale1 needs backward computation.
I0927 00:20:24.356878 19128 net.cpp:301] conv3_2bn1 needs backward computation.
I0927 00:20:24.356884 19128 net.cpp:301] conv3_2_1 needs backward computation.
I0927 00:20:24.356887 19128 net.cpp:301] conv3_2_ReLU0 needs backward computation.
I0927 00:20:24.356891 19128 net.cpp:301] conv3_2_scale0 needs backward computation.
I0927 00:20:24.356896 19128 net.cpp:301] conv3_2_bn0 needs backward computation.
I0927 00:20:24.356900 19128 net.cpp:301] conv3_2_0 needs backward computation.
I0927 00:20:24.356905 19128 net.cpp:301] conv3_Eltwise_1_conv3_1ReLU_1_0_split needs backward computation.
I0927 00:20:24.356910 19128 net.cpp:301] conv3_1ReLU_1 needs backward computation.
I0927 00:20:24.356915 19128 net.cpp:301] conv3_Eltwise_1 needs backward computation.
I0927 00:20:24.356920 19128 net.cpp:301] conv3_1_scale_down needs backward computation.
I0927 00:20:24.356925 19128 net.cpp:301] conv3_1_bn_down needs backward computation.
I0927 00:20:24.356930 19128 net.cpp:301] conv3_1_down needs backward computation.
I0927 00:20:24.356935 19128 net.cpp:301] conv3_1_scale1 needs backward computation.
I0927 00:20:24.356940 19128 net.cpp:301] conv3_1bn1 needs backward computation.
I0927 00:20:24.356943 19128 net.cpp:301] conv3_1_1 needs backward computation.
I0927 00:20:24.356948 19128 net.cpp:301] conv3_1_ReLU0 needs backward computation.
I0927 00:20:24.356956 19128 net.cpp:301] conv3_1_scale0 needs backward computation.
I0927 00:20:24.356961 19128 net.cpp:301] conv3_1_bn0 needs backward computation.
I0927 00:20:24.356966 19128 net.cpp:301] conv3_1_0 needs backward computation.
I0927 00:20:24.356971 19128 net.cpp:301] conv2_Eltwise_5_conv2_5ReLU_1_0_split needs backward computation.
I0927 00:20:24.356976 19128 net.cpp:301] conv2_5ReLU_1 needs backward computation.
I0927 00:20:24.356981 19128 net.cpp:301] conv2_Eltwise_5 needs backward computation.
I0927 00:20:24.356986 19128 net.cpp:301] conv2_5_scale1 needs backward computation.
I0927 00:20:24.356990 19128 net.cpp:301] conv2_5bn1 needs backward computation.
I0927 00:20:24.356995 19128 net.cpp:301] conv2_5_1 needs backward computation.
I0927 00:20:24.357000 19128 net.cpp:301] conv2_5_ReLU0 needs backward computation.
I0927 00:20:24.357004 19128 net.cpp:301] conv2_5_scale0 needs backward computation.
I0927 00:20:24.357008 19128 net.cpp:301] conv2_5_bn0 needs backward computation.
I0927 00:20:24.357013 19128 net.cpp:301] conv2_5_0 needs backward computation.
I0927 00:20:24.357018 19128 net.cpp:301] conv2_Eltwise_4_conv2_4ReLU_1_0_split needs backward computation.
I0927 00:20:24.357023 19128 net.cpp:301] conv2_4ReLU_1 needs backward computation.
I0927 00:20:24.357028 19128 net.cpp:301] conv2_Eltwise_4 needs backward computation.
I0927 00:20:24.357033 19128 net.cpp:301] conv2_4_scale1 needs backward computation.
I0927 00:20:24.357038 19128 net.cpp:301] conv2_4bn1 needs backward computation.
I0927 00:20:24.357043 19128 net.cpp:301] conv2_4_1 needs backward computation.
I0927 00:20:24.357048 19128 net.cpp:301] conv2_4_ReLU0 needs backward computation.
I0927 00:20:24.357053 19128 net.cpp:301] conv2_4_scale0 needs backward computation.
I0927 00:20:24.357058 19128 net.cpp:301] conv2_4_bn0 needs backward computation.
I0927 00:20:24.357061 19128 net.cpp:301] conv2_4_0 needs backward computation.
I0927 00:20:24.357066 19128 net.cpp:301] conv2_Eltwise_3_conv2_3ReLU_1_0_split needs backward computation.
I0927 00:20:24.357071 19128 net.cpp:301] conv2_3ReLU_1 needs backward computation.
I0927 00:20:24.357076 19128 net.cpp:301] conv2_Eltwise_3 needs backward computation.
I0927 00:20:24.357081 19128 net.cpp:301] conv2_3_scale1 needs backward computation.
I0927 00:20:24.357086 19128 net.cpp:301] conv2_3bn1 needs backward computation.
I0927 00:20:24.357090 19128 net.cpp:301] conv2_3_1 needs backward computation.
I0927 00:20:24.357095 19128 net.cpp:301] conv2_3_ReLU0 needs backward computation.
I0927 00:20:24.357100 19128 net.cpp:301] conv2_3_scale0 needs backward computation.
I0927 00:20:24.357110 19128 net.cpp:301] conv2_3_bn0 needs backward computation.
I0927 00:20:24.357115 19128 net.cpp:301] conv2_3_0 needs backward computation.
I0927 00:20:24.357120 19128 net.cpp:301] conv2_Eltwise_2_conv2_2ReLU_1_0_split needs backward computation.
I0927 00:20:24.357125 19128 net.cpp:301] conv2_2ReLU_1 needs backward computation.
I0927 00:20:24.357129 19128 net.cpp:301] conv2_Eltwise_2 needs backward computation.
I0927 00:20:24.357136 19128 net.cpp:301] conv2_2_scale1 needs backward computation.
I0927 00:20:24.357139 19128 net.cpp:301] conv2_2bn1 needs backward computation.
I0927 00:20:24.357149 19128 net.cpp:301] conv2_2_1 needs backward computation.
I0927 00:20:24.357154 19128 net.cpp:301] conv2_2_ReLU0 needs backward computation.
I0927 00:20:24.357159 19128 net.cpp:301] conv2_2_scale0 needs backward computation.
I0927 00:20:24.357163 19128 net.cpp:301] conv2_2_bn0 needs backward computation.
I0927 00:20:24.357168 19128 net.cpp:301] conv2_2_0 needs backward computation.
I0927 00:20:24.357172 19128 net.cpp:301] conv2_Eltwise_1_conv2_1ReLU_1_0_split needs backward computation.
I0927 00:20:24.357178 19128 net.cpp:301] conv2_1ReLU_1 needs backward computation.
I0927 00:20:24.357182 19128 net.cpp:301] conv2_Eltwise_1 needs backward computation.
I0927 00:20:24.357192 19128 net.cpp:301] conv2_1_scale1 needs backward computation.
I0927 00:20:24.357197 19128 net.cpp:301] conv2_1bn1 needs backward computation.
I0927 00:20:24.357200 19128 net.cpp:301] conv2_1_1 needs backward computation.
I0927 00:20:24.357205 19128 net.cpp:301] conv2_1_ReLU0 needs backward computation.
I0927 00:20:24.357210 19128 net.cpp:301] conv2_1_scale0 needs backward computation.
I0927 00:20:24.357214 19128 net.cpp:301] conv2_1_bn0 needs backward computation.
I0927 00:20:24.357219 19128 net.cpp:301] conv2_1_0 needs backward computation.
I0927 00:20:24.357224 19128 net.cpp:301] conv1_conv1/ReLU_0_split needs backward computation.
I0927 00:20:24.357229 19128 net.cpp:301] conv1/ReLU needs backward computation.
I0927 00:20:24.357234 19128 net.cpp:301] conv1/scale needs backward computation.
I0927 00:20:24.357239 19128 net.cpp:301] conv1/bn needs backward computation.
I0927 00:20:24.357244 19128 net.cpp:301] conv1 needs backward computation.
I0927 00:20:24.357249 19128 net.cpp:303] label_Data1_1_split does not need backward computation.
I0927 00:20:24.357254 19128 net.cpp:303] Data1 does not need backward computation.
I0927 00:20:24.357259 19128 net.cpp:348] This network produces output Softmax1
I0927 00:20:24.357264 19128 net.cpp:348] This network produces output prob
I0927 00:20:24.357352 19128 net.cpp:363] Network initialization done.
I0927 00:20:24.358022 19128 solver.cpp:110] Solver scaffolding done.
I0927 00:20:24.372303 19128 caffe.cpp:313] Starting Optimization
I0927 00:20:24.372328 19128 solver.cpp:425] Solving ResNet-32
I0927 00:20:24.372331 19128 solver.cpp:427] Learning Rate Policy: multistep
I0927 00:20:24.377666 19128 solver.cpp:514] Iteration 0, Testing net (#0)
I0927 00:20:53.179930 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:20:53.266919 19128 solver.cpp:580]     Test net output #0: Softmax1 = 2.30259 (* 1 = 2.30259 loss)
I0927 00:20:53.266953 19128 solver.cpp:580]     Test net output #1: prob = 0
I0927 00:20:53.708828 19128 solver.cpp:357] Iteration 0 (-6.16415e+32 iter/s, 29.3382s/100 iters), loss = 3.68816
I0927 00:20:53.708896 19128 solver.cpp:376]     Train net output #0: Softmax1 = 3.68816 (* 1 = 3.68816 loss)
I0927 00:20:53.708922 19128 sgd_solver.cpp:165] Iteration 0, lr = 0.1
I0927 00:21:27.359483 19128 solver.cpp:357] Iteration 100 (2.97148 iter/s, 33.6533s/100 iters), loss = 1.84197
I0927 00:21:27.359642 19128 solver.cpp:376]     Train net output #0: Softmax1 = 1.84197 (* 1 = 1.84197 loss)
I0927 00:21:27.359652 19128 sgd_solver.cpp:165] Iteration 100, lr = 0.1
I0927 00:21:55.744664 19128 solver.cpp:357] Iteration 200 (3.52286 iter/s, 28.3861s/100 iters), loss = 1.61706
I0927 00:21:55.744740 19128 solver.cpp:376]     Train net output #0: Softmax1 = 1.61706 (* 1 = 1.61706 loss)
I0927 00:21:55.744750 19128 sgd_solver.cpp:165] Iteration 200, lr = 0.1
I0927 00:22:31.664871 19128 solver.cpp:357] Iteration 300 (2.7839 iter/s, 35.9208s/100 iters), loss = 1.6074
I0927 00:22:31.665123 19128 solver.cpp:376]     Train net output #0: Softmax1 = 1.6074 (* 1 = 1.6074 loss)
I0927 00:22:31.665134 19128 sgd_solver.cpp:165] Iteration 300, lr = 0.1
I0927 00:23:02.702206 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:23:07.731608 19128 solver.cpp:357] Iteration 400 (2.77245 iter/s, 36.0692s/100 iters), loss = 1.45882
I0927 00:23:07.731673 19128 solver.cpp:376]     Train net output #0: Softmax1 = 1.45882 (* 1 = 1.45882 loss)
I0927 00:23:07.731683 19128 sgd_solver.cpp:165] Iteration 400, lr = 0.1
I0927 00:23:43.423671 19128 solver.cpp:514] Iteration 500, Testing net (#0)
I0927 00:24:11.908517 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:24:12.037878 19128 solver.cpp:580]     Test net output #0: Softmax1 = 2.07654 (* 1 = 2.07654 loss)
I0927 00:24:12.037905 19128 solver.cpp:580]     Test net output #1: prob = 0.2514
I0927 00:24:12.316845 19128 solver.cpp:357] Iteration 500 (1.54823 iter/s, 64.5898s/100 iters), loss = 1.24511
I0927 00:24:12.316911 19128 solver.cpp:376]     Train net output #0: Softmax1 = 1.24511 (* 1 = 1.24511 loss)
I0927 00:24:12.316923 19128 sgd_solver.cpp:165] Iteration 500, lr = 0.1
I0927 00:24:45.871914 19128 solver.cpp:357] Iteration 600 (2.98017 iter/s, 33.5552s/100 iters), loss = 1.17045
I0927 00:24:45.872073 19128 solver.cpp:376]     Train net output #0: Softmax1 = 1.17045 (* 1 = 1.17045 loss)
I0927 00:24:45.872087 19128 sgd_solver.cpp:165] Iteration 600, lr = 0.1
I0927 00:25:14.329310 19128 solver.cpp:357] Iteration 700 (3.51397 iter/s, 28.4579s/100 iters), loss = 0.997307
I0927 00:25:14.329391 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.997307 (* 1 = 0.997307 loss)
I0927 00:25:14.329402 19128 sgd_solver.cpp:165] Iteration 700, lr = 0.1
I0927 00:25:42.142668 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:25:50.416213 19128 solver.cpp:357] Iteration 800 (2.77107 iter/s, 36.0871s/100 iters), loss = 1.05768
I0927 00:25:50.416281 19128 solver.cpp:376]     Train net output #0: Softmax1 = 1.05768 (* 1 = 1.05768 loss)
I0927 00:25:50.416291 19128 sgd_solver.cpp:165] Iteration 800, lr = 0.1
I0927 00:26:26.447405 19128 solver.cpp:357] Iteration 900 (2.7752 iter/s, 36.0334s/100 iters), loss = 1.06821
I0927 00:26:26.447582 19128 solver.cpp:376]     Train net output #0: Softmax1 = 1.06821 (* 1 = 1.06821 loss)
I0927 00:26:26.447592 19128 sgd_solver.cpp:165] Iteration 900, lr = 0.1
I0927 00:27:02.150631 19128 solver.cpp:514] Iteration 1000, Testing net (#0)
I0927 00:27:30.852694 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:27:30.992697 19128 solver.cpp:580]     Test net output #0: Softmax1 = 3.23694 (* 1 = 3.23694 loss)
I0927 00:27:30.992723 19128 solver.cpp:580]     Test net output #1: prob = 0.100599
I0927 00:27:31.256079 19128 solver.cpp:357] Iteration 1000 (1.54296 iter/s, 64.8105s/100 iters), loss = 0.854122
I0927 00:27:31.256141 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.854122 (* 1 = 0.854122 loss)
I0927 00:27:31.256152 19128 sgd_solver.cpp:165] Iteration 1000, lr = 0.1
I0927 00:28:04.745805 19128 solver.cpp:357] Iteration 1100 (2.986 iter/s, 33.4896s/100 iters), loss = 0.774183
I0927 00:28:04.745937 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.774183 (* 1 = 0.774183 loss)
I0927 00:28:04.745949 19128 sgd_solver.cpp:165] Iteration 1100, lr = 0.1
I0927 00:28:22.688002 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:28:33.560009 19128 solver.cpp:357] Iteration 1200 (3.47033 iter/s, 28.8157s/100 iters), loss = 0.803596
I0927 00:28:33.560088 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.803596 (* 1 = 0.803596 loss)
I0927 00:28:33.560099 19128 sgd_solver.cpp:165] Iteration 1200, lr = 0.1
I0927 00:29:09.532339 19128 solver.cpp:357] Iteration 1300 (2.77992 iter/s, 35.9722s/100 iters), loss = 0.73133
I0927 00:29:09.532577 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.73133 (* 1 = 0.73133 loss)
I0927 00:29:09.532589 19128 sgd_solver.cpp:165] Iteration 1300, lr = 0.1
I0927 00:29:45.582254 19128 solver.cpp:357] Iteration 1400 (2.77394 iter/s, 36.0498s/100 iters), loss = 0.719723
I0927 00:29:45.582370 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.719723 (* 1 = 0.719723 loss)
I0927 00:29:45.582381 19128 sgd_solver.cpp:165] Iteration 1400, lr = 0.1
I0927 00:30:21.273453 19128 solver.cpp:514] Iteration 1500, Testing net (#0)
I0927 00:30:50.085292 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:30:50.160164 19128 solver.cpp:580]     Test net output #0: Softmax1 = 3.78352 (* 1 = 3.78352 loss)
I0927 00:30:50.160190 19128 solver.cpp:580]     Test net output #1: prob = 0.0999995
I0927 00:30:50.509721 19128 solver.cpp:357] Iteration 1500 (1.5401 iter/s, 64.9309s/100 iters), loss = 0.739504
I0927 00:30:50.509778 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.739504 (* 1 = 0.739504 loss)
I0927 00:30:50.509791 19128 sgd_solver.cpp:165] Iteration 1500, lr = 0.1
I0927 00:31:11.441789 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:31:23.717981 19128 solver.cpp:357] Iteration 1600 (3.01134 iter/s, 33.2078s/100 iters), loss = 0.624551
I0927 00:31:23.718047 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.624551 (* 1 = 0.624551 loss)
I0927 00:31:23.718062 19128 sgd_solver.cpp:165] Iteration 1600, lr = 0.1
I0927 00:31:52.546936 19128 solver.cpp:357] Iteration 1700 (3.46856 iter/s, 28.8304s/100 iters), loss = 0.817996
I0927 00:31:52.547089 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.817996 (* 1 = 0.817996 loss)
I0927 00:31:52.547099 19128 sgd_solver.cpp:165] Iteration 1700, lr = 0.1
I0927 00:32:28.592254 19128 solver.cpp:357] Iteration 1800 (2.7742 iter/s, 36.0464s/100 iters), loss = 0.854723
I0927 00:32:28.592430 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.854723 (* 1 = 0.854723 loss)
I0927 00:32:28.592442 19128 sgd_solver.cpp:165] Iteration 1800, lr = 0.1
I0927 00:33:04.644628 19128 solver.cpp:357] Iteration 1900 (2.77369 iter/s, 36.0531s/100 iters), loss = 0.653006
I0927 00:33:04.644757 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.653006 (* 1 = 0.653006 loss)
I0927 00:33:04.644768 19128 sgd_solver.cpp:165] Iteration 1900, lr = 0.1
I0927 00:33:22.325222 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:33:40.341393 19128 solver.cpp:514] Iteration 2000, Testing net (#0)
I0927 00:34:08.945323 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:34:09.043778 19128 solver.cpp:580]     Test net output #0: Softmax1 = 3.13715 (* 1 = 3.13715 loss)
I0927 00:34:09.043815 19128 solver.cpp:580]     Test net output #1: prob = 0.100099
I0927 00:34:09.388058 19128 solver.cpp:357] Iteration 2000 (1.54448 iter/s, 64.7466s/100 iters), loss = 0.55134
I0927 00:34:09.388110 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.55134 (* 1 = 0.55134 loss)
I0927 00:34:09.388120 19128 sgd_solver.cpp:165] Iteration 2000, lr = 0.1
I0927 00:34:42.572145 19128 solver.cpp:357] Iteration 2100 (3.01335 iter/s, 33.1856s/100 iters), loss = 0.640582
I0927 00:34:42.572263 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.640582 (* 1 = 0.640582 loss)
I0927 00:34:42.572274 19128 sgd_solver.cpp:165] Iteration 2100, lr = 0.1
I0927 00:35:11.363593 19128 solver.cpp:357] Iteration 2200 (3.47334 iter/s, 28.7907s/100 iters), loss = 0.675061
I0927 00:35:11.363662 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.675061 (* 1 = 0.675061 loss)
I0927 00:35:11.363672 19128 sgd_solver.cpp:165] Iteration 2200, lr = 0.1
I0927 00:35:47.251814 19128 solver.cpp:357] Iteration 2300 (2.7863 iter/s, 35.8899s/100 iters), loss = 0.626209
I0927 00:35:47.252115 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.626209 (* 1 = 0.626209 loss)
I0927 00:35:47.252127 19128 sgd_solver.cpp:165] Iteration 2300, lr = 0.1
I0927 00:36:01.350150 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:36:23.113607 19128 solver.cpp:357] Iteration 2400 (2.78852 iter/s, 35.8614s/100 iters), loss = 0.542543
I0927 00:36:23.113766 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.542543 (* 1 = 0.542543 loss)
I0927 00:36:23.113777 19128 sgd_solver.cpp:165] Iteration 2400, lr = 0.1
I0927 00:36:58.848608 19128 solver.cpp:514] Iteration 2500, Testing net (#0)
I0927 00:37:27.763736 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:37:27.905603 19128 solver.cpp:580]     Test net output #0: Softmax1 = 3.00598 (* 1 = 3.00598 loss)
I0927 00:37:27.905632 19128 solver.cpp:580]     Test net output #1: prob = 0.100199
I0927 00:37:28.169186 19128 solver.cpp:357] Iteration 2500 (1.53713 iter/s, 65.0565s/100 iters), loss = 0.589815
I0927 00:37:28.169245 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.589815 (* 1 = 0.589815 loss)
I0927 00:37:28.169258 19128 sgd_solver.cpp:165] Iteration 2500, lr = 0.1
I0927 00:38:00.965868 19128 solver.cpp:357] Iteration 2600 (3.04915 iter/s, 32.796s/100 iters), loss = 0.809581
I0927 00:38:00.966032 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.809581 (* 1 = 0.809581 loss)
I0927 00:38:00.966043 19128 sgd_solver.cpp:165] Iteration 2600, lr = 0.1
I0927 00:38:30.008385 19128 solver.cpp:357] Iteration 2700 (3.44333 iter/s, 29.0417s/100 iters), loss = 0.786597
I0927 00:38:30.008451 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.786597 (* 1 = 0.786597 loss)
I0927 00:38:30.008462 19128 sgd_solver.cpp:165] Iteration 2700, lr = 0.1
I0927 00:38:40.833076 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:39:06.059829 19128 solver.cpp:357] Iteration 2800 (2.77369 iter/s, 36.053s/100 iters), loss = 0.53583
I0927 00:39:06.059898 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.53583 (* 1 = 0.53583 loss)
I0927 00:39:06.059908 19128 sgd_solver.cpp:165] Iteration 2800, lr = 0.1
I0927 00:39:42.098831 19128 solver.cpp:357] Iteration 2900 (2.77467 iter/s, 36.0403s/100 iters), loss = 0.57261
I0927 00:39:42.098987 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.57261 (* 1 = 0.57261 loss)
I0927 00:39:42.098997 19128 sgd_solver.cpp:165] Iteration 2900, lr = 0.1
I0927 00:40:17.793776 19128 solver.cpp:514] Iteration 3000, Testing net (#0)
I0927 00:40:46.384721 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:40:46.464610 19128 solver.cpp:580]     Test net output #0: Softmax1 = 3.40169 (* 1 = 3.40169 loss)
I0927 00:40:46.464646 19128 solver.cpp:580]     Test net output #1: prob = 0.100199
I0927 00:40:46.772200 19128 solver.cpp:357] Iteration 3000 (1.54617 iter/s, 64.6761s/100 iters), loss = 0.616257
I0927 00:40:46.772253 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.616257 (* 1 = 0.616257 loss)
I0927 00:40:46.772264 19128 sgd_solver.cpp:165] Iteration 3000, lr = 0.1
I0927 00:41:19.814004 19128 solver.cpp:357] Iteration 3100 (3.02634 iter/s, 33.0432s/100 iters), loss = 0.569128
I0927 00:41:19.814157 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.569128 (* 1 = 0.569128 loss)
I0927 00:41:19.814168 19128 sgd_solver.cpp:165] Iteration 3100, lr = 0.1
I0927 00:41:25.160496 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:41:48.741724 19128 solver.cpp:357] Iteration 3200 (3.45676 iter/s, 28.9288s/100 iters), loss = 0.550637
I0927 00:41:48.741797 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.550637 (* 1 = 0.550637 loss)
I0927 00:41:48.741808 19128 sgd_solver.cpp:165] Iteration 3200, lr = 0.1
I0927 00:42:24.828434 19128 solver.cpp:357] Iteration 3300 (2.77115 iter/s, 36.0862s/100 iters), loss = 0.503013
I0927 00:42:24.828603 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.503013 (* 1 = 0.503013 loss)
I0927 00:42:24.828613 19128 sgd_solver.cpp:165] Iteration 3300, lr = 0.1
I0927 00:43:00.876667 19128 solver.cpp:357] Iteration 3400 (2.77402 iter/s, 36.0488s/100 iters), loss = 0.52953
I0927 00:43:00.876901 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.52953 (* 1 = 0.52953 loss)
I0927 00:43:00.876914 19128 sgd_solver.cpp:165] Iteration 3400, lr = 0.1
I0927 00:43:36.576225 19128 solver.cpp:514] Iteration 3500, Testing net (#0)
I0927 00:44:05.189535 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:44:05.296833 19128 solver.cpp:580]     Test net output #0: Softmax1 = 3.29877 (* 1 = 3.29877 loss)
I0927 00:44:05.296869 19128 solver.cpp:580]     Test net output #1: prob = 0.105999
I0927 00:44:05.583879 19128 solver.cpp:357] Iteration 3500 (1.54541 iter/s, 64.7078s/100 iters), loss = 0.6729
I0927 00:44:05.583938 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.6729 (* 1 = 0.6729 loss)
I0927 00:44:05.583951 19128 sgd_solver.cpp:165] Iteration 3500, lr = 0.1
I0927 00:44:09.667951 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:44:38.509028 19128 solver.cpp:357] Iteration 3600 (3.03741 iter/s, 32.9227s/100 iters), loss = 0.558094
I0927 00:44:38.509105 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.558094 (* 1 = 0.558094 loss)
I0927 00:44:38.509119 19128 sgd_solver.cpp:165] Iteration 3600, lr = 0.1
I0927 00:45:07.305824 19128 solver.cpp:357] Iteration 3700 (3.47309 iter/s, 28.7928s/100 iters), loss = 0.468902
I0927 00:45:07.306015 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.468902 (* 1 = 0.468902 loss)
I0927 00:45:07.306026 19128 sgd_solver.cpp:165] Iteration 3700, lr = 0.1
I0927 00:45:43.453085 19128 solver.cpp:357] Iteration 3800 (2.76679 iter/s, 36.1429s/100 iters), loss = 0.466223
I0927 00:45:43.453229 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.466223 (* 1 = 0.466223 loss)
I0927 00:45:43.453240 19128 sgd_solver.cpp:165] Iteration 3800, lr = 0.1
I0927 00:46:19.497929 19128 solver.cpp:357] Iteration 3900 (2.77454 iter/s, 36.042s/100 iters), loss = 0.7011
I0927 00:46:19.498081 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.7011 (* 1 = 0.7011 loss)
I0927 00:46:19.498092 19128 sgd_solver.cpp:165] Iteration 3900, lr = 0.1
I0927 00:46:20.227166 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:46:55.184612 19128 solver.cpp:514] Iteration 4000, Testing net (#0)
I0927 00:47:23.793666 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:47:23.911227 19128 solver.cpp:580]     Test net output #0: Softmax1 = 2.16491 (* 1 = 2.16491 loss)
I0927 00:47:23.911267 19128 solver.cpp:580]     Test net output #1: prob = 0.3077
I0927 00:47:24.190248 19128 solver.cpp:357] Iteration 4000 (1.54585 iter/s, 64.6892s/100 iters), loss = 0.585802
I0927 00:47:24.190310 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.585802 (* 1 = 0.585802 loss)
I0927 00:47:24.190321 19128 sgd_solver.cpp:165] Iteration 4000, lr = 0.1
I0927 00:47:57.144798 19128 solver.cpp:357] Iteration 4100 (3.03481 iter/s, 32.951s/100 iters), loss = 0.458372
I0927 00:47:57.144942 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.458372 (* 1 = 0.458372 loss)
I0927 00:47:57.144953 19128 sgd_solver.cpp:165] Iteration 4100, lr = 0.1
I0927 00:48:26.263981 19128 solver.cpp:357] Iteration 4200 (3.43431 iter/s, 29.118s/100 iters), loss = 0.539311
I0927 00:48:26.264061 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.539311 (* 1 = 0.539311 loss)
I0927 00:48:26.264072 19128 sgd_solver.cpp:165] Iteration 4200, lr = 0.1
I0927 00:48:59.369172 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:49:02.171573 19128 solver.cpp:357] Iteration 4300 (2.78518 iter/s, 35.9043s/100 iters), loss = 0.445227
I0927 00:49:02.171643 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.445227 (* 1 = 0.445227 loss)
I0927 00:49:02.171653 19128 sgd_solver.cpp:165] Iteration 4300, lr = 0.1
I0927 00:49:38.108386 19128 solver.cpp:357] Iteration 4400 (2.78278 iter/s, 35.9353s/100 iters), loss = 0.526646
I0927 00:49:38.108510 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.526646 (* 1 = 0.526646 loss)
I0927 00:49:38.108521 19128 sgd_solver.cpp:165] Iteration 4400, lr = 0.1
I0927 00:50:13.802537 19128 solver.cpp:514] Iteration 4500, Testing net (#0)
I0927 00:50:42.505837 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:50:42.647980 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.53467 (* 1 = 1.53467 loss)
I0927 00:50:42.648008 19128 solver.cpp:580]     Test net output #1: prob = 0.447
I0927 00:50:42.909065 19128 solver.cpp:357] Iteration 4500 (1.54328 iter/s, 64.797s/100 iters), loss = 0.575075
I0927 00:50:42.909132 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.575075 (* 1 = 0.575075 loss)
I0927 00:50:42.909143 19128 sgd_solver.cpp:165] Iteration 4500, lr = 0.1
I0927 00:51:15.865819 19128 solver.cpp:357] Iteration 4600 (3.03454 iter/s, 32.954s/100 iters), loss = 0.443253
I0927 00:51:15.865988 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.443253 (* 1 = 0.443253 loss)
I0927 00:51:15.865999 19128 sgd_solver.cpp:165] Iteration 4600, lr = 0.1
I0927 00:51:39.080377 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:51:45.198781 19128 solver.cpp:357] Iteration 4700 (3.40922 iter/s, 29.3323s/100 iters), loss = 0.392845
I0927 00:51:45.198855 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.392845 (* 1 = 0.392845 loss)
I0927 00:51:45.198865 19128 sgd_solver.cpp:165] Iteration 4700, lr = 0.1
I0927 00:52:21.252939 19128 solver.cpp:357] Iteration 4800 (2.77368 iter/s, 36.0532s/100 iters), loss = 0.472865
I0927 00:52:21.253062 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.472865 (* 1 = 0.472865 loss)
I0927 00:52:21.253073 19128 sgd_solver.cpp:165] Iteration 4800, lr = 0.1
I0927 00:52:57.301542 19128 solver.cpp:357] Iteration 4900 (2.77423 iter/s, 36.046s/100 iters), loss = 0.512562
I0927 00:52:57.301657 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.512562 (* 1 = 0.512562 loss)
I0927 00:52:57.301668 19128 sgd_solver.cpp:165] Iteration 4900, lr = 0.1
I0927 00:53:32.999732 19128 solver.cpp:514] Iteration 5000, Testing net (#0)
I0927 00:54:01.561012 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:54:01.654240 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.59523 (* 1 = 1.59523 loss)
I0927 00:54:01.654268 19128 solver.cpp:580]     Test net output #1: prob = 0.4346
I0927 00:54:01.974617 19128 solver.cpp:357] Iteration 5000 (1.5463 iter/s, 64.6703s/100 iters), loss = 0.331622
I0927 00:54:01.974679 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.331622 (* 1 = 0.331622 loss)
I0927 00:54:01.974692 19128 sgd_solver.cpp:165] Iteration 5000, lr = 0.1
I0927 00:54:27.859156 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:54:34.742086 19128 solver.cpp:357] Iteration 5100 (3.05203 iter/s, 32.7651s/100 iters), loss = 0.591094
I0927 00:54:34.742156 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.591094 (* 1 = 0.591094 loss)
I0927 00:54:34.742168 19128 sgd_solver.cpp:165] Iteration 5100, lr = 0.1
I0927 00:55:04.176188 19128 solver.cpp:357] Iteration 5200 (3.39756 iter/s, 29.4329s/100 iters), loss = 0.702191
I0927 00:55:04.176337 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.702191 (* 1 = 0.702191 loss)
I0927 00:55:04.176348 19128 sgd_solver.cpp:165] Iteration 5200, lr = 0.1
I0927 00:55:40.117050 19128 solver.cpp:357] Iteration 5300 (2.78252 iter/s, 35.9386s/100 iters), loss = 0.501853
I0927 00:55:40.117367 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.501853 (* 1 = 0.501853 loss)
I0927 00:55:40.117431 19128 sgd_solver.cpp:165] Iteration 5300, lr = 0.1
I0927 00:56:16.252436 19128 solver.cpp:357] Iteration 5400 (2.76754 iter/s, 36.1332s/100 iters), loss = 0.363156
I0927 00:56:16.252605 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.363156 (* 1 = 0.363156 loss)
I0927 00:56:16.252616 19128 sgd_solver.cpp:165] Iteration 5400, lr = 0.1
I0927 00:56:39.344691 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:56:51.960845 19128 solver.cpp:514] Iteration 5500, Testing net (#0)
I0927 00:57:20.429399 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:57:20.561827 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.19988 (* 1 = 1.19988 loss)
I0927 00:57:20.561864 19128 solver.cpp:580]     Test net output #1: prob = 0.6082
I0927 00:57:20.840054 19128 solver.cpp:357] Iteration 5500 (1.54831 iter/s, 64.5865s/100 iters), loss = 0.396093
I0927 00:57:20.840123 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.396093 (* 1 = 0.396093 loss)
I0927 00:57:20.840135 19128 sgd_solver.cpp:165] Iteration 5500, lr = 0.1
I0927 00:57:53.488716 19128 solver.cpp:357] Iteration 5600 (3.06311 iter/s, 32.6466s/100 iters), loss = 0.430807
I0927 00:57:53.488869 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.430807 (* 1 = 0.430807 loss)
I0927 00:57:53.488879 19128 sgd_solver.cpp:165] Iteration 5600, lr = 0.1
I0927 00:58:22.812574 19128 solver.cpp:357] Iteration 5700 (3.4102 iter/s, 29.3238s/100 iters), loss = 0.431088
I0927 00:58:22.812649 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.431088 (* 1 = 0.431088 loss)
I0927 00:58:22.812659 19128 sgd_solver.cpp:165] Iteration 5700, lr = 0.1
I0927 00:58:58.847915 19128 solver.cpp:357] Iteration 5800 (2.77521 iter/s, 36.0334s/100 iters), loss = 0.391298
I0927 00:58:58.848067 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.391298 (* 1 = 0.391298 loss)
I0927 00:58:58.848078 19128 sgd_solver.cpp:165] Iteration 5800, lr = 0.1
I0927 00:59:18.692131 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 00:59:34.896178 19128 solver.cpp:357] Iteration 5900 (2.77407 iter/s, 36.0481s/100 iters), loss = 0.567861
I0927 00:59:34.896322 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.567861 (* 1 = 0.567861 loss)
I0927 00:59:34.896332 19128 sgd_solver.cpp:165] Iteration 5900, lr = 0.1
I0927 01:00:10.586458 19128 solver.cpp:514] Iteration 6000, Testing net (#0)
I0927 01:00:39.258004 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:00:39.400240 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.47425 (* 1 = 1.47425 loss)
I0927 01:00:39.400266 19128 solver.cpp:580]     Test net output #1: prob = 0.4789
I0927 01:00:39.688915 19128 solver.cpp:357] Iteration 6000 (1.54337 iter/s, 64.7931s/100 iters), loss = 0.473986
I0927 01:00:39.688976 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.473986 (* 1 = 0.473986 loss)
I0927 01:00:39.688989 19128 sgd_solver.cpp:165] Iteration 6000, lr = 0.1
I0927 01:01:12.324545 19128 solver.cpp:357] Iteration 6100 (3.06431 iter/s, 32.6337s/100 iters), loss = 0.429653
I0927 01:01:12.324687 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.429653 (* 1 = 0.429653 loss)
I0927 01:01:12.324699 19128 sgd_solver.cpp:165] Iteration 6100, lr = 0.1
I0927 01:01:42.005587 19128 solver.cpp:357] Iteration 6200 (3.36936 iter/s, 29.6792s/100 iters), loss = 0.36963
I0927 01:01:42.005656 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.36963 (* 1 = 0.36963 loss)
I0927 01:01:42.005666 19128 sgd_solver.cpp:165] Iteration 6200, lr = 0.1
I0927 01:01:58.245947 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:02:18.065138 19128 solver.cpp:357] Iteration 6300 (2.77317 iter/s, 36.0599s/100 iters), loss = 0.359189
I0927 01:02:18.065217 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.359189 (* 1 = 0.359189 loss)
I0927 01:02:18.065228 19128 sgd_solver.cpp:165] Iteration 6300, lr = 0.1
I0927 01:02:54.115222 19128 solver.cpp:357] Iteration 6400 (2.77405 iter/s, 36.0483s/100 iters), loss = 0.506603
I0927 01:02:54.115396 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.506603 (* 1 = 0.506603 loss)
I0927 01:02:54.115406 19128 sgd_solver.cpp:165] Iteration 6400, lr = 0.1
I0927 01:03:29.808256 19128 solver.cpp:514] Iteration 6500, Testing net (#0)
I0927 01:03:58.593333 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:03:58.715442 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.884833 (* 1 = 0.884833 loss)
I0927 01:03:58.715481 19128 solver.cpp:580]     Test net output #1: prob = 0.708399
I0927 01:03:58.991637 19128 solver.cpp:357] Iteration 6500 (1.54142 iter/s, 64.8751s/100 iters), loss = 0.391271
I0927 01:03:58.991695 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.391271 (* 1 = 0.391271 loss)
I0927 01:03:58.991708 19128 sgd_solver.cpp:165] Iteration 6500, lr = 0.1
I0927 01:04:31.293638 19128 solver.cpp:357] Iteration 6600 (3.09576 iter/s, 32.3023s/100 iters), loss = 0.506663
I0927 01:04:31.293830 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.506663 (* 1 = 0.506663 loss)
I0927 01:04:31.293843 19128 sgd_solver.cpp:165] Iteration 6600, lr = 0.1
I0927 01:04:40.894832 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:05:01.055143 19128 solver.cpp:357] Iteration 6700 (3.36002 iter/s, 29.7617s/100 iters), loss = 0.468204
I0927 01:05:01.055217 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.468204 (* 1 = 0.468204 loss)
I0927 01:05:01.055228 19128 sgd_solver.cpp:165] Iteration 6700, lr = 0.1
I0927 01:05:37.123648 19128 solver.cpp:357] Iteration 6800 (2.77263 iter/s, 36.0669s/100 iters), loss = 0.454647
I0927 01:05:37.123765 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.454647 (* 1 = 0.454647 loss)
I0927 01:05:37.123775 19128 sgd_solver.cpp:165] Iteration 6800, lr = 0.1
I0927 01:06:13.192472 19128 solver.cpp:357] Iteration 6900 (2.77245 iter/s, 36.0692s/100 iters), loss = 0.454823
I0927 01:06:13.192595 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.454823 (* 1 = 0.454823 loss)
I0927 01:06:13.192605 19128 sgd_solver.cpp:165] Iteration 6900, lr = 0.1
I0927 01:06:48.891423 19128 solver.cpp:514] Iteration 7000, Testing net (#0)
I0927 01:07:17.523522 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:07:17.631435 19128 solver.cpp:580]     Test net output #0: Softmax1 = 2.11314 (* 1 = 2.11314 loss)
I0927 01:07:17.631472 19128 solver.cpp:580]     Test net output #1: prob = 0.4036
I0927 01:07:17.920348 19128 solver.cpp:357] Iteration 7000 (1.54491 iter/s, 64.7288s/100 iters), loss = 0.4529
I0927 01:07:17.920409 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.4529 (* 1 = 0.4529 loss)
I0927 01:07:17.920419 19128 sgd_solver.cpp:165] Iteration 7000, lr = 0.1
I0927 01:07:27.822576 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:07:50.224629 19128 solver.cpp:357] Iteration 7100 (3.09552 iter/s, 32.3047s/100 iters), loss = 0.474461
I0927 01:07:50.224694 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.474461 (* 1 = 0.474461 loss)
I0927 01:07:50.224704 19128 sgd_solver.cpp:165] Iteration 7100, lr = 0.1
I0927 01:08:19.938351 19128 solver.cpp:357] Iteration 7200 (3.3654 iter/s, 29.7141s/100 iters), loss = 0.460151
I0927 01:08:19.938506 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.460151 (* 1 = 0.460151 loss)
I0927 01:08:19.938518 19128 sgd_solver.cpp:165] Iteration 7200, lr = 0.1
I0927 01:08:55.980335 19128 solver.cpp:357] Iteration 7300 (2.77454 iter/s, 36.042s/100 iters), loss = 0.440453
I0927 01:08:55.980504 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.440453 (* 1 = 0.440453 loss)
I0927 01:08:55.980515 19128 sgd_solver.cpp:165] Iteration 7300, lr = 0.1
I0927 01:09:32.018292 19128 solver.cpp:357] Iteration 7400 (2.77488 iter/s, 36.0376s/100 iters), loss = 0.464818
I0927 01:09:32.018465 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.464818 (* 1 = 0.464818 loss)
I0927 01:09:32.018476 19128 sgd_solver.cpp:165] Iteration 7400, lr = 0.1
I0927 01:09:38.159917 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:10:07.640347 19128 solver.cpp:514] Iteration 7500, Testing net (#0)
I0927 01:10:36.313141 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:10:36.445598 19128 solver.cpp:580]     Test net output #0: Softmax1 = 2.25348 (* 1 = 2.25348 loss)
I0927 01:10:36.445626 19128 solver.cpp:580]     Test net output #1: prob = 0.384899
I0927 01:10:36.713194 19128 solver.cpp:357] Iteration 7500 (1.54572 iter/s, 64.6948s/100 iters), loss = 0.409155
I0927 01:10:36.713254 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.409155 (* 1 = 0.409155 loss)
I0927 01:10:36.713265 19128 sgd_solver.cpp:165] Iteration 7500, lr = 0.1
I0927 01:11:08.805855 19128 solver.cpp:357] Iteration 7600 (3.11593 iter/s, 32.0932s/100 iters), loss = 0.520848
I0927 01:11:08.806025 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.520848 (* 1 = 0.520848 loss)
I0927 01:11:08.806036 19128 sgd_solver.cpp:165] Iteration 7600, lr = 0.1
I0927 01:11:38.378362 19128 solver.cpp:357] Iteration 7700 (3.38148 iter/s, 29.5729s/100 iters), loss = 0.398716
I0927 01:11:38.378434 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.398716 (* 1 = 0.398716 loss)
I0927 01:11:38.378444 19128 sgd_solver.cpp:165] Iteration 7700, lr = 0.1
I0927 01:12:14.486603 19128 solver.cpp:357] Iteration 7800 (2.76956 iter/s, 36.1068s/100 iters), loss = 0.416511
I0927 01:12:14.486762 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.416511 (* 1 = 0.416511 loss)
I0927 01:12:14.486773 19128 sgd_solver.cpp:165] Iteration 7800, lr = 0.1
I0927 01:12:17.385453 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:12:50.526103 19128 solver.cpp:357] Iteration 7900 (2.77469 iter/s, 36.04s/100 iters), loss = 0.499442
I0927 01:12:50.526250 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.499442 (* 1 = 0.499442 loss)
I0927 01:12:50.526262 19128 sgd_solver.cpp:165] Iteration 7900, lr = 0.1
I0927 01:13:26.202388 19128 solver.cpp:514] Iteration 8000, Testing net (#0)
I0927 01:13:54.641026 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:13:54.772156 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.76881 (* 1 = 1.76881 loss)
I0927 01:13:54.772184 19128 solver.cpp:580]     Test net output #1: prob = 0.5455
I0927 01:13:55.052117 19128 solver.cpp:357] Iteration 8000 (1.54974 iter/s, 64.5271s/100 iters), loss = 0.403557
I0927 01:13:55.052188 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.403557 (* 1 = 0.403557 loss)
I0927 01:13:55.052201 19128 sgd_solver.cpp:165] Iteration 8000, lr = 0.1
I0927 01:14:27.277405 19128 solver.cpp:357] Iteration 8100 (3.1033 iter/s, 32.2237s/100 iters), loss = 0.474223
I0927 01:14:27.277711 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.474223 (* 1 = 0.474223 loss)
I0927 01:14:27.277775 19128 sgd_solver.cpp:165] Iteration 8100, lr = 0.1
I0927 01:14:56.626796 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:14:56.974755 19128 solver.cpp:357] Iteration 8200 (3.36739 iter/s, 29.6966s/100 iters), loss = 0.426144
I0927 01:14:56.974829 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.426144 (* 1 = 0.426144 loss)
I0927 01:14:56.974840 19128 sgd_solver.cpp:165] Iteration 8200, lr = 0.1
I0927 01:15:33.039315 19128 solver.cpp:357] Iteration 8300 (2.77292 iter/s, 36.0631s/100 iters), loss = 0.483304
I0927 01:15:33.039469 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.483304 (* 1 = 0.483304 loss)
I0927 01:15:33.039480 19128 sgd_solver.cpp:165] Iteration 8300, lr = 0.1
I0927 01:16:09.077493 19128 solver.cpp:357] Iteration 8400 (2.77483 iter/s, 36.0382s/100 iters), loss = 0.423555
I0927 01:16:09.077659 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.423555 (* 1 = 0.423555 loss)
I0927 01:16:09.077670 19128 sgd_solver.cpp:165] Iteration 8400, lr = 0.1
I0927 01:16:44.780532 19128 solver.cpp:514] Iteration 8500, Testing net (#0)
I0927 01:17:13.434257 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:17:13.564873 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.07136 (* 1 = 1.07136 loss)
I0927 01:17:13.564903 19128 solver.cpp:580]     Test net output #1: prob = 0.6748
I0927 01:17:13.837462 19128 solver.cpp:357] Iteration 8500 (1.54416 iter/s, 64.7602s/100 iters), loss = 0.508818
I0927 01:17:13.837530 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.508818 (* 1 = 0.508818 loss)
I0927 01:17:13.837545 19128 sgd_solver.cpp:165] Iteration 8500, lr = 0.1
I0927 01:17:43.175681 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:17:46.033262 19128 solver.cpp:357] Iteration 8600 (3.10614 iter/s, 32.1943s/100 iters), loss = 0.475209
I0927 01:17:46.033325 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.475209 (* 1 = 0.475209 loss)
I0927 01:17:46.033336 19128 sgd_solver.cpp:165] Iteration 8600, lr = 0.1
I0927 01:18:15.745393 19128 solver.cpp:357] Iteration 8700 (3.3656 iter/s, 29.7124s/100 iters), loss = 0.371399
I0927 01:18:15.745504 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.371399 (* 1 = 0.371399 loss)
I0927 01:18:15.745514 19128 sgd_solver.cpp:165] Iteration 8700, lr = 0.1
I0927 01:18:51.807889 19128 solver.cpp:357] Iteration 8800 (2.77333 iter/s, 36.0577s/100 iters), loss = 0.53607
I0927 01:18:51.808035 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.53607 (* 1 = 0.53607 loss)
I0927 01:18:51.808045 19128 sgd_solver.cpp:165] Iteration 8800, lr = 0.1
I0927 01:19:27.880972 19128 solver.cpp:357] Iteration 8900 (2.7725 iter/s, 36.0686s/100 iters), loss = 0.542145
I0927 01:19:27.881125 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.542145 (* 1 = 0.542145 loss)
I0927 01:19:27.881135 19128 sgd_solver.cpp:165] Iteration 8900, lr = 0.1
I0927 01:19:56.736943 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:20:03.579517 19128 solver.cpp:514] Iteration 9000, Testing net (#0)
I0927 01:20:32.427633 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:20:32.512794 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.11671 (* 1 = 1.11671 loss)
I0927 01:20:32.512831 19128 solver.cpp:580]     Test net output #1: prob = 0.6333
I0927 01:20:32.816545 19128 solver.cpp:357] Iteration 9000 (1.54016 iter/s, 64.9283s/100 iters), loss = 0.327353
I0927 01:20:32.816604 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.327353 (* 1 = 0.327353 loss)
I0927 01:20:32.816618 19128 sgd_solver.cpp:165] Iteration 9000, lr = 0.1
I0927 01:21:04.988678 19128 solver.cpp:357] Iteration 9100 (3.1086 iter/s, 32.1688s/100 iters), loss = 0.467998
I0927 01:21:04.988832 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.467998 (* 1 = 0.467998 loss)
I0927 01:21:04.988843 19128 sgd_solver.cpp:165] Iteration 9100, lr = 0.1
I0927 01:21:34.603461 19128 solver.cpp:357] Iteration 9200 (3.37703 iter/s, 29.6118s/100 iters), loss = 0.374943
I0927 01:21:34.603533 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.374943 (* 1 = 0.374943 loss)
I0927 01:21:34.603543 19128 sgd_solver.cpp:165] Iteration 9200, lr = 0.1
I0927 01:22:10.525202 19128 solver.cpp:357] Iteration 9300 (2.78408 iter/s, 35.9185s/100 iters), loss = 0.390326
I0927 01:22:10.525378 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.390326 (* 1 = 0.390326 loss)
I0927 01:22:10.525389 19128 sgd_solver.cpp:165] Iteration 9300, lr = 0.1
I0927 01:22:35.900214 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:22:46.700853 19128 solver.cpp:357] Iteration 9400 (2.76469 iter/s, 36.1705s/100 iters), loss = 0.519984
I0927 01:22:46.701129 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.519984 (* 1 = 0.519984 loss)
I0927 01:22:46.701189 19128 sgd_solver.cpp:165] Iteration 9400, lr = 0.1
I0927 01:23:22.519338 19128 solver.cpp:514] Iteration 9500, Testing net (#0)
I0927 01:23:51.270486 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:23:51.362860 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.07441 (* 1 = 1.07441 loss)
I0927 01:23:51.362890 19128 solver.cpp:580]     Test net output #1: prob = 0.6524
I0927 01:23:51.715734 19128 solver.cpp:357] Iteration 9500 (1.53823 iter/s, 65.0098s/100 iters), loss = 0.398499
I0927 01:23:51.715791 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.398499 (* 1 = 0.398499 loss)
I0927 01:23:51.715801 19128 sgd_solver.cpp:165] Iteration 9500, lr = 0.1
I0927 01:24:23.821966 19128 solver.cpp:357] Iteration 9600 (3.11488 iter/s, 32.104s/100 iters), loss = 0.454364
I0927 01:24:23.822074 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.454364 (* 1 = 0.454364 loss)
I0927 01:24:23.822085 19128 sgd_solver.cpp:165] Iteration 9600, lr = 0.1
I0927 01:24:53.751018 19128 solver.cpp:357] Iteration 9700 (3.34147 iter/s, 29.927s/100 iters), loss = 0.456448
I0927 01:24:53.751087 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.456448 (* 1 = 0.456448 loss)
I0927 01:24:53.751097 19128 sgd_solver.cpp:165] Iteration 9700, lr = 0.1
I0927 01:25:15.767030 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:25:29.644788 19128 solver.cpp:357] Iteration 9800 (2.78634 iter/s, 35.8894s/100 iters), loss = 0.398262
I0927 01:25:29.644856 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.398262 (* 1 = 0.398262 loss)
I0927 01:25:29.644866 19128 sgd_solver.cpp:165] Iteration 9800, lr = 0.1
I0927 01:26:05.723196 19128 solver.cpp:357] Iteration 9900 (2.7719 iter/s, 36.0763s/100 iters), loss = 0.41119
I0927 01:26:05.723311 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.41119 (* 1 = 0.41119 loss)
I0927 01:26:05.723321 19128 sgd_solver.cpp:165] Iteration 9900, lr = 0.1
I0927 01:26:41.401618 19128 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_10000.caffemodel
I0927 01:26:41.438992 19128 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_10000.solverstate
I0927 01:26:41.444561 19128 solver.cpp:514] Iteration 10000, Testing net (#0)
I0927 01:27:09.804623 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:27:09.887542 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.994565 (* 1 = 0.994565 loss)
I0927 01:27:09.887574 19128 solver.cpp:580]     Test net output #1: prob = 0.6768
I0927 01:27:10.201078 19128 solver.cpp:357] Iteration 10000 (1.551 iter/s, 64.4744s/100 iters), loss = 0.378497
I0927 01:27:10.201135 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.378497 (* 1 = 0.378497 loss)
I0927 01:27:10.201145 19128 sgd_solver.cpp:165] Iteration 10000, lr = 0.1
I0927 01:27:42.170121 19128 solver.cpp:357] Iteration 10100 (3.12818 iter/s, 31.9675s/100 iters), loss = 0.50153
I0927 01:27:42.170282 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.50153 (* 1 = 0.50153 loss)
I0927 01:27:42.170295 19128 sgd_solver.cpp:165] Iteration 10100, lr = 0.1
I0927 01:27:56.038803 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:28:11.954596 19128 solver.cpp:357] Iteration 10200 (3.35775 iter/s, 29.7818s/100 iters), loss = 0.377396
I0927 01:28:11.954670 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.377396 (* 1 = 0.377396 loss)
I0927 01:28:11.954681 19128 sgd_solver.cpp:165] Iteration 10200, lr = 0.1
I0927 01:28:48.035542 19128 solver.cpp:357] Iteration 10300 (2.77183 iter/s, 36.0773s/100 iters), loss = 0.418872
I0927 01:28:48.035668 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.418872 (* 1 = 0.418872 loss)
I0927 01:28:48.035678 19128 sgd_solver.cpp:165] Iteration 10300, lr = 0.1
I0927 01:29:24.074393 19128 solver.cpp:357] Iteration 10400 (2.7749 iter/s, 36.0373s/100 iters), loss = 0.488823
I0927 01:29:24.074501 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.488823 (* 1 = 0.488823 loss)
I0927 01:29:24.074510 19128 sgd_solver.cpp:165] Iteration 10400, lr = 0.1
I0927 01:29:59.777143 19128 solver.cpp:514] Iteration 10500, Testing net (#0)
I0927 01:30:28.587656 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:30:28.704262 19128 solver.cpp:580]     Test net output #0: Softmax1 = 5.29905 (* 1 = 5.29905 loss)
I0927 01:30:28.704298 19128 solver.cpp:580]     Test net output #1: prob = 0.2534
I0927 01:30:28.984067 19128 solver.cpp:357] Iteration 10500 (1.54066 iter/s, 64.9073s/100 iters), loss = 0.436089
I0927 01:30:28.984127 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.436089 (* 1 = 0.436089 loss)
I0927 01:30:28.984138 19128 sgd_solver.cpp:165] Iteration 10500, lr = 0.1
I0927 01:30:44.199542 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:31:00.958652 19128 solver.cpp:357] Iteration 10600 (3.12768 iter/s, 31.9726s/100 iters), loss = 0.503298
I0927 01:31:00.958716 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.503298 (* 1 = 0.503298 loss)
I0927 01:31:00.958731 19128 sgd_solver.cpp:165] Iteration 10600, lr = 0.1
I0927 01:31:31.118840 19128 solver.cpp:357] Iteration 10700 (3.31574 iter/s, 30.1592s/100 iters), loss = 0.406073
I0927 01:31:31.119083 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.406073 (* 1 = 0.406073 loss)
I0927 01:31:31.119094 19128 sgd_solver.cpp:165] Iteration 10700, lr = 0.1
I0927 01:32:07.160739 19128 solver.cpp:357] Iteration 10800 (2.7748 iter/s, 36.0387s/100 iters), loss = 0.375606
I0927 01:32:07.160987 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.375606 (* 1 = 0.375606 loss)
I0927 01:32:07.161000 19128 sgd_solver.cpp:165] Iteration 10800, lr = 0.1
I0927 01:32:43.208353 19128 solver.cpp:357] Iteration 10900 (2.77435 iter/s, 36.0444s/100 iters), loss = 0.444934
I0927 01:32:43.208468 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.444934 (* 1 = 0.444934 loss)
I0927 01:32:43.208479 19128 sgd_solver.cpp:165] Iteration 10900, lr = 0.1
I0927 01:32:55.134111 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:33:18.909631 19128 solver.cpp:514] Iteration 11000, Testing net (#0)
I0927 01:33:47.572717 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:33:47.704716 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.924717 (* 1 = 0.924717 loss)
I0927 01:33:47.704746 19128 solver.cpp:580]     Test net output #1: prob = 0.6996
I0927 01:33:47.984277 19128 solver.cpp:357] Iteration 11000 (1.54387 iter/s, 64.7722s/100 iters), loss = 0.401054
I0927 01:33:47.984349 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.401054 (* 1 = 0.401054 loss)
I0927 01:33:47.984359 19128 sgd_solver.cpp:165] Iteration 11000, lr = 0.1
I0927 01:34:19.691659 19128 solver.cpp:357] Iteration 11100 (3.15413 iter/s, 31.7045s/100 iters), loss = 0.427633
I0927 01:34:19.691776 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.427633 (* 1 = 0.427633 loss)
I0927 01:34:19.691787 19128 sgd_solver.cpp:165] Iteration 11100, lr = 0.1
I0927 01:34:49.739886 19128 solver.cpp:357] Iteration 11200 (3.32807 iter/s, 30.0474s/100 iters), loss = 0.297677
I0927 01:34:49.740053 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.297677 (* 1 = 0.297677 loss)
I0927 01:34:49.740068 19128 sgd_solver.cpp:165] Iteration 11200, lr = 0.1
I0927 01:35:25.788923 19128 solver.cpp:357] Iteration 11300 (2.77422 iter/s, 36.0461s/100 iters), loss = 0.482235
I0927 01:35:25.789093 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.482235 (* 1 = 0.482235 loss)
I0927 01:35:25.789105 19128 sgd_solver.cpp:165] Iteration 11300, lr = 0.1
I0927 01:35:34.465273 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:36:01.857223 19128 solver.cpp:357] Iteration 11400 (2.77274 iter/s, 36.0654s/100 iters), loss = 0.417892
I0927 01:36:01.857340 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.417892 (* 1 = 0.417892 loss)
I0927 01:36:01.857352 19128 sgd_solver.cpp:165] Iteration 11400, lr = 0.1
I0927 01:36:37.553537 19128 solver.cpp:514] Iteration 11500, Testing net (#0)
I0927 01:37:06.216812 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:37:06.357532 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.794829 (* 1 = 0.794829 loss)
I0927 01:37:06.357559 19128 solver.cpp:580]     Test net output #1: prob = 0.732701
I0927 01:37:06.623657 19128 solver.cpp:357] Iteration 11500 (1.54404 iter/s, 64.7652s/100 iters), loss = 0.52541
I0927 01:37:06.623723 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.52541 (* 1 = 0.52541 loss)
I0927 01:37:06.623736 19128 sgd_solver.cpp:165] Iteration 11500, lr = 0.1
I0927 01:37:38.465976 19128 solver.cpp:357] Iteration 11600 (3.14074 iter/s, 31.8397s/100 iters), loss = 0.450027
I0927 01:37:38.466084 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.450027 (* 1 = 0.450027 loss)
I0927 01:37:38.466095 19128 sgd_solver.cpp:165] Iteration 11600, lr = 0.1
I0927 01:38:08.501734 19128 solver.cpp:357] Iteration 11700 (3.32943 iter/s, 30.0352s/100 iters), loss = 0.41682
I0927 01:38:08.501943 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.41682 (* 1 = 0.41682 loss)
I0927 01:38:08.501955 19128 sgd_solver.cpp:165] Iteration 11700, lr = 0.1
I0927 01:38:13.572345 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:38:44.544605 19128 solver.cpp:357] Iteration 11800 (2.77459 iter/s, 36.0414s/100 iters), loss = 0.50435
I0927 01:38:44.544715 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.50435 (* 1 = 0.50435 loss)
I0927 01:38:44.544726 19128 sgd_solver.cpp:165] Iteration 11800, lr = 0.1
I0927 01:39:20.604940 19128 solver.cpp:357] Iteration 11900 (2.77322 iter/s, 36.0592s/100 iters), loss = 0.421777
I0927 01:39:20.605065 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.421777 (* 1 = 0.421777 loss)
I0927 01:39:20.605078 19128 sgd_solver.cpp:165] Iteration 11900, lr = 0.1
I0927 01:39:56.305615 19128 solver.cpp:514] Iteration 12000, Testing net (#0)
I0927 01:40:24.947098 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:40:25.092123 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.13259 (* 1 = 1.13259 loss)
I0927 01:40:25.092151 19128 solver.cpp:580]     Test net output #1: prob = 0.658001
I0927 01:40:25.350309 19128 solver.cpp:357] Iteration 12000 (1.54457 iter/s, 64.7429s/100 iters), loss = 0.41207
I0927 01:40:25.350371 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.41207 (* 1 = 0.41207 loss)
I0927 01:40:25.350383 19128 sgd_solver.cpp:165] Iteration 12000, lr = 0.1
I0927 01:40:57.280486 19128 solver.cpp:357] Iteration 12100 (3.13208 iter/s, 31.9277s/100 iters), loss = 0.372602
I0927 01:40:57.280638 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.372602 (* 1 = 0.372602 loss)
I0927 01:40:57.280650 19128 sgd_solver.cpp:165] Iteration 12100, lr = 0.1
I0927 01:40:58.646770 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:41:27.262265 19128 solver.cpp:357] Iteration 12200 (3.33542 iter/s, 29.9813s/100 iters), loss = 0.399097
I0927 01:41:27.262342 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.399097 (* 1 = 0.399097 loss)
I0927 01:41:27.262353 19128 sgd_solver.cpp:165] Iteration 12200, lr = 0.1
I0927 01:42:03.098646 19128 solver.cpp:357] Iteration 12300 (2.79066 iter/s, 35.8338s/100 iters), loss = 0.360705
I0927 01:42:03.098773 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.360705 (* 1 = 0.360705 loss)
I0927 01:42:03.098783 19128 sgd_solver.cpp:165] Iteration 12300, lr = 0.1
I0927 01:42:39.268424 19128 solver.cpp:357] Iteration 12400 (2.76493 iter/s, 36.1672s/100 iters), loss = 0.579189
I0927 01:42:39.268698 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.579189 (* 1 = 0.579189 loss)
I0927 01:42:39.268708 19128 sgd_solver.cpp:165] Iteration 12400, lr = 0.1
I0927 01:43:13.531205 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:43:14.965863 19128 solver.cpp:514] Iteration 12500, Testing net (#0)
I0927 01:43:43.962901 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:43:44.065440 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.95876 (* 1 = 1.95876 loss)
I0927 01:43:44.065476 19128 solver.cpp:580]     Test net output #1: prob = 0.389299
I0927 01:43:44.382349 19128 solver.cpp:357] Iteration 12500 (1.53579 iter/s, 65.1131s/100 iters), loss = 0.314244
I0927 01:43:44.382402 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.314244 (* 1 = 0.314244 loss)
I0927 01:43:44.382412 19128 sgd_solver.cpp:165] Iteration 12500, lr = 0.1
I0927 01:44:16.058787 19128 solver.cpp:357] Iteration 12600 (3.15695 iter/s, 31.6761s/100 iters), loss = 0.419736
I0927 01:44:16.058934 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.419736 (* 1 = 0.419736 loss)
I0927 01:44:16.058945 19128 sgd_solver.cpp:165] Iteration 12600, lr = 0.1
I0927 01:44:46.195688 19128 solver.cpp:357] Iteration 12700 (3.31824 iter/s, 30.1365s/100 iters), loss = 0.655259
I0927 01:44:46.195938 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.655259 (* 1 = 0.655259 loss)
I0927 01:44:46.195950 19128 sgd_solver.cpp:165] Iteration 12700, lr = 0.1
I0927 01:45:22.310909 19128 solver.cpp:357] Iteration 12800 (2.7691 iter/s, 36.1128s/100 iters), loss = 0.457004
I0927 01:45:22.311060 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.457004 (* 1 = 0.457004 loss)
I0927 01:45:22.311072 19128 sgd_solver.cpp:165] Iteration 12800, lr = 0.1
I0927 01:45:53.326606 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:45:58.353257 19128 solver.cpp:357] Iteration 12900 (2.77455 iter/s, 36.0419s/100 iters), loss = 0.476025
I0927 01:45:58.353324 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.476025 (* 1 = 0.476025 loss)
I0927 01:45:58.353335 19128 sgd_solver.cpp:165] Iteration 12900, lr = 0.1
I0927 01:46:34.069953 19128 solver.cpp:514] Iteration 13000, Testing net (#0)
I0927 01:47:02.730978 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:47:02.857264 19128 solver.cpp:580]     Test net output #0: Softmax1 = 2.33808 (* 1 = 2.33808 loss)
I0927 01:47:02.857291 19128 solver.cpp:580]     Test net output #1: prob = 0.427
I0927 01:47:03.154821 19128 solver.cpp:357] Iteration 13000 (1.54318 iter/s, 64.8011s/100 iters), loss = 0.313322
I0927 01:47:03.154881 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.313322 (* 1 = 0.313322 loss)
I0927 01:47:03.154892 19128 sgd_solver.cpp:165] Iteration 13000, lr = 0.1
I0927 01:47:34.728322 19128 solver.cpp:357] Iteration 13100 (3.16724 iter/s, 31.5732s/100 iters), loss = 0.397572
I0927 01:47:34.728485 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.397572 (* 1 = 0.397572 loss)
I0927 01:47:34.728497 19128 sgd_solver.cpp:165] Iteration 13100, lr = 0.1
I0927 01:48:04.868837 19128 solver.cpp:357] Iteration 13200 (3.31783 iter/s, 30.1401s/100 iters), loss = 0.402035
I0927 01:48:04.868959 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.402035 (* 1 = 0.402035 loss)
I0927 01:48:04.868969 19128 sgd_solver.cpp:165] Iteration 13200, lr = 0.1
I0927 01:48:32.595520 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:48:40.748890 19128 solver.cpp:357] Iteration 13300 (2.78711 iter/s, 35.8795s/100 iters), loss = 0.530398
I0927 01:48:40.749040 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.530398 (* 1 = 0.530398 loss)
I0927 01:48:40.749050 19128 sgd_solver.cpp:165] Iteration 13300, lr = 0.1
I0927 01:49:16.806866 19128 solver.cpp:357] Iteration 13400 (2.77338 iter/s, 36.0571s/100 iters), loss = 0.547841
I0927 01:49:16.806977 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.547841 (* 1 = 0.547841 loss)
I0927 01:49:16.806987 19128 sgd_solver.cpp:165] Iteration 13400, lr = 0.1
I0927 01:49:52.501212 19128 solver.cpp:514] Iteration 13500, Testing net (#0)
I0927 01:50:21.237825 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:50:21.370646 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.19995 (* 1 = 1.19995 loss)
I0927 01:50:21.370672 19128 solver.cpp:580]     Test net output #1: prob = 0.6693
I0927 01:50:21.645691 19128 solver.cpp:357] Iteration 13500 (1.5423 iter/s, 64.8384s/100 iters), loss = 0.381651
I0927 01:50:21.645752 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.381651 (* 1 = 0.381651 loss)
I0927 01:50:21.645766 19128 sgd_solver.cpp:165] Iteration 13500, lr = 0.1
I0927 01:50:53.322582 19128 solver.cpp:357] Iteration 13600 (3.15711 iter/s, 31.6746s/100 iters), loss = 0.385009
I0927 01:50:53.322744 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.385009 (* 1 = 0.385009 loss)
I0927 01:50:53.322757 19128 sgd_solver.cpp:165] Iteration 13600, lr = 0.1
I0927 01:51:11.804424 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:51:23.503250 19128 solver.cpp:357] Iteration 13700 (3.31352 iter/s, 30.1793s/100 iters), loss = 0.415839
I0927 01:51:23.503438 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.415839 (* 1 = 0.415839 loss)
I0927 01:51:23.503449 19128 sgd_solver.cpp:165] Iteration 13700, lr = 0.1
I0927 01:51:59.390658 19128 solver.cpp:357] Iteration 13800 (2.78668 iter/s, 35.8851s/100 iters), loss = 0.391665
I0927 01:51:59.390893 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.391665 (* 1 = 0.391665 loss)
I0927 01:51:59.390904 19128 sgd_solver.cpp:165] Iteration 13800, lr = 0.1
I0927 01:52:35.247925 19128 solver.cpp:357] Iteration 13900 (2.78869 iter/s, 35.8591s/100 iters), loss = 0.385059
I0927 01:52:35.248102 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.385059 (* 1 = 0.385059 loss)
I0927 01:52:35.248113 19128 sgd_solver.cpp:165] Iteration 13900, lr = 0.1
I0927 01:53:11.024370 19128 solver.cpp:514] Iteration 14000, Testing net (#0)
I0927 01:53:39.361347 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:53:39.495767 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.1232 (* 1 = 1.1232 loss)
I0927 01:53:39.495795 19128 solver.cpp:580]     Test net output #1: prob = 0.6315
I0927 01:53:39.774605 19128 solver.cpp:357] Iteration 14000 (1.5495 iter/s, 64.537s/100 iters), loss = 0.501506
I0927 01:53:39.774665 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.501506 (* 1 = 0.501506 loss)
I0927 01:53:39.774677 19128 sgd_solver.cpp:165] Iteration 14000, lr = 0.1
I0927 01:54:00.335461 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:54:11.464854 19128 solver.cpp:357] Iteration 14100 (3.1552 iter/s, 31.6937s/100 iters), loss = 0.321496
I0927 01:54:11.464923 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.321496 (* 1 = 0.321496 loss)
I0927 01:54:11.464936 19128 sgd_solver.cpp:165] Iteration 14100, lr = 0.1
I0927 01:54:41.835042 19128 solver.cpp:357] Iteration 14200 (3.29217 iter/s, 30.3751s/100 iters), loss = 0.402689
I0927 01:54:41.835191 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.402689 (* 1 = 0.402689 loss)
I0927 01:54:41.835201 19128 sgd_solver.cpp:165] Iteration 14200, lr = 0.1
I0927 01:55:17.867447 19128 solver.cpp:357] Iteration 14300 (2.77485 iter/s, 36.038s/100 iters), loss = 0.52456
I0927 01:55:17.867595 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.52456 (* 1 = 0.52456 loss)
I0927 01:55:17.867609 19128 sgd_solver.cpp:165] Iteration 14300, lr = 0.1
I0927 01:55:53.906440 19128 solver.cpp:357] Iteration 14400 (2.77452 iter/s, 36.0422s/100 iters), loss = 0.383808
I0927 01:55:53.906572 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.383808 (* 1 = 0.383808 loss)
I0927 01:55:53.906584 19128 sgd_solver.cpp:165] Iteration 14400, lr = 0.1
I0927 01:56:11.590760 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:56:29.621225 19128 solver.cpp:514] Iteration 14500, Testing net (#0)
I0927 01:56:58.217923 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:56:58.286358 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.988864 (* 1 = 0.988864 loss)
I0927 01:56:58.286391 19128 solver.cpp:580]     Test net output #1: prob = 0.6622
I0927 01:56:58.641068 19128 solver.cpp:357] Iteration 14500 (1.54459 iter/s, 64.7421s/100 iters), loss = 0.351932
I0927 01:56:58.641129 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.351932 (* 1 = 0.351932 loss)
I0927 01:56:58.641139 19128 sgd_solver.cpp:165] Iteration 14500, lr = 0.1
I0927 01:57:30.308908 19128 solver.cpp:357] Iteration 14600 (3.15742 iter/s, 31.6714s/100 iters), loss = 0.469406
I0927 01:57:30.309059 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.469406 (* 1 = 0.469406 loss)
I0927 01:57:30.309072 19128 sgd_solver.cpp:165] Iteration 14600, lr = 0.1
I0927 01:58:00.393694 19128 solver.cpp:357] Iteration 14700 (3.32356 iter/s, 30.0883s/100 iters), loss = 0.350332
I0927 01:58:00.393868 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.350332 (* 1 = 0.350332 loss)
I0927 01:58:00.393880 19128 sgd_solver.cpp:165] Iteration 14700, lr = 0.1
I0927 01:58:36.227705 19128 solver.cpp:357] Iteration 14800 (2.79049 iter/s, 35.8359s/100 iters), loss = 0.267966
I0927 01:58:36.227839 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.267966 (* 1 = 0.267966 loss)
I0927 01:58:36.227850 19128 sgd_solver.cpp:165] Iteration 14800, lr = 0.1
I0927 01:58:50.396515 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 01:59:12.188444 19128 solver.cpp:357] Iteration 14900 (2.78068 iter/s, 35.9625s/100 iters), loss = 0.334107
I0927 01:59:12.188642 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.334107 (* 1 = 0.334107 loss)
I0927 01:59:12.188652 19128 sgd_solver.cpp:165] Iteration 14900, lr = 0.1
I0927 01:59:47.783404 19128 solver.cpp:514] Iteration 15000, Testing net (#0)
I0927 02:00:16.231915 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:00:16.299499 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.952035 (* 1 = 0.952035 loss)
I0927 02:00:16.299526 19128 solver.cpp:580]     Test net output #1: prob = 0.669401
I0927 02:00:16.639276 19128 solver.cpp:357] Iteration 15000 (1.55147 iter/s, 64.4552s/100 iters), loss = 0.377107
I0927 02:00:16.639338 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.377107 (* 1 = 0.377107 loss)
I0927 02:00:16.639351 19128 sgd_solver.cpp:165] Iteration 15000, lr = 0.1
I0927 02:00:48.456360 19128 solver.cpp:357] Iteration 15100 (3.14289 iter/s, 31.8179s/100 iters), loss = 0.477659
I0927 02:00:48.456483 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.477659 (* 1 = 0.477659 loss)
I0927 02:00:48.456496 19128 sgd_solver.cpp:165] Iteration 15100, lr = 0.1
I0927 02:01:18.665436 19128 solver.cpp:357] Iteration 15200 (3.31 iter/s, 30.2115s/100 iters), loss = 0.708409
I0927 02:01:18.665586 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.708409 (* 1 = 0.708409 loss)
I0927 02:01:18.665597 19128 sgd_solver.cpp:165] Iteration 15200, lr = 0.1
I0927 02:01:29.495760 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:01:54.703832 19128 solver.cpp:357] Iteration 15300 (2.7746 iter/s, 36.0413s/100 iters), loss = 0.329448
I0927 02:01:54.704004 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.329448 (* 1 = 0.329448 loss)
I0927 02:01:54.704016 19128 sgd_solver.cpp:165] Iteration 15300, lr = 0.1
I0927 02:02:30.781249 19128 solver.cpp:357] Iteration 15400 (2.77176 iter/s, 36.0781s/100 iters), loss = 0.518598
I0927 02:02:30.781399 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.518598 (* 1 = 0.518598 loss)
I0927 02:02:30.781411 19128 sgd_solver.cpp:165] Iteration 15400, lr = 0.1
I0927 02:03:06.478647 19128 solver.cpp:514] Iteration 15500, Testing net (#0)
I0927 02:03:35.201491 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:03:35.335295 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.699042 (* 1 = 0.699042 loss)
I0927 02:03:35.335324 19128 solver.cpp:580]     Test net output #1: prob = 0.7615
I0927 02:03:35.628718 19128 solver.cpp:357] Iteration 15500 (1.54197 iter/s, 64.8521s/100 iters), loss = 0.392969
I0927 02:03:35.628777 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.392969 (* 1 = 0.392969 loss)
I0927 02:03:35.628790 19128 sgd_solver.cpp:165] Iteration 15500, lr = 0.1
I0927 02:04:07.371125 19128 solver.cpp:357] Iteration 15600 (3.15036 iter/s, 31.7424s/100 iters), loss = 0.411705
I0927 02:04:07.371258 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.411705 (* 1 = 0.411705 loss)
I0927 02:04:07.371269 19128 sgd_solver.cpp:165] Iteration 15600, lr = 0.1
I0927 02:04:12.696194 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:04:37.476917 19128 solver.cpp:357] Iteration 15700 (3.32141 iter/s, 30.1077s/100 iters), loss = 0.393154
I0927 02:04:37.477075 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.393154 (* 1 = 0.393154 loss)
I0927 02:04:37.477087 19128 sgd_solver.cpp:165] Iteration 15700, lr = 0.1
I0927 02:05:13.363870 19128 solver.cpp:357] Iteration 15800 (2.78651 iter/s, 35.8871s/100 iters), loss = 0.429964
I0927 02:05:13.363984 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.429964 (* 1 = 0.429964 loss)
I0927 02:05:13.363996 19128 sgd_solver.cpp:165] Iteration 15800, lr = 0.1
I0927 02:05:49.545012 19128 solver.cpp:357] Iteration 15900 (2.76371 iter/s, 36.1832s/100 iters), loss = 0.276347
I0927 02:05:49.545254 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.276347 (* 1 = 0.276347 loss)
I0927 02:05:49.545266 19128 sgd_solver.cpp:165] Iteration 15900, lr = 0.1
I0927 02:06:25.268931 19128 solver.cpp:514] Iteration 16000, Testing net (#0)
I0927 02:06:53.708830 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:06:53.837630 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.21099 (* 1 = 1.21099 loss)
I0927 02:06:53.837666 19128 solver.cpp:580]     Test net output #1: prob = 0.5865
I0927 02:06:54.117907 19128 solver.cpp:357] Iteration 16000 (1.5486 iter/s, 64.5745s/100 iters), loss = 0.423161
I0927 02:06:54.117980 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.423161 (* 1 = 0.423161 loss)
I0927 02:06:54.117991 19128 sgd_solver.cpp:165] Iteration 16000, lr = 0.1
I0927 02:06:58.201248 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:07:25.843925 19128 solver.cpp:357] Iteration 16100 (3.15203 iter/s, 31.7255s/100 iters), loss = 0.473378
I0927 02:07:25.843993 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.473378 (* 1 = 0.473378 loss)
I0927 02:07:25.844005 19128 sgd_solver.cpp:165] Iteration 16100, lr = 0.1
I0927 02:07:55.812640 19128 solver.cpp:357] Iteration 16200 (3.33665 iter/s, 29.9701s/100 iters), loss = 0.355882
I0927 02:07:55.812822 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.355882 (* 1 = 0.355882 loss)
I0927 02:07:55.812834 19128 sgd_solver.cpp:165] Iteration 16200, lr = 0.1
I0927 02:08:31.726490 19128 solver.cpp:357] Iteration 16300 (2.78447 iter/s, 35.9135s/100 iters), loss = 0.304822
I0927 02:08:31.726637 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.304822 (* 1 = 0.304822 loss)
I0927 02:08:31.726649 19128 sgd_solver.cpp:165] Iteration 16300, lr = 0.1
I0927 02:09:07.600276 19128 solver.cpp:357] Iteration 16400 (2.78758 iter/s, 35.8734s/100 iters), loss = 0.412201
I0927 02:09:07.600435 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.412201 (* 1 = 0.412201 loss)
I0927 02:09:07.600447 19128 sgd_solver.cpp:165] Iteration 16400, lr = 0.1
I0927 02:09:08.399139 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:09:43.245329 19128 solver.cpp:514] Iteration 16500, Testing net (#0)
I0927 02:10:11.688076 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:10:11.802466 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.917534 (* 1 = 0.917534 loss)
I0927 02:10:11.802502 19128 solver.cpp:580]     Test net output #1: prob = 0.7089
I0927 02:10:12.083112 19128 solver.cpp:357] Iteration 16500 (1.55078 iter/s, 64.4837s/100 iters), loss = 0.383497
I0927 02:10:12.083170 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.383497 (* 1 = 0.383497 loss)
I0927 02:10:12.083182 19128 sgd_solver.cpp:165] Iteration 16500, lr = 0.1
I0927 02:10:43.867378 19128 solver.cpp:357] Iteration 16600 (3.14621 iter/s, 31.7843s/100 iters), loss = 0.420826
I0927 02:10:43.867533 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.420826 (* 1 = 0.420826 loss)
I0927 02:10:43.867547 19128 sgd_solver.cpp:165] Iteration 16600, lr = 0.1
I0927 02:11:13.821847 19128 solver.cpp:357] Iteration 16700 (3.33828 iter/s, 29.9556s/100 iters), loss = 0.454459
I0927 02:11:13.821926 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.454459 (* 1 = 0.454459 loss)
I0927 02:11:13.821938 19128 sgd_solver.cpp:165] Iteration 16700, lr = 0.1
I0927 02:11:47.024407 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:11:49.891451 19128 solver.cpp:357] Iteration 16800 (2.77247 iter/s, 36.0689s/100 iters), loss = 0.428973
I0927 02:11:49.891526 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.428973 (* 1 = 0.428973 loss)
I0927 02:11:49.891536 19128 sgd_solver.cpp:165] Iteration 16800, lr = 0.1
I0927 02:12:25.936859 19128 solver.cpp:357] Iteration 16900 (2.77434 iter/s, 36.0447s/100 iters), loss = 0.319291
I0927 02:12:25.936990 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.319291 (* 1 = 0.319291 loss)
I0927 02:12:25.937000 19128 sgd_solver.cpp:165] Iteration 16900, lr = 0.1
I0927 02:13:01.627337 19128 solver.cpp:514] Iteration 17000, Testing net (#0)
I0927 02:13:30.240705 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:13:30.345160 19128 solver.cpp:580]     Test net output #0: Softmax1 = 2.1209 (* 1 = 2.1209 loss)
I0927 02:13:30.345197 19128 solver.cpp:580]     Test net output #1: prob = 0.524
I0927 02:13:30.634462 19128 solver.cpp:357] Iteration 17000 (1.54563 iter/s, 64.6985s/100 iters), loss = 0.406314
I0927 02:13:30.634521 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.406314 (* 1 = 0.406314 loss)
I0927 02:13:30.634532 19128 sgd_solver.cpp:165] Iteration 17000, lr = 0.1
I0927 02:14:02.538082 19128 solver.cpp:357] Iteration 17100 (3.13434 iter/s, 31.9047s/100 iters), loss = 0.340123
I0927 02:14:02.538233 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.340123 (* 1 = 0.340123 loss)
I0927 02:14:02.538244 19128 sgd_solver.cpp:165] Iteration 17100, lr = 0.1
I0927 02:14:26.564692 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:14:32.578907 19128 solver.cpp:357] Iteration 17200 (3.3287 iter/s, 30.0417s/100 iters), loss = 0.296172
I0927 02:14:32.579082 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.296172 (* 1 = 0.296172 loss)
I0927 02:14:32.579092 19128 sgd_solver.cpp:165] Iteration 17200, lr = 0.1
I0927 02:15:08.583573 19128 solver.cpp:357] Iteration 17300 (2.77749 iter/s, 36.0037s/100 iters), loss = 0.335283
I0927 02:15:08.583745 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.335283 (* 1 = 0.335283 loss)
I0927 02:15:08.583755 19128 sgd_solver.cpp:165] Iteration 17300, lr = 0.1
I0927 02:15:44.685761 19128 solver.cpp:357] Iteration 17400 (2.76999 iter/s, 36.1012s/100 iters), loss = 0.349093
I0927 02:15:44.685871 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.349093 (* 1 = 0.349093 loss)
I0927 02:15:44.685883 19128 sgd_solver.cpp:165] Iteration 17400, lr = 0.1
I0927 02:16:20.371984 19128 solver.cpp:514] Iteration 17500, Testing net (#0)
I0927 02:16:48.934193 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:16:49.037861 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.06393 (* 1 = 1.06393 loss)
I0927 02:16:49.037889 19128 solver.cpp:580]     Test net output #1: prob = 0.659301
I0927 02:16:49.369165 19128 solver.cpp:357] Iteration 17500 (1.54595 iter/s, 64.685s/100 iters), loss = 0.317561
I0927 02:16:49.369230 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.317561 (* 1 = 0.317561 loss)
I0927 02:16:49.369241 19128 sgd_solver.cpp:165] Iteration 17500, lr = 0.1
I0927 02:17:14.327930 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:17:21.190973 19128 solver.cpp:357] Iteration 17600 (3.14262 iter/s, 31.8206s/100 iters), loss = 0.356059
I0927 02:17:21.191040 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.356059 (* 1 = 0.356059 loss)
I0927 02:17:21.191051 19128 sgd_solver.cpp:165] Iteration 17600, lr = 0.1
I0927 02:17:51.266160 19128 solver.cpp:357] Iteration 17700 (3.32491 iter/s, 30.076s/100 iters), loss = 0.545382
I0927 02:17:51.266324 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.545382 (* 1 = 0.545382 loss)
I0927 02:17:51.266335 19128 sgd_solver.cpp:165] Iteration 17700, lr = 0.1
I0927 02:18:27.143815 19128 solver.cpp:357] Iteration 17800 (2.78722 iter/s, 35.8781s/100 iters), loss = 0.403709
I0927 02:18:27.143970 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.403709 (* 1 = 0.403709 loss)
I0927 02:18:27.143981 19128 sgd_solver.cpp:165] Iteration 17800, lr = 0.1
I0927 02:19:02.928021 19128 solver.cpp:357] Iteration 17900 (2.7945 iter/s, 35.7846s/100 iters), loss = 0.248175
I0927 02:19:02.928172 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.248175 (* 1 = 0.248175 loss)
I0927 02:19:02.928181 19128 sgd_solver.cpp:165] Iteration 17900, lr = 0.1
I0927 02:19:26.023272 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:19:38.552556 19128 solver.cpp:514] Iteration 18000, Testing net (#0)
I0927 02:20:07.058660 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:20:07.188990 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.42762 (* 1 = 1.42762 loss)
I0927 02:20:07.189018 19128 solver.cpp:580]     Test net output #1: prob = 0.5781
I0927 02:20:07.462244 19128 solver.cpp:357] Iteration 18000 (1.54952 iter/s, 64.536s/100 iters), loss = 0.270902
I0927 02:20:07.462316 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.270902 (* 1 = 0.270902 loss)
I0927 02:20:07.462327 19128 sgd_solver.cpp:165] Iteration 18000, lr = 0.1
I0927 02:20:39.357483 19128 solver.cpp:357] Iteration 18100 (3.13539 iter/s, 31.894s/100 iters), loss = 0.384837
I0927 02:20:39.357615 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.384837 (* 1 = 0.384837 loss)
I0927 02:20:39.357626 19128 sgd_solver.cpp:165] Iteration 18100, lr = 0.1
I0927 02:21:09.140987 19128 solver.cpp:357] Iteration 18200 (3.3575 iter/s, 29.7841s/100 iters), loss = 0.401639
I0927 02:21:09.141065 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.401639 (* 1 = 0.401639 loss)
I0927 02:21:09.141075 19128 sgd_solver.cpp:165] Iteration 18200, lr = 0.1
I0927 02:21:45.160415 19128 solver.cpp:357] Iteration 18300 (2.77637 iter/s, 36.0182s/100 iters), loss = 0.265533
I0927 02:21:45.160594 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.265533 (* 1 = 0.265533 loss)
I0927 02:21:45.160605 19128 sgd_solver.cpp:165] Iteration 18300, lr = 0.1
I0927 02:22:05.075839 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:22:21.290835 19128 solver.cpp:357] Iteration 18400 (2.76784 iter/s, 36.1293s/100 iters), loss = 0.489687
I0927 02:22:21.290969 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.489687 (* 1 = 0.489687 loss)
I0927 02:22:21.290979 19128 sgd_solver.cpp:165] Iteration 18400, lr = 0.1
I0927 02:22:57.000434 19128 solver.cpp:514] Iteration 18500, Testing net (#0)
I0927 02:23:25.621385 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:23:25.738662 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.08294 (* 1 = 1.08294 loss)
I0927 02:23:25.738698 19128 solver.cpp:580]     Test net output #1: prob = 0.6557
I0927 02:23:26.017029 19128 solver.cpp:357] Iteration 18500 (1.54493 iter/s, 64.7278s/100 iters), loss = 0.409756
I0927 02:23:26.017088 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.409756 (* 1 = 0.409756 loss)
I0927 02:23:26.017099 19128 sgd_solver.cpp:165] Iteration 18500, lr = 0.1
I0927 02:23:57.984938 19128 solver.cpp:357] Iteration 18600 (3.12821 iter/s, 31.9672s/100 iters), loss = 0.38039
I0927 02:23:57.985049 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.38039 (* 1 = 0.38039 loss)
I0927 02:23:57.985061 19128 sgd_solver.cpp:165] Iteration 18600, lr = 0.1
I0927 02:24:28.000279 19128 solver.cpp:357] Iteration 18700 (3.33156 iter/s, 30.016s/100 iters), loss = 0.355415
I0927 02:24:28.000722 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.355415 (* 1 = 0.355415 loss)
I0927 02:24:28.000733 19128 sgd_solver.cpp:165] Iteration 18700, lr = 0.1
I0927 02:24:44.288383 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:25:03.924295 19128 solver.cpp:357] Iteration 18800 (2.78375 iter/s, 35.9228s/100 iters), loss = 0.307963
I0927 02:25:03.924479 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.307963 (* 1 = 0.307963 loss)
I0927 02:25:03.924490 19128 sgd_solver.cpp:165] Iteration 18800, lr = 0.1
I0927 02:25:39.859963 19128 solver.cpp:357] Iteration 18900 (2.78285 iter/s, 35.9344s/100 iters), loss = 0.391517
I0927 02:25:39.860285 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.391517 (* 1 = 0.391517 loss)
I0927 02:25:39.860296 19128 sgd_solver.cpp:165] Iteration 18900, lr = 0.1
I0927 02:26:15.487130 19128 solver.cpp:514] Iteration 19000, Testing net (#0)
I0927 02:26:44.005304 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:26:44.135303 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.769045 (* 1 = 0.769045 loss)
I0927 02:26:44.135334 19128 solver.cpp:580]     Test net output #1: prob = 0.7465
I0927 02:26:44.410179 19128 solver.cpp:357] Iteration 19000 (1.54919 iter/s, 64.5498s/100 iters), loss = 0.359325
I0927 02:26:44.410246 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.359325 (* 1 = 0.359325 loss)
I0927 02:26:44.410257 19128 sgd_solver.cpp:165] Iteration 19000, lr = 0.1
I0927 02:27:16.401592 19128 solver.cpp:357] Iteration 19100 (3.12596 iter/s, 31.9902s/100 iters), loss = 0.385353
I0927 02:27:16.401804 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.385353 (* 1 = 0.385353 loss)
I0927 02:27:16.401816 19128 sgd_solver.cpp:165] Iteration 19100, lr = 0.1
I0927 02:27:25.922586 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:27:46.294500 19128 solver.cpp:357] Iteration 19200 (3.3452 iter/s, 29.8936s/100 iters), loss = 0.398321
I0927 02:27:46.294577 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.398321 (* 1 = 0.398321 loss)
I0927 02:27:46.294587 19128 sgd_solver.cpp:165] Iteration 19200, lr = 0.1
I0927 02:28:22.315538 19128 solver.cpp:357] Iteration 19300 (2.77624 iter/s, 36.02s/100 iters), loss = 0.418969
I0927 02:28:22.315673 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.418969 (* 1 = 0.418969 loss)
I0927 02:28:22.315685 19128 sgd_solver.cpp:165] Iteration 19300, lr = 0.1
I0927 02:28:58.431918 19128 solver.cpp:357] Iteration 19400 (2.76891 iter/s, 36.1153s/100 iters), loss = 0.425924
I0927 02:28:58.432044 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.425924 (* 1 = 0.425924 loss)
I0927 02:28:58.432054 19128 sgd_solver.cpp:165] Iteration 19400, lr = 0.1
I0927 02:29:34.128132 19128 solver.cpp:514] Iteration 19500, Testing net (#0)
I0927 02:30:02.654469 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:30:02.770331 19128 solver.cpp:580]     Test net output #0: Softmax1 = 2.01034 (* 1 = 2.01034 loss)
I0927 02:30:02.770359 19128 solver.cpp:580]     Test net output #1: prob = 0.5587
I0927 02:30:03.077600 19128 solver.cpp:357] Iteration 19500 (1.5469 iter/s, 64.6454s/100 iters), loss = 0.409736
I0927 02:30:03.077663 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.409736 (* 1 = 0.409736 loss)
I0927 02:30:03.077677 19128 sgd_solver.cpp:165] Iteration 19500, lr = 0.1
I0927 02:30:12.884320 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:30:34.995131 19128 solver.cpp:357] Iteration 19600 (3.1332 iter/s, 31.9163s/100 iters), loss = 0.421858
I0927 02:30:34.995198 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.421858 (* 1 = 0.421858 loss)
I0927 02:30:34.995208 19128 sgd_solver.cpp:165] Iteration 19600, lr = 0.1
I0927 02:31:05.109306 19128 solver.cpp:357] Iteration 19700 (3.32061 iter/s, 30.1149s/100 iters), loss = 0.418436
I0927 02:31:05.109432 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.418436 (* 1 = 0.418436 loss)
I0927 02:31:05.109442 19128 sgd_solver.cpp:165] Iteration 19700, lr = 0.1
I0927 02:31:41.136377 19128 solver.cpp:357] Iteration 19800 (2.77565 iter/s, 36.0275s/100 iters), loss = 0.413037
I0927 02:31:41.136536 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.413037 (* 1 = 0.413037 loss)
I0927 02:31:41.136548 19128 sgd_solver.cpp:165] Iteration 19800, lr = 0.1
I0927 02:32:17.202719 19128 solver.cpp:357] Iteration 19900 (2.77276 iter/s, 36.0651s/100 iters), loss = 0.45447
I0927 02:32:17.202836 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.45447 (* 1 = 0.45447 loss)
I0927 02:32:17.202847 19128 sgd_solver.cpp:165] Iteration 19900, lr = 0.1
I0927 02:32:23.359441 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:32:52.918529 19128 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_20000.caffemodel
I0927 02:32:52.953524 19128 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_20000.solverstate
I0927 02:32:52.958807 19128 solver.cpp:514] Iteration 20000, Testing net (#0)
I0927 02:33:21.653983 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:33:21.767624 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.46425 (* 1 = 1.46425 loss)
I0927 02:33:21.767652 19128 solver.cpp:580]     Test net output #1: prob = 0.5835
I0927 02:33:22.094787 19128 solver.cpp:357] Iteration 20000 (1.54098 iter/s, 64.8937s/100 iters), loss = 0.418124
I0927 02:33:22.094858 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.418124 (* 1 = 0.418124 loss)
I0927 02:33:22.094871 19128 sgd_solver.cpp:165] Iteration 20000, lr = 0.1
I0927 02:33:53.852783 19128 solver.cpp:357] Iteration 20100 (3.14894 iter/s, 31.7567s/100 iters), loss = 0.33527
I0927 02:33:53.852958 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.33527 (* 1 = 0.33527 loss)
I0927 02:33:53.852970 19128 sgd_solver.cpp:165] Iteration 20100, lr = 0.1
I0927 02:34:23.992035 19128 solver.cpp:357] Iteration 20200 (3.31787 iter/s, 30.1399s/100 iters), loss = 0.360562
I0927 02:34:23.992214 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.360562 (* 1 = 0.360562 loss)
I0927 02:34:23.992226 19128 sgd_solver.cpp:165] Iteration 20200, lr = 0.1
I0927 02:35:00.131300 19128 solver.cpp:357] Iteration 20300 (2.76717 iter/s, 36.138s/100 iters), loss = 0.345956
I0927 02:35:00.131425 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.345956 (* 1 = 0.345956 loss)
I0927 02:35:00.131436 19128 sgd_solver.cpp:165] Iteration 20300, lr = 0.1
I0927 02:35:03.031096 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:35:36.152645 19128 solver.cpp:357] Iteration 20400 (2.77607 iter/s, 36.0221s/100 iters), loss = 0.423476
I0927 02:35:36.152815 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.423476 (* 1 = 0.423476 loss)
I0927 02:35:36.152827 19128 sgd_solver.cpp:165] Iteration 20400, lr = 0.1
I0927 02:36:11.853999 19128 solver.cpp:514] Iteration 20500, Testing net (#0)
I0927 02:36:40.294298 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:36:40.377434 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.798037 (* 1 = 0.798037 loss)
I0927 02:36:40.377471 19128 solver.cpp:580]     Test net output #1: prob = 0.7476
I0927 02:36:40.687119 19128 solver.cpp:357] Iteration 20500 (1.54957 iter/s, 64.534s/100 iters), loss = 0.276006
I0927 02:36:40.687172 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.276006 (* 1 = 0.276006 loss)
I0927 02:36:40.687181 19128 sgd_solver.cpp:165] Iteration 20500, lr = 0.1
I0927 02:37:12.575338 19128 solver.cpp:357] Iteration 20600 (3.13588 iter/s, 31.889s/100 iters), loss = 0.362899
I0927 02:37:12.575466 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.362899 (* 1 = 0.362899 loss)
I0927 02:37:12.575477 19128 sgd_solver.cpp:165] Iteration 20600, lr = 0.1
I0927 02:37:42.308681 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:37:42.659381 19128 solver.cpp:357] Iteration 20700 (3.32395 iter/s, 30.0847s/100 iters), loss = 0.369761
I0927 02:37:42.659531 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.369761 (* 1 = 0.369761 loss)
I0927 02:37:42.659541 19128 sgd_solver.cpp:165] Iteration 20700, lr = 0.1
I0927 02:38:18.709318 19128 solver.cpp:357] Iteration 20800 (2.77392 iter/s, 36.0501s/100 iters), loss = 0.399202
I0927 02:38:18.709434 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.399202 (* 1 = 0.399202 loss)
I0927 02:38:18.709444 19128 sgd_solver.cpp:165] Iteration 20800, lr = 0.1
I0927 02:38:54.748219 19128 solver.cpp:357] Iteration 20900 (2.77472 iter/s, 36.0397s/100 iters), loss = 0.473408
I0927 02:38:54.748347 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.473408 (* 1 = 0.473408 loss)
I0927 02:38:54.748356 19128 sgd_solver.cpp:165] Iteration 20900, lr = 0.1
I0927 02:39:30.426059 19128 solver.cpp:514] Iteration 21000, Testing net (#0)
I0927 02:39:58.781452 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:39:58.921545 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.08507 (* 1 = 1.08507 loss)
I0927 02:39:58.921574 19128 solver.cpp:580]     Test net output #1: prob = 0.6781
I0927 02:39:59.183004 19128 solver.cpp:357] Iteration 21000 (1.55192 iter/s, 64.4362s/100 iters), loss = 0.330571
I0927 02:39:59.183068 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.330571 (* 1 = 0.330571 loss)
I0927 02:39:59.183081 19128 sgd_solver.cpp:165] Iteration 21000, lr = 0.1
I0927 02:40:28.199776 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:40:31.121917 19128 solver.cpp:357] Iteration 21100 (3.13111 iter/s, 31.9375s/100 iters), loss = 0.403503
I0927 02:40:31.121980 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.403503 (* 1 = 0.403503 loss)
I0927 02:40:31.121995 19128 sgd_solver.cpp:165] Iteration 21100, lr = 0.1
I0927 02:41:00.771921 19128 solver.cpp:357] Iteration 21200 (3.37261 iter/s, 29.6506s/100 iters), loss = 0.415197
I0927 02:41:00.772051 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.415197 (* 1 = 0.415197 loss)
I0927 02:41:00.772063 19128 sgd_solver.cpp:165] Iteration 21200, lr = 0.1
I0927 02:41:36.910768 19128 solver.cpp:357] Iteration 21300 (2.7672 iter/s, 36.1375s/100 iters), loss = 0.354232
I0927 02:41:36.910923 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.354232 (* 1 = 0.354232 loss)
I0927 02:41:36.910933 19128 sgd_solver.cpp:165] Iteration 21300, lr = 0.1
I0927 02:42:12.962298 19128 solver.cpp:357] Iteration 21400 (2.77386 iter/s, 36.0508s/100 iters), loss = 0.568497
I0927 02:42:12.962467 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.568497 (* 1 = 0.568497 loss)
I0927 02:42:12.962478 19128 sgd_solver.cpp:165] Iteration 21400, lr = 0.1
I0927 02:42:41.815485 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:42:48.658020 19128 solver.cpp:514] Iteration 21500, Testing net (#0)
I0927 02:43:17.376211 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:43:17.514225 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.761264 (* 1 = 0.761264 loss)
I0927 02:43:17.514251 19128 solver.cpp:580]     Test net output #1: prob = 0.7403
I0927 02:43:17.785617 19128 solver.cpp:357] Iteration 21500 (1.54265 iter/s, 64.8237s/100 iters), loss = 0.25312
I0927 02:43:17.785677 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.25312 (* 1 = 0.25312 loss)
I0927 02:43:17.785691 19128 sgd_solver.cpp:165] Iteration 21500, lr = 0.1
I0927 02:43:49.885530 19128 solver.cpp:357] Iteration 21600 (3.11541 iter/s, 32.0985s/100 iters), loss = 0.391948
I0927 02:43:49.885684 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.391948 (* 1 = 0.391948 loss)
I0927 02:43:49.885696 19128 sgd_solver.cpp:165] Iteration 21600, lr = 0.1
I0927 02:44:19.538738 19128 solver.cpp:357] Iteration 21700 (3.37248 iter/s, 29.6518s/100 iters), loss = 0.352746
I0927 02:44:19.538807 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.352746 (* 1 = 0.352746 loss)
I0927 02:44:19.538831 19128 sgd_solver.cpp:165] Iteration 21700, lr = 0.1
I0927 02:44:55.656330 19128 solver.cpp:357] Iteration 21800 (2.76884 iter/s, 36.1163s/100 iters), loss = 0.334778
I0927 02:44:55.656443 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.334778 (* 1 = 0.334778 loss)
I0927 02:44:55.656455 19128 sgd_solver.cpp:165] Iteration 21800, lr = 0.1
I0927 02:45:20.940455 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:45:31.734002 19128 solver.cpp:357] Iteration 21900 (2.77174 iter/s, 36.0784s/100 iters), loss = 0.511752
I0927 02:45:31.734172 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.511752 (* 1 = 0.511752 loss)
I0927 02:45:31.734184 19128 sgd_solver.cpp:165] Iteration 21900, lr = 0.1
I0927 02:46:07.421093 19128 solver.cpp:514] Iteration 22000, Testing net (#0)
I0927 02:46:36.083767 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:46:36.217341 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.05864 (* 1 = 1.05864 loss)
I0927 02:46:36.217371 19128 solver.cpp:580]     Test net output #1: prob = 0.6506
I0927 02:46:36.491236 19128 solver.cpp:357] Iteration 22000 (1.54422 iter/s, 64.7578s/100 iters), loss = 0.329558
I0927 02:46:36.491305 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.329558 (* 1 = 0.329558 loss)
I0927 02:46:36.491317 19128 sgd_solver.cpp:165] Iteration 22000, lr = 0.1
I0927 02:47:08.574571 19128 solver.cpp:357] Iteration 22100 (3.11686 iter/s, 32.0836s/100 iters), loss = 0.408229
I0927 02:47:08.574775 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.408229 (* 1 = 0.408229 loss)
I0927 02:47:08.574787 19128 sgd_solver.cpp:165] Iteration 22100, lr = 0.1
I0927 02:47:38.394465 19128 solver.cpp:357] Iteration 22200 (3.35341 iter/s, 29.8204s/100 iters), loss = 0.398313
I0927 02:47:38.394536 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.398313 (* 1 = 0.398313 loss)
I0927 02:47:38.394546 19128 sgd_solver.cpp:165] Iteration 22200, lr = 0.1
I0927 02:48:00.317658 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:48:14.360406 19128 solver.cpp:357] Iteration 22300 (2.78051 iter/s, 35.9646s/100 iters), loss = 0.397223
I0927 02:48:14.360472 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.397223 (* 1 = 0.397223 loss)
I0927 02:48:14.360483 19128 sgd_solver.cpp:165] Iteration 22300, lr = 0.1
I0927 02:48:50.402454 19128 solver.cpp:357] Iteration 22400 (2.77448 iter/s, 36.0428s/100 iters), loss = 0.277445
I0927 02:48:50.402565 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.277445 (* 1 = 0.277445 loss)
I0927 02:48:50.402575 19128 sgd_solver.cpp:165] Iteration 22400, lr = 0.1
I0927 02:49:26.090458 19128 solver.cpp:514] Iteration 22500, Testing net (#0)
I0927 02:49:54.730510 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:49:54.794843 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.856557 (* 1 = 0.856557 loss)
I0927 02:49:54.794878 19128 solver.cpp:580]     Test net output #1: prob = 0.7011
I0927 02:49:55.125134 19128 solver.cpp:357] Iteration 22500 (1.54502 iter/s, 64.7241s/100 iters), loss = 0.437789
I0927 02:49:55.125190 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.437789 (* 1 = 0.437789 loss)
I0927 02:49:55.125201 19128 sgd_solver.cpp:165] Iteration 22500, lr = 0.1
I0927 02:50:27.234983 19128 solver.cpp:357] Iteration 22600 (3.11424 iter/s, 32.1105s/100 iters), loss = 0.483888
I0927 02:50:27.235095 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.483888 (* 1 = 0.483888 loss)
I0927 02:50:27.235106 19128 sgd_solver.cpp:165] Iteration 22600, lr = 0.1
I0927 02:50:41.099229 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:50:56.875264 19128 solver.cpp:357] Iteration 22700 (3.37372 iter/s, 29.6408s/100 iters), loss = 0.424374
I0927 02:50:56.875344 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.424374 (* 1 = 0.424374 loss)
I0927 02:50:56.875355 19128 sgd_solver.cpp:165] Iteration 22700, lr = 0.1
I0927 02:51:32.797628 19128 solver.cpp:357] Iteration 22800 (2.78389 iter/s, 35.921s/100 iters), loss = 0.330248
I0927 02:51:32.797781 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.330248 (* 1 = 0.330248 loss)
I0927 02:51:32.797792 19128 sgd_solver.cpp:165] Iteration 22800, lr = 0.1
I0927 02:52:08.760208 19128 solver.cpp:357] Iteration 22900 (2.78077 iter/s, 35.9612s/100 iters), loss = 0.422874
I0927 02:52:08.760386 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.422874 (* 1 = 0.422874 loss)
I0927 02:52:08.760398 19128 sgd_solver.cpp:165] Iteration 22900, lr = 0.1
I0927 02:52:44.397107 19128 solver.cpp:514] Iteration 23000, Testing net (#0)
I0927 02:53:13.110309 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:53:13.248330 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.20474 (* 1 = 1.20474 loss)
I0927 02:53:13.248359 19128 solver.cpp:580]     Test net output #1: prob = 0.6284
I0927 02:53:13.511831 19128 solver.cpp:357] Iteration 23000 (1.54438 iter/s, 64.751s/100 iters), loss = 0.411392
I0927 02:53:13.511899 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.411392 (* 1 = 0.411392 loss)
I0927 02:53:13.511910 19128 sgd_solver.cpp:165] Iteration 23000, lr = 0.1
I0927 02:53:28.702090 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:53:45.555518 19128 solver.cpp:357] Iteration 23100 (3.12088 iter/s, 32.0423s/100 iters), loss = 0.53934
I0927 02:53:45.555588 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.53934 (* 1 = 0.53934 loss)
I0927 02:53:45.555599 19128 sgd_solver.cpp:165] Iteration 23100, lr = 0.1
I0927 02:54:15.367666 19128 solver.cpp:357] Iteration 23200 (3.35433 iter/s, 29.8122s/100 iters), loss = 0.39347
I0927 02:54:15.367823 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.39347 (* 1 = 0.39347 loss)
I0927 02:54:15.367835 19128 sgd_solver.cpp:165] Iteration 23200, lr = 0.1
I0927 02:54:51.413398 19128 solver.cpp:357] Iteration 23300 (2.7742 iter/s, 36.0464s/100 iters), loss = 0.274654
I0927 02:54:51.413528 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.274654 (* 1 = 0.274654 loss)
I0927 02:54:51.413539 19128 sgd_solver.cpp:165] Iteration 23300, lr = 0.1
I0927 02:55:27.458554 19128 solver.cpp:357] Iteration 23400 (2.77438 iter/s, 36.0441s/100 iters), loss = 0.428762
I0927 02:55:27.458700 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.428762 (* 1 = 0.428762 loss)
I0927 02:55:27.458711 19128 sgd_solver.cpp:165] Iteration 23400, lr = 0.1
I0927 02:55:39.360834 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:56:03.150851 19128 solver.cpp:514] Iteration 23500, Testing net (#0)
I0927 02:56:31.717228 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:56:31.854952 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.830332 (* 1 = 0.830332 loss)
I0927 02:56:31.854986 19128 solver.cpp:580]     Test net output #1: prob = 0.7232
I0927 02:56:32.167990 19128 solver.cpp:357] Iteration 23500 (1.54534 iter/s, 64.7108s/100 iters), loss = 0.256301
I0927 02:56:32.168042 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.256301 (* 1 = 0.256301 loss)
I0927 02:56:32.168054 19128 sgd_solver.cpp:165] Iteration 23500, lr = 0.1
I0927 02:57:04.289373 19128 solver.cpp:357] Iteration 23600 (3.11313 iter/s, 32.1221s/100 iters), loss = 0.463338
I0927 02:57:04.289480 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.463338 (* 1 = 0.463338 loss)
I0927 02:57:04.289491 19128 sgd_solver.cpp:165] Iteration 23600, lr = 0.1
I0927 02:57:34.059238 19128 solver.cpp:357] Iteration 23700 (3.35904 iter/s, 29.7704s/100 iters), loss = 0.362392
I0927 02:57:34.059314 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.362392 (* 1 = 0.362392 loss)
I0927 02:57:34.059324 19128 sgd_solver.cpp:165] Iteration 23700, lr = 0.1
I0927 02:58:09.944278 19128 solver.cpp:357] Iteration 23800 (2.78678 iter/s, 35.8837s/100 iters), loss = 0.505003
I0927 02:58:09.944440 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.505003 (* 1 = 0.505003 loss)
I0927 02:58:09.944453 19128 sgd_solver.cpp:165] Iteration 23800, lr = 0.1
I0927 02:58:18.651000 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:58:45.858422 19128 solver.cpp:357] Iteration 23900 (2.78452 iter/s, 35.9128s/100 iters), loss = 0.390083
I0927 02:58:45.858530 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.390083 (* 1 = 0.390083 loss)
I0927 02:58:45.858539 19128 sgd_solver.cpp:165] Iteration 23900, lr = 0.1
I0927 02:59:21.389475 19128 solver.cpp:514] Iteration 24000, Testing net (#0)
I0927 02:59:50.034065 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 02:59:50.137063 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.22759 (* 1 = 1.22759 loss)
I0927 02:59:50.137090 19128 solver.cpp:580]     Test net output #1: prob = 0.623001
I0927 02:59:50.459708 19128 solver.cpp:357] Iteration 24000 (1.54797 iter/s, 64.6006s/100 iters), loss = 0.38948
I0927 02:59:50.459770 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.389481 (* 1 = 0.389481 loss)
I0927 02:59:50.459784 19128 sgd_solver.cpp:165] Iteration 24000, lr = 0.1
I0927 03:00:22.485064 19128 solver.cpp:357] Iteration 24100 (3.12267 iter/s, 32.0239s/100 iters), loss = 0.382071
I0927 03:00:22.485205 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.382071 (* 1 = 0.382071 loss)
I0927 03:00:22.485218 19128 sgd_solver.cpp:165] Iteration 24100, lr = 0.1
I0927 03:00:52.142024 19128 solver.cpp:357] Iteration 24200 (3.37183 iter/s, 29.6574s/100 iters), loss = 0.378475
I0927 03:00:52.142099 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.378475 (* 1 = 0.378475 loss)
I0927 03:00:52.142109 19128 sgd_solver.cpp:165] Iteration 24200, lr = 0.1
I0927 03:00:57.244073 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:01:28.068202 19128 solver.cpp:357] Iteration 24300 (2.78359 iter/s, 35.9248s/100 iters), loss = 0.555496
I0927 03:01:28.068317 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.555496 (* 1 = 0.555496 loss)
I0927 03:01:28.068328 19128 sgd_solver.cpp:165] Iteration 24300, lr = 0.1
I0927 03:02:03.965962 19128 solver.cpp:357] Iteration 24400 (2.7858 iter/s, 35.8964s/100 iters), loss = 0.392636
I0927 03:02:03.966118 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.392636 (* 1 = 0.392636 loss)
I0927 03:02:03.966128 19128 sgd_solver.cpp:165] Iteration 24400, lr = 0.1
I0927 03:02:39.771523 19128 solver.cpp:514] Iteration 24500, Testing net (#0)
I0927 03:03:08.109570 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:03:08.232642 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.966941 (* 1 = 0.966941 loss)
I0927 03:03:08.232674 19128 solver.cpp:580]     Test net output #1: prob = 0.6804
I0927 03:03:08.522789 19128 solver.cpp:357] Iteration 24500 (1.54904 iter/s, 64.5561s/100 iters), loss = 0.28957
I0927 03:03:08.522855 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.28957 (* 1 = 0.28957 loss)
I0927 03:03:08.522867 19128 sgd_solver.cpp:165] Iteration 24500, lr = 0.1
I0927 03:03:40.797996 19128 solver.cpp:357] Iteration 24600 (3.09849 iter/s, 32.2737s/100 iters), loss = 0.391345
I0927 03:03:40.798144 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.391345 (* 1 = 0.391345 loss)
I0927 03:03:40.798156 19128 sgd_solver.cpp:165] Iteration 24600, lr = 0.1
I0927 03:03:42.175638 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:04:10.447827 19128 solver.cpp:357] Iteration 24700 (3.37265 iter/s, 29.6503s/100 iters), loss = 0.372678
I0927 03:04:10.447896 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.372678 (* 1 = 0.372678 loss)
I0927 03:04:10.447907 19128 sgd_solver.cpp:165] Iteration 24700, lr = 0.1
I0927 03:04:46.512950 19128 solver.cpp:357] Iteration 24800 (2.77272 iter/s, 36.0656s/100 iters), loss = 0.318342
I0927 03:04:46.513103 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.318342 (* 1 = 0.318342 loss)
I0927 03:04:46.513113 19128 sgd_solver.cpp:165] Iteration 24800, lr = 0.1
I0927 03:05:22.585569 19128 solver.cpp:357] Iteration 24900 (2.77214 iter/s, 36.0732s/100 iters), loss = 0.492137
I0927 03:05:22.585680 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.492137 (* 1 = 0.492137 loss)
I0927 03:05:22.585691 19128 sgd_solver.cpp:165] Iteration 24900, lr = 0.1
I0927 03:05:56.867704 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:05:58.298686 19128 solver.cpp:514] Iteration 25000, Testing net (#0)
I0927 03:06:26.765688 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:06:26.896472 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.658854 (* 1 = 0.658854 loss)
I0927 03:06:26.896539 19128 solver.cpp:580]     Test net output #1: prob = 0.7869
I0927 03:06:27.170478 19128 solver.cpp:357] Iteration 25000 (1.54832 iter/s, 64.586s/100 iters), loss = 0.335191
I0927 03:06:27.170545 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.335192 (* 1 = 0.335192 loss)
I0927 03:06:27.170557 19128 sgd_solver.cpp:165] Iteration 25000, lr = 0.1
I0927 03:06:59.528374 19128 solver.cpp:357] Iteration 25100 (3.09058 iter/s, 32.3564s/100 iters), loss = 0.460742
I0927 03:06:59.528508 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.460742 (* 1 = 0.460742 loss)
I0927 03:06:59.528522 19128 sgd_solver.cpp:165] Iteration 25100, lr = 0.1
I0927 03:07:29.019070 19128 solver.cpp:357] Iteration 25200 (3.39084 iter/s, 29.4912s/100 iters), loss = 0.514375
I0927 03:07:29.019148 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.514375 (* 1 = 0.514375 loss)
I0927 03:07:29.019160 19128 sgd_solver.cpp:165] Iteration 25200, lr = 0.1
I0927 03:08:04.964186 19128 solver.cpp:357] Iteration 25300 (2.78213 iter/s, 35.9437s/100 iters), loss = 0.390692
I0927 03:08:04.964380 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.390692 (* 1 = 0.390692 loss)
I0927 03:08:04.964390 19128 sgd_solver.cpp:165] Iteration 25300, lr = 0.1
I0927 03:08:36.037787 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:08:41.077914 19128 solver.cpp:357] Iteration 25400 (2.76913 iter/s, 36.1124s/100 iters), loss = 0.421502
I0927 03:08:41.077980 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.421502 (* 1 = 0.421502 loss)
I0927 03:08:41.077991 19128 sgd_solver.cpp:165] Iteration 25400, lr = 0.1
I0927 03:09:16.782856 19128 solver.cpp:514] Iteration 25500, Testing net (#0)
I0927 03:09:45.071525 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:09:45.215620 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.01159 (* 1 = 1.01159 loss)
I0927 03:09:45.215649 19128 solver.cpp:580]     Test net output #1: prob = 0.694
I0927 03:09:45.500380 19128 solver.cpp:357] Iteration 25500 (1.55224 iter/s, 64.423s/100 iters), loss = 0.416919
I0927 03:09:45.500447 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.416919 (* 1 = 0.416919 loss)
I0927 03:09:45.500459 19128 sgd_solver.cpp:165] Iteration 25500, lr = 0.1
I0927 03:10:18.054731 19128 solver.cpp:357] Iteration 25600 (3.07192 iter/s, 32.5529s/100 iters), loss = 0.389374
I0927 03:10:18.054847 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.389374 (* 1 = 0.389374 loss)
I0927 03:10:18.054858 19128 sgd_solver.cpp:165] Iteration 25600, lr = 0.1
I0927 03:10:47.361374 19128 solver.cpp:357] Iteration 25700 (3.41214 iter/s, 29.3072s/100 iters), loss = 0.437046
I0927 03:10:47.361440 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.437046 (* 1 = 0.437046 loss)
I0927 03:10:47.361449 19128 sgd_solver.cpp:165] Iteration 25700, lr = 0.1
I0927 03:11:15.142079 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:11:23.425932 19128 solver.cpp:357] Iteration 25800 (2.77275 iter/s, 36.0653s/100 iters), loss = 0.429918
I0927 03:11:23.426000 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.429918 (* 1 = 0.429918 loss)
I0927 03:11:23.426012 19128 sgd_solver.cpp:165] Iteration 25800, lr = 0.1
I0927 03:11:59.475059 19128 solver.cpp:357] Iteration 25900 (2.77394 iter/s, 36.0498s/100 iters), loss = 0.368763
I0927 03:11:59.475203 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.368763 (* 1 = 0.368763 loss)
I0927 03:11:59.475214 19128 sgd_solver.cpp:165] Iteration 25900, lr = 0.1
I0927 03:12:35.178398 19128 solver.cpp:514] Iteration 26000, Testing net (#0)
I0927 03:13:03.716617 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:13:03.817886 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.12446 (* 1 = 1.12446 loss)
I0927 03:13:03.817922 19128 solver.cpp:580]     Test net output #1: prob = 0.673701
I0927 03:13:04.138527 19128 solver.cpp:357] Iteration 26000 (1.54644 iter/s, 64.6648s/100 iters), loss = 0.285031
I0927 03:13:04.138581 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.285031 (* 1 = 0.285031 loss)
I0927 03:13:04.138590 19128 sgd_solver.cpp:165] Iteration 26000, lr = 0.1
I0927 03:13:36.609612 19128 solver.cpp:357] Iteration 26100 (3.0796 iter/s, 32.4717s/100 iters), loss = 0.331152
I0927 03:13:36.609724 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.331152 (* 1 = 0.331152 loss)
I0927 03:13:36.609735 19128 sgd_solver.cpp:165] Iteration 26100, lr = 0.1
I0927 03:13:54.372287 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:14:05.806578 19128 solver.cpp:357] Iteration 26200 (3.42495 iter/s, 29.1975s/100 iters), loss = 0.441571
I0927 03:14:05.806644 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.441571 (* 1 = 0.441571 loss)
I0927 03:14:05.806654 19128 sgd_solver.cpp:165] Iteration 26200, lr = 0.1
I0927 03:14:41.830796 19128 solver.cpp:357] Iteration 26300 (2.77586 iter/s, 36.0249s/100 iters), loss = 0.29514
I0927 03:14:41.830997 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.29514 (* 1 = 0.29514 loss)
I0927 03:14:41.831009 19128 sgd_solver.cpp:165] Iteration 26300, lr = 0.1
I0927 03:15:17.895992 19128 solver.cpp:357] Iteration 26400 (2.77271 iter/s, 36.0658s/100 iters), loss = 0.298535
I0927 03:15:17.896103 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.298535 (* 1 = 0.298535 loss)
I0927 03:15:17.896114 19128 sgd_solver.cpp:165] Iteration 26400, lr = 0.1
I0927 03:15:53.584544 19128 solver.cpp:514] Iteration 26500, Testing net (#0)
I0927 03:16:22.187656 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:16:22.252194 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.03641 (* 1 = 1.03641 loss)
I0927 03:16:22.252233 19128 solver.cpp:580]     Test net output #1: prob = 0.6629
I0927 03:16:22.581620 19128 solver.cpp:357] Iteration 26500 (1.54591 iter/s, 64.687s/100 iters), loss = 0.288827
I0927 03:16:22.581677 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.288827 (* 1 = 0.288827 loss)
I0927 03:16:22.581689 19128 sgd_solver.cpp:165] Iteration 26500, lr = 0.1
I0927 03:16:43.512984 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:16:55.306638 19128 solver.cpp:357] Iteration 26600 (3.0557 iter/s, 32.7257s/100 iters), loss = 0.321873
I0927 03:16:55.306711 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.321873 (* 1 = 0.321873 loss)
I0927 03:16:55.306723 19128 sgd_solver.cpp:165] Iteration 26600, lr = 0.1
I0927 03:17:24.786348 19128 solver.cpp:357] Iteration 26700 (3.39234 iter/s, 29.4782s/100 iters), loss = 0.513597
I0927 03:17:24.786475 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.513597 (* 1 = 0.513597 loss)
I0927 03:17:24.786486 19128 sgd_solver.cpp:165] Iteration 26700, lr = 0.1
I0927 03:18:00.830232 19128 solver.cpp:357] Iteration 26800 (2.77434 iter/s, 36.0446s/100 iters), loss = 0.402421
I0927 03:18:00.830404 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.402421 (* 1 = 0.402421 loss)
I0927 03:18:00.830416 19128 sgd_solver.cpp:165] Iteration 26800, lr = 0.1
I0927 03:18:36.892871 19128 solver.cpp:357] Iteration 26900 (2.77301 iter/s, 36.0619s/100 iters), loss = 0.336032
I0927 03:18:36.893023 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.336032 (* 1 = 0.336032 loss)
I0927 03:18:36.893033 19128 sgd_solver.cpp:165] Iteration 26900, lr = 0.1
I0927 03:18:54.571735 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:19:12.594120 19128 solver.cpp:514] Iteration 27000, Testing net (#0)
I0927 03:19:41.039862 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:19:41.137938 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.5188 (* 1 = 1.5188 loss)
I0927 03:19:41.137974 19128 solver.cpp:580]     Test net output #1: prob = 0.5865
I0927 03:19:41.433020 19128 solver.cpp:357] Iteration 27000 (1.54939 iter/s, 64.5415s/100 iters), loss = 0.424507
I0927 03:19:41.433081 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.424507 (* 1 = 0.424507 loss)
I0927 03:19:41.433092 19128 sgd_solver.cpp:165] Iteration 27000, lr = 0.1
I0927 03:20:14.268887 19128 solver.cpp:357] Iteration 27100 (3.04539 iter/s, 32.8365s/100 iters), loss = 0.409054
I0927 03:20:14.269009 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.409054 (* 1 = 0.409054 loss)
I0927 03:20:14.269021 19128 sgd_solver.cpp:165] Iteration 27100, lr = 0.1
I0927 03:20:43.791739 19128 solver.cpp:357] Iteration 27200 (3.38716 iter/s, 29.5233s/100 iters), loss = 0.381683
I0927 03:20:43.791807 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.381683 (* 1 = 0.381683 loss)
I0927 03:20:43.791817 19128 sgd_solver.cpp:165] Iteration 27200, lr = 0.1
I0927 03:21:19.849706 19128 solver.cpp:357] Iteration 27300 (2.77326 iter/s, 36.0587s/100 iters), loss = 0.295348
I0927 03:21:19.849926 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.295348 (* 1 = 0.295348 loss)
I0927 03:21:19.849938 19128 sgd_solver.cpp:165] Iteration 27300, lr = 0.1
I0927 03:21:33.925470 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:21:55.899379 19128 solver.cpp:357] Iteration 27400 (2.77399 iter/s, 36.0491s/100 iters), loss = 0.351707
I0927 03:21:55.899586 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.351707 (* 1 = 0.351707 loss)
I0927 03:21:55.899617 19128 sgd_solver.cpp:165] Iteration 27400, lr = 0.1
I0927 03:22:31.585536 19128 solver.cpp:514] Iteration 27500, Testing net (#0)
I0927 03:23:00.216728 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:23:00.306211 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.08947 (* 1 = 1.08947 loss)
I0927 03:23:00.306248 19128 solver.cpp:580]     Test net output #1: prob = 0.6653
I0927 03:23:00.610011 19128 solver.cpp:357] Iteration 27500 (1.54535 iter/s, 64.7104s/100 iters), loss = 0.369893
I0927 03:23:00.610065 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.369893 (* 1 = 0.369893 loss)
I0927 03:23:00.610077 19128 sgd_solver.cpp:165] Iteration 27500, lr = 0.1
I0927 03:23:32.961623 19128 solver.cpp:357] Iteration 27600 (3.09097 iter/s, 32.3523s/100 iters), loss = 0.392894
I0927 03:23:32.961771 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.392894 (* 1 = 0.392894 loss)
I0927 03:23:32.961782 19128 sgd_solver.cpp:165] Iteration 27600, lr = 0.1
I0927 03:24:02.172369 19128 solver.cpp:357] Iteration 27700 (3.42334 iter/s, 29.2112s/100 iters), loss = 0.659852
I0927 03:24:02.172439 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.659852 (* 1 = 0.659852 loss)
I0927 03:24:02.172451 19128 sgd_solver.cpp:165] Iteration 27700, lr = 0.1
I0927 03:24:12.982336 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:24:37.997750 19128 solver.cpp:357] Iteration 27800 (2.79142 iter/s, 35.824s/100 iters), loss = 0.405218
I0927 03:24:37.997822 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.405218 (* 1 = 0.405218 loss)
I0927 03:24:37.997833 19128 sgd_solver.cpp:165] Iteration 27800, lr = 0.1
I0927 03:25:13.918591 19128 solver.cpp:357] Iteration 27900 (2.784 iter/s, 35.9195s/100 iters), loss = 0.545332
I0927 03:25:13.918758 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.545332 (* 1 = 0.545332 loss)
I0927 03:25:13.918771 19128 sgd_solver.cpp:165] Iteration 27900, lr = 0.1
I0927 03:25:49.529243 19128 solver.cpp:514] Iteration 28000, Testing net (#0)
I0927 03:26:18.197109 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:26:18.249070 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.39212 (* 1 = 1.39212 loss)
I0927 03:26:18.249099 19128 solver.cpp:580]     Test net output #1: prob = 0.574701
I0927 03:26:18.598438 19128 solver.cpp:357] Iteration 28000 (1.54609 iter/s, 64.6791s/100 iters), loss = 0.409739
I0927 03:26:18.598498 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.409739 (* 1 = 0.409739 loss)
I0927 03:26:18.598510 19128 sgd_solver.cpp:165] Iteration 28000, lr = 0.1
I0927 03:26:51.280973 19128 solver.cpp:357] Iteration 28100 (3.05987 iter/s, 32.6811s/100 iters), loss = 0.33066
I0927 03:26:51.281097 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.33066 (* 1 = 0.33066 loss)
I0927 03:26:51.281110 19128 sgd_solver.cpp:165] Iteration 28100, lr = 0.1
I0927 03:26:56.640374 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:27:20.785974 19128 solver.cpp:357] Iteration 28200 (3.38943 iter/s, 29.5035s/100 iters), loss = 0.493353
I0927 03:27:20.786044 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.493353 (* 1 = 0.493353 loss)
I0927 03:27:20.786056 19128 sgd_solver.cpp:165] Iteration 28200, lr = 0.1
I0927 03:27:56.834209 19128 solver.cpp:357] Iteration 28300 (2.77405 iter/s, 36.0483s/100 iters), loss = 0.456692
I0927 03:27:56.834364 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.456692 (* 1 = 0.456692 loss)
I0927 03:27:56.834375 19128 sgd_solver.cpp:165] Iteration 28300, lr = 0.1
I0927 03:28:32.893085 19128 solver.cpp:357] Iteration 28400 (2.77319 iter/s, 36.0595s/100 iters), loss = 0.346951
I0927 03:28:32.893254 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.346951 (* 1 = 0.346951 loss)
I0927 03:28:32.893265 19128 sgd_solver.cpp:165] Iteration 28400, lr = 0.1
I0927 03:29:08.598037 19128 solver.cpp:514] Iteration 28500, Testing net (#0)
I0927 03:29:37.079316 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:29:37.217669 19128 solver.cpp:580]     Test net output #0: Softmax1 = 2.14236 (* 1 = 2.14236 loss)
I0927 03:29:37.217698 19128 solver.cpp:580]     Test net output #1: prob = 0.4892
I0927 03:29:37.477283 19128 solver.cpp:357] Iteration 28500 (1.54834 iter/s, 64.5852s/100 iters), loss = 0.332316
I0927 03:29:37.477349 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.332316 (* 1 = 0.332316 loss)
I0927 03:29:37.477362 19128 sgd_solver.cpp:165] Iteration 28500, lr = 0.1
I0927 03:29:41.550582 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:30:10.007966 19128 solver.cpp:357] Iteration 28600 (3.07415 iter/s, 32.5293s/100 iters), loss = 0.311345
I0927 03:30:10.008033 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.311345 (* 1 = 0.311345 loss)
I0927 03:30:10.008049 19128 sgd_solver.cpp:165] Iteration 28600, lr = 0.1
I0927 03:30:39.182327 19128 solver.cpp:357] Iteration 28700 (3.4276 iter/s, 29.1749s/100 iters), loss = 0.216862
I0927 03:30:39.182495 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.216862 (* 1 = 0.216862 loss)
I0927 03:30:39.182507 19128 sgd_solver.cpp:165] Iteration 28700, lr = 0.1
I0927 03:31:15.322906 19128 solver.cpp:357] Iteration 28800 (2.76707 iter/s, 36.1393s/100 iters), loss = 0.264449
I0927 03:31:15.323015 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.264449 (* 1 = 0.264449 loss)
I0927 03:31:15.323026 19128 sgd_solver.cpp:165] Iteration 28800, lr = 0.1
I0927 03:31:51.369735 19128 solver.cpp:357] Iteration 28900 (2.77414 iter/s, 36.0472s/100 iters), loss = 0.380102
I0927 03:31:51.369861 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.380102 (* 1 = 0.380102 loss)
I0927 03:31:51.369873 19128 sgd_solver.cpp:165] Iteration 28900, lr = 0.1
I0927 03:31:52.101990 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:32:27.072892 19128 solver.cpp:514] Iteration 29000, Testing net (#0)
I0927 03:32:55.722585 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:32:55.851101 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.36111 (* 1 = 1.36111 loss)
I0927 03:32:55.851130 19128 solver.cpp:580]     Test net output #1: prob = 0.621
I0927 03:32:56.129065 19128 solver.cpp:357] Iteration 29000 (1.54415 iter/s, 64.7607s/100 iters), loss = 0.396416
I0927 03:32:56.129125 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.396417 (* 1 = 0.396417 loss)
I0927 03:32:56.129135 19128 sgd_solver.cpp:165] Iteration 29000, lr = 0.1
I0927 03:33:28.684607 19128 solver.cpp:357] Iteration 29100 (3.07161 iter/s, 32.5562s/100 iters), loss = 0.43442
I0927 03:33:28.684732 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.43442 (* 1 = 0.43442 loss)
I0927 03:33:28.684744 19128 sgd_solver.cpp:165] Iteration 29100, lr = 0.1
I0927 03:33:58.118496 19128 solver.cpp:357] Iteration 29200 (3.39753 iter/s, 29.4332s/100 iters), loss = 0.345542
I0927 03:33:58.118571 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.345542 (* 1 = 0.345542 loss)
I0927 03:33:58.118580 19128 sgd_solver.cpp:165] Iteration 29200, lr = 0.1
I0927 03:34:31.299484 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:34:34.166914 19128 solver.cpp:357] Iteration 29300 (2.77411 iter/s, 36.0476s/100 iters), loss = 0.313189
I0927 03:34:34.166986 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.313189 (* 1 = 0.313189 loss)
I0927 03:34:34.166997 19128 sgd_solver.cpp:165] Iteration 29300, lr = 0.1
I0927 03:35:10.208650 19128 solver.cpp:357] Iteration 29400 (2.7747 iter/s, 36.04s/100 iters), loss = 0.405548
I0927 03:35:10.208854 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.405548 (* 1 = 0.405548 loss)
I0927 03:35:10.208866 19128 sgd_solver.cpp:165] Iteration 29400, lr = 0.1
I0927 03:35:45.909173 19128 solver.cpp:514] Iteration 29500, Testing net (#0)
I0927 03:36:14.655700 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:36:14.702193 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.35639 (* 1 = 1.35639 loss)
I0927 03:36:14.702221 19128 solver.cpp:580]     Test net output #1: prob = 0.6184
I0927 03:36:15.055176 19128 solver.cpp:357] Iteration 29500 (1.5421 iter/s, 64.8467s/100 iters), loss = 0.382589
I0927 03:36:15.055234 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.382589 (* 1 = 0.382589 loss)
I0927 03:36:15.055245 19128 sgd_solver.cpp:165] Iteration 29500, lr = 0.1
I0927 03:36:47.456498 19128 solver.cpp:357] Iteration 29600 (3.08628 iter/s, 32.4015s/100 iters), loss = 0.269237
I0927 03:36:47.456647 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.269237 (* 1 = 0.269237 loss)
I0927 03:36:47.456658 19128 sgd_solver.cpp:165] Iteration 29600, lr = 0.1
I0927 03:37:10.882344 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:37:16.870190 19128 solver.cpp:357] Iteration 29700 (3.39977 iter/s, 29.4138s/100 iters), loss = 0.285999
I0927 03:37:16.870259 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.285999 (* 1 = 0.285999 loss)
I0927 03:37:16.870268 19128 sgd_solver.cpp:165] Iteration 29700, lr = 0.1
I0927 03:37:52.938107 19128 solver.cpp:357] Iteration 29800 (2.77253 iter/s, 36.0682s/100 iters), loss = 0.322613
I0927 03:37:52.938230 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.322613 (* 1 = 0.322613 loss)
I0927 03:37:52.938241 19128 sgd_solver.cpp:165] Iteration 29800, lr = 0.1
I0927 03:38:28.995539 19128 solver.cpp:357] Iteration 29900 (2.77349 iter/s, 36.0556s/100 iters), loss = 0.307014
I0927 03:38:28.995689 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.307014 (* 1 = 0.307014 loss)
I0927 03:38:28.995700 19128 sgd_solver.cpp:165] Iteration 29900, lr = 0.1
I0927 03:39:04.705821 19128 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_30000.caffemodel
I0927 03:39:04.722930 19128 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_30000.solverstate
I0927 03:39:04.728422 19128 solver.cpp:514] Iteration 30000, Testing net (#0)
I0927 03:39:33.355283 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:39:33.496285 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.888974 (* 1 = 0.888974 loss)
I0927 03:39:33.496312 19128 solver.cpp:580]     Test net output #1: prob = 0.7294
I0927 03:39:33.756462 19128 solver.cpp:357] Iteration 30000 (1.54413 iter/s, 64.7615s/100 iters), loss = 0.254372
I0927 03:39:33.756531 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.254372 (* 1 = 0.254372 loss)
I0927 03:39:33.756542 19128 sgd_solver.cpp:165] Iteration 30000, lr = 0.1
I0927 03:39:59.251529 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:40:06.145531 19128 solver.cpp:357] Iteration 30100 (3.08763 iter/s, 32.3873s/100 iters), loss = 0.31712
I0927 03:40:06.145597 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.31712 (* 1 = 0.31712 loss)
I0927 03:40:06.145608 19128 sgd_solver.cpp:165] Iteration 30100, lr = 0.1
I0927 03:40:35.581212 19128 solver.cpp:357] Iteration 30200 (3.39721 iter/s, 29.4359s/100 iters), loss = 0.535692
I0927 03:40:35.581341 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.535692 (* 1 = 0.535692 loss)
I0927 03:40:35.581351 19128 sgd_solver.cpp:165] Iteration 30200, lr = 0.1
I0927 03:41:11.765887 19128 solver.cpp:357] Iteration 30300 (2.76373 iter/s, 36.183s/100 iters), loss = 0.400472
I0927 03:41:11.765998 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.400472 (* 1 = 0.400472 loss)
I0927 03:41:11.766010 19128 sgd_solver.cpp:165] Iteration 30300, lr = 0.1
I0927 03:41:47.806883 19128 solver.cpp:357] Iteration 30400 (2.77459 iter/s, 36.0413s/100 iters), loss = 0.221537
I0927 03:41:47.807078 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.221537 (* 1 = 0.221537 loss)
I0927 03:41:47.807090 19128 sgd_solver.cpp:165] Iteration 30400, lr = 0.1
I0927 03:42:10.892022 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:42:23.497398 19128 solver.cpp:514] Iteration 30500, Testing net (#0)
I0927 03:42:52.320305 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:42:52.452735 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.695199 (* 1 = 0.695199 loss)
I0927 03:42:52.452765 19128 solver.cpp:580]     Test net output #1: prob = 0.772201
I0927 03:42:52.726305 19128 solver.cpp:357] Iteration 30500 (1.5404 iter/s, 64.9182s/100 iters), loss = 0.249832
I0927 03:42:52.726368 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.249833 (* 1 = 0.249833 loss)
I0927 03:42:52.726379 19128 sgd_solver.cpp:165] Iteration 30500, lr = 0.1
I0927 03:43:24.818262 19128 solver.cpp:357] Iteration 30600 (3.11621 iter/s, 32.0903s/100 iters), loss = 0.360098
I0927 03:43:24.818375 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.360098 (* 1 = 0.360098 loss)
I0927 03:43:24.818387 19128 sgd_solver.cpp:165] Iteration 30600, lr = 0.1
I0927 03:43:54.397590 19128 solver.cpp:357] Iteration 30700 (3.38071 iter/s, 29.5796s/100 iters), loss = 0.412623
I0927 03:43:54.397665 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.412623 (* 1 = 0.412623 loss)
I0927 03:43:54.397676 19128 sgd_solver.cpp:165] Iteration 30700, lr = 0.1
I0927 03:44:30.319573 19128 solver.cpp:357] Iteration 30800 (2.78394 iter/s, 35.9204s/100 iters), loss = 0.412078
I0927 03:44:30.319717 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.412078 (* 1 = 0.412078 loss)
I0927 03:44:30.319728 19128 sgd_solver.cpp:165] Iteration 30800, lr = 0.1
I0927 03:44:50.092044 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:45:06.155642 19128 solver.cpp:357] Iteration 30900 (2.79061 iter/s, 35.8345s/100 iters), loss = 0.491297
I0927 03:45:06.155782 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.491297 (* 1 = 0.491297 loss)
I0927 03:45:06.155793 19128 sgd_solver.cpp:165] Iteration 30900, lr = 0.1
I0927 03:45:41.799204 19128 solver.cpp:514] Iteration 31000, Testing net (#0)
I0927 03:46:10.473932 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:46:10.606127 19128 solver.cpp:580]     Test net output #0: Softmax1 = 1.03426 (* 1 = 1.03426 loss)
I0927 03:46:10.606155 19128 solver.cpp:580]     Test net output #1: prob = 0.654201
I0927 03:46:10.883155 19128 solver.cpp:357] Iteration 31000 (1.54497 iter/s, 64.7264s/100 iters), loss = 0.363995
I0927 03:46:10.883225 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.363995 (* 1 = 0.363995 loss)
I0927 03:46:10.883237 19128 sgd_solver.cpp:165] Iteration 31000, lr = 0.1
I0927 03:46:43.078047 19128 solver.cpp:357] Iteration 31100 (3.10624 iter/s, 32.1932s/100 iters), loss = 0.395208
I0927 03:46:43.078161 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.395208 (* 1 = 0.395208 loss)
I0927 03:46:43.078172 19128 sgd_solver.cpp:165] Iteration 31100, lr = 0.1
I0927 03:47:12.976225 19128 solver.cpp:357] Iteration 31200 (3.34465 iter/s, 29.8985s/100 iters), loss = 0.293455
I0927 03:47:12.976306 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.293455 (* 1 = 0.293455 loss)
I0927 03:47:12.976316 19128 sgd_solver.cpp:165] Iteration 31200, lr = 0.1
I0927 03:47:29.216593 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:47:49.024700 19128 solver.cpp:357] Iteration 31300 (2.77413 iter/s, 36.0474s/100 iters), loss = 0.277315
I0927 03:47:49.024767 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.277315 (* 1 = 0.277315 loss)
I0927 03:47:49.024778 19128 sgd_solver.cpp:165] Iteration 31300, lr = 0.1
I0927 03:48:25.081794 19128 solver.cpp:357] Iteration 31400 (2.77334 iter/s, 36.0576s/100 iters), loss = 0.389412
I0927 03:48:25.081960 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.389412 (* 1 = 0.389412 loss)
I0927 03:48:25.081971 19128 sgd_solver.cpp:165] Iteration 31400, lr = 0.1
I0927 03:49:00.765853 19128 solver.cpp:514] Iteration 31500, Testing net (#0)
I0927 03:49:29.541749 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:49:29.613569 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.661964 (* 1 = 0.661964 loss)
I0927 03:49:29.613608 19128 solver.cpp:580]     Test net output #1: prob = 0.7743
I0927 03:49:29.956912 19128 solver.cpp:357] Iteration 31500 (1.54141 iter/s, 64.8755s/100 iters), loss = 0.368394
I0927 03:49:29.956966 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.368394 (* 1 = 0.368394 loss)
I0927 03:49:29.956977 19128 sgd_solver.cpp:165] Iteration 31500, lr = 0.1
I0927 03:50:01.919762 19128 solver.cpp:357] Iteration 31600 (3.12859 iter/s, 31.9633s/100 iters), loss = 0.357188
I0927 03:50:01.919869 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.357188 (* 1 = 0.357188 loss)
I0927 03:50:01.919883 19128 sgd_solver.cpp:165] Iteration 31600, lr = 0.1
I0927 03:50:11.475550 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:50:31.603360 19128 solver.cpp:357] Iteration 31700 (3.36882 iter/s, 29.684s/100 iters), loss = 0.420494
I0927 03:50:31.603436 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.420494 (* 1 = 0.420494 loss)
I0927 03:50:31.603446 19128 sgd_solver.cpp:165] Iteration 31700, lr = 0.1
I0927 03:51:07.441584 19128 solver.cpp:357] Iteration 31800 (2.79043 iter/s, 35.8367s/100 iters), loss = 0.378834
I0927 03:51:07.441751 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.378834 (* 1 = 0.378834 loss)
I0927 03:51:07.441761 19128 sgd_solver.cpp:165] Iteration 31800, lr = 0.1
I0927 03:51:43.425849 19128 solver.cpp:357] Iteration 31900 (2.77907 iter/s, 35.9832s/100 iters), loss = 0.434405
I0927 03:51:43.426013 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.434405 (* 1 = 0.434405 loss)
I0927 03:51:43.426024 19128 sgd_solver.cpp:165] Iteration 31900, lr = 0.1
I0927 03:52:19.063346 19128 solver.cpp:514] Iteration 32000, Testing net (#0)
I0927 03:52:47.641506 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:52:47.755266 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.786101 (* 1 = 0.786101 loss)
I0927 03:52:47.755300 19128 solver.cpp:580]     Test net output #1: prob = 0.7573
I0927 03:52:48.110606 19128 solver.cpp:357] Iteration 32000 (1.54598 iter/s, 64.6837s/100 iters), loss = 0.34285
I0927 03:52:48.110664 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.342851 (* 1 = 0.342851 loss)
I0927 03:52:48.110673 19128 sgd_solver.cpp:64] MultiStep Status: Iteration 32000, step = 1
I0927 03:52:48.110679 19128 sgd_solver.cpp:165] Iteration 32000, lr = 0.01
I0927 03:52:57.851928 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:53:20.223878 19128 solver.cpp:357] Iteration 32100 (3.11393 iter/s, 32.1138s/100 iters), loss = 0.264273
I0927 03:53:20.223944 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.264273 (* 1 = 0.264273 loss)
I0927 03:53:20.223959 19128 sgd_solver.cpp:165] Iteration 32100, lr = 0.01
I0927 03:53:50.097570 19128 solver.cpp:357] Iteration 32200 (3.34738 iter/s, 29.8742s/100 iters), loss = 0.390047
I0927 03:53:50.097733 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.390047 (* 1 = 0.390047 loss)
I0927 03:53:50.097743 19128 sgd_solver.cpp:165] Iteration 32200, lr = 0.01
I0927 03:54:26.022357 19128 solver.cpp:357] Iteration 32300 (2.78356 iter/s, 35.9253s/100 iters), loss = 0.18759
I0927 03:54:26.022492 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.18759 (* 1 = 0.18759 loss)
I0927 03:54:26.022502 19128 sgd_solver.cpp:165] Iteration 32300, lr = 0.01
I0927 03:55:01.882586 19128 solver.cpp:357] Iteration 32400 (2.78873 iter/s, 35.8587s/100 iters), loss = 0.222385
I0927 03:55:01.882750 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.222385 (* 1 = 0.222385 loss)
I0927 03:55:01.882761 19128 sgd_solver.cpp:165] Iteration 32400, lr = 0.01
I0927 03:55:08.106256 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:55:37.444959 19128 solver.cpp:514] Iteration 32500, Testing net (#0)
I0927 03:56:05.952548 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:56:06.088984 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.537802 (* 1 = 0.537802 loss)
I0927 03:56:06.089013 19128 solver.cpp:580]     Test net output #1: prob = 0.820901
I0927 03:56:06.363257 19128 solver.cpp:357] Iteration 32500 (1.55088 iter/s, 64.4797s/100 iters), loss = 0.224432
I0927 03:56:06.363340 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.224432 (* 1 = 0.224432 loss)
I0927 03:56:06.363353 19128 sgd_solver.cpp:165] Iteration 32500, lr = 0.01
I0927 03:56:38.411921 19128 solver.cpp:357] Iteration 32600 (3.12041 iter/s, 32.0471s/100 iters), loss = 0.131327
I0927 03:56:38.412052 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.131327 (* 1 = 0.131327 loss)
I0927 03:56:38.412063 19128 sgd_solver.cpp:165] Iteration 32600, lr = 0.01
I0927 03:57:08.448781 19128 solver.cpp:357] Iteration 32700 (3.3292 iter/s, 30.0373s/100 iters), loss = 0.16063
I0927 03:57:08.448901 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.16063 (* 1 = 0.16063 loss)
I0927 03:57:08.448911 19128 sgd_solver.cpp:165] Iteration 32700, lr = 0.01
I0927 03:57:44.489697 19128 solver.cpp:357] Iteration 32800 (2.77458 iter/s, 36.0415s/100 iters), loss = 0.143458
I0927 03:57:44.489830 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.143458 (* 1 = 0.143458 loss)
I0927 03:57:44.489841 19128 sgd_solver.cpp:165] Iteration 32800, lr = 0.01
I0927 03:57:47.388607 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:58:20.544486 19128 solver.cpp:357] Iteration 32900 (2.77367 iter/s, 36.0533s/100 iters), loss = 0.134142
I0927 03:58:20.544607 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.134142 (* 1 = 0.134142 loss)
I0927 03:58:20.544620 19128 sgd_solver.cpp:165] Iteration 32900, lr = 0.01
I0927 03:58:56.239063 19128 solver.cpp:514] Iteration 33000, Testing net (#0)
I0927 03:59:24.887614 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 03:59:25.019891 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.517275 (* 1 = 0.517275 loss)
I0927 03:59:25.019917 19128 solver.cpp:580]     Test net output #1: prob = 0.8283
I0927 03:59:25.294440 19128 solver.cpp:357] Iteration 33000 (1.54442 iter/s, 64.7491s/100 iters), loss = 0.148231
I0927 03:59:25.294503 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.148231 (* 1 = 0.148231 loss)
I0927 03:59:25.294514 19128 sgd_solver.cpp:165] Iteration 33000, lr = 0.01
I0927 03:59:57.306639 19128 solver.cpp:357] Iteration 33100 (3.12396 iter/s, 32.0106s/100 iters), loss = 0.184052
I0927 03:59:57.306767 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.184052 (* 1 = 0.184052 loss)
I0927 03:59:57.306779 19128 sgd_solver.cpp:165] Iteration 33100, lr = 0.01
I0927 04:00:26.941361 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:00:27.253844 19128 solver.cpp:357] Iteration 33200 (3.33939 iter/s, 29.9456s/100 iters), loss = 0.175679
I0927 04:00:27.253918 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.175679 (* 1 = 0.175679 loss)
I0927 04:00:27.253931 19128 sgd_solver.cpp:165] Iteration 33200, lr = 0.01
I0927 04:01:03.368321 19128 solver.cpp:357] Iteration 33300 (2.76909 iter/s, 36.113s/100 iters), loss = 0.224404
I0927 04:01:03.368594 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.224404 (* 1 = 0.224404 loss)
I0927 04:01:03.368654 19128 sgd_solver.cpp:165] Iteration 33300, lr = 0.01
I0927 04:01:39.539456 19128 solver.cpp:357] Iteration 33400 (2.7646 iter/s, 36.1716s/100 iters), loss = 0.14467
I0927 04:01:39.539584 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.144671 (* 1 = 0.144671 loss)
I0927 04:01:39.539597 19128 sgd_solver.cpp:165] Iteration 33400, lr = 0.01
I0927 04:02:15.227211 19128 solver.cpp:514] Iteration 33500, Testing net (#0)
I0927 04:02:43.994802 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:02:44.125581 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.738424 (* 1 = 0.738424 loss)
I0927 04:02:44.125617 19128 solver.cpp:580]     Test net output #1: prob = 0.7717
I0927 04:02:44.400650 19128 solver.cpp:357] Iteration 33500 (1.54178 iter/s, 64.8603s/100 iters), loss = 0.19805
I0927 04:02:44.400724 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.19805 (* 1 = 0.19805 loss)
I0927 04:02:44.400741 19128 sgd_solver.cpp:165] Iteration 33500, lr = 0.01
I0927 04:03:13.267410 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:03:16.157411 19128 solver.cpp:357] Iteration 33600 (3.14909 iter/s, 31.7552s/100 iters), loss = 0.190004
I0927 04:03:16.157476 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.190004 (* 1 = 0.190004 loss)
I0927 04:03:16.157490 19128 sgd_solver.cpp:165] Iteration 33600, lr = 0.01
I0927 04:03:46.369534 19128 solver.cpp:357] Iteration 33700 (3.30988 iter/s, 30.2126s/100 iters), loss = 0.157676
I0927 04:03:46.369694 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.157676 (* 1 = 0.157676 loss)
I0927 04:03:46.369704 19128 sgd_solver.cpp:165] Iteration 33700, lr = 0.01
I0927 04:04:22.221989 19128 solver.cpp:357] Iteration 33800 (2.78933 iter/s, 35.851s/100 iters), loss = 0.196287
I0927 04:04:22.222137 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.196287 (* 1 = 0.196287 loss)
I0927 04:04:22.222147 19128 sgd_solver.cpp:165] Iteration 33800, lr = 0.01
I0927 04:04:58.146965 19128 solver.cpp:357] Iteration 33900 (2.78369 iter/s, 35.9235s/100 iters), loss = 0.155558
I0927 04:04:58.147142 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.155558 (* 1 = 0.155558 loss)
I0927 04:04:58.147153 19128 sgd_solver.cpp:165] Iteration 33900, lr = 0.01
I0927 04:05:27.117841 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:05:33.948390 19128 solver.cpp:514] Iteration 34000, Testing net (#0)
I0927 04:06:02.589756 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:06:02.708331 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.752183 (* 1 = 0.752183 loss)
I0927 04:06:02.708369 19128 solver.cpp:580]     Test net output #1: prob = 0.7657
I0927 04:06:02.987159 19128 solver.cpp:357] Iteration 34000 (1.54227 iter/s, 64.8393s/100 iters), loss = 0.0735872
I0927 04:06:02.987220 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0735873 (* 1 = 0.0735873 loss)
I0927 04:06:02.987229 19128 sgd_solver.cpp:165] Iteration 34000, lr = 0.01
I0927 04:06:34.695902 19128 solver.cpp:357] Iteration 34100 (3.15365 iter/s, 31.7093s/100 iters), loss = 0.138701
I0927 04:06:34.696084 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.138701 (* 1 = 0.138701 loss)
I0927 04:06:34.696102 19128 sgd_solver.cpp:165] Iteration 34100, lr = 0.01
I0927 04:07:04.980295 19128 solver.cpp:357] Iteration 34200 (3.30199 iter/s, 30.2848s/100 iters), loss = 0.0674872
I0927 04:07:04.980468 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0674873 (* 1 = 0.0674873 loss)
I0927 04:07:04.980480 19128 sgd_solver.cpp:165] Iteration 34200, lr = 0.01
I0927 04:07:40.854069 19128 solver.cpp:357] Iteration 34300 (2.78766 iter/s, 35.8723s/100 iters), loss = 0.0699189
I0927 04:07:40.854202 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.069919 (* 1 = 0.069919 loss)
I0927 04:07:40.854212 19128 sgd_solver.cpp:165] Iteration 34300, lr = 0.01
I0927 04:08:06.114967 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:08:16.801748 19128 solver.cpp:357] Iteration 34400 (2.78182 iter/s, 35.9477s/100 iters), loss = 0.160568
I0927 04:08:16.801908 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.160568 (* 1 = 0.160568 loss)
I0927 04:08:16.801918 19128 sgd_solver.cpp:165] Iteration 34400, lr = 0.01
I0927 04:08:52.386646 19128 solver.cpp:514] Iteration 34500, Testing net (#0)
I0927 04:09:21.322019 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:09:21.381008 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.670959 (* 1 = 0.670959 loss)
I0927 04:09:21.381044 19128 solver.cpp:580]     Test net output #1: prob = 0.7844
I0927 04:09:21.720543 19128 solver.cpp:357] Iteration 34500 (1.54044 iter/s, 64.9167s/100 iters), loss = 0.0814165
I0927 04:09:21.720593 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0814166 (* 1 = 0.0814166 loss)
I0927 04:09:21.720604 19128 sgd_solver.cpp:165] Iteration 34500, lr = 0.01
I0927 04:09:53.166990 19128 solver.cpp:357] Iteration 34600 (3.18027 iter/s, 31.4438s/100 iters), loss = 0.149913
I0927 04:09:53.167176 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.149913 (* 1 = 0.149913 loss)
I0927 04:09:53.167187 19128 sgd_solver.cpp:165] Iteration 34600, lr = 0.01
I0927 04:10:23.536121 19128 solver.cpp:357] Iteration 34700 (3.2933 iter/s, 30.3646s/100 iters), loss = 0.142347
I0927 04:10:23.536285 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.142347 (* 1 = 0.142347 loss)
I0927 04:10:23.536295 19128 sgd_solver.cpp:165] Iteration 34700, lr = 0.01
I0927 04:10:45.548764 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:10:59.588915 19128 solver.cpp:357] Iteration 34800 (2.77394 iter/s, 36.0498s/100 iters), loss = 0.0896897
I0927 04:10:59.589063 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0896897 (* 1 = 0.0896897 loss)
I0927 04:10:59.589074 19128 sgd_solver.cpp:165] Iteration 34800, lr = 0.01
I0927 04:11:35.630967 19128 solver.cpp:357] Iteration 34900 (2.77473 iter/s, 36.0395s/100 iters), loss = 0.13891
I0927 04:11:35.631114 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.13891 (* 1 = 0.13891 loss)
I0927 04:11:35.631124 19128 sgd_solver.cpp:165] Iteration 34900, lr = 0.01
I0927 04:12:11.331207 19128 solver.cpp:514] Iteration 35000, Testing net (#0)
I0927 04:12:40.168890 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:12:40.301057 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.645022 (* 1 = 0.645022 loss)
I0927 04:12:40.301089 19128 solver.cpp:580]     Test net output #1: prob = 0.7951
I0927 04:12:40.576898 19128 solver.cpp:357] Iteration 35000 (1.53984 iter/s, 64.942s/100 iters), loss = 0.104174
I0927 04:12:40.576969 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.104174 (* 1 = 0.104174 loss)
I0927 04:12:40.576985 19128 sgd_solver.cpp:165] Iteration 35000, lr = 0.01
I0927 04:13:12.070144 19128 solver.cpp:357] Iteration 35100 (3.17567 iter/s, 31.4895s/100 iters), loss = 0.17676
I0927 04:13:12.070318 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.17676 (* 1 = 0.17676 loss)
I0927 04:13:12.070330 19128 sgd_solver.cpp:165] Iteration 35100, lr = 0.01
I0927 04:13:25.947275 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:13:42.448859 19128 solver.cpp:357] Iteration 35200 (3.29217 iter/s, 30.3751s/100 iters), loss = 0.148911
I0927 04:13:42.449029 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.148911 (* 1 = 0.148911 loss)
I0927 04:13:42.449040 19128 sgd_solver.cpp:165] Iteration 35200, lr = 0.01
I0927 04:14:18.540843 19128 solver.cpp:357] Iteration 35300 (2.77099 iter/s, 36.0882s/100 iters), loss = 0.141145
I0927 04:14:18.541093 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.141145 (* 1 = 0.141145 loss)
I0927 04:14:18.541103 19128 sgd_solver.cpp:165] Iteration 35300, lr = 0.01
I0927 04:14:54.588528 19128 solver.cpp:357] Iteration 35400 (2.77424 iter/s, 36.0459s/100 iters), loss = 0.127244
I0927 04:14:54.588639 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.127244 (* 1 = 0.127244 loss)
I0927 04:14:54.588649 19128 sgd_solver.cpp:165] Iteration 35400, lr = 0.01
I0927 04:15:30.271121 19128 solver.cpp:514] Iteration 35500, Testing net (#0)
I0927 04:15:58.917285 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:15:59.009721 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.701436 (* 1 = 0.701436 loss)
I0927 04:15:59.009760 19128 solver.cpp:580]     Test net output #1: prob = 0.7769
I0927 04:15:59.315017 19128 solver.cpp:357] Iteration 35500 (1.54502 iter/s, 64.724s/100 iters), loss = 0.100162
I0927 04:15:59.315083 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.100162 (* 1 = 0.100162 loss)
I0927 04:15:59.315095 19128 sgd_solver.cpp:165] Iteration 35500, lr = 0.01
I0927 04:16:14.567123 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:16:30.696264 19128 solver.cpp:357] Iteration 35600 (3.18673 iter/s, 31.3801s/100 iters), loss = 0.14727
I0927 04:16:30.696327 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.14727 (* 1 = 0.14727 loss)
I0927 04:16:30.696338 19128 sgd_solver.cpp:165] Iteration 35600, lr = 0.01
I0927 04:17:01.152612 19128 solver.cpp:357] Iteration 35700 (3.2835 iter/s, 30.4553s/100 iters), loss = 0.0848225
I0927 04:17:01.152779 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0848225 (* 1 = 0.0848225 loss)
I0927 04:17:01.152789 19128 sgd_solver.cpp:165] Iteration 35700, lr = 0.01
I0927 04:17:37.024328 19128 solver.cpp:357] Iteration 35800 (2.78796 iter/s, 35.8686s/100 iters), loss = 0.0649684
I0927 04:17:37.024466 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0649684 (* 1 = 0.0649684 loss)
I0927 04:17:37.024475 19128 sgd_solver.cpp:165] Iteration 35800, lr = 0.01
I0927 04:18:13.175237 19128 solver.cpp:357] Iteration 35900 (2.76631 iter/s, 36.1493s/100 iters), loss = 0.141839
I0927 04:18:13.175516 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.141839 (* 1 = 0.141839 loss)
I0927 04:18:13.175526 19128 sgd_solver.cpp:165] Iteration 35900, lr = 0.01
I0927 04:18:25.086776 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:18:48.878571 19128 solver.cpp:514] Iteration 36000, Testing net (#0)
I0927 04:19:17.582358 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:19:17.692378 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.827005 (* 1 = 0.827005 loss)
I0927 04:19:17.692414 19128 solver.cpp:580]     Test net output #1: prob = 0.7384
I0927 04:19:18.034956 19128 solver.cpp:357] Iteration 36000 (1.54183 iter/s, 64.858s/100 iters), loss = 0.120947
I0927 04:19:18.035012 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.120947 (* 1 = 0.120947 loss)
I0927 04:19:18.035022 19128 sgd_solver.cpp:165] Iteration 36000, lr = 0.01
I0927 04:19:49.288098 19128 solver.cpp:357] Iteration 36100 (3.19975 iter/s, 31.2524s/100 iters), loss = 0.14045
I0927 04:19:49.288256 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.14045 (* 1 = 0.14045 loss)
I0927 04:19:49.288269 19128 sgd_solver.cpp:165] Iteration 36100, lr = 0.01
I0927 04:20:20.025739 19128 solver.cpp:357] Iteration 36200 (3.25342 iter/s, 30.7369s/100 iters), loss = 0.0839407
I0927 04:20:20.025866 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0839407 (* 1 = 0.0839407 loss)
I0927 04:20:20.025876 19128 sgd_solver.cpp:165] Iteration 36200, lr = 0.01
I0927 04:20:56.075273 19128 solver.cpp:357] Iteration 36300 (2.77404 iter/s, 36.0485s/100 iters), loss = 0.109067
I0927 04:20:56.075397 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.109067 (* 1 = 0.109067 loss)
I0927 04:20:56.075407 19128 sgd_solver.cpp:165] Iteration 36300, lr = 0.01
I0927 04:21:04.747267 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:21:32.140239 19128 solver.cpp:357] Iteration 36400 (2.77283 iter/s, 36.0643s/100 iters), loss = 0.101386
I0927 04:21:32.140414 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.101386 (* 1 = 0.101386 loss)
I0927 04:21:32.140425 19128 sgd_solver.cpp:165] Iteration 36400, lr = 0.01
I0927 04:22:07.819268 19128 solver.cpp:514] Iteration 36500, Testing net (#0)
I0927 04:22:36.694686 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:22:36.837177 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.46192 (* 1 = 0.46192 loss)
I0927 04:22:36.837203 19128 solver.cpp:580]     Test net output #1: prob = 0.847701
I0927 04:22:37.098834 19128 solver.cpp:357] Iteration 36500 (1.53951 iter/s, 64.9559s/100 iters), loss = 0.0846487
I0927 04:22:37.098898 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0846488 (* 1 = 0.0846488 loss)
I0927 04:22:37.098911 19128 sgd_solver.cpp:165] Iteration 36500, lr = 0.01
I0927 04:23:08.030836 19128 solver.cpp:357] Iteration 36600 (3.23316 iter/s, 30.9295s/100 iters), loss = 0.0969917
I0927 04:23:08.031056 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0969917 (* 1 = 0.0969917 loss)
I0927 04:23:08.031069 19128 sgd_solver.cpp:165] Iteration 36600, lr = 0.01
I0927 04:23:38.943603 19128 solver.cpp:357] Iteration 36700 (3.23496 iter/s, 30.9123s/100 iters), loss = 0.0684866
I0927 04:23:38.943717 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0684866 (* 1 = 0.0684866 loss)
I0927 04:23:38.943727 19128 sgd_solver.cpp:165] Iteration 36700, lr = 0.01
I0927 04:23:44.008141 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:24:14.990101 19128 solver.cpp:357] Iteration 36800 (2.77423 iter/s, 36.0461s/100 iters), loss = 0.180041
I0927 04:24:14.990272 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.180041 (* 1 = 0.180041 loss)
I0927 04:24:14.990283 19128 sgd_solver.cpp:165] Iteration 36800, lr = 0.01
I0927 04:24:51.048965 19128 solver.cpp:357] Iteration 36900 (2.77338 iter/s, 36.0571s/100 iters), loss = 0.132788
I0927 04:24:51.049114 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.132788 (* 1 = 0.132788 loss)
I0927 04:24:51.049124 19128 sgd_solver.cpp:165] Iteration 36900, lr = 0.01
I0927 04:25:26.756436 19128 solver.cpp:514] Iteration 37000, Testing net (#0)
I0927 04:25:55.274165 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:25:55.416653 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.476497 (* 1 = 0.476497 loss)
I0927 04:25:55.416682 19128 solver.cpp:580]     Test net output #1: prob = 0.845501
I0927 04:25:55.680351 19128 solver.cpp:357] Iteration 37000 (1.54725 iter/s, 64.6309s/100 iters), loss = 0.147038
I0927 04:25:55.680415 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.147038 (* 1 = 0.147038 loss)
I0927 04:25:55.680428 19128 sgd_solver.cpp:165] Iteration 37000, lr = 0.01
I0927 04:26:26.887645 19128 solver.cpp:357] Iteration 37100 (3.20462 iter/s, 31.2049s/100 iters), loss = 0.0603614
I0927 04:26:26.887775 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0603615 (* 1 = 0.0603615 loss)
I0927 04:26:26.887787 19128 sgd_solver.cpp:165] Iteration 37100, lr = 0.01
I0927 04:26:28.243371 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:26:57.538434 19128 solver.cpp:357] Iteration 37200 (3.26259 iter/s, 30.6505s/100 iters), loss = 0.155913
I0927 04:26:57.538600 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.155913 (* 1 = 0.155913 loss)
I0927 04:26:57.538612 19128 sgd_solver.cpp:165] Iteration 37200, lr = 0.01
I0927 04:27:33.402604 19128 solver.cpp:357] Iteration 37300 (2.78847 iter/s, 35.8619s/100 iters), loss = 0.0979911
I0927 04:27:33.402770 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0979912 (* 1 = 0.0979912 loss)
I0927 04:27:33.402779 19128 sgd_solver.cpp:165] Iteration 37300, lr = 0.01
I0927 04:28:09.468274 19128 solver.cpp:357] Iteration 37400 (2.77289 iter/s, 36.0634s/100 iters), loss = 0.123956
I0927 04:28:09.468457 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.123956 (* 1 = 0.123956 loss)
I0927 04:28:09.468468 19128 sgd_solver.cpp:165] Iteration 37400, lr = 0.01
I0927 04:28:43.752213 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:28:45.179699 19128 solver.cpp:514] Iteration 37500, Testing net (#0)
I0927 04:29:13.795367 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:29:13.930490 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.645223 (* 1 = 0.645223 loss)
I0927 04:29:13.930526 19128 solver.cpp:580]     Test net output #1: prob = 0.796699
I0927 04:29:14.210131 19128 solver.cpp:357] Iteration 37500 (1.54463 iter/s, 64.7406s/100 iters), loss = 0.0871204
I0927 04:29:14.210208 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0871205 (* 1 = 0.0871205 loss)
I0927 04:29:14.210218 19128 sgd_solver.cpp:165] Iteration 37500, lr = 0.01
I0927 04:29:45.268566 19128 solver.cpp:357] Iteration 37600 (3.21997 iter/s, 31.0562s/100 iters), loss = 0.0880035
I0927 04:29:45.268779 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0880036 (* 1 = 0.0880036 loss)
I0927 04:29:45.268791 19128 sgd_solver.cpp:165] Iteration 37600, lr = 0.01
I0927 04:30:16.272867 19128 solver.cpp:357] Iteration 37700 (3.22538 iter/s, 31.0041s/100 iters), loss = 0.0963265
I0927 04:30:16.272986 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0963266 (* 1 = 0.0963266 loss)
I0927 04:30:16.272996 19128 sgd_solver.cpp:165] Iteration 37700, lr = 0.01
I0927 04:30:52.304901 19128 solver.cpp:357] Iteration 37800 (2.77532 iter/s, 36.0319s/100 iters), loss = 0.109898
I0927 04:30:52.305071 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.109898 (* 1 = 0.109898 loss)
I0927 04:30:52.305083 19128 sgd_solver.cpp:165] Iteration 37800, lr = 0.01
I0927 04:31:23.329695 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:31:28.364634 19128 solver.cpp:357] Iteration 37900 (2.77334 iter/s, 36.0576s/100 iters), loss = 0.127306
I0927 04:31:28.364701 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.127306 (* 1 = 0.127306 loss)
I0927 04:31:28.364712 19128 sgd_solver.cpp:165] Iteration 37900, lr = 0.01
I0927 04:32:04.064415 19128 solver.cpp:514] Iteration 38000, Testing net (#0)
I0927 04:32:32.575561 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:32:32.717972 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.459374 (* 1 = 0.459374 loss)
I0927 04:32:32.718000 19128 solver.cpp:580]     Test net output #1: prob = 0.850001
I0927 04:32:32.980677 19128 solver.cpp:357] Iteration 38000 (1.5476 iter/s, 64.6161s/100 iters), loss = 0.0549424
I0927 04:32:32.980741 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0549425 (* 1 = 0.0549425 loss)
I0927 04:32:32.980754 19128 sgd_solver.cpp:165] Iteration 38000, lr = 0.01
I0927 04:33:04.074771 19128 solver.cpp:357] Iteration 38100 (3.21626 iter/s, 31.092s/100 iters), loss = 0.0963932
I0927 04:33:04.074923 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0963932 (* 1 = 0.0963932 loss)
I0927 04:33:04.074934 19128 sgd_solver.cpp:165] Iteration 38100, lr = 0.01
I0927 04:33:34.918723 19128 solver.cpp:357] Iteration 38200 (3.24214 iter/s, 30.8439s/100 iters), loss = 0.0908281
I0927 04:33:34.918848 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0908282 (* 1 = 0.0908282 loss)
I0927 04:33:34.918859 19128 sgd_solver.cpp:165] Iteration 38200, lr = 0.01
I0927 04:34:02.684440 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:34:10.963512 19128 solver.cpp:357] Iteration 38300 (2.77435 iter/s, 36.0444s/100 iters), loss = 0.102243
I0927 04:34:10.963680 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.102243 (* 1 = 0.102243 loss)
I0927 04:34:10.963691 19128 sgd_solver.cpp:165] Iteration 38300, lr = 0.01
I0927 04:34:47.011998 19128 solver.cpp:357] Iteration 38400 (2.7742 iter/s, 36.0464s/100 iters), loss = 0.0670314
I0927 04:34:47.012140 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0670315 (* 1 = 0.0670315 loss)
I0927 04:34:47.012151 19128 sgd_solver.cpp:165] Iteration 38400, lr = 0.01
I0927 04:35:22.611737 19128 solver.cpp:514] Iteration 38500, Testing net (#0)
I0927 04:35:50.985185 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:35:51.087466 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.538294 (* 1 = 0.538294 loss)
I0927 04:35:51.087492 19128 solver.cpp:580]     Test net output #1: prob = 0.830801
I0927 04:35:51.403285 19128 solver.cpp:357] Iteration 38500 (1.55305 iter/s, 64.3894s/100 iters), loss = 0.0585548
I0927 04:35:51.403354 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0585549 (* 1 = 0.0585549 loss)
I0927 04:35:51.403367 19128 sgd_solver.cpp:165] Iteration 38500, lr = 0.01
I0927 04:36:22.595724 19128 solver.cpp:357] Iteration 38600 (3.20611 iter/s, 31.1904s/100 iters), loss = 0.0730262
I0927 04:36:22.595883 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0730263 (* 1 = 0.0730263 loss)
I0927 04:36:22.595896 19128 sgd_solver.cpp:165] Iteration 38600, lr = 0.01
I0927 04:36:41.460780 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:36:53.218194 19128 solver.cpp:357] Iteration 38700 (3.26569 iter/s, 30.6214s/100 iters), loss = 0.131462
I0927 04:36:53.218433 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.131462 (* 1 = 0.131462 loss)
I0927 04:36:53.218446 19128 sgd_solver.cpp:165] Iteration 38700, lr = 0.01
I0927 04:37:29.109287 19128 solver.cpp:357] Iteration 38800 (2.78625 iter/s, 35.8905s/100 iters), loss = 0.0458525
I0927 04:37:29.109608 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0458526 (* 1 = 0.0458526 loss)
I0927 04:37:29.109621 19128 sgd_solver.cpp:165] Iteration 38800, lr = 0.01
I0927 04:38:05.048318 19128 solver.cpp:357] Iteration 38900 (2.78264 iter/s, 35.937s/100 iters), loss = 0.0780576
I0927 04:38:05.048467 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0780577 (* 1 = 0.0780577 loss)
I0927 04:38:05.048478 19128 sgd_solver.cpp:165] Iteration 38900, lr = 0.01
I0927 04:38:40.742734 19128 solver.cpp:514] Iteration 39000, Testing net (#0)
I0927 04:39:09.635023 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:39:09.769292 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.57868 (* 1 = 0.57868 loss)
I0927 04:39:09.769321 19128 solver.cpp:580]     Test net output #1: prob = 0.830101
I0927 04:39:10.035109 19128 solver.cpp:357] Iteration 39000 (1.53882 iter/s, 64.985s/100 iters), loss = 0.0595629
I0927 04:39:10.035173 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.059563 (* 1 = 0.059563 loss)
I0927 04:39:10.035185 19128 sgd_solver.cpp:165] Iteration 39000, lr = 0.01
I0927 04:39:29.946902 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:39:41.122894 19128 solver.cpp:357] Iteration 39100 (3.21691 iter/s, 31.0857s/100 iters), loss = 0.109096
I0927 04:39:41.122961 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.109097 (* 1 = 0.109097 loss)
I0927 04:39:41.122972 19128 sgd_solver.cpp:165] Iteration 39100, lr = 0.01
I0927 04:40:12.076467 19128 solver.cpp:357] Iteration 39200 (3.2308 iter/s, 30.952s/100 iters), loss = 0.126114
I0927 04:40:12.076648 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.126114 (* 1 = 0.126114 loss)
I0927 04:40:12.076659 19128 sgd_solver.cpp:165] Iteration 39200, lr = 0.01
I0927 04:40:48.140224 19128 solver.cpp:357] Iteration 39300 (2.77295 iter/s, 36.0627s/100 iters), loss = 0.10312
I0927 04:40:48.140331 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.10312 (* 1 = 0.10312 loss)
I0927 04:40:48.140342 19128 sgd_solver.cpp:165] Iteration 39300, lr = 0.01
I0927 04:41:24.178158 19128 solver.cpp:357] Iteration 39400 (2.77485 iter/s, 36.038s/100 iters), loss = 0.0890039
I0927 04:41:24.178400 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.089004 (* 1 = 0.089004 loss)
I0927 04:41:24.178431 19128 sgd_solver.cpp:165] Iteration 39400, lr = 0.01
I0927 04:41:41.852785 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:41:59.868121 19128 solver.cpp:514] Iteration 39500, Testing net (#0)
I0927 04:42:28.461419 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:42:28.554636 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.512996 (* 1 = 0.512996 loss)
I0927 04:42:28.554672 19128 solver.cpp:580]     Test net output #1: prob = 0.844001
I0927 04:42:28.854266 19128 solver.cpp:357] Iteration 39500 (1.54621 iter/s, 64.6744s/100 iters), loss = 0.107246
I0927 04:42:28.854328 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.107246 (* 1 = 0.107246 loss)
I0927 04:42:28.854339 19128 sgd_solver.cpp:165] Iteration 39500, lr = 0.01
I0927 04:42:59.855938 19128 solver.cpp:357] Iteration 39600 (3.22562 iter/s, 31.0018s/100 iters), loss = 0.0444176
I0927 04:42:59.856091 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0444178 (* 1 = 0.0444178 loss)
I0927 04:42:59.856101 19128 sgd_solver.cpp:165] Iteration 39600, lr = 0.01
I0927 04:43:30.392951 19128 solver.cpp:357] Iteration 39700 (3.27432 iter/s, 30.5407s/100 iters), loss = 0.0781192
I0927 04:43:30.393189 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0781193 (* 1 = 0.0781193 loss)
I0927 04:43:30.393201 19128 sgd_solver.cpp:165] Iteration 39700, lr = 0.01
I0927 04:44:06.312430 19128 solver.cpp:357] Iteration 39800 (2.78378 iter/s, 35.9224s/100 iters), loss = 0.0452326
I0927 04:44:06.312566 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0452327 (* 1 = 0.0452327 loss)
I0927 04:44:06.312575 19128 sgd_solver.cpp:165] Iteration 39800, lr = 0.01
I0927 04:44:20.416191 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:44:42.184556 19128 solver.cpp:357] Iteration 39900 (2.78747 iter/s, 35.8748s/100 iters), loss = 0.0868679
I0927 04:44:42.184715 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.086868 (* 1 = 0.086868 loss)
I0927 04:44:42.184725 19128 sgd_solver.cpp:165] Iteration 39900, lr = 0.01
I0927 04:45:17.745331 19128 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_40000.caffemodel
I0927 04:45:17.772043 19128 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_40000.solverstate
I0927 04:45:17.778882 19128 solver.cpp:514] Iteration 40000, Testing net (#0)
I0927 04:45:46.231237 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:45:46.286758 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.591318 (* 1 = 0.591318 loss)
I0927 04:45:46.286790 19128 solver.cpp:580]     Test net output #1: prob = 0.823401
I0927 04:45:46.641312 19128 solver.cpp:357] Iteration 40000 (1.55129 iter/s, 64.4626s/100 iters), loss = 0.203111
I0927 04:45:46.641371 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.203111 (* 1 = 0.203111 loss)
I0927 04:45:46.641381 19128 sgd_solver.cpp:165] Iteration 40000, lr = 0.01
I0927 04:46:17.969887 19128 solver.cpp:357] Iteration 40100 (3.19162 iter/s, 31.3321s/100 iters), loss = 0.107278
I0927 04:46:17.970001 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.107278 (* 1 = 0.107278 loss)
I0927 04:46:17.970012 19128 sgd_solver.cpp:165] Iteration 40100, lr = 0.01
I0927 04:46:48.623466 19128 solver.cpp:357] Iteration 40200 (3.26192 iter/s, 30.6568s/100 iters), loss = 0.135923
I0927 04:46:48.623589 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.135923 (* 1 = 0.135923 loss)
I0927 04:46:48.623602 19128 sgd_solver.cpp:165] Iteration 40200, lr = 0.01
I0927 04:46:59.451059 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:47:24.470898 19128 solver.cpp:357] Iteration 40300 (2.78948 iter/s, 35.849s/100 iters), loss = 0.0976645
I0927 04:47:24.471076 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0976646 (* 1 = 0.0976646 loss)
I0927 04:47:24.471086 19128 sgd_solver.cpp:165] Iteration 40300, lr = 0.01
I0927 04:48:00.380882 19128 solver.cpp:357] Iteration 40400 (2.78464 iter/s, 35.9113s/100 iters), loss = 0.0916785
I0927 04:48:00.381023 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0916786 (* 1 = 0.0916786 loss)
I0927 04:48:00.381034 19128 sgd_solver.cpp:165] Iteration 40400, lr = 0.01
I0927 04:48:35.932643 19128 solver.cpp:514] Iteration 40500, Testing net (#0)
I0927 04:49:04.684964 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:49:04.824452 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.490659 (* 1 = 0.490659 loss)
I0927 04:49:04.824479 19128 solver.cpp:580]     Test net output #1: prob = 0.846201
I0927 04:49:05.085274 19128 solver.cpp:357] Iteration 40500 (1.5454 iter/s, 64.7082s/100 iters), loss = 0.0741879
I0927 04:49:05.085336 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.074188 (* 1 = 0.074188 loss)
I0927 04:49:05.085348 19128 sgd_solver.cpp:165] Iteration 40500, lr = 0.01
I0927 04:49:36.207263 19128 solver.cpp:357] Iteration 40600 (3.21311 iter/s, 31.1225s/100 iters), loss = 0.0824031
I0927 04:49:36.207376 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0824032 (* 1 = 0.0824032 loss)
I0927 04:49:36.207388 19128 sgd_solver.cpp:165] Iteration 40600, lr = 0.01
I0927 04:49:41.539726 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:50:07.084704 19128 solver.cpp:357] Iteration 40700 (3.23836 iter/s, 30.8798s/100 iters), loss = 0.0979423
I0927 04:50:07.084924 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0979424 (* 1 = 0.0979424 loss)
I0927 04:50:07.084936 19128 sgd_solver.cpp:165] Iteration 40700, lr = 0.01
I0927 04:50:43.138689 19128 solver.cpp:357] Iteration 40800 (2.77357 iter/s, 36.0546s/100 iters), loss = 0.0599606
I0927 04:50:43.138870 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0599607 (* 1 = 0.0599607 loss)
I0927 04:50:43.138880 19128 sgd_solver.cpp:165] Iteration 40800, lr = 0.01
I0927 04:51:19.197543 19128 solver.cpp:357] Iteration 40900 (2.77305 iter/s, 36.0614s/100 iters), loss = 0.0717319
I0927 04:51:19.197695 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.071732 (* 1 = 0.071732 loss)
I0927 04:51:19.197706 19128 sgd_solver.cpp:165] Iteration 40900, lr = 0.01
I0927 04:51:54.896647 19128 solver.cpp:514] Iteration 41000, Testing net (#0)
I0927 04:52:23.543514 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:52:23.676201 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.505668 (* 1 = 0.505668 loss)
I0927 04:52:23.676231 19128 solver.cpp:580]     Test net output #1: prob = 0.8436
I0927 04:52:23.948490 19128 solver.cpp:357] Iteration 41000 (1.54427 iter/s, 64.7553s/100 iters), loss = 0.0898207
I0927 04:52:23.948554 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0898208 (* 1 = 0.0898208 loss)
I0927 04:52:23.948565 19128 sgd_solver.cpp:165] Iteration 41000, lr = 0.01
I0927 04:52:28.011270 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:52:54.981743 19128 solver.cpp:357] Iteration 41100 (3.22236 iter/s, 31.0331s/100 iters), loss = 0.117791
I0927 04:52:54.981814 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.117791 (* 1 = 0.117791 loss)
I0927 04:52:54.981825 19128 sgd_solver.cpp:165] Iteration 41100, lr = 0.01
I0927 04:53:25.582157 19128 solver.cpp:357] Iteration 41200 (3.26773 iter/s, 30.6023s/100 iters), loss = 0.107714
I0927 04:53:25.582314 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.107714 (* 1 = 0.107714 loss)
I0927 04:53:25.582325 19128 sgd_solver.cpp:165] Iteration 41200, lr = 0.01
I0927 04:54:01.573989 19128 solver.cpp:357] Iteration 41300 (2.77829 iter/s, 35.9933s/100 iters), loss = 0.0614596
I0927 04:54:01.574141 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0614597 (* 1 = 0.0614597 loss)
I0927 04:54:01.574151 19128 sgd_solver.cpp:165] Iteration 41300, lr = 0.01
I0927 04:54:37.616365 19128 solver.cpp:357] Iteration 41400 (2.7744 iter/s, 36.0439s/100 iters), loss = 0.131199
I0927 04:54:37.616494 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.131199 (* 1 = 0.131199 loss)
I0927 04:54:37.616506 19128 sgd_solver.cpp:165] Iteration 41400, lr = 0.01
I0927 04:54:38.348834 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:55:13.293051 19128 solver.cpp:514] Iteration 41500, Testing net (#0)
I0927 04:55:41.966795 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:55:42.109061 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.606057 (* 1 = 0.606057 loss)
I0927 04:55:42.109088 19128 solver.cpp:580]     Test net output #1: prob = 0.8225
I0927 04:55:42.368795 19128 solver.cpp:357] Iteration 41500 (1.54426 iter/s, 64.7557s/100 iters), loss = 0.0675182
I0927 04:55:42.368861 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0675184 (* 1 = 0.0675184 loss)
I0927 04:55:42.368875 19128 sgd_solver.cpp:165] Iteration 41500, lr = 0.01
I0927 04:56:13.437618 19128 solver.cpp:357] Iteration 41600 (3.21872 iter/s, 31.0683s/100 iters), loss = 0.069737
I0927 04:56:13.437746 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0697371 (* 1 = 0.0697371 loss)
I0927 04:56:13.437755 19128 sgd_solver.cpp:165] Iteration 41600, lr = 0.01
I0927 04:56:44.226130 19128 solver.cpp:357] Iteration 41700 (3.24782 iter/s, 30.7899s/100 iters), loss = 0.0720053
I0927 04:56:44.226379 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0720054 (* 1 = 0.0720054 loss)
I0927 04:56:44.226392 19128 sgd_solver.cpp:165] Iteration 41700, lr = 0.01
I0927 04:57:17.415448 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:57:20.283779 19128 solver.cpp:357] Iteration 41800 (2.77331 iter/s, 36.058s/100 iters), loss = 0.110907
I0927 04:57:20.283854 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.110907 (* 1 = 0.110907 loss)
I0927 04:57:20.283864 19128 sgd_solver.cpp:165] Iteration 41800, lr = 0.01
I0927 04:57:56.338454 19128 solver.cpp:357] Iteration 41900 (2.7736 iter/s, 36.0542s/100 iters), loss = 0.0518885
I0927 04:57:56.338610 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0518886 (* 1 = 0.0518886 loss)
I0927 04:57:56.338620 19128 sgd_solver.cpp:165] Iteration 41900, lr = 0.01
I0927 04:58:32.023195 19128 solver.cpp:514] Iteration 42000, Testing net (#0)
I0927 04:59:00.528220 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 04:59:00.671461 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.390763 (* 1 = 0.390763 loss)
I0927 04:59:00.671488 19128 solver.cpp:580]     Test net output #1: prob = 0.875802
I0927 04:59:00.948942 19128 solver.cpp:357] Iteration 42000 (1.54767 iter/s, 64.6133s/100 iters), loss = 0.0594711
I0927 04:59:00.949005 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0594712 (* 1 = 0.0594712 loss)
I0927 04:59:00.949018 19128 sgd_solver.cpp:165] Iteration 42000, lr = 0.01
I0927 04:59:32.105511 19128 solver.cpp:357] Iteration 42100 (3.20968 iter/s, 31.1557s/100 iters), loss = 0.0346477
I0927 04:59:32.105653 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0346478 (* 1 = 0.0346478 loss)
I0927 04:59:32.105664 19128 sgd_solver.cpp:165] Iteration 42100, lr = 0.01
I0927 04:59:56.726029 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:00:02.835956 19128 solver.cpp:357] Iteration 42200 (3.25398 iter/s, 30.7316s/100 iters), loss = 0.110236
I0927 05:00:02.836061 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.110236 (* 1 = 0.110236 loss)
I0927 05:00:02.836071 19128 sgd_solver.cpp:165] Iteration 42200, lr = 0.01
I0927 05:00:38.900626 19128 solver.cpp:357] Iteration 42300 (2.77274 iter/s, 36.0655s/100 iters), loss = 0.0827471
I0927 05:00:38.900779 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0827472 (* 1 = 0.0827472 loss)
I0927 05:00:38.900789 19128 sgd_solver.cpp:165] Iteration 42300, lr = 0.01
I0927 05:01:14.948516 19128 solver.cpp:357] Iteration 42400 (2.77399 iter/s, 36.0492s/100 iters), loss = 0.091417
I0927 05:01:14.948684 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0914171 (* 1 = 0.0914171 loss)
I0927 05:01:14.948694 19128 sgd_solver.cpp:165] Iteration 42400, lr = 0.01
I0927 05:01:50.643695 19128 solver.cpp:514] Iteration 42500, Testing net (#0)
I0927 05:02:19.453742 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:02:19.588740 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.881265 (* 1 = 0.881265 loss)
I0927 05:02:19.588768 19128 solver.cpp:580]     Test net output #1: prob = 0.7741
I0927 05:02:19.855075 19128 solver.cpp:357] Iteration 42500 (1.54067 iter/s, 64.9069s/100 iters), loss = 0.0448899
I0927 05:02:19.855137 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.04489 (* 1 = 0.04489 loss)
I0927 05:02:19.855149 19128 sgd_solver.cpp:165] Iteration 42500, lr = 0.01
I0927 05:02:43.955113 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:02:50.841357 19128 solver.cpp:357] Iteration 42600 (3.22712 iter/s, 30.9874s/100 iters), loss = 0.125694
I0927 05:02:50.841418 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.125695 (* 1 = 0.125695 loss)
I0927 05:02:50.841429 19128 sgd_solver.cpp:165] Iteration 42600, lr = 0.01
I0927 05:03:21.760958 19128 solver.cpp:357] Iteration 42700 (3.23409 iter/s, 30.9206s/100 iters), loss = 0.110817
I0927 05:03:21.761178 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.110817 (* 1 = 0.110817 loss)
I0927 05:03:21.761188 19128 sgd_solver.cpp:165] Iteration 42700, lr = 0.01
I0927 05:03:57.792645 19128 solver.cpp:357] Iteration 42800 (2.7754 iter/s, 36.0308s/100 iters), loss = 0.0566952
I0927 05:03:57.792750 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0566954 (* 1 = 0.0566954 loss)
I0927 05:03:57.792760 19128 sgd_solver.cpp:165] Iteration 42800, lr = 0.01
I0927 05:04:33.852344 19128 solver.cpp:357] Iteration 42900 (2.77309 iter/s, 36.0608s/100 iters), loss = 0.0482577
I0927 05:04:33.852455 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0482578 (* 1 = 0.0482578 loss)
I0927 05:04:33.852465 19128 sgd_solver.cpp:165] Iteration 42900, lr = 0.01
I0927 05:04:56.923867 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:05:09.524480 19128 solver.cpp:514] Iteration 43000, Testing net (#0)
I0927 05:05:38.102363 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:05:38.172708 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.380332 (* 1 = 0.380332 loss)
I0927 05:05:38.172744 19128 solver.cpp:580]     Test net output #1: prob = 0.880302
I0927 05:05:38.516769 19128 solver.cpp:357] Iteration 43000 (1.5464 iter/s, 64.6662s/100 iters), loss = 0.0496391
I0927 05:05:38.516822 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0496392 (* 1 = 0.0496392 loss)
I0927 05:05:38.516834 19128 sgd_solver.cpp:165] Iteration 43000, lr = 0.01
I0927 05:06:09.696166 19128 solver.cpp:357] Iteration 43100 (3.20715 iter/s, 31.1803s/100 iters), loss = 0.0617744
I0927 05:06:09.696355 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0617746 (* 1 = 0.0617746 loss)
I0927 05:06:09.696382 19128 sgd_solver.cpp:165] Iteration 43100, lr = 0.01
I0927 05:06:40.376899 19128 solver.cpp:357] Iteration 43200 (3.25929 iter/s, 30.6815s/100 iters), loss = 0.0937366
I0927 05:06:40.377220 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0937367 (* 1 = 0.0937367 loss)
I0927 05:06:40.377231 19128 sgd_solver.cpp:165] Iteration 43200, lr = 0.01
I0927 05:07:16.267442 19128 solver.cpp:357] Iteration 43300 (2.78633 iter/s, 35.8895s/100 iters), loss = 0.0312097
I0927 05:07:16.267568 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0312099 (* 1 = 0.0312099 loss)
I0927 05:07:16.267578 19128 sgd_solver.cpp:165] Iteration 43300, lr = 0.01
I0927 05:07:36.083629 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:07:52.089221 19128 solver.cpp:357] Iteration 43400 (2.79168 iter/s, 35.8208s/100 iters), loss = 0.107716
I0927 05:07:52.089380 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.107716 (* 1 = 0.107716 loss)
I0927 05:07:52.089391 19128 sgd_solver.cpp:165] Iteration 43400, lr = 0.01
I0927 05:08:27.854779 19128 solver.cpp:514] Iteration 43500, Testing net (#0)
I0927 05:08:56.447005 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:08:56.525113 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.477196 (* 1 = 0.477196 loss)
I0927 05:08:56.525168 19128 solver.cpp:580]     Test net output #1: prob = 0.866701
I0927 05:08:56.839030 19128 solver.cpp:357] Iteration 43500 (1.54441 iter/s, 64.7496s/100 iters), loss = 0.122694
I0927 05:08:56.839087 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.122694 (* 1 = 0.122694 loss)
I0927 05:08:56.839098 19128 sgd_solver.cpp:165] Iteration 43500, lr = 0.01
I0927 05:09:27.961467 19128 solver.cpp:357] Iteration 43600 (3.21303 iter/s, 31.1233s/100 iters), loss = 0.0565427
I0927 05:09:27.961627 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0565428 (* 1 = 0.0565428 loss)
I0927 05:09:27.961639 19128 sgd_solver.cpp:165] Iteration 43600, lr = 0.01
I0927 05:09:58.966310 19128 solver.cpp:357] Iteration 43700 (3.22524 iter/s, 31.0055s/100 iters), loss = 0.0607378
I0927 05:09:58.966459 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0607379 (* 1 = 0.0607379 loss)
I0927 05:09:58.966471 19128 sgd_solver.cpp:165] Iteration 43700, lr = 0.01
I0927 05:10:15.209422 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:10:34.998133 19128 solver.cpp:357] Iteration 43800 (2.77526 iter/s, 36.0327s/100 iters), loss = 0.0754926
I0927 05:10:34.998378 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0754927 (* 1 = 0.0754927 loss)
I0927 05:10:34.998390 19128 sgd_solver.cpp:165] Iteration 43800, lr = 0.01
I0927 05:11:11.048298 19128 solver.cpp:357] Iteration 43900 (2.774 iter/s, 36.049s/100 iters), loss = 0.0857229
I0927 05:11:11.048452 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0857231 (* 1 = 0.0857231 loss)
I0927 05:11:11.048463 19128 sgd_solver.cpp:165] Iteration 43900, lr = 0.01
I0927 05:11:46.750675 19128 solver.cpp:514] Iteration 44000, Testing net (#0)
I0927 05:12:15.397972 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:12:15.456427 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.472364 (* 1 = 0.472364 loss)
I0927 05:12:15.456467 19128 solver.cpp:580]     Test net output #1: prob = 0.873002
I0927 05:12:15.792150 19128 solver.cpp:357] Iteration 44000 (1.54451 iter/s, 64.7456s/100 iters), loss = 0.0881493
I0927 05:12:15.792206 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0881494 (* 1 = 0.0881494 loss)
I0927 05:12:15.792215 19128 sgd_solver.cpp:165] Iteration 44000, lr = 0.01
I0927 05:12:46.866750 19128 solver.cpp:357] Iteration 44100 (3.21798 iter/s, 31.0754s/100 iters), loss = 0.03197
I0927 05:12:46.866909 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0319702 (* 1 = 0.0319702 loss)
I0927 05:12:46.866920 19128 sgd_solver.cpp:165] Iteration 44100, lr = 0.01
I0927 05:12:56.467155 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:13:17.780383 19128 solver.cpp:357] Iteration 44200 (3.23475 iter/s, 30.9143s/100 iters), loss = 0.100336
I0927 05:13:17.780550 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.100336 (* 1 = 0.100336 loss)
I0927 05:13:17.780561 19128 sgd_solver.cpp:165] Iteration 44200, lr = 0.01
I0927 05:13:53.628969 19128 solver.cpp:357] Iteration 44300 (2.7896 iter/s, 35.8474s/100 iters), loss = 0.0599733
I0927 05:13:53.629148 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0599734 (* 1 = 0.0599734 loss)
I0927 05:13:53.629159 19128 sgd_solver.cpp:165] Iteration 44300, lr = 0.01
I0927 05:14:29.549316 19128 solver.cpp:357] Iteration 44400 (2.78403 iter/s, 35.9192s/100 iters), loss = 0.118918
I0927 05:14:29.549469 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.118918 (* 1 = 0.118918 loss)
I0927 05:14:29.549480 19128 sgd_solver.cpp:165] Iteration 44400, lr = 0.01
I0927 05:15:05.168944 19128 solver.cpp:514] Iteration 44500, Testing net (#0)
I0927 05:15:34.012338 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:15:34.107605 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.524454 (* 1 = 0.524454 loss)
I0927 05:15:34.107641 19128 solver.cpp:580]     Test net output #1: prob = 0.847301
I0927 05:15:34.401204 19128 solver.cpp:357] Iteration 44500 (1.54195 iter/s, 64.853s/100 iters), loss = 0.0365639
I0927 05:15:34.401268 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.036564 (* 1 = 0.036564 loss)
I0927 05:15:34.401278 19128 sgd_solver.cpp:165] Iteration 44500, lr = 0.01
I0927 05:15:44.270748 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:16:05.240684 19128 solver.cpp:357] Iteration 44600 (3.24252 iter/s, 30.8402s/100 iters), loss = 0.0573567
I0927 05:16:05.240753 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0573568 (* 1 = 0.0573568 loss)
I0927 05:16:05.240766 19128 sgd_solver.cpp:165] Iteration 44600, lr = 0.01
I0927 05:16:36.395871 19128 solver.cpp:357] Iteration 44700 (3.20966 iter/s, 31.1559s/100 iters), loss = 0.10385
I0927 05:16:36.395978 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.10385 (* 1 = 0.10385 loss)
I0927 05:16:36.395989 19128 sgd_solver.cpp:165] Iteration 44700, lr = 0.01
I0927 05:17:12.447600 19128 solver.cpp:357] Iteration 44800 (2.77373 iter/s, 36.0526s/100 iters), loss = 0.0758199
I0927 05:17:12.447845 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.07582 (* 1 = 0.07582 loss)
I0927 05:17:12.447856 19128 sgd_solver.cpp:165] Iteration 44800, lr = 0.01
I0927 05:17:48.487151 19128 solver.cpp:357] Iteration 44900 (2.77501 iter/s, 36.0358s/100 iters), loss = 0.149276
I0927 05:17:48.487331 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.149276 (* 1 = 0.149276 loss)
I0927 05:17:48.487344 19128 sgd_solver.cpp:165] Iteration 44900, lr = 0.01
I0927 05:17:54.627255 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:18:24.187065 19128 solver.cpp:514] Iteration 45000, Testing net (#0)
I0927 05:18:52.595398 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:18:52.688028 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.404223 (* 1 = 0.404223 loss)
I0927 05:18:52.688064 19128 solver.cpp:580]     Test net output #1: prob = 0.881602
I0927 05:18:53.020532 19128 solver.cpp:357] Iteration 45000 (1.54978 iter/s, 64.5255s/100 iters), loss = 0.0956915
I0927 05:18:53.020589 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0956916 (* 1 = 0.0956916 loss)
I0927 05:18:53.020602 19128 sgd_solver.cpp:165] Iteration 45000, lr = 0.01
I0927 05:19:23.921918 19128 solver.cpp:357] Iteration 45100 (3.23637 iter/s, 30.8988s/100 iters), loss = 0.104187
I0927 05:19:23.922031 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.104187 (* 1 = 0.104187 loss)
I0927 05:19:23.922042 19128 sgd_solver.cpp:165] Iteration 45100, lr = 0.01
I0927 05:19:54.679535 19128 solver.cpp:357] Iteration 45200 (3.25149 iter/s, 30.7552s/100 iters), loss = 0.118407
I0927 05:19:54.679683 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.118407 (* 1 = 0.118407 loss)
I0927 05:19:54.679693 19128 sgd_solver.cpp:165] Iteration 45200, lr = 0.01
I0927 05:20:30.841545 19128 solver.cpp:357] Iteration 45300 (2.76558 iter/s, 36.1588s/100 iters), loss = 0.12407
I0927 05:20:30.841712 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.12407 (* 1 = 0.12407 loss)
I0927 05:20:30.841724 19128 sgd_solver.cpp:165] Iteration 45300, lr = 0.01
I0927 05:20:33.742596 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:21:06.891532 19128 solver.cpp:357] Iteration 45400 (2.77428 iter/s, 36.0455s/100 iters), loss = 0.0804868
I0927 05:21:06.891683 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.080487 (* 1 = 0.080487 loss)
I0927 05:21:06.891695 19128 sgd_solver.cpp:165] Iteration 45400, lr = 0.01
I0927 05:21:42.592883 19128 solver.cpp:514] Iteration 45500, Testing net (#0)
I0927 05:22:11.277837 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:22:11.410228 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.367565 (* 1 = 0.367565 loss)
I0927 05:22:11.410256 19128 solver.cpp:580]     Test net output #1: prob = 0.885301
I0927 05:22:11.678776 19128 solver.cpp:357] Iteration 45500 (1.54361 iter/s, 64.7833s/100 iters), loss = 0.113541
I0927 05:22:11.678843 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.113541 (* 1 = 0.113541 loss)
I0927 05:22:11.678854 19128 sgd_solver.cpp:165] Iteration 45500, lr = 0.01
I0927 05:22:42.587467 19128 solver.cpp:357] Iteration 45600 (3.23552 iter/s, 30.907s/100 iters), loss = 0.0873825
I0927 05:22:42.587625 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0873826 (* 1 = 0.0873826 loss)
I0927 05:22:42.587635 19128 sgd_solver.cpp:165] Iteration 45600, lr = 0.01
I0927 05:23:13.203964 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:23:13.554685 19128 solver.cpp:357] Iteration 45700 (3.2294 iter/s, 30.9655s/100 iters), loss = 0.0500519
I0927 05:23:13.554761 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.050052 (* 1 = 0.050052 loss)
I0927 05:23:13.554772 19128 sgd_solver.cpp:165] Iteration 45700, lr = 0.01
I0927 05:23:49.589241 19128 solver.cpp:357] Iteration 45800 (2.77535 iter/s, 36.0315s/100 iters), loss = 0.0935263
I0927 05:23:49.589521 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0935264 (* 1 = 0.0935264 loss)
I0927 05:23:49.589581 19128 sgd_solver.cpp:165] Iteration 45800, lr = 0.01
I0927 05:24:25.753988 19128 solver.cpp:357] Iteration 45900 (2.76526 iter/s, 36.163s/100 iters), loss = 0.101243
I0927 05:24:25.754192 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.101243 (* 1 = 0.101243 loss)
I0927 05:24:25.754204 19128 sgd_solver.cpp:165] Iteration 45900, lr = 0.01
I0927 05:25:01.452005 19128 solver.cpp:514] Iteration 46000, Testing net (#0)
I0927 05:25:30.046524 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:25:30.180181 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.65358 (* 1 = 0.65358 loss)
I0927 05:25:30.180209 19128 solver.cpp:580]     Test net output #1: prob = 0.825901
I0927 05:25:30.457048 19128 solver.cpp:357] Iteration 46000 (1.5456 iter/s, 64.6996s/100 iters), loss = 0.0984486
I0927 05:25:30.457113 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0984487 (* 1 = 0.0984487 loss)
I0927 05:25:30.457124 19128 sgd_solver.cpp:165] Iteration 46000, lr = 0.01
I0927 05:25:58.383728 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:26:01.268805 19128 solver.cpp:357] Iteration 46100 (3.24586 iter/s, 30.8085s/100 iters), loss = 0.0962446
I0927 05:26:01.268869 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0962447 (* 1 = 0.0962447 loss)
I0927 05:26:01.268882 19128 sgd_solver.cpp:165] Iteration 46100, lr = 0.01
I0927 05:26:32.167549 19128 solver.cpp:357] Iteration 46200 (3.23671 iter/s, 30.8956s/100 iters), loss = 0.11605
I0927 05:26:32.167701 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.11605 (* 1 = 0.11605 loss)
I0927 05:26:32.167712 19128 sgd_solver.cpp:165] Iteration 46200, lr = 0.01
I0927 05:27:08.042480 19128 solver.cpp:357] Iteration 46300 (2.7876 iter/s, 35.8731s/100 iters), loss = 0.0490024
I0927 05:27:08.042635 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0490026 (* 1 = 0.0490026 loss)
I0927 05:27:08.042646 19128 sgd_solver.cpp:165] Iteration 46300, lr = 0.01
I0927 05:27:43.989383 19128 solver.cpp:357] Iteration 46400 (2.78201 iter/s, 35.9452s/100 iters), loss = 0.0849932
I0927 05:27:43.989507 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0849933 (* 1 = 0.0849933 loss)
I0927 05:27:43.989518 19128 sgd_solver.cpp:165] Iteration 46400, lr = 0.01
I0927 05:28:12.809077 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:28:19.619992 19128 solver.cpp:514] Iteration 46500, Testing net (#0)
I0927 05:28:48.161983 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:28:48.297348 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.598785 (* 1 = 0.598785 loss)
I0927 05:28:48.297379 19128 solver.cpp:580]     Test net output #1: prob = 0.826601
I0927 05:28:48.574533 19128 solver.cpp:357] Iteration 46500 (1.54843 iter/s, 64.5814s/100 iters), loss = 0.0341541
I0927 05:28:48.574599 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0341543 (* 1 = 0.0341543 loss)
I0927 05:28:48.574615 19128 sgd_solver.cpp:165] Iteration 46500, lr = 0.01
I0927 05:29:19.489454 19128 solver.cpp:357] Iteration 46600 (3.23499 iter/s, 30.912s/100 iters), loss = 0.0948221
I0927 05:29:19.489562 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0948222 (* 1 = 0.0948222 loss)
I0927 05:29:19.489573 19128 sgd_solver.cpp:165] Iteration 46600, lr = 0.01
I0927 05:29:50.471499 19128 solver.cpp:357] Iteration 46700 (3.22776 iter/s, 30.9813s/100 iters), loss = 0.101939
I0927 05:29:50.471606 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.101939 (* 1 = 0.101939 loss)
I0927 05:29:50.471616 19128 sgd_solver.cpp:165] Iteration 46700, lr = 0.01
I0927 05:30:26.532205 19128 solver.cpp:357] Iteration 46800 (2.77316 iter/s, 36.0599s/100 iters), loss = 0.0753534
I0927 05:30:26.532372 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0753535 (* 1 = 0.0753535 loss)
I0927 05:30:26.532384 19128 sgd_solver.cpp:165] Iteration 46800, lr = 0.01
I0927 05:30:51.783321 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:31:02.575317 19128 solver.cpp:357] Iteration 46900 (2.77467 iter/s, 36.0403s/100 iters), loss = 0.119019
I0927 05:31:02.575510 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.11902 (* 1 = 0.11902 loss)
I0927 05:31:02.575520 19128 sgd_solver.cpp:165] Iteration 46900, lr = 0.01
I0927 05:31:38.276839 19128 solver.cpp:514] Iteration 47000, Testing net (#0)
I0927 05:32:06.944303 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:32:07.088963 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.568408 (* 1 = 0.568408 loss)
I0927 05:32:07.088990 19128 solver.cpp:580]     Test net output #1: prob = 0.852401
I0927 05:32:07.355892 19128 solver.cpp:357] Iteration 47000 (1.54372 iter/s, 64.7785s/100 iters), loss = 0.0793445
I0927 05:32:07.355953 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0793446 (* 1 = 0.0793446 loss)
I0927 05:32:07.355964 19128 sgd_solver.cpp:165] Iteration 47000, lr = 0.01
I0927 05:32:38.286916 19128 solver.cpp:357] Iteration 47100 (3.23327 iter/s, 30.9284s/100 iters), loss = 0.0743133
I0927 05:32:38.287055 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0743134 (* 1 = 0.0743134 loss)
I0927 05:32:38.287066 19128 sgd_solver.cpp:165] Iteration 47100, lr = 0.01
I0927 05:33:09.414039 19128 solver.cpp:357] Iteration 47200 (3.2127 iter/s, 31.1265s/100 iters), loss = 0.0921528
I0927 05:33:09.414209 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0921529 (* 1 = 0.0921529 loss)
I0927 05:33:09.414222 19128 sgd_solver.cpp:165] Iteration 47200, lr = 0.01
I0927 05:33:31.420577 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:33:45.444615 19128 solver.cpp:357] Iteration 47300 (2.77562 iter/s, 36.028s/100 iters), loss = 0.101141
I0927 05:33:45.444914 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.101141 (* 1 = 0.101141 loss)
I0927 05:33:45.444926 19128 sgd_solver.cpp:165] Iteration 47300, lr = 0.01
I0927 05:34:21.491169 19128 solver.cpp:357] Iteration 47400 (2.77439 iter/s, 36.044s/100 iters), loss = 0.0817645
I0927 05:34:21.491302 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0817647 (* 1 = 0.0817647 loss)
I0927 05:34:21.491313 19128 sgd_solver.cpp:165] Iteration 47400, lr = 0.01
I0927 05:34:57.206856 19128 solver.cpp:514] Iteration 47500, Testing net (#0)
I0927 05:35:26.022238 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:35:26.100154 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.402751 (* 1 = 0.402751 loss)
I0927 05:35:26.100188 19128 solver.cpp:580]     Test net output #1: prob = 0.881302
I0927 05:35:26.413080 19128 solver.cpp:357] Iteration 47500 (1.54033 iter/s, 64.9212s/100 iters), loss = 0.0853874
I0927 05:35:26.413136 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0853875 (* 1 = 0.0853875 loss)
I0927 05:35:26.413148 19128 sgd_solver.cpp:165] Iteration 47500, lr = 0.01
I0927 05:35:57.199237 19128 solver.cpp:357] Iteration 47600 (3.24825 iter/s, 30.7858s/100 iters), loss = 0.0847333
I0927 05:35:57.199409 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0847334 (* 1 = 0.0847334 loss)
I0927 05:35:57.199420 19128 sgd_solver.cpp:165] Iteration 47600, lr = 0.01
I0927 05:36:11.087610 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:36:28.368968 19128 solver.cpp:357] Iteration 47700 (3.20839 iter/s, 31.1683s/100 iters), loss = 0.0428292
I0927 05:36:28.369117 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0428293 (* 1 = 0.0428293 loss)
I0927 05:36:28.369127 19128 sgd_solver.cpp:165] Iteration 47700, lr = 0.01
I0927 05:37:04.422253 19128 solver.cpp:357] Iteration 47800 (2.7737 iter/s, 36.0529s/100 iters), loss = 0.0919146
I0927 05:37:04.422372 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0919147 (* 1 = 0.0919147 loss)
I0927 05:37:04.422384 19128 sgd_solver.cpp:165] Iteration 47800, lr = 0.01
I0927 05:37:40.455235 19128 solver.cpp:357] Iteration 47900 (2.7753 iter/s, 36.0322s/100 iters), loss = 0.138026
I0927 05:37:40.455410 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.138026 (* 1 = 0.138026 loss)
I0927 05:37:40.455421 19128 sgd_solver.cpp:165] Iteration 47900, lr = 0.01
I0927 05:38:16.148154 19128 solver.cpp:514] Iteration 48000, Testing net (#0)
I0927 05:38:44.787703 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:38:44.916673 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.692738 (* 1 = 0.692738 loss)
I0927 05:38:44.916702 19128 solver.cpp:580]     Test net output #1: prob = 0.8238
I0927 05:38:45.192591 19128 solver.cpp:357] Iteration 48000 (1.54476 iter/s, 64.7349s/100 iters), loss = 0.149027
I0927 05:38:45.192662 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.149027 (* 1 = 0.149027 loss)
I0927 05:38:45.192670 19128 sgd_solver.cpp:64] MultiStep Status: Iteration 48000, step = 2
I0927 05:38:45.192677 19128 sgd_solver.cpp:165] Iteration 48000, lr = 0.001
I0927 05:39:00.395052 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:39:15.874562 19128 solver.cpp:357] Iteration 48100 (3.25949 iter/s, 30.6797s/100 iters), loss = 0.0473414
I0927 05:39:15.874630 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0473415 (* 1 = 0.0473415 loss)
I0927 05:39:15.874641 19128 sgd_solver.cpp:165] Iteration 48100, lr = 0.001
I0927 05:39:46.741771 19128 solver.cpp:357] Iteration 48200 (3.23971 iter/s, 30.867s/100 iters), loss = 0.0502918
I0927 05:39:46.741904 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0502919 (* 1 = 0.0502919 loss)
I0927 05:39:46.741914 19128 sgd_solver.cpp:165] Iteration 48200, lr = 0.001
I0927 05:40:22.768684 19128 solver.cpp:357] Iteration 48300 (2.77572 iter/s, 36.0267s/100 iters), loss = 0.0757842
I0927 05:40:22.768930 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0757843 (* 1 = 0.0757843 loss)
I0927 05:40:22.768941 19128 sgd_solver.cpp:165] Iteration 48300, lr = 0.001
I0927 05:40:58.827461 19128 solver.cpp:357] Iteration 48400 (2.77332 iter/s, 36.0579s/100 iters), loss = 0.0593428
I0927 05:40:58.827602 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0593429 (* 1 = 0.0593429 loss)
I0927 05:40:58.827612 19128 sgd_solver.cpp:165] Iteration 48400, lr = 0.001
I0927 05:41:10.745630 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:41:34.523499 19128 solver.cpp:514] Iteration 48500, Testing net (#0)
I0927 05:42:02.885058 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:42:02.987087 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.299489 (* 1 = 0.299489 loss)
I0927 05:42:02.987113 19128 solver.cpp:580]     Test net output #1: prob = 0.910402
I0927 05:42:03.264045 19128 solver.cpp:357] Iteration 48500 (1.55192 iter/s, 64.4363s/100 iters), loss = 0.0525038
I0927 05:42:03.264109 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0525039 (* 1 = 0.0525039 loss)
I0927 05:42:03.264122 19128 sgd_solver.cpp:165] Iteration 48500, lr = 0.001
I0927 05:42:34.486826 19128 solver.cpp:357] Iteration 48600 (3.20302 iter/s, 31.2206s/100 iters), loss = 0.0509644
I0927 05:42:34.486984 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0509645 (* 1 = 0.0509645 loss)
I0927 05:42:34.486994 19128 sgd_solver.cpp:165] Iteration 48600, lr = 0.001
I0927 05:43:05.307467 19128 solver.cpp:357] Iteration 48700 (3.2446 iter/s, 30.8204s/100 iters), loss = 0.0242132
I0927 05:43:05.307571 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0242132 (* 1 = 0.0242132 loss)
I0927 05:43:05.307581 19128 sgd_solver.cpp:165] Iteration 48700, lr = 0.001
I0927 05:43:41.348953 19128 solver.cpp:357] Iteration 48800 (2.77459 iter/s, 36.0413s/100 iters), loss = 0.0387712
I0927 05:43:41.349086 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0387713 (* 1 = 0.0387713 loss)
I0927 05:43:41.349097 19128 sgd_solver.cpp:165] Iteration 48800, lr = 0.001
I0927 05:43:50.009564 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:44:17.209352 19128 solver.cpp:357] Iteration 48900 (2.78869 iter/s, 35.8591s/100 iters), loss = 0.0470602
I0927 05:44:17.209472 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0470603 (* 1 = 0.0470603 loss)
I0927 05:44:17.209483 19128 sgd_solver.cpp:165] Iteration 48900, lr = 0.001
I0927 05:44:52.804013 19128 solver.cpp:514] Iteration 49000, Testing net (#0)
I0927 05:45:21.379755 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:45:21.496129 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.272295 (* 1 = 0.272295 loss)
I0927 05:45:21.496158 19128 solver.cpp:580]     Test net output #1: prob = 0.918502
I0927 05:45:21.785050 19128 solver.cpp:357] Iteration 49000 (1.54862 iter/s, 64.5735s/100 iters), loss = 0.0420576
I0927 05:45:21.785115 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0420577 (* 1 = 0.0420577 loss)
I0927 05:45:21.785127 19128 sgd_solver.cpp:165] Iteration 49000, lr = 0.001
I0927 05:45:52.930853 19128 solver.cpp:357] Iteration 49100 (3.21093 iter/s, 31.1437s/100 iters), loss = 0.016799
I0927 05:45:52.930990 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0167991 (* 1 = 0.0167991 loss)
I0927 05:45:52.931002 19128 sgd_solver.cpp:165] Iteration 49100, lr = 0.001
I0927 05:46:23.653764 19128 solver.cpp:357] Iteration 49200 (3.25492 iter/s, 30.7228s/100 iters), loss = 0.0231889
I0927 05:46:23.653934 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.023189 (* 1 = 0.023189 loss)
I0927 05:46:23.653944 19128 sgd_solver.cpp:165] Iteration 49200, lr = 0.001
I0927 05:46:28.774497 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:46:59.791563 19128 solver.cpp:357] Iteration 49300 (2.76735 iter/s, 36.1357s/100 iters), loss = 0.0458234
I0927 05:46:59.791672 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0458235 (* 1 = 0.0458235 loss)
I0927 05:46:59.791683 19128 sgd_solver.cpp:165] Iteration 49300, lr = 0.001
I0927 05:47:35.841892 19128 solver.cpp:357] Iteration 49400 (2.77391 iter/s, 36.0502s/100 iters), loss = 0.0440182
I0927 05:47:35.841998 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0440183 (* 1 = 0.0440183 loss)
I0927 05:47:35.842010 19128 sgd_solver.cpp:165] Iteration 49400, lr = 0.001
I0927 05:48:11.523828 19128 solver.cpp:514] Iteration 49500, Testing net (#0)
I0927 05:48:39.931082 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:48:40.011701 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.262581 (* 1 = 0.262581 loss)
I0927 05:48:40.011730 19128 solver.cpp:580]     Test net output #1: prob = 0.922002
I0927 05:48:40.353258 19128 solver.cpp:357] Iteration 49500 (1.55011 iter/s, 64.5114s/100 iters), loss = 0.0380626
I0927 05:48:40.353309 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0380627 (* 1 = 0.0380627 loss)
I0927 05:48:40.353322 19128 sgd_solver.cpp:165] Iteration 49500, lr = 0.001
I0927 05:49:11.527815 19128 solver.cpp:357] Iteration 49600 (3.20775 iter/s, 31.1745s/100 iters), loss = 0.0310444
I0927 05:49:11.527956 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0310445 (* 1 = 0.0310445 loss)
I0927 05:49:11.527969 19128 sgd_solver.cpp:165] Iteration 49600, lr = 0.001
I0927 05:49:12.868211 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:49:42.349854 19128 solver.cpp:357] Iteration 49700 (3.24444 iter/s, 30.8219s/100 iters), loss = 0.0228135
I0927 05:49:42.350065 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0228136 (* 1 = 0.0228136 loss)
I0927 05:49:42.350076 19128 sgd_solver.cpp:165] Iteration 49700, lr = 0.001
I0927 05:50:18.388850 19128 solver.cpp:357] Iteration 49800 (2.7748 iter/s, 36.0387s/100 iters), loss = 0.0341308
I0927 05:50:18.388979 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.034131 (* 1 = 0.034131 loss)
I0927 05:50:18.388989 19128 sgd_solver.cpp:165] Iteration 49800, lr = 0.001
I0927 05:50:54.451391 19128 solver.cpp:357] Iteration 49900 (2.77308 iter/s, 36.061s/100 iters), loss = 0.0267977
I0927 05:50:54.451499 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0267979 (* 1 = 0.0267979 loss)
I0927 05:50:54.451510 19128 sgd_solver.cpp:165] Iteration 49900, lr = 0.001
I0927 05:51:28.719357 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:51:30.149703 19128 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_50000.caffemodel
I0927 05:51:30.166669 19128 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_50000.solverstate
I0927 05:51:30.172211 19128 solver.cpp:514] Iteration 50000, Testing net (#0)
I0927 05:51:58.924993 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:51:59.032662 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.254399 (* 1 = 0.254399 loss)
I0927 05:51:59.032698 19128 solver.cpp:580]     Test net output #1: prob = 0.925802
I0927 05:51:59.320104 19128 solver.cpp:357] Iteration 50000 (1.54146 iter/s, 64.8734s/100 iters), loss = 0.0421342
I0927 05:51:59.320170 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0421343 (* 1 = 0.0421343 loss)
I0927 05:51:59.320184 19128 sgd_solver.cpp:165] Iteration 50000, lr = 0.001
I0927 05:52:30.461750 19128 solver.cpp:357] Iteration 50100 (3.21077 iter/s, 31.1452s/100 iters), loss = 0.0205581
I0927 05:52:30.461908 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0205582 (* 1 = 0.0205582 loss)
I0927 05:52:30.461921 19128 sgd_solver.cpp:165] Iteration 50100, lr = 0.001
I0927 05:53:01.445947 19128 solver.cpp:357] Iteration 50200 (3.22732 iter/s, 30.9855s/100 iters), loss = 0.028113
I0927 05:53:01.446099 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0281131 (* 1 = 0.0281131 loss)
I0927 05:53:01.446110 19128 sgd_solver.cpp:165] Iteration 50200, lr = 0.001
I0927 05:53:37.478207 19128 solver.cpp:357] Iteration 50300 (2.77502 iter/s, 36.0358s/100 iters), loss = 0.0198488
I0927 05:53:37.478315 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0198489 (* 1 = 0.0198489 loss)
I0927 05:53:37.478327 19128 sgd_solver.cpp:165] Iteration 50300, lr = 0.001
I0927 05:54:08.488870 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:54:13.525723 19128 solver.cpp:357] Iteration 50400 (2.77385 iter/s, 36.0509s/100 iters), loss = 0.0334615
I0927 05:54:13.525789 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0334616 (* 1 = 0.0334616 loss)
I0927 05:54:13.525799 19128 sgd_solver.cpp:165] Iteration 50400, lr = 0.001
I0927 05:54:49.219035 19128 solver.cpp:514] Iteration 50500, Testing net (#0)
I0927 05:55:18.084214 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:55:18.218155 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.254374 (* 1 = 0.254374 loss)
I0927 05:55:18.218184 19128 solver.cpp:580]     Test net output #1: prob = 0.925502
I0927 05:55:18.488508 19128 solver.cpp:357] Iteration 50500 (1.5392 iter/s, 64.9686s/100 iters), loss = 0.0293683
I0927 05:55:18.488574 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0293685 (* 1 = 0.0293685 loss)
I0927 05:55:18.488585 19128 sgd_solver.cpp:165] Iteration 50500, lr = 0.001
I0927 05:55:49.321967 19128 solver.cpp:357] Iteration 50600 (3.24319 iter/s, 30.8339s/100 iters), loss = 0.081144
I0927 05:55:49.322080 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0811441 (* 1 = 0.0811441 loss)
I0927 05:55:49.322093 19128 sgd_solver.cpp:165] Iteration 50600, lr = 0.001
I0927 05:56:20.359181 19128 solver.cpp:357] Iteration 50700 (3.22169 iter/s, 31.0396s/100 iters), loss = 0.0179928
I0927 05:56:20.359345 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0179929 (* 1 = 0.0179929 loss)
I0927 05:56:20.359357 19128 sgd_solver.cpp:165] Iteration 50700, lr = 0.001
I0927 05:56:48.146108 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:56:56.411183 19128 solver.cpp:357] Iteration 50800 (2.77369 iter/s, 36.053s/100 iters), loss = 0.035975
I0927 05:56:56.411347 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0359751 (* 1 = 0.0359751 loss)
I0927 05:56:56.411358 19128 sgd_solver.cpp:165] Iteration 50800, lr = 0.001
I0927 05:57:32.456233 19128 solver.cpp:357] Iteration 50900 (2.77427 iter/s, 36.0455s/100 iters), loss = 0.0244161
I0927 05:57:32.456413 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0244162 (* 1 = 0.0244162 loss)
I0927 05:57:32.456425 19128 sgd_solver.cpp:165] Iteration 50900, lr = 0.001
I0927 05:58:08.162405 19128 solver.cpp:514] Iteration 51000, Testing net (#0)
I0927 05:58:36.993182 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:58:37.137349 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.260511 (* 1 = 0.260511 loss)
I0927 05:58:37.137378 19128 solver.cpp:580]     Test net output #1: prob = 0.926402
I0927 05:58:37.404104 19128 solver.cpp:357] Iteration 51000 (1.53964 iter/s, 64.9501s/100 iters), loss = 0.0246257
I0927 05:58:37.404167 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0246259 (* 1 = 0.0246259 loss)
I0927 05:58:37.404179 19128 sgd_solver.cpp:165] Iteration 51000, lr = 0.001
I0927 05:59:08.244184 19128 solver.cpp:357] Iteration 51100 (3.24256 iter/s, 30.8399s/100 iters), loss = 0.019198
I0927 05:59:08.244348 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0191981 (* 1 = 0.0191981 loss)
I0927 05:59:08.244359 19128 sgd_solver.cpp:165] Iteration 51100, lr = 0.001
I0927 05:59:27.436131 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 05:59:39.309545 19128 solver.cpp:357] Iteration 51200 (3.21884 iter/s, 31.067s/100 iters), loss = 0.0162229
I0927 05:59:39.309667 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0162231 (* 1 = 0.0162231 loss)
I0927 05:59:39.309679 19128 sgd_solver.cpp:165] Iteration 51200, lr = 0.001
I0927 06:00:15.379526 19128 solver.cpp:357] Iteration 51300 (2.7724 iter/s, 36.0699s/100 iters), loss = 0.0111054
I0927 06:00:15.379678 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0111055 (* 1 = 0.0111055 loss)
I0927 06:00:15.379689 19128 sgd_solver.cpp:165] Iteration 51300, lr = 0.001
I0927 06:00:51.428520 19128 solver.cpp:357] Iteration 51400 (2.77402 iter/s, 36.0488s/100 iters), loss = 0.0125396
I0927 06:00:51.428635 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0125398 (* 1 = 0.0125398 loss)
I0927 06:00:51.428645 19128 sgd_solver.cpp:165] Iteration 51400, lr = 0.001
I0927 06:01:27.131399 19128 solver.cpp:514] Iteration 51500, Testing net (#0)
I0927 06:01:55.642660 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:01:55.776216 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.264362 (* 1 = 0.264362 loss)
I0927 06:01:55.776245 19128 solver.cpp:580]     Test net output #1: prob = 0.925702
I0927 06:01:56.129551 19128 solver.cpp:357] Iteration 51500 (1.54549 iter/s, 64.7042s/100 iters), loss = 0.00557012
I0927 06:01:56.129621 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00557024 (* 1 = 0.00557024 loss)
I0927 06:01:56.129631 19128 sgd_solver.cpp:165] Iteration 51500, lr = 0.001
I0927 06:02:15.771028 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:02:26.902308 19128 solver.cpp:357] Iteration 51600 (3.2497 iter/s, 30.7721s/100 iters), loss = 0.0255615
I0927 06:02:26.902380 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0255616 (* 1 = 0.0255616 loss)
I0927 06:02:26.902391 19128 sgd_solver.cpp:165] Iteration 51600, lr = 0.001
I0927 06:02:57.976969 19128 solver.cpp:357] Iteration 51700 (3.21813 iter/s, 31.074s/100 iters), loss = 0.0308668
I0927 06:02:57.977124 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0308669 (* 1 = 0.0308669 loss)
I0927 06:02:57.977134 19128 sgd_solver.cpp:165] Iteration 51700, lr = 0.001
I0927 06:03:34.019029 19128 solver.cpp:357] Iteration 51800 (2.77443 iter/s, 36.0435s/100 iters), loss = 0.035546
I0927 06:03:34.019373 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0355462 (* 1 = 0.0355462 loss)
I0927 06:03:34.019438 19128 sgd_solver.cpp:165] Iteration 51800, lr = 0.001
I0927 06:04:09.966878 19128 solver.cpp:357] Iteration 51900 (2.78186 iter/s, 35.9472s/100 iters), loss = 0.0226187
I0927 06:04:09.966984 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0226188 (* 1 = 0.0226188 loss)
I0927 06:04:09.966994 19128 sgd_solver.cpp:165] Iteration 51900, lr = 0.001
I0927 06:04:27.656489 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:04:45.673164 19128 solver.cpp:514] Iteration 52000, Testing net (#0)
I0927 06:05:14.256628 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:05:14.356452 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.263237 (* 1 = 0.263237 loss)
I0927 06:05:14.356490 19128 solver.cpp:580]     Test net output #1: prob = 0.927202
I0927 06:05:14.647759 19128 solver.cpp:357] Iteration 52000 (1.54599 iter/s, 64.6834s/100 iters), loss = 0.0154344
I0927 06:05:14.647820 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0154346 (* 1 = 0.0154346 loss)
I0927 06:05:14.647832 19128 sgd_solver.cpp:165] Iteration 52000, lr = 0.001
I0927 06:05:45.608031 19128 solver.cpp:357] Iteration 52100 (3.22983 iter/s, 30.9614s/100 iters), loss = 0.0334996
I0927 06:05:45.608172 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0334997 (* 1 = 0.0334997 loss)
I0927 06:05:45.608184 19128 sgd_solver.cpp:165] Iteration 52100, lr = 0.001
I0927 06:06:16.513033 19128 solver.cpp:357] Iteration 52200 (3.23562 iter/s, 30.906s/100 iters), loss = 0.0143124
I0927 06:06:16.513144 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0143126 (* 1 = 0.0143126 loss)
I0927 06:06:16.513155 19128 sgd_solver.cpp:165] Iteration 52200, lr = 0.001
I0927 06:06:52.353752 19128 solver.cpp:357] Iteration 52300 (2.79019 iter/s, 35.8398s/100 iters), loss = 0.0171738
I0927 06:06:52.353968 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0171739 (* 1 = 0.0171739 loss)
I0927 06:06:52.353994 19128 sgd_solver.cpp:165] Iteration 52300, lr = 0.001
I0927 06:07:06.409828 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:07:28.216907 19128 solver.cpp:357] Iteration 52400 (2.7883 iter/s, 35.8642s/100 iters), loss = 0.0145828
I0927 06:07:28.217038 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.014583 (* 1 = 0.014583 loss)
I0927 06:07:28.217049 19128 sgd_solver.cpp:165] Iteration 52400, lr = 0.001
I0927 06:08:04.058463 19128 solver.cpp:514] Iteration 52500, Testing net (#0)
I0927 06:08:32.499188 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:08:32.632849 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.266697 (* 1 = 0.266697 loss)
I0927 06:08:32.632879 19128 solver.cpp:580]     Test net output #1: prob = 0.926902
I0927 06:08:32.899327 19128 solver.cpp:357] Iteration 52500 (1.54601 iter/s, 64.6824s/100 iters), loss = 0.0339843
I0927 06:08:32.899391 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0339844 (* 1 = 0.0339844 loss)
I0927 06:08:32.899401 19128 sgd_solver.cpp:165] Iteration 52500, lr = 0.001
I0927 06:09:03.898967 19128 solver.cpp:357] Iteration 52600 (3.22575 iter/s, 31.0005s/100 iters), loss = 0.0129279
I0927 06:09:03.899128 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.012928 (* 1 = 0.012928 loss)
I0927 06:09:03.899139 19128 sgd_solver.cpp:165] Iteration 52600, lr = 0.001
I0927 06:09:34.738929 19128 solver.cpp:357] Iteration 52700 (3.24247 iter/s, 30.8407s/100 iters), loss = 0.0139581
I0927 06:09:34.739049 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0139582 (* 1 = 0.0139582 loss)
I0927 06:09:34.739061 19128 sgd_solver.cpp:165] Iteration 52700, lr = 0.001
I0927 06:09:45.629259 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:10:10.832257 19128 solver.cpp:357] Iteration 52800 (2.77068 iter/s, 36.0923s/100 iters), loss = 0.0264455
I0927 06:10:10.832432 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0264456 (* 1 = 0.0264456 loss)
I0927 06:10:10.832443 19128 sgd_solver.cpp:165] Iteration 52800, lr = 0.001
I0927 06:10:46.903764 19128 solver.cpp:357] Iteration 52900 (2.77235 iter/s, 36.0704s/100 iters), loss = 0.0199712
I0927 06:10:46.903890 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0199713 (* 1 = 0.0199713 loss)
I0927 06:10:46.903901 19128 sgd_solver.cpp:165] Iteration 52900, lr = 0.001
I0927 06:11:22.620833 19128 solver.cpp:514] Iteration 53000, Testing net (#0)
I0927 06:11:51.382565 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:11:51.461961 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.258288 (* 1 = 0.258288 loss)
I0927 06:11:51.461994 19128 solver.cpp:580]     Test net output #1: prob = 0.929702
I0927 06:11:51.773090 19128 solver.cpp:357] Iteration 53000 (1.54157 iter/s, 64.869s/100 iters), loss = 0.0230773
I0927 06:11:51.773146 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0230774 (* 1 = 0.0230774 loss)
I0927 06:11:51.773156 19128 sgd_solver.cpp:165] Iteration 53000, lr = 0.001
I0927 06:12:22.678133 19128 solver.cpp:357] Iteration 53100 (3.23564 iter/s, 30.9058s/100 iters), loss = 0.0221678
I0927 06:12:22.678283 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0221679 (* 1 = 0.0221679 loss)
I0927 06:12:22.678294 19128 sgd_solver.cpp:165] Iteration 53100, lr = 0.001
I0927 06:12:28.052531 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:12:53.926280 19128 solver.cpp:357] Iteration 53200 (3.20012 iter/s, 31.2488s/100 iters), loss = 0.0124853
I0927 06:12:53.926403 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0124854 (* 1 = 0.0124854 loss)
I0927 06:12:53.926414 19128 sgd_solver.cpp:165] Iteration 53200, lr = 0.001
I0927 06:13:29.978056 19128 solver.cpp:357] Iteration 53300 (2.77373 iter/s, 36.0526s/100 iters), loss = 0.0119209
I0927 06:13:29.978219 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.011921 (* 1 = 0.011921 loss)
I0927 06:13:29.978229 19128 sgd_solver.cpp:165] Iteration 53300, lr = 0.001
I0927 06:14:06.048763 19128 solver.cpp:357] Iteration 53400 (2.77228 iter/s, 36.0715s/100 iters), loss = 0.00662886
I0927 06:14:06.048915 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00662897 (* 1 = 0.00662897 loss)
I0927 06:14:06.048926 19128 sgd_solver.cpp:165] Iteration 53400, lr = 0.001
I0927 06:14:41.742544 19128 solver.cpp:514] Iteration 53500, Testing net (#0)
I0927 06:15:10.351897 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:15:10.430397 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.267796 (* 1 = 0.267796 loss)
I0927 06:15:10.430431 19128 solver.cpp:580]     Test net output #1: prob = 0.926102
I0927 06:15:10.742215 19128 solver.cpp:357] Iteration 53500 (1.54572 iter/s, 64.6949s/100 iters), loss = 0.0439689
I0927 06:15:10.742269 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.043969 (* 1 = 0.043969 loss)
I0927 06:15:10.742278 19128 sgd_solver.cpp:165] Iteration 53500, lr = 0.001
I0927 06:15:14.836758 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:15:41.443426 19128 solver.cpp:357] Iteration 53600 (3.25713 iter/s, 30.7019s/100 iters), loss = 0.0129341
I0927 06:15:41.443497 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0129342 (* 1 = 0.0129342 loss)
I0927 06:15:41.443508 19128 sgd_solver.cpp:165] Iteration 53600, lr = 0.001
I0927 06:16:12.652792 19128 solver.cpp:357] Iteration 53700 (3.2041 iter/s, 31.21s/100 iters), loss = 0.0116207
I0927 06:16:12.652966 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0116208 (* 1 = 0.0116208 loss)
I0927 06:16:12.652977 19128 sgd_solver.cpp:165] Iteration 53700, lr = 0.001
I0927 06:16:48.716572 19128 solver.cpp:357] Iteration 53800 (2.77297 iter/s, 36.0625s/100 iters), loss = 0.0287996
I0927 06:16:48.716683 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0287997 (* 1 = 0.0287997 loss)
I0927 06:16:48.716696 19128 sgd_solver.cpp:165] Iteration 53800, lr = 0.001
I0927 06:17:24.759589 19128 solver.cpp:357] Iteration 53900 (2.77441 iter/s, 36.0437s/100 iters), loss = 0.025285
I0927 06:17:24.759713 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0252851 (* 1 = 0.0252851 loss)
I0927 06:17:24.759723 19128 sgd_solver.cpp:165] Iteration 53900, lr = 0.001
I0927 06:17:25.499302 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:18:00.454110 19128 solver.cpp:514] Iteration 54000, Testing net (#0)
I0927 06:18:28.933107 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:18:29.060236 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.263159 (* 1 = 0.263159 loss)
I0927 06:18:29.060266 19128 solver.cpp:580]     Test net output #1: prob = 0.929102
I0927 06:18:29.328151 19128 solver.cpp:357] Iteration 54000 (1.54871 iter/s, 64.5699s/100 iters), loss = 0.00605066
I0927 06:18:29.328210 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00605076 (* 1 = 0.00605076 loss)
I0927 06:18:29.328222 19128 sgd_solver.cpp:165] Iteration 54000, lr = 0.001
I0927 06:19:00.037539 19128 solver.cpp:357] Iteration 54100 (3.25627 iter/s, 30.71s/100 iters), loss = 0.0223432
I0927 06:19:00.037748 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0223433 (* 1 = 0.0223433 loss)
I0927 06:19:00.037760 19128 sgd_solver.cpp:165] Iteration 54100, lr = 0.001
I0927 06:19:31.031904 19128 solver.cpp:357] Iteration 54200 (3.22635 iter/s, 30.9948s/100 iters), loss = 0.0185282
I0927 06:19:31.032065 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0185283 (* 1 = 0.0185283 loss)
I0927 06:19:31.032076 19128 sgd_solver.cpp:165] Iteration 54200, lr = 0.001
I0927 06:20:04.218763 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:20:07.089563 19128 solver.cpp:357] Iteration 54300 (2.77333 iter/s, 36.0578s/100 iters), loss = 0.0265616
I0927 06:20:07.089645 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0265617 (* 1 = 0.0265617 loss)
I0927 06:20:07.089656 19128 sgd_solver.cpp:165] Iteration 54300, lr = 0.001
I0927 06:20:43.119616 19128 solver.cpp:357] Iteration 54400 (2.77553 iter/s, 36.0291s/100 iters), loss = 0.0255347
I0927 06:20:43.119773 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0255348 (* 1 = 0.0255348 loss)
I0927 06:20:43.119784 19128 sgd_solver.cpp:165] Iteration 54400, lr = 0.001
I0927 06:21:18.824195 19128 solver.cpp:514] Iteration 54500, Testing net (#0)
I0927 06:21:47.577615 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:21:47.708823 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.264045 (* 1 = 0.264045 loss)
I0927 06:21:47.708853 19128 solver.cpp:580]     Test net output #1: prob = 0.927802
I0927 06:21:47.986837 19128 solver.cpp:357] Iteration 54500 (1.54158 iter/s, 64.8684s/100 iters), loss = 0.0069986
I0927 06:21:47.986908 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00699869 (* 1 = 0.00699869 loss)
I0927 06:21:47.986919 19128 sgd_solver.cpp:165] Iteration 54500, lr = 0.001
I0927 06:22:18.887418 19128 solver.cpp:357] Iteration 54600 (3.23635 iter/s, 30.899s/100 iters), loss = 0.0167165
I0927 06:22:18.887537 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0167166 (* 1 = 0.0167166 loss)
I0927 06:22:18.887549 19128 sgd_solver.cpp:165] Iteration 54600, lr = 0.001
I0927 06:22:44.124927 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:22:50.140558 19128 solver.cpp:357] Iteration 54700 (3.19983 iter/s, 31.2516s/100 iters), loss = 0.0135981
I0927 06:22:50.140727 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0135981 (* 1 = 0.0135981 loss)
I0927 06:22:50.140738 19128 sgd_solver.cpp:165] Iteration 54700, lr = 0.001
I0927 06:23:26.197525 19128 solver.cpp:357] Iteration 54800 (2.7735 iter/s, 36.0555s/100 iters), loss = 0.00840121
I0927 06:23:26.197640 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00840129 (* 1 = 0.00840129 loss)
I0927 06:23:26.197651 19128 sgd_solver.cpp:165] Iteration 54800, lr = 0.001
I0927 06:24:01.991132 19128 solver.cpp:357] Iteration 54900 (2.79377 iter/s, 35.7939s/100 iters), loss = 0.0115515
I0927 06:24:01.991241 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0115516 (* 1 = 0.0115516 loss)
I0927 06:24:01.991257 19128 sgd_solver.cpp:165] Iteration 54900, lr = 0.001
I0927 06:24:37.746181 19128 solver.cpp:514] Iteration 55000, Testing net (#0)
I0927 06:25:06.446350 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:25:06.569175 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.268121 (* 1 = 0.268121 loss)
I0927 06:25:06.569200 19128 solver.cpp:580]     Test net output #1: prob = 0.926303
I0927 06:25:06.857460 19128 solver.cpp:357] Iteration 55000 (1.5416 iter/s, 64.8675s/100 iters), loss = 0.0173466
I0927 06:25:06.857522 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0173466 (* 1 = 0.0173466 loss)
I0927 06:25:06.857532 19128 sgd_solver.cpp:165] Iteration 55000, lr = 0.001
I0927 06:25:30.622680 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:25:37.544427 19128 solver.cpp:357] Iteration 55100 (3.25891 iter/s, 30.6851s/100 iters), loss = 0.0210537
I0927 06:25:37.544497 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0210538 (* 1 = 0.0210538 loss)
I0927 06:25:37.544508 19128 sgd_solver.cpp:165] Iteration 55100, lr = 0.001
I0927 06:26:08.946826 19128 solver.cpp:357] Iteration 55200 (3.18454 iter/s, 31.4017s/100 iters), loss = 0.0142411
I0927 06:26:08.946957 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0142411 (* 1 = 0.0142411 loss)
I0927 06:26:08.946969 19128 sgd_solver.cpp:165] Iteration 55200, lr = 0.001
I0927 06:26:45.013165 19128 solver.cpp:357] Iteration 55300 (2.77288 iter/s, 36.0636s/100 iters), loss = 0.0218573
I0927 06:26:45.013275 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0218574 (* 1 = 0.0218574 loss)
I0927 06:26:45.013285 19128 sgd_solver.cpp:165] Iteration 55300, lr = 0.001
I0927 06:27:21.040881 19128 solver.cpp:357] Iteration 55400 (2.77575 iter/s, 36.0262s/100 iters), loss = 0.0162491
I0927 06:27:21.040992 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0162492 (* 1 = 0.0162492 loss)
I0927 06:27:21.041002 19128 sgd_solver.cpp:165] Iteration 55400, lr = 0.001
I0927 06:27:44.123666 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:27:56.735085 19128 solver.cpp:514] Iteration 55500, Testing net (#0)
I0927 06:28:25.487943 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:28:25.595461 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.268099 (* 1 = 0.268099 loss)
I0927 06:28:25.595520 19128 solver.cpp:580]     Test net output #1: prob = 0.929102
I0927 06:28:25.909246 19128 solver.cpp:357] Iteration 55500 (1.5416 iter/s, 64.8675s/100 iters), loss = 0.0200657
I0927 06:28:25.909301 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0200658 (* 1 = 0.0200658 loss)
I0927 06:28:25.909312 19128 sgd_solver.cpp:165] Iteration 55500, lr = 0.001
I0927 06:28:56.372787 19128 solver.cpp:357] Iteration 55600 (3.28265 iter/s, 30.4632s/100 iters), loss = 0.00473865
I0927 06:28:56.372901 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0047387 (* 1 = 0.0047387 loss)
I0927 06:28:56.372913 19128 sgd_solver.cpp:165] Iteration 55600, lr = 0.001
I0927 06:29:27.931069 19128 solver.cpp:357] Iteration 55700 (3.16878 iter/s, 31.5579s/100 iters), loss = 0.0187108
I0927 06:29:27.931190 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0187109 (* 1 = 0.0187109 loss)
I0927 06:29:27.931201 19128 sgd_solver.cpp:165] Iteration 55700, lr = 0.001
I0927 06:30:03.988526 19128 solver.cpp:357] Iteration 55800 (2.77354 iter/s, 36.0551s/100 iters), loss = 0.00910648
I0927 06:30:03.988646 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00910653 (* 1 = 0.00910653 loss)
I0927 06:30:03.988657 19128 sgd_solver.cpp:165] Iteration 55800, lr = 0.001
I0927 06:30:23.823577 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:30:40.039016 19128 solver.cpp:357] Iteration 55900 (2.77392 iter/s, 36.0501s/100 iters), loss = 0.0233874
I0927 06:30:40.039259 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0233874 (* 1 = 0.0233874 loss)
I0927 06:30:40.039270 19128 sgd_solver.cpp:165] Iteration 55900, lr = 0.001
I0927 06:31:15.731182 19128 solver.cpp:514] Iteration 56000, Testing net (#0)
I0927 06:31:44.340667 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:31:44.473212 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.273419 (* 1 = 0.273419 loss)
I0927 06:31:44.473249 19128 solver.cpp:580]     Test net output #1: prob = 0.927102
I0927 06:31:44.772397 19128 solver.cpp:357] Iteration 56000 (1.54482 iter/s, 64.7324s/100 iters), loss = 0.0272544
I0927 06:31:44.772467 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0272544 (* 1 = 0.0272544 loss)
I0927 06:31:44.772478 19128 sgd_solver.cpp:165] Iteration 56000, lr = 0.001
I0927 06:32:15.266816 19128 solver.cpp:357] Iteration 56100 (3.27953 iter/s, 30.4922s/100 iters), loss = 0.0127943
I0927 06:32:15.267056 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0127943 (* 1 = 0.0127943 loss)
I0927 06:32:15.267071 19128 sgd_solver.cpp:165] Iteration 56100, lr = 0.001
I0927 06:32:46.780392 19128 solver.cpp:357] Iteration 56200 (3.17346 iter/s, 31.5114s/100 iters), loss = 0.00864372
I0927 06:32:46.780537 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00864376 (* 1 = 0.00864376 loss)
I0927 06:32:46.780549 19128 sgd_solver.cpp:165] Iteration 56200, lr = 0.001
I0927 06:33:03.081321 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:33:22.899300 19128 solver.cpp:357] Iteration 56300 (2.7688 iter/s, 36.1167s/100 iters), loss = 0.00551339
I0927 06:33:22.899411 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00551342 (* 1 = 0.00551342 loss)
I0927 06:33:22.899421 19128 sgd_solver.cpp:165] Iteration 56300, lr = 0.001
I0927 06:33:58.937301 19128 solver.cpp:357] Iteration 56400 (2.77492 iter/s, 36.037s/100 iters), loss = 0.0128962
I0927 06:33:58.937412 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0128962 (* 1 = 0.0128962 loss)
I0927 06:33:58.937422 19128 sgd_solver.cpp:165] Iteration 56400, lr = 0.001
I0927 06:34:34.617693 19128 solver.cpp:514] Iteration 56500, Testing net (#0)
I0927 06:35:03.394166 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:35:03.466697 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.275335 (* 1 = 0.275335 loss)
I0927 06:35:03.466729 19128 solver.cpp:580]     Test net output #1: prob = 0.928303
I0927 06:35:03.821281 19128 solver.cpp:357] Iteration 56500 (1.54121 iter/s, 64.884s/100 iters), loss = 0.0129805
I0927 06:35:03.821346 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0129805 (* 1 = 0.0129805 loss)
I0927 06:35:03.821359 19128 sgd_solver.cpp:165] Iteration 56500, lr = 0.001
I0927 06:35:34.053447 19128 solver.cpp:357] Iteration 56600 (3.30784 iter/s, 30.2312s/100 iters), loss = 0.0083638
I0927 06:35:34.053570 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00836383 (* 1 = 0.00836383 loss)
I0927 06:35:34.053580 19128 sgd_solver.cpp:165] Iteration 56600, lr = 0.001
I0927 06:35:43.707383 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:36:05.851358 19128 solver.cpp:357] Iteration 56700 (3.14486 iter/s, 31.7979s/100 iters), loss = 0.0169886
I0927 06:36:05.851464 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0169887 (* 1 = 0.0169887 loss)
I0927 06:36:05.851475 19128 sgd_solver.cpp:165] Iteration 56700, lr = 0.001
I0927 06:36:41.878485 19128 solver.cpp:357] Iteration 56800 (2.77574 iter/s, 36.0264s/100 iters), loss = 0.0298792
I0927 06:36:41.878634 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0298792 (* 1 = 0.0298792 loss)
I0927 06:36:41.878644 19128 sgd_solver.cpp:165] Iteration 56800, lr = 0.001
I0927 06:37:17.931533 19128 solver.cpp:357] Iteration 56900 (2.77369 iter/s, 36.0531s/100 iters), loss = 0.0293287
I0927 06:37:17.931658 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0293287 (* 1 = 0.0293287 loss)
I0927 06:37:17.931671 19128 sgd_solver.cpp:165] Iteration 56900, lr = 0.001
I0927 06:37:53.609292 19128 solver.cpp:514] Iteration 57000, Testing net (#0)
I0927 06:38:22.292454 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:38:22.432924 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.274906 (* 1 = 0.274906 loss)
I0927 06:38:22.432953 19128 solver.cpp:580]     Test net output #1: prob = 0.928702
I0927 06:38:22.696264 19128 solver.cpp:357] Iteration 57000 (1.54409 iter/s, 64.763s/100 iters), loss = 0.0258967
I0927 06:38:22.696328 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0258967 (* 1 = 0.0258967 loss)
I0927 06:38:22.696341 19128 sgd_solver.cpp:165] Iteration 57000, lr = 0.001
I0927 06:38:32.417662 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:38:52.749876 19128 solver.cpp:357] Iteration 57100 (3.3276 iter/s, 30.0517s/100 iters), loss = 0.0362869
I0927 06:38:52.749939 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0362869 (* 1 = 0.0362869 loss)
I0927 06:38:52.749951 19128 sgd_solver.cpp:165] Iteration 57100, lr = 0.001
I0927 06:39:24.176983 19128 solver.cpp:357] Iteration 57200 (3.18195 iter/s, 31.4272s/100 iters), loss = 0.0212264
I0927 06:39:24.177160 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0212264 (* 1 = 0.0212264 loss)
I0927 06:39:24.177170 19128 sgd_solver.cpp:165] Iteration 57200, lr = 0.001
I0927 06:40:00.268859 19128 solver.cpp:357] Iteration 57300 (2.77085 iter/s, 36.09s/100 iters), loss = 0.00918515
I0927 06:40:00.269012 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00918518 (* 1 = 0.00918518 loss)
I0927 06:40:00.269023 19128 sgd_solver.cpp:165] Iteration 57300, lr = 0.001
I0927 06:40:36.335548 19128 solver.cpp:357] Iteration 57400 (2.77263 iter/s, 36.0668s/100 iters), loss = 0.0103969
I0927 06:40:36.335664 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0103969 (* 1 = 0.0103969 loss)
I0927 06:40:36.335675 19128 sgd_solver.cpp:165] Iteration 57400, lr = 0.001
I0927 06:40:42.472532 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:41:12.022737 19128 solver.cpp:514] Iteration 57500, Testing net (#0)
I0927 06:41:40.482336 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:41:40.616773 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.272949 (* 1 = 0.272949 loss)
I0927 06:41:40.616809 19128 solver.cpp:580]     Test net output #1: prob = 0.927102
I0927 06:41:40.916482 19128 solver.cpp:357] Iteration 57500 (1.54845 iter/s, 64.5809s/100 iters), loss = 0.00706779
I0927 06:41:40.916551 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00706782 (* 1 = 0.00706782 loss)
I0927 06:41:40.916568 19128 sgd_solver.cpp:165] Iteration 57500, lr = 0.001
I0927 06:42:11.269695 19128 solver.cpp:357] Iteration 57600 (3.29475 iter/s, 30.3513s/100 iters), loss = 0.00636876
I0927 06:42:11.269815 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00636879 (* 1 = 0.00636879 loss)
I0927 06:42:11.269829 19128 sgd_solver.cpp:165] Iteration 57600, lr = 0.001
I0927 06:42:42.848448 19128 solver.cpp:357] Iteration 57700 (3.16678 iter/s, 31.5779s/100 iters), loss = 0.0139897
I0927 06:42:42.848598 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0139897 (* 1 = 0.0139897 loss)
I0927 06:42:42.848609 19128 sgd_solver.cpp:165] Iteration 57700, lr = 0.001
I0927 06:43:18.890772 19128 solver.cpp:357] Iteration 57800 (2.77462 iter/s, 36.041s/100 iters), loss = 0.0125961
I0927 06:43:18.891034 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0125962 (* 1 = 0.0125962 loss)
I0927 06:43:18.891046 19128 sgd_solver.cpp:165] Iteration 57800, lr = 0.001
I0927 06:43:21.789063 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:43:54.924408 19128 solver.cpp:357] Iteration 57900 (2.77523 iter/s, 36.033s/100 iters), loss = 0.00900529
I0927 06:43:54.924584 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00900532 (* 1 = 0.00900532 loss)
I0927 06:43:54.924597 19128 sgd_solver.cpp:165] Iteration 57900, lr = 0.001
I0927 06:44:30.623375 19128 solver.cpp:514] Iteration 58000, Testing net (#0)
I0927 06:44:59.314695 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:44:59.458853 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.276899 (* 1 = 0.276899 loss)
I0927 06:44:59.458878 19128 solver.cpp:580]     Test net output #1: prob = 0.927302
I0927 06:44:59.722844 19128 solver.cpp:357] Iteration 58000 (1.54328 iter/s, 64.7969s/100 iters), loss = 0.012794
I0927 06:44:59.722905 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.012794 (* 1 = 0.012794 loss)
I0927 06:44:59.722918 19128 sgd_solver.cpp:165] Iteration 58000, lr = 0.001
I0927 06:45:30.181646 19128 solver.cpp:357] Iteration 58100 (3.28332 iter/s, 30.457s/100 iters), loss = 0.00635142
I0927 06:45:30.181875 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00635145 (* 1 = 0.00635145 loss)
I0927 06:45:30.181888 19128 sgd_solver.cpp:165] Iteration 58100, lr = 0.001
I0927 06:46:01.501554 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:46:01.852562 19128 solver.cpp:357] Iteration 58200 (3.15746 iter/s, 31.671s/100 iters), loss = 0.00893643
I0927 06:46:01.852684 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00893645 (* 1 = 0.00893645 loss)
I0927 06:46:01.852710 19128 sgd_solver.cpp:165] Iteration 58200, lr = 0.001
I0927 06:46:37.927126 19128 solver.cpp:357] Iteration 58300 (2.77202 iter/s, 36.0748s/100 iters), loss = 0.0137622
I0927 06:46:37.927269 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0137622 (* 1 = 0.0137622 loss)
I0927 06:46:37.927280 19128 sgd_solver.cpp:165] Iteration 58300, lr = 0.001
I0927 06:47:13.985982 19128 solver.cpp:357] Iteration 58400 (2.77338 iter/s, 36.0571s/100 iters), loss = 0.0194005
I0927 06:47:13.986095 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0194006 (* 1 = 0.0194006 loss)
I0927 06:47:13.986106 19128 sgd_solver.cpp:165] Iteration 58400, lr = 0.001
I0927 06:47:49.686043 19128 solver.cpp:514] Iteration 58500, Testing net (#0)
I0927 06:48:18.547386 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:48:18.689105 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.276676 (* 1 = 0.276676 loss)
I0927 06:48:18.689134 19128 solver.cpp:580]     Test net output #1: prob = 0.927803
I0927 06:48:18.950155 19128 solver.cpp:357] Iteration 58500 (1.5393 iter/s, 64.9645s/100 iters), loss = 0.0179216
I0927 06:48:18.950222 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0179217 (* 1 = 0.0179217 loss)
I0927 06:48:18.950232 19128 sgd_solver.cpp:165] Iteration 58500, lr = 0.001
I0927 06:48:46.207927 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:48:49.126354 19128 solver.cpp:357] Iteration 58600 (3.31407 iter/s, 30.1743s/100 iters), loss = 0.0143079
I0927 06:48:49.126418 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0143079 (* 1 = 0.0143079 loss)
I0927 06:48:49.126430 19128 sgd_solver.cpp:165] Iteration 58600, lr = 0.001
I0927 06:49:20.852211 19128 solver.cpp:357] Iteration 58700 (3.15198 iter/s, 31.7261s/100 iters), loss = 0.00605668
I0927 06:49:20.852324 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00605671 (* 1 = 0.00605671 loss)
I0927 06:49:20.852335 19128 sgd_solver.cpp:165] Iteration 58700, lr = 0.001
I0927 06:49:56.900842 19128 solver.cpp:357] Iteration 58800 (2.77404 iter/s, 36.0485s/100 iters), loss = 0.0103729
I0927 06:49:56.901015 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0103729 (* 1 = 0.0103729 loss)
I0927 06:49:56.901026 19128 sgd_solver.cpp:165] Iteration 58800, lr = 0.001
I0927 06:50:32.965318 19128 solver.cpp:357] Iteration 58900 (2.77295 iter/s, 36.0627s/100 iters), loss = 0.0187731
I0927 06:50:32.965492 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0187731 (* 1 = 0.0187731 loss)
I0927 06:50:32.965502 19128 sgd_solver.cpp:165] Iteration 58900, lr = 0.001
I0927 06:51:01.820058 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:51:08.667295 19128 solver.cpp:514] Iteration 59000, Testing net (#0)
I0927 06:51:37.268748 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:51:37.389120 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.276578 (* 1 = 0.276578 loss)
I0927 06:51:37.389160 19128 solver.cpp:580]     Test net output #1: prob = 0.926703
I0927 06:51:37.666857 19128 solver.cpp:357] Iteration 59000 (1.54557 iter/s, 64.7012s/100 iters), loss = 0.0048349
I0927 06:51:37.666924 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00483492 (* 1 = 0.00483492 loss)
I0927 06:51:37.666936 19128 sgd_solver.cpp:165] Iteration 59000, lr = 0.001
I0927 06:52:07.855599 19128 solver.cpp:357] Iteration 59100 (3.31269 iter/s, 30.1869s/100 iters), loss = 0.0128567
I0927 06:52:07.855805 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0128568 (* 1 = 0.0128568 loss)
I0927 06:52:07.855818 19128 sgd_solver.cpp:165] Iteration 59100, lr = 0.001
I0927 06:52:39.426115 19128 solver.cpp:357] Iteration 59200 (3.1675 iter/s, 31.5707s/100 iters), loss = 0.00772161
I0927 06:52:39.426302 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00772164 (* 1 = 0.00772164 loss)
I0927 06:52:39.426313 19128 sgd_solver.cpp:165] Iteration 59200, lr = 0.001
I0927 06:53:15.488731 19128 solver.cpp:357] Iteration 59300 (2.77301 iter/s, 36.0619s/100 iters), loss = 0.0127813
I0927 06:53:15.488843 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0127813 (* 1 = 0.0127813 loss)
I0927 06:53:15.488854 19128 sgd_solver.cpp:165] Iteration 59300, lr = 0.001
I0927 06:53:40.730271 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:53:51.524822 19128 solver.cpp:357] Iteration 59400 (2.775 iter/s, 36.0361s/100 iters), loss = 0.0392986
I0927 06:53:51.524936 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0392986 (* 1 = 0.0392986 loss)
I0927 06:53:51.524947 19128 sgd_solver.cpp:165] Iteration 59400, lr = 0.001
I0927 06:54:27.230937 19128 solver.cpp:514] Iteration 59500, Testing net (#0)
I0927 06:54:55.879333 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:54:55.986482 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.270235 (* 1 = 0.270235 loss)
I0927 06:54:55.986519 19128 solver.cpp:580]     Test net output #1: prob = 0.929602
I0927 06:54:56.276044 19128 solver.cpp:357] Iteration 59500 (1.54436 iter/s, 64.7516s/100 iters), loss = 0.00721234
I0927 06:54:56.276104 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00721236 (* 1 = 0.00721236 loss)
I0927 06:54:56.276115 19128 sgd_solver.cpp:165] Iteration 59500, lr = 0.001
I0927 06:55:26.664700 19128 solver.cpp:357] Iteration 59600 (3.29067 iter/s, 30.3889s/100 iters), loss = 0.00944839
I0927 06:55:26.664861 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00944841 (* 1 = 0.00944841 loss)
I0927 06:55:26.664873 19128 sgd_solver.cpp:165] Iteration 59600, lr = 0.001
I0927 06:55:58.274500 19128 solver.cpp:357] Iteration 59700 (3.16367 iter/s, 31.6089s/100 iters), loss = 0.0152288
I0927 06:55:58.274662 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0152288 (* 1 = 0.0152288 loss)
I0927 06:55:58.274674 19128 sgd_solver.cpp:165] Iteration 59700, lr = 0.001
I0927 06:56:20.271173 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:56:34.117103 19128 solver.cpp:357] Iteration 59800 (2.79011 iter/s, 35.8409s/100 iters), loss = 0.0145327
I0927 06:56:34.117240 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0145327 (* 1 = 0.0145327 loss)
I0927 06:56:34.117251 19128 sgd_solver.cpp:165] Iteration 59800, lr = 0.001
I0927 06:57:10.272712 19128 solver.cpp:357] Iteration 59900 (2.76595 iter/s, 36.1539s/100 iters), loss = 0.0134177
I0927 06:57:10.272857 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0134177 (* 1 = 0.0134177 loss)
I0927 06:57:10.272867 19128 sgd_solver.cpp:165] Iteration 59900, lr = 0.001
I0927 06:57:45.965772 19128 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_60000.caffemodel
I0927 06:57:45.982843 19128 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_60000.solverstate
I0927 06:57:46.024435 19128 solver.cpp:514] Iteration 60000, Testing net (#0)
I0927 06:58:14.989424 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:58:15.095744 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.272765 (* 1 = 0.272765 loss)
I0927 06:58:15.095782 19128 solver.cpp:580]     Test net output #1: prob = 0.928602
I0927 06:58:15.384927 19128 solver.cpp:357] Iteration 60000 (1.53582 iter/s, 65.112s/100 iters), loss = 0.00721546
I0927 06:58:15.384989 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00721549 (* 1 = 0.00721549 loss)
I0927 06:58:15.384999 19128 sgd_solver.cpp:165] Iteration 60000, lr = 0.001
I0927 06:58:45.457778 19128 solver.cpp:357] Iteration 60100 (3.32523 iter/s, 30.0731s/100 iters), loss = 0.0129291
I0927 06:58:45.457962 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0129291 (* 1 = 0.0129291 loss)
I0927 06:58:45.457974 19128 sgd_solver.cpp:165] Iteration 60100, lr = 0.001
I0927 06:58:59.951752 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 06:59:17.185670 19128 solver.cpp:357] Iteration 60200 (3.15197 iter/s, 31.7262s/100 iters), loss = 0.0046784
I0927 06:59:17.185784 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00467842 (* 1 = 0.00467842 loss)
I0927 06:59:17.185794 19128 sgd_solver.cpp:165] Iteration 60200, lr = 0.001
I0927 06:59:53.244637 19128 solver.cpp:357] Iteration 60300 (2.77314 iter/s, 36.0602s/100 iters), loss = 0.018295
I0927 06:59:53.244750 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.018295 (* 1 = 0.018295 loss)
I0927 06:59:53.244761 19128 sgd_solver.cpp:165] Iteration 60300, lr = 0.001
I0927 07:00:29.286345 19128 solver.cpp:357] Iteration 60400 (2.7744 iter/s, 36.0438s/100 iters), loss = 0.00666456
I0927 07:00:29.286453 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00666458 (* 1 = 0.00666458 loss)
I0927 07:00:29.286463 19128 sgd_solver.cpp:165] Iteration 60400, lr = 0.001
I0927 07:01:04.958164 19128 solver.cpp:514] Iteration 60500, Testing net (#0)
I0927 07:01:33.574277 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:01:33.667469 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.276553 (* 1 = 0.276553 loss)
I0927 07:01:33.667505 19128 solver.cpp:580]     Test net output #1: prob = 0.927802
I0927 07:01:33.970782 19128 solver.cpp:357] Iteration 60500 (1.54587 iter/s, 64.6885s/100 iters), loss = 0.00365477
I0927 07:01:33.970846 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00365479 (* 1 = 0.00365479 loss)
I0927 07:01:33.970856 19128 sgd_solver.cpp:165] Iteration 60500, lr = 0.001
I0927 07:01:48.815697 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:02:04.184057 19128 solver.cpp:357] Iteration 60600 (3.30961 iter/s, 30.215s/100 iters), loss = 0.00542899
I0927 07:02:04.184129 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00542901 (* 1 = 0.00542901 loss)
I0927 07:02:04.184146 19128 sgd_solver.cpp:165] Iteration 60600, lr = 0.001
I0927 07:02:36.129581 19128 solver.cpp:357] Iteration 60700 (3.13036 iter/s, 31.9452s/100 iters), loss = 0.0212785
I0927 07:02:36.129706 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0212785 (* 1 = 0.0212785 loss)
I0927 07:02:36.129715 19128 sgd_solver.cpp:165] Iteration 60700, lr = 0.001
I0927 07:03:12.181699 19128 solver.cpp:357] Iteration 60800 (2.77362 iter/s, 36.054s/100 iters), loss = 0.0040781
I0927 07:03:12.181957 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00407813 (* 1 = 0.00407813 loss)
I0927 07:03:12.181967 19128 sgd_solver.cpp:165] Iteration 60800, lr = 0.001
I0927 07:03:48.212815 19128 solver.cpp:357] Iteration 60900 (2.7753 iter/s, 36.0321s/100 iters), loss = 0.0221047
I0927 07:03:48.212945 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0221047 (* 1 = 0.0221047 loss)
I0927 07:03:48.212956 19128 sgd_solver.cpp:165] Iteration 60900, lr = 0.001
I0927 07:04:00.124748 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:04:23.906738 19128 solver.cpp:514] Iteration 61000, Testing net (#0)
I0927 07:04:52.551582 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:04:52.640301 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.278291 (* 1 = 0.278291 loss)
I0927 07:04:52.640338 19128 solver.cpp:580]     Test net output #1: prob = 0.928002
I0927 07:04:52.943678 19128 solver.cpp:357] Iteration 61000 (1.54483 iter/s, 64.732s/100 iters), loss = 0.00831507
I0927 07:04:52.943732 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00831509 (* 1 = 0.00831509 loss)
I0927 07:04:52.943742 19128 sgd_solver.cpp:165] Iteration 61000, lr = 0.001
I0927 07:05:22.929340 19128 solver.cpp:357] Iteration 61100 (3.33477 iter/s, 29.987s/100 iters), loss = 0.0160626
I0927 07:05:22.929540 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0160627 (* 1 = 0.0160627 loss)
I0927 07:05:22.929551 19128 sgd_solver.cpp:165] Iteration 61100, lr = 0.001
I0927 07:05:54.700160 19128 solver.cpp:357] Iteration 61200 (3.14742 iter/s, 31.7721s/100 iters), loss = 0.00940065
I0927 07:05:54.700286 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00940068 (* 1 = 0.00940068 loss)
I0927 07:05:54.700297 19128 sgd_solver.cpp:165] Iteration 61200, lr = 0.001
I0927 07:06:30.869791 19128 solver.cpp:357] Iteration 61300 (2.76479 iter/s, 36.1691s/100 iters), loss = 0.0244682
I0927 07:06:30.869918 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0244682 (* 1 = 0.0244682 loss)
I0927 07:06:30.869928 19128 sgd_solver.cpp:165] Iteration 61300, lr = 0.001
I0927 07:06:39.531841 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:07:06.909529 19128 solver.cpp:357] Iteration 61400 (2.77473 iter/s, 36.0396s/100 iters), loss = 0.0199828
I0927 07:07:06.909678 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0199828 (* 1 = 0.0199828 loss)
I0927 07:07:06.909689 19128 sgd_solver.cpp:165] Iteration 61400, lr = 0.001
I0927 07:07:42.588914 19128 solver.cpp:514] Iteration 61500, Testing net (#0)
I0927 07:08:11.165087 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:08:11.266381 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.277425 (* 1 = 0.277425 loss)
I0927 07:08:11.266419 19128 solver.cpp:580]     Test net output #1: prob = 0.927703
I0927 07:08:11.567819 19128 solver.cpp:357] Iteration 61500 (1.54655 iter/s, 64.6601s/100 iters), loss = 0.0106868
I0927 07:08:11.567893 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0106868 (* 1 = 0.0106868 loss)
I0927 07:08:11.567904 19128 sgd_solver.cpp:165] Iteration 61500, lr = 0.001
I0927 07:08:41.650633 19128 solver.cpp:357] Iteration 61600 (3.32427 iter/s, 30.0818s/100 iters), loss = 0.0068383
I0927 07:08:41.650797 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00683833 (* 1 = 0.00683833 loss)
I0927 07:08:41.650815 19128 sgd_solver.cpp:165] Iteration 61600, lr = 0.001
I0927 07:09:03.015911 19128 solver.cpp:357] Iteration 61700 (4.68079 iter/s, 21.3639s/100 iters), loss = 0.00990812
I0927 07:09:03.015975 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00990815 (* 1 = 0.00990815 loss)
I0927 07:09:03.015985 19128 sgd_solver.cpp:165] Iteration 61700, lr = 0.001
I0927 07:09:05.438371 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:09:20.243453 19128 solver.cpp:357] Iteration 61800 (5.80445 iter/s, 17.2281s/100 iters), loss = 0.0128826
I0927 07:09:20.243575 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0128827 (* 1 = 0.0128827 loss)
I0927 07:09:20.243587 19128 sgd_solver.cpp:165] Iteration 61800, lr = 0.001
I0927 07:09:37.471351 19128 solver.cpp:357] Iteration 61900 (5.80436 iter/s, 17.2284s/100 iters), loss = 0.0198371
I0927 07:09:37.471415 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0198371 (* 1 = 0.0198371 loss)
I0927 07:09:37.471426 19128 sgd_solver.cpp:165] Iteration 61900, lr = 0.001
I0927 07:09:54.541640 19128 solver.cpp:514] Iteration 62000, Testing net (#0)
I0927 07:09:59.457293 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:09:59.475908 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.280241 (* 1 = 0.280241 loss)
I0927 07:09:59.475935 19128 solver.cpp:580]     Test net output #1: prob = 0.927302
I0927 07:09:59.645473 19128 solver.cpp:357] Iteration 62000 (4.5096 iter/s, 22.1749s/100 iters), loss = 0.0115474
I0927 07:09:59.645520 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0115474 (* 1 = 0.0115474 loss)
I0927 07:09:59.645531 19128 sgd_solver.cpp:165] Iteration 62000, lr = 0.001
I0927 07:10:16.874770 19128 solver.cpp:357] Iteration 62100 (5.80387 iter/s, 17.2299s/100 iters), loss = 0.0142834
I0927 07:10:16.874841 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0142834 (* 1 = 0.0142834 loss)
I0927 07:10:16.874850 19128 sgd_solver.cpp:165] Iteration 62100, lr = 0.001
I0927 07:10:17.740044 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:10:34.101415 19128 solver.cpp:357] Iteration 62200 (5.80477 iter/s, 17.2272s/100 iters), loss = 0.0151968
I0927 07:10:34.101706 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0151968 (* 1 = 0.0151968 loss)
I0927 07:10:34.101716 19128 sgd_solver.cpp:165] Iteration 62200, lr = 0.001
I0927 07:10:51.333719 19128 solver.cpp:357] Iteration 62300 (5.80294 iter/s, 17.2326s/100 iters), loss = 0.0113102
I0927 07:10:51.333783 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0113102 (* 1 = 0.0113102 loss)
I0927 07:10:51.333794 19128 sgd_solver.cpp:165] Iteration 62300, lr = 0.001
I0927 07:11:08.556818 19128 solver.cpp:357] Iteration 62400 (5.80597 iter/s, 17.2236s/100 iters), loss = 0.00922321
I0927 07:11:08.556972 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00922323 (* 1 = 0.00922323 loss)
I0927 07:11:08.556983 19128 sgd_solver.cpp:165] Iteration 62400, lr = 0.001
I0927 07:11:24.935415 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:11:25.611567 19128 solver.cpp:514] Iteration 62500, Testing net (#0)
I0927 07:11:30.512142 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:11:30.530792 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.278595 (* 1 = 0.278595 loss)
I0927 07:11:30.530835 19128 solver.cpp:580]     Test net output #1: prob = 0.928503
I0927 07:11:30.700062 19128 solver.cpp:357] Iteration 62500 (4.51592 iter/s, 22.1439s/100 iters), loss = 0.0120472
I0927 07:11:30.700106 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0120473 (* 1 = 0.0120473 loss)
I0927 07:11:30.700120 19128 sgd_solver.cpp:165] Iteration 62500, lr = 0.001
I0927 07:11:47.930186 19128 solver.cpp:357] Iteration 62600 (5.8036 iter/s, 17.2307s/100 iters), loss = 0.0117338
I0927 07:11:47.930331 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0117338 (* 1 = 0.0117338 loss)
I0927 07:11:47.930341 19128 sgd_solver.cpp:165] Iteration 62600, lr = 0.001
I0927 07:12:05.158448 19128 solver.cpp:357] Iteration 62700 (5.80426 iter/s, 17.2287s/100 iters), loss = 0.0113955
I0927 07:12:05.158514 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0113956 (* 1 = 0.0113956 loss)
I0927 07:12:05.158522 19128 sgd_solver.cpp:165] Iteration 62700, lr = 0.001
I0927 07:12:22.390523 19128 solver.cpp:357] Iteration 62800 (5.80296 iter/s, 17.2326s/100 iters), loss = 0.00894876
I0927 07:12:22.390628 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00894879 (* 1 = 0.00894879 loss)
I0927 07:12:22.390640 19128 sgd_solver.cpp:165] Iteration 62800, lr = 0.001
I0927 07:12:37.214151 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:12:39.614941 19128 solver.cpp:357] Iteration 62900 (5.80555 iter/s, 17.2249s/100 iters), loss = 0.0199881
I0927 07:12:39.615000 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0199881 (* 1 = 0.0199881 loss)
I0927 07:12:39.615010 19128 sgd_solver.cpp:165] Iteration 62900, lr = 0.001
I0927 07:12:56.670869 19128 solver.cpp:514] Iteration 63000, Testing net (#0)
I0927 07:13:01.548596 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:13:01.566865 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.276627 (* 1 = 0.276627 loss)
I0927 07:13:01.566891 19128 solver.cpp:580]     Test net output #1: prob = 0.928602
I0927 07:13:01.736032 19128 solver.cpp:357] Iteration 63000 (4.52043 iter/s, 22.1218s/100 iters), loss = 0.0104143
I0927 07:13:01.736078 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0104143 (* 1 = 0.0104143 loss)
I0927 07:13:01.736089 19128 sgd_solver.cpp:165] Iteration 63000, lr = 0.001
I0927 07:13:18.962782 19128 solver.cpp:357] Iteration 63100 (5.80475 iter/s, 17.2273s/100 iters), loss = 0.00558678
I0927 07:13:18.962854 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00558681 (* 1 = 0.00558681 loss)
I0927 07:13:18.962863 19128 sgd_solver.cpp:165] Iteration 63100, lr = 0.001
I0927 07:13:36.197840 19128 solver.cpp:357] Iteration 63200 (5.80196 iter/s, 17.2355s/100 iters), loss = 0.00641534
I0927 07:13:36.198050 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00641538 (* 1 = 0.00641538 loss)
I0927 07:13:36.198060 19128 sgd_solver.cpp:165] Iteration 63200, lr = 0.001
I0927 07:13:49.473464 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:13:53.434536 19128 solver.cpp:357] Iteration 63300 (5.80146 iter/s, 17.237s/100 iters), loss = 0.00851932
I0927 07:13:53.434602 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00851935 (* 1 = 0.00851935 loss)
I0927 07:13:53.434610 19128 sgd_solver.cpp:165] Iteration 63300, lr = 0.001
I0927 07:14:10.660502 19128 solver.cpp:357] Iteration 63400 (5.80503 iter/s, 17.2265s/100 iters), loss = 0.00681899
I0927 07:14:10.660657 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00681902 (* 1 = 0.00681902 loss)
I0927 07:14:10.660667 19128 sgd_solver.cpp:165] Iteration 63400, lr = 0.001
I0927 07:14:27.718417 19128 solver.cpp:514] Iteration 63500, Testing net (#0)
I0927 07:14:32.653543 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:14:32.672147 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.28246 (* 1 = 0.28246 loss)
I0927 07:14:32.672174 19128 solver.cpp:580]     Test net output #1: prob = 0.928603
I0927 07:14:32.841918 19128 solver.cpp:357] Iteration 63500 (4.50817 iter/s, 22.182s/100 iters), loss = 0.0197607
I0927 07:14:32.841965 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.0197607 (* 1 = 0.0197607 loss)
I0927 07:14:32.841977 19128 sgd_solver.cpp:165] Iteration 63500, lr = 0.001
I0927 07:14:50.075806 19128 solver.cpp:357] Iteration 63600 (5.80236 iter/s, 17.2344s/100 iters), loss = 0.00432719
I0927 07:14:50.075955 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00432722 (* 1 = 0.00432722 loss)
I0927 07:14:50.075965 19128 sgd_solver.cpp:165] Iteration 63600, lr = 0.001
I0927 07:15:01.634964 19133 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:15:07.306385 19128 solver.cpp:357] Iteration 63700 (5.80351 iter/s, 17.231s/100 iters), loss = 0.0134369
I0927 07:15:07.306449 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.013437 (* 1 = 0.013437 loss)
I0927 07:15:07.306462 19128 sgd_solver.cpp:165] Iteration 63700, lr = 0.001
I0927 07:15:24.540606 19128 solver.cpp:357] Iteration 63800 (5.80225 iter/s, 17.2347s/100 iters), loss = 0.00737657
I0927 07:15:24.540745 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00737659 (* 1 = 0.00737659 loss)
I0927 07:15:24.540755 19128 sgd_solver.cpp:165] Iteration 63800, lr = 0.001
I0927 07:15:41.777382 19128 solver.cpp:357] Iteration 63900 (5.80142 iter/s, 17.2372s/100 iters), loss = 0.00461021
I0927 07:15:41.777446 19128 solver.cpp:376]     Train net output #0: Softmax1 = 0.00461023 (* 1 = 0.00461023 loss)
I0927 07:15:41.777456 19128 sgd_solver.cpp:165] Iteration 63900, lr = 0.001
I0927 07:15:58.840015 19128 solver.cpp:671] Snapshotting to binary proto file ./model_save/cifar10_ResNet_32_iter_64000.caffemodel
I0927 07:15:58.853572 19128 sgd_solver.cpp:372] Snapshotting solver state to binary proto file ./model_save/cifar10_ResNet_32_iter_64000.solverstate
I0927 07:15:58.947234 19128 solver.cpp:472] Iteration 64000, loss = 0.00444215
I0927 07:15:58.947283 19128 solver.cpp:514] Iteration 64000, Testing net (#0)
I0927 07:16:03.859984 19134 data_layer.cpp:73] Restarting data prefetching from start.
I0927 07:16:03.877959 19128 solver.cpp:580]     Test net output #0: Softmax1 = 0.285888 (* 1 = 0.285888 loss)
I0927 07:16:03.877986 19128 solver.cpp:580]     Test net output #1: prob = 0.928102
I0927 07:16:03.877993 19128 solver.cpp:479] Optimization Done.
I0927 07:16:03.877998 19128 caffe.cpp:326] Optimization Done.
